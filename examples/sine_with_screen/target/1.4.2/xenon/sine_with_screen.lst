
/Users/bsatrom/Development/particle/libraries/Particle_TensorFlowLite_Examples/sine_with_screen/target/1.4.2/xenon/sine_with_screen.elf:     file format elf32-littlearm

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .module_info  00000018  000d4000  000d4000  00004000  2**2
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  1 .dynalib      00000004  000d4018  000d4018  00004018  2**2
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  2 .text         00019500  000d4020  000d4020  00004020  2**3
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  3 .backup       00000000  2003f400  2003f400  0002daf0  2**0
                  CONTENTS
  4 .data         000005a4  2003bcf8  000ed520  0002bcf8  2**3
                  CONTENTS, ALLOC, LOAD, DATA
  5 .bss          00002554  2003c2a0  2003c2a0  0003c2a0  2**3
                  ALLOC
  6 .module_info_suffix 00000028  000edac4  000edac4  0002dac4  2**0
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  7 .module_info_crc 00000004  000edaec  000edaec  0002daec  2**0
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  8 .debug_info   002b2ce1  00000000  00000000  0002daf0  2**0
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_abbrev 000299f2  00000000  00000000  002e07d1  2**0
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_loc    0005ad1d  00000000  00000000  0030a1c3  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_aranges 00003b00  00000000  00000000  00364ee0  2**0
                  CONTENTS, READONLY, DEBUGGING
 12 .debug_ranges 00009d90  00000000  00000000  003689e0  2**0
                  CONTENTS, READONLY, DEBUGGING
 13 .debug_macro  0004fcf5  00000000  00000000  00372770  2**0
                  CONTENTS, READONLY, DEBUGGING
 14 .debug_line   00068549  00000000  00000000  003c2465  2**0
                  CONTENTS, READONLY, DEBUGGING
 15 .debug_str    00190f68  00000000  00000000  0042a9ae  2**0
                  CONTENTS, READONLY, DEBUGGING
 16 .debug_frame  00011b84  00000000  00000000  005bb918  2**2
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

000d4020 <module_user_pre_init>:
/**
 * Initializes this user module. Returns the start of the heap.
 */
void* module_user_pre_init() {

    if ( (&link_global_data_start!=&link_global_data_initial_values) && (link_global_data_size != 0))
   d4020:	4809      	ldr	r0, [pc, #36]	; (d4048 <module_user_pre_init+0x28>)
   d4022:	490a      	ldr	r1, [pc, #40]	; (d404c <module_user_pre_init+0x2c>)
   d4024:	4288      	cmp	r0, r1
extern constructor_ptr_t link_constructors_end;

/**
 * Initializes this user module. Returns the start of the heap.
 */
void* module_user_pre_init() {
   d4026:	b508      	push	{r3, lr}

    if ( (&link_global_data_start!=&link_global_data_initial_values) && (link_global_data_size != 0))
   d4028:	d005      	beq.n	d4036 <module_user_pre_init+0x16>
   d402a:	4a09      	ldr	r2, [pc, #36]	; (d4050 <module_user_pre_init+0x30>)
   d402c:	4282      	cmp	r2, r0
   d402e:	d002      	beq.n	d4036 <module_user_pre_init+0x16>
    {
        memcpy(&link_global_data_start, &link_global_data_initial_values, link_global_data_size);
   d4030:	1a12      	subs	r2, r2, r0
   d4032:	f014 fd96 	bl	e8b62 <memcpy>
    }

    memset(&link_bss_location, 0, link_bss_size );
   d4036:	4807      	ldr	r0, [pc, #28]	; (d4054 <module_user_pre_init+0x34>)
   d4038:	4a07      	ldr	r2, [pc, #28]	; (d4058 <module_user_pre_init+0x38>)
   d403a:	2100      	movs	r1, #0
   d403c:	1a12      	subs	r2, r2, r0
   d403e:	f014 fd9b 	bl	e8b78 <memset>
    return &link_global_data_start;
}
   d4042:	4801      	ldr	r0, [pc, #4]	; (d4048 <module_user_pre_init+0x28>)
   d4044:	bd08      	pop	{r3, pc}
   d4046:	bf00      	nop
   d4048:	2003bcf8 	.word	0x2003bcf8
   d404c:	000ed520 	.word	0x000ed520
   d4050:	2003c29c 	.word	0x2003c29c
   d4054:	2003c2a0 	.word	0x2003c2a0
   d4058:	2003e7f4 	.word	0x2003e7f4

000d405c <module_user_init>:
extern constructor_ptr_t link_constructors_location[];
extern constructor_ptr_t link_constructors_end;
#define link_constructors_size   ((unsigned long)&link_constructors_end  -  (unsigned long)&link_constructors_location )

void module_user_init()
{
   d405c:	b570      	push	{r4, r5, r6, lr}
    module_user_init_hook();
   d405e:	f011 ffd3 	bl	e6008 <module_user_init_hook>
   d4062:	4c07      	ldr	r4, [pc, #28]	; (d4080 <module_user_init+0x24>)
   d4064:	4b07      	ldr	r3, [pc, #28]	; (d4084 <module_user_init+0x28>)
   d4066:	1ae4      	subs	r4, r4, r3
   d4068:	08a4      	lsrs	r4, r4, #2

    // invoke constructors
    int ctor_num;
    for (ctor_num=0; ctor_num < link_constructors_size/sizeof(constructor_ptr_t); ctor_num++ )
   d406a:	2500      	movs	r5, #0
   d406c:	461e      	mov	r6, r3
   d406e:	42a5      	cmp	r5, r4
   d4070:	d004      	beq.n	d407c <module_user_init+0x20>
    {
        link_constructors_location[ctor_num]();
   d4072:	f856 3025 	ldr.w	r3, [r6, r5, lsl #2]
   d4076:	4798      	blx	r3
{
    module_user_init_hook();

    // invoke constructors
    int ctor_num;
    for (ctor_num=0; ctor_num < link_constructors_size/sizeof(constructor_ptr_t); ctor_num++ )
   d4078:	3501      	adds	r5, #1
   d407a:	e7f8      	b.n	d406e <module_user_init+0x12>
    {
        link_constructors_location[ctor_num]();
    }
}
   d407c:	bd70      	pop	{r4, r5, r6, pc}
   d407e:	bf00      	nop
   d4080:	000ed514 	.word	0x000ed514
   d4084:	000ed4c4 	.word	0x000ed4c4

000d4088 <module_user_setup>:

/**
 * Export these functions with a fuller name so they don't clash with the setup/loop wrappers in the system module.
 */
void module_user_setup() {
    setup();
   d4088:	f000 b9c2 	b.w	d4410 <setup>

000d408c <module_user_loop>:
}

void module_user_loop() {
   d408c:	b508      	push	{r3, lr}
    loop();
   d408e:	f000 f8a3 	bl	d41d8 <loop>
    _post_loop();
}
   d4092:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
    setup();
}

void module_user_loop() {
    loop();
    _post_loop();
   d4096:	f011 bf85 	b.w	e5fa4 <_post_loop>

000d409a <_Znaj>:
	return malloc(size);
}

void *operator new[](size_t size)
{
	return malloc(size);
   d409a:	f011 ba13 	b.w	e54c4 <malloc>

000d409e <_ZdlPv>:
   d409e:	f011 ba19 	b.w	e54d4 <free>

000d40a2 <_ZdaPv>:
	free(p);
}

void operator delete[](void *p)
{
	free(p);
   d40a2:	f011 ba17 	b.w	e54d4 <free>
	...

000d40a8 <_exit>:
int _getpid(void)
{
	return 1;
}

void _exit(int status) {
   d40a8:	b508      	push	{r3, lr}
    PANIC(Exit,"Exit Called");
   d40aa:	4a03      	ldr	r2, [pc, #12]	; (d40b8 <_exit+0x10>)
   d40ac:	2100      	movs	r1, #0
   d40ae:	2007      	movs	r0, #7
   d40b0:	f011 f97c 	bl	e53ac <panic_>
   d40b4:	e7fe      	b.n	d40b4 <_exit+0xc>
   d40b6:	bf00      	nop
   d40b8:	000e510d 	.word	0x000e510d

000d40bc <__cxa_pure_virtual>:
        ;
    }
}

/* Default implementation for call made to pure virtual function. */
void __cxa_pure_virtual() {
   d40bc:	b508      	push	{r3, lr}
  PANIC(PureVirtualCall,"Call on pure virtual");
   d40be:	4a03      	ldr	r2, [pc, #12]	; (d40cc <__cxa_pure_virtual+0x10>)
   d40c0:	2100      	movs	r1, #0
   d40c2:	200c      	movs	r0, #12
   d40c4:	f011 f972 	bl	e53ac <panic_>
   d40c8:	e7fe      	b.n	d40c8 <__cxa_pure_virtual+0xc>
   d40ca:	bf00      	nop
   d40cc:	000e510d 	.word	0x000e510d

000d40d0 <__cxa_guard_acquire>:

/* Provide default implemenation for __cxa_guard_acquire() and
 * __cxa_guard_release(). Note: these must be revisited if a multitasking
 * OS is ported to this platform. */
__extension__ typedef int __guard __attribute__((mode (__DI__)));
int __cxa_guard_acquire(__guard *g) {return !*(char *)(g);};
   d40d0:	7800      	ldrb	r0, [r0, #0]
   d40d2:	fab0 f080 	clz	r0, r0
   d40d6:	0940      	lsrs	r0, r0, #5
   d40d8:	4770      	bx	lr

000d40da <__cxa_guard_release>:
void __cxa_guard_release (__guard *g) {*(char *)g = 1;};
   d40da:	2301      	movs	r3, #1
   d40dc:	7003      	strb	r3, [r0, #0]
   d40de:	4770      	bx	lr

000d40e0 <TfLiteIntArrayEqualsArray>:
  if (a == NULL || b == NULL) return 0;
  return TfLiteIntArrayEqualsArray(a, b->size, b->data);
}

int TfLiteIntArrayEqualsArray(const TfLiteIntArray* a, int b_size,
                              const int b_data[]) {
   d40e0:	b530      	push	{r4, r5, lr}
  if (a == NULL) return (b_size == 0);
   d40e2:	b918      	cbnz	r0, d40ec <TfLiteIntArrayEqualsArray+0xc>
   d40e4:	fab1 f081 	clz	r0, r1
   d40e8:	0940      	lsrs	r0, r0, #5
   d40ea:	bd30      	pop	{r4, r5, pc}
  if (a->size != b_size) return 0;
   d40ec:	6803      	ldr	r3, [r0, #0]
   d40ee:	4299      	cmp	r1, r3
   d40f0:	d10c      	bne.n	d410c <TfLiteIntArrayEqualsArray+0x2c>
   d40f2:	2300      	movs	r3, #0
  int i = 0;
  for (; i < a->size; i++)
   d40f4:	428b      	cmp	r3, r1
   d40f6:	da07      	bge.n	d4108 <TfLiteIntArrayEqualsArray+0x28>
    if (a->data[i] != b_data[i]) return 0;
   d40f8:	f850 5f04 	ldr.w	r5, [r0, #4]!
   d40fc:	f852 4023 	ldr.w	r4, [r2, r3, lsl #2]
   d4100:	42a5      	cmp	r5, r4
   d4102:	d103      	bne.n	d410c <TfLiteIntArrayEqualsArray+0x2c>
int TfLiteIntArrayEqualsArray(const TfLiteIntArray* a, int b_size,
                              const int b_data[]) {
  if (a == NULL) return (b_size == 0);
  if (a->size != b_size) return 0;
  int i = 0;
  for (; i < a->size; i++)
   d4104:	3301      	adds	r3, #1
   d4106:	e7f5      	b.n	d40f4 <TfLiteIntArrayEqualsArray+0x14>
    if (a->data[i] != b_data[i]) return 0;
  return 1;
   d4108:	2001      	movs	r0, #1
   d410a:	bd30      	pop	{r4, r5, pc}
}

int TfLiteIntArrayEqualsArray(const TfLiteIntArray* a, int b_size,
                              const int b_data[]) {
  if (a == NULL) return (b_size == 0);
  if (a->size != b_size) return 0;
   d410c:	2000      	movs	r0, #0
  int i = 0;
  for (; i < a->size; i++)
    if (a->data[i] != b_data[i]) return 0;
  return 1;
}
   d410e:	bd30      	pop	{r4, r5, pc}

000d4110 <TfLiteIntArrayEqual>:
  static TfLiteIntArray dummy;
  return sizeof(dummy) + sizeof(dummy.data[0]) * size;
}

int TfLiteIntArrayEqual(const TfLiteIntArray* a, const TfLiteIntArray* b) {
  if (a == b) return 1;
   d4110:	4288      	cmp	r0, r1
   d4112:	d005      	beq.n	d4120 <TfLiteIntArrayEqual+0x10>
  if (a == NULL || b == NULL) return 0;
   d4114:	b130      	cbz	r0, d4124 <TfLiteIntArrayEqual+0x14>
   d4116:	b131      	cbz	r1, d4126 <TfLiteIntArrayEqual+0x16>
  return TfLiteIntArrayEqualsArray(a, b->size, b->data);
   d4118:	1d0a      	adds	r2, r1, #4
   d411a:	6809      	ldr	r1, [r1, #0]
   d411c:	f7ff bfe0 	b.w	d40e0 <TfLiteIntArrayEqualsArray>
  static TfLiteIntArray dummy;
  return sizeof(dummy) + sizeof(dummy.data[0]) * size;
}

int TfLiteIntArrayEqual(const TfLiteIntArray* a, const TfLiteIntArray* b) {
  if (a == b) return 1;
   d4120:	2001      	movs	r0, #1
   d4122:	4770      	bx	lr
   d4124:	4770      	bx	lr
  if (a == NULL || b == NULL) return 0;
   d4126:	4608      	mov	r0, r1
  return TfLiteIntArrayEqualsArray(a, b->size, b->data);
}
   d4128:	4770      	bx	lr
	...

000d412c <TfLiteTypeGetName>:
  }
  tensor->bytes = num_bytes;
}
#endif  // TF_LITE_STATIC_MEMORY

const char* TfLiteTypeGetName(TfLiteType type) {
   d412c:	280a      	cmp	r0, #10
   d412e:	bf9a      	itte	ls
   d4130:	4b02      	ldrls	r3, [pc, #8]	; (d413c <TfLiteTypeGetName+0x10>)
   d4132:	f853 0020 	ldrls.w	r0, [r3, r0, lsl #2]
   d4136:	4802      	ldrhi	r0, [pc, #8]	; (d4140 <TfLiteTypeGetName+0x14>)
      return "STRING";
    case kTfLiteFloat16:
      return "FLOAT16";
  }
  return "Unknown type";
}
   d4138:	4770      	bx	lr
   d413a:	bf00      	nop
   d413c:	000e8c74 	.word	0x000e8c74
   d4140:	000e8c20 	.word	0x000e8c20

000d4144 <_Z12HandleOutputPN6tflite13ErrorReporterEff>:
bool initialized = false;

// Animates a dot across the screen to represent the current x and y values
void HandleOutput(tflite::ErrorReporter *error_reporter, float x_value,
                  float y_value)
{
   d4144:	b570      	push	{r4, r5, r6, lr}
  // Do this only once
  if (!initialized)
   d4146:	4d15      	ldr	r5, [pc, #84]	; (d419c <_Z12HandleOutputPN6tflite13ErrorReporterEff+0x58>)
   d4148:	4c15      	ldr	r4, [pc, #84]	; (d41a0 <_Z12HandleOutputPN6tflite13ErrorReporterEff+0x5c>)
   d414a:	782b      	ldrb	r3, [r5, #0]
bool initialized = false;

// Animates a dot across the screen to represent the current x and y values
void HandleOutput(tflite::ErrorReporter *error_reporter, float x_value,
                  float y_value)
{
   d414c:	ed2d 8b02 	vpush	{d8}
   d4150:	4606      	mov	r6, r0
   d4152:	b082      	sub	sp, #8
   d4154:	eeb0 8a60 	vmov.f32	s16, s1
  // Do this only once
  if (!initialized)
   d4158:	b92b      	cbnz	r3, d4166 <_Z12HandleOutputPN6tflite13ErrorReporterEff+0x22>
  {
    // Set the LED pin to output
    pinMode(led, OUTPUT);
   d415a:	2101      	movs	r1, #1
   d415c:	8820      	ldrh	r0, [r4, #0]
   d415e:	f011 ff91 	bl	e6084 <pinMode>
    initialized = true;
   d4162:	2301      	movs	r3, #1
   d4164:	702b      	strb	r3, [r5, #0]
  }

  // Calculate the brightness of the LED such that y=-1 is fully off
  // and y=1 is fully on. The LED's brightness can range from 0-255.
  int brightness = (int)(127.5f * (y_value + 1));
   d4166:	eef7 0a00 	vmov.f32	s1, #112	; 0x3f800000  1.0
   d416a:	ee78 0a20 	vadd.f32	s1, s16, s1
   d416e:	eddf 7a0d 	vldr	s15, [pc, #52]	; d41a4 <_Z12HandleOutputPN6tflite13ErrorReporterEff+0x60>

  // Set the brightness of the LED. If the specified pin does not support PWM,
  // this will result in the LED being on when y > 127, off otherwise.
  analogWrite(led, brightness);
   d4172:	8820      	ldrh	r0, [r4, #0]
    initialized = true;
  }

  // Calculate the brightness of the LED such that y=-1 is fully off
  // and y=1 is fully on. The LED's brightness can range from 0-255.
  int brightness = (int)(127.5f * (y_value + 1));
   d4174:	ee60 0aa7 	vmul.f32	s1, s1, s15
   d4178:	eefd 7ae0 	vcvt.s32.f32	s15, s1

  // Set the brightness of the LED. If the specified pin does not support PWM,
  // this will result in the LED being on when y > 127, off otherwise.
  analogWrite(led, brightness);
   d417c:	ee17 1a90 	vmov	r1, s15
    initialized = true;
  }

  // Calculate the brightness of the LED such that y=-1 is fully off
  // and y=1 is fully on. The LED's brightness can range from 0-255.
  int brightness = (int)(127.5f * (y_value + 1));
   d4180:	edcd 7a01 	vstr	s15, [sp, #4]

  // Set the brightness of the LED. If the specified pin does not support PWM,
  // this will result in the LED being on when y > 127, off otherwise.
  analogWrite(led, brightness);
   d4184:	f011 ffa8 	bl	e60d8 <_Z11analogWritetm>

  // Log the current brightness value
  error_reporter->Report("%d\n", brightness);
   d4188:	9a01      	ldr	r2, [sp, #4]
   d418a:	4907      	ldr	r1, [pc, #28]	; (d41a8 <_Z12HandleOutputPN6tflite13ErrorReporterEff+0x64>)
   d418c:	4630      	mov	r0, r6
}
   d418e:	b002      	add	sp, #8
   d4190:	ecbd 8b02 	vpop	{d8}
   d4194:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
  // Set the brightness of the LED. If the specified pin does not support PWM,
  // this will result in the LED being on when y > 127, off otherwise.
  analogWrite(led, brightness);

  // Log the current brightness value
  error_reporter->Report("%d\n", brightness);
   d4198:	f001 b9a8 	b.w	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
   d419c:	2003c2a4 	.word	0x2003c2a4
   d41a0:	2003bcf8 	.word	0x2003bcf8
   d41a4:	42ff0000 	.word	0x42ff0000
   d41a8:	000eb04d 	.word	0x000eb04d

000d41ac <_GLOBAL__sub_I_led>:

inline void pinSetFast(pin_t _pin) __attribute__((always_inline));
inline void pinResetFast(pin_t _pin) __attribute__((always_inline));
inline int32_t pinReadFast(pin_t _pin) __attribute__((always_inline));

static Hal_Pin_Info* PIN_MAP = HAL_Pin_Map();
   d41ac:	f010 bfbe 	b.w	e512c <HAL_Pin_Map>

000d41b0 <_ZN6tflite18MicroErrorReporterD1Ev>:

namespace tflite {

class MicroErrorReporter : public ErrorReporter {
 public:
  ~MicroErrorReporter() {}
   d41b0:	4770      	bx	lr

000d41b2 <_ZN6tflite3ops5micro14AllOpsResolverD1Ev>:

namespace tflite {
namespace ops {
namespace micro {

class AllOpsResolver : public MicroMutableOpResolver {
   d41b2:	4770      	bx	lr

000d41b4 <_ZN6tflite3ops5micro14AllOpsResolverD0Ev>:
   d41b4:	b510      	push	{r4, lr}
   d41b6:	f241 0108 	movw	r1, #4104	; 0x1008
   d41ba:	4604      	mov	r4, r0
   d41bc:	f011 fff9 	bl	e61b2 <_ZdlPvj>
   d41c0:	4620      	mov	r0, r4
   d41c2:	bd10      	pop	{r4, pc}

000d41c4 <_ZN6tflite18MicroErrorReporterD0Ev>:
   d41c4:	b510      	push	{r4, lr}
   d41c6:	2104      	movs	r1, #4
   d41c8:	4604      	mov	r4, r0
   d41ca:	f011 fff2 	bl	e61b2 <_ZdlPvj>
   d41ce:	4620      	mov	r0, r4
   d41d0:	bd10      	pop	{r4, pc}
   d41d2:	0000      	movs	r0, r0
   d41d4:	0000      	movs	r0, r0
	...

000d41d8 <loop>:
  inference_count = 0;
}

// The name of this function is important for Arduino compatibility.
void loop()
{
   d41d8:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d41dc:	ed2d 8b04 	vpush	{d8-d9}
  // Calculate an x value to feed into the model. We compare the current
  // inference_count to the number of inferences per cycle to determine
  // our position within the range of possible x values the model was
  // trained on, and use this to calculate a value.
  float position = static_cast<float>(inference_count) /
   d41e0:	4c65      	ldr	r4, [pc, #404]	; (d4378 <loop+0x1a0>)
   d41e2:	4b66      	ldr	r3, [pc, #408]	; (d437c <loop+0x1a4>)
                   static_cast<float>(kInferencesPerCycle);
  float x_val = position * kXrange;
   d41e4:	edd4 7a00 	vldr	s15, [r4]
{
  // Calculate an x value to feed into the model. We compare the current
  // inference_count to the number of inferences per cycle to determine
  // our position within the range of possible x values the model was
  // trained on, and use this to calculate a value.
  float position = static_cast<float>(inference_count) /
   d41e8:	681b      	ldr	r3, [r3, #0]
                   static_cast<float>(kInferencesPerCycle);
  float x_val = position * kXrange;
   d41ea:	ed9f 8a65 	vldr	s16, [pc, #404]	; d4380 <loop+0x1a8>
   d41ee:	f8df a1bc 	ldr.w	sl, [pc, #444]	; d43ac <loop+0x1d4>
   d41f2:	eeb8 7ae7 	vcvt.f32.s32	s14, s15
   d41f6:	ee07 3a90 	vmov	s15, r3
   d41fa:	eef8 6ae7 	vcvt.f32.s32	s13, s15
  inference_count = 0;
}

// The name of this function is important for Arduino compatibility.
void loop()
{
   d41fe:	b087      	sub	sp, #28
  // inference_count to the number of inferences per cycle to determine
  // our position within the range of possible x values the model was
  // trained on, and use this to calculate a value.
  float position = static_cast<float>(inference_count) /
                   static_cast<float>(kInferencesPerCycle);
  float x_val = position * kXrange;
   d4200:	eec7 7a26 	vdiv.f32	s15, s14, s13
{
  // Calculate an x value to feed into the model. We compare the current
  // inference_count to the number of inferences per cycle to determine
  // our position within the range of possible x values the model was
  // trained on, and use this to calculate a value.
  float position = static_cast<float>(inference_count) /
   d4204:	9304      	str	r3, [sp, #16]
                   static_cast<float>(kInferencesPerCycle);
  float x_val = position * kXrange;

  // Place our calculated x value in the model's input tensor
  input->data.f[0] = x_val;
   d4206:	4b5f      	ldr	r3, [pc, #380]	; (d4384 <loop+0x1ac>)
   d4208:	681b      	ldr	r3, [r3, #0]
   d420a:	685b      	ldr	r3, [r3, #4]
  // inference_count to the number of inferences per cycle to determine
  // our position within the range of possible x values the model was
  // trained on, and use this to calculate a value.
  float position = static_cast<float>(inference_count) /
                   static_cast<float>(kInferencesPerCycle);
  float x_val = position * kXrange;
   d420c:	ee27 8a88 	vmul.f32	s16, s15, s16

  // Place our calculated x value in the model's input tensor
  input->data.f[0] = x_val;
   d4210:	ed83 8a00 	vstr	s16, [r3]

  // Run inference, and report any error
  TfLiteStatus invoke_status = interpreter->Invoke();
   d4214:	4b5c      	ldr	r3, [pc, #368]	; (d4388 <loop+0x1b0>)
   d4216:	6818      	ldr	r0, [r3, #0]
   d4218:	f002 ff5a 	bl	d70d0 <_ZN6tflite16MicroInterpreter6InvokeEv>
   d421c:	9405      	str	r4, [sp, #20]
  if (invoke_status != kTfLiteOk)
   d421e:	4683      	mov	fp, r0
   d4220:	b178      	cbz	r0, d4242 <loop+0x6a>
  {
    error_reporter->Report("Invoke failed on x_val: %f\n",
                           static_cast<double>(x_val));
   d4222:	ee18 0a10 	vmov	r0, s16
   d4226:	f014 f8a9 	bl	e837c <__aeabi_f2d>
   d422a:	4602      	mov	r2, r0
   d422c:	460b      	mov	r3, r1
   d422e:	f8da 0000 	ldr.w	r0, [sl]
   d4232:	4956      	ldr	r1, [pc, #344]	; (d438c <loop+0x1b4>)
  // Increment the inference_counter, and reset it if we have reached
  // the total number per cycle
  inference_count += 1;
  if (inference_count >= kInferencesPerCycle)
    inference_count = 0;
}
   d4234:	b007      	add	sp, #28
   d4236:	ecbd 8b04 	vpop	{d8-d9}
   d423a:	e8bd 4ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  // Run inference, and report any error
  TfLiteStatus invoke_status = interpreter->Invoke();
  if (invoke_status != kTfLiteOk)
  {
    error_reporter->Report("Invoke failed on x_val: %f\n",
                           static_cast<double>(x_val));
   d423e:	f001 b955 	b.w	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    return;
  }

  // Read the predicted y value from the model's output tensor
  float y_val = output->data.f[0];
   d4242:	4b53      	ldr	r3, [pc, #332]	; (d4390 <loop+0x1b8>)
  // if y is 1, we'll draw the circle at the top (y = 20) of the screen
  // The x value will increment each time through and roll back to 0 after
  // the screen widge of 480 is reached.
  float yPos = map(y_val, -1.f, 1.f, 40.f, waveBoxHeight);

  if (currentXPos == 0.d)
   d4244:	4c53      	ldr	r4, [pc, #332]	; (d4394 <loop+0x1bc>)
                           static_cast<double>(x_val));
    return;
  }

  // Read the predicted y value from the model's output tensor
  float y_val = output->data.f[0];
   d4246:	681b      	ldr	r3, [r3, #0]
   d4248:	4d53      	ldr	r5, [pc, #332]	; (d4398 <loop+0x1c0>)
   d424a:	685b      	ldr	r3, [r3, #4]
   d424c:	4e53      	ldr	r6, [pc, #332]	; (d439c <loop+0x1c4>)
   d424e:	edd3 8a00 	vldr	s17, [r3]
  // Draw a circle on the tft_screen that corresponds with the y value
  // if is -1, we'll draw the circle at the bottom (y = 300) of the screen
  // if y is 1, we'll draw the circle at the top (y = 20) of the screen
  // The x value will increment each time through and roll back to 0 after
  // the screen widge of 480 is reached.
  float yPos = map(y_val, -1.f, 1.f, 40.f, waveBoxHeight);
   d4252:	4b53      	ldr	r3, [pc, #332]	; (d43a0 <loop+0x1c8>)
   d4254:	4f53      	ldr	r7, [pc, #332]	; (d43a4 <loop+0x1cc>)
   d4256:	6818      	ldr	r0, [r3, #0]
   d4258:	f014 f890 	bl	e837c <__aeabi_f2d>
   d425c:	e9cd 0102 	strd	r0, r1, [sp, #8]
   d4260:	ee18 0a90 	vmov	r0, s17
   d4264:	f014 f88a 	bl	e837c <__aeabi_f2d>
   d4268:	ed9d 4b02 	vldr	d4, [sp, #8]
   d426c:	ed9f 3b3c 	vldr	d3, [pc, #240]	; d4360 <loop+0x188>
   d4270:	ed9f 2b3d 	vldr	d2, [pc, #244]	; d4368 <loop+0x190>
   d4274:	ed9f 1b3e 	vldr	d1, [pc, #248]	; d4370 <loop+0x198>
   d4278:	ec41 0b10 	vmov	d0, r0, r1
   d427c:	f011 f952 	bl	e5524 <_Z3mapddddd>
   d4280:	ec51 0b10 	vmov	r0, r1, d0
   d4284:	f014 fbb0 	bl	e89e8 <__aeabi_d2f>

  if (currentXPos == 0.d)
   d4288:	e9d4 8900 	ldrd	r8, r9, [r4]
  // Draw a circle on the tft_screen that corresponds with the y value
  // if is -1, we'll draw the circle at the bottom (y = 300) of the screen
  // if y is 1, we'll draw the circle at the top (y = 20) of the screen
  // The x value will increment each time through and roll back to 0 after
  // the screen widge of 480 is reached.
  float yPos = map(y_val, -1.f, 1.f, 40.f, waveBoxHeight);
   d428c:	ee09 0a10 	vmov	s18, r0

  if (currentXPos == 0.d)
   d4290:	2200      	movs	r2, #0
   d4292:	2300      	movs	r3, #0
   d4294:	4640      	mov	r0, r8
   d4296:	4649      	mov	r1, r9
   d4298:	f014 fb2c 	bl	e88f4 <__aeabi_dcmpeq>
   d429c:	9002      	str	r0, [sp, #8]
   d429e:	b138      	cbz	r0, d42b0 <loop+0xd8>
  {
    tft.fillCircle(waveBoxWidth, lastYPos, 5, HX8357_BLACK);
   d42a0:	f9b5 2000 	ldrsh.w	r2, [r5]
   d42a4:	f9b6 1000 	ldrsh.w	r1, [r6]
   d42a8:	f8cd b000 	str.w	fp, [sp]
   d42ac:	2305      	movs	r3, #5
   d42ae:	e00e      	b.n	d42ce <loop+0xf6>
  }
  else
  {
    tft.fillCircle(currentXPos - xStep, lastYPos, 5, HX8357_BLACK);
   d42b0:	e9d7 2300 	ldrd	r2, r3, [r7]
   d42b4:	4640      	mov	r0, r8
   d42b6:	4649      	mov	r1, r9
   d42b8:	f013 ff00 	bl	e80bc <__aeabi_dsub>
   d42bc:	f014 fb4c 	bl	e8958 <__aeabi_d2iz>
   d42c0:	f9b5 b000 	ldrsh.w	fp, [r5]
   d42c4:	9b02      	ldr	r3, [sp, #8]
   d42c6:	9300      	str	r3, [sp, #0]
   d42c8:	465a      	mov	r2, fp
   d42ca:	2305      	movs	r3, #5
   d42cc:	b201      	sxth	r1, r0
   d42ce:	4836      	ldr	r0, [pc, #216]	; (d43a8 <loop+0x1d0>)
   d42d0:	f000 fb94 	bl	d49fc <_ZN12Adafruit_GFX10fillCircleEssst>
  }
  tft.fillCircle(currentXPos, (int)yPos, 5, HX8357_RED);
   d42d4:	eefd 7ac9 	vcvt.s32.f32	s15, s18
   d42d8:	e9d4 0100 	ldrd	r0, r1, [r4]
   d42dc:	ee17 8a90 	vmov	r8, s15
   d42e0:	f014 fb3a 	bl	e8958 <__aeabi_d2iz>
   d42e4:	fa0f f988 	sxth.w	r9, r8
   d42e8:	f44f 4378 	mov.w	r3, #63488	; 0xf800
   d42ec:	464a      	mov	r2, r9
   d42ee:	b201      	sxth	r1, r0
   d42f0:	9300      	str	r3, [sp, #0]
   d42f2:	482d      	ldr	r0, [pc, #180]	; (d43a8 <loop+0x1d0>)
   d42f4:	2305      	movs	r3, #5
   d42f6:	f000 fb81 	bl	d49fc <_ZN12Adafruit_GFX10fillCircleEssst>

  lastYPos = (int)yPos;
  currentXPos = currentXPos + xStep;
   d42fa:	e9d7 2300 	ldrd	r2, r3, [r7]
   d42fe:	e9d4 0100 	ldrd	r0, r1, [r4]
  {
    tft.fillCircle(currentXPos - xStep, lastYPos, 5, HX8357_BLACK);
  }
  tft.fillCircle(currentXPos, (int)yPos, 5, HX8357_RED);

  lastYPos = (int)yPos;
   d4302:	f8c5 8000 	str.w	r8, [r5]
  currentXPos = currentXPos + xStep;
   d4306:	f013 fedb 	bl	e80c0 <__adddf3>
   d430a:	4680      	mov	r8, r0
   d430c:	4689      	mov	r9, r1
   d430e:	e9c4 8900 	strd	r8, r9, [r4]
  if (currentXPos > waveBoxWidth)
   d4312:	6830      	ldr	r0, [r6, #0]
   d4314:	f014 f820 	bl	e8358 <__aeabi_i2d>
   d4318:	4602      	mov	r2, r0
   d431a:	460b      	mov	r3, r1
   d431c:	4640      	mov	r0, r8
   d431e:	4649      	mov	r1, r9
   d4320:	f014 fb10 	bl	e8944 <__aeabi_dcmpgt>
   d4324:	b120      	cbz	r0, d4330 <loop+0x158>
  {
    currentXPos = 0.d;
   d4326:	4b1b      	ldr	r3, [pc, #108]	; (d4394 <loop+0x1bc>)
   d4328:	2000      	movs	r0, #0
   d432a:	2100      	movs	r1, #0
   d432c:	e9c3 0100 	strd	r0, r1, [r3]
  }

  // Output the results. A custom HandleOutput function can be implemented
  // for each supported hardware target.
  HandleOutput(error_reporter, x_val, y_val);
   d4330:	eef0 0a68 	vmov.f32	s1, s17
   d4334:	eeb0 0a48 	vmov.f32	s0, s16
   d4338:	f8da 0000 	ldr.w	r0, [sl]
   d433c:	f7ff ff02 	bl	d4144 <_Z12HandleOutputPN6tflite13ErrorReporterEff>

  // Increment the inference_counter, and reset it if we have reached
  // the total number per cycle
  inference_count += 1;
   d4340:	9b05      	ldr	r3, [sp, #20]
  if (inference_count >= kInferencesPerCycle)
   d4342:	9904      	ldr	r1, [sp, #16]
  // for each supported hardware target.
  HandleOutput(error_reporter, x_val, y_val);

  // Increment the inference_counter, and reset it if we have reached
  // the total number per cycle
  inference_count += 1;
   d4344:	681b      	ldr	r3, [r3, #0]
   d4346:	4a0c      	ldr	r2, [pc, #48]	; (d4378 <loop+0x1a0>)
   d4348:	3301      	adds	r3, #1
  if (inference_count >= kInferencesPerCycle)
   d434a:	4299      	cmp	r1, r3
    inference_count = 0;
   d434c:	bfd8      	it	le
   d434e:	2300      	movle	r3, #0
   d4350:	6013      	str	r3, [r2, #0]
}
   d4352:	b007      	add	sp, #28
   d4354:	ecbd 8b04 	vpop	{d8-d9}
   d4358:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   d435c:	f3af 8000 	nop.w
   d4360:	00000000 	.word	0x00000000
   d4364:	40440000 	.word	0x40440000
   d4368:	00000000 	.word	0x00000000
   d436c:	3ff00000 	.word	0x3ff00000
   d4370:	00000000 	.word	0x00000000
   d4374:	bff00000 	.word	0xbff00000
   d4378:	2003dbb0 	.word	0x2003dbb0
   d437c:	000e8ca0 	.word	0x000e8ca0
   d4380:	40c90fdb 	.word	0x40c90fdb
   d4384:	2003c2a8 	.word	0x2003c2a8
   d4388:	2003c2fc 	.word	0x2003c2fc
   d438c:	000e96f4 	.word	0x000e96f4
   d4390:	2003dba8 	.word	0x2003dba8
   d4394:	2003db20 	.word	0x2003db20
   d4398:	2003cb10 	.word	0x2003cb10
   d439c:	2003bd08 	.word	0x2003bd08
   d43a0:	2003bcfc 	.word	0x2003bcfc
   d43a4:	2003bd00 	.word	0x2003bd00
   d43a8:	2003c2ac 	.word	0x2003c2ac
   d43ac:	2003cb08 	.word	0x2003cb08

000d43b0 <_GLOBAL__sub_I_SystemMode>:
   d43b0:	b513      	push	{r0, r1, r4, lr}
   d43b2:	f010 febb 	bl	e512c <HAL_Pin_Map>
    WAKEUP_REASON_RTC = 2,
    WAKEUP_REASON_PIN_OR_RTC = 3
};

struct SleepResult {
    SleepResult() {}
   d43b6:	4b11      	ldr	r3, [pc, #68]	; (d43fc <_GLOBAL__sub_I_SystemMode+0x4c>)
   d43b8:	2400      	movs	r4, #0
   d43ba:	f64f 72ff 	movw	r2, #65535	; 0xffff
   d43be:	701c      	strb	r4, [r3, #0]
   d43c0:	805c      	strh	r4, [r3, #2]
   d43c2:	809a      	strh	r2, [r3, #4]

class SystemClass {
public:

    SystemClass(System_Mode_TypeDef mode = DEFAULT) {
        set_system_mode(mode);
   d43c4:	2003      	movs	r0, #3
   d43c6:	f010 fff9 	bl	e53bc <set_system_mode>
#include <TensorFlowLite.h>
#include <Particle.h>
#include "Adafruit_HX8357.h"

SYSTEM_MODE(MANUAL);
SYSTEM_THREAD(ENABLED);
   d43ca:	4621      	mov	r1, r4
   d43cc:	2001      	movs	r0, #1
   d43ce:	f011 f805 	bl	e53dc <system_thread_set_state>
float waveBoxHeight = 300.f;
int lastYPos = 0;
double currentXPos = 0.d;
double xStep = 0.75;

Adafruit_HX8357 tft = Adafruit_HX8357(TFT_CS, TFT_DC, TFT_RST);
   d43d2:	4c0b      	ldr	r4, [pc, #44]	; (d4400 <_GLOBAL__sub_I_SystemMode+0x50>)
   d43d4:	4b0b      	ldr	r3, [pc, #44]	; (d4404 <_GLOBAL__sub_I_SystemMode+0x54>)
   d43d6:	9301      	str	r3, [sp, #4]
   d43d8:	230d      	movs	r3, #13
   d43da:	9300      	str	r3, [sp, #0]
   d43dc:	2205      	movs	r2, #5
   d43de:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
   d43e2:	2104      	movs	r1, #4
   d43e4:	4620      	mov	r0, r4
   d43e6:	f001 f82b 	bl	d5440 <_ZN15Adafruit_HX8357C1EaaahP8SPIClass>
   d43ea:	4a07      	ldr	r2, [pc, #28]	; (d4408 <_GLOBAL__sub_I_SystemMode+0x58>)
   d43ec:	4907      	ldr	r1, [pc, #28]	; (d440c <_GLOBAL__sub_I_SystemMode+0x5c>)
   d43ee:	4620      	mov	r0, r4
  // Increment the inference_counter, and reset it if we have reached
  // the total number per cycle
  inference_count += 1;
  if (inference_count >= kInferencesPerCycle)
    inference_count = 0;
}
   d43f0:	b002      	add	sp, #8
   d43f2:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
float waveBoxHeight = 300.f;
int lastYPos = 0;
double currentXPos = 0.d;
double xStep = 0.75;

Adafruit_HX8357 tft = Adafruit_HX8357(TFT_CS, TFT_DC, TFT_RST);
   d43f6:	f011 bed7 	b.w	e61a8 <__aeabi_atexit>
   d43fa:	bf00      	nop
   d43fc:	2003c2f4 	.word	0x2003c2f4
   d4400:	2003c2ac 	.word	0x2003c2ac
   d4404:	2003e734 	.word	0x2003e734
   d4408:	2003c2a0 	.word	0x2003c2a0
   d440c:	000d5231 	.word	0x000d5231

000d4410 <setup>:
uint8_t tensor_arena[kTensorArenaSize];
} // namespace

// The name of this function is important for Arduino compatibility.
void setup()
{
   d4410:	b573      	push	{r0, r1, r4, r5, r6, lr}
  tft.begin();
   d4412:	2100      	movs	r1, #0
   d4414:	4848      	ldr	r0, [pc, #288]	; (d4538 <setup+0x128>)
  tft.println("TFLite for Particle");

  // Set up logging. Google style is to avoid globals or statics because of
  // lifetime uncertainty, but since this has a trivial destructor it's okay.
  // NOLINTNEXTLINE(runtime-global-variables)
  static tflite::MicroErrorReporter micro_error_reporter;
   d4416:	4c49      	ldr	r4, [pc, #292]	; (d453c <setup+0x12c>)
} // namespace

// The name of this function is important for Arduino compatibility.
void setup()
{
  tft.begin();
   d4418:	f000 ff26 	bl	d5268 <_ZN15Adafruit_HX83575beginEm>
  tft.fillScreen(HX8357_BLACK);
   d441c:	2100      	movs	r1, #0
   d441e:	4846      	ldr	r0, [pc, #280]	; (d4538 <setup+0x128>)
   d4420:	f000 f999 	bl	d4756 <_ZN12Adafruit_GFX10fillScreenEt>
  tft.setRotation(1);
   d4424:	2101      	movs	r1, #1
   d4426:	4844      	ldr	r0, [pc, #272]	; (d4538 <setup+0x128>)
   d4428:	f000 ff66 	bl	d52f8 <_ZN15Adafruit_HX835711setRotationEh>
  tft.setTextSize(3);
   d442c:	2103      	movs	r1, #3
   d442e:	4842      	ldr	r0, [pc, #264]	; (d4538 <setup+0x128>)
   d4430:	f000 fcf0 	bl	d4e14 <_ZN12Adafruit_GFX11setTextSizeEh>
  tft.setCursor(70, 10);
   d4434:	220a      	movs	r2, #10
   d4436:	2146      	movs	r1, #70	; 0x46
   d4438:	483f      	ldr	r0, [pc, #252]	; (d4538 <setup+0x128>)
   d443a:	f000 fce8 	bl	d4e0e <_ZN12Adafruit_GFX9setCursorEss>
  tft.setTextColor(HX8357_WHITE);
   d443e:	f64f 71ff 	movw	r1, #65535	; 0xffff
   d4442:	483d      	ldr	r0, [pc, #244]	; (d4538 <setup+0x128>)
   d4444:	f000 fceb 	bl	d4e1e <_ZN12Adafruit_GFX12setTextColorEt>
  tft.println("TFLite for Particle");
   d4448:	493d      	ldr	r1, [pc, #244]	; (d4540 <setup+0x130>)
   d444a:	483b      	ldr	r0, [pc, #236]	; (d4538 <setup+0x128>)
   d444c:	f011 fb51 	bl	e5af2 <_ZN5Print7printlnEPKc>

  // Set up logging. Google style is to avoid globals or statics because of
  // lifetime uncertainty, but since this has a trivial destructor it's okay.
  // NOLINTNEXTLINE(runtime-global-variables)
  static tflite::MicroErrorReporter micro_error_reporter;
   d4450:	6823      	ldr	r3, [r4, #0]
   d4452:	07d9      	lsls	r1, r3, #31
   d4454:	d40b      	bmi.n	d446e <setup+0x5e>
   d4456:	4620      	mov	r0, r4
   d4458:	f7ff fe3a 	bl	d40d0 <__cxa_guard_acquire>
   d445c:	b138      	cbz	r0, d446e <setup+0x5e>
   d445e:	4620      	mov	r0, r4
   d4460:	f7ff fe3b 	bl	d40da <__cxa_guard_release>
   d4464:	4a37      	ldr	r2, [pc, #220]	; (d4544 <setup+0x134>)
   d4466:	4938      	ldr	r1, [pc, #224]	; (d4548 <setup+0x138>)
   d4468:	4838      	ldr	r0, [pc, #224]	; (d454c <setup+0x13c>)
   d446a:	f011 fe9d 	bl	e61a8 <__aeabi_atexit>
  error_reporter = &micro_error_reporter;
   d446e:	4c38      	ldr	r4, [pc, #224]	; (d4550 <setup+0x140>)
   d4470:	4b36      	ldr	r3, [pc, #216]	; (d454c <setup+0x13c>)
   d4472:	6023      	str	r3, [r4, #0]
// Helpers to get a typed pointer to the root object contained in the buffer.
template<typename T> T *GetMutableRoot(void *buf) {
  EndianCheck();
  return reinterpret_cast<T *>(
      reinterpret_cast<uint8_t *>(buf) +
      EndianScalar(*reinterpret_cast<uoffset_t *>(buf)));
   d4474:	4b37      	ldr	r3, [pc, #220]	; (d4554 <setup+0x144>)

  // Map the model into a usable data structure. This doesn't involve any
  // copying or parsing, it's a very lightweight operation.
  model = tflite::GetModel(g_sine_model_data);
   d4476:	4a38      	ldr	r2, [pc, #224]	; (d4558 <setup+0x148>)
   d4478:	6818      	ldr	r0, [r3, #0]
   d447a:	18c1      	adds	r1, r0, r3
// "tables" use an offset table (possibly shared) that allows fields to be
// omitted and added at will, but uses an extra indirection to read.
class Table {
 public:
  const uint8_t *GetVTable() const {
    return data_ - ReadScalar<soffset_t>(data_);
   d447c:	58c3      	ldr	r3, [r0, r3]
   d447e:	6011      	str	r1, [r2, #0]
   d4480:	1acb      	subs	r3, r1, r3
   d4482:	4616      	mov	r6, r2
    auto vtable = GetVTable();
    // The first element is the size of the vtable (fields + type id + itself).
    auto vtsize = ReadScalar<voffset_t>(vtable);
    // If the field we're accessing is outside the vtable, we're reading older
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
   d4484:	8818      	ldrh	r0, [r3, #0]
   d4486:	2804      	cmp	r0, #4
   d4488:	d905      	bls.n	d4496 <setup+0x86>

template<typename T>
// UBSAN: C++ aliasing type rules, see std::bit_cast<> for details.
__supress_ubsan__("alignment")
T ReadScalar(const void *p) {
  return EndianScalar(*reinterpret_cast<const T *>(p));
   d448a:	889a      	ldrh	r2, [r3, #4]
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
    auto field_offset = GetOptionalFieldOffset(field);
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d448c:	b122      	cbz	r2, d4498 <setup+0x88>
   d448e:	588a      	ldr	r2, [r1, r2]
  if (model->version() != TFLITE_SCHEMA_VERSION)
   d4490:	2a03      	cmp	r2, #3
   d4492:	d009      	beq.n	d44a8 <setup+0x98>
   d4494:	e000      	b.n	d4498 <setup+0x88>
   d4496:	2200      	movs	r2, #0
  {
    error_reporter->Report(
        "Model provided is schema version %d not equal "
        "to supported version %d.",
        model->version(), TFLITE_SCHEMA_VERSION);
   d4498:	4930      	ldr	r1, [pc, #192]	; (d455c <setup+0x14c>)
   d449a:	482c      	ldr	r0, [pc, #176]	; (d454c <setup+0x13c>)
   d449c:	2303      	movs	r3, #3
  input = interpreter->input(0);
  output = interpreter->output(0);

  // Keep track of how many inferences we have performed.
  inference_count = 0;
}
   d449e:	b002      	add	sp, #8
   d44a0:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
  if (model->version() != TFLITE_SCHEMA_VERSION)
  {
    error_reporter->Report(
        "Model provided is schema version %d not equal "
        "to supported version %d.",
        model->version(), TFLITE_SCHEMA_VERSION);
   d44a4:	f001 b822 	b.w	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    return;
  }

  // This pulls in all the operation implementations we need.
  // NOLINTNEXTLINE(runtime-global-variables)
  static tflite::ops::micro::AllOpsResolver resolver;
   d44a8:	4d2d      	ldr	r5, [pc, #180]	; (d4560 <setup+0x150>)
   d44aa:	682b      	ldr	r3, [r5, #0]
   d44ac:	07da      	lsls	r2, r3, #31
   d44ae:	d40e      	bmi.n	d44ce <setup+0xbe>
   d44b0:	4628      	mov	r0, r5
   d44b2:	f7ff fe0d 	bl	d40d0 <__cxa_guard_acquire>
   d44b6:	b150      	cbz	r0, d44ce <setup+0xbe>
   d44b8:	482a      	ldr	r0, [pc, #168]	; (d4564 <setup+0x154>)
   d44ba:	f003 ff3f 	bl	d833c <_ZN6tflite3ops5micro14AllOpsResolverC1Ev>
   d44be:	4628      	mov	r0, r5
   d44c0:	f7ff fe0b 	bl	d40da <__cxa_guard_release>
   d44c4:	4a1f      	ldr	r2, [pc, #124]	; (d4544 <setup+0x134>)
   d44c6:	4928      	ldr	r1, [pc, #160]	; (d4568 <setup+0x158>)
   d44c8:	4826      	ldr	r0, [pc, #152]	; (d4564 <setup+0x154>)
   d44ca:	f011 fe6d 	bl	e61a8 <__aeabi_atexit>

  // Build an interpreter to run the model with.
  static tflite::MicroInterpreter static_interpreter(
      model, resolver, tensor_arena, kTensorArenaSize, error_reporter);
   d44ce:	4d27      	ldr	r5, [pc, #156]	; (d456c <setup+0x15c>)
   d44d0:	682b      	ldr	r3, [r5, #0]
   d44d2:	07db      	lsls	r3, r3, #31
   d44d4:	d411      	bmi.n	d44fa <setup+0xea>
   d44d6:	4628      	mov	r0, r5
   d44d8:	f7ff fdfa 	bl	d40d0 <__cxa_guard_acquire>
   d44dc:	b168      	cbz	r0, d44fa <setup+0xea>
   d44de:	6823      	ldr	r3, [r4, #0]
   d44e0:	9301      	str	r3, [sp, #4]
   d44e2:	f44f 6300 	mov.w	r3, #2048	; 0x800
   d44e6:	9300      	str	r3, [sp, #0]
   d44e8:	4a1e      	ldr	r2, [pc, #120]	; (d4564 <setup+0x154>)
   d44ea:	4b21      	ldr	r3, [pc, #132]	; (d4570 <setup+0x160>)
   d44ec:	6831      	ldr	r1, [r6, #0]
   d44ee:	4821      	ldr	r0, [pc, #132]	; (d4574 <setup+0x164>)
   d44f0:	f002 fd6e 	bl	d6fd0 <_ZN6tflite16MicroInterpreterC1EPKNS_5ModelERKNS_10OpResolverEPhjPNS_13ErrorReporterE>
   d44f4:	4628      	mov	r0, r5
   d44f6:	f7ff fdf0 	bl	d40da <__cxa_guard_release>
  interpreter = &static_interpreter;
   d44fa:	4e1f      	ldr	r6, [pc, #124]	; (d4578 <setup+0x168>)
   d44fc:	481d      	ldr	r0, [pc, #116]	; (d4574 <setup+0x164>)
   d44fe:	6030      	str	r0, [r6, #0]

  // Allocate memory from the tensor_arena for the model's tensors.
  TfLiteStatus allocate_status = interpreter->AllocateTensors();
   d4500:	f002 fd4c 	bl	d6f9c <_ZN6tflite16MicroInterpreter15AllocateTensorsEv>
  if (allocate_status != kTfLiteOk)
   d4504:	4605      	mov	r5, r0
   d4506:	b130      	cbz	r0, d4516 <setup+0x106>
  {
    error_reporter->Report("AllocateTensors() failed");
   d4508:	491c      	ldr	r1, [pc, #112]	; (d457c <setup+0x16c>)
   d450a:	6820      	ldr	r0, [r4, #0]
  input = interpreter->input(0);
  output = interpreter->output(0);

  // Keep track of how many inferences we have performed.
  inference_count = 0;
}
   d450c:	b002      	add	sp, #8
   d450e:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}

  // Allocate memory from the tensor_arena for the model's tensors.
  TfLiteStatus allocate_status = interpreter->AllocateTensors();
  if (allocate_status != kTfLiteOk)
  {
    error_reporter->Report("AllocateTensors() failed");
   d4512:	f000 bfeb 	b.w	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    return;
  }

  // Obtain pointers to the model's input and output tensors.
  input = interpreter->input(0);
   d4516:	4601      	mov	r1, r0
   d4518:	6830      	ldr	r0, [r6, #0]
   d451a:	f002 fdbd 	bl	d7098 <_ZN6tflite16MicroInterpreter5inputEj>
   d451e:	4b18      	ldr	r3, [pc, #96]	; (d4580 <setup+0x170>)
  output = interpreter->output(0);
   d4520:	4629      	mov	r1, r5
    error_reporter->Report("AllocateTensors() failed");
    return;
  }

  // Obtain pointers to the model's input and output tensors.
  input = interpreter->input(0);
   d4522:	6018      	str	r0, [r3, #0]
  output = interpreter->output(0);
   d4524:	6830      	ldr	r0, [r6, #0]
   d4526:	f002 fd9b 	bl	d7060 <_ZN6tflite16MicroInterpreter6outputEj>
   d452a:	4b16      	ldr	r3, [pc, #88]	; (d4584 <setup+0x174>)
   d452c:	6018      	str	r0, [r3, #0]

  // Keep track of how many inferences we have performed.
  inference_count = 0;
   d452e:	4b16      	ldr	r3, [pc, #88]	; (d4588 <setup+0x178>)
   d4530:	601d      	str	r5, [r3, #0]
}
   d4532:	b002      	add	sp, #8
   d4534:	bd70      	pop	{r4, r5, r6, pc}
   d4536:	bf00      	nop
   d4538:	2003c2ac 	.word	0x2003c2ac
   d453c:	2003c300 	.word	0x2003c300
   d4540:	000e9710 	.word	0x000e9710
   d4544:	2003c2a0 	.word	0x2003c2a0
   d4548:	000d41b1 	.word	0x000d41b1
   d454c:	2003bd0c 	.word	0x2003bd0c
   d4550:	2003cb08 	.word	0x2003cb08
   d4554:	000e8ca4 	.word	0x000e8ca4
   d4558:	2003cb04 	.word	0x2003cb04
   d455c:	000e9724 	.word	0x000e9724
   d4560:	2003cb0c 	.word	0x2003cb0c
   d4564:	2003cb14 	.word	0x2003cb14
   d4568:	000d41b3 	.word	0x000d41b3
   d456c:	2003dbac 	.word	0x2003dbac
   d4570:	2003c304 	.word	0x2003c304
   d4574:	2003db28 	.word	0x2003db28
   d4578:	2003c2fc 	.word	0x2003c2fc
   d457c:	000e976b 	.word	0x000e976b
   d4580:	2003c2a8 	.word	0x2003c2a8
   d4584:	2003dba8 	.word	0x2003dba8
   d4588:	2003dbb0 	.word	0x2003dbb0

000d458c <_ZN12Adafruit_GFX9writeLineEsssst>:
    @param    y1  End point y coordinate
    @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_GFX::writeLine(int16_t x0, int16_t y0, int16_t x1, int16_t y1,
        uint16_t color) {
   d458c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d4590:	b085      	sub	sp, #20
   d4592:	461e      	mov	r6, r3
   d4594:	f9bd 3038 	ldrsh.w	r3, [sp, #56]	; 0x38
   d4598:	f8bd a03c 	ldrh.w	sl, [sp, #60]	; 0x3c
   d459c:	4615      	mov	r5, r2
    int16_t steep = abs(y1 - y0) > abs(x1 - x0);
   d459e:	1a9a      	subs	r2, r3, r2
   d45a0:	2a00      	cmp	r2, #0
   d45a2:	bfb8      	it	lt
   d45a4:	4252      	neglt	r2, r2
   d45a6:	9200      	str	r2, [sp, #0]
   d45a8:	1a72      	subs	r2, r6, r1
   d45aa:	2a00      	cmp	r2, #0
   d45ac:	bfb8      	it	lt
   d45ae:	4252      	neglt	r2, r2
   d45b0:	9201      	str	r2, [sp, #4]
    @param    y1  End point y coordinate
    @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_GFX::writeLine(int16_t x0, int16_t y0, int16_t x1, int16_t y1,
        uint16_t color) {
   d45b2:	460c      	mov	r4, r1
    int16_t steep = abs(y1 - y0) > abs(x1 - x0);
    if (steep) {
   d45b4:	9a00      	ldr	r2, [sp, #0]
   d45b6:	9901      	ldr	r1, [sp, #4]
   d45b8:	428a      	cmp	r2, r1
    @param    y1  End point y coordinate
    @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_GFX::writeLine(int16_t x0, int16_t y0, int16_t x1, int16_t y1,
        uint16_t color) {
   d45ba:	4681      	mov	r9, r0
    int16_t steep = abs(y1 - y0) > abs(x1 - x0);
    if (steep) {
   d45bc:	dd05      	ble.n	d45ca <_ZN12Adafruit_GFX9writeLineEsssst+0x3e>
   d45be:	4632      	mov	r2, r6
        _swap_int16_t(x0, y0);
        _swap_int16_t(x1, y1);
   d45c0:	461e      	mov	r6, r3
   d45c2:	4613      	mov	r3, r2
*/
/**************************************************************************/
void Adafruit_GFX::writeLine(int16_t x0, int16_t y0, int16_t x1, int16_t y1,
        uint16_t color) {
    int16_t steep = abs(y1 - y0) > abs(x1 - x0);
    if (steep) {
   d45c4:	4622      	mov	r2, r4
        _swap_int16_t(x0, y0);
   d45c6:	462c      	mov	r4, r5
   d45c8:	4615      	mov	r5, r2
        _swap_int16_t(x1, y1);
    }

    if (x0 > x1) {
   d45ca:	42b4      	cmp	r4, r6
   d45cc:	dd05      	ble.n	d45da <_ZN12Adafruit_GFX9writeLineEsssst+0x4e>
   d45ce:	462a      	mov	r2, r5
        _swap_int16_t(x0, x1);
        _swap_int16_t(y0, y1);
   d45d0:	461d      	mov	r5, r3
   d45d2:	4613      	mov	r3, r2
    if (steep) {
        _swap_int16_t(x0, y0);
        _swap_int16_t(x1, y1);
    }

    if (x0 > x1) {
   d45d4:	4622      	mov	r2, r4
   d45d6:	4634      	mov	r4, r6
   d45d8:	4616      	mov	r6, r2
        _swap_int16_t(y0, y1);
    }

    int16_t dx, dy;
    dx = x1 - x0;
    dy = abs(y1 - y0);
   d45da:	1b5a      	subs	r2, r3, r5
   d45dc:	2a00      	cmp	r2, #0
   d45de:	bfb8      	it	lt
   d45e0:	4252      	neglt	r2, r2
        _swap_int16_t(x0, x1);
        _swap_int16_t(y0, y1);
    }

    int16_t dx, dy;
    dx = x1 - x0;
   d45e2:	ebc4 0806 	rsb	r8, r4, r6
    int16_t ystep;

    if (y0 < y1) {
        ystep = 1;
    } else {
        ystep = -1;
   d45e6:	429d      	cmp	r5, r3
   d45e8:	bfb4      	ite	lt
   d45ea:	2301      	movlt	r3, #1
   d45ec:	f04f 33ff 	movge.w	r3, #4294967295	; 0xffffffff
        _swap_int16_t(x0, x1);
        _swap_int16_t(y0, y1);
    }

    int16_t dx, dy;
    dx = x1 - x0;
   d45f0:	fa1f f888 	uxth.w	r8, r8
    int16_t ystep;

    if (y0 < y1) {
        ystep = 1;
    } else {
        ystep = -1;
   d45f4:	9302      	str	r3, [sp, #8]
        _swap_int16_t(y0, y1);
    }

    int16_t dx, dy;
    dx = x1 - x0;
    dy = abs(y1 - y0);
   d45f6:	9203      	str	r2, [sp, #12]

    int16_t err = dx / 2;
   d45f8:	fa0f f788 	sxth.w	r7, r8
   d45fc:	2202      	movs	r2, #2
   d45fe:	fb97 f7f2 	sdiv	r7, r7, r2
        ystep = 1;
    } else {
        ystep = -1;
    }

    for (; x0<=x1; x0++) {
   d4602:	42b4      	cmp	r4, r6
   d4604:	dc1f      	bgt.n	d4646 <_ZN12Adafruit_GFX9writeLineEsssst+0xba>
        if (steep) {
   d4606:	9a01      	ldr	r2, [sp, #4]
   d4608:	9b00      	ldr	r3, [sp, #0]
   d460a:	4293      	cmp	r3, r2
   d460c:	f8d9 3000 	ldr.w	r3, [r9]
            writePixel(y0, x0, color);
   d4610:	bfc8      	it	gt
   d4612:	4622      	movgt	r2, r4
   d4614:	f8d3 b018 	ldr.w	fp, [r3, #24]
   d4618:	bfc8      	it	gt
   d461a:	4629      	movgt	r1, r5
   d461c:	4653      	mov	r3, sl
        } else {
            writePixel(x0, y0, color);
   d461e:	bfdc      	itt	le
   d4620:	462a      	movle	r2, r5
   d4622:	4621      	movle	r1, r4
   d4624:	4648      	mov	r0, r9
   d4626:	47d8      	blx	fp
        }
        err -= dy;
   d4628:	9b03      	ldr	r3, [sp, #12]
   d462a:	1aff      	subs	r7, r7, r3
   d462c:	b2bb      	uxth	r3, r7
   d462e:	b21f      	sxth	r7, r3
        if (err < 0) {
   d4630:	2f00      	cmp	r7, #0
   d4632:	da05      	bge.n	d4640 <_ZN12Adafruit_GFX9writeLineEsssst+0xb4>
            y0 += ystep;
   d4634:	9a02      	ldr	r2, [sp, #8]
            err += dx;
   d4636:	eb08 0703 	add.w	r7, r8, r3
        } else {
            writePixel(x0, y0, color);
        }
        err -= dy;
        if (err < 0) {
            y0 += ystep;
   d463a:	4415      	add	r5, r2
   d463c:	b22d      	sxth	r5, r5
            err += dx;
   d463e:	b23f      	sxth	r7, r7
   d4640:	3401      	adds	r4, #1
   d4642:	b224      	sxth	r4, r4
        ystep = 1;
    } else {
        ystep = -1;
    }

    for (; x0<=x1; x0++) {
   d4644:	e7dd      	b.n	d4602 <_ZN12Adafruit_GFX9writeLineEsssst+0x76>
        if (err < 0) {
            y0 += ystep;
            err += dx;
        }
    }
}
   d4646:	b005      	add	sp, #20
   d4648:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d464c <_ZN12Adafruit_GFX10writePixelEsst>:
    @param   x   x coordinate
    @param   y   y coordinate
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::writePixel(int16_t x, int16_t y, uint16_t color){
   d464c:	b410      	push	{r4}
    drawPixel(x, y, color);
   d464e:	6804      	ldr	r4, [r0, #0]
   d4650:	6924      	ldr	r4, [r4, #16]
   d4652:	46a4      	mov	ip, r4
}
   d4654:	f85d 4b04 	ldr.w	r4, [sp], #4
    @param   y   y coordinate
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::writePixel(int16_t x, int16_t y, uint16_t color){
    drawPixel(x, y, color);
   d4658:	4760      	bx	ip

000d465a <_ZN12Adafruit_GFX14writeFastVLineEssst>:
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::writeFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
   d465a:	b430      	push	{r4, r5}
    // Overwrite in subclasses if startWrite is defined!
    // Can be just writeLine(x, y, x, y+h-1, color);
    // or writeFillRect(x, y, 1, h, color);
    drawFastVLine(x, y, h, color);
   d465c:	6804      	ldr	r4, [r0, #0]
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::writeFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
   d465e:	f8bd 5008 	ldrh.w	r5, [sp, #8]
    // Overwrite in subclasses if startWrite is defined!
    // Can be just writeLine(x, y, x, y+h-1, color);
    // or writeFillRect(x, y, 1, h, color);
    drawFastVLine(x, y, h, color);
   d4662:	9502      	str	r5, [sp, #8]
   d4664:	6ba4      	ldr	r4, [r4, #56]	; 0x38
   d4666:	46a4      	mov	ip, r4
}
   d4668:	bc30      	pop	{r4, r5}
void Adafruit_GFX::writeFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
    // Overwrite in subclasses if startWrite is defined!
    // Can be just writeLine(x, y, x, y+h-1, color);
    // or writeFillRect(x, y, 1, h, color);
    drawFastVLine(x, y, h, color);
   d466a:	4760      	bx	ip

000d466c <_ZN12Adafruit_GFX14writeFastHLineEssst>:
    @param    w   Width in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::writeFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
   d466c:	b430      	push	{r4, r5}
    // Overwrite in subclasses if startWrite is defined!
    // Example: writeLine(x, y, x+w-1, y, color);
    // or writeFillRect(x, y, w, 1, color);
    drawFastHLine(x, y, w, color);
   d466e:	6804      	ldr	r4, [r0, #0]
    @param    w   Width in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::writeFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
   d4670:	f8bd 5008 	ldrh.w	r5, [sp, #8]
    // Overwrite in subclasses if startWrite is defined!
    // Example: writeLine(x, y, x+w-1, y, color);
    // or writeFillRect(x, y, w, 1, color);
    drawFastHLine(x, y, w, color);
   d4674:	9502      	str	r5, [sp, #8]
   d4676:	6be4      	ldr	r4, [r4, #60]	; 0x3c
   d4678:	46a4      	mov	ip, r4
}
   d467a:	bc30      	pop	{r4, r5}
void Adafruit_GFX::writeFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
    // Overwrite in subclasses if startWrite is defined!
    // Example: writeLine(x, y, x+w-1, y, color);
    // or writeFillRect(x, y, w, 1, color);
    drawFastHLine(x, y, w, color);
   d467c:	4760      	bx	ip

000d467e <_ZN12Adafruit_GFX13writeFillRectEsssst>:
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::writeFillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d467e:	b470      	push	{r4, r5, r6}
    // Overwrite in subclasses if desired!
    fillRect(x,y,w,h,color);
   d4680:	6804      	ldr	r4, [r0, #0]
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::writeFillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d4682:	f9bd 500c 	ldrsh.w	r5, [sp, #12]
   d4686:	f8bd 6010 	ldrh.w	r6, [sp, #16]
    // Overwrite in subclasses if desired!
    fillRect(x,y,w,h,color);
   d468a:	9604      	str	r6, [sp, #16]
   d468c:	9503      	str	r5, [sp, #12]
   d468e:	6c24      	ldr	r4, [r4, #64]	; 0x40
   d4690:	46a4      	mov	ip, r4
}
   d4692:	bc70      	pop	{r4, r5, r6}
*/
/**************************************************************************/
void Adafruit_GFX::writeFillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
    // Overwrite in subclasses if desired!
    fillRect(x,y,w,h,color);
   d4694:	4760      	bx	ip

000d4696 <_ZN12Adafruit_GFX10startWriteEv>:
/**************************************************************************/
/*!
   @brief    End a display-writing routine, overwrite in subclasses if startWrite is defined!
*/
/**************************************************************************/
void Adafruit_GFX::endWrite(){
   d4696:	4770      	bx	lr

000d4698 <_ZN12Adafruit_GFX13drawFastVLineEssst>:
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::drawFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
   d4698:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
   d469c:	461c      	mov	r4, r3
    startWrite();
   d469e:	6803      	ldr	r3, [r0, #0]
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::drawFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
   d46a0:	f8bd 8020 	ldrh.w	r8, [sp, #32]
    startWrite();
   d46a4:	695b      	ldr	r3, [r3, #20]
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::drawFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
   d46a6:	4605      	mov	r5, r0
   d46a8:	4616      	mov	r6, r2
    startWrite();
    writeLine(x, y, x, y+h-1, color);
   d46aa:	3c01      	subs	r4, #1
   d46ac:	4434      	add	r4, r6
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::drawFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
   d46ae:	460f      	mov	r7, r1
    startWrite();
    writeLine(x, y, x, y+h-1, color);
   d46b0:	b224      	sxth	r4, r4
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::drawFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
    startWrite();
   d46b2:	4798      	blx	r3
    writeLine(x, y, x, y+h-1, color);
   d46b4:	682b      	ldr	r3, [r5, #0]
   d46b6:	f8cd 8004 	str.w	r8, [sp, #4]
   d46ba:	9400      	str	r4, [sp, #0]
   d46bc:	6a9c      	ldr	r4, [r3, #40]	; 0x28
   d46be:	4628      	mov	r0, r5
   d46c0:	463b      	mov	r3, r7
   d46c2:	4632      	mov	r2, r6
   d46c4:	4639      	mov	r1, r7
   d46c6:	47a0      	blx	r4
    endWrite();
   d46c8:	682b      	ldr	r3, [r5, #0]
   d46ca:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   d46cc:	4628      	mov	r0, r5
}
   d46ce:	b002      	add	sp, #8
   d46d0:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
/**************************************************************************/
void Adafruit_GFX::drawFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
    startWrite();
    writeLine(x, y, x, y+h-1, color);
    endWrite();
   d46d4:	4718      	bx	r3

000d46d6 <_ZN12Adafruit_GFX13drawFastHLineEssst>:
    @param    w   Width in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::drawFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
   d46d6:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
   d46da:	461d      	mov	r5, r3
    startWrite();
   d46dc:	6803      	ldr	r3, [r0, #0]
    @param    w   Width in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::drawFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
   d46de:	f8bd 8020 	ldrh.w	r8, [sp, #32]
    startWrite();
   d46e2:	695b      	ldr	r3, [r3, #20]
    @param    w   Width in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::drawFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
   d46e4:	4604      	mov	r4, r0
   d46e6:	4617      	mov	r7, r2
   d46e8:	460e      	mov	r6, r1
    startWrite();
   d46ea:	4798      	blx	r3
    writeLine(x, y, x+w-1, y, color);
   d46ec:	e88d 0180 	stmia.w	sp, {r7, r8}
   d46f0:	6822      	ldr	r2, [r4, #0]
   d46f2:	1e6b      	subs	r3, r5, #1
   d46f4:	4433      	add	r3, r6
   d46f6:	6a95      	ldr	r5, [r2, #40]	; 0x28
   d46f8:	4620      	mov	r0, r4
   d46fa:	b21b      	sxth	r3, r3
   d46fc:	463a      	mov	r2, r7
   d46fe:	4631      	mov	r1, r6
   d4700:	47a8      	blx	r5
    endWrite();
   d4702:	6823      	ldr	r3, [r4, #0]
   d4704:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   d4706:	4620      	mov	r0, r4
}
   d4708:	b002      	add	sp, #8
   d470a:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
/**************************************************************************/
void Adafruit_GFX::drawFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
    startWrite();
    writeLine(x, y, x+w-1, y, color);
    endWrite();
   d470e:	4718      	bx	r3

000d4710 <_ZN12Adafruit_GFX8fillRectEsssst>:
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::fillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d4710:	e92d 47f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, r9, sl, lr}
   d4714:	461e      	mov	r6, r3
    startWrite();
   d4716:	6803      	ldr	r3, [r0, #0]
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::fillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d4718:	f9bd 8028 	ldrsh.w	r8, [sp, #40]	; 0x28
    startWrite();
   d471c:	695b      	ldr	r3, [r3, #20]
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::fillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d471e:	f8bd 902c 	ldrh.w	r9, [sp, #44]	; 0x2c
   d4722:	460c      	mov	r4, r1
   d4724:	4605      	mov	r5, r0
   d4726:	4617      	mov	r7, r2
    startWrite();
   d4728:	4798      	blx	r3
    for (int16_t i=x; i<x+w; i++) {
   d472a:	4426      	add	r6, r4
   d472c:	42b4      	cmp	r4, r6
   d472e:	682a      	ldr	r2, [r5, #0]
   d4730:	da0b      	bge.n	d474a <_ZN12Adafruit_GFX8fillRectEsssst+0x3a>
        writeFastVLine(i, y, h, color);
   d4732:	f8cd 9000 	str.w	r9, [sp]
   d4736:	f8d2 a020 	ldr.w	sl, [r2, #32]
   d473a:	4621      	mov	r1, r4
   d473c:	4643      	mov	r3, r8
   d473e:	463a      	mov	r2, r7
   d4740:	4628      	mov	r0, r5
   d4742:	3401      	adds	r4, #1
   d4744:	47d0      	blx	sl
   d4746:	b224      	sxth	r4, r4
*/
/**************************************************************************/
void Adafruit_GFX::fillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
    startWrite();
    for (int16_t i=x; i<x+w; i++) {
   d4748:	e7f0      	b.n	d472c <_ZN12Adafruit_GFX8fillRectEsssst+0x1c>
        writeFastVLine(i, y, h, color);
    }
    endWrite();
   d474a:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
   d474c:	4628      	mov	r0, r5
}
   d474e:	b002      	add	sp, #8
   d4750:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
        uint16_t color) {
    startWrite();
    for (int16_t i=x; i<x+w; i++) {
        writeFastVLine(i, y, h, color);
    }
    endWrite();
   d4754:	4718      	bx	r3

000d4756 <_ZN12Adafruit_GFX10fillScreenEt>:
/*!
   @brief    Fill the screen completely with one color. Update in subclasses if desired!
    @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::fillScreen(uint16_t color) {
   d4756:	b513      	push	{r0, r1, r4, lr}
    fillRect(0, 0, _width, _height, color);
   d4758:	f9b0 200e 	ldrsh.w	r2, [r0, #14]
   d475c:	6804      	ldr	r4, [r0, #0]
   d475e:	9101      	str	r1, [sp, #4]
   d4760:	9200      	str	r2, [sp, #0]
   d4762:	2200      	movs	r2, #0
   d4764:	f9b0 300c 	ldrsh.w	r3, [r0, #12]
   d4768:	6c24      	ldr	r4, [r4, #64]	; 0x40
   d476a:	4611      	mov	r1, r2
   d476c:	47a0      	blx	r4
}
   d476e:	b002      	add	sp, #8
   d4770:	bd10      	pop	{r4, pc}

000d4772 <_ZN12Adafruit_GFX8drawLineEsssst>:
    @param    y1  End point y coordinate
    @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_GFX::drawLine(int16_t x0, int16_t y0, int16_t x1, int16_t y1,
        uint16_t color) {
   d4772:	e92d 43f7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, lr}
    // Update in subclasses if desired!
    if(x0 == x1){
   d4776:	4299      	cmp	r1, r3
    @param    y1  End point y coordinate
    @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_GFX::drawLine(int16_t x0, int16_t y0, int16_t x1, int16_t y1,
        uint16_t color) {
   d4778:	4690      	mov	r8, r2
   d477a:	4607      	mov	r7, r0
   d477c:	460e      	mov	r6, r1
   d477e:	461c      	mov	r4, r3
   d4780:	f9bd 5028 	ldrsh.w	r5, [sp, #40]	; 0x28
   d4784:	f8bd 902c 	ldrh.w	r9, [sp, #44]	; 0x2c
   d4788:	6802      	ldr	r2, [r0, #0]
    // Update in subclasses if desired!
    if(x0 == x1){
   d478a:	d10b      	bne.n	d47a4 <_ZN12Adafruit_GFX8drawLineEsssst+0x32>
        if(y0 > y1) _swap_int16_t(y0, y1);
   d478c:	45a8      	cmp	r8, r5
   d478e:	bfc2      	ittt	gt
   d4790:	4643      	movgt	r3, r8
   d4792:	46a8      	movgt	r8, r5
   d4794:	461d      	movgt	r5, r3
        drawFastVLine(x0, y0, y1 - y0 + 1, color);
   d4796:	1c6b      	adds	r3, r5, #1
   d4798:	f8cd 9028 	str.w	r9, [sp, #40]	; 0x28
   d479c:	ebc8 0303 	rsb	r3, r8, r3
   d47a0:	6b94      	ldr	r4, [r2, #56]	; 0x38
   d47a2:	e00c      	b.n	d47be <_ZN12Adafruit_GFX8drawLineEsssst+0x4c>
    } else if(y0 == y1){
   d47a4:	45a8      	cmp	r8, r5
   d47a6:	d113      	bne.n	d47d0 <_ZN12Adafruit_GFX8drawLineEsssst+0x5e>
        if(x0 > x1) _swap_int16_t(x0, x1);
   d47a8:	4299      	cmp	r1, r3
   d47aa:	bfc4      	itt	gt
   d47ac:	460b      	movgt	r3, r1
   d47ae:	4626      	movgt	r6, r4
        drawFastHLine(x0, y0, x1 - x0 + 1, color);
   d47b0:	f8cd 9028 	str.w	r9, [sp, #40]	; 0x28
    // Update in subclasses if desired!
    if(x0 == x1){
        if(y0 > y1) _swap_int16_t(y0, y1);
        drawFastVLine(x0, y0, y1 - y0 + 1, color);
    } else if(y0 == y1){
        if(x0 > x1) _swap_int16_t(x0, x1);
   d47b4:	bfc8      	it	gt
   d47b6:	461c      	movgt	r4, r3
        drawFastHLine(x0, y0, x1 - x0 + 1, color);
   d47b8:	1c63      	adds	r3, r4, #1
   d47ba:	6bd4      	ldr	r4, [r2, #60]	; 0x3c
   d47bc:	1b9b      	subs	r3, r3, r6
   d47be:	b21b      	sxth	r3, r3
   d47c0:	4642      	mov	r2, r8
   d47c2:	4631      	mov	r1, r6
   d47c4:	4638      	mov	r0, r7
   d47c6:	46a4      	mov	ip, r4
    } else {
        startWrite();
        writeLine(x0, y0, x1, y1, color);
        endWrite();
    }
}
   d47c8:	b003      	add	sp, #12
   d47ca:	e8bd 43f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, lr}
    if(x0 == x1){
        if(y0 > y1) _swap_int16_t(y0, y1);
        drawFastVLine(x0, y0, y1 - y0 + 1, color);
    } else if(y0 == y1){
        if(x0 > x1) _swap_int16_t(x0, x1);
        drawFastHLine(x0, y0, x1 - x0 + 1, color);
   d47ce:	4760      	bx	ip
    } else {
        startWrite();
   d47d0:	6953      	ldr	r3, [r2, #20]
   d47d2:	4798      	blx	r3
        writeLine(x0, y0, x1, y1, color);
   d47d4:	683b      	ldr	r3, [r7, #0]
   d47d6:	e88d 0220 	stmia.w	sp, {r5, r9}
   d47da:	4638      	mov	r0, r7
   d47dc:	6a9d      	ldr	r5, [r3, #40]	; 0x28
   d47de:	4642      	mov	r2, r8
   d47e0:	4623      	mov	r3, r4
   d47e2:	4631      	mov	r1, r6
   d47e4:	47a8      	blx	r5
        endWrite();
   d47e6:	683b      	ldr	r3, [r7, #0]
   d47e8:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   d47ea:	4638      	mov	r0, r7
    }
}
   d47ec:	b003      	add	sp, #12
   d47ee:	e8bd 43f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, lr}
        if(x0 > x1) _swap_int16_t(x0, x1);
        drawFastHLine(x0, y0, x1 - x0 + 1, color);
    } else {
        startWrite();
        writeLine(x0, y0, x1, y1, color);
        endWrite();
   d47f2:	4718      	bx	r3

000d47f4 <_ZN12Adafruit_GFX8drawRectEsssst>:
    @param    h   Height in pixels
    @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_GFX::drawRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d47f4:	e92d 47f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, r9, sl, lr}
   d47f8:	461e      	mov	r6, r3
    startWrite();
   d47fa:	6803      	ldr	r3, [r0, #0]
    @param    h   Height in pixels
    @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_GFX::drawRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d47fc:	f8bd 802c 	ldrh.w	r8, [sp, #44]	; 0x2c
    startWrite();
   d4800:	695b      	ldr	r3, [r3, #20]
    @param    h   Height in pixels
    @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_GFX::drawRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d4802:	f9bd 9028 	ldrsh.w	r9, [sp, #40]	; 0x28
   d4806:	4604      	mov	r4, r0
   d4808:	460d      	mov	r5, r1
   d480a:	4617      	mov	r7, r2
    startWrite();
   d480c:	4798      	blx	r3
    writeFastHLine(x, y, w, color);
   d480e:	6823      	ldr	r3, [r4, #0]
   d4810:	f8cd 8000 	str.w	r8, [sp]
   d4814:	f8d3 a024 	ldr.w	sl, [r3, #36]	; 0x24
   d4818:	463a      	mov	r2, r7
   d481a:	4633      	mov	r3, r6
   d481c:	4629      	mov	r1, r5
   d481e:	4620      	mov	r0, r4
   d4820:	47d0      	blx	sl
    writeFastHLine(x, y+h-1, w, color);
   d4822:	6823      	ldr	r3, [r4, #0]
   d4824:	f8cd 8000 	str.w	r8, [sp]
   d4828:	f109 32ff 	add.w	r2, r9, #4294967295	; 0xffffffff
   d482c:	443a      	add	r2, r7
   d482e:	f8d3 a024 	ldr.w	sl, [r3, #36]	; 0x24
   d4832:	4629      	mov	r1, r5
   d4834:	4633      	mov	r3, r6
   d4836:	4620      	mov	r0, r4
   d4838:	b212      	sxth	r2, r2
   d483a:	47d0      	blx	sl
    writeFastVLine(x, y, h, color);
   d483c:	6823      	ldr	r3, [r4, #0]
   d483e:	f8cd 8000 	str.w	r8, [sp]
   d4842:	f8d3 a020 	ldr.w	sl, [r3, #32]
   d4846:	463a      	mov	r2, r7
   d4848:	464b      	mov	r3, r9
   d484a:	4629      	mov	r1, r5
   d484c:	4620      	mov	r0, r4
   d484e:	47d0      	blx	sl
    writeFastVLine(x+w-1, y, h, color);
   d4850:	6823      	ldr	r3, [r4, #0]
   d4852:	f8cd 8000 	str.w	r8, [sp]
   d4856:	1e71      	subs	r1, r6, #1
   d4858:	4429      	add	r1, r5
   d485a:	4620      	mov	r0, r4
   d485c:	6a1d      	ldr	r5, [r3, #32]
   d485e:	463a      	mov	r2, r7
   d4860:	464b      	mov	r3, r9
   d4862:	b209      	sxth	r1, r1
   d4864:	47a8      	blx	r5
    endWrite();
   d4866:	6823      	ldr	r3, [r4, #0]
   d4868:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   d486a:	4620      	mov	r0, r4
}
   d486c:	b002      	add	sp, #8
   d486e:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    startWrite();
    writeFastHLine(x, y, w, color);
    writeFastHLine(x, y+h-1, w, color);
    writeFastVLine(x, y, h, color);
    writeFastVLine(x+w-1, y, h, color);
    endWrite();
   d4872:	4718      	bx	r3

000d4874 <_ZN12Adafruit_GFX13invertDisplayEb>:
/*!
    @brief      Invert the display (ideally using built-in hardware command)
    @param   i  True if you want to invert, false to make 'normal'
*/
/**************************************************************************/
void Adafruit_GFX::invertDisplay(boolean i) {
   d4874:	4770      	bx	lr

000d4876 <_ZN12Adafruit_GFX11setRotationEh>:
    @brief      Set rotation setting for display
    @param  x   0 thru 3 corresponding to 4 cardinal rotations
*/
/**************************************************************************/
void Adafruit_GFX::setRotation(uint8_t x) {
    rotation = (x & 3);
   d4876:	f001 0103 	and.w	r1, r1, #3
    switch(rotation) {
   d487a:	2901      	cmp	r1, #1
    @brief      Set rotation setting for display
    @param  x   0 thru 3 corresponding to 4 cardinal rotations
*/
/**************************************************************************/
void Adafruit_GFX::setRotation(uint8_t x) {
    rotation = (x & 3);
   d487c:	7641      	strb	r1, [r0, #25]
   d487e:	8903      	ldrh	r3, [r0, #8]
   d4880:	8942      	ldrh	r2, [r0, #10]
    switch(rotation) {
   d4882:	d004      	beq.n	d488e <_ZN12Adafruit_GFX11setRotationEh+0x18>
   d4884:	2903      	cmp	r1, #3
   d4886:	d002      	beq.n	d488e <_ZN12Adafruit_GFX11setRotationEh+0x18>
        case 0:
        case 2:
            _width  = WIDTH;
   d4888:	8183      	strh	r3, [r0, #12]
            _height = HEIGHT;
   d488a:	81c2      	strh	r2, [r0, #14]
   d488c:	4770      	bx	lr
            break;
        case 1:
        case 3:
            _width  = HEIGHT;
   d488e:	8182      	strh	r2, [r0, #12]
            _height = WIDTH;
   d4890:	81c3      	strh	r3, [r0, #14]
   d4892:	4770      	bx	lr

000d4894 <_ZN12Adafruit_GFXC1Ess>:
   @brief    Instatiate a GFX context for graphics! Can only be done by a superclass
   @param    w   Display width, in pixels
   @param    h   Display height, in pixels
*/
/**************************************************************************/
Adafruit_GFX::Adafruit_GFX(int16_t w, int16_t h):
   d4894:	b530      	push	{r4, r5, lr}
WIDTH(w), HEIGHT(h)
   d4896:	8101      	strh	r1, [r0, #8]
  protected:
    void setWriteError(int err = 1) { write_error = err; }
    size_t printf_impl(bool newline, const char* format, ...);

  public:
    Print() : write_error(0) {}
   d4898:	2400      	movs	r4, #0
   d489a:	4d09      	ldr	r5, [pc, #36]	; (d48c0 <_ZN12Adafruit_GFXC1Ess+0x2c>)
   d489c:	8142      	strh	r2, [r0, #10]
{
    _width    = WIDTH;
   d489e:	8181      	strh	r1, [r0, #12]
    _height   = HEIGHT;
   d48a0:	81c2      	strh	r2, [r0, #14]
    rotation  = 0;
    cursor_y  = cursor_x    = 0;
    textsize  = 1;
    textcolor = textbgcolor = 0xFFFF;
   d48a2:	f64f 71ff 	movw	r1, #65535	; 0xffff
{
    _width    = WIDTH;
    _height   = HEIGHT;
    rotation  = 0;
    cursor_y  = cursor_x    = 0;
    textsize  = 1;
   d48a6:	2201      	movs	r2, #1
   d48a8:	6044      	str	r4, [r0, #4]
   @param    w   Display width, in pixels
   @param    h   Display height, in pixels
*/
/**************************************************************************/
Adafruit_GFX::Adafruit_GFX(int16_t w, int16_t h):
WIDTH(w), HEIGHT(h)
   d48aa:	6005      	str	r5, [r0, #0]
{
    _width    = WIDTH;
    _height   = HEIGHT;
    rotation  = 0;
   d48ac:	7644      	strb	r4, [r0, #25]
    cursor_y  = cursor_x    = 0;
   d48ae:	8204      	strh	r4, [r0, #16]
   d48b0:	8244      	strh	r4, [r0, #18]
    textsize  = 1;
   d48b2:	7602      	strb	r2, [r0, #24]
    textcolor = textbgcolor = 0xFFFF;
   d48b4:	82c1      	strh	r1, [r0, #22]
   d48b6:	8281      	strh	r1, [r0, #20]
    wrap      = true;
   d48b8:	7682      	strb	r2, [r0, #26]
    _cp437    = false;
   d48ba:	76c4      	strb	r4, [r0, #27]
    gfxFont   = NULL;
   d48bc:	61c4      	str	r4, [r0, #28]
}
   d48be:	bd30      	pop	{r4, r5, pc}
   d48c0:	000e97a0 	.word	0x000e97a0

000d48c4 <_ZN12Adafruit_GFX16fillCircleHelperEssshst>:
    @param  delta    Offset from center-point, used for round-rects
    @param  color    16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::fillCircleHelper(int16_t x0, int16_t y0, int16_t r,
  uint8_t corners, int16_t delta, uint16_t color) {
   d48c4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d48c8:	b08b      	sub	sp, #44	; 0x2c
   d48ca:	461c      	mov	r4, r3
   d48cc:	f8bd 3058 	ldrh.w	r3, [sp, #88]	; 0x58
   d48d0:	9304      	str	r3, [sp, #16]

    int16_t f     = 1 - r;
   d48d2:	b2a3      	uxth	r3, r4
   d48d4:	f1c3 0501 	rsb	r5, r3, #1
    int16_t ddF_x = 1;
    int16_t ddF_y = -2 * r;
   d48d8:	ebc3 33c3 	rsb	r3, r3, r3, lsl #15
   d48dc:	005b      	lsls	r3, r3, #1
   d48de:	b21b      	sxth	r3, r3
   d48e0:	9306      	str	r3, [sp, #24]
    int16_t x     = 0;
    int16_t y     = r;
    int16_t px    = x;
    int16_t py    = y;

    delta++; // Avoid some +1's in the loop
   d48e2:	f9bd 3054 	ldrsh.w	r3, [sp, #84]	; 0x54
   d48e6:	3301      	adds	r3, #1
   d48e8:	b29b      	uxth	r3, r3
    @param  delta    Offset from center-point, used for round-rects
    @param  color    16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::fillCircleHelper(int16_t x0, int16_t y0, int16_t r,
  uint8_t corners, int16_t delta, uint16_t color) {
   d48ea:	4692      	mov	sl, r2
   d48ec:	f89d 2050 	ldrb.w	r2, [sp, #80]	; 0x50
    int16_t x     = 0;
    int16_t y     = r;
    int16_t px    = x;
    int16_t py    = y;

    delta++; // Avoid some +1's in the loop
   d48f0:	9305      	str	r3, [sp, #20]
   d48f2:	9302      	str	r3, [sp, #8]
   d48f4:	2300      	movs	r3, #0
   d48f6:	9303      	str	r3, [sp, #12]
        ddF_x += 2;
        f     += ddF_x;
        // These checks avoid double-drawing certain lines, important
        // for the SSD1306 library which has an INVERT drawing mode.
        if(x < (y + 1)) {
            if(corners & 1) writeFastVLine(x0+x, y0-y, 2*y+delta, color);
   d48f8:	f002 0301 	and.w	r3, r2, #1
   d48fc:	9307      	str	r3, [sp, #28]
            if(corners & 2) writeFastVLine(x0-x, y0-y, 2*y+delta, color);
   d48fe:	f002 0302 	and.w	r3, r2, #2
    @param  delta    Offset from center-point, used for round-rects
    @param  color    16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::fillCircleHelper(int16_t x0, int16_t y0, int16_t r,
  uint8_t corners, int16_t delta, uint16_t color) {
   d4902:	4606      	mov	r6, r0
   d4904:	4689      	mov	r9, r1

    int16_t f     = 1 - r;
   d4906:	b22d      	sxth	r5, r5
    int16_t ddF_x = 1;
    int16_t ddF_y = -2 * r;
    int16_t x     = 0;
    int16_t y     = r;
    int16_t px    = x;
    int16_t py    = y;
   d4908:	46a0      	mov	r8, r4
        f     += ddF_x;
        // These checks avoid double-drawing certain lines, important
        // for the SSD1306 library which has an INVERT drawing mode.
        if(x < (y + 1)) {
            if(corners & 1) writeFastVLine(x0+x, y0-y, 2*y+delta, color);
            if(corners & 2) writeFastVLine(x0-x, y0-y, 2*y+delta, color);
   d490a:	9308      	str	r3, [sp, #32]
    int16_t px    = x;
    int16_t py    = y;

    delta++; // Avoid some +1's in the loop

    while(x < y) {
   d490c:	f9bd 300c 	ldrsh.w	r3, [sp, #12]
   d4910:	42a3      	cmp	r3, r4
   d4912:	da70      	bge.n	d49f6 <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0x132>
        if (f >= 0) {
   d4914:	2d00      	cmp	r5, #0
   d4916:	db08      	blt.n	d492a <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0x66>
            y--;
            ddF_y += 2;
   d4918:	9b06      	ldr	r3, [sp, #24]
   d491a:	3302      	adds	r3, #2
   d491c:	b29b      	uxth	r3, r3

    delta++; // Avoid some +1's in the loop

    while(x < y) {
        if (f >= 0) {
            y--;
   d491e:	3c01      	subs	r4, #1
            ddF_y += 2;
   d4920:	b21a      	sxth	r2, r3
            f     += ddF_y;
   d4922:	441d      	add	r5, r3

    delta++; // Avoid some +1's in the loop

    while(x < y) {
        if (f >= 0) {
            y--;
   d4924:	b224      	sxth	r4, r4
            ddF_y += 2;
   d4926:	9206      	str	r2, [sp, #24]
            f     += ddF_y;
   d4928:	b22d      	sxth	r5, r5
   d492a:	f8bd 700c 	ldrh.w	r7, [sp, #12]
        x++;
        ddF_x += 2;
        f     += ddF_x;
        // These checks avoid double-drawing certain lines, important
        // for the SSD1306 library which has an INVERT drawing mode.
        if(x < (y + 1)) {
   d492e:	1c7b      	adds	r3, r7, #1
            ddF_y += 2;
            f     += ddF_y;
        }
        x++;
        ddF_x += 2;
        f     += ddF_x;
   d4930:	eb05 0547 	add.w	r5, r5, r7, lsl #1
        // These checks avoid double-drawing certain lines, important
        // for the SSD1306 library which has an INVERT drawing mode.
        if(x < (y + 1)) {
   d4934:	b21b      	sxth	r3, r3
            ddF_y += 2;
            f     += ddF_y;
        }
        x++;
        ddF_x += 2;
        f     += ddF_x;
   d4936:	3503      	adds	r5, #3
        // These checks avoid double-drawing certain lines, important
        // for the SSD1306 library which has an INVERT drawing mode.
        if(x < (y + 1)) {
   d4938:	429c      	cmp	r4, r3
            ddF_y += 2;
            f     += ddF_y;
        }
        x++;
        ddF_x += 2;
        f     += ddF_x;
   d493a:	b22d      	sxth	r5, r5
        // These checks avoid double-drawing certain lines, important
        // for the SSD1306 library which has an INVERT drawing mode.
        if(x < (y + 1)) {
   d493c:	db2d      	blt.n	d499a <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0xd6>
            if(corners & 1) writeFastVLine(x0+x, y0-y, 2*y+delta, color);
   d493e:	9b07      	ldr	r3, [sp, #28]
   d4940:	b1a3      	cbz	r3, d496c <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0xa8>
   d4942:	6830      	ldr	r0, [r6, #0]
   d4944:	9009      	str	r0, [sp, #36]	; 0x24
   d4946:	9b05      	ldr	r3, [sp, #20]
   d4948:	9804      	ldr	r0, [sp, #16]
   d494a:	9000      	str	r0, [sp, #0]
   d494c:	b2a2      	uxth	r2, r4
   d494e:	9809      	ldr	r0, [sp, #36]	; 0x24
   d4950:	f109 0101 	add.w	r1, r9, #1
   d4954:	eb03 0342 	add.w	r3, r3, r2, lsl #1
   d4958:	4439      	add	r1, r7
   d495a:	ebc2 020a 	rsb	r2, r2, sl
   d495e:	f8d0 b020 	ldr.w	fp, [r0, #32]
   d4962:	b21b      	sxth	r3, r3
   d4964:	b212      	sxth	r2, r2
   d4966:	b209      	sxth	r1, r1
   d4968:	4630      	mov	r0, r6
   d496a:	47d8      	blx	fp
            if(corners & 2) writeFastVLine(x0-x, y0-y, 2*y+delta, color);
   d496c:	9b08      	ldr	r3, [sp, #32]
   d496e:	b1a3      	cbz	r3, d499a <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0xd6>
   d4970:	6830      	ldr	r0, [r6, #0]
   d4972:	9009      	str	r0, [sp, #36]	; 0x24
   d4974:	9b05      	ldr	r3, [sp, #20]
   d4976:	9804      	ldr	r0, [sp, #16]
   d4978:	9000      	str	r0, [sp, #0]
   d497a:	b2a2      	uxth	r2, r4
   d497c:	9809      	ldr	r0, [sp, #36]	; 0x24
   d497e:	f109 31ff 	add.w	r1, r9, #4294967295	; 0xffffffff
   d4982:	eb03 0342 	add.w	r3, r3, r2, lsl #1
   d4986:	1bc9      	subs	r1, r1, r7
   d4988:	ebc2 020a 	rsb	r2, r2, sl
   d498c:	f8d0 b020 	ldr.w	fp, [r0, #32]
   d4990:	b21b      	sxth	r3, r3
   d4992:	b212      	sxth	r2, r2
   d4994:	b209      	sxth	r1, r1
   d4996:	4630      	mov	r0, r6
   d4998:	47d8      	blx	fp
        }
        if(y != py) {
   d499a:	4544      	cmp	r4, r8
   d499c:	d107      	bne.n	d49ae <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0xea>
   d499e:	9b03      	ldr	r3, [sp, #12]
   d49a0:	3301      	adds	r3, #1
   d49a2:	9303      	str	r3, [sp, #12]
   d49a4:	9b02      	ldr	r3, [sp, #8]
   d49a6:	3302      	adds	r3, #2
   d49a8:	b29b      	uxth	r3, r3
   d49aa:	9302      	str	r3, [sp, #8]
   d49ac:	e7ae      	b.n	d490c <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0x48>
            if(corners & 1) writeFastVLine(x0+py, y0-px, 2*px+delta, color);
   d49ae:	9b07      	ldr	r3, [sp, #28]
   d49b0:	b173      	cbz	r3, d49d0 <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0x10c>
   d49b2:	6833      	ldr	r3, [r6, #0]
   d49b4:	9804      	ldr	r0, [sp, #16]
   d49b6:	9000      	str	r0, [sp, #0]
   d49b8:	ebc7 020a 	rsb	r2, r7, sl
   d49bc:	eb09 0108 	add.w	r1, r9, r8
   d49c0:	f8d3 b020 	ldr.w	fp, [r3, #32]
   d49c4:	f9bd 3008 	ldrsh.w	r3, [sp, #8]
   d49c8:	b212      	sxth	r2, r2
   d49ca:	b209      	sxth	r1, r1
   d49cc:	4630      	mov	r0, r6
   d49ce:	47d8      	blx	fp
            if(corners & 2) writeFastVLine(x0-py, y0-px, 2*px+delta, color);
   d49d0:	9b08      	ldr	r3, [sp, #32]
   d49d2:	b90b      	cbnz	r3, d49d8 <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0x114>
   d49d4:	46a0      	mov	r8, r4
   d49d6:	e7e2      	b.n	d499e <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0xda>
   d49d8:	6833      	ldr	r3, [r6, #0]
   d49da:	9804      	ldr	r0, [sp, #16]
   d49dc:	9000      	str	r0, [sp, #0]
   d49de:	ebc7 020a 	rsb	r2, r7, sl
   d49e2:	ebc8 0109 	rsb	r1, r8, r9
   d49e6:	6a1f      	ldr	r7, [r3, #32]
   d49e8:	f9bd 3008 	ldrsh.w	r3, [sp, #8]
   d49ec:	b212      	sxth	r2, r2
   d49ee:	b209      	sxth	r1, r1
   d49f0:	4630      	mov	r0, r6
   d49f2:	47b8      	blx	r7
   d49f4:	e7ee      	b.n	d49d4 <_ZN12Adafruit_GFX16fillCircleHelperEssshst+0x110>
            py = y;
        }
        px = x;
    }
}
   d49f6:	b00b      	add	sp, #44	; 0x2c
   d49f8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d49fc <_ZN12Adafruit_GFX10fillCircleEssst>:
    @param    r   Radius of circle
    @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::fillCircle(int16_t x0, int16_t y0, int16_t r,
        uint16_t color) {
   d49fc:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
   d4a00:	461f      	mov	r7, r3
    startWrite();
   d4a02:	6803      	ldr	r3, [r0, #0]
    @param    r   Radius of circle
    @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::fillCircle(int16_t x0, int16_t y0, int16_t r,
        uint16_t color) {
   d4a04:	b085      	sub	sp, #20
   d4a06:	4604      	mov	r4, r0
    startWrite();
   d4a08:	695b      	ldr	r3, [r3, #20]
    @param    r   Radius of circle
    @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_GFX::fillCircle(int16_t x0, int16_t y0, int16_t r,
        uint16_t color) {
   d4a0a:	f8bd 8030 	ldrh.w	r8, [sp, #48]	; 0x30
   d4a0e:	460d      	mov	r5, r1
   d4a10:	4616      	mov	r6, r2
    startWrite();
   d4a12:	4798      	blx	r3
    writeFastVLine(x0, y0-r, 2*r+1, color);
   d4a14:	b2ba      	uxth	r2, r7
   d4a16:	6821      	ldr	r1, [r4, #0]
   d4a18:	f8cd 8000 	str.w	r8, [sp]
   d4a1c:	0053      	lsls	r3, r2, #1
   d4a1e:	3301      	adds	r3, #1
   d4a20:	1ab2      	subs	r2, r6, r2
   d4a22:	f8d1 9020 	ldr.w	r9, [r1, #32]
   d4a26:	4620      	mov	r0, r4
   d4a28:	4629      	mov	r1, r5
   d4a2a:	b21b      	sxth	r3, r3
   d4a2c:	b212      	sxth	r2, r2
   d4a2e:	47c8      	blx	r9
    fillCircleHelper(x0, y0, r, 3, 0, color);
   d4a30:	2203      	movs	r2, #3
   d4a32:	2300      	movs	r3, #0
   d4a34:	e88d 000c 	stmia.w	sp, {r2, r3}
   d4a38:	4620      	mov	r0, r4
   d4a3a:	463b      	mov	r3, r7
   d4a3c:	f8cd 8008 	str.w	r8, [sp, #8]
   d4a40:	4632      	mov	r2, r6
   d4a42:	4629      	mov	r1, r5
   d4a44:	f7ff ff3e 	bl	d48c4 <_ZN12Adafruit_GFX16fillCircleHelperEssshst>
    endWrite();
   d4a48:	6823      	ldr	r3, [r4, #0]
   d4a4a:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   d4a4c:	4620      	mov	r0, r4
}
   d4a4e:	b005      	add	sp, #20
   d4a50:	e8bd 43f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, lr}
void Adafruit_GFX::fillCircle(int16_t x0, int16_t y0, int16_t r,
        uint16_t color) {
    startWrite();
    writeFastVLine(x0, y0-r, 2*r+1, color);
    fillCircleHelper(x0, y0, r, 3, 0, color);
    endWrite();
   d4a54:	4718      	bx	r3
	...

000d4a58 <_ZN12Adafruit_GFX8drawCharEsshtth>:
    @param    bg 16-bit 5-6-5 Color to fill background with (if same as color, no background)
    @param    size  Font magnification level, 1 is 'original' size
*/
/**************************************************************************/
void Adafruit_GFX::drawChar(int16_t x, int16_t y, unsigned char c,
  uint16_t color, uint16_t bg, uint8_t size) {
   d4a58:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d4a5c:	b091      	sub	sp, #68	; 0x44
   d4a5e:	4691      	mov	r9, r2

    if(!gfxFont) { // 'Classic' built-in font
   d4a60:	69c2      	ldr	r2, [r0, #28]
    @param    bg 16-bit 5-6-5 Color to fill background with (if same as color, no background)
    @param    size  Font magnification level, 1 is 'original' size
*/
/**************************************************************************/
void Adafruit_GFX::drawChar(int16_t x, int16_t y, unsigned char c,
  uint16_t color, uint16_t bg, uint8_t size) {
   d4a62:	9105      	str	r1, [sp, #20]
   d4a64:	461e      	mov	r6, r3
   d4a66:	f8bd 3068 	ldrh.w	r3, [sp, #104]	; 0x68
   d4a6a:	9302      	str	r3, [sp, #8]
   d4a6c:	4604      	mov	r4, r0
   d4a6e:	f8bd a06c 	ldrh.w	sl, [sp, #108]	; 0x6c
   d4a72:	f89d 5070 	ldrb.w	r5, [sp, #112]	; 0x70

    if(!gfxFont) { // 'Classic' built-in font
   d4a76:	2a00      	cmp	r2, #0
   d4a78:	f040 80b7 	bne.w	d4bea <_ZN12Adafruit_GFX8drawCharEsshtth+0x192>

        if((x >= _width)            || // Clip right
   d4a7c:	f9b0 300c 	ldrsh.w	r3, [r0, #12]
   d4a80:	428b      	cmp	r3, r1
   d4a82:	f340 8145 	ble.w	d4d10 <_ZN12Adafruit_GFX8drawCharEsshtth+0x2b8>
   d4a86:	f9b0 300e 	ldrsh.w	r3, [r0, #14]
   d4a8a:	454b      	cmp	r3, r9
   d4a8c:	f340 8140 	ble.w	d4d10 <_ZN12Adafruit_GFX8drawCharEsshtth+0x2b8>
           (y >= _height)           || // Clip bottom
           ((x + 6 * size - 1) < 0) || // Clip left
   d4a90:	2306      	movs	r3, #6
  uint16_t color, uint16_t bg, uint8_t size) {

    if(!gfxFont) { // 'Classic' built-in font

        if((x >= _width)            || // Clip right
           (y >= _height)           || // Clip bottom
   d4a92:	fb13 1305 	smlabb	r3, r3, r5, r1
   d4a96:	2b00      	cmp	r3, #0
   d4a98:	f340 813a 	ble.w	d4d10 <_ZN12Adafruit_GFX8drawCharEsshtth+0x2b8>
           ((x + 6 * size - 1) < 0) || // Clip left
   d4a9c:	eb09 03c5 	add.w	r3, r9, r5, lsl #3
   d4aa0:	2b00      	cmp	r3, #0
   d4aa2:	f340 8135 	ble.w	d4d10 <_ZN12Adafruit_GFX8drawCharEsshtth+0x2b8>
           ((y + 8 * size - 1) < 0))   // Clip top
            return;

        if(!_cp437 && (c >= 176)) c++; // Handle 'classic' charset behavior
   d4aa6:	7ec3      	ldrb	r3, [r0, #27]
   d4aa8:	b91b      	cbnz	r3, d4ab2 <_ZN12Adafruit_GFX8drawCharEsshtth+0x5a>
   d4aaa:	2eaf      	cmp	r6, #175	; 0xaf
   d4aac:	bf84      	itt	hi
   d4aae:	3601      	addhi	r6, #1
   d4ab0:	b2f6      	uxtbhi	r6, r6

        startWrite();
   d4ab2:	6823      	ldr	r3, [r4, #0]
   d4ab4:	4620      	mov	r0, r4
   d4ab6:	695b      	ldr	r3, [r3, #20]
   d4ab8:	4798      	blx	r3
        for(int8_t i=0; i<5; i++ ) { // Char bitmap = 5 columns
            uint8_t line = pgm_read_byte(&font[c * 5 + i]);
   d4aba:	2305      	movs	r3, #5
   d4abc:	930c      	str	r3, [sp, #48]	; 0x30
            return;

        if(!_cp437 && (c >= 176)) c++; // Handle 'classic' charset behavior

        startWrite();
        for(int8_t i=0; i<5; i++ ) { // Char bitmap = 5 columns
   d4abe:	2300      	movs	r3, #0
   d4ac0:	9303      	str	r3, [sp, #12]
   d4ac2:	fa1f f389 	uxth.w	r3, r9
   d4ac6:	9307      	str	r3, [sp, #28]
   d4ac8:	3308      	adds	r3, #8
   d4aca:	b29b      	uxth	r3, r3
   d4acc:	930e      	str	r3, [sp, #56]	; 0x38
            uint8_t line = pgm_read_byte(&font[c * 5 + i]);
   d4ace:	2305      	movs	r3, #5
   d4ad0:	461a      	mov	r2, r3
   d4ad2:	9b03      	ldr	r3, [sp, #12]
   d4ad4:	f8dd 801c 	ldr.w	r8, [sp, #28]
            for(int8_t j=0; j<8; j++, line >>= 1) {
                if(line & 1) {
                    if(size == 1)
                        writePixel(x+i, y+j, color);
                    else
                        writeFillRect(x+i*size, y+j*size, size, size, color);
   d4ad8:	f8cd 8024 	str.w	r8, [sp, #36]	; 0x24

        if(!_cp437 && (c >= 176)) c++; // Handle 'classic' charset behavior

        startWrite();
        for(int8_t i=0; i<5; i++ ) { // Char bitmap = 5 columns
            uint8_t line = pgm_read_byte(&font[c * 5 + i]);
   d4adc:	fb12 3306 	smlabb	r3, r2, r6, r3
   d4ae0:	4a8d      	ldr	r2, [pc, #564]	; (d4d18 <_ZN12Adafruit_GFX8drawCharEsshtth+0x2c0>)
            for(int8_t j=0; j<8; j++, line >>= 1) {
                if(line & 1) {
                    if(size == 1)
                        writePixel(x+i, y+j, color);
                    else
                        writeFillRect(x+i*size, y+j*size, size, size, color);
   d4ae2:	f8cd 8028 	str.w	r8, [sp, #40]	; 0x28

        if(!_cp437 && (c >= 176)) c++; // Handle 'classic' charset behavior

        startWrite();
        for(int8_t i=0; i<5; i++ ) { // Char bitmap = 5 columns
            uint8_t line = pgm_read_byte(&font[c * 5 + i]);
   d4ae6:	5cd3      	ldrb	r3, [r2, r3]
   d4ae8:	9308      	str	r3, [sp, #32]
            for(int8_t j=0; j<8; j++, line >>= 1) {
                if(line & 1) {
                    if(size == 1)
                        writePixel(x+i, y+j, color);
                    else
                        writeFillRect(x+i*size, y+j*size, size, size, color);
   d4aea:	f8bd 3014 	ldrh.w	r3, [sp, #20]
   d4aee:	9304      	str	r3, [sp, #16]
   d4af0:	9a04      	ldr	r2, [sp, #16]
   d4af2:	9b03      	ldr	r3, [sp, #12]
   d4af4:	b2af      	uxth	r7, r5
   d4af6:	fb03 2307 	mla	r3, r3, r7, r2
   d4afa:	b21b      	sxth	r3, r3
   d4afc:	930b      	str	r3, [sp, #44]	; 0x2c
                } else if(bg != color) {
                    if(size == 1)
                        writePixel(x+i, y+j, bg);
                    else
                        writeFillRect(x+i*size, y+j*size, size, size, bg);
   d4afe:	b22b      	sxth	r3, r5
   d4b00:	9306      	str	r3, [sp, #24]
                        writePixel(x+i, y+j, color);
                    else
                        writeFillRect(x+i*size, y+j*size, size, size, color);
                } else if(bg != color) {
                    if(size == 1)
                        writePixel(x+i, y+j, bg);
   d4b02:	f8bd 200c 	ldrh.w	r2, [sp, #12]
   d4b06:	9b04      	ldr	r3, [sp, #16]
   d4b08:	fa13 f382 	uxtah	r3, r3, r2
   d4b0c:	b21b      	sxth	r3, r3
   d4b0e:	930d      	str	r3, [sp, #52]	; 0x34

        startWrite();
        for(int8_t i=0; i<5; i++ ) { // Char bitmap = 5 columns
            uint8_t line = pgm_read_byte(&font[c * 5 + i]);
            for(int8_t j=0; j<8; j++, line >>= 1) {
                if(line & 1) {
   d4b10:	9b08      	ldr	r3, [sp, #32]
   d4b12:	07d9      	lsls	r1, r3, #31
   d4b14:	d510      	bpl.n	d4b38 <_ZN12Adafruit_GFX8drawCharEsshtth+0xe0>
                    if(size == 1)
   d4b16:	2d01      	cmp	r5, #1
   d4b18:	6823      	ldr	r3, [r4, #0]
   d4b1a:	d103      	bne.n	d4b24 <_ZN12Adafruit_GFX8drawCharEsshtth+0xcc>
                        writePixel(x+i, y+j, color);
   d4b1c:	f8d3 b018 	ldr.w	fp, [r3, #24]
   d4b20:	9b02      	ldr	r3, [sp, #8]
   d4b22:	e012      	b.n	d4b4a <_ZN12Adafruit_GFX8drawCharEsshtth+0xf2>
                    else
                        writeFillRect(x+i*size, y+j*size, size, size, color);
   d4b24:	9a02      	ldr	r2, [sp, #8]
   d4b26:	9201      	str	r2, [sp, #4]
   d4b28:	9a06      	ldr	r2, [sp, #24]
   d4b2a:	9200      	str	r2, [sp, #0]
   d4b2c:	f8d3 b01c 	ldr.w	fp, [r3, #28]
   d4b30:	4613      	mov	r3, r2
   d4b32:	f9bd 2028 	ldrsh.w	r2, [sp, #40]	; 0x28
   d4b36:	e017      	b.n	d4b68 <_ZN12Adafruit_GFX8drawCharEsshtth+0x110>
                } else if(bg != color) {
   d4b38:	9b02      	ldr	r3, [sp, #8]
   d4b3a:	4553      	cmp	r3, sl
   d4b3c:	d017      	beq.n	d4b6e <_ZN12Adafruit_GFX8drawCharEsshtth+0x116>
                    if(size == 1)
   d4b3e:	2d01      	cmp	r5, #1
   d4b40:	6823      	ldr	r3, [r4, #0]
   d4b42:	d108      	bne.n	d4b56 <_ZN12Adafruit_GFX8drawCharEsshtth+0xfe>
                        writePixel(x+i, y+j, bg);
   d4b44:	f8d3 b018 	ldr.w	fp, [r3, #24]
   d4b48:	4653      	mov	r3, sl
   d4b4a:	fa0f f288 	sxth.w	r2, r8
   d4b4e:	990d      	ldr	r1, [sp, #52]	; 0x34
   d4b50:	4620      	mov	r0, r4
   d4b52:	47d8      	blx	fp
   d4b54:	e00b      	b.n	d4b6e <_ZN12Adafruit_GFX8drawCharEsshtth+0x116>
                    else
                        writeFillRect(x+i*size, y+j*size, size, size, bg);
   d4b56:	9a06      	ldr	r2, [sp, #24]
   d4b58:	9200      	str	r2, [sp, #0]
   d4b5a:	f8cd a004 	str.w	sl, [sp, #4]
   d4b5e:	f8d3 b01c 	ldr.w	fp, [r3, #28]
   d4b62:	4613      	mov	r3, r2
   d4b64:	f9bd 2024 	ldrsh.w	r2, [sp, #36]	; 0x24
   d4b68:	990b      	ldr	r1, [sp, #44]	; 0x2c
   d4b6a:	4620      	mov	r0, r4
   d4b6c:	47d8      	blx	fp
        if(!_cp437 && (c >= 176)) c++; // Handle 'classic' charset behavior

        startWrite();
        for(int8_t i=0; i<5; i++ ) { // Char bitmap = 5 columns
            uint8_t line = pgm_read_byte(&font[c * 5 + i]);
            for(int8_t j=0; j<8; j++, line >>= 1) {
   d4b6e:	9b08      	ldr	r3, [sp, #32]
   d4b70:	085b      	lsrs	r3, r3, #1
   d4b72:	9308      	str	r3, [sp, #32]
   d4b74:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   d4b76:	443b      	add	r3, r7
   d4b78:	b29b      	uxth	r3, r3
   d4b7a:	930a      	str	r3, [sp, #40]	; 0x28
   d4b7c:	9b09      	ldr	r3, [sp, #36]	; 0x24
   d4b7e:	443b      	add	r3, r7
   d4b80:	b29b      	uxth	r3, r3
   d4b82:	9309      	str	r3, [sp, #36]	; 0x24
   d4b84:	f108 0801 	add.w	r8, r8, #1
   d4b88:	9b0e      	ldr	r3, [sp, #56]	; 0x38
   d4b8a:	fa1f f888 	uxth.w	r8, r8
   d4b8e:	4543      	cmp	r3, r8
   d4b90:	d1be      	bne.n	d4b10 <_ZN12Adafruit_GFX8drawCharEsshtth+0xb8>
            return;

        if(!_cp437 && (c >= 176)) c++; // Handle 'classic' charset behavior

        startWrite();
        for(int8_t i=0; i<5; i++ ) { // Char bitmap = 5 columns
   d4b92:	9b03      	ldr	r3, [sp, #12]
   d4b94:	3301      	adds	r3, #1
   d4b96:	b25b      	sxtb	r3, r3
   d4b98:	9303      	str	r3, [sp, #12]
   d4b9a:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   d4b9c:	3b01      	subs	r3, #1
   d4b9e:	f013 03ff 	ands.w	r3, r3, #255	; 0xff
   d4ba2:	930c      	str	r3, [sp, #48]	; 0x30
   d4ba4:	d193      	bne.n	d4ace <_ZN12Adafruit_GFX8drawCharEsshtth+0x76>
                    else
                        writeFillRect(x+i*size, y+j*size, size, size, bg);
                }
            }
        }
        if(bg != color) { // If opaque, draw vertical line for last column
   d4ba6:	9b02      	ldr	r3, [sp, #8]
   d4ba8:	4553      	cmp	r3, sl
   d4baa:	f000 80aa 	beq.w	d4d02 <_ZN12Adafruit_GFX8drawCharEsshtth+0x2aa>
            if(size == 1) writeFastVLine(x+5, y, 8, bg);
   d4bae:	2d01      	cmp	r5, #1
   d4bb0:	6823      	ldr	r3, [r4, #0]
   d4bb2:	d10a      	bne.n	d4bca <_ZN12Adafruit_GFX8drawCharEsshtth+0x172>
   d4bb4:	9904      	ldr	r1, [sp, #16]
   d4bb6:	f8cd a000 	str.w	sl, [sp]
   d4bba:	3105      	adds	r1, #5
   d4bbc:	6a1d      	ldr	r5, [r3, #32]
   d4bbe:	464a      	mov	r2, r9
   d4bc0:	2308      	movs	r3, #8
   d4bc2:	b209      	sxth	r1, r1
   d4bc4:	4620      	mov	r0, r4
   d4bc6:	47a8      	blx	r5
   d4bc8:	e09b      	b.n	d4d02 <_ZN12Adafruit_GFX8drawCharEsshtth+0x2aa>
            else          writeFillRect(x+5*size, y, size, 8*size, bg);
   d4bca:	9a04      	ldr	r2, [sp, #16]
   d4bcc:	f8cd a004 	str.w	sl, [sp, #4]
   d4bd0:	eb07 0187 	add.w	r1, r7, r7, lsl #2
   d4bd4:	440a      	add	r2, r1
   d4bd6:	00ff      	lsls	r7, r7, #3
   d4bd8:	4611      	mov	r1, r2
   d4bda:	9700      	str	r7, [sp, #0]
   d4bdc:	69de      	ldr	r6, [r3, #28]
   d4bde:	464a      	mov	r2, r9
   d4be0:	462b      	mov	r3, r5
   d4be2:	b209      	sxth	r1, r1
   d4be4:	4620      	mov	r0, r4
   d4be6:	47b0      	blx	r6
   d4be8:	e08b      	b.n	d4d02 <_ZN12Adafruit_GFX8drawCharEsshtth+0x2aa>

        // Character is assumed previously filtered by write() to eliminate
        // newlines, returns, non-printable characters, etc.  Calling
        // drawChar() directly with 'bad' characters of font may cause mayhem!

        c -= (uint8_t)pgm_read_byte(&gfxFont->first);
   d4bea:	7a13      	ldrb	r3, [r2, #8]
   d4bec:	1af6      	subs	r6, r6, r3
        GFXglyph *glyph  = &(((GFXglyph *)pgm_read_pointer(&gfxFont->glyph))[c]);
   d4bee:	6853      	ldr	r3, [r2, #4]

        // Character is assumed previously filtered by write() to eliminate
        // newlines, returns, non-printable characters, etc.  Calling
        // drawChar() directly with 'bad' characters of font may cause mayhem!

        c -= (uint8_t)pgm_read_byte(&gfxFont->first);
   d4bf0:	b2f6      	uxtb	r6, r6
        GFXglyph *glyph  = &(((GFXglyph *)pgm_read_pointer(&gfxFont->glyph))[c]);
   d4bf2:	eb03 06c6 	add.w	r6, r3, r6, lsl #3
        uint8_t  *bitmap = (uint8_t *)pgm_read_pointer(&gfxFont->bitmap);
   d4bf6:	6813      	ldr	r3, [r2, #0]
   d4bf8:	930b      	str	r3, [sp, #44]	; 0x2c

        uint16_t bo = pgm_read_word(&glyph->bitmapOffset);
        uint8_t  w  = pgm_read_byte(&glyph->width),
   d4bfa:	78b3      	ldrb	r3, [r6, #2]
                 h  = pgm_read_byte(&glyph->height);
        int8_t   xo = pgm_read_byte(&glyph->xOffset),
                 yo = pgm_read_byte(&glyph->yOffset);
   d4bfc:	f996 a006 	ldrsb.w	sl, [r6, #6]
        c -= (uint8_t)pgm_read_byte(&gfxFont->first);
        GFXglyph *glyph  = &(((GFXglyph *)pgm_read_pointer(&gfxFont->glyph))[c]);
        uint8_t  *bitmap = (uint8_t *)pgm_read_pointer(&gfxFont->bitmap);

        uint16_t bo = pgm_read_word(&glyph->bitmapOffset);
        uint8_t  w  = pgm_read_byte(&glyph->width),
   d4c00:	9307      	str	r3, [sp, #28]
                 h  = pgm_read_byte(&glyph->height);
   d4c02:	78f3      	ldrb	r3, [r6, #3]
   d4c04:	930c      	str	r3, [sp, #48]	; 0x30
        int8_t   xo = pgm_read_byte(&glyph->xOffset),
                 yo = pgm_read_byte(&glyph->yOffset);
        uint8_t  xx, yy, bits = 0, bit = 0;
        int16_t  xo16 = 0, yo16 = 0;

        if(size > 1) {
   d4c06:	2d01      	cmp	r5, #1
        uint8_t  *bitmap = (uint8_t *)pgm_read_pointer(&gfxFont->bitmap);

        uint16_t bo = pgm_read_word(&glyph->bitmapOffset);
        uint8_t  w  = pgm_read_byte(&glyph->width),
                 h  = pgm_read_byte(&glyph->height);
        int8_t   xo = pgm_read_byte(&glyph->xOffset),
   d4c08:	f996 3005 	ldrsb.w	r3, [r6, #5]
   d4c0c:	9308      	str	r3, [sp, #32]
                 yo = pgm_read_byte(&glyph->yOffset);
        uint8_t  xx, yy, bits = 0, bit = 0;
        int16_t  xo16 = 0, yo16 = 0;
   d4c0e:	bf94      	ite	ls
   d4c10:	2300      	movls	r3, #0

        if(size > 1) {
            xo16 = xo;
            yo16 = yo;
   d4c12:	fa0f f38a 	sxthhi.w	r3, sl

        c -= (uint8_t)pgm_read_byte(&gfxFont->first);
        GFXglyph *glyph  = &(((GFXglyph *)pgm_read_pointer(&gfxFont->glyph))[c]);
        uint8_t  *bitmap = (uint8_t *)pgm_read_pointer(&gfxFont->bitmap);

        uint16_t bo = pgm_read_word(&glyph->bitmapOffset);
   d4c16:	f8b6 b000 	ldrh.w	fp, [r6]
        uint8_t  xx, yy, bits = 0, bit = 0;
        int16_t  xo16 = 0, yo16 = 0;

        if(size > 1) {
            xo16 = xo;
            yo16 = yo;
   d4c1a:	bf8e      	itee	hi
   d4c1c:	9304      	strhi	r3, [sp, #16]
        uint8_t  w  = pgm_read_byte(&glyph->width),
                 h  = pgm_read_byte(&glyph->height);
        int8_t   xo = pgm_read_byte(&glyph->xOffset),
                 yo = pgm_read_byte(&glyph->yOffset);
        uint8_t  xx, yy, bits = 0, bit = 0;
        int16_t  xo16 = 0, yo16 = 0;
   d4c1e:	461e      	movls	r6, r3
   d4c20:	9304      	strls	r3, [sp, #16]
        // only creates a new set of problems.  Have an idea to work around
        // this (a canvas object type for MCUs that can afford the RAM and
        // displays supporting setAddrWindow() and pushColors()), but haven't
        // implemented this yet.

        startWrite();
   d4c22:	6803      	ldr	r3, [r0, #0]
                 yo = pgm_read_byte(&glyph->yOffset);
        uint8_t  xx, yy, bits = 0, bit = 0;
        int16_t  xo16 = 0, yo16 = 0;

        if(size > 1) {
            xo16 = xo;
   d4c24:	bf88      	it	hi
   d4c26:	f9bd 6020 	ldrshhi.w	r6, [sp, #32]
        // only creates a new set of problems.  Have an idea to work around
        // this (a canvas object type for MCUs that can afford the RAM and
        // displays supporting setAddrWindow() and pushColors()), but haven't
        // implemented this yet.

        startWrite();
   d4c2a:	695b      	ldr	r3, [r3, #20]
   d4c2c:	4798      	blx	r3
                }
                if(bits & 0x80) {
                    if(size == 1) {
                        writePixel(x+xo+xx, y+yo+yy, color);
                    } else {
                        writeFillRect(x+(xo16+xx)*size, y+(yo16+yy)*size,
   d4c2e:	b2ab      	uxth	r3, r5
   d4c30:	9306      	str	r3, [sp, #24]
   d4c32:	f8bd 3014 	ldrh.w	r3, [sp, #20]
   d4c36:	9305      	str	r3, [sp, #20]
   d4c38:	9a05      	ldr	r2, [sp, #20]
   d4c3a:	9b06      	ldr	r3, [sp, #24]
   d4c3c:	fb06 2603 	mla	r6, r6, r3, r2
   d4c40:	b2b3      	uxth	r3, r6
   d4c42:	930a      	str	r3, [sp, #40]	; 0x28
   d4c44:	fa1f f389 	uxth.w	r3, r9
   d4c48:	2600      	movs	r6, #0
   d4c4a:	9309      	str	r3, [sp, #36]	; 0x24
                if(!(bit++ & 7)) {
                    bits = pgm_read_byte(&bitmap[bo++]);
                }
                if(bits & 0x80) {
                    if(size == 1) {
                        writePixel(x+xo+xx, y+yo+yy, color);
   d4c4c:	4453      	add	r3, sl
        uint16_t bo = pgm_read_word(&glyph->bitmapOffset);
        uint8_t  w  = pgm_read_byte(&glyph->width),
                 h  = pgm_read_byte(&glyph->height);
        int8_t   xo = pgm_read_byte(&glyph->xOffset),
                 yo = pgm_read_byte(&glyph->yOffset);
        uint8_t  xx, yy, bits = 0, bit = 0;
   d4c4e:	46b0      	mov	r8, r6
   d4c50:	9603      	str	r6, [sp, #12]
                if(!(bit++ & 7)) {
                    bits = pgm_read_byte(&bitmap[bo++]);
                }
                if(bits & 0x80) {
                    if(size == 1) {
                        writePixel(x+xo+xx, y+yo+yy, color);
   d4c52:	930f      	str	r3, [sp, #60]	; 0x3c
        // this (a canvas object type for MCUs that can afford the RAM and
        // displays supporting setAddrWindow() and pushColors()), but haven't
        // implemented this yet.

        startWrite();
        for(yy=0; yy<h; yy++) {
   d4c54:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   d4c56:	b2f2      	uxtb	r2, r6
   d4c58:	429a      	cmp	r2, r3
   d4c5a:	d252      	bcs.n	d4d02 <_ZN12Adafruit_GFX8drawCharEsshtth+0x2aa>
                }
                if(bits & 0x80) {
                    if(size == 1) {
                        writePixel(x+xo+xx, y+yo+yy, color);
                    } else {
                        writeFillRect(x+(xo16+xx)*size, y+(yo16+yy)*size,
   d4c5c:	9b04      	ldr	r3, [sp, #16]
   d4c5e:	f8bd 1018 	ldrh.w	r1, [sp, #24]
   d4c62:	f8dd 9028 	ldr.w	r9, [sp, #40]	; 0x28
   d4c66:	18f3      	adds	r3, r6, r3
   d4c68:	fb13 f301 	smulbb	r3, r3, r1
   d4c6c:	9909      	ldr	r1, [sp, #36]	; 0x24
   d4c6e:	440b      	add	r3, r1
   d4c70:	b21b      	sxth	r3, r3
   d4c72:	930d      	str	r3, [sp, #52]	; 0x34
                if(!(bit++ & 7)) {
                    bits = pgm_read_byte(&bitmap[bo++]);
                }
                if(bits & 0x80) {
                    if(size == 1) {
                        writePixel(x+xo+xx, y+yo+yy, color);
   d4c74:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   d4c76:	441a      	add	r2, r3
   d4c78:	b213      	sxth	r3, r2
                    } else {
                        writeFillRect(x+(xo16+xx)*size, y+(yo16+yy)*size,
   d4c7a:	f04f 0a00 	mov.w	sl, #0
                if(!(bit++ & 7)) {
                    bits = pgm_read_byte(&bitmap[bo++]);
                }
                if(bits & 0x80) {
                    if(size == 1) {
                        writePixel(x+xo+xx, y+yo+yy, color);
   d4c7e:	930e      	str	r3, [sp, #56]	; 0x38
        // displays supporting setAddrWindow() and pushColors()), but haven't
        // implemented this yet.

        startWrite();
        for(yy=0; yy<h; yy++) {
            for(xx=0; xx<w; xx++) {
   d4c80:	9907      	ldr	r1, [sp, #28]
   d4c82:	fa5f f28a 	uxtb.w	r2, sl
   d4c86:	eb08 0302 	add.w	r3, r8, r2
   d4c8a:	4291      	cmp	r1, r2
   d4c8c:	b2db      	uxtb	r3, r3
   d4c8e:	d932      	bls.n	d4cf6 <_ZN12Adafruit_GFX8drawCharEsshtth+0x29e>
                if(!(bit++ & 7)) {
   d4c90:	075a      	lsls	r2, r3, #29
   d4c92:	d107      	bne.n	d4ca4 <_ZN12Adafruit_GFX8drawCharEsshtth+0x24c>
                    bits = pgm_read_byte(&bitmap[bo++]);
   d4c94:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   d4c96:	f10b 0301 	add.w	r3, fp, #1
   d4c9a:	f812 200b 	ldrb.w	r2, [r2, fp]
   d4c9e:	9203      	str	r2, [sp, #12]
   d4ca0:	fa1f fb83 	uxth.w	fp, r3
                }
                if(bits & 0x80) {
   d4ca4:	9b03      	ldr	r3, [sp, #12]
   d4ca6:	061b      	lsls	r3, r3, #24
   d4ca8:	d51a      	bpl.n	d4ce0 <_ZN12Adafruit_GFX8drawCharEsshtth+0x288>
                    if(size == 1) {
   d4caa:	2d01      	cmp	r5, #1
   d4cac:	d10c      	bne.n	d4cc8 <_ZN12Adafruit_GFX8drawCharEsshtth+0x270>
                        writePixel(x+xo+xx, y+yo+yy, color);
   d4cae:	9b05      	ldr	r3, [sp, #20]
   d4cb0:	9a08      	ldr	r2, [sp, #32]
   d4cb2:	1899      	adds	r1, r3, r2
   d4cb4:	6823      	ldr	r3, [r4, #0]
   d4cb6:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   d4cb8:	699b      	ldr	r3, [r3, #24]
   d4cba:	4451      	add	r1, sl
   d4cbc:	461f      	mov	r7, r3
   d4cbe:	b209      	sxth	r1, r1
   d4cc0:	9b02      	ldr	r3, [sp, #8]
   d4cc2:	4620      	mov	r0, r4
   d4cc4:	47b8      	blx	r7
   d4cc6:	e00b      	b.n	d4ce0 <_ZN12Adafruit_GFX8drawCharEsshtth+0x288>
                    } else {
                        writeFillRect(x+(xo16+xx)*size, y+(yo16+yy)*size,
                          size, size, color);
   d4cc8:	9902      	ldr	r1, [sp, #8]
   d4cca:	6822      	ldr	r2, [r4, #0]
   d4ccc:	9101      	str	r1, [sp, #4]
                }
                if(bits & 0x80) {
                    if(size == 1) {
                        writePixel(x+xo+xx, y+yo+yy, color);
                    } else {
                        writeFillRect(x+(xo16+xx)*size, y+(yo16+yy)*size,
   d4cce:	b22b      	sxth	r3, r5
                          size, size, color);
   d4cd0:	9300      	str	r3, [sp, #0]
   d4cd2:	69d2      	ldr	r2, [r2, #28]
   d4cd4:	fa0f f189 	sxth.w	r1, r9
   d4cd8:	4617      	mov	r7, r2
   d4cda:	4620      	mov	r0, r4
   d4cdc:	9a0d      	ldr	r2, [sp, #52]	; 0x34
   d4cde:	47b8      	blx	r7
                    }
                }
                bits <<= 1;
   d4ce0:	9b03      	ldr	r3, [sp, #12]
   d4ce2:	005f      	lsls	r7, r3, #1
   d4ce4:	b2fb      	uxtb	r3, r7
   d4ce6:	9303      	str	r3, [sp, #12]
   d4ce8:	9b06      	ldr	r3, [sp, #24]
   d4cea:	4499      	add	r9, r3
   d4cec:	f10a 0a01 	add.w	sl, sl, #1
   d4cf0:	fa1f f989 	uxth.w	r9, r9
        // displays supporting setAddrWindow() and pushColors()), but haven't
        // implemented this yet.

        startWrite();
        for(yy=0; yy<h; yy++) {
            for(xx=0; xx<w; xx++) {
   d4cf4:	e7c4      	b.n	d4c80 <_ZN12Adafruit_GFX8drawCharEsshtth+0x228>
   d4cf6:	9b07      	ldr	r3, [sp, #28]
   d4cf8:	4498      	add	r8, r3
   d4cfa:	fa5f f888 	uxtb.w	r8, r8
   d4cfe:	3601      	adds	r6, #1
        // this (a canvas object type for MCUs that can afford the RAM and
        // displays supporting setAddrWindow() and pushColors()), but haven't
        // implemented this yet.

        startWrite();
        for(yy=0; yy<h; yy++) {
   d4d00:	e7a8      	b.n	d4c54 <_ZN12Adafruit_GFX8drawCharEsshtth+0x1fc>
                    }
                }
                bits <<= 1;
            }
        }
        endWrite();
   d4d02:	6823      	ldr	r3, [r4, #0]
   d4d04:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   d4d06:	4620      	mov	r0, r4

    } // End classic vs custom font
}
   d4d08:	b011      	add	sp, #68	; 0x44
   d4d0a:	e8bd 4ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
                    }
                }
                bits <<= 1;
            }
        }
        endWrite();
   d4d0e:	4718      	bx	r3

    } // End classic vs custom font
}
   d4d10:	b011      	add	sp, #68	; 0x44
   d4d12:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   d4d16:	bf00      	nop
   d4d18:	000e97f0 	.word	0x000e97f0

000d4d1c <_ZN12Adafruit_GFX5writeEh>:
/*!
    @brief  Print one byte/character of data, used to support print()
    @param  c  The 8-bit ascii character to write
*/
/**************************************************************************/
size_t Adafruit_GFX::write(uint8_t c) {
   d4d1c:	b57f      	push	{r0, r1, r2, r3, r4, r5, r6, lr}
    if(!gfxFont) { // 'Classic' built-in font
   d4d1e:	69c2      	ldr	r2, [r0, #28]
/*!
    @brief  Print one byte/character of data, used to support print()
    @param  c  The 8-bit ascii character to write
*/
/**************************************************************************/
size_t Adafruit_GFX::write(uint8_t c) {
   d4d20:	4604      	mov	r4, r0
   d4d22:	460b      	mov	r3, r1
    if(!gfxFont) { // 'Classic' built-in font
   d4d24:	2a00      	cmp	r2, #0
   d4d26:	d12d      	bne.n	d4d84 <_ZN12Adafruit_GFX5writeEh+0x68>

        if(c == '\n') {                        // Newline?
   d4d28:	290a      	cmp	r1, #10
   d4d2a:	d105      	bne.n	d4d38 <_ZN12Adafruit_GFX5writeEh+0x1c>
            cursor_x  = 0;                     // Reset x to zero,
   d4d2c:	8202      	strh	r2, [r0, #16]
            cursor_y += textsize * 8;          // advance y one line
   d4d2e:	8a43      	ldrh	r3, [r0, #18]
   d4d30:	7e02      	ldrb	r2, [r0, #24]
   d4d32:	eb03 03c2 	add.w	r3, r3, r2, lsl #3
   d4d36:	e02e      	b.n	d4d96 <_ZN12Adafruit_GFX5writeEh+0x7a>
        } else if(c != '\r') {                 // Ignore carriage returns
   d4d38:	290d      	cmp	r1, #13
   d4d3a:	d065      	beq.n	d4e08 <_ZN12Adafruit_GFX5writeEh+0xec>
            if(wrap && ((cursor_x + textsize * 6) > _width)) { // Off right?
   d4d3c:	7e81      	ldrb	r1, [r0, #26]
   d4d3e:	7e00      	ldrb	r0, [r0, #24]
   d4d40:	b169      	cbz	r1, d4d5e <_ZN12Adafruit_GFX5writeEh+0x42>
   d4d42:	f9b4 5010 	ldrsh.w	r5, [r4, #16]
   d4d46:	2106      	movs	r1, #6
   d4d48:	fb11 5100 	smlabb	r1, r1, r0, r5
   d4d4c:	f9b4 500c 	ldrsh.w	r5, [r4, #12]
   d4d50:	42a9      	cmp	r1, r5
                cursor_x  = 0;                 // Reset x to zero,
   d4d52:	bfc1      	itttt	gt
   d4d54:	8222      	strhgt	r2, [r4, #16]
                cursor_y += textsize * 8;      // advance y one line
   d4d56:	8a62      	ldrhgt	r2, [r4, #18]
   d4d58:	eb02 02c0 	addgt.w	r2, r2, r0, lsl #3
   d4d5c:	8262      	strhgt	r2, [r4, #18]
            }
            drawChar(cursor_x, cursor_y, c, textcolor, textbgcolor, textsize);
   d4d5e:	9002      	str	r0, [sp, #8]
   d4d60:	8ae0      	ldrh	r0, [r4, #22]
   d4d62:	9001      	str	r0, [sp, #4]
   d4d64:	8aa0      	ldrh	r0, [r4, #20]
   d4d66:	f9b4 2012 	ldrsh.w	r2, [r4, #18]
   d4d6a:	9000      	str	r0, [sp, #0]
   d4d6c:	f9b4 1010 	ldrsh.w	r1, [r4, #16]
   d4d70:	4620      	mov	r0, r4
   d4d72:	f7ff fe71 	bl	d4a58 <_ZN12Adafruit_GFX8drawCharEsshtth>
            cursor_x += textsize * 6;          // Advance x one char
   d4d76:	7e23      	ldrb	r3, [r4, #24]
   d4d78:	8a22      	ldrh	r2, [r4, #16]
   d4d7a:	eb03 0343 	add.w	r3, r3, r3, lsl #1
   d4d7e:	eb02 0343 	add.w	r3, r2, r3, lsl #1
   d4d82:	e040      	b.n	d4e06 <_ZN12Adafruit_GFX5writeEh+0xea>
        }

    } else { // Custom font

        if(c == '\n') {
   d4d84:	290a      	cmp	r1, #10
   d4d86:	d108      	bne.n	d4d9a <_ZN12Adafruit_GFX5writeEh+0x7e>
            cursor_x  = 0;
   d4d88:	2300      	movs	r3, #0
   d4d8a:	8203      	strh	r3, [r0, #16]
            cursor_y += (int16_t)textsize *
                        (uint8_t)pgm_read_byte(&gfxFont->yAdvance);
   d4d8c:	7e01      	ldrb	r1, [r0, #24]
   d4d8e:	7a92      	ldrb	r2, [r2, #10]
   d4d90:	8a43      	ldrh	r3, [r0, #18]
   d4d92:	fb01 3302 	mla	r3, r1, r2, r3
   d4d96:	8263      	strh	r3, [r4, #18]
   d4d98:	e036      	b.n	d4e08 <_ZN12Adafruit_GFX5writeEh+0xec>
        } else if(c != '\r') {
   d4d9a:	290d      	cmp	r1, #13
   d4d9c:	d034      	beq.n	d4e08 <_ZN12Adafruit_GFX5writeEh+0xec>
            uint8_t first = pgm_read_byte(&gfxFont->first);
   d4d9e:	7a15      	ldrb	r5, [r2, #8]
            if((c >= first) && (c <= (uint8_t)pgm_read_byte(&gfxFont->last))) {
   d4da0:	42a9      	cmp	r1, r5
   d4da2:	d331      	bcc.n	d4e08 <_ZN12Adafruit_GFX5writeEh+0xec>
   d4da4:	7a51      	ldrb	r1, [r2, #9]
   d4da6:	4299      	cmp	r1, r3
   d4da8:	d32e      	bcc.n	d4e08 <_ZN12Adafruit_GFX5writeEh+0xec>
                GFXglyph *glyph = &(((GFXglyph *)pgm_read_pointer(
                  &gfxFont->glyph))[c - first]);
   d4daa:	6851      	ldr	r1, [r2, #4]
   d4dac:	1b5d      	subs	r5, r3, r5
   d4dae:	eb01 05c5 	add.w	r5, r1, r5, lsl #3
                uint8_t   w     = pgm_read_byte(&glyph->width),
   d4db2:	78a9      	ldrb	r1, [r5, #2]
                          h     = pgm_read_byte(&glyph->height);
                if((w > 0) && (h > 0)) { // Is there an associated bitmap?
   d4db4:	b311      	cbz	r1, d4dfc <_ZN12Adafruit_GFX5writeEh+0xe0>
   d4db6:	78e8      	ldrb	r0, [r5, #3]
   d4db8:	b300      	cbz	r0, d4dfc <_ZN12Adafruit_GFX5writeEh+0xe0>
                    int16_t xo = (int8_t)pgm_read_byte(&glyph->xOffset); // sic
                    if(wrap && ((cursor_x + textsize * (xo + w)) > _width)) {
   d4dba:	7ea6      	ldrb	r6, [r4, #26]
   d4dbc:	7e20      	ldrb	r0, [r4, #24]
   d4dbe:	b18e      	cbz	r6, d4de4 <_ZN12Adafruit_GFX5writeEh+0xc8>
   d4dc0:	f995 6005 	ldrsb.w	r6, [r5, #5]
   d4dc4:	4431      	add	r1, r6
   d4dc6:	f9b4 6010 	ldrsh.w	r6, [r4, #16]
   d4dca:	fb00 6101 	mla	r1, r0, r1, r6
   d4dce:	f9b4 600c 	ldrsh.w	r6, [r4, #12]
   d4dd2:	42b1      	cmp	r1, r6
   d4dd4:	dd06      	ble.n	d4de4 <_ZN12Adafruit_GFX5writeEh+0xc8>
                        cursor_x  = 0;
   d4dd6:	2100      	movs	r1, #0
   d4dd8:	8221      	strh	r1, [r4, #16]
                        cursor_y += (int16_t)textsize *
                          (uint8_t)pgm_read_byte(&gfxFont->yAdvance);
   d4dda:	7a92      	ldrb	r2, [r2, #10]
   d4ddc:	8a61      	ldrh	r1, [r4, #18]
   d4dde:	fb02 1200 	mla	r2, r2, r0, r1
   d4de2:	8262      	strh	r2, [r4, #18]
                    }
                    drawChar(cursor_x, cursor_y, c, textcolor, textbgcolor, textsize);
   d4de4:	9002      	str	r0, [sp, #8]
   d4de6:	8ae0      	ldrh	r0, [r4, #22]
   d4de8:	9001      	str	r0, [sp, #4]
   d4dea:	8aa0      	ldrh	r0, [r4, #20]
   d4dec:	9000      	str	r0, [sp, #0]
   d4dee:	f9b4 2012 	ldrsh.w	r2, [r4, #18]
   d4df2:	f9b4 1010 	ldrsh.w	r1, [r4, #16]
   d4df6:	4620      	mov	r0, r4
   d4df8:	f7ff fe2e 	bl	d4a58 <_ZN12Adafruit_GFX8drawCharEsshtth>
                }
                cursor_x += (uint8_t)pgm_read_byte(&glyph->xAdvance) * (int16_t)textsize;
   d4dfc:	7929      	ldrb	r1, [r5, #4]
   d4dfe:	7e22      	ldrb	r2, [r4, #24]
   d4e00:	8a23      	ldrh	r3, [r4, #16]
   d4e02:	fb01 3302 	mla	r3, r1, r2, r3
   d4e06:	8223      	strh	r3, [r4, #16]
            }
        }

    }
    return 1;
}
   d4e08:	2001      	movs	r0, #1
   d4e0a:	b004      	add	sp, #16
   d4e0c:	bd70      	pop	{r4, r5, r6, pc}

000d4e0e <_ZN12Adafruit_GFX9setCursorEss>:
    @param  x    X coordinate in pixels
    @param  y    Y coordinate in pixels
*/
/**************************************************************************/
void Adafruit_GFX::setCursor(int16_t x, int16_t y) {
    cursor_x = x;
   d4e0e:	8201      	strh	r1, [r0, #16]
    cursor_y = y;
   d4e10:	8242      	strh	r2, [r0, #18]
   d4e12:	4770      	bx	lr

000d4e14 <_ZN12Adafruit_GFX11setTextSizeEh>:
    @brief   Set text 'magnification' size. Each increase in s makes 1 pixel that much bigger.
    @param  s  Desired text size. 1 is default 6x8, 2 is 12x16, 3 is 18x24, etc
*/
/**************************************************************************/
void Adafruit_GFX::setTextSize(uint8_t s) {
    textsize = (s > 0) ? s : 1;
   d4e14:	2900      	cmp	r1, #0
   d4e16:	bf08      	it	eq
   d4e18:	2101      	moveq	r1, #1
   d4e1a:	7601      	strb	r1, [r0, #24]
   d4e1c:	4770      	bx	lr

000d4e1e <_ZN12Adafruit_GFX12setTextColorEt>:
*/
/**************************************************************************/
void Adafruit_GFX::setTextColor(uint16_t c) {
    // For 'transparent' background, we'll set the bg
    // to the same as fg instead of using a flag
    textcolor = textbgcolor = c;
   d4e1e:	82c1      	strh	r1, [r0, #22]
   d4e20:	8281      	strh	r1, [r0, #20]
   d4e22:	4770      	bx	lr

000d4e24 <_GLOBAL__sub_I__ZN12Adafruit_GFXC2Ess>:
   d4e24:	f010 b982 	b.w	e512c <HAL_Pin_Map>

000d4e28 <_ZN15Adafruit_SPITFT14writeFastVLineEssst>:
    @param    y   Top-most y coordinate
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void inline Adafruit_SPITFT::writeFastVLine(int16_t x, int16_t y, int16_t h, uint16_t color){
   d4e28:	b537      	push	{r0, r1, r2, r4, r5, lr}
    writeFillRect(x, y, 1, h, color);
   d4e2a:	f8bd 5018 	ldrh.w	r5, [sp, #24]
   d4e2e:	6804      	ldr	r4, [r0, #0]
   d4e30:	e88d 0028 	stmia.w	sp, {r3, r5}
   d4e34:	2301      	movs	r3, #1
   d4e36:	69e4      	ldr	r4, [r4, #28]
   d4e38:	47a0      	blx	r4
}
   d4e3a:	b003      	add	sp, #12
   d4e3c:	bd30      	pop	{r4, r5, pc}

000d4e3e <_ZN15Adafruit_SPITFT14writeFastHLineEssst>:
    @param    y   Left-most y coordinate
    @param    w   Width in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void inline Adafruit_SPITFT::writeFastHLine(int16_t x, int16_t y, int16_t w, uint16_t color){
   d4e3e:	b537      	push	{r0, r1, r2, r4, r5, lr}
    writeFillRect(x, y, w, 1, color);
   d4e40:	f8bd 5018 	ldrh.w	r5, [sp, #24]
   d4e44:	9501      	str	r5, [sp, #4]
   d4e46:	6804      	ldr	r4, [r0, #0]
   d4e48:	2501      	movs	r5, #1
   d4e4a:	9500      	str	r5, [sp, #0]
   d4e4c:	69e4      	ldr	r4, [r4, #28]
   d4e4e:	47a0      	blx	r4
}
   d4e50:	b003      	add	sp, #12
   d4e52:	bd30      	pop	{r4, r5, pc}

000d4e54 <_ZN15Adafruit_SPITFT9drawPixelEsst>:
    @param   x   x coordinate
    @param   y   y coordinate
   @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_SPITFT::drawPixel(int16_t x, int16_t y, uint16_t color){
   d4e54:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   d4e58:	4698      	mov	r8, r3
    startWrite();
   d4e5a:	6803      	ldr	r3, [r0, #0]
    @param   x   x coordinate
    @param   y   y coordinate
   @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_SPITFT::drawPixel(int16_t x, int16_t y, uint16_t color){
   d4e5c:	4604      	mov	r4, r0
    startWrite();
   d4e5e:	695b      	ldr	r3, [r3, #20]
    @param   x   x coordinate
    @param   y   y coordinate
   @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_SPITFT::drawPixel(int16_t x, int16_t y, uint16_t color){
   d4e60:	460e      	mov	r6, r1
   d4e62:	4617      	mov	r7, r2
    startWrite();
   d4e64:	4798      	blx	r3
    writePixel(x, y, color);
   d4e66:	6823      	ldr	r3, [r4, #0]
   d4e68:	4620      	mov	r0, r4
   d4e6a:	699d      	ldr	r5, [r3, #24]
   d4e6c:	463a      	mov	r2, r7
   d4e6e:	4643      	mov	r3, r8
   d4e70:	4631      	mov	r1, r6
   d4e72:	47a8      	blx	r5
    endWrite();
   d4e74:	6823      	ldr	r3, [r4, #0]
   d4e76:	4620      	mov	r0, r4
   d4e78:	6adb      	ldr	r3, [r3, #44]	; 0x2c
}
   d4e7a:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
*/
/**************************************************************************/
void Adafruit_SPITFT::drawPixel(int16_t x, int16_t y, uint16_t color){
    startWrite();
    writePixel(x, y, color);
    endWrite();
   d4e7e:	4718      	bx	r3

000d4e80 <_ZN15Adafruit_SPITFT13drawFastVLineEssst>:
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::drawFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
   d4e80:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
   d4e84:	4698      	mov	r8, r3
    startWrite();
   d4e86:	6803      	ldr	r3, [r0, #0]
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::drawFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
   d4e88:	f8bd 5020 	ldrh.w	r5, [sp, #32]
    startWrite();
   d4e8c:	695b      	ldr	r3, [r3, #20]
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::drawFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
   d4e8e:	4604      	mov	r4, r0
   d4e90:	460e      	mov	r6, r1
   d4e92:	4617      	mov	r7, r2
    startWrite();
   d4e94:	4798      	blx	r3
    writeFastVLine(x, y, h, color);
   d4e96:	6823      	ldr	r3, [r4, #0]
   d4e98:	9500      	str	r5, [sp, #0]
   d4e9a:	6a1d      	ldr	r5, [r3, #32]
   d4e9c:	4620      	mov	r0, r4
   d4e9e:	4643      	mov	r3, r8
   d4ea0:	463a      	mov	r2, r7
   d4ea2:	4631      	mov	r1, r6
   d4ea4:	47a8      	blx	r5
    endWrite();
   d4ea6:	6823      	ldr	r3, [r4, #0]
   d4ea8:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   d4eaa:	4620      	mov	r0, r4
}
   d4eac:	b002      	add	sp, #8
   d4eae:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
/**************************************************************************/
void Adafruit_SPITFT::drawFastVLine(int16_t x, int16_t y,
        int16_t h, uint16_t color) {
    startWrite();
    writeFastVLine(x, y, h, color);
    endWrite();
   d4eb2:	4718      	bx	r3

000d4eb4 <_ZN15Adafruit_SPITFT13drawFastHLineEssst>:
    @param    w   Width in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::drawFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
   d4eb4:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
   d4eb8:	4698      	mov	r8, r3
    startWrite();
   d4eba:	6803      	ldr	r3, [r0, #0]
    @param    w   Width in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::drawFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
   d4ebc:	f8bd 5020 	ldrh.w	r5, [sp, #32]
    startWrite();
   d4ec0:	695b      	ldr	r3, [r3, #20]
    @param    w   Width in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::drawFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
   d4ec2:	4604      	mov	r4, r0
   d4ec4:	460e      	mov	r6, r1
   d4ec6:	4617      	mov	r7, r2
    startWrite();
   d4ec8:	4798      	blx	r3
    writeFastHLine(x, y, w, color);
   d4eca:	6823      	ldr	r3, [r4, #0]
   d4ecc:	9500      	str	r5, [sp, #0]
   d4ece:	6a5d      	ldr	r5, [r3, #36]	; 0x24
   d4ed0:	4620      	mov	r0, r4
   d4ed2:	4643      	mov	r3, r8
   d4ed4:	463a      	mov	r2, r7
   d4ed6:	4631      	mov	r1, r6
   d4ed8:	47a8      	blx	r5
    endWrite();
   d4eda:	6823      	ldr	r3, [r4, #0]
   d4edc:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   d4ede:	4620      	mov	r0, r4
}
   d4ee0:	b002      	add	sp, #8
   d4ee2:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
/**************************************************************************/
void Adafruit_SPITFT::drawFastHLine(int16_t x, int16_t y,
        int16_t w, uint16_t color) {
    startWrite();
    writeFastHLine(x, y, w, color);
    endWrite();
   d4ee6:	4718      	bx	r3

000d4ee8 <_ZN15Adafruit_SPITFT8fillRectEsssst>:
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::fillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d4ee8:	e92d 43f7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, lr}
   d4eec:	4698      	mov	r8, r3
    startWrite();
   d4eee:	6803      	ldr	r3, [r0, #0]
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::fillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d4ef0:	f9bd 5028 	ldrsh.w	r5, [sp, #40]	; 0x28
   d4ef4:	f8bd 902c 	ldrh.w	r9, [sp, #44]	; 0x2c
    startWrite();
   d4ef8:	695b      	ldr	r3, [r3, #20]
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::fillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
   d4efa:	4604      	mov	r4, r0
   d4efc:	460e      	mov	r6, r1
   d4efe:	4617      	mov	r7, r2
    startWrite();
   d4f00:	4798      	blx	r3
    writeFillRect(x,y,w,h,color);
   d4f02:	e88d 0220 	stmia.w	sp, {r5, r9}
   d4f06:	6823      	ldr	r3, [r4, #0]
   d4f08:	4620      	mov	r0, r4
   d4f0a:	69dd      	ldr	r5, [r3, #28]
   d4f0c:	463a      	mov	r2, r7
   d4f0e:	4643      	mov	r3, r8
   d4f10:	4631      	mov	r1, r6
   d4f12:	47a8      	blx	r5
    endWrite();
   d4f14:	6823      	ldr	r3, [r4, #0]
   d4f16:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   d4f18:	4620      	mov	r0, r4
}
   d4f1a:	b003      	add	sp, #12
   d4f1c:	e8bd 43f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, lr}
/**************************************************************************/
void Adafruit_SPITFT::fillRect(int16_t x, int16_t y, int16_t w, int16_t h,
        uint16_t color) {
    startWrite();
    writeFillRect(x,y,w,h,color);
    endWrite();
   d4f20:	4718      	bx	r3

000d4f22 <_ZN15Adafruit_SPITFT8endWriteEv>:
/*!
    @brief   Begin an SPI transaction & set CS high.
*/
/**************************************************************************/
void inline Adafruit_SPITFT::endWrite(void){
    SPI_CS_HIGH();
   d4f22:	6a80      	ldr	r0, [r0, #40]	; 0x28
   d4f24:	2800      	cmp	r0, #0
   d4f26:	db03      	blt.n	d4f30 <_ZN15Adafruit_SPITFT8endWriteEv+0xe>
   d4f28:	2101      	movs	r1, #1
   d4f2a:	b280      	uxth	r0, r0
   d4f2c:	f011 b8bb 	b.w	e60a6 <digitalWrite>
   d4f30:	4770      	bx	lr

000d4f32 <_ZN15Adafruit_SPITFT10startWriteEv>:
/**************************************************************************/
/*!
    @brief   Begin an SPI transaction & set CS low.
*/
/**************************************************************************/
void inline Adafruit_SPITFT::startWrite(void){
   d4f32:	b510      	push	{r4, lr}
    SPI_BEGIN_TRANSACTION();
   d4f34:	6b43      	ldr	r3, [r0, #52]	; 0x34
   d4f36:	2b00      	cmp	r3, #0
/**************************************************************************/
/*!
    @brief   Begin an SPI transaction & set CS low.
*/
/**************************************************************************/
void inline Adafruit_SPITFT::startWrite(void){
   d4f38:	4604      	mov	r4, r0
    SPI_BEGIN_TRANSACTION();
   d4f3a:	da0b      	bge.n	d4f54 <_ZN15Adafruit_SPITFT10startWriteEv+0x22>
   d4f3c:	210b      	movs	r1, #11
   d4f3e:	6a00      	ldr	r0, [r0, #32]
   d4f40:	f010 fecc 	bl	e5cdc <_ZN8SPIClass15setClockDividerEh>
   d4f44:	2101      	movs	r1, #1
   d4f46:	6a20      	ldr	r0, [r4, #32]
   d4f48:	f010 fe7b 	bl	e5c42 <_ZN8SPIClass11setBitOrderEh>
   d4f4c:	2100      	movs	r1, #0
   d4f4e:	6a20      	ldr	r0, [r4, #32]
   d4f50:	f010 fe7a 	bl	e5c48 <_ZN8SPIClass11setDataModeEh>
    SPI_CS_LOW();
   d4f54:	6aa0      	ldr	r0, [r4, #40]	; 0x28
   d4f56:	2800      	cmp	r0, #0
   d4f58:	db05      	blt.n	d4f66 <_ZN15Adafruit_SPITFT10startWriteEv+0x34>
   d4f5a:	2100      	movs	r1, #0
   d4f5c:	b280      	uxth	r0, r0
}
   d4f5e:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
    @brief   Begin an SPI transaction & set CS low.
*/
/**************************************************************************/
void inline Adafruit_SPITFT::startWrite(void){
    SPI_BEGIN_TRANSACTION();
    SPI_CS_LOW();
   d4f62:	f011 b8a0 	b.w	e60a6 <digitalWrite>
   d4f66:	bd10      	pop	{r4, pc}

000d4f68 <_ZN15Adafruit_SPITFTC1EttP8SPIClassaaa>:
    @param    cs    Chip select pin #
    @param    dc    Data/Command pin #
    @param    rst   Reset pin # (optional, pass -1 if unused)
*/
/**************************************************************************/
Adafruit_SPITFT::Adafruit_SPITFT(uint16_t w, uint16_t h, SPIClass *spiClass,
   d4f68:	b538      	push	{r3, r4, r5, lr}
				 int8_t cs, int8_t dc, int8_t rst) 
  : Adafruit_GFX(w, h) {
   d4f6a:	b212      	sxth	r2, r2
    @param    cs    Chip select pin #
    @param    dc    Data/Command pin #
    @param    rst   Reset pin # (optional, pass -1 if unused)
*/
/**************************************************************************/
Adafruit_SPITFT::Adafruit_SPITFT(uint16_t w, uint16_t h, SPIClass *spiClass,
   d4f6c:	4604      	mov	r4, r0
				 int8_t cs, int8_t dc, int8_t rst) 
  : Adafruit_GFX(w, h) {
   d4f6e:	b209      	sxth	r1, r1
    @param    cs    Chip select pin #
    @param    dc    Data/Command pin #
    @param    rst   Reset pin # (optional, pass -1 if unused)
*/
/**************************************************************************/
Adafruit_SPITFT::Adafruit_SPITFT(uint16_t w, uint16_t h, SPIClass *spiClass,
   d4f70:	461d      	mov	r5, r3
				 int8_t cs, int8_t dc, int8_t rst) 
  : Adafruit_GFX(w, h) {
   d4f72:	f7ff fc8f 	bl	d4894 <_ZN12Adafruit_GFXC1Ess>
   d4f76:	4b0e      	ldr	r3, [pc, #56]	; (d4fb0 <_ZN15Adafruit_SPITFTC1EttP8SPIClassaaa+0x48>)
   d4f78:	6023      	str	r3, [r4, #0]
    _cs   = cs;
   d4f7a:	f99d 3010 	ldrsb.w	r3, [sp, #16]
   d4f7e:	62a3      	str	r3, [r4, #40]	; 0x28
    _dc   = dc;
   d4f80:	f99d 3014 	ldrsb.w	r3, [sp, #20]
   d4f84:	62e3      	str	r3, [r4, #44]	; 0x2c
    _rst  = rst;
   d4f86:	f99d 3018 	ldrsb.w	r3, [sp, #24]
   d4f8a:	6323      	str	r3, [r4, #48]	; 0x30
    @param    rst   Reset pin # (optional, pass -1 if unused)
*/
/**************************************************************************/
Adafruit_SPITFT::Adafruit_SPITFT(uint16_t w, uint16_t h, SPIClass *spiClass,
				 int8_t cs, int8_t dc, int8_t rst) 
  : Adafruit_GFX(w, h) {
   d4f8c:	2200      	movs	r2, #0
    _cs   = cs;
    _dc   = dc;
    _rst  = rst;
    _spi = spiClass;
    _sclk = -1;
   d4f8e:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    @param    rst   Reset pin # (optional, pass -1 if unused)
*/
/**************************************************************************/
Adafruit_SPITFT::Adafruit_SPITFT(uint16_t w, uint16_t h, SPIClass *spiClass,
				 int8_t cs, int8_t dc, int8_t rst) 
  : Adafruit_GFX(w, h) {
   d4f92:	f884 2040 	strb.w	r2, [r4, #64]	; 0x40
   d4f96:	f884 2041 	strb.w	r2, [r4, #65]	; 0x41
   d4f9a:	f8a4 2042 	strh.w	r2, [r4, #66]	; 0x42
   d4f9e:	f8a4 2044 	strh.w	r2, [r4, #68]	; 0x44
    _cs   = cs;
    _dc   = dc;
    _rst  = rst;
    _spi = spiClass;
   d4fa2:	6225      	str	r5, [r4, #32]
    _sclk = -1;
   d4fa4:	6363      	str	r3, [r4, #52]	; 0x34
    _mosi = -1;
   d4fa6:	63a3      	str	r3, [r4, #56]	; 0x38
    _miso = -1;
   d4fa8:	63e3      	str	r3, [r4, #60]	; 0x3c
    _freq = 0;
   d4faa:	6262      	str	r2, [r4, #36]	; 0x24
        // See notes in prior constructor.
        csport    = dcport;
        cspinmask = 0;
    }
#endif
}
   d4fac:	4620      	mov	r0, r4
   d4fae:	bd38      	pop	{r3, r4, r5, pc}
   d4fb0:	000e9cf8 	.word	0x000e9cf8

000d4fb4 <_ZN15Adafruit_SPITFT7initSPIEm>:
/*!
    @brief   Initialiaze the SPI interface (hardware or software)
    @param    freq  The desired maximum SPI hardware clock frequency
*/
/**************************************************************************/
void Adafruit_SPITFT::initSPI(uint32_t freq) {
   d4fb4:	b510      	push	{r4, lr}
   d4fb6:	4604      	mov	r4, r0
    _freq = freq;
   d4fb8:	6241      	str	r1, [r0, #36]	; 0x24

    // Control Pins
    if(_cs >= 0) {
   d4fba:	6a80      	ldr	r0, [r0, #40]	; 0x28
   d4fbc:	2800      	cmp	r0, #0
   d4fbe:	db07      	blt.n	d4fd0 <_ZN15Adafruit_SPITFT7initSPIEm+0x1c>
        pinMode(_cs, OUTPUT);
   d4fc0:	2101      	movs	r1, #1
   d4fc2:	b280      	uxth	r0, r0
   d4fc4:	f011 f85e 	bl	e6084 <pinMode>
        digitalWrite(_cs, HIGH); // Deselect
   d4fc8:	2101      	movs	r1, #1
   d4fca:	8d20      	ldrh	r0, [r4, #40]	; 0x28
   d4fcc:	f011 f86b 	bl	e60a6 <digitalWrite>
    }
    pinMode(_dc, OUTPUT);
   d4fd0:	2101      	movs	r1, #1
   d4fd2:	8da0      	ldrh	r0, [r4, #44]	; 0x2c
   d4fd4:	f011 f856 	bl	e6084 <pinMode>
    digitalWrite(_dc, LOW);
   d4fd8:	2100      	movs	r1, #0
   d4fda:	8da0      	ldrh	r0, [r4, #44]	; 0x2c
   d4fdc:	f011 f863 	bl	e60a6 <digitalWrite>

    // Software SPI
    if(_sclk >= 0){
   d4fe0:	6b63      	ldr	r3, [r4, #52]	; 0x34
   d4fe2:	2b00      	cmp	r3, #0
   d4fe4:	db19      	blt.n	d501a <_ZN15Adafruit_SPITFT7initSPIEm+0x66>
        pinMode(_mosi, OUTPUT);
   d4fe6:	2101      	movs	r1, #1
   d4fe8:	8f20      	ldrh	r0, [r4, #56]	; 0x38
   d4fea:	f011 f84b 	bl	e6084 <pinMode>
        digitalWrite(_mosi, LOW);
   d4fee:	2100      	movs	r1, #0
   d4ff0:	8f20      	ldrh	r0, [r4, #56]	; 0x38
   d4ff2:	f011 f858 	bl	e60a6 <digitalWrite>
        pinMode(_sclk, OUTPUT);
   d4ff6:	2101      	movs	r1, #1
   d4ff8:	8ea0      	ldrh	r0, [r4, #52]	; 0x34
   d4ffa:	f011 f843 	bl	e6084 <pinMode>
        digitalWrite(_sclk, HIGH);
   d4ffe:	8ea0      	ldrh	r0, [r4, #52]	; 0x34
   d5000:	2101      	movs	r1, #1
   d5002:	f011 f850 	bl	e60a6 <digitalWrite>
        if(_miso >= 0){
   d5006:	6be0      	ldr	r0, [r4, #60]	; 0x3c
   d5008:	2800      	cmp	r0, #0
   d500a:	db03      	blt.n	d5014 <_ZN15Adafruit_SPITFT7initSPIEm+0x60>
            pinMode(_miso, INPUT);
   d500c:	2100      	movs	r1, #0
   d500e:	b280      	uxth	r0, r0
   d5010:	f011 f838 	bl	e6084 <pinMode>
        }
    }

    // Hardware SPI
    SPI_BEGIN();
   d5014:	6b63      	ldr	r3, [r4, #52]	; 0x34
   d5016:	2b00      	cmp	r3, #0
   d5018:	da02      	bge.n	d5020 <_ZN15Adafruit_SPITFT7initSPIEm+0x6c>
   d501a:	6a20      	ldr	r0, [r4, #32]
   d501c:	f010 fe0c 	bl	e5c38 <_ZN8SPIClass5beginEv>

    // toggle RST low to reset
    if (_rst >= 0) {
   d5020:	6b20      	ldr	r0, [r4, #48]	; 0x30
   d5022:	2800      	cmp	r0, #0
   d5024:	db1a      	blt.n	d505c <_ZN15Adafruit_SPITFT7initSPIEm+0xa8>
        pinMode(_rst, OUTPUT);
   d5026:	2101      	movs	r1, #1
   d5028:	b280      	uxth	r0, r0
   d502a:	f011 f82b 	bl	e6084 <pinMode>
        digitalWrite(_rst, HIGH);
   d502e:	2101      	movs	r1, #1
   d5030:	8e20      	ldrh	r0, [r4, #48]	; 0x30
   d5032:	f011 f838 	bl	e60a6 <digitalWrite>
        delay(100);
   d5036:	2064      	movs	r0, #100	; 0x64
   d5038:	f010 fabd 	bl	e55b6 <delay>
        digitalWrite(_rst, LOW);
   d503c:	2100      	movs	r1, #0
   d503e:	8e20      	ldrh	r0, [r4, #48]	; 0x30
   d5040:	f011 f831 	bl	e60a6 <digitalWrite>
        delay(100);
   d5044:	2064      	movs	r0, #100	; 0x64
   d5046:	f010 fab6 	bl	e55b6 <delay>
        digitalWrite(_rst, HIGH);
   d504a:	8e20      	ldrh	r0, [r4, #48]	; 0x30
   d504c:	2101      	movs	r1, #1
   d504e:	f011 f82a 	bl	e60a6 <digitalWrite>
        delay(200);
   d5052:	20c8      	movs	r0, #200	; 0xc8
    }
}
   d5054:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
        digitalWrite(_rst, HIGH);
        delay(100);
        digitalWrite(_rst, LOW);
        delay(100);
        digitalWrite(_rst, HIGH);
        delay(200);
   d5058:	f010 baad 	b.w	e55b6 <delay>
   d505c:	bd10      	pop	{r4, pc}

000d505e <_ZN15Adafruit_SPITFT8spiWriteEh>:
/*!
    @brief   Write one byte to SPI interface (hardware or software)
    @param  b  One byte to send, MSB order
*/
/**************************************************************************/
void Adafruit_SPITFT::spiWrite(uint8_t b) {
   d505e:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    if(_sclk < 0){
   d5060:	6b43      	ldr	r3, [r0, #52]	; 0x34
   d5062:	2b00      	cmp	r3, #0
/*!
    @brief   Write one byte to SPI interface (hardware or software)
    @param  b  One byte to send, MSB order
*/
/**************************************************************************/
void Adafruit_SPITFT::spiWrite(uint8_t b) {
   d5064:	4604      	mov	r4, r0
   d5066:	460f      	mov	r7, r1
    if(_sclk < 0){
   d5068:	da04      	bge.n	d5074 <_ZN15Adafruit_SPITFT8spiWriteEh+0x16>
        HSPI_WRITE(b);
   d506a:	6a00      	ldr	r0, [r0, #32]
            SSPI_MOSI_LOW();
        }
        SSPI_SCK_LOW();
        SSPI_SCK_HIGH();
    }
}
   d506c:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    @param  b  One byte to send, MSB order
*/
/**************************************************************************/
void Adafruit_SPITFT::spiWrite(uint8_t b) {
    if(_sclk < 0){
        HSPI_WRITE(b);
   d5070:	f010 be48 	b.w	e5d04 <_ZN8SPIClass8transferEh>
   d5074:	2608      	movs	r6, #8
   d5076:	2580      	movs	r5, #128	; 0x80
   d5078:	6ba0      	ldr	r0, [r4, #56]	; 0x38
        return;
    }
    for(uint8_t bit = 0x80; bit; bit >>= 1){
        if((b) & bit){
   d507a:	ea17 0105 	ands.w	r1, r7, r5
            SSPI_MOSI_HIGH();
   d507e:	bf18      	it	ne
   d5080:	2101      	movne	r1, #1
        } else {
            SSPI_MOSI_LOW();
   d5082:	b280      	uxth	r0, r0
   d5084:	f011 f80f 	bl	e60a6 <digitalWrite>
        }
        SSPI_SCK_LOW();
   d5088:	2100      	movs	r1, #0
   d508a:	8ea0      	ldrh	r0, [r4, #52]	; 0x34
   d508c:	f011 f80b 	bl	e60a6 <digitalWrite>
        SSPI_SCK_HIGH();
   d5090:	2101      	movs	r1, #1
   d5092:	8ea0      	ldrh	r0, [r4, #52]	; 0x34
   d5094:	f011 f807 	bl	e60a6 <digitalWrite>
void Adafruit_SPITFT::spiWrite(uint8_t b) {
    if(_sclk < 0){
        HSPI_WRITE(b);
        return;
    }
    for(uint8_t bit = 0x80; bit; bit >>= 1){
   d5098:	3e01      	subs	r6, #1
   d509a:	ea4f 0555 	mov.w	r5, r5, lsr #1
   d509e:	d1eb      	bne.n	d5078 <_ZN15Adafruit_SPITFT8spiWriteEh+0x1a>
            SSPI_MOSI_LOW();
        }
        SSPI_SCK_LOW();
        SSPI_SCK_HIGH();
    }
}
   d50a0:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

000d50a2 <_ZN15Adafruit_SPITFT10writePixelEsst>:
    @param   x   x coordinate
    @param   y   y coordinate
   @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_SPITFT::writePixel(int16_t x, int16_t y, uint16_t color) {
   d50a2:	b573      	push	{r0, r1, r4, r5, r6, lr}
    if((x < 0) ||(x >= _width) || (y < 0) || (y >= _height)) return;
   d50a4:	2900      	cmp	r1, #0
    @param   x   x coordinate
    @param   y   y coordinate
   @param    color 16-bit 5-6-5 Color to draw with
*/
/**************************************************************************/
void Adafruit_SPITFT::writePixel(int16_t x, int16_t y, uint16_t color) {
   d50a6:	4604      	mov	r4, r0
   d50a8:	461d      	mov	r5, r3
    if((x < 0) ||(x >= _width) || (y < 0) || (y >= _height)) return;
   d50aa:	db2a      	blt.n	d5102 <_ZN15Adafruit_SPITFT10writePixelEsst+0x60>
   d50ac:	f9b0 300c 	ldrsh.w	r3, [r0, #12]
   d50b0:	428b      	cmp	r3, r1
   d50b2:	dd26      	ble.n	d5102 <_ZN15Adafruit_SPITFT10writePixelEsst+0x60>
   d50b4:	2a00      	cmp	r2, #0
   d50b6:	db24      	blt.n	d5102 <_ZN15Adafruit_SPITFT10writePixelEsst+0x60>
   d50b8:	f9b0 300e 	ldrsh.w	r3, [r0, #14]
   d50bc:	4293      	cmp	r3, r2
   d50be:	dd20      	ble.n	d5102 <_ZN15Adafruit_SPITFT10writePixelEsst+0x60>
    setAddrWindow(x,y,1,1);
   d50c0:	6806      	ldr	r6, [r0, #0]
   d50c2:	2301      	movs	r3, #1
   d50c4:	9300      	str	r3, [sp, #0]
   d50c6:	b289      	uxth	r1, r1
   d50c8:	6d76      	ldr	r6, [r6, #84]	; 0x54
   d50ca:	b292      	uxth	r2, r2
   d50cc:	47b0      	blx	r6

	/*!
	  @brief   Write a 2-byte color  (must have a transaction in progress)
	  @param    color 16-bit 5-6-5 Color to draw
	*/
	void      inline writePixel(uint16_t color) { SPI_WRITE16(color); }
   d50ce:	6b63      	ldr	r3, [r4, #52]	; 0x34
   d50d0:	2b00      	cmp	r3, #0
   d50d2:	ea4f 2125 	mov.w	r1, r5, asr #8
   d50d6:	b2ed      	uxtb	r5, r5
   d50d8:	da09      	bge.n	d50ee <_ZN15Adafruit_SPITFT10writePixelEsst+0x4c>
   d50da:	6a20      	ldr	r0, [r4, #32]
   d50dc:	f010 fe12 	bl	e5d04 <_ZN8SPIClass8transferEh>
   d50e0:	6a20      	ldr	r0, [r4, #32]
   d50e2:	4629      	mov	r1, r5
    writePixel(color);
}
   d50e4:	b002      	add	sp, #8
   d50e6:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
   d50ea:	f010 be0b 	b.w	e5d04 <_ZN8SPIClass8transferEh>
   d50ee:	4620      	mov	r0, r4
   d50f0:	f7ff ffb5 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
   d50f4:	4629      	mov	r1, r5
   d50f6:	4620      	mov	r0, r4
   d50f8:	b002      	add	sp, #8
   d50fa:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
   d50fe:	f7ff bfae 	b.w	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
   d5102:	b002      	add	sp, #8
   d5104:	bd70      	pop	{r4, r5, r6, pc}

000d5106 <_ZN15Adafruit_SPITFT12writeCommandEh>:
/*!
    @brief   Write a command byte (must have a transaction in progress)
    @param   cmd  The 8-bit command to send
*/
/**************************************************************************/
void Adafruit_SPITFT::writeCommand(uint8_t cmd){
   d5106:	b538      	push	{r3, r4, r5, lr}
   d5108:	4604      	mov	r4, r0
   d510a:	460d      	mov	r5, r1
    SPI_DC_LOW();
   d510c:	8d80      	ldrh	r0, [r0, #44]	; 0x2c
   d510e:	2100      	movs	r1, #0
   d5110:	f010 ffc9 	bl	e60a6 <digitalWrite>
    spiWrite(cmd);
   d5114:	4629      	mov	r1, r5
   d5116:	4620      	mov	r0, r4
   d5118:	f7ff ffa1 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
    SPI_DC_HIGH();
   d511c:	8da0      	ldrh	r0, [r4, #44]	; 0x2c
   d511e:	2101      	movs	r1, #1
}
   d5120:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
*/
/**************************************************************************/
void Adafruit_SPITFT::writeCommand(uint8_t cmd){
    SPI_DC_LOW();
    spiWrite(cmd);
    SPI_DC_HIGH();
   d5124:	f010 bfbf 	b.w	e60a6 <digitalWrite>

000d5128 <_ZN15Adafruit_SPITFT13invertDisplayEb>:
/*!
    @brief      Invert the display using built-in hardware command
    @param   i  True if you want to invert, false to make 'normal'
*/
/**************************************************************************/
void Adafruit_SPITFT::invertDisplay(boolean i) {
   d5128:	b570      	push	{r4, r5, r6, lr}
  startWrite();
   d512a:	6803      	ldr	r3, [r0, #0]
/*!
    @brief      Invert the display using built-in hardware command
    @param   i  True if you want to invert, false to make 'normal'
*/
/**************************************************************************/
void Adafruit_SPITFT::invertDisplay(boolean i) {
   d512c:	460d      	mov	r5, r1
  startWrite();
   d512e:	695b      	ldr	r3, [r3, #20]
/*!
    @brief      Invert the display using built-in hardware command
    @param   i  True if you want to invert, false to make 'normal'
*/
/**************************************************************************/
void Adafruit_SPITFT::invertDisplay(boolean i) {
   d5130:	4604      	mov	r4, r0
  startWrite();
   d5132:	4798      	blx	r3
  writeCommand(i ? invertOnCommand : invertOffCommand);
   d5134:	b115      	cbz	r5, d513c <_ZN15Adafruit_SPITFT13invertDisplayEb+0x14>
   d5136:	f894 1040 	ldrb.w	r1, [r4, #64]	; 0x40
   d513a:	e001      	b.n	d5140 <_ZN15Adafruit_SPITFT13invertDisplayEb+0x18>
   d513c:	f894 1041 	ldrb.w	r1, [r4, #65]	; 0x41
   d5140:	4620      	mov	r0, r4
   d5142:	f7ff ffe0 	bl	d5106 <_ZN15Adafruit_SPITFT12writeCommandEh>
  endWrite();
   d5146:	6823      	ldr	r3, [r4, #0]
   d5148:	4620      	mov	r0, r4
   d514a:	6adb      	ldr	r3, [r3, #44]	; 0x2c
}
   d514c:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
*/
/**************************************************************************/
void Adafruit_SPITFT::invertDisplay(boolean i) {
  startWrite();
  writeCommand(i ? invertOnCommand : invertOffCommand);
  endWrite();
   d5150:	4718      	bx	r3

000d5152 <_ZN15Adafruit_SPITFT10writeColorEtm>:
    @brief   Blit a 2-byte color many times  (must have a transaction in progress)
    @param    color  The 16-bit 5-6-5 Color to draw
    @param    len    How many pixels to draw
*/
/**************************************************************************/
void Adafruit_SPITFT::writeColor(uint16_t color, uint32_t len){
   d5152:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
        writePixels(temp, tlen);
        len -= tlen;
    }
#else
    uint8_t hi = color >> 8, lo = color;
    if(_sclk < 0){ //AVR Optimization
   d5154:	6b43      	ldr	r3, [r0, #52]	; 0x34
   d5156:	2b00      	cmp	r3, #0
    @brief   Blit a 2-byte color many times  (must have a transaction in progress)
    @param    color  The 16-bit 5-6-5 Color to draw
    @param    len    How many pixels to draw
*/
/**************************************************************************/
void Adafruit_SPITFT::writeColor(uint16_t color, uint32_t len){
   d5158:	4605      	mov	r5, r0
   d515a:	4614      	mov	r4, r2
        tlen = (len>blen)?blen:len;
        writePixels(temp, tlen);
        len -= tlen;
    }
#else
    uint8_t hi = color >> 8, lo = color;
   d515c:	ea4f 2711 	mov.w	r7, r1, lsr #8
   d5160:	b2ce      	uxtb	r6, r1
    if(_sclk < 0){ //AVR Optimization
   d5162:	da0a      	bge.n	d517a <_ZN15Adafruit_SPITFT10writeColorEtm+0x28>
        for (uint32_t t=len; t; t--){
   d5164:	b1a4      	cbz	r4, d5190 <_ZN15Adafruit_SPITFT10writeColorEtm+0x3e>
            HSPI_WRITE(hi);
   d5166:	4639      	mov	r1, r7
   d5168:	6a28      	ldr	r0, [r5, #32]
   d516a:	f010 fdcb 	bl	e5d04 <_ZN8SPIClass8transferEh>
            HSPI_WRITE(lo);
   d516e:	4631      	mov	r1, r6
   d5170:	6a28      	ldr	r0, [r5, #32]
   d5172:	f010 fdc7 	bl	e5d04 <_ZN8SPIClass8transferEh>
        len -= tlen;
    }
#else
    uint8_t hi = color >> 8, lo = color;
    if(_sclk < 0){ //AVR Optimization
        for (uint32_t t=len; t; t--){
   d5176:	3c01      	subs	r4, #1
   d5178:	e7f4      	b.n	d5164 <_ZN15Adafruit_SPITFT10writeColorEtm+0x12>
            HSPI_WRITE(hi);
            HSPI_WRITE(lo);
        }
        return;
    }
    for (uint32_t t=len; t; t--){
   d517a:	b14c      	cbz	r4, d5190 <_ZN15Adafruit_SPITFT10writeColorEtm+0x3e>
        spiWrite(hi);
   d517c:	4639      	mov	r1, r7
   d517e:	4628      	mov	r0, r5
   d5180:	f7ff ff6d 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
        spiWrite(lo);
   d5184:	4631      	mov	r1, r6
   d5186:	4628      	mov	r0, r5
   d5188:	f7ff ff69 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
            HSPI_WRITE(hi);
            HSPI_WRITE(lo);
        }
        return;
    }
    for (uint32_t t=len; t; t--){
   d518c:	3c01      	subs	r4, #1
   d518e:	e7f4      	b.n	d517a <_ZN15Adafruit_SPITFT10writeColorEtm+0x28>
   d5190:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

000d5192 <_ZN15Adafruit_SPITFT13writeFillRectEsssst>:
    @param    w   Width in pixels
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::writeFillRect(int16_t x, int16_t y, int16_t w, int16_t h, uint16_t color){
   d5192:	e92d 43f7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, lr}
   d5196:	4604      	mov	r4, r0
   d5198:	f8bd 502c 	ldrh.w	r5, [sp, #44]	; 0x2c
    if((x >= _width) || (y >= _height)) return;
   d519c:	f9b4 700c 	ldrsh.w	r7, [r4, #12]
    @param    w   Width in pixels
    @param    h   Height in pixels
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::writeFillRect(int16_t x, int16_t y, int16_t w, int16_t h, uint16_t color){
   d51a0:	f9bd 0028 	ldrsh.w	r0, [sp, #40]	; 0x28
    if((x >= _width) || (y >= _height)) return;
   d51a4:	428f      	cmp	r7, r1
   d51a6:	dd3e      	ble.n	d5226 <_ZN15Adafruit_SPITFT13writeFillRectEsssst+0x94>
   d51a8:	f9b4 600e 	ldrsh.w	r6, [r4, #14]
   d51ac:	4296      	cmp	r6, r2
   d51ae:	dd3a      	ble.n	d5226 <_ZN15Adafruit_SPITFT13writeFillRectEsssst+0x94>
    int16_t x2 = x + w - 1, y2 = y + h - 1;
   d51b0:	eb01 0903 	add.w	r9, r1, r3
   d51b4:	fa1f f989 	uxth.w	r9, r9
   d51b8:	f109 3cff 	add.w	ip, r9, #4294967295	; 0xffffffff
   d51bc:	eb02 0800 	add.w	r8, r2, r0
   d51c0:	fa0f fc8c 	sxth.w	ip, ip
   d51c4:	fa1f f888 	uxth.w	r8, r8
   d51c8:	f108 3eff 	add.w	lr, r8, #4294967295	; 0xffffffff
    if((x2 < 0) || (y2 < 0)) return;
   d51cc:	f1bc 0f00 	cmp.w	ip, #0
   @param    color 16-bit 5-6-5 Color to fill with
*/
/**************************************************************************/
void Adafruit_SPITFT::writeFillRect(int16_t x, int16_t y, int16_t w, int16_t h, uint16_t color){
    if((x >= _width) || (y >= _height)) return;
    int16_t x2 = x + w - 1, y2 = y + h - 1;
   d51d0:	fa0f fe8e 	sxth.w	lr, lr
    if((x2 < 0) || (y2 < 0)) return;
   d51d4:	db27      	blt.n	d5226 <_ZN15Adafruit_SPITFT13writeFillRectEsssst+0x94>
   d51d6:	f1be 0f00 	cmp.w	lr, #0
   d51da:	db24      	blt.n	d5226 <_ZN15Adafruit_SPITFT13writeFillRectEsssst+0x94>

    // Clip left/top
    if(x < 0) {
   d51dc:	2900      	cmp	r1, #0
        x = 0;
        w = x2 + 1;
   d51de:	bfbc      	itt	lt
   d51e0:	fa0f f389 	sxthlt.w	r3, r9
    int16_t x2 = x + w - 1, y2 = y + h - 1;
    if((x2 < 0) || (y2 < 0)) return;

    // Clip left/top
    if(x < 0) {
        x = 0;
   d51e4:	2100      	movlt	r1, #0
        w = x2 + 1;
    }
    if(y < 0) {
   d51e6:	2a00      	cmp	r2, #0
        y = 0;
        h = y2 + 1;
   d51e8:	bfbc      	itt	lt
   d51ea:	fa0f f088 	sxthlt.w	r0, r8
    if(x < 0) {
        x = 0;
        w = x2 + 1;
    }
    if(y < 0) {
        y = 0;
   d51ee:	2200      	movlt	r2, #0
        h = y2 + 1;
    }

    // Clip right/bottom
    if(x2 >= _width)  w = _width  - x;
   d51f0:	4567      	cmp	r7, ip
   d51f2:	bfdc      	itt	le
   d51f4:	1a7b      	suble	r3, r7, r1
   d51f6:	b21b      	sxthle	r3, r3
    if(y2 >= _height) h = _height - y;
   d51f8:	4576      	cmp	r6, lr
   d51fa:	bfdc      	itt	le
   d51fc:	1ab0      	suble	r0, r6, r2
   d51fe:	b200      	sxthle	r0, r0

    int32_t len = (int32_t)w * h;
   d5200:	fb03 f600 	mul.w	r6, r3, r0
    setAddrWindow(x, y, w, h);
   d5204:	6827      	ldr	r7, [r4, #0]
   d5206:	b280      	uxth	r0, r0
   d5208:	9000      	str	r0, [sp, #0]
   d520a:	6d7f      	ldr	r7, [r7, #84]	; 0x54
   d520c:	4620      	mov	r0, r4
   d520e:	b29b      	uxth	r3, r3
   d5210:	b292      	uxth	r2, r2
   d5212:	b289      	uxth	r1, r1
   d5214:	47b8      	blx	r7
    writeColor(color, len);
   d5216:	4632      	mov	r2, r6
   d5218:	4629      	mov	r1, r5
   d521a:	4620      	mov	r0, r4
}
   d521c:	b003      	add	sp, #12
   d521e:	e8bd 43f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, lr}
    if(x2 >= _width)  w = _width  - x;
    if(y2 >= _height) h = _height - y;

    int32_t len = (int32_t)w * h;
    setAddrWindow(x, y, w, h);
    writeColor(color, len);
   d5222:	f7ff bf96 	b.w	d5152 <_ZN15Adafruit_SPITFT10writeColorEtm>
}
   d5226:	b003      	add	sp, #12
   d5228:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}

000d522c <_GLOBAL__sub_I__ZN15Adafruit_SPITFT8color565Ehhh>:
   d522c:	f00f bf7e 	b.w	e512c <HAL_Pin_Map>

000d5230 <_ZN15Adafruit_HX8357D1Ev>:
/*!
    @brief   Destructor for Adafruit_HX8357 object.
    @return  None (void).
*/
Adafruit_HX8357::~Adafruit_HX8357(void) {
}
   d5230:	4770      	bx	lr

000d5232 <_ZN15Adafruit_HX8357D0Ev>:

/*!
    @brief   Destructor for Adafruit_HX8357 object.
    @return  None (void).
*/
Adafruit_HX8357::~Adafruit_HX8357(void) {
   d5232:	b510      	push	{r4, lr}
}
   d5234:	2148      	movs	r1, #72	; 0x48

/*!
    @brief   Destructor for Adafruit_HX8357 object.
    @return  None (void).
*/
Adafruit_HX8357::~Adafruit_HX8357(void) {
   d5236:	4604      	mov	r4, r0
}
   d5238:	f010 ffbb 	bl	e61b2 <_ZdlPvj>
   d523c:	4620      	mov	r0, r4
   d523e:	bd10      	pop	{r4, pc}

000d5240 <_ZN15Adafruit_HX835713invertDisplayEb>:
    @brief   Enable/Disable display color inversion
    @param   invert
             True to invert display, False for normal color.
    @return  None (void).
*/
void Adafruit_HX8357::invertDisplay(boolean invert) {
   d5240:	b570      	push	{r4, r5, r6, lr}
  startWrite();
   d5242:	6803      	ldr	r3, [r0, #0]
    @brief   Enable/Disable display color inversion
    @param   invert
             True to invert display, False for normal color.
    @return  None (void).
*/
void Adafruit_HX8357::invertDisplay(boolean invert) {
   d5244:	460d      	mov	r5, r1
  startWrite();
   d5246:	695b      	ldr	r3, [r3, #20]
    @brief   Enable/Disable display color inversion
    @param   invert
             True to invert display, False for normal color.
    @return  None (void).
*/
void Adafruit_HX8357::invertDisplay(boolean invert) {
   d5248:	4604      	mov	r4, r0
  startWrite();
   d524a:	4798      	blx	r3
  writeCommand(invert ? HX8357_INVON : HX8357_INVOFF);
   d524c:	2d00      	cmp	r5, #0
   d524e:	4620      	mov	r0, r4
   d5250:	bf14      	ite	ne
   d5252:	2121      	movne	r1, #33	; 0x21
   d5254:	2120      	moveq	r1, #32
   d5256:	f7ff ff56 	bl	d5106 <_ZN15Adafruit_SPITFT12writeCommandEh>
  endWrite();
   d525a:	6823      	ldr	r3, [r4, #0]
   d525c:	4620      	mov	r0, r4
   d525e:	6adb      	ldr	r3, [r3, #44]	; 0x2c
}
   d5260:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
    @return  None (void).
*/
void Adafruit_HX8357::invertDisplay(boolean invert) {
  startWrite();
  writeCommand(invert ? HX8357_INVON : HX8357_INVOFF);
  endWrite();
   d5264:	4718      	bx	r3
	...

000d5268 <_ZN15Adafruit_HX83575beginEm>:
    @param   freq
             SPI bitrate -- default of 0 will use a (usually) platform-
             optimized value, e.g. 8 MHz on AVR, 12 MHz on M0.
    @return  None (void).
*/
void Adafruit_HX8357::begin(uint32_t freq) {
   d5268:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   d526c:	4604      	mov	r4, r0
  // the value passed here, and use the default SPI bitrate for platform.
  if(freq == HX8357D) {
    displayType = freq;
    freq        = 0; // Use default SPI frequency
  } else if(HX8357B) {
    displayType = freq;
   d526e:	f880 1046 	strb.w	r1, [r0, #70]	; 0x46
    freq        = 0; // Use default SPI frequency
  }

  if(!freq) freq = SPI_DEFAULT_FREQ;
  initSPI(freq);
   d5272:	491e      	ldr	r1, [pc, #120]	; (d52ec <_ZN15Adafruit_HX83575beginEm+0x84>)
   d5274:	f7ff fe9e 	bl	d4fb4 <_ZN15Adafruit_SPITFT7initSPIEm>

  startWrite();
   d5278:	6823      	ldr	r3, [r4, #0]
   d527a:	4620      	mov	r0, r4
   d527c:	695b      	ldr	r3, [r3, #20]
   d527e:	4798      	blx	r3
  const uint8_t *addr = (displayType == HX8357B) ? initb : initd;
   d5280:	f894 5046 	ldrb.w	r5, [r4, #70]	; 0x46
   d5284:	4a1a      	ldr	r2, [pc, #104]	; (d52f0 <_ZN15Adafruit_HX83575beginEm+0x88>)
   d5286:	4b1b      	ldr	r3, [pc, #108]	; (d52f4 <_ZN15Adafruit_HX83575beginEm+0x8c>)
   d5288:	2d0b      	cmp	r5, #11
   d528a:	bf0c      	ite	eq
   d528c:	461d      	moveq	r5, r3
   d528e:	4615      	movne	r5, r2
  uint8_t        cmd, x, numArgs;
  while((cmd = pgm_read_byte(addr++)) > 0) { // '0' command ends list
   d5290:	7829      	ldrb	r1, [r5, #0]
   d5292:	b1f9      	cbz	r1, d52d4 <_ZN15Adafruit_HX83575beginEm+0x6c>
    if(cmd != 0xFF) writeCommand(cmd);       // '255' is ignored
   d5294:	29ff      	cmp	r1, #255	; 0xff
   d5296:	d002      	beq.n	d529e <_ZN15Adafruit_HX83575beginEm+0x36>
   d5298:	4620      	mov	r0, r4
   d529a:	f7ff ff34 	bl	d5106 <_ZN15Adafruit_SPITFT12writeCommandEh>
    x       = pgm_read_byte(addr++);
   d529e:	786b      	ldrb	r3, [r5, #1]
    numArgs = x & 0x7F;
   d52a0:	f003 077f 	and.w	r7, r3, #127	; 0x7f
    if(x & 0x80) {        // If high bit set...
   d52a4:	061b      	lsls	r3, r3, #24
  startWrite();
  const uint8_t *addr = (displayType == HX8357B) ? initb : initd;
  uint8_t        cmd, x, numArgs;
  while((cmd = pgm_read_byte(addr++)) > 0) { // '0' command ends list
    if(cmd != 0xFF) writeCommand(cmd);       // '255' is ignored
    x       = pgm_read_byte(addr++);
   d52a6:	f105 0602 	add.w	r6, r5, #2
    numArgs = x & 0x7F;
    if(x & 0x80) {        // If high bit set...
   d52aa:	d402      	bmi.n	d52b2 <_ZN15Adafruit_HX83575beginEm+0x4a>
   d52ac:	463d      	mov	r5, r7
   d52ae:	46b0      	mov	r8, r6
   d52b0:	e00a      	b.n	d52c8 <_ZN15Adafruit_HX83575beginEm+0x60>
      delay(numArgs * 5); // numArgs is actually a delay time (5ms units)
   d52b2:	eb07 0087 	add.w	r0, r7, r7, lsl #2
   d52b6:	f010 f97e 	bl	e55b6 <delay>

  if(!freq) freq = SPI_DEFAULT_FREQ;
  initSPI(freq);

  startWrite();
  const uint8_t *addr = (displayType == HX8357B) ? initb : initd;
   d52ba:	4635      	mov	r5, r6
   d52bc:	e7e8      	b.n	d5290 <_ZN15Adafruit_HX83575beginEm+0x28>
    x       = pgm_read_byte(addr++);
    numArgs = x & 0x7F;
    if(x & 0x80) {        // If high bit set...
      delay(numArgs * 5); // numArgs is actually a delay time (5ms units)
    } else {              // Otherwise, issue args to command...
      while(numArgs--) spiWrite(pgm_read_byte(addr++));
   d52be:	f818 1b01 	ldrb.w	r1, [r8], #1
   d52c2:	4620      	mov	r0, r4
   d52c4:	f7ff fecb 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
   d52c8:	3d01      	subs	r5, #1
   d52ca:	b2ed      	uxtb	r5, r5
   d52cc:	2dff      	cmp	r5, #255	; 0xff
   d52ce:	d1f6      	bne.n	d52be <_ZN15Adafruit_HX83575beginEm+0x56>
   d52d0:	443e      	add	r6, r7
   d52d2:	e7f2      	b.n	d52ba <_ZN15Adafruit_HX83575beginEm+0x52>
    }
  }
  endWrite();
   d52d4:	6823      	ldr	r3, [r4, #0]
   d52d6:	4620      	mov	r0, r4
   d52d8:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   d52da:	4798      	blx	r3

  _width  = HX8357_TFTWIDTH;  // Screen dimensions for default rotation 0
   d52dc:	f44f 73a0 	mov.w	r3, #320	; 0x140
   d52e0:	81a3      	strh	r3, [r4, #12]
  _height = HX8357_TFTHEIGHT;
   d52e2:	f44f 73f0 	mov.w	r3, #480	; 0x1e0
   d52e6:	81e3      	strh	r3, [r4, #14]
   d52e8:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   d52ec:	016e3600 	.word	0x016e3600
   d52f0:	000e9dfd 	.word	0x000e9dfd
   d52f4:	000e9db0 	.word	0x000e9db0

000d52f8 <_ZN15Adafruit_HX835711setRotationEh>:
             The index for rotation, from 0-3 inclusive
    @return  None (void).
*/
void Adafruit_HX8357::setRotation(uint8_t m) {

  rotation = m & 3; // can't be higher than 3
   d52f8:	f001 0103 	and.w	r1, r1, #3
  switch(rotation) {
   d52fc:	2902      	cmp	r1, #2
    @brief   Set origin of (0,0) and orientation of TFT display
    @param   m
             The index for rotation, from 0-3 inclusive
    @return  None (void).
*/
void Adafruit_HX8357::setRotation(uint8_t m) {
   d52fe:	b570      	push	{r4, r5, r6, lr}
   d5300:	f44f 73f0 	mov.w	r3, #480	; 0x1e0
   d5304:	4604      	mov	r4, r0

  rotation = m & 3; // can't be higher than 3
   d5306:	7641      	strb	r1, [r0, #25]
  switch(rotation) {
   d5308:	d00d      	beq.n	d5326 <_ZN15Adafruit_HX835711setRotationEh+0x2e>
   d530a:	2903      	cmp	r1, #3
   d530c:	f44f 72a0 	mov.w	r2, #320	; 0x140
   d5310:	d00f      	beq.n	d5332 <_ZN15Adafruit_HX835711setRotationEh+0x3a>
   d5312:	2901      	cmp	r1, #1
    case 0:
      m       = MADCTL_MX | MADCTL_MY | MADCTL_RGB;
      _width  = HX8357_TFTWIDTH;
   d5314:	bf1d      	ittte	ne
   d5316:	8182      	strhne	r2, [r0, #12]
      _height = HX8357_TFTHEIGHT;
   d5318:	81c3      	strhne	r3, [r0, #14]
void Adafruit_HX8357::setRotation(uint8_t m) {

  rotation = m & 3; // can't be higher than 3
  switch(rotation) {
    case 0:
      m       = MADCTL_MX | MADCTL_MY | MADCTL_RGB;
   d531a:	25c0      	movne	r5, #192	; 0xc0
      _width  = HX8357_TFTWIDTH;
      _height = HX8357_TFTHEIGHT;
      break;
    case 1:
      m       = MADCTL_MV | MADCTL_MY | MADCTL_RGB;
      _width  = HX8357_TFTHEIGHT;
   d531c:	8183      	strheq	r3, [r0, #12]
      _height = HX8357_TFTWIDTH;
   d531e:	bf04      	itt	eq
   d5320:	81c2      	strheq	r2, [r0, #14]
      m       = MADCTL_MX | MADCTL_MY | MADCTL_RGB;
      _width  = HX8357_TFTWIDTH;
      _height = HX8357_TFTHEIGHT;
      break;
    case 1:
      m       = MADCTL_MV | MADCTL_MY | MADCTL_RGB;
   d5322:	25a0      	moveq	r5, #160	; 0xa0
      _width  = HX8357_TFTHEIGHT;
      _height = HX8357_TFTWIDTH;
      break;
   d5324:	e008      	b.n	d5338 <_ZN15Adafruit_HX835711setRotationEh+0x40>
    case 2:
      m       = MADCTL_RGB;
      _width  = HX8357_TFTWIDTH;
   d5326:	f44f 72a0 	mov.w	r2, #320	; 0x140
   d532a:	8182      	strh	r2, [r0, #12]
      _height = HX8357_TFTHEIGHT;
   d532c:	81c3      	strh	r3, [r0, #14]
      m       = MADCTL_MV | MADCTL_MY | MADCTL_RGB;
      _width  = HX8357_TFTHEIGHT;
      _height = HX8357_TFTWIDTH;
      break;
    case 2:
      m       = MADCTL_RGB;
   d532e:	2500      	movs	r5, #0
      _width  = HX8357_TFTWIDTH;
      _height = HX8357_TFTHEIGHT;
      break;
   d5330:	e002      	b.n	d5338 <_ZN15Adafruit_HX835711setRotationEh+0x40>
    case 3:
      m       = MADCTL_MX | MADCTL_MV | MADCTL_RGB;
      _width  = HX8357_TFTHEIGHT;
   d5332:	8183      	strh	r3, [r0, #12]
      _height = HX8357_TFTWIDTH;
   d5334:	81c2      	strh	r2, [r0, #14]
      m       = MADCTL_RGB;
      _width  = HX8357_TFTWIDTH;
      _height = HX8357_TFTHEIGHT;
      break;
    case 3:
      m       = MADCTL_MX | MADCTL_MV | MADCTL_RGB;
   d5336:	2560      	movs	r5, #96	; 0x60
      _width  = HX8357_TFTHEIGHT;
      _height = HX8357_TFTWIDTH;
      break;
  }

  startWrite();
   d5338:	6823      	ldr	r3, [r4, #0]
   d533a:	4620      	mov	r0, r4
   d533c:	695b      	ldr	r3, [r3, #20]
   d533e:	4798      	blx	r3
  writeCommand(HX8357_MADCTL);
   d5340:	4620      	mov	r0, r4
   d5342:	2136      	movs	r1, #54	; 0x36
   d5344:	f7ff fedf 	bl	d5106 <_ZN15Adafruit_SPITFT12writeCommandEh>
  spiWrite(m);
   d5348:	4620      	mov	r0, r4
   d534a:	4629      	mov	r1, r5
   d534c:	f7ff fe87 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
  endWrite();
   d5350:	6823      	ldr	r3, [r4, #0]
   d5352:	4620      	mov	r0, r4
   d5354:	6adb      	ldr	r3, [r3, #44]	; 0x2c
}
   d5356:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
  }

  startWrite();
  writeCommand(HX8357_MADCTL);
  spiWrite(m);
  endWrite();
   d535a:	4718      	bx	r3

000d535c <_ZN15Adafruit_HX835713setAddrWindowEtttt>:
    @param   h
             Height of rectangle.
    @return  None (void).
*/
void Adafruit_HX8357::setAddrWindow(
  uint16_t x1, uint16_t y1, uint16_t w, uint16_t h) {
   d535c:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
  uint16_t x2 = (x1 + w - 1),
   d5360:	f101 38ff 	add.w	r8, r1, #4294967295	; 0xffffffff
    @param   h
             Height of rectangle.
    @return  None (void).
*/
void Adafruit_HX8357::setAddrWindow(
  uint16_t x1, uint16_t y1, uint16_t w, uint16_t h) {
   d5364:	4604      	mov	r4, r0
   d5366:	f8bd 7020 	ldrh.w	r7, [sp, #32]
  uint16_t x2 = (x1 + w - 1),
   d536a:	4443      	add	r3, r8
    @param   h
             Height of rectangle.
    @return  None (void).
*/
void Adafruit_HX8357::setAddrWindow(
  uint16_t x1, uint16_t y1, uint16_t w, uint16_t h) {
   d536c:	4689      	mov	r9, r1
  uint16_t x2 = (x1 + w - 1),
   d536e:	fa1f f883 	uxth.w	r8, r3
           y2 = (y1 + h - 1);
  writeCommand(HX8357_CASET); // Column address set
   d5372:	212a      	movs	r1, #42	; 0x2a
    @return  None (void).
*/
void Adafruit_HX8357::setAddrWindow(
  uint16_t x1, uint16_t y1, uint16_t w, uint16_t h) {
  uint16_t x2 = (x1 + w - 1),
           y2 = (y1 + h - 1);
   d5374:	1e53      	subs	r3, r2, #1
   d5376:	441f      	add	r7, r3
    @param   h
             Height of rectangle.
    @return  None (void).
*/
void Adafruit_HX8357::setAddrWindow(
  uint16_t x1, uint16_t y1, uint16_t w, uint16_t h) {
   d5378:	4615      	mov	r5, r2
  uint16_t x2 = (x1 + w - 1),
           y2 = (y1 + h - 1);
  writeCommand(HX8357_CASET); // Column address set
   d537a:	f7ff fec4 	bl	d5106 <_ZN15Adafruit_SPITFT12writeCommandEh>
  SPI_WRITE16(x1);
   d537e:	6b63      	ldr	r3, [r4, #52]	; 0x34
   d5380:	2b00      	cmp	r3, #0
    @return  None (void).
*/
void Adafruit_HX8357::setAddrWindow(
  uint16_t x1, uint16_t y1, uint16_t w, uint16_t h) {
  uint16_t x2 = (x1 + w - 1),
           y2 = (y1 + h - 1);
   d5382:	b2bf      	uxth	r7, r7
   d5384:	ea4f 2129 	mov.w	r1, r9, asr #8
   d5388:	fa5f f689 	uxtb.w	r6, r9
  writeCommand(HX8357_CASET); // Column address set
  SPI_WRITE16(x1);
   d538c:	da07      	bge.n	d539e <_ZN15Adafruit_HX835713setAddrWindowEtttt+0x42>
   d538e:	6a20      	ldr	r0, [r4, #32]
   d5390:	f010 fcb8 	bl	e5d04 <_ZN8SPIClass8transferEh>
   d5394:	4631      	mov	r1, r6
   d5396:	6a20      	ldr	r0, [r4, #32]
   d5398:	f010 fcb4 	bl	e5d04 <_ZN8SPIClass8transferEh>
   d539c:	e006      	b.n	d53ac <_ZN15Adafruit_HX835713setAddrWindowEtttt+0x50>
   d539e:	4620      	mov	r0, r4
   d53a0:	f7ff fe5d 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
   d53a4:	4631      	mov	r1, r6
   d53a6:	4620      	mov	r0, r4
   d53a8:	f7ff fe59 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
  SPI_WRITE16(x2);
   d53ac:	6b63      	ldr	r3, [r4, #52]	; 0x34
   d53ae:	2b00      	cmp	r3, #0
   d53b0:	ea4f 2128 	mov.w	r1, r8, asr #8
   d53b4:	fa5f f688 	uxtb.w	r6, r8
   d53b8:	da07      	bge.n	d53ca <_ZN15Adafruit_HX835713setAddrWindowEtttt+0x6e>
   d53ba:	6a20      	ldr	r0, [r4, #32]
   d53bc:	f010 fca2 	bl	e5d04 <_ZN8SPIClass8transferEh>
   d53c0:	4631      	mov	r1, r6
   d53c2:	6a20      	ldr	r0, [r4, #32]
   d53c4:	f010 fc9e 	bl	e5d04 <_ZN8SPIClass8transferEh>
   d53c8:	e006      	b.n	d53d8 <_ZN15Adafruit_HX835713setAddrWindowEtttt+0x7c>
   d53ca:	4620      	mov	r0, r4
   d53cc:	f7ff fe47 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
   d53d0:	4631      	mov	r1, r6
   d53d2:	4620      	mov	r0, r4
   d53d4:	f7ff fe43 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
  writeCommand(HX8357_PASET); // Row address set
   d53d8:	212b      	movs	r1, #43	; 0x2b
   d53da:	4620      	mov	r0, r4
   d53dc:	f7ff fe93 	bl	d5106 <_ZN15Adafruit_SPITFT12writeCommandEh>
  SPI_WRITE16(y1);
   d53e0:	6b63      	ldr	r3, [r4, #52]	; 0x34
   d53e2:	2b00      	cmp	r3, #0
   d53e4:	ea4f 2125 	mov.w	r1, r5, asr #8
   d53e8:	b2ed      	uxtb	r5, r5
   d53ea:	da07      	bge.n	d53fc <_ZN15Adafruit_HX835713setAddrWindowEtttt+0xa0>
   d53ec:	6a20      	ldr	r0, [r4, #32]
   d53ee:	f010 fc89 	bl	e5d04 <_ZN8SPIClass8transferEh>
   d53f2:	4629      	mov	r1, r5
   d53f4:	6a20      	ldr	r0, [r4, #32]
   d53f6:	f010 fc85 	bl	e5d04 <_ZN8SPIClass8transferEh>
   d53fa:	e006      	b.n	d540a <_ZN15Adafruit_HX835713setAddrWindowEtttt+0xae>
   d53fc:	4620      	mov	r0, r4
   d53fe:	f7ff fe2e 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
   d5402:	4629      	mov	r1, r5
   d5404:	4620      	mov	r0, r4
   d5406:	f7ff fe2a 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
  SPI_WRITE16(y2);
   d540a:	6b63      	ldr	r3, [r4, #52]	; 0x34
   d540c:	2b00      	cmp	r3, #0
   d540e:	ea4f 2127 	mov.w	r1, r7, asr #8
   d5412:	b2fd      	uxtb	r5, r7
   d5414:	da07      	bge.n	d5426 <_ZN15Adafruit_HX835713setAddrWindowEtttt+0xca>
   d5416:	6a20      	ldr	r0, [r4, #32]
   d5418:	f010 fc74 	bl	e5d04 <_ZN8SPIClass8transferEh>
   d541c:	4629      	mov	r1, r5
   d541e:	6a20      	ldr	r0, [r4, #32]
   d5420:	f010 fc70 	bl	e5d04 <_ZN8SPIClass8transferEh>
   d5424:	e006      	b.n	d5434 <_ZN15Adafruit_HX835713setAddrWindowEtttt+0xd8>
   d5426:	4620      	mov	r0, r4
   d5428:	f7ff fe19 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
   d542c:	4629      	mov	r1, r5
   d542e:	4620      	mov	r0, r4
   d5430:	f7ff fe15 	bl	d505e <_ZN15Adafruit_SPITFT8spiWriteEh>
  writeCommand(HX8357_RAMWR); // Write to RAM
   d5434:	4620      	mov	r0, r4
   d5436:	212c      	movs	r1, #44	; 0x2c
}
   d5438:	e8bd 43f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
  SPI_WRITE16(x1);
  SPI_WRITE16(x2);
  writeCommand(HX8357_PASET); // Row address set
  SPI_WRITE16(y1);
  SPI_WRITE16(y2);
  writeCommand(HX8357_RAMWR); // Write to RAM
   d543c:	f7ff be63 	b.w	d5106 <_ZN15Adafruit_SPITFT12writeCommandEh>

000d5440 <_ZN15Adafruit_HX8357C1EaaahP8SPIClass>:
    @param   spi
             SPI peripheral to use (will use primary SPI if unspecified)
    @return  Adafruit_HX8357 object.
    @note    Call the object's begin() function before use.
*/
Adafruit_HX8357::Adafruit_HX8357(int8_t cs, int8_t dc, int8_t rst,
   d5440:	b51f      	push	{r0, r1, r2, r3, r4, lr}
   d5442:	4604      	mov	r4, r0
  uint8_t type, SPIClass *spi) : Adafruit_SPITFT(HX8357_TFTWIDTH,
  HX8357_TFTHEIGHT, spi, cs, dc, rst), displayType(type) {
   d5444:	e88d 000e 	stmia.w	sp, {r1, r2, r3}
   d5448:	9b07      	ldr	r3, [sp, #28]
   d544a:	f44f 72f0 	mov.w	r2, #480	; 0x1e0
   d544e:	f44f 71a0 	mov.w	r1, #320	; 0x140
   d5452:	f7ff fd89 	bl	d4f68 <_ZN15Adafruit_SPITFTC1EttP8SPIClassaaa>
   d5456:	4b04      	ldr	r3, [pc, #16]	; (d5468 <_ZN15Adafruit_HX8357C1EaaahP8SPIClass+0x28>)
   d5458:	6023      	str	r3, [r4, #0]
   d545a:	f89d 3018 	ldrb.w	r3, [sp, #24]
   d545e:	f884 3046 	strb.w	r3, [r4, #70]	; 0x46
}
   d5462:	4620      	mov	r0, r4
   d5464:	b004      	add	sp, #16
   d5466:	bd10      	pop	{r4, pc}
   d5468:	000e9d58 	.word	0x000e9d58

000d546c <_GLOBAL__sub_I__ZN15Adafruit_HX8357C2Eaaaaaah>:
   d546c:	f00f be5e 	b.w	e512c <HAL_Pin_Map>

000d5470 <_ZNK8particle13__SPISettings7printToER5Print>:
  bool operator!=(const __SPISettings& other) const
  {
    return !(other == *this);
  }

  virtual size_t printTo(Print& p) const
   d5470:	b57f      	push	{r0, r1, r2, r3, r4, r5, r6, lr}
   d5472:	4602      	mov	r2, r0
   d5474:	4608      	mov	r0, r1
  {
    if (default_ && clock_ == 0)
   d5476:	7913      	ldrb	r3, [r2, #4]
   d5478:	6895      	ldr	r5, [r2, #8]
   d547a:	b133      	cbz	r3, d548a <_ZNK8particle13__SPISettings7printToER5Print+0x1a>
   d547c:	b93d      	cbnz	r5, d548e <_ZNK8particle13__SPISettings7printToER5Print+0x1e>
      return p.print("<SPISettings default>");
   d547e:	490c      	ldr	r1, [pc, #48]	; (d54b0 <_ZNK8particle13__SPISettings7printToER5Print+0x40>)
    else
      return p.printf("<SPISettings %s%lu %s MODE%d>", default_ ? "default " : "", clock_, bitOrder_ == MSBFIRST ? "MSB" : "LSB", dataMode_);
  }
   d5480:	b004      	add	sp, #16
   d5482:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
  }

  virtual size_t printTo(Print& p) const
  {
    if (default_ && clock_ == 0)
      return p.print("<SPISettings default>");
   d5486:	f010 bb21 	b.w	e5acc <_ZN5Print5printEPKc>
    else
      return p.printf("<SPISettings %s%lu %s MODE%d>", default_ ? "default " : "", clock_, bitOrder_ == MSBFIRST ? "MSB" : "LSB", dataMode_);
   d548a:	4b0a      	ldr	r3, [pc, #40]	; (d54b4 <_ZNK8particle13__SPISettings7printToER5Print+0x44>)
   d548c:	e000      	b.n	d5490 <_ZNK8particle13__SPISettings7printToER5Print+0x20>
   d548e:	4b0a      	ldr	r3, [pc, #40]	; (d54b8 <_ZNK8particle13__SPISettings7printToER5Print+0x48>)
   d5490:	7b16      	ldrb	r6, [r2, #12]
   d5492:	4c0a      	ldr	r4, [pc, #40]	; (d54bc <_ZNK8particle13__SPISettings7printToER5Print+0x4c>)
   d5494:	490a      	ldr	r1, [pc, #40]	; (d54c0 <_ZNK8particle13__SPISettings7printToER5Print+0x50>)
    size_t println(const __FlashStringHelper*);

    template <typename... Args>
    inline size_t printf(const char* format, Args... args)
    {
        return this->printf_impl(false, format, args...);
   d5496:	7b52      	ldrb	r2, [r2, #13]
   d5498:	9202      	str	r2, [sp, #8]
   d549a:	2e01      	cmp	r6, #1
   d549c:	bf08      	it	eq
   d549e:	4621      	moveq	r1, r4
   d54a0:	9101      	str	r1, [sp, #4]
   d54a2:	9500      	str	r5, [sp, #0]
   d54a4:	4a07      	ldr	r2, [pc, #28]	; (d54c4 <_ZNK8particle13__SPISettings7printToER5Print+0x54>)
   d54a6:	2100      	movs	r1, #0
   d54a8:	f010 fb5c 	bl	e5b64 <_ZN5Print11printf_implEbPKcz>
  }
   d54ac:	b004      	add	sp, #16
   d54ae:	bd70      	pop	{r4, r5, r6, pc}
   d54b0:	000e9e81 	.word	0x000e9e81
   d54b4:	000eaf76 	.word	0x000eaf76
   d54b8:	000e9e70 	.word	0x000e9e70
   d54bc:	000e9e79 	.word	0x000e9e79
   d54c0:	000e9e7d 	.word	0x000e9e7d
   d54c4:	000e9e97 	.word	0x000e9e97

000d54c8 <_GLOBAL__sub_I__ZN17Adafruit_STMPE610C2Ehhhh>:
  return  ((p1.x == x) && (p1.y == y) && (p1.z == z));
}

bool TS_Point::operator!=(TS_Point p1) {
  return  ((p1.x != x) || (p1.y != y) || (p1.z != z));
}
   d54c8:	b508      	push	{r3, lr}
   d54ca:	f00f fe2f 	bl	e512c <HAL_Pin_Map>
      dataMode_{dataMode}
  {
  }

  __SPISettings()
  {
   d54ce:	4b05      	ldr	r3, [pc, #20]	; (d54e4 <_GLOBAL__sub_I__ZN17Adafruit_STMPE610C2Ehhhh+0x1c>)
   d54d0:	4a05      	ldr	r2, [pc, #20]	; (d54e8 <_GLOBAL__sub_I__ZN17Adafruit_STMPE610C2Ehhhh+0x20>)
   d54d2:	601a      	str	r2, [r3, #0]
   d54d4:	2201      	movs	r2, #1
   d54d6:	711a      	strb	r2, [r3, #4]
   d54d8:	2200      	movs	r2, #0
   d54da:	609a      	str	r2, [r3, #8]
   d54dc:	731a      	strb	r2, [r3, #12]
   d54de:	735a      	strb	r2, [r3, #13]
   d54e0:	bd08      	pop	{r3, pc}
   d54e2:	bf00      	nop
   d54e4:	2003dbb4 	.word	0x2003dbb4
   d54e8:	000e9e6c 	.word	0x000e9e6c

000d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>:
#include "tensorflow/lite/core/api/error_reporter.h"
#include <cstdarg>

namespace tflite {

int ErrorReporter::Report(const char* format, ...) {
   d54ec:	b40e      	push	{r1, r2, r3}
   d54ee:	b503      	push	{r0, r1, lr}
   d54f0:	aa03      	add	r2, sp, #12
  va_list args;
  va_start(args, format);
  int code = Report(format, args);
   d54f2:	6803      	ldr	r3, [r0, #0]
#include "tensorflow/lite/core/api/error_reporter.h"
#include <cstdarg>

namespace tflite {

int ErrorReporter::Report(const char* format, ...) {
   d54f4:	f852 1b04 	ldr.w	r1, [r2], #4
  va_list args;
  va_start(args, format);
   d54f8:	9201      	str	r2, [sp, #4]
  int code = Report(format, args);
   d54fa:	689b      	ldr	r3, [r3, #8]
   d54fc:	4798      	blx	r3
  va_end(args);
  return code;
}
   d54fe:	b002      	add	sp, #8
   d5500:	f85d eb04 	ldr.w	lr, [sp], #4
   d5504:	b003      	add	sp, #12
   d5506:	4770      	bx	lr

000d5508 <_ZN6tflite12_GLOBAL__N_124SafeBuiltinDataAllocator18BuiltinDataDeleterclEPv>:
  class BuiltinDataDeleter {
   public:
    explicit BuiltinDataDeleter(BuiltinDataAllocator* allocator)
        : allocator_(allocator) {}

    void operator()(void* data) { allocator_->Deallocate(data); }
   d5508:	6800      	ldr	r0, [r0, #0]
   d550a:	6803      	ldr	r3, [r0, #0]
   d550c:	685b      	ldr	r3, [r3, #4]
   d550e:	4718      	bx	r3

000d5510 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_7PaddingEE_clESA_.isra.0>:
// If it returns kTfLiteError, `builtin_data` will be `nullptr`.
TfLiteStatus ParseOpData(const Operator* op, BuiltinOperator op_type,
                         ErrorReporter* error_reporter,
                         BuiltinDataAllocator* allocator, void** builtin_data) {
  auto parse_padding = [](Padding padding) {
    switch (padding) {
   d5510:	b120      	cbz	r0, d551c <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_7PaddingEE_clESA_.isra.0+0xc>
   d5512:	2801      	cmp	r0, #1
      case Padding_SAME:
        return kTfLitePaddingSame;
      case Padding_VALID:
        return kTfLitePaddingValid;
    }
    return kTfLitePaddingUnknown;
   d5514:	bf0c      	ite	eq
   d5516:	2002      	moveq	r0, #2
   d5518:	2000      	movne	r0, #0
   d551a:	4770      	bx	lr
                         ErrorReporter* error_reporter,
                         BuiltinDataAllocator* allocator, void** builtin_data) {
  auto parse_padding = [](Padding padding) {
    switch (padding) {
      case Padding_SAME:
        return kTfLitePaddingSame;
   d551c:	2001      	movs	r0, #1
      case Padding_VALID:
        return kTfLitePaddingValid;
    }
    return kTfLitePaddingUnknown;
  };
   d551e:	4770      	bx	lr

000d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>:
  auto parse_activation = [](ActivationFunctionType activation) {
   d5520:	3801      	subs	r0, #1
   d5522:	b2c0      	uxtb	r0, r0
   d5524:	2804      	cmp	r0, #4
   d5526:	bf9a      	itte	ls
   d5528:	4b01      	ldrls	r3, [pc, #4]	; (d5530 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1+0x10>)
   d552a:	5c18      	ldrbls	r0, [r3, r0]
   d552c:	2000      	movhi	r0, #0
        return kTfLiteActTanh;
      case ActivationFunctionType_SIGN_BIT:
        return kTfLiteActSignBit;
    }
    return kTfLiteActNone;
  };
   d552e:	4770      	bx	lr
   d5530:	000ea175 	.word	0x000ea175

000d5534 <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4>:
};

// Copies the contents from the flatbuffer int vector `flatbuffer` into the
// int array `buffer`. `flat_vector` and `buffer` represent the same
// configuration operation for a given operation.
TfLiteStatus FlatBufferIntVectorToArray(
   d5534:	b538      	push	{r3, r4, r5, lr}
   d5536:	4615      	mov	r5, r2
   d5538:	461a      	mov	r2, r3
    int max_size_of_buffer, const flatbuffers::Vector<int32_t>* flat_vector,
    int* buffer, ErrorReporter* error_reporter, const char* op_name) {
  if (!flat_vector) {
   d553a:	b908      	cbnz	r0, d5540 <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0xc>
    error_reporter->Report("Input array not provided for operation '%s'.\n",
                           op_name);
   d553c:	490f      	ldr	r1, [pc, #60]	; (d557c <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0x48>)
   d553e:	e003      	b.n	d5548 <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0x14>
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d5540:	6804      	ldr	r4, [r0, #0]
    return kTfLiteError;
  } else {
    int num_dimensions = flat_vector->size();
    if (num_dimensions > max_size_of_buffer / sizeof(int)) {
   d5542:	2c08      	cmp	r4, #8
   d5544:	d905      	bls.n	d5552 <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0x1e>
      error_reporter->Report(
          "Found too many dimensions in the input array of operation '%s'.\n",
          op_name);
   d5546:	490e      	ldr	r1, [pc, #56]	; (d5580 <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0x4c>)
   d5548:	4628      	mov	r0, r5
   d554a:	f7ff ffcf 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
      return kTfLiteError;
   d554e:	2001      	movs	r0, #1
   d5550:	bd38      	pop	{r3, r4, r5, pc}
   d5552:	4602      	mov	r2, r0
    error_reporter->Report("Input array not provided for operation '%s'.\n",
                           op_name);
    return kTfLiteError;
  } else {
    int num_dimensions = flat_vector->size();
    if (num_dimensions > max_size_of_buffer / sizeof(int)) {
   d5554:	2300      	movs	r3, #0
      error_reporter->Report(
          "Found too many dimensions in the input array of operation '%s'.\n",
          op_name);
      return kTfLiteError;
    } else {
      for (int i = 0; i < num_dimensions; ++i) {
   d5556:	429c      	cmp	r4, r3
   d5558:	d00e      	beq.n	d5578 <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0x44>

  typedef typename IndirectHelper<T>::return_type return_type;
  typedef typename IndirectHelper<T>::mutable_return_type mutable_return_type;

  return_type Get(uoffset_t i) const {
    FLATBUFFERS_ASSERT(i < size());
   d555a:	6805      	ldr	r5, [r0, #0]
   d555c:	42ab      	cmp	r3, r5
   d555e:	d305      	bcc.n	d556c <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0x38>
   d5560:	4b08      	ldr	r3, [pc, #32]	; (d5584 <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0x50>)
   d5562:	4a09      	ldr	r2, [pc, #36]	; (d5588 <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0x54>)
   d5564:	4809      	ldr	r0, [pc, #36]	; (d558c <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0x58>)
   d5566:	21ed      	movs	r1, #237	; 0xed
   d5568:	f00f ffd4 	bl	e5514 <__assert_func>
template<typename T> struct IndirectHelper {
  typedef T return_type;
  typedef T mutable_return_type;
  static const size_t element_stride = sizeof(T);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    return EndianScalar((reinterpret_cast<const T *>(p))[i]);
   d556c:	f852 5f04 	ldr.w	r5, [r2, #4]!
        buffer[i] = flat_vector->Get(i);
   d5570:	f841 5023 	str.w	r5, [r1, r3, lsl #2]
      error_reporter->Report(
          "Found too many dimensions in the input array of operation '%s'.\n",
          op_name);
      return kTfLiteError;
    } else {
      for (int i = 0; i < num_dimensions; ++i) {
   d5574:	3301      	adds	r3, #1
   d5576:	e7ee      	b.n	d5556 <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4+0x22>
        buffer[i] = flat_vector->Get(i);
      }
    }
  }
  return kTfLiteOk;
   d5578:	2000      	movs	r0, #0
}
   d557a:	bd38      	pop	{r3, r4, r5, pc}
   d557c:	000e9f83 	.word	0x000e9f83
   d5580:	000e9fb1 	.word	0x000e9fb1
   d5584:	000e9ff2 	.word	0x000e9ff2
   d5588:	000e9eb5 	.word	0x000e9eb5
   d558c:	000e9ffd 	.word	0x000e9ffd

000d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>:
// "tables" use an offset table (possibly shared) that allows fields to be
// omitted and added at will, but uses an extra indirection to read.
class Table {
 public:
  const uint8_t *GetVTable() const {
    return data_ - ReadScalar<soffset_t>(data_);
   d5590:	6803      	ldr	r3, [r0, #0]
   d5592:	1ac0      	subs	r0, r0, r3
    auto vtable = GetVTable();
    // The first element is the size of the vtable (fields + type id + itself).
    auto vtsize = ReadScalar<voffset_t>(vtable);
    // If the field we're accessing is outside the vtable, we're reading older
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
   d5594:	8803      	ldrh	r3, [r0, #0]
   d5596:	428b      	cmp	r3, r1
   d5598:	bf8c      	ite	hi
   d559a:	5a40      	ldrhhi	r0, [r0, r1]
   d559c:	2000      	movls	r0, #0
  }
   d559e:	4770      	bx	lr

000d55a0 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE>:

}  // namespace

TfLiteStatus ConvertTensorType(TensorType tensor_type, TfLiteType* type,
                               ErrorReporter* error_reporter) {
   d55a0:	b508      	push	{r3, lr}
   d55a2:	4603      	mov	r3, r0
   d55a4:	4610      	mov	r0, r2
  *type = kTfLiteNoType;
  switch (tensor_type) {
   d55a6:	2b09      	cmp	r3, #9
   d55a8:	d806      	bhi.n	d55b8 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x18>
   d55aa:	e8df f003 	tbb	[pc, r3]
   d55ae:	0907      	.short	0x0907
   d55b0:	15130f0d 	.word	0x15130f0d
   d55b4:	11190b17 	.word	0x11190b17

}  // namespace

TfLiteStatus ConvertTensorType(TensorType tensor_type, TfLiteType* type,
                               ErrorReporter* error_reporter) {
  *type = kTfLiteNoType;
   d55b8:	2200      	movs	r2, #0
   d55ba:	e012      	b.n	d55e2 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x42>
  switch (tensor_type) {
    case TensorType_FLOAT32:
      *type = kTfLiteFloat32;
   d55bc:	2201      	movs	r2, #1
   d55be:	e010      	b.n	d55e2 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x42>
      break;
    case TensorType_FLOAT16:
      *type = kTfLiteFloat16;
   d55c0:	220a      	movs	r2, #10
   d55c2:	e00e      	b.n	d55e2 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x42>
      break;
    case TensorType_INT16:
      *type = kTfLiteInt16;
   d55c4:	2207      	movs	r2, #7
   d55c6:	e00c      	b.n	d55e2 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x42>
      break;
    case TensorType_INT32:
      *type = kTfLiteInt32;
   d55c8:	2202      	movs	r2, #2
   d55ca:	e00a      	b.n	d55e2 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x42>
      break;
    case TensorType_UINT8:
      *type = kTfLiteUInt8;
   d55cc:	2203      	movs	r2, #3
   d55ce:	e008      	b.n	d55e2 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x42>
      break;
    case TensorType_INT8:
      *type = kTfLiteInt8;
   d55d0:	2209      	movs	r2, #9
   d55d2:	e006      	b.n	d55e2 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x42>
      break;
    case TensorType_INT64:
      *type = kTfLiteInt64;
   d55d4:	2204      	movs	r2, #4
   d55d6:	e004      	b.n	d55e2 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x42>
      break;
    case TensorType_STRING:
      *type = kTfLiteString;
   d55d8:	2205      	movs	r2, #5
   d55da:	e002      	b.n	d55e2 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x42>
      break;
    case TensorType_BOOL:
      *type = kTfLiteBool;
   d55dc:	2206      	movs	r2, #6
   d55de:	e000      	b.n	d55e2 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x42>
      break;
    case TensorType_COMPLEX64:
      *type = kTfLiteComplex64;
   d55e0:	2208      	movs	r2, #8
   d55e2:	700a      	strb	r2, [r1, #0]
      break;
  }
  if (*type == kTfLiteNoType) {
   d55e4:	780a      	ldrb	r2, [r1, #0]
   d55e6:	b92a      	cbnz	r2, d55f4 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x54>
    error_reporter->Report("Unsupported data type %d in tensor\n", tensor_type);
   d55e8:	461a      	mov	r2, r3
   d55ea:	4903      	ldr	r1, [pc, #12]	; (d55f8 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE+0x58>)
   d55ec:	f7ff ff7e 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    return kTfLiteError;
   d55f0:	2001      	movs	r0, #1
   d55f2:	bd08      	pop	{r3, pc}
  }
  return kTfLiteOk;
   d55f4:	2000      	movs	r0, #0
}
   d55f6:	bd08      	pop	{r3, pc}
   d55f8:	000ea0ae 	.word	0x000ea0ae

000d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>:

  template<typename T> T GetField(voffset_t field, T defaultval) const {
   d55fc:	b538      	push	{r3, r4, r5, lr}
   d55fe:	4605      	mov	r5, r0
   d5600:	4614      	mov	r4, r2
    auto field_offset = GetOptionalFieldOffset(field);
   d5602:	f7ff ffc5 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d5606:	b108      	cbz	r0, d560c <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_+0x10>
   d5608:	5c28      	ldrb	r0, [r5, r0]
   d560a:	bd38      	pop	{r3, r4, r5, pc}
   d560c:	4620      	mov	r0, r4
  }
   d560e:	bd38      	pop	{r3, r4, r5, pc}

000d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>:
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_INPUTS);
  }
  const flatbuffers::Vector<int32_t> *outputs() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_OUTPUTS);
  }
  BuiltinOptions builtin_options_type() const {
   d5610:	b508      	push	{r3, lr}
    return static_cast<BuiltinOptions>(GetField<uint8_t>(VT_BUILTIN_OPTIONS_TYPE, 0));
   d5612:	2200      	movs	r2, #0
   d5614:	210a      	movs	r1, #10
   d5616:	f7ff fff1 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
  }
   d561a:	bd08      	pop	{r3, pc}

000d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>:
    // If the field we're accessing is outside the vtable, we're reading older
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
   d561c:	b538      	push	{r3, r4, r5, lr}
   d561e:	4605      	mov	r5, r0
   d5620:	4614      	mov	r4, r2
    auto field_offset = GetOptionalFieldOffset(field);
   d5622:	f7ff ffb5 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d5626:	b108      	cbz	r0, d562c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_+0x10>
   d5628:	5828      	ldr	r0, [r5, r0]
   d562a:	bd38      	pop	{r3, r4, r5, pc}
   d562c:	4620      	mov	r0, r4
  }
   d562e:	bd38      	pop	{r3, r4, r5, pc}

000d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>:
    // If the field we're accessing is outside the vtable, we're reading older
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
   d5630:	b538      	push	{r3, r4, r5, lr}
   d5632:	4605      	mov	r5, r0
   d5634:	4614      	mov	r4, r2
    auto field_offset = GetOptionalFieldOffset(field);
   d5636:	f7ff ffab 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d563a:	b108      	cbz	r0, d5640 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_+0x10>
   d563c:	5628      	ldrsb	r0, [r5, r0]
   d563e:	bd38      	pop	{r3, r4, r5, pc}
   d5640:	4620      	mov	r0, r4
  }
   d5642:	bd38      	pop	{r3, r4, r5, pc}

000d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>:
    // If the field we're accessing is outside the vtable, we're reading older
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
   d5644:	b510      	push	{r4, lr}
   d5646:	ed2d 8b02 	vpush	{d8}
   d564a:	4604      	mov	r4, r0
   d564c:	eeb0 8a40 	vmov.f32	s16, s0
    auto field_offset = GetOptionalFieldOffset(field);
   d5650:	f7ff ff9e 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d5654:	b118      	cbz	r0, d565e <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_+0x1a>
   d5656:	4420      	add	r0, r4
   d5658:	ed90 0a00 	vldr	s0, [r0]
   d565c:	e001      	b.n	d5662 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_+0x1e>
   d565e:	eeb0 0a48 	vmov.f32	s0, s16
  }
   d5662:	ecbd 8b02 	vpop	{d8}
   d5666:	bd10      	pop	{r4, pc}

000d5668 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorIlEEEET_t>:

  template<typename P> P GetPointer(voffset_t field) {
   d5668:	b510      	push	{r4, lr}
   d566a:	4604      	mov	r4, r0
    auto field_offset = GetOptionalFieldOffset(field);
   d566c:	f7ff ff90 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    auto p = data_ + field_offset;
   d5670:	1822      	adds	r2, r4, r0
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
   d5672:	b108      	cbz	r0, d5678 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorIlEEEET_t+0x10>
   d5674:	5823      	ldr	r3, [r4, r0]
   d5676:	18d0      	adds	r0, r2, r3
  }
   d5678:	bd10      	pop	{r4, pc}

000d567a <_ZNK6tflite8Operator15builtin_optionsEv>:
  const void *builtin_options() const {
   d567a:	b508      	push	{r3, lr}
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d567c:	210c      	movs	r1, #12
   d567e:	f7ff fff3 	bl	d5668 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorIlEEEET_t>
    return GetPointer<const void *>(VT_BUILTIN_OPTIONS);
  }
   d5682:	bd08      	pop	{r3, pc}

000d5684 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI23TfLiteSequenceRNNParamsEEPT_v>:
  // extension part will take ownership so destructors  will not be run during
  // deallocation.
  template <typename T>
  T* AllocatePOD() {
    static_assert(std::is_pod<T>::value, "Builtin data structure must be POD.");
    return static_cast<T*>(this->Allocate(sizeof(T)));
   d5684:	6803      	ldr	r3, [r0, #0]
   d5686:	2102      	movs	r1, #2
   d5688:	681b      	ldr	r3, [r3, #0]
   d568a:	4718      	bx	r3

000d568c <_ZN6tflite20BuiltinDataAllocator11AllocatePODI26TfLiteFullyConnectedParamsEEPT_v>:
   d568c:	6803      	ldr	r3, [r0, #0]
   d568e:	2103      	movs	r1, #3
   d5690:	681b      	ldr	r3, [r3, #0]
   d5692:	4718      	bx	r3

000d5694 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI19TfLiteSqueezeParamsEEPT_v>:
   d5694:	6803      	ldr	r3, [r0, #0]
   d5696:	2124      	movs	r1, #36	; 0x24
   d5698:	681b      	ldr	r3, [r3, #0]
   d569a:	4718      	bx	r3

000d569c <_ZN6tflite20BuiltinDataAllocator11AllocatePODI25TfLiteTransposeConvParamsEEPT_v>:
   d569c:	6803      	ldr	r3, [r0, #0]
   d569e:	210c      	movs	r1, #12
   d56a0:	681b      	ldr	r3, [r3, #0]
   d56a2:	4718      	bx	r3

000d56a4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteFakeQuantParamsEEPT_v>:
   d56a4:	6803      	ldr	r3, [r0, #0]
   d56a6:	2110      	movs	r1, #16
   d56a8:	681b      	ldr	r3, [r3, #0]
   d56aa:	4718      	bx	r3

000d56ac <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteLeakyReluParamsEEPT_v>:
   d56ac:	6803      	ldr	r3, [r0, #0]
   d56ae:	2104      	movs	r1, #4
   d56b0:	681b      	ldr	r3, [r3, #0]
   d56b2:	4718      	bx	r3

000d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>:
   d56b4:	6803      	ldr	r3, [r0, #0]
   d56b6:	2101      	movs	r1, #1
   d56b8:	681b      	ldr	r3, [r3, #0]
   d56ba:	4718      	bx	r3

000d56bc <_ZN6tflite20BuiltinDataAllocator11AllocatePODI27TfLiteReverseSequenceParamsEEPT_v>:
   d56bc:	6803      	ldr	r3, [r0, #0]
   d56be:	2108      	movs	r1, #8
   d56c0:	681b      	ldr	r3, [r3, #0]
   d56c2:	4718      	bx	r3

000d56c4 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv>:
// If it returns kTfLiteOk, it passes the data out with `builtin_data`, which
// need to be released by calling `free`.`
// If it returns kTfLiteError, `builtin_data` will be `nullptr`.
TfLiteStatus ParseOpData(const Operator* op, BuiltinOperator op_type,
                         ErrorReporter* error_reporter,
                         BuiltinDataAllocator* allocator, void** builtin_data) {
   d56c4:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
   d56c8:	9e08      	ldr	r6, [sp, #32]
   d56ca:	461d      	mov	r5, r3
        return kTfLiteCombinerTypeSum;
    }
  };

  SafeBuiltinDataAllocator safe_allocator(allocator);
  *builtin_data = nullptr;
   d56cc:	2300      	movs	r3, #0
// If it returns kTfLiteOk, it passes the data out with `builtin_data`, which
// need to be released by calling `free`.`
// If it returns kTfLiteError, `builtin_data` will be `nullptr`.
TfLiteStatus ParseOpData(const Operator* op, BuiltinOperator op_type,
                         ErrorReporter* error_reporter,
                         BuiltinDataAllocator* allocator, void** builtin_data) {
   d56ce:	4604      	mov	r4, r0
   d56d0:	4617      	mov	r7, r2
        return kTfLiteCombinerTypeSum;
    }
  };

  SafeBuiltinDataAllocator safe_allocator(allocator);
  *builtin_data = nullptr;
   d56d2:	6033      	str	r3, [r6, #0]
   d56d4:	4698      	mov	r8, r3
  switch (op_type) {
   d56d6:	2977      	cmp	r1, #119	; 0x77
   d56d8:	f200 870b 	bhi.w	d64f2 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2e>
   d56dc:	e8df f011 	tbh	[pc, r1, lsl #1]
   d56e0:	010402be 	.word	0x010402be
   d56e4:	00780283 	.word	0x00780283
   d56e8:	048f0142 	.word	0x048f0142
   d56ec:	07090709 	.word	0x07090709
   d56f0:	02300709 	.word	0x02300709
   d56f4:	030b0709 	.word	0x030b0709
   d56f8:	03240104 	.word	0x03240104
   d56fc:	00e60709 	.word	0x00e60709
   d5700:	01040353 	.word	0x01040353
   d5704:	070902a4 	.word	0x070902a4
   d5708:	07090709 	.word	0x07090709
   d570c:	0400043b 	.word	0x0400043b
   d5710:	026a01f9 	.word	0x026a01f9
   d5714:	01860479 	.word	0x01860479
   d5718:	07090709 	.word	0x07090709
   d571c:	07090453 	.word	0x07090453
   d5720:	02130709 	.word	0x02130709
   d5724:	01a80709 	.word	0x01a80709
   d5728:	070904a5 	.word	0x070904a5
   d572c:	07090709 	.word	0x07090709
   d5730:	02f204bd 	.word	0x02f204bd
   d5734:	050202d8 	.word	0x050202d8
   d5738:	05280391 	.word	0x05280391
   d573c:	070901cc 	.word	0x070901cc
   d5740:	04d60709 	.word	0x04d60709
   d5744:	06070709 	.word	0x06070709
   d5748:	00b703c4 	.word	0x00b703c4
   d574c:	07090709 	.word	0x07090709
   d5750:	07090559 	.word	0x07090559
   d5754:	07090709 	.word	0x07090709
   d5758:	07090709 	.word	0x07090709
   d575c:	07090709 	.word	0x07090709
   d5760:	07090709 	.word	0x07090709
   d5764:	058d0709 	.word	0x058d0709
   d5768:	070905b3 	.word	0x070905b3
   d576c:	07090709 	.word	0x07090709
   d5770:	07090709 	.word	0x07090709
   d5774:	070904bd 	.word	0x070904bd
   d5778:	05cc0709 	.word	0x05cc0709
   d577c:	05730709 	.word	0x05730709
   d5780:	04bd060d 	.word	0x04bd060d
   d5784:	05ea04bd 	.word	0x05ea04bd
   d5788:	063d0709 	.word	0x063d0709
   d578c:	07090709 	.word	0x07090709
   d5790:	04bd0653 	.word	0x04bd0653
   d5794:	04bd0709 	.word	0x04bd0709
   d5798:	07090709 	.word	0x07090709
   d579c:	07090709 	.word	0x07090709
   d57a0:	04220709 	.word	0x04220709
   d57a4:	07090670 	.word	0x07090670
   d57a8:	07090688 	.word	0x07090688
   d57ac:	06a104ec 	.word	0x06a104ec
   d57b0:	07090709 	.word	0x07090709
   d57b4:	07090709 	.word	0x07090709
   d57b8:	07090709 	.word	0x07090709
   d57bc:	07090709 	.word	0x07090709
   d57c0:	070906ba 	.word	0x070906ba
   d57c4:	07090709 	.word	0x07090709
   d57c8:	07090709 	.word	0x07090709
   d57cc:	06ef06d5 	.word	0x06ef06d5
   d57d0:	682b      	ldr	r3, [r5, #0]
   d57d2:	2118      	movs	r1, #24
   d57d4:	681b      	ldr	r3, [r3, #0]
   d57d6:	4628      	mov	r0, r5
   d57d8:	4798      	blx	r3
   d57da:	4605      	mov	r5, r0
  template<typename T> const T *builtin_options_as() const;
  const Conv2DOptions *builtin_options_as_Conv2DOptions() const {
    return builtin_options_type() == BuiltinOptions_Conv2DOptions ? static_cast<const Conv2DOptions *>(builtin_options()) : nullptr;
   d57dc:	4620      	mov	r0, r4
   d57de:	f7ff ff17 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d57e2:	2801      	cmp	r0, #1
   d57e4:	4607      	mov	r7, r0
   d57e6:	f040 8683 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d57ea:	4620      	mov	r0, r4
   d57ec:	f7ff ff45 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
    case BuiltinOperator_CONV_2D: {
      auto params = safe_allocator.Allocate<TfLiteConvParams>();
      if (auto* conv_params = op->builtin_options_as_Conv2DOptions()) {
   d57f0:	4604      	mov	r4, r0
   d57f2:	2800      	cmp	r0, #0
   d57f4:	f000 867c 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
    VT_FUSED_ACTIVATION_FUNCTION = 10,
    VT_DILATION_W_FACTOR = 12,
    VT_DILATION_H_FACTOR = 14
  };
  Padding padding() const {
    return static_cast<Padding>(GetField<int8_t>(VT_PADDING, 0));
   d57f8:	2200      	movs	r2, #0
   d57fa:	2104      	movs	r1, #4
   d57fc:	f7ff ff18 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->padding = parse_padding(conv_params->padding());
   d5800:	b2c0      	uxtb	r0, r0
   d5802:	f7ff fe85 	bl	d5510 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_7PaddingEE_clESA_.isra.0>
  }
  int32_t stride_w() const {
    return GetField<int32_t>(VT_STRIDE_W, 0);
   d5806:	2200      	movs	r2, #0
   d5808:	7028      	strb	r0, [r5, #0]
   d580a:	2106      	movs	r1, #6
   d580c:	4620      	mov	r0, r4
   d580e:	f7ff ff05 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t stride_h() const {
    return GetField<int32_t>(VT_STRIDE_H, 0);
   d5812:	2200      	movs	r2, #0
        params->stride_width = conv_params->stride_w();
   d5814:	6068      	str	r0, [r5, #4]
   d5816:	2108      	movs	r1, #8
   d5818:	4620      	mov	r0, r4
   d581a:	f7ff feff 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d581e:	2200      	movs	r2, #0
   d5820:	210a      	movs	r1, #10
        params->stride_height = conv_params->stride_h();
   d5822:	60a8      	str	r0, [r5, #8]
   d5824:	4620      	mov	r0, r4
   d5826:	f7ff ff03 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(conv_params->fused_activation_function());
   d582a:	b2c0      	uxtb	r0, r0
   d582c:	f7ff fe78 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
  }
  int32_t dilation_w_factor() const {
    return GetField<int32_t>(VT_DILATION_W_FACTOR, 1);
   d5830:	463a      	mov	r2, r7
   d5832:	7528      	strb	r0, [r5, #20]
   d5834:	210c      	movs	r1, #12
   d5836:	4620      	mov	r0, r4
   d5838:	f7ff fef0 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t dilation_h_factor() const {
    return GetField<int32_t>(VT_DILATION_H_FACTOR, 1);
   d583c:	463a      	mov	r2, r7

        params->dilation_width_factor = conv_params->dilation_w_factor();
   d583e:	60e8      	str	r0, [r5, #12]
   d5840:	210e      	movs	r1, #14
   d5842:	4620      	mov	r0, r4
   d5844:	f7ff feea 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->dilation_height_factor = conv_params->dilation_h_factor();
   d5848:	6128      	str	r0, [r5, #16]
   d584a:	f000 be51 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d584e:	4628      	mov	r0, r5
   d5850:	f7ff ff18 	bl	d5684 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI23TfLiteSequenceRNNParamsEEPT_v>
   d5854:	4680      	mov	r8, r0
  }
  const LogSoftmaxOptions *builtin_options_as_LogSoftmaxOptions() const {
    return builtin_options_type() == BuiltinOptions_LogSoftmaxOptions ? static_cast<const LogSoftmaxOptions *>(builtin_options()) : nullptr;
  }
  const CastOptions *builtin_options_as_CastOptions() const {
    return builtin_options_type() == BuiltinOptions_CastOptions ? static_cast<const CastOptions *>(builtin_options()) : nullptr;
   d5856:	4620      	mov	r0, r4
      constexpr _Head_base(const _Head_base&) = default;
      constexpr _Head_base(_Head_base&&) = default;

      template<typename _UHead>
        constexpr _Head_base(_UHead&& __h)
	: _M_head_impl(std::forward<_UHead>(__h)) { }
   d5858:	e88d 0120 	stmia.w	sp, {r5, r8}
   d585c:	f7ff fed8 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5860:	2825      	cmp	r0, #37	; 0x25
   d5862:	f040 8462 	bne.w	d612a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa66>
   d5866:	4620      	mov	r0, r4
   d5868:	f7ff ff07 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_CAST: {
      auto params = safe_allocator.Allocate<TfLiteCastParams>();
      if (const auto* schema_params = op->builtin_options_as_CastOptions()) {
   d586c:	4605      	mov	r5, r0
   d586e:	2800      	cmp	r0, #0
   d5870:	f000 845b 	beq.w	d612a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa66>
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_IN_DATA_TYPE = 4,
    VT_OUT_DATA_TYPE = 6
  };
  TensorType in_data_type() const {
    return static_cast<TensorType>(GetField<int8_t>(VT_IN_DATA_TYPE, 0));
   d5874:	2200      	movs	r2, #0
   d5876:	2104      	movs	r1, #4
   d5878:	f7ff feda 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        auto in_status =
            ConvertTensorType(schema_params->in_data_type(),
                              &params->in_data_type, error_reporter);
   d587c:	463a      	mov	r2, r7
   d587e:	4641      	mov	r1, r8
   d5880:	b2c0      	uxtb	r0, r0
   d5882:	f7ff fe8d 	bl	d55a0 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE>
  }
  TensorType out_data_type() const {
    return static_cast<TensorType>(GetField<int8_t>(VT_OUT_DATA_TYPE, 0));
   d5886:	2200      	movs	r2, #0
   d5888:	4604      	mov	r4, r0
   d588a:	2106      	movs	r1, #6
   d588c:	4628      	mov	r0, r5
   d588e:	f7ff fecf 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        auto out_status =
            ConvertTensorType(schema_params->out_data_type(),
                              &params->out_data_type, error_reporter);
   d5892:	9901      	ldr	r1, [sp, #4]
   d5894:	463a      	mov	r2, r7
   d5896:	3101      	adds	r1, #1
   d5898:	b2c0      	uxtb	r0, r0
   d589a:	f7ff fe81 	bl	d55a0 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE>
        if (in_status != kTfLiteOk || out_status != kTfLiteOk) {
   d589e:	2c00      	cmp	r4, #0
   d58a0:	f040 8186 	bne.w	d5bb0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x4ec>
   d58a4:	2800      	cmp	r0, #0
   d58a6:	f000 8440 	beq.w	d612a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa66>
   d58aa:	e181      	b.n	d5bb0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x4ec>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d58ac:	4628      	mov	r0, r5
   d58ae:	f7ff ff01 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d58b2:	4605      	mov	r5, r0
  }
  const ConcatEmbeddingsOptions *builtin_options_as_ConcatEmbeddingsOptions() const {
    return builtin_options_type() == BuiltinOptions_ConcatEmbeddingsOptions ? static_cast<const ConcatEmbeddingsOptions *>(builtin_options()) : nullptr;
  }
  const LSHProjectionOptions *builtin_options_as_LSHProjectionOptions() const {
    return builtin_options_type() == BuiltinOptions_LSHProjectionOptions ? static_cast<const LSHProjectionOptions *>(builtin_options()) : nullptr;
   d58b4:	4620      	mov	r0, r4
   d58b6:	f7ff feab 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d58ba:	2804      	cmp	r0, #4
   d58bc:	4607      	mov	r7, r0
   d58be:	f040 8617 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d58c2:	4620      	mov	r0, r4
   d58c4:	f7ff fed9 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_LSH_PROJECTION: {
      auto params = safe_allocator.Allocate<TfLiteLSHProjectionParams>();
      if (const auto* lshParams =
   d58c8:	2800      	cmp	r0, #0
   d58ca:	f000 8611 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef LSHProjectionOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TYPE = 4
  };
  LSHProjectionType type() const {
    return static_cast<LSHProjectionType>(GetField<int8_t>(VT_TYPE, 0));
   d58ce:	2200      	movs	r2, #0
   d58d0:	4639      	mov	r1, r7
   d58d2:	f7ff fead 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
      default:
        return kTfLiteLshProjectionUnknown;
    }
  };
  auto parseCombinerType = [](CombinerType type) {
    switch (type) {
   d58d6:	2801      	cmp	r0, #1
   d58d8:	d003      	beq.n	d58e2 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x21e>
        return kTfLiteCombinerTypeMean;
      case CombinerType_SQRTN:
        return kTfLiteCombinerTypeSqrtn;
      case CombinerType_SUM:
      default:
        return kTfLiteCombinerTypeSum;
   d58da:	2802      	cmp	r0, #2
   d58dc:	bf0c      	ite	eq
   d58de:	2002      	moveq	r0, #2
   d58e0:	2000      	movne	r0, #0
    }
    case BuiltinOperator_LSH_PROJECTION: {
      auto params = safe_allocator.Allocate<TfLiteLSHProjectionParams>();
      if (const auto* lshParams =
              op->builtin_options_as_LSHProjectionOptions()) {
        params->type = parseLSHProjectionType(lshParams->type());
   d58e2:	7028      	strb	r0, [r5, #0]
   d58e4:	f000 be04 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d58e8:	682b      	ldr	r3, [r5, #0]
   d58ea:	2128      	movs	r1, #40	; 0x28
   d58ec:	681b      	ldr	r3, [r3, #0]
   d58ee:	4628      	mov	r0, r5
   d58f0:	4798      	blx	r3
   d58f2:	4605      	mov	r5, r0
  }
  const LSHProjectionOptions *builtin_options_as_LSHProjectionOptions() const {
    return builtin_options_type() == BuiltinOptions_LSHProjectionOptions ? static_cast<const LSHProjectionOptions *>(builtin_options()) : nullptr;
  }
  const Pool2DOptions *builtin_options_as_Pool2DOptions() const {
    return builtin_options_type() == BuiltinOptions_Pool2DOptions ? static_cast<const Pool2DOptions *>(builtin_options()) : nullptr;
   d58f4:	4620      	mov	r0, r4
   d58f6:	f7ff fe8b 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d58fa:	2805      	cmp	r0, #5
   d58fc:	f040 85f8 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5900:	4620      	mov	r0, r4
   d5902:	f7ff feba 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
    }
    case BuiltinOperator_AVERAGE_POOL_2D:
    case BuiltinOperator_MAX_POOL_2D:
    case BuiltinOperator_L2_POOL_2D: {
      auto params = safe_allocator.Allocate<TfLitePoolParams>();
      if (const auto* pool_params = op->builtin_options_as_Pool2DOptions()) {
   d5906:	4604      	mov	r4, r0
   d5908:	2800      	cmp	r0, #0
   d590a:	f000 85f1 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
    VT_FILTER_WIDTH = 10,
    VT_FILTER_HEIGHT = 12,
    VT_FUSED_ACTIVATION_FUNCTION = 14
  };
  Padding padding() const {
    return static_cast<Padding>(GetField<int8_t>(VT_PADDING, 0));
   d590e:	2200      	movs	r2, #0
   d5910:	2104      	movs	r1, #4
   d5912:	f7ff fe8d 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->padding = parse_padding(pool_params->padding());
   d5916:	b2c0      	uxtb	r0, r0
   d5918:	f7ff fdfa 	bl	d5510 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_7PaddingEE_clESA_.isra.0>
  }
  int32_t stride_w() const {
    return GetField<int32_t>(VT_STRIDE_W, 0);
   d591c:	2200      	movs	r2, #0
   d591e:	7028      	strb	r0, [r5, #0]
   d5920:	2106      	movs	r1, #6
   d5922:	4620      	mov	r0, r4
   d5924:	f7ff fe7a 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t stride_h() const {
    return GetField<int32_t>(VT_STRIDE_H, 0);
   d5928:	2200      	movs	r2, #0
        params->stride_width = pool_params->stride_w();
   d592a:	6068      	str	r0, [r5, #4]
   d592c:	2108      	movs	r1, #8
   d592e:	4620      	mov	r0, r4
   d5930:	f7ff fe74 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t filter_width() const {
    return GetField<int32_t>(VT_FILTER_WIDTH, 0);
   d5934:	2200      	movs	r2, #0
        params->stride_height = pool_params->stride_h();
   d5936:	60a8      	str	r0, [r5, #8]
   d5938:	210a      	movs	r1, #10
   d593a:	4620      	mov	r0, r4
   d593c:	f7ff fe6e 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t filter_height() const {
    return GetField<int32_t>(VT_FILTER_HEIGHT, 0);
   d5940:	2200      	movs	r2, #0
        params->filter_width = pool_params->filter_width();
   d5942:	60e8      	str	r0, [r5, #12]
   d5944:	210c      	movs	r1, #12
   d5946:	4620      	mov	r0, r4
   d5948:	f7ff fe68 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d594c:	2200      	movs	r2, #0
        params->filter_height = pool_params->filter_height();
   d594e:	6128      	str	r0, [r5, #16]
   d5950:	210e      	movs	r1, #14
   d5952:	4620      	mov	r0, r4
   d5954:	f7ff fe6c 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(pool_params->fused_activation_function());
   d5958:	b2c0      	uxtb	r0, r0
   d595a:	f7ff fde1 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
   d595e:	7528      	strb	r0, [r5, #20]
   d5960:	f000 bdc6 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5964:	682b      	ldr	r3, [r5, #0]
   d5966:	211c      	movs	r1, #28
   d5968:	681b      	ldr	r3, [r3, #0]
   d596a:	4628      	mov	r0, r5
   d596c:	4798      	blx	r3
   d596e:	4605      	mov	r5, r0
  template<typename T> const T *builtin_options_as() const;
  const Conv2DOptions *builtin_options_as_Conv2DOptions() const {
    return builtin_options_type() == BuiltinOptions_Conv2DOptions ? static_cast<const Conv2DOptions *>(builtin_options()) : nullptr;
  }
  const DepthwiseConv2DOptions *builtin_options_as_DepthwiseConv2DOptions() const {
    return builtin_options_type() == BuiltinOptions_DepthwiseConv2DOptions ? static_cast<const DepthwiseConv2DOptions *>(builtin_options()) : nullptr;
   d5970:	4620      	mov	r0, r4
   d5972:	f7ff fe4d 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5976:	2802      	cmp	r0, #2
   d5978:	f040 85ba 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d597c:	4620      	mov	r0, r4
   d597e:	f7ff fe7c 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_DEPTHWISE_CONV_2D: {
      auto params = safe_allocator.Allocate<TfLiteDepthwiseConvParams>();
      if (const auto* conv_params =
   d5982:	4604      	mov	r4, r0
   d5984:	2800      	cmp	r0, #0
   d5986:	f000 85b3 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
    VT_FUSED_ACTIVATION_FUNCTION = 12,
    VT_DILATION_W_FACTOR = 14,
    VT_DILATION_H_FACTOR = 16
  };
  Padding padding() const {
    return static_cast<Padding>(GetField<int8_t>(VT_PADDING, 0));
   d598a:	2200      	movs	r2, #0
   d598c:	2104      	movs	r1, #4
   d598e:	f7ff fe4f 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
              op->builtin_options_as_DepthwiseConv2DOptions()) {
        params->padding = parse_padding(conv_params->padding());
   d5992:	b2c0      	uxtb	r0, r0
   d5994:	f7ff fdbc 	bl	d5510 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_7PaddingEE_clESA_.isra.0>
  }
  int32_t stride_w() const {
    return GetField<int32_t>(VT_STRIDE_W, 0);
   d5998:	2200      	movs	r2, #0
   d599a:	7028      	strb	r0, [r5, #0]
   d599c:	2106      	movs	r1, #6
   d599e:	4620      	mov	r0, r4
   d59a0:	f7ff fe3c 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t stride_h() const {
    return GetField<int32_t>(VT_STRIDE_H, 0);
   d59a4:	2200      	movs	r2, #0
        params->stride_width = conv_params->stride_w();
   d59a6:	6068      	str	r0, [r5, #4]
   d59a8:	2108      	movs	r1, #8
   d59aa:	4620      	mov	r0, r4
   d59ac:	f7ff fe36 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t depth_multiplier() const {
    return GetField<int32_t>(VT_DEPTH_MULTIPLIER, 0);
   d59b0:	2200      	movs	r2, #0
        params->stride_height = conv_params->stride_h();
   d59b2:	60a8      	str	r0, [r5, #8]
   d59b4:	210a      	movs	r1, #10
   d59b6:	4620      	mov	r0, r4
   d59b8:	f7ff fe30 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d59bc:	2200      	movs	r2, #0
   d59be:	210c      	movs	r1, #12
        params->depth_multiplier = conv_params->depth_multiplier();
   d59c0:	60e8      	str	r0, [r5, #12]
   d59c2:	4620      	mov	r0, r4
   d59c4:	f7ff fe34 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(conv_params->fused_activation_function());
   d59c8:	b2c0      	uxtb	r0, r0
   d59ca:	f7ff fda9 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
  }
  int32_t dilation_w_factor() const {
    return GetField<int32_t>(VT_DILATION_W_FACTOR, 1);
   d59ce:	2201      	movs	r2, #1
   d59d0:	7428      	strb	r0, [r5, #16]
   d59d2:	210e      	movs	r1, #14
   d59d4:	4620      	mov	r0, r4
   d59d6:	f7ff fe21 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t dilation_h_factor() const {
    return GetField<int32_t>(VT_DILATION_H_FACTOR, 1);
   d59da:	2201      	movs	r2, #1

        params->dilation_width_factor = conv_params->dilation_w_factor();
   d59dc:	6168      	str	r0, [r5, #20]
   d59de:	2110      	movs	r1, #16
   d59e0:	4620      	mov	r0, r4
   d59e2:	f7ff fe1b 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->dilation_height_factor = conv_params->dilation_h_factor();
   d59e6:	61a8      	str	r0, [r5, #24]
   d59e8:	f000 bd82 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d59ec:	4628      	mov	r0, r5
   d59ee:	f7ff fe65 	bl	d56bc <_ZN6tflite20BuiltinDataAllocator11AllocatePODI27TfLiteReverseSequenceParamsEEPT_v>
   d59f2:	4605      	mov	r5, r0
  }
  const Pool2DOptions *builtin_options_as_Pool2DOptions() const {
    return builtin_options_type() == BuiltinOptions_Pool2DOptions ? static_cast<const Pool2DOptions *>(builtin_options()) : nullptr;
  }
  const SVDFOptions *builtin_options_as_SVDFOptions() const {
    return builtin_options_type() == BuiltinOptions_SVDFOptions ? static_cast<const SVDFOptions *>(builtin_options()) : nullptr;
   d59f4:	4620      	mov	r0, r4
   d59f6:	f7ff fe0b 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d59fa:	2806      	cmp	r0, #6
   d59fc:	4607      	mov	r7, r0
   d59fe:	f040 8577 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5a02:	4620      	mov	r0, r4
   d5a04:	f7ff fe39 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_SVDF: {
      auto params = safe_allocator.Allocate<TfLiteSVDFParams>();
      if (const auto* svdf_params = op->builtin_options_as_SVDFOptions()) {
   d5a08:	4604      	mov	r4, r0
   d5a0a:	2800      	cmp	r0, #0
   d5a0c:	f000 8570 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_RANK = 4,
    VT_FUSED_ACTIVATION_FUNCTION = 6
  };
  int32_t rank() const {
    return GetField<int32_t>(VT_RANK, 0);
   d5a10:	2200      	movs	r2, #0
   d5a12:	2104      	movs	r1, #4
   d5a14:	f7ff fe02 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5a18:	2200      	movs	r2, #0
        params->rank = svdf_params->rank();
   d5a1a:	6028      	str	r0, [r5, #0]
   d5a1c:	4639      	mov	r1, r7
   d5a1e:	4620      	mov	r0, r4
   d5a20:	f7ff fe06 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(svdf_params->fused_activation_function());
   d5a24:	b2c0      	uxtb	r0, r0
   d5a26:	f7ff fd7b 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
   d5a2a:	7128      	strb	r0, [r5, #4]
   d5a2c:	f000 bd60 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5a30:	4628      	mov	r0, r5
   d5a32:	f7ff fe27 	bl	d5684 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI23TfLiteSequenceRNNParamsEEPT_v>
   d5a36:	4605      	mov	r5, r0
  }
  const SqueezeOptions *builtin_options_as_SqueezeOptions() const {
    return builtin_options_type() == BuiltinOptions_SqueezeOptions ? static_cast<const SqueezeOptions *>(builtin_options()) : nullptr;
  }
  const SequenceRNNOptions *builtin_options_as_SequenceRNNOptions() const {
    return builtin_options_type() == BuiltinOptions_SequenceRNNOptions ? static_cast<const SequenceRNNOptions *>(builtin_options()) : nullptr;
   d5a38:	4620      	mov	r0, r4
   d5a3a:	f7ff fde9 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5a3e:	281f      	cmp	r0, #31
   d5a40:	f040 8556 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5a44:	4620      	mov	r0, r4
   d5a46:	f7ff fe18 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_UNIDIRECTIONAL_SEQUENCE_RNN: {
      auto params = safe_allocator.Allocate<TfLiteSequenceRNNParams>();
      if (const auto* sequence_rnn_params =
   d5a4a:	4604      	mov	r4, r0
   d5a4c:	2800      	cmp	r0, #0
   d5a4e:	f000 854f 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  };
  bool time_major() const {
    return GetField<uint8_t>(VT_TIME_MAJOR, 0) != 0;
  }
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5a52:	2200      	movs	r2, #0
   d5a54:	2106      	movs	r1, #6
   d5a56:	f7ff fdeb 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
              op->builtin_options_as_SequenceRNNOptions()) {
        params->activation =
            parse_activation(sequence_rnn_params->fused_activation_function());
   d5a5a:	b2c0      	uxtb	r0, r0
   d5a5c:	f7ff fd60 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TIME_MAJOR = 4,
    VT_FUSED_ACTIVATION_FUNCTION = 6
  };
  bool time_major() const {
    return GetField<uint8_t>(VT_TIME_MAJOR, 0) != 0;
   d5a60:	2200      	movs	r2, #0
   d5a62:	7068      	strb	r0, [r5, #1]
   d5a64:	2104      	movs	r1, #4
   d5a66:	4620      	mov	r0, r4
   d5a68:	f7ff fdc8 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
        params->time_major = sequence_rnn_params->time_major();
   d5a6c:	3000      	adds	r0, #0
   d5a6e:	bf18      	it	ne
   d5a70:	2001      	movne	r0, #1
   d5a72:	7028      	strb	r0, [r5, #0]
   d5a74:	f000 bd3c 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5a78:	4628      	mov	r0, r5
   d5a7a:	f7ff fe07 	bl	d568c <_ZN6tflite20BuiltinDataAllocator11AllocatePODI26TfLiteFullyConnectedParamsEEPT_v>
   d5a7e:	4605      	mov	r5, r0
  }
  const BidirectionalSequenceLSTMOptions *builtin_options_as_BidirectionalSequenceLSTMOptions() const {
    return builtin_options_type() == BuiltinOptions_BidirectionalSequenceLSTMOptions ? static_cast<const BidirectionalSequenceLSTMOptions *>(builtin_options()) : nullptr;
  }
  const BidirectionalSequenceRNNOptions *builtin_options_as_BidirectionalSequenceRNNOptions() const {
    return builtin_options_type() == BuiltinOptions_BidirectionalSequenceRNNOptions ? static_cast<const BidirectionalSequenceRNNOptions *>(builtin_options()) : nullptr;
   d5a80:	4620      	mov	r0, r4
   d5a82:	f7ff fdc5 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5a86:	2846      	cmp	r0, #70	; 0x46
   d5a88:	f040 8532 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5a8c:	4620      	mov	r0, r4
   d5a8e:	f7ff fdf4 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      break;
    }
    case BuiltinOperator_BIDIRECTIONAL_SEQUENCE_RNN: {
      auto params =
          safe_allocator.Allocate<TfLiteBidirectionalSequenceRNNParams>();
      if (const auto* bidi_sequence_rnn_params =
   d5a92:	4604      	mov	r4, r0
   d5a94:	2800      	cmp	r0, #0
   d5a96:	f000 852b 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  };
  bool time_major() const {
    return GetField<uint8_t>(VT_TIME_MAJOR, 0) != 0;
  }
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5a9a:	2200      	movs	r2, #0
   d5a9c:	2106      	movs	r1, #6
   d5a9e:	f7ff fdc7 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
              op->builtin_options_as_BidirectionalSequenceRNNOptions()) {
        params->activation = parse_activation(
   d5aa2:	b2c0      	uxtb	r0, r0
   d5aa4:	f7ff fd3c 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
    VT_TIME_MAJOR = 4,
    VT_FUSED_ACTIVATION_FUNCTION = 6,
    VT_MERGE_OUTPUTS = 8
  };
  bool time_major() const {
    return GetField<uint8_t>(VT_TIME_MAJOR, 0) != 0;
   d5aa8:	2200      	movs	r2, #0
            bidi_sequence_rnn_params->fused_activation_function());
   d5aaa:	7068      	strb	r0, [r5, #1]
   d5aac:	2104      	movs	r1, #4
   d5aae:	4620      	mov	r0, r4
   d5ab0:	f7ff fda4 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
        params->time_major = bidi_sequence_rnn_params->time_major();
   d5ab4:	3000      	adds	r0, #0
   d5ab6:	bf18      	it	ne
   d5ab8:	2001      	movne	r0, #1
   d5aba:	7028      	strb	r0, [r5, #0]
  }
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
  }
  bool merge_outputs() const {
    return GetField<uint8_t>(VT_MERGE_OUTPUTS, 0) != 0;
   d5abc:	2200      	movs	r2, #0
   d5abe:	2108      	movs	r1, #8
   d5ac0:	4620      	mov	r0, r4
   d5ac2:	f7ff fd9b 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
        params->merge_outputs = bidi_sequence_rnn_params->merge_outputs();
   d5ac6:	3000      	adds	r0, #0
   d5ac8:	bf18      	it	ne
   d5aca:	2001      	movne	r0, #1
   d5acc:	70a8      	strb	r0, [r5, #2]
   d5ace:	f000 bd0f 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5ad2:	4628      	mov	r0, r5
   d5ad4:	f7ff fdee 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d5ad8:	4605      	mov	r5, r0
  }
  const SVDFOptions *builtin_options_as_SVDFOptions() const {
    return builtin_options_type() == BuiltinOptions_SVDFOptions ? static_cast<const SVDFOptions *>(builtin_options()) : nullptr;
  }
  const RNNOptions *builtin_options_as_RNNOptions() const {
    return builtin_options_type() == BuiltinOptions_RNNOptions ? static_cast<const RNNOptions *>(builtin_options()) : nullptr;
   d5ada:	4620      	mov	r0, r4
   d5adc:	f7ff fd98 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5ae0:	2807      	cmp	r0, #7
   d5ae2:	f040 8505 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5ae6:	4620      	mov	r0, r4
   d5ae8:	f7ff fdc7 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_RNN: {
      auto params = safe_allocator.Allocate<TfLiteRNNParams>();
      if (const auto* rnn_params = op->builtin_options_as_RNNOptions()) {
   d5aec:	2800      	cmp	r0, #0
   d5aee:	f000 84ff 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef RNNOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_FUSED_ACTIVATION_FUNCTION = 4
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5af2:	2200      	movs	r2, #0
   d5af4:	2104      	movs	r1, #4
   d5af6:	f7ff fd9b 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(rnn_params->fused_activation_function());
   d5afa:	b2c0      	uxtb	r0, r0
   d5afc:	f7ff fd10 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
   d5b00:	7028      	strb	r0, [r5, #0]
   d5b02:	f000 bcf5 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5b06:	4628      	mov	r0, r5
   d5b08:	f7ff fdd4 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d5b0c:	4605      	mov	r5, r0
  }
  const SpaceToDepthOptions *builtin_options_as_SpaceToDepthOptions() const {
    return builtin_options_type() == BuiltinOptions_SpaceToDepthOptions ? static_cast<const SpaceToDepthOptions *>(builtin_options()) : nullptr;
  }
  const EmbeddingLookupSparseOptions *builtin_options_as_EmbeddingLookupSparseOptions() const {
    return builtin_options_type() == BuiltinOptions_EmbeddingLookupSparseOptions ? static_cast<const EmbeddingLookupSparseOptions *>(builtin_options()) : nullptr;
   d5b0e:	4620      	mov	r0, r4
   d5b10:	f7ff fd7e 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5b14:	2814      	cmp	r0, #20
   d5b16:	f040 84eb 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5b1a:	4620      	mov	r0, r4
   d5b1c:	f7ff fdad 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      break;
    }
    case BuiltinOperator_EMBEDDING_LOOKUP_SPARSE: {
      auto params =
          safe_allocator.Allocate<TfLiteEmbeddingLookupSparseParams>();
      if (const auto* embedding_params =
   d5b20:	2800      	cmp	r0, #0
   d5b22:	f000 84e5 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef EmbeddingLookupSparseOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_COMBINER = 4
  };
  CombinerType combiner() const {
    return static_cast<CombinerType>(GetField<int8_t>(VT_COMBINER, 0));
   d5b26:	2200      	movs	r2, #0
   d5b28:	2104      	movs	r1, #4
   d5b2a:	f7ff fd81 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
      default:
        return kTfLiteLshProjectionUnknown;
    }
  };
  auto parseCombinerType = [](CombinerType type) {
    switch (type) {
   d5b2e:	2801      	cmp	r0, #1
   d5b30:	d003      	beq.n	d5b3a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x476>
        return kTfLiteCombinerTypeMean;
      case CombinerType_SQRTN:
        return kTfLiteCombinerTypeSqrtn;
      case CombinerType_SUM:
      default:
        return kTfLiteCombinerTypeSum;
   d5b32:	2802      	cmp	r0, #2
   d5b34:	bf0c      	ite	eq
   d5b36:	2002      	moveq	r0, #2
   d5b38:	2000      	movne	r0, #0
    case BuiltinOperator_EMBEDDING_LOOKUP_SPARSE: {
      auto params =
          safe_allocator.Allocate<TfLiteEmbeddingLookupSparseParams>();
      if (const auto* embedding_params =
              op->builtin_options_as_EmbeddingLookupSparseOptions()) {
        params->combiner = parseCombinerType(embedding_params->combiner());
   d5b3a:	7028      	strb	r0, [r5, #0]
   d5b3c:	f000 bcd8 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5b40:	4628      	mov	r0, r5
   d5b42:	f7ff fda3 	bl	d568c <_ZN6tflite20BuiltinDataAllocator11AllocatePODI26TfLiteFullyConnectedParamsEEPT_v>
   d5b46:	4680      	mov	r8, r0
  }
  const RNNOptions *builtin_options_as_RNNOptions() const {
    return builtin_options_type() == BuiltinOptions_RNNOptions ? static_cast<const RNNOptions *>(builtin_options()) : nullptr;
  }
  const FullyConnectedOptions *builtin_options_as_FullyConnectedOptions() const {
    return builtin_options_type() == BuiltinOptions_FullyConnectedOptions ? static_cast<const FullyConnectedOptions *>(builtin_options()) : nullptr;
   d5b48:	4620      	mov	r0, r4
   d5b4a:	e88d 0120 	stmia.w	sp, {r5, r8}
   d5b4e:	f7ff fd5f 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5b52:	2808      	cmp	r0, #8
   d5b54:	4605      	mov	r5, r0
   d5b56:	f040 82e8 	bne.w	d612a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa66>
   d5b5a:	4620      	mov	r0, r4
   d5b5c:	f7ff fd8d 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_FULLY_CONNECTED: {
      auto params = safe_allocator.Allocate<TfLiteFullyConnectedParams>();
      if (const auto* fully_connected_params =
   d5b60:	4604      	mov	r4, r0
   d5b62:	2800      	cmp	r0, #0
   d5b64:	f000 82e1 	beq.w	d612a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa66>
    VT_FUSED_ACTIVATION_FUNCTION = 4,
    VT_WEIGHTS_FORMAT = 6,
    VT_KEEP_NUM_DIMS = 8
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5b68:	2200      	movs	r2, #0
   d5b6a:	2104      	movs	r1, #4
   d5b6c:	f7ff fd60 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
              op->builtin_options_as_FullyConnectedOptions()) {
        params->activation = parse_activation(
   d5b70:	b2c0      	uxtb	r0, r0
   d5b72:	f7ff fcd5 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
  }
  FullyConnectedOptionsWeightsFormat weights_format() const {
    return static_cast<FullyConnectedOptionsWeightsFormat>(GetField<int8_t>(VT_WEIGHTS_FORMAT, 0));
  }
  bool keep_num_dims() const {
    return GetField<uint8_t>(VT_KEEP_NUM_DIMS, 0) != 0;
   d5b76:	2200      	movs	r2, #0
            fully_connected_params->fused_activation_function());
   d5b78:	f888 0000 	strb.w	r0, [r8]
   d5b7c:	4629      	mov	r1, r5
   d5b7e:	4620      	mov	r0, r4
   d5b80:	f7ff fd3c 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
      }

      /// Return the stored pointer.
      pointer
      get() const noexcept
      { return std::get<0>(_M_t); }
   d5b84:	f8dd 8004 	ldr.w	r8, [sp, #4]
        params->keep_num_dims = fully_connected_params->keep_num_dims();
   d5b88:	3000      	adds	r0, #0
   d5b8a:	bf18      	it	ne
   d5b8c:	2001      	movne	r0, #1
   d5b8e:	f888 0002 	strb.w	r0, [r8, #2]
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
  }
  FullyConnectedOptionsWeightsFormat weights_format() const {
    return static_cast<FullyConnectedOptionsWeightsFormat>(GetField<int8_t>(VT_WEIGHTS_FORMAT, 0));
   d5b92:	2200      	movs	r2, #0
   d5b94:	2106      	movs	r1, #6
   d5b96:	4620      	mov	r0, r4
   d5b98:	f7ff fd4a 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        switch (fully_connected_params->weights_format()) {
   d5b9c:	b108      	cbz	r0, d5ba2 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x4de>
   d5b9e:	2801      	cmp	r0, #1
   d5ba0:	d102      	bne.n	d5ba8 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x4e4>
   d5ba2:	9b01      	ldr	r3, [sp, #4]
          case FullyConnectedOptionsWeightsFormat_DEFAULT:
            params->weights_format = kTfLiteFullyConnectedWeightsFormatDefault;
            break;
          case FullyConnectedOptionsWeightsFormat_SHUFFLED4x16INT8:
            params->weights_format =
                kTfLiteFullyConnectedWeightsFormatShuffled4x16Int8;
   d5ba4:	7058      	strb	r0, [r3, #1]
            break;
   d5ba6:	e2c0      	b.n	d612a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa66>
          default:
            error_reporter->Report("Unhandled fully-connected weights format.");
   d5ba8:	49da      	ldr	r1, [pc, #872]	; (d5f14 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x850>)
   d5baa:	4638      	mov	r0, r7
   d5bac:	f7ff fc9e 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>

      /// Destructor, invokes the deleter if the stored pointer is not null.
      ~unique_ptr() noexcept
      {
	auto& __ptr = std::get<0>(_M_t);
	if (__ptr != nullptr)
   d5bb0:	9901      	ldr	r1, [sp, #4]
   d5bb2:	e2b1      	b.n	d6118 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa54>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5bb4:	4628      	mov	r0, r5
   d5bb6:	f7ff fd79 	bl	d56ac <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteLeakyReluParamsEEPT_v>
   d5bba:	4605      	mov	r5, r0
  }
  const FullyConnectedOptions *builtin_options_as_FullyConnectedOptions() const {
    return builtin_options_type() == BuiltinOptions_FullyConnectedOptions ? static_cast<const FullyConnectedOptions *>(builtin_options()) : nullptr;
  }
  const SoftmaxOptions *builtin_options_as_SoftmaxOptions() const {
    return builtin_options_type() == BuiltinOptions_SoftmaxOptions ? static_cast<const SoftmaxOptions *>(builtin_options()) : nullptr;
   d5bbc:	4620      	mov	r0, r4
   d5bbe:	f7ff fd27 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5bc2:	2809      	cmp	r0, #9
   d5bc4:	f040 8494 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5bc8:	4620      	mov	r0, r4
   d5bca:	f7ff fd56 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
    case BuiltinOperator_HASHTABLE_LOOKUP:
      // no-op.
      break;
    case BuiltinOperator_SOFTMAX: {
      auto params = safe_allocator.Allocate<TfLiteSoftmaxParams>();
      if (const auto* softmax_params =
   d5bce:	2800      	cmp	r0, #0
   d5bd0:	f000 848e 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef SoftmaxOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_BETA = 4
  };
  float beta() const {
    return GetField<float>(VT_BETA, 0.0f);
   d5bd4:	ed9f 0ad0 	vldr	s0, [pc, #832]	; d5f18 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x854>
   d5bd8:	2104      	movs	r1, #4
   d5bda:	f7ff fd33 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
              op->builtin_options_as_SoftmaxOptions()) {
        params->beta = softmax_params->beta();
   d5bde:	ed85 0a00 	vstr	s0, [r5]
   d5be2:	f000 bc85 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5be6:	4628      	mov	r0, r5
   d5be8:	f7ff fd68 	bl	d56bc <_ZN6tflite20BuiltinDataAllocator11AllocatePODI27TfLiteReverseSequenceParamsEEPT_v>
   d5bec:	4605      	mov	r5, r0
  }
  const SoftmaxOptions *builtin_options_as_SoftmaxOptions() const {
    return builtin_options_type() == BuiltinOptions_SoftmaxOptions ? static_cast<const SoftmaxOptions *>(builtin_options()) : nullptr;
  }
  const ConcatenationOptions *builtin_options_as_ConcatenationOptions() const {
    return builtin_options_type() == BuiltinOptions_ConcatenationOptions ? static_cast<const ConcatenationOptions *>(builtin_options()) : nullptr;
   d5bee:	4620      	mov	r0, r4
   d5bf0:	f7ff fd0e 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5bf4:	280a      	cmp	r0, #10
   d5bf6:	f040 847b 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5bfa:	4620      	mov	r0, r4
   d5bfc:	f7ff fd3d 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_CONCATENATION: {
      auto params = safe_allocator.Allocate<TfLiteConcatenationParams>();
      if (const auto* concatenation_params =
   d5c00:	4604      	mov	r4, r0
   d5c02:	2800      	cmp	r0, #0
   d5c04:	f000 8474 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  };
  int32_t axis() const {
    return GetField<int32_t>(VT_AXIS, 0);
  }
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5c08:	2200      	movs	r2, #0
   d5c0a:	2106      	movs	r1, #6
   d5c0c:	f7ff fd10 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
              op->builtin_options_as_ConcatenationOptions()) {
        params->activation =
            parse_activation(concatenation_params->fused_activation_function());
   d5c10:	b2c0      	uxtb	r0, r0
   d5c12:	f7ff fc85 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_AXIS = 4,
    VT_FUSED_ACTIVATION_FUNCTION = 6
  };
  int32_t axis() const {
    return GetField<int32_t>(VT_AXIS, 0);
   d5c16:	2200      	movs	r2, #0
   d5c18:	7128      	strb	r0, [r5, #4]
   d5c1a:	2104      	movs	r1, #4
   d5c1c:	4620      	mov	r0, r4
   d5c1e:	f7ff fcfd 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->axis = concatenation_params->axis();
   d5c22:	6028      	str	r0, [r5, #0]
   d5c24:	f000 bc64 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5c28:	4628      	mov	r0, r5
   d5c2a:	f7ff fd43 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d5c2e:	4605      	mov	r5, r0
  }
  const EmbeddingLookupSparseOptions *builtin_options_as_EmbeddingLookupSparseOptions() const {
    return builtin_options_type() == BuiltinOptions_EmbeddingLookupSparseOptions ? static_cast<const EmbeddingLookupSparseOptions *>(builtin_options()) : nullptr;
  }
  const MulOptions *builtin_options_as_MulOptions() const {
    return builtin_options_type() == BuiltinOptions_MulOptions ? static_cast<const MulOptions *>(builtin_options()) : nullptr;
   d5c30:	4620      	mov	r0, r4
   d5c32:	f7ff fced 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5c36:	2815      	cmp	r0, #21
   d5c38:	f040 845a 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5c3c:	4620      	mov	r0, r4
   d5c3e:	f7ff fd1c 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_MUL: {
      auto params = safe_allocator.Allocate<TfLiteMulParams>();
      if (const auto* schema_params = op->builtin_options_as_MulOptions()) {
   d5c42:	2800      	cmp	r0, #0
   d5c44:	f000 8454 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef MulOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_FUSED_ACTIVATION_FUNCTION = 4
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5c48:	2200      	movs	r2, #0
   d5c4a:	2104      	movs	r1, #4
   d5c4c:	f7ff fcf0 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(schema_params->fused_activation_function());
   d5c50:	b2c0      	uxtb	r0, r0
   d5c52:	f7ff fc65 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
   d5c56:	7028      	strb	r0, [r5, #0]
   d5c58:	f000 bc4a 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5c5c:	4628      	mov	r0, r5
   d5c5e:	f7ff fd29 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d5c62:	4605      	mov	r5, r0
  }
  const ConcatenationOptions *builtin_options_as_ConcatenationOptions() const {
    return builtin_options_type() == BuiltinOptions_ConcatenationOptions ? static_cast<const ConcatenationOptions *>(builtin_options()) : nullptr;
  }
  const AddOptions *builtin_options_as_AddOptions() const {
    return builtin_options_type() == BuiltinOptions_AddOptions ? static_cast<const AddOptions *>(builtin_options()) : nullptr;
   d5c64:	4620      	mov	r0, r4
   d5c66:	f7ff fcd3 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5c6a:	280b      	cmp	r0, #11
   d5c6c:	f040 8440 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5c70:	4620      	mov	r0, r4
   d5c72:	f7ff fd02 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_ADD: {
      auto params = safe_allocator.Allocate<TfLiteAddParams>();
      if (const auto* schema_params = op->builtin_options_as_AddOptions()) {
   d5c76:	2800      	cmp	r0, #0
   d5c78:	f000 843a 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef AddOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_FUSED_ACTIVATION_FUNCTION = 4
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5c7c:	2200      	movs	r2, #0
   d5c7e:	2104      	movs	r1, #4
   d5c80:	f7ff fcd6 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(schema_params->fused_activation_function());
   d5c84:	b2c0      	uxtb	r0, r0
   d5c86:	f7ff fc4b 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
   d5c8a:	7028      	strb	r0, [r5, #0]
   d5c8c:	f000 bc30 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5c90:	4628      	mov	r0, r5
   d5c92:	f7ff fd0f 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d5c96:	4605      	mov	r5, r0
  }
  const SubOptions *builtin_options_as_SubOptions() const {
    return builtin_options_type() == BuiltinOptions_SubOptions ? static_cast<const SubOptions *>(builtin_options()) : nullptr;
  }
  const DivOptions *builtin_options_as_DivOptions() const {
    return builtin_options_type() == BuiltinOptions_DivOptions ? static_cast<const DivOptions *>(builtin_options()) : nullptr;
   d5c98:	4620      	mov	r0, r4
   d5c9a:	f7ff fcb9 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5c9e:	281d      	cmp	r0, #29
   d5ca0:	f040 8426 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5ca4:	4620      	mov	r0, r4
   d5ca6:	f7ff fce8 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_DIV: {
      auto params = safe_allocator.Allocate<TfLiteDivParams>();
      if (const auto* schema_params = op->builtin_options_as_DivOptions()) {
   d5caa:	2800      	cmp	r0, #0
   d5cac:	f000 8420 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef DivOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_FUSED_ACTIVATION_FUNCTION = 4
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5cb0:	2200      	movs	r2, #0
   d5cb2:	2104      	movs	r1, #4
   d5cb4:	f7ff fcbc 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(schema_params->fused_activation_function());
   d5cb8:	b2c0      	uxtb	r0, r0
   d5cba:	f7ff fc31 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
   d5cbe:	7028      	strb	r0, [r5, #0]
   d5cc0:	f000 bc16 	b.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5cc4:	4628      	mov	r0, r5
   d5cc6:	f7ff fcf5 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d5cca:	4605      	mov	r5, r0
  }
  const ReducerOptions *builtin_options_as_ReducerOptions() const {
    return builtin_options_type() == BuiltinOptions_ReducerOptions ? static_cast<const ReducerOptions *>(builtin_options()) : nullptr;
  }
  const SubOptions *builtin_options_as_SubOptions() const {
    return builtin_options_type() == BuiltinOptions_SubOptions ? static_cast<const SubOptions *>(builtin_options()) : nullptr;
   d5ccc:	4620      	mov	r0, r4
   d5cce:	f7ff fc9f 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5cd2:	281c      	cmp	r0, #28
   d5cd4:	f040 840c 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5cd8:	4620      	mov	r0, r4
   d5cda:	f7ff fcce 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_SUB: {
      auto params = safe_allocator.Allocate<TfLiteSubParams>();
      if (const auto* schema_params = op->builtin_options_as_SubOptions()) {
   d5cde:	2800      	cmp	r0, #0
   d5ce0:	f000 8406 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef SubOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_FUSED_ACTIVATION_FUNCTION = 4
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5ce4:	2200      	movs	r2, #0
   d5ce6:	2104      	movs	r1, #4
   d5ce8:	f7ff fca2 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(schema_params->fused_activation_function());
   d5cec:	b2c0      	uxtb	r0, r0
   d5cee:	f7ff fc17 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
   d5cf2:	7028      	strb	r0, [r5, #0]
   d5cf4:	e3fc      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5cf6:	4628      	mov	r0, r5
   d5cf8:	f7ff fcdc 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d5cfc:	4605      	mov	r5, r0
  }
  const AddOptions *builtin_options_as_AddOptions() const {
    return builtin_options_type() == BuiltinOptions_AddOptions ? static_cast<const AddOptions *>(builtin_options()) : nullptr;
  }
  const L2NormOptions *builtin_options_as_L2NormOptions() const {
    return builtin_options_type() == BuiltinOptions_L2NormOptions ? static_cast<const L2NormOptions *>(builtin_options()) : nullptr;
   d5cfe:	4620      	mov	r0, r4
   d5d00:	f7ff fc86 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5d04:	280c      	cmp	r0, #12
   d5d06:	f040 83f3 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5d0a:	4620      	mov	r0, r4
   d5d0c:	f7ff fcb5 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_L2_NORMALIZATION: {
      auto params = safe_allocator.Allocate<TfLiteL2NormParams>();
      if (const auto* schema_params = op->builtin_options_as_L2NormOptions()) {
   d5d10:	2800      	cmp	r0, #0
   d5d12:	f000 83ed 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef L2NormOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_FUSED_ACTIVATION_FUNCTION = 4
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5d16:	2200      	movs	r2, #0
   d5d18:	2104      	movs	r1, #4
   d5d1a:	f7ff fc89 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(schema_params->fused_activation_function());
   d5d1e:	b2c0      	uxtb	r0, r0
   d5d20:	f7ff fbfe 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
   d5d24:	7028      	strb	r0, [r5, #0]
   d5d26:	e3e3      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5d28:	4628      	mov	r0, r5
   d5d2a:	f7ff fcbb 	bl	d56a4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteFakeQuantParamsEEPT_v>
   d5d2e:	4605      	mov	r5, r0
  }
  const L2NormOptions *builtin_options_as_L2NormOptions() const {
    return builtin_options_type() == BuiltinOptions_L2NormOptions ? static_cast<const L2NormOptions *>(builtin_options()) : nullptr;
  }
  const LocalResponseNormalizationOptions *builtin_options_as_LocalResponseNormalizationOptions() const {
    return builtin_options_type() == BuiltinOptions_LocalResponseNormalizationOptions ? static_cast<const LocalResponseNormalizationOptions *>(builtin_options()) : nullptr;
   d5d30:	4620      	mov	r0, r4
   d5d32:	f7ff fc6d 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5d36:	280d      	cmp	r0, #13
   d5d38:	f040 83da 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5d3c:	4620      	mov	r0, r4
   d5d3e:	f7ff fc9c 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_LOCAL_RESPONSE_NORMALIZATION: {
      auto params = safe_allocator.Allocate<TfLiteLocalResponseNormParams>();
      if (const auto* schema_params =
   d5d42:	4604      	mov	r4, r0
   d5d44:	2800      	cmp	r0, #0
   d5d46:	f000 83d3 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
    VT_BIAS = 6,
    VT_ALPHA = 8,
    VT_BETA = 10
  };
  int32_t radius() const {
    return GetField<int32_t>(VT_RADIUS, 0);
   d5d4a:	2200      	movs	r2, #0
   d5d4c:	2104      	movs	r1, #4
   d5d4e:	f7ff fc65 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  float bias() const {
    return GetField<float>(VT_BIAS, 0.0f);
   d5d52:	2106      	movs	r1, #6
              op->builtin_options_as_LocalResponseNormalizationOptions()) {
        params->radius = schema_params->radius();
   d5d54:	6028      	str	r0, [r5, #0]
   d5d56:	ed9f 0a70 	vldr	s0, [pc, #448]	; d5f18 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x854>
   d5d5a:	4620      	mov	r0, r4
   d5d5c:	f7ff fc72 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
  }
  float alpha() const {
    return GetField<float>(VT_ALPHA, 0.0f);
   d5d60:	2108      	movs	r1, #8
        params->bias = schema_params->bias();
   d5d62:	ed85 0a01 	vstr	s0, [r5, #4]
   d5d66:	4620      	mov	r0, r4
   d5d68:	ed9f 0a6b 	vldr	s0, [pc, #428]	; d5f18 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x854>
   d5d6c:	f7ff fc6a 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
  }
  float beta() const {
    return GetField<float>(VT_BETA, 0.0f);
   d5d70:	210a      	movs	r1, #10
        params->alpha = schema_params->alpha();
   d5d72:	ed85 0a02 	vstr	s0, [r5, #8]
   d5d76:	4620      	mov	r0, r4
   d5d78:	ed9f 0a67 	vldr	s0, [pc, #412]	; d5f18 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x854>
   d5d7c:	f7ff fc62 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
        params->beta = schema_params->beta();
   d5d80:	ed85 0a03 	vstr	s0, [r5, #12]
   d5d84:	e3b4      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5d86:	4628      	mov	r0, r5
   d5d88:	f7ff fc8c 	bl	d56a4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteFakeQuantParamsEEPT_v>
   d5d8c:	4680      	mov	r8, r0
  }
  const LocalResponseNormalizationOptions *builtin_options_as_LocalResponseNormalizationOptions() const {
    return builtin_options_type() == BuiltinOptions_LocalResponseNormalizationOptions ? static_cast<const LocalResponseNormalizationOptions *>(builtin_options()) : nullptr;
  }
  const LSTMOptions *builtin_options_as_LSTMOptions() const {
    return builtin_options_type() == BuiltinOptions_LSTMOptions ? static_cast<const LSTMOptions *>(builtin_options()) : nullptr;
   d5d8e:	4620      	mov	r0, r4
   d5d90:	e88d 0120 	stmia.w	sp, {r5, r8}
   d5d94:	f7ff fc3c 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5d98:	280e      	cmp	r0, #14
   d5d9a:	d130      	bne.n	d5dfe <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x73a>
   d5d9c:	4620      	mov	r0, r4
   d5d9e:	f7ff fc6c 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_LSTM: {
      auto params = safe_allocator.Allocate<TfLiteLSTMParams>();
      if (const auto* lstm_params = op->builtin_options_as_LSTMOptions()) {
   d5da2:	4605      	mov	r5, r0
   d5da4:	b358      	cbz	r0, d5dfe <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x73a>
    VT_CELL_CLIP = 6,
    VT_PROJ_CLIP = 8,
    VT_KERNEL_TYPE = 10
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5da6:	2200      	movs	r2, #0
   d5da8:	2104      	movs	r1, #4
   d5daa:	f7ff fc41 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->activation =
            parse_activation(lstm_params->fused_activation_function());
   d5dae:	b2c0      	uxtb	r0, r0
   d5db0:	f7ff fbb6 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
  }
  float cell_clip() const {
    return GetField<float>(VT_CELL_CLIP, 0.0f);
   d5db4:	2106      	movs	r1, #6
   d5db6:	f888 0000 	strb.w	r0, [r8]
   d5dba:	ed9f 0a57 	vldr	s0, [pc, #348]	; d5f18 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x854>
      }

      /// Return the stored pointer.
      pointer
      get() const noexcept
      { return std::get<0>(_M_t); }
   d5dbe:	9c01      	ldr	r4, [sp, #4]
   d5dc0:	4628      	mov	r0, r5
   d5dc2:	f7ff fc3f 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
  }
  float proj_clip() const {
    return GetField<float>(VT_PROJ_CLIP, 0.0f);
   d5dc6:	2108      	movs	r1, #8
        params->cell_clip = lstm_params->cell_clip();
   d5dc8:	ed84 0a01 	vstr	s0, [r4, #4]
   d5dcc:	4628      	mov	r0, r5
   d5dce:	ed9f 0a52 	vldr	s0, [pc, #328]	; d5f18 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x854>
   d5dd2:	9c01      	ldr	r4, [sp, #4]
   d5dd4:	f7ff fc36 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
  }
  LSTMKernelType kernel_type() const {
    return static_cast<LSTMKernelType>(GetField<int8_t>(VT_KERNEL_TYPE, 0));
   d5dd8:	2200      	movs	r2, #0
        params->proj_clip = lstm_params->proj_clip();
   d5dda:	ed84 0a02 	vstr	s0, [r4, #8]
   d5dde:	210a      	movs	r1, #10
   d5de0:	4628      	mov	r0, r5
   d5de2:	f7ff fc25 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        switch (lstm_params->kernel_type()) {
   d5de6:	b108      	cbz	r0, d5dec <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x728>
   d5de8:	2801      	cmp	r0, #1
   d5dea:	d102      	bne.n	d5df2 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x72e>
          case LSTMKernelType_FULL:
            params->kernel_type = kTfLiteLSTMFullKernel;
            break;
          case LSTMKernelType_BASIC:
            params->kernel_type = kTfLiteLSTMBasicKernel;
   d5dec:	7320      	strb	r0, [r4, #12]
        }
      } else {
        error_reporter->Report("No valid LSTM builtin options exist");
        return kTfLiteError;
      }
      *builtin_data = reinterpret_cast<void*>(params.release());
   d5dee:	6034      	str	r4, [r6, #0]
   d5df0:	e37f      	b.n	d64f2 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2e>
          case LSTMKernelType_BASIC:
            params->kernel_type = kTfLiteLSTMBasicKernel;
            break;
          default:
            error_reporter->Report("Unhandled LSTM kernel type: %d",
                                   lstm_params->kernel_type());
   d5df2:	b2c2      	uxtb	r2, r0
   d5df4:	4949      	ldr	r1, [pc, #292]	; (d5f1c <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x858>)
   d5df6:	4638      	mov	r0, r7
   d5df8:	f7ff fb78 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
            return kTfLiteError;
   d5dfc:	e6d8      	b.n	d5bb0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x4ec>
        }
      } else {
        error_reporter->Report("No valid LSTM builtin options exist");
   d5dfe:	4948      	ldr	r1, [pc, #288]	; (d5f20 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x85c>)
   d5e00:	e6d3      	b.n	d5baa <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x4e6>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5e02:	4628      	mov	r0, r5
   d5e04:	f7ff fc4e 	bl	d56a4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteFakeQuantParamsEEPT_v>
   d5e08:	4605      	mov	r5, r0
  }
  const BidirectionalSequenceRNNOptions *builtin_options_as_BidirectionalSequenceRNNOptions() const {
    return builtin_options_type() == BuiltinOptions_BidirectionalSequenceRNNOptions ? static_cast<const BidirectionalSequenceRNNOptions *>(builtin_options()) : nullptr;
  }
  const UnidirectionalSequenceLSTMOptions *builtin_options_as_UnidirectionalSequenceLSTMOptions() const {
    return builtin_options_type() == BuiltinOptions_UnidirectionalSequenceLSTMOptions ? static_cast<const UnidirectionalSequenceLSTMOptions *>(builtin_options()) : nullptr;
   d5e0a:	4620      	mov	r0, r4
   d5e0c:	f7ff fc00 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5e10:	2847      	cmp	r0, #71	; 0x47
   d5e12:	f040 836d 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5e16:	4620      	mov	r0, r4
   d5e18:	f7ff fc2f 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      break;
    }
    case BuiltinOperator_UNIDIRECTIONAL_SEQUENCE_LSTM: {
      auto params =
          safe_allocator.Allocate<TfLiteUnidirectionalSequenceLSTMParams>();
      if (const auto* seq_lstm_params =
   d5e1c:	4604      	mov	r4, r0
   d5e1e:	2800      	cmp	r0, #0
   d5e20:	f000 8366 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
    VT_CELL_CLIP = 6,
    VT_PROJ_CLIP = 8,
    VT_TIME_MAJOR = 10
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5e24:	2200      	movs	r2, #0
   d5e26:	2104      	movs	r1, #4
   d5e28:	f7ff fc02 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
              op->builtin_options_as_UnidirectionalSequenceLSTMOptions()) {
        params->activation =
            parse_activation(seq_lstm_params->fused_activation_function());
   d5e2c:	b2c0      	uxtb	r0, r0
   d5e2e:	f7ff fb77 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
  }
  float cell_clip() const {
    return GetField<float>(VT_CELL_CLIP, 0.0f);
   d5e32:	2106      	movs	r1, #6
   d5e34:	7028      	strb	r0, [r5, #0]
   d5e36:	ed9f 0a38 	vldr	s0, [pc, #224]	; d5f18 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x854>
   d5e3a:	4620      	mov	r0, r4
   d5e3c:	f7ff fc02 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
  }
  float proj_clip() const {
    return GetField<float>(VT_PROJ_CLIP, 0.0f);
   d5e40:	2108      	movs	r1, #8
        params->cell_clip = seq_lstm_params->cell_clip();
   d5e42:	ed85 0a01 	vstr	s0, [r5, #4]
   d5e46:	4620      	mov	r0, r4
   d5e48:	ed9f 0a33 	vldr	s0, [pc, #204]	; d5f18 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x854>
   d5e4c:	f7ff fbfa 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
  }
  bool time_major() const {
    return GetField<uint8_t>(VT_TIME_MAJOR, 0) != 0;
   d5e50:	2200      	movs	r2, #0
        params->proj_clip = seq_lstm_params->proj_clip();
   d5e52:	ed85 0a02 	vstr	s0, [r5, #8]
   d5e56:	210a      	movs	r1, #10
   d5e58:	4620      	mov	r0, r4
   d5e5a:	f7ff fbcf 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
        params->time_major = seq_lstm_params->time_major();
   d5e5e:	3000      	adds	r0, #0
   d5e60:	bf18      	it	ne
   d5e62:	2001      	movne	r0, #1
   d5e64:	7328      	strb	r0, [r5, #12]
   d5e66:	e343      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5e68:	4628      	mov	r0, r5
   d5e6a:	f7ff fc1b 	bl	d56a4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteFakeQuantParamsEEPT_v>
   d5e6e:	4605      	mov	r5, r0
  }
  const FillOptions *builtin_options_as_FillOptions() const {
    return builtin_options_type() == BuiltinOptions_FillOptions ? static_cast<const FillOptions *>(builtin_options()) : nullptr;
  }
  const BidirectionalSequenceLSTMOptions *builtin_options_as_BidirectionalSequenceLSTMOptions() const {
    return builtin_options_type() == BuiltinOptions_BidirectionalSequenceLSTMOptions ? static_cast<const BidirectionalSequenceLSTMOptions *>(builtin_options()) : nullptr;
   d5e70:	4620      	mov	r0, r4
   d5e72:	f7ff fbcd 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5e76:	2845      	cmp	r0, #69	; 0x45
   d5e78:	f040 833a 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5e7c:	4620      	mov	r0, r4
   d5e7e:	f7ff fbfc 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      break;
    }
    case BuiltinOperator_BIDIRECTIONAL_SEQUENCE_LSTM: {
      auto params =
          safe_allocator.Allocate<TfLiteBidirectionalSequenceLSTMParams>();
      if (const auto* bidi_lstm_params =
   d5e82:	4604      	mov	r4, r0
   d5e84:	2800      	cmp	r0, #0
   d5e86:	f000 8333 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
    VT_PROJ_CLIP = 8,
    VT_MERGE_OUTPUTS = 10,
    VT_TIME_MAJOR = 12
  };
  ActivationFunctionType fused_activation_function() const {
    return static_cast<ActivationFunctionType>(GetField<int8_t>(VT_FUSED_ACTIVATION_FUNCTION, 0));
   d5e8a:	2200      	movs	r2, #0
   d5e8c:	2104      	movs	r1, #4
   d5e8e:	f7ff fbcf 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
              op->builtin_options_as_BidirectionalSequenceLSTMOptions()) {
        params->activation =
            parse_activation(bidi_lstm_params->fused_activation_function());
   d5e92:	b2c0      	uxtb	r0, r0
   d5e94:	f7ff fb44 	bl	d5520 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_22ActivationFunctionTypeEE0_clESA_.isra.1>
  }
  float cell_clip() const {
    return GetField<float>(VT_CELL_CLIP, 0.0f);
   d5e98:	2106      	movs	r1, #6
   d5e9a:	7028      	strb	r0, [r5, #0]
   d5e9c:	ed9f 0a1e 	vldr	s0, [pc, #120]	; d5f18 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x854>
   d5ea0:	4620      	mov	r0, r4
   d5ea2:	f7ff fbcf 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
  }
  float proj_clip() const {
    return GetField<float>(VT_PROJ_CLIP, 0.0f);
   d5ea6:	2108      	movs	r1, #8
        params->cell_clip = bidi_lstm_params->cell_clip();
   d5ea8:	ed85 0a01 	vstr	s0, [r5, #4]
   d5eac:	4620      	mov	r0, r4
   d5eae:	ed9f 0a1a 	vldr	s0, [pc, #104]	; d5f18 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0x854>
   d5eb2:	f7ff fbc7 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
  }
  bool merge_outputs() const {
    return GetField<uint8_t>(VT_MERGE_OUTPUTS, 0) != 0;
   d5eb6:	2200      	movs	r2, #0
        params->proj_clip = bidi_lstm_params->proj_clip();
   d5eb8:	ed85 0a02 	vstr	s0, [r5, #8]
   d5ebc:	210a      	movs	r1, #10
   d5ebe:	4620      	mov	r0, r4
   d5ec0:	f7ff fb9c 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
        params->merge_outputs = bidi_lstm_params->merge_outputs();
   d5ec4:	3000      	adds	r0, #0
   d5ec6:	bf18      	it	ne
   d5ec8:	2001      	movne	r0, #1
   d5eca:	7328      	strb	r0, [r5, #12]
  }
  bool time_major() const {
    return GetField<uint8_t>(VT_TIME_MAJOR, 1) != 0;
   d5ecc:	2201      	movs	r2, #1
   d5ece:	210c      	movs	r1, #12
   d5ed0:	4620      	mov	r0, r4
   d5ed2:	f7ff fb93 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
        params->time_major = bidi_lstm_params->time_major();
   d5ed6:	3000      	adds	r0, #0
   d5ed8:	bf18      	it	ne
   d5eda:	2001      	movne	r0, #1
   d5edc:	7368      	strb	r0, [r5, #13]
   d5ede:	e307      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5ee0:	4628      	mov	r0, r5
   d5ee2:	f7ff fbe7 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d5ee6:	4605      	mov	r5, r0
  }
  const LSTMOptions *builtin_options_as_LSTMOptions() const {
    return builtin_options_type() == BuiltinOptions_LSTMOptions ? static_cast<const LSTMOptions *>(builtin_options()) : nullptr;
  }
  const ResizeBilinearOptions *builtin_options_as_ResizeBilinearOptions() const {
    return builtin_options_type() == BuiltinOptions_ResizeBilinearOptions ? static_cast<const ResizeBilinearOptions *>(builtin_options()) : nullptr;
   d5ee8:	4620      	mov	r0, r4
   d5eea:	f7ff fb91 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5eee:	280f      	cmp	r0, #15
   d5ef0:	f040 82fe 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5ef4:	4620      	mov	r0, r4
   d5ef6:	f7ff fbc0 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_RESIZE_BILINEAR: {
      auto params = safe_allocator.Allocate<TfLiteResizeBilinearParams>();
      if (const auto* schema_params =
   d5efa:	2800      	cmp	r0, #0
   d5efc:	f000 82f8 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef ResizeBilinearOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ALIGN_CORNERS = 8
  };
  bool align_corners() const {
    return GetField<uint8_t>(VT_ALIGN_CORNERS, 0) != 0;
   d5f00:	2200      	movs	r2, #0
   d5f02:	2108      	movs	r1, #8
   d5f04:	f7ff fb7a 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
              op->builtin_options_as_ResizeBilinearOptions()) {
        params->align_corners = schema_params->align_corners();
   d5f08:	3000      	adds	r0, #0
   d5f0a:	bf18      	it	ne
   d5f0c:	2001      	movne	r0, #1
   d5f0e:	7028      	strb	r0, [r5, #0]
   d5f10:	e2ee      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5f12:	bf00      	nop
   d5f14:	000ea0d2 	.word	0x000ea0d2
   d5f18:	00000000 	.word	0x00000000
   d5f1c:	000ea0fc 	.word	0x000ea0fc
   d5f20:	000ea11b 	.word	0x000ea11b
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5f24:	4628      	mov	r0, r5
   d5f26:	f7ff fbc5 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d5f2a:	4605      	mov	r5, r0
  }
  const RangeOptions *builtin_options_as_RangeOptions() const {
    return builtin_options_type() == BuiltinOptions_RangeOptions ? static_cast<const RangeOptions *>(builtin_options()) : nullptr;
  }
  const ResizeNearestNeighborOptions *builtin_options_as_ResizeNearestNeighborOptions() const {
    return builtin_options_type() == BuiltinOptions_ResizeNearestNeighborOptions ? static_cast<const ResizeNearestNeighborOptions *>(builtin_options()) : nullptr;
   d5f2c:	4620      	mov	r0, r4
   d5f2e:	f7ff fb6f 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5f32:	284a      	cmp	r0, #74	; 0x4a
   d5f34:	f040 82dc 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5f38:	4620      	mov	r0, r4
   d5f3a:	f7ff fb9e 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      // required to minimize function size. TODO(b/118447267): Simplify
      // ParseOpData function and reduce its length.
      [&]() {
        auto params =
            safe_allocator.Allocate<TfLiteResizeNearestNeighborParams>();
        if (const auto* schema_params =
   d5f3e:	2800      	cmp	r0, #0
   d5f40:	f000 82d6 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef ResizeNearestNeighborOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ALIGN_CORNERS = 4
  };
  bool align_corners() const {
    return GetField<uint8_t>(VT_ALIGN_CORNERS, 0) != 0;
   d5f44:	2200      	movs	r2, #0
   d5f46:	2104      	movs	r1, #4
   d5f48:	f7ff fb58 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
                op->builtin_options_as_ResizeNearestNeighborOptions()) {
          params->align_corners = schema_params->align_corners();
   d5f4c:	3000      	adds	r0, #0
   d5f4e:	bf18      	it	ne
   d5f50:	2001      	movne	r0, #1
   d5f52:	7028      	strb	r0, [r5, #0]
   d5f54:	e2cc      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5f56:	4628      	mov	r0, r5
   d5f58:	f7ff fb9c 	bl	d5694 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI19TfLiteSqueezeParamsEEPT_v>
   d5f5c:	4680      	mov	r8, r0
  }
  const CallOptions *builtin_options_as_CallOptions() const {
    return builtin_options_type() == BuiltinOptions_CallOptions ? static_cast<const CallOptions *>(builtin_options()) : nullptr;
  }
  const ReshapeOptions *builtin_options_as_ReshapeOptions() const {
    return builtin_options_type() == BuiltinOptions_ReshapeOptions ? static_cast<const ReshapeOptions *>(builtin_options()) : nullptr;
   d5f5e:	4620      	mov	r0, r4
   d5f60:	e88d 0120 	stmia.w	sp, {r5, r8}
   d5f64:	f7ff fb54 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5f68:	2811      	cmp	r0, #17
   d5f6a:	f040 80de 	bne.w	d612a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa66>
   d5f6e:	4620      	mov	r0, r4
   d5f70:	f7ff fb83 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      }();
      break;
    }
    case BuiltinOperator_RESHAPE: {
      auto params = safe_allocator.Allocate<TfLiteReshapeParams>();
      if (const auto* schema_params = op->builtin_options_as_ReshapeOptions()) {
   d5f74:	2800      	cmp	r0, #0
   d5f76:	f000 80d8 	beq.w	d612a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa66>
   d5f7a:	2104      	movs	r1, #4
   d5f7c:	f7ff fb74 	bl	d5668 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorIlEEEET_t>
        auto* new_shape = schema_params->new_shape();
        TF_LITE_ENSURE_STATUS(FlatBufferIntVectorToArray(
   d5f80:	4bca      	ldr	r3, [pc, #808]	; (d62ac <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xbe8>)
   d5f82:	4604      	mov	r4, r0
   d5f84:	e0c2      	b.n	d610c <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa48>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5f86:	4628      	mov	r0, r5
   d5f88:	f7ff fb88 	bl	d569c <_ZN6tflite20BuiltinDataAllocator11AllocatePODI25TfLiteTransposeConvParamsEEPT_v>
   d5f8c:	4605      	mov	r5, r0
  }
  const SkipGramOptions *builtin_options_as_SkipGramOptions() const {
    return builtin_options_type() == BuiltinOptions_SkipGramOptions ? static_cast<const SkipGramOptions *>(builtin_options()) : nullptr;
   d5f8e:	4620      	mov	r0, r4
   d5f90:	f7ff fb3e 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5f94:	2812      	cmp	r0, #18
   d5f96:	f040 82ab 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5f9a:	4620      	mov	r0, r4
   d5f9c:	f7ff fb6d 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_SKIP_GRAM: {
      auto params = safe_allocator.Allocate<TfLiteSkipGramParams>();
      if (const auto* skip_gram_params =
   d5fa0:	4604      	mov	r4, r0
   d5fa2:	2800      	cmp	r0, #0
   d5fa4:	f000 82a4 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
    VT_NGRAM_SIZE = 4,
    VT_MAX_SKIP_SIZE = 6,
    VT_INCLUDE_ALL_NGRAMS = 8
  };
  int32_t ngram_size() const {
    return GetField<int32_t>(VT_NGRAM_SIZE, 0);
   d5fa8:	2200      	movs	r2, #0
   d5faa:	2104      	movs	r1, #4
   d5fac:	f7ff fb36 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t max_skip_size() const {
    return GetField<int32_t>(VT_MAX_SKIP_SIZE, 0);
   d5fb0:	2200      	movs	r2, #0
              op->builtin_options_as_SkipGramOptions()) {
        params->ngram_size = skip_gram_params->ngram_size();
   d5fb2:	6028      	str	r0, [r5, #0]
   d5fb4:	2106      	movs	r1, #6
   d5fb6:	4620      	mov	r0, r4
   d5fb8:	f7ff fb30 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  bool include_all_ngrams() const {
    return GetField<uint8_t>(VT_INCLUDE_ALL_NGRAMS, 0) != 0;
   d5fbc:	2200      	movs	r2, #0
        params->max_skip_size = skip_gram_params->max_skip_size();
   d5fbe:	6068      	str	r0, [r5, #4]
   d5fc0:	2108      	movs	r1, #8
   d5fc2:	4620      	mov	r0, r4
   d5fc4:	f7ff fb1a 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
        params->include_all_ngrams = skip_gram_params->include_all_ngrams();
   d5fc8:	3000      	adds	r0, #0
   d5fca:	bf18      	it	ne
   d5fcc:	2001      	movne	r0, #1
   d5fce:	7228      	strb	r0, [r5, #8]
   d5fd0:	e28e      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5fd2:	4628      	mov	r0, r5
   d5fd4:	f7ff fb6a 	bl	d56ac <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteLeakyReluParamsEEPT_v>
   d5fd8:	4605      	mov	r5, r0
  }
  const SkipGramOptions *builtin_options_as_SkipGramOptions() const {
    return builtin_options_type() == BuiltinOptions_SkipGramOptions ? static_cast<const SkipGramOptions *>(builtin_options()) : nullptr;
  }
  const SpaceToDepthOptions *builtin_options_as_SpaceToDepthOptions() const {
    return builtin_options_type() == BuiltinOptions_SpaceToDepthOptions ? static_cast<const SpaceToDepthOptions *>(builtin_options()) : nullptr;
   d5fda:	4620      	mov	r0, r4
   d5fdc:	f7ff fb18 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d5fe0:	2813      	cmp	r0, #19
   d5fe2:	f040 8285 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d5fe6:	4620      	mov	r0, r4
   d5fe8:	f7ff fb47 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_SPACE_TO_DEPTH: {
      auto params = safe_allocator.Allocate<TfLiteSpaceToDepthParams>();
      if (const auto* schema_params =
   d5fec:	2800      	cmp	r0, #0
   d5fee:	f000 827f 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef SpaceToDepthOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_BLOCK_SIZE = 4
  };
  int32_t block_size() const {
    return GetField<int32_t>(VT_BLOCK_SIZE, 0);
   d5ff2:	2200      	movs	r2, #0
   d5ff4:	2104      	movs	r1, #4
   d5ff6:	f7ff fb11 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
              op->builtin_options_as_SpaceToDepthOptions()) {
        params->block_size = schema_params->block_size();
   d5ffa:	6028      	str	r0, [r5, #0]
   d5ffc:	e278      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d5ffe:	4628      	mov	r0, r5
   d6000:	f7ff fb54 	bl	d56ac <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteLeakyReluParamsEEPT_v>
   d6004:	4605      	mov	r5, r0
  }
  const WhileOptions *builtin_options_as_WhileOptions() const {
    return builtin_options_type() == BuiltinOptions_WhileOptions ? static_cast<const WhileOptions *>(builtin_options()) : nullptr;
  }
  const DepthToSpaceOptions *builtin_options_as_DepthToSpaceOptions() const {
    return builtin_options_type() == BuiltinOptions_DepthToSpaceOptions ? static_cast<const DepthToSpaceOptions *>(builtin_options()) : nullptr;
   d6006:	4620      	mov	r0, r4
   d6008:	f7ff fb02 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d600c:	285e      	cmp	r0, #94	; 0x5e
   d600e:	f040 826f 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d6012:	4620      	mov	r0, r4
   d6014:	f7ff fb31 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_DEPTH_TO_SPACE: {
      auto params = safe_allocator.Allocate<TfLiteDepthToSpaceParams>();
      if (const auto* schema_params =
   d6018:	2800      	cmp	r0, #0
   d601a:	f000 8269 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef DepthToSpaceOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_BLOCK_SIZE = 4
  };
  int32_t block_size() const {
    return GetField<int32_t>(VT_BLOCK_SIZE, 0);
   d601e:	2200      	movs	r2, #0
   d6020:	2104      	movs	r1, #4
   d6022:	f7ff fafb 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
              op->builtin_options_as_DepthToSpaceOptions()) {
        params->block_size = schema_params->block_size();
   d6026:	6028      	str	r0, [r5, #0]
   d6028:	e262      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d602a:	4628      	mov	r0, r5
   d602c:	f7ff fb3e 	bl	d56ac <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteLeakyReluParamsEEPT_v>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_GATHER: {
      auto params = safe_allocator.Allocate<TfLiteGatherParams>();
      params->axis = 0;
   d6030:	f8c0 8000 	str.w	r8, [r0]
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d6034:	4605      	mov	r5, r0
  }
  const PadOptions *builtin_options_as_PadOptions() const {
    return builtin_options_type() == BuiltinOptions_PadOptions ? static_cast<const PadOptions *>(builtin_options()) : nullptr;
  }
  const GatherOptions *builtin_options_as_GatherOptions() const {
    return builtin_options_type() == BuiltinOptions_GatherOptions ? static_cast<const GatherOptions *>(builtin_options()) : nullptr;
   d6036:	4620      	mov	r0, r4
   d6038:	f7ff faea 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d603c:	2817      	cmp	r0, #23
   d603e:	f040 8257 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d6042:	4620      	mov	r0, r4
   d6044:	f7ff fb19 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      break;
    }
    case BuiltinOperator_GATHER: {
      auto params = safe_allocator.Allocate<TfLiteGatherParams>();
      params->axis = 0;
      if (const auto* gather_params = op->builtin_options_as_GatherOptions()) {
   d6048:	2800      	cmp	r0, #0
   d604a:	f000 8251 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef GatherOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_AXIS = 4
  };
  int32_t axis() const {
    return GetField<int32_t>(VT_AXIS, 0);
   d604e:	2200      	movs	r2, #0
   d6050:	2104      	movs	r1, #4
   d6052:	f7ff fae3 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->axis = gather_params->axis();
   d6056:	6028      	str	r0, [r5, #0]
   d6058:	e24a      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d605a:	4628      	mov	r0, r5
   d605c:	f7ff fb2a 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d6060:	4605      	mov	r5, r0
  }
  const TransposeOptions *builtin_options_as_TransposeOptions() const {
    return builtin_options_type() == BuiltinOptions_TransposeOptions ? static_cast<const TransposeOptions *>(builtin_options()) : nullptr;
  }
  const ReducerOptions *builtin_options_as_ReducerOptions() const {
    return builtin_options_type() == BuiltinOptions_ReducerOptions ? static_cast<const ReducerOptions *>(builtin_options()) : nullptr;
   d6062:	4620      	mov	r0, r4
   d6064:	f7ff fad4 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6068:	281b      	cmp	r0, #27
   d606a:	f040 8241 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d606e:	4620      	mov	r0, r4
   d6070:	f7ff fb03 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
    case BuiltinOperator_REDUCE_MIN:
    case BuiltinOperator_REDUCE_PROD:
    case BuiltinOperator_REDUCE_ANY:
    case BuiltinOperator_SUM: {
      auto params = safe_allocator.Allocate<TfLiteReducerParams>();
      if (const auto* schema_params = op->builtin_options_as_ReducerOptions()) {
   d6074:	2800      	cmp	r0, #0
   d6076:	f000 823b 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef ReducerOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_KEEP_DIMS = 4
  };
  bool keep_dims() const {
    return GetField<uint8_t>(VT_KEEP_DIMS, 0) != 0;
   d607a:	2200      	movs	r2, #0
   d607c:	2104      	movs	r1, #4
   d607e:	f7ff fabd 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
        params->keep_dims = schema_params->keep_dims();
   d6082:	3000      	adds	r0, #0
   d6084:	bf18      	it	ne
   d6086:	2001      	movne	r0, #1
   d6088:	7028      	strb	r0, [r5, #0]
   d608a:	e231      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d608c:	4628      	mov	r0, r5
   d608e:	f7ff fb0d 	bl	d56ac <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteLeakyReluParamsEEPT_v>
   d6092:	4605      	mov	r5, r0
  }
  const TopKV2Options *builtin_options_as_TopKV2Options() const {
    return builtin_options_type() == BuiltinOptions_TopKV2Options ? static_cast<const TopKV2Options *>(builtin_options()) : nullptr;
  }
  const SplitOptions *builtin_options_as_SplitOptions() const {
    return builtin_options_type() == BuiltinOptions_SplitOptions ? static_cast<const SplitOptions *>(builtin_options()) : nullptr;
   d6094:	4620      	mov	r0, r4
   d6096:	f7ff fabb 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d609a:	2823      	cmp	r0, #35	; 0x23
   d609c:	f040 8228 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d60a0:	4620      	mov	r0, r4
   d60a2:	f7ff faea 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_SPLIT: {
      auto params = safe_allocator.Allocate<TfLiteSplitParams>();
      if (const auto* schema_params = op->builtin_options_as_SplitOptions()) {
   d60a6:	2800      	cmp	r0, #0
   d60a8:	f000 8222 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef SplitOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NUM_SPLITS = 4
  };
  int32_t num_splits() const {
    return GetField<int32_t>(VT_NUM_SPLITS, 0);
   d60ac:	2200      	movs	r2, #0
   d60ae:	2104      	movs	r1, #4
   d60b0:	f7ff fab4 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->num_splits = schema_params->num_splits();
   d60b4:	6028      	str	r0, [r5, #0]
   d60b6:	e21b      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d60b8:	4628      	mov	r0, r5
   d60ba:	f7ff faf7 	bl	d56ac <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteLeakyReluParamsEEPT_v>
   d60be:	4605      	mov	r5, r0
  }
  const AbsOptions *builtin_options_as_AbsOptions() const {
    return builtin_options_type() == BuiltinOptions_AbsOptions ? static_cast<const AbsOptions *>(builtin_options()) : nullptr;
  }
  const SplitVOptions *builtin_options_as_SplitVOptions() const {
    return builtin_options_type() == BuiltinOptions_SplitVOptions ? static_cast<const SplitVOptions *>(builtin_options()) : nullptr;
   d60c0:	4620      	mov	r0, r4
   d60c2:	f7ff faa5 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d60c6:	284f      	cmp	r0, #79	; 0x4f
   d60c8:	f040 8212 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d60cc:	4620      	mov	r0, r4
   d60ce:	f7ff fad4 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_SPLIT_V: {
      auto params = safe_allocator.Allocate<TfLiteSplitParams>();
      if (const auto* schema_params = op->builtin_options_as_SplitVOptions()) {
   d60d2:	2800      	cmp	r0, #0
   d60d4:	f000 820c 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef SplitVOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NUM_SPLITS = 4
  };
  int32_t num_splits() const {
    return GetField<int32_t>(VT_NUM_SPLITS, 0);
   d60d8:	2200      	movs	r2, #0
   d60da:	2104      	movs	r1, #4
   d60dc:	f7ff fa9e 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->num_splits = schema_params->num_splits();
   d60e0:	6028      	str	r0, [r5, #0]
   d60e2:	e205      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d60e4:	4628      	mov	r0, r5
   d60e6:	f7ff fad5 	bl	d5694 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI19TfLiteSqueezeParamsEEPT_v>
   d60ea:	4680      	mov	r8, r0
  }
  const DivOptions *builtin_options_as_DivOptions() const {
    return builtin_options_type() == BuiltinOptions_DivOptions ? static_cast<const DivOptions *>(builtin_options()) : nullptr;
  }
  const SqueezeOptions *builtin_options_as_SqueezeOptions() const {
    return builtin_options_type() == BuiltinOptions_SqueezeOptions ? static_cast<const SqueezeOptions *>(builtin_options()) : nullptr;
   d60ec:	4620      	mov	r0, r4
   d60ee:	e88d 0120 	stmia.w	sp, {r5, r8}
   d60f2:	f7ff fa8d 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d60f6:	281e      	cmp	r0, #30
   d60f8:	d117      	bne.n	d612a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa66>
   d60fa:	4620      	mov	r0, r4
   d60fc:	f7ff fabd 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_SQUEEZE: {
      auto params = safe_allocator.Allocate<TfLiteSqueezeParams>();
      if (const auto* schema_params = op->builtin_options_as_SqueezeOptions()) {
   d6100:	b198      	cbz	r0, d612a <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa66>
   d6102:	2104      	movs	r1, #4
   d6104:	f7ff fab0 	bl	d5668 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorIlEEEET_t>
        const auto& squeeze_dims = schema_params->squeeze_dims();
        TF_LITE_ENSURE_STATUS(FlatBufferIntVectorToArray(
   d6108:	4b69      	ldr	r3, [pc, #420]	; (d62b0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xbec>)
   d610a:	4604      	mov	r4, r0
   d610c:	4641      	mov	r1, r8
   d610e:	463a      	mov	r2, r7
   d6110:	f7ff fa10 	bl	d5534 <_ZN6tflite12_GLOBAL__N_126FlatBufferIntVectorToArrayEiPKN11flatbuffers6VectorIlEEPiPNS_13ErrorReporterEPKc.constprop.4>
   d6114:	9901      	ldr	r1, [sp, #4]
   d6116:	b130      	cbz	r0, d6126 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xa62>

      /// Destructor, invokes the deleter if the stored pointer is not null.
      ~unique_ptr() noexcept
      {
	auto& __ptr = std::get<0>(_M_t);
	if (__ptr != nullptr)
   d6118:	2900      	cmp	r1, #0
   d611a:	f000 80ec 	beq.w	d62f6 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xc32>
	  get_deleter()(__ptr);
   d611e:	4668      	mov	r0, sp
   d6120:	f7ff f9f2 	bl	d5508 <_ZN6tflite12_GLOBAL__N_124SafeBuiltinDataAllocator18BuiltinDataDeleterclEPv>
   d6124:	e0e7      	b.n	d62f6 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xc32>
            sizeof(params->squeeze_dims), squeeze_dims, params->squeeze_dims,
            error_reporter, "squeeze"));
        params->num_squeeze_dims = squeeze_dims->size();
   d6126:	6823      	ldr	r3, [r4, #0]
   d6128:	620b      	str	r3, [r1, #32]
      }
      *builtin_data = reinterpret_cast<void*>(params.release());
   d612a:	9b01      	ldr	r3, [sp, #4]
   d612c:	6033      	str	r3, [r6, #0]
   d612e:	e1e0      	b.n	d64f2 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2e>
   d6130:	682b      	ldr	r3, [r5, #0]
   d6132:	2114      	movs	r1, #20
   d6134:	681b      	ldr	r3, [r3, #0]
   d6136:	4628      	mov	r0, r5
   d6138:	4798      	blx	r3
   d613a:	4605      	mov	r5, r0
  }
  const SequenceRNNOptions *builtin_options_as_SequenceRNNOptions() const {
    return builtin_options_type() == BuiltinOptions_SequenceRNNOptions ? static_cast<const SequenceRNNOptions *>(builtin_options()) : nullptr;
  }
  const StridedSliceOptions *builtin_options_as_StridedSliceOptions() const {
    return builtin_options_type() == BuiltinOptions_StridedSliceOptions ? static_cast<const StridedSliceOptions *>(builtin_options()) : nullptr;
   d613c:	4620      	mov	r0, r4
   d613e:	f7ff fa67 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6142:	2820      	cmp	r0, #32
   d6144:	f040 81d4 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d6148:	4620      	mov	r0, r4
   d614a:	f7ff fa96 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      break;
    }
    case BuiltinOperator_STRIDED_SLICE: {
      auto params = safe_allocator.Allocate<TfLiteStridedSliceParams>();
      if (const auto* schema_params =
   d614e:	4604      	mov	r4, r0
   d6150:	2800      	cmp	r0, #0
   d6152:	f000 81cd 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
    VT_ELLIPSIS_MASK = 8,
    VT_NEW_AXIS_MASK = 10,
    VT_SHRINK_AXIS_MASK = 12
  };
  int32_t begin_mask() const {
    return GetField<int32_t>(VT_BEGIN_MASK, 0);
   d6156:	2200      	movs	r2, #0
   d6158:	2104      	movs	r1, #4
   d615a:	f7ff fa5f 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t end_mask() const {
    return GetField<int32_t>(VT_END_MASK, 0);
   d615e:	2200      	movs	r2, #0
              op->builtin_options_as_StridedSliceOptions()) {
        params->begin_mask = schema_params->begin_mask();
   d6160:	6028      	str	r0, [r5, #0]
   d6162:	2106      	movs	r1, #6
   d6164:	4620      	mov	r0, r4
   d6166:	f7ff fa59 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t ellipsis_mask() const {
    return GetField<int32_t>(VT_ELLIPSIS_MASK, 0);
   d616a:	2200      	movs	r2, #0
        params->end_mask = schema_params->end_mask();
   d616c:	6068      	str	r0, [r5, #4]
   d616e:	2108      	movs	r1, #8
   d6170:	4620      	mov	r0, r4
   d6172:	f7ff fa53 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t new_axis_mask() const {
    return GetField<int32_t>(VT_NEW_AXIS_MASK, 0);
   d6176:	2200      	movs	r2, #0
        params->ellipsis_mask = schema_params->ellipsis_mask();
   d6178:	60a8      	str	r0, [r5, #8]
   d617a:	210a      	movs	r1, #10
   d617c:	4620      	mov	r0, r4
   d617e:	f7ff fa4d 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t shrink_axis_mask() const {
    return GetField<int32_t>(VT_SHRINK_AXIS_MASK, 0);
   d6182:	2200      	movs	r2, #0
        params->new_axis_mask = schema_params->new_axis_mask();
   d6184:	60e8      	str	r0, [r5, #12]
   d6186:	210c      	movs	r1, #12
   d6188:	4620      	mov	r0, r4
   d618a:	f7ff fa47 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->shrink_axis_mask = schema_params->shrink_axis_mask();
   d618e:	6128      	str	r0, [r5, #16]
   d6190:	e1ae      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d6192:	4628      	mov	r0, r5
   d6194:	f7ff fa8e 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d6198:	4605      	mov	r5, r0
  }
  const MaximumMinimumOptions *builtin_options_as_MaximumMinimumOptions() const {
    return builtin_options_type() == BuiltinOptions_MaximumMinimumOptions ? static_cast<const MaximumMinimumOptions *>(builtin_options()) : nullptr;
  }
  const ArgMaxOptions *builtin_options_as_ArgMaxOptions() const {
    return builtin_options_type() == BuiltinOptions_ArgMaxOptions ? static_cast<const ArgMaxOptions *>(builtin_options()) : nullptr;
   d619a:	4620      	mov	r0, r4
   d619c:	f7ff fa38 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d61a0:	2828      	cmp	r0, #40	; 0x28
   d61a2:	f040 81a5 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d61a6:	4620      	mov	r0, r4
   d61a8:	f7ff fa67 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_ARG_MAX: {
      auto params = safe_allocator.Allocate<TfLiteArgMaxParams>();
      if (const auto* schema_params = op->builtin_options_as_ArgMaxOptions()) {
   d61ac:	2800      	cmp	r0, #0
   d61ae:	f000 819f 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef ArgMaxOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_OUTPUT_TYPE = 4
  };
  TensorType output_type() const {
    return static_cast<TensorType>(GetField<int8_t>(VT_OUTPUT_TYPE, 0));
   d61b2:	2200      	movs	r2, #0
   d61b4:	2104      	movs	r1, #4
   d61b6:	f7ff fa3b 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        ConvertTensorType(schema_params->output_type(), &params->output_type,
                          error_reporter);
   d61ba:	463a      	mov	r2, r7
   d61bc:	4629      	mov	r1, r5
   d61be:	b2c0      	uxtb	r0, r0
   d61c0:	f7ff f9ee 	bl	d55a0 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE>
   d61c4:	e194      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d61c6:	4628      	mov	r0, r5
   d61c8:	f7ff fa74 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d61cc:	4605      	mov	r5, r0
  }
  const PowOptions *builtin_options_as_PowOptions() const {
    return builtin_options_type() == BuiltinOptions_PowOptions ? static_cast<const PowOptions *>(builtin_options()) : nullptr;
  }
  const ArgMinOptions *builtin_options_as_ArgMinOptions() const {
    return builtin_options_type() == BuiltinOptions_ArgMinOptions ? static_cast<const ArgMinOptions *>(builtin_options()) : nullptr;
   d61ce:	4620      	mov	r0, r4
   d61d0:	f7ff fa1e 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d61d4:	2839      	cmp	r0, #57	; 0x39
   d61d6:	f040 818b 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d61da:	4620      	mov	r0, r4
   d61dc:	f7ff fa4d 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_ARG_MIN: {
      auto params = safe_allocator.Allocate<TfLiteArgMinParams>();
      if (const auto* schema_params = op->builtin_options_as_ArgMinOptions()) {
   d61e0:	2800      	cmp	r0, #0
   d61e2:	f000 8185 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef ArgMinOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_OUTPUT_TYPE = 4
  };
  TensorType output_type() const {
    return static_cast<TensorType>(GetField<int8_t>(VT_OUTPUT_TYPE, 0));
   d61e6:	2200      	movs	r2, #0
   d61e8:	2104      	movs	r1, #4
   d61ea:	f7ff fa21 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        ConvertTensorType(schema_params->output_type(), &params->output_type,
                          error_reporter);
   d61ee:	463a      	mov	r2, r7
   d61f0:	4629      	mov	r1, r5
   d61f2:	b2c0      	uxtb	r0, r0
   d61f4:	f7ff f9d4 	bl	d55a0 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE>
   d61f8:	e17a      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d61fa:	4628      	mov	r0, r5
   d61fc:	f7ff fa4e 	bl	d569c <_ZN6tflite20BuiltinDataAllocator11AllocatePODI25TfLiteTransposeConvParamsEEPT_v>
   d6200:	4605      	mov	r5, r0
  }
  const SliceOptions *builtin_options_as_SliceOptions() const {
    return builtin_options_type() == BuiltinOptions_SliceOptions ? static_cast<const SliceOptions *>(builtin_options()) : nullptr;
  }
  const TransposeConvOptions *builtin_options_as_TransposeConvOptions() const {
    return builtin_options_type() == BuiltinOptions_TransposeConvOptions ? static_cast<const TransposeConvOptions *>(builtin_options()) : nullptr;
   d6202:	4620      	mov	r0, r4
   d6204:	f7ff fa04 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6208:	2831      	cmp	r0, #49	; 0x31
   d620a:	f040 8171 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d620e:	4620      	mov	r0, r4
   d6210:	f7ff fa33 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_TRANSPOSE_CONV: {
      auto params = safe_allocator.Allocate<TfLiteTransposeConvParams>();
      if (const auto* transpose_conv_params =
   d6214:	4604      	mov	r4, r0
   d6216:	2800      	cmp	r0, #0
   d6218:	f000 816a 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
    VT_PADDING = 4,
    VT_STRIDE_W = 6,
    VT_STRIDE_H = 8
  };
  Padding padding() const {
    return static_cast<Padding>(GetField<int8_t>(VT_PADDING, 0));
   d621c:	2200      	movs	r2, #0
   d621e:	2104      	movs	r1, #4
   d6220:	f7ff fa06 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
              op->builtin_options_as_TransposeConvOptions()) {
        params->padding = parse_padding(transpose_conv_params->padding());
   d6224:	b2c0      	uxtb	r0, r0
   d6226:	f7ff f973 	bl	d5510 <_ZZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPvENKUlNS_7PaddingEE_clESA_.isra.0>
  }
  int32_t stride_w() const {
    return GetField<int32_t>(VT_STRIDE_W, 0);
   d622a:	2200      	movs	r2, #0
   d622c:	7028      	strb	r0, [r5, #0]
   d622e:	2106      	movs	r1, #6
   d6230:	4620      	mov	r0, r4
   d6232:	f7ff f9f3 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t stride_h() const {
    return GetField<int32_t>(VT_STRIDE_H, 0);
   d6236:	2200      	movs	r2, #0
        params->stride_width = transpose_conv_params->stride_w();
   d6238:	6068      	str	r0, [r5, #4]
   d623a:	2108      	movs	r1, #8
   d623c:	4620      	mov	r0, r4
   d623e:	f7ff f9ed 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->stride_height = transpose_conv_params->stride_h();
   d6242:	60a8      	str	r0, [r5, #8]
   d6244:	e154      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d6246:	4628      	mov	r0, r5
   d6248:	f7ff fa34 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d624c:	4605      	mov	r5, r0
  }
  const TransposeConvOptions *builtin_options_as_TransposeConvOptions() const {
    return builtin_options_type() == BuiltinOptions_TransposeConvOptions ? static_cast<const TransposeConvOptions *>(builtin_options()) : nullptr;
  }
  const SparseToDenseOptions *builtin_options_as_SparseToDenseOptions() const {
    return builtin_options_type() == BuiltinOptions_SparseToDenseOptions ? static_cast<const SparseToDenseOptions *>(builtin_options()) : nullptr;
   d624e:	4620      	mov	r0, r4
   d6250:	f7ff f9de 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6254:	2832      	cmp	r0, #50	; 0x32
   d6256:	f040 814b 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d625a:	4620      	mov	r0, r4
   d625c:	f7ff fa0d 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_SPARSE_TO_DENSE: {
      auto params = safe_allocator.Allocate<TfLiteSparseToDenseParams>();
      if (const auto* sparse_to_dense_params =
   d6260:	2800      	cmp	r0, #0
   d6262:	f000 8145 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef SparseToDenseOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VALIDATE_INDICES = 4
  };
  bool validate_indices() const {
    return GetField<uint8_t>(VT_VALIDATE_INDICES, 0) != 0;
   d6266:	2200      	movs	r2, #0
   d6268:	2104      	movs	r1, #4
   d626a:	f7ff f9c7 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
              op->builtin_options_as_SparseToDenseOptions()) {
        params->validate_indices = sparse_to_dense_params->validate_indices();
   d626e:	3000      	adds	r0, #0
   d6270:	bf18      	it	ne
   d6272:	2001      	movne	r0, #1
   d6274:	7028      	strb	r0, [r5, #0]
   d6276:	e13b      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d6278:	4628      	mov	r0, r5
   d627a:	f7ff fa1b 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d627e:	4605      	mov	r5, r0
  }
  const NotEqualOptions *builtin_options_as_NotEqualOptions() const {
    return builtin_options_type() == BuiltinOptions_NotEqualOptions ? static_cast<const NotEqualOptions *>(builtin_options()) : nullptr;
  }
  const ShapeOptions *builtin_options_as_ShapeOptions() const {
    return builtin_options_type() == BuiltinOptions_ShapeOptions ? static_cast<const ShapeOptions *>(builtin_options()) : nullptr;
   d6280:	4620      	mov	r0, r4
   d6282:	f7ff f9c5 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6286:	2837      	cmp	r0, #55	; 0x37
   d6288:	f040 8132 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d628c:	4620      	mov	r0, r4
   d628e:	f7ff f9f4 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_SHAPE: {
      auto params = safe_allocator.Allocate<TfLiteShapeParams>();
      if (const auto* schema_params = op->builtin_options_as_ShapeOptions()) {
   d6292:	2800      	cmp	r0, #0
   d6294:	f000 812c 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef ShapeOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_OUT_TYPE = 4
  };
  TensorType out_type() const {
    return static_cast<TensorType>(GetField<int8_t>(VT_OUT_TYPE, 0));
   d6298:	2200      	movs	r2, #0
   d629a:	2104      	movs	r1, #4
   d629c:	f7ff f9c8 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        ConvertTensorType(schema_params->out_type(), &params->out_type,
                          error_reporter);
   d62a0:	463a      	mov	r2, r7
   d62a2:	4629      	mov	r1, r5
   d62a4:	b2c0      	uxtb	r0, r0
   d62a6:	f7ff f97b 	bl	d55a0 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE>
   d62aa:	e121      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d62ac:	000ea13f 	.word	0x000ea13f
   d62b0:	000ea147 	.word	0x000ea147
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d62b4:	4628      	mov	r0, r5
   d62b6:	f7ff fa01 	bl	d56bc <_ZN6tflite20BuiltinDataAllocator11AllocatePODI27TfLiteReverseSequenceParamsEEPT_v>
   d62ba:	4605      	mov	r5, r0
  }
  const FakeQuantOptions *builtin_options_as_FakeQuantOptions() const {
    return builtin_options_type() == BuiltinOptions_FakeQuantOptions ? static_cast<const FakeQuantOptions *>(builtin_options()) : nullptr;
  }
  const PackOptions *builtin_options_as_PackOptions() const {
    return builtin_options_type() == BuiltinOptions_PackOptions ? static_cast<const PackOptions *>(builtin_options()) : nullptr;
   d62bc:	4620      	mov	r0, r4
   d62be:	f7ff f9a7 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d62c2:	283b      	cmp	r0, #59	; 0x3b
   d62c4:	f040 8114 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d62c8:	4620      	mov	r0, r4
   d62ca:	f7ff f9d6 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = static_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_PACK: {
      auto params = safe_allocator.Allocate<TfLitePackParams>();
      if (const auto* pack_params = op->builtin_options_as_PackOptions()) {
   d62ce:	4604      	mov	r4, r0
   d62d0:	2800      	cmp	r0, #0
   d62d2:	f000 810d 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VALUES_COUNT = 4,
    VT_AXIS = 6
  };
  int32_t values_count() const {
    return GetField<int32_t>(VT_VALUES_COUNT, 0);
   d62d6:	2200      	movs	r2, #0
   d62d8:	2104      	movs	r1, #4
   d62da:	f7ff f99f 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t axis() const {
    return GetField<int32_t>(VT_AXIS, 0);
   d62de:	2200      	movs	r2, #0
        params->values_count = pack_params->values_count();
   d62e0:	6028      	str	r0, [r5, #0]
   d62e2:	2106      	movs	r1, #6
   d62e4:	4620      	mov	r0, r4
   d62e6:	f7ff f999 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->axis = pack_params->axis();
   d62ea:	6068      	str	r0, [r5, #4]
   d62ec:	e100      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_DELEGATE: {
      // TODO(ycling): Revisit when supporting saving delegated models.
      error_reporter->Report("DELEGATE op shouldn't exist in model.");
   d62ee:	4983      	ldr	r1, [pc, #524]	; (d64fc <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe38>)
   d62f0:	4610      	mov	r0, r2
   d62f2:	f7ff f8fb 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
      return kTfLiteError;
   d62f6:	2001      	movs	r0, #1
   d62f8:	e0fc      	b.n	d64f4 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe30>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d62fa:	4628      	mov	r0, r5
   d62fc:	f7ff f9d2 	bl	d56a4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteFakeQuantParamsEEPT_v>
   d6300:	4605      	mov	r5, r0
  }
  const ArgMinOptions *builtin_options_as_ArgMinOptions() const {
    return builtin_options_type() == BuiltinOptions_ArgMinOptions ? static_cast<const ArgMinOptions *>(builtin_options()) : nullptr;
  }
  const FakeQuantOptions *builtin_options_as_FakeQuantOptions() const {
    return builtin_options_type() == BuiltinOptions_FakeQuantOptions ? static_cast<const FakeQuantOptions *>(builtin_options()) : nullptr;
   d6302:	4620      	mov	r0, r4
   d6304:	f7ff f984 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6308:	283a      	cmp	r0, #58	; 0x3a
   d630a:	f040 80f1 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d630e:	4620      	mov	r0, r4
   d6310:	f7ff f9b3 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      error_reporter->Report("DELEGATE op shouldn't exist in model.");
      return kTfLiteError;
    }
    case BuiltinOperator_FAKE_QUANT: {
      auto params = safe_allocator.Allocate<TfLiteFakeQuantParams>();
      if (const auto* schema_params =
   d6314:	4604      	mov	r4, r0
   d6316:	2800      	cmp	r0, #0
   d6318:	f000 80ea 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
    VT_MAX = 6,
    VT_NUM_BITS = 8,
    VT_NARROW_RANGE = 10
  };
  float min() const {
    return GetField<float>(VT_MIN, 0.0f);
   d631c:	2104      	movs	r1, #4
   d631e:	ed9f 0a78 	vldr	s0, [pc, #480]	; d6500 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe3c>
   d6322:	f7ff f98f 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
  }
  float max() const {
    return GetField<float>(VT_MAX, 0.0f);
   d6326:	2106      	movs	r1, #6
              op->builtin_options_as_FakeQuantOptions()) {
        params->min = schema_params->min();
   d6328:	ed85 0a00 	vstr	s0, [r5]
   d632c:	4620      	mov	r0, r4
   d632e:	ed9f 0a74 	vldr	s0, [pc, #464]	; d6500 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe3c>
   d6332:	f7ff f987 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
  }
  int32_t num_bits() const {
    return GetField<int32_t>(VT_NUM_BITS, 0);
   d6336:	2200      	movs	r2, #0
        params->max = schema_params->max();
   d6338:	ed85 0a01 	vstr	s0, [r5, #4]
   d633c:	2108      	movs	r1, #8
   d633e:	4620      	mov	r0, r4
   d6340:	f7ff f96c 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  bool narrow_range() const {
    return GetField<uint8_t>(VT_NARROW_RANGE, 0) != 0;
   d6344:	2200      	movs	r2, #0
        params->num_bits = schema_params->num_bits();
   d6346:	60a8      	str	r0, [r5, #8]
   d6348:	210a      	movs	r1, #10
   d634a:	4620      	mov	r0, r4
   d634c:	f7ff f956 	bl	d55fc <_ZNK11flatbuffers5Table8GetFieldIhEET_tS2_>
        params->narrow_range = schema_params->narrow_range();
   d6350:	3000      	adds	r0, #0
   d6352:	bf18      	it	ne
   d6354:	2001      	movne	r0, #1
   d6356:	7328      	strb	r0, [r5, #12]
   d6358:	e0ca      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d635a:	4628      	mov	r0, r5
   d635c:	f7ff f9a6 	bl	d56ac <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteLeakyReluParamsEEPT_v>
   d6360:	4605      	mov	r5, r0
  }
  const LogicalOrOptions *builtin_options_as_LogicalOrOptions() const {
    return builtin_options_type() == BuiltinOptions_LogicalOrOptions ? static_cast<const LogicalOrOptions *>(builtin_options()) : nullptr;
  }
  const OneHotOptions *builtin_options_as_OneHotOptions() const {
    return builtin_options_type() == BuiltinOptions_OneHotOptions ? static_cast<const OneHotOptions *>(builtin_options()) : nullptr;
   d6362:	4620      	mov	r0, r4
   d6364:	f7ff f954 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6368:	283d      	cmp	r0, #61	; 0x3d
   d636a:	f040 80c1 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d636e:	4620      	mov	r0, r4
   d6370:	f7ff f983 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = static_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_ONE_HOT: {
      auto params = safe_allocator.Allocate<TfLiteOneHotParams>();
      if (const auto* schema_params = op->builtin_options_as_OneHotOptions()) {
   d6374:	2800      	cmp	r0, #0
   d6376:	f000 80bb 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef OneHotOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_AXIS = 4
  };
  int32_t axis() const {
    return GetField<int32_t>(VT_AXIS, 0);
   d637a:	2200      	movs	r2, #0
   d637c:	2104      	movs	r1, #4
   d637e:	f7ff f94d 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->axis = schema_params->axis();
   d6382:	6028      	str	r0, [r5, #0]
   d6384:	e0b4      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d6386:	4628      	mov	r0, r5
   d6388:	f7ff f998 	bl	d56bc <_ZN6tflite20BuiltinDataAllocator11AllocatePODI27TfLiteReverseSequenceParamsEEPT_v>
   d638c:	4605      	mov	r5, r0
  }
  const LogicalNotOptions *builtin_options_as_LogicalNotOptions() const {
    return builtin_options_type() == BuiltinOptions_LogicalNotOptions ? static_cast<const LogicalNotOptions *>(builtin_options()) : nullptr;
  }
  const UnpackOptions *builtin_options_as_UnpackOptions() const {
    return builtin_options_type() == BuiltinOptions_UnpackOptions ? static_cast<const UnpackOptions *>(builtin_options()) : nullptr;
   d638e:	4620      	mov	r0, r4
   d6390:	f7ff f93e 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6394:	2840      	cmp	r0, #64	; 0x40
   d6396:	f040 80ab 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d639a:	4620      	mov	r0, r4
   d639c:	f7ff f96d 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = static_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_UNPACK: {
      auto params = safe_allocator.Allocate<TfLiteUnpackParams>();
      if (const auto* unpack_params = op->builtin_options_as_UnpackOptions()) {
   d63a0:	4604      	mov	r4, r0
   d63a2:	2800      	cmp	r0, #0
   d63a4:	f000 80a4 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NUM = 4,
    VT_AXIS = 6
  };
  int32_t num() const {
    return GetField<int32_t>(VT_NUM, 0);
   d63a8:	2200      	movs	r2, #0
   d63aa:	2104      	movs	r1, #4
   d63ac:	f7ff f936 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t axis() const {
    return GetField<int32_t>(VT_AXIS, 0);
   d63b0:	2200      	movs	r2, #0
        params->num = unpack_params->num();
   d63b2:	6028      	str	r0, [r5, #0]
   d63b4:	2106      	movs	r1, #6
   d63b6:	4620      	mov	r0, r4
   d63b8:	f7ff f930 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->axis = unpack_params->axis();
   d63bc:	6068      	str	r0, [r5, #4]
   d63be:	e097      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d63c0:	4628      	mov	r0, r5
   d63c2:	f7ff f973 	bl	d56ac <_ZN6tflite20BuiltinDataAllocator11AllocatePODI21TfLiteLeakyReluParamsEEPT_v>
   d63c6:	4605      	mov	r5, r0
  }
  const ResizeNearestNeighborOptions *builtin_options_as_ResizeNearestNeighborOptions() const {
    return builtin_options_type() == BuiltinOptions_ResizeNearestNeighborOptions ? static_cast<const ResizeNearestNeighborOptions *>(builtin_options()) : nullptr;
  }
  const LeakyReluOptions *builtin_options_as_LeakyReluOptions() const {
    return builtin_options_type() == BuiltinOptions_LeakyReluOptions ? static_cast<const LeakyReluOptions *>(builtin_options()) : nullptr;
   d63c8:	4620      	mov	r0, r4
   d63ca:	f7ff f921 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d63ce:	284b      	cmp	r0, #75	; 0x4b
   d63d0:	f040 808e 	bne.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d63d4:	4620      	mov	r0, r4
   d63d6:	f7ff f950 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_LEAKY_RELU: {
      auto params = safe_allocator.Allocate<TfLiteLeakyReluParams>();
      if (const auto* leaky_relu_params =
   d63da:	2800      	cmp	r0, #0
   d63dc:	f000 8088 	beq.w	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef LeakyReluOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ALPHA = 4
  };
  float alpha() const {
    return GetField<float>(VT_ALPHA, 0.0f);
   d63e0:	ed9f 0a47 	vldr	s0, [pc, #284]	; d6500 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe3c>
   d63e4:	2104      	movs	r1, #4
   d63e6:	f7ff f92d 	bl	d5644 <_ZNK11flatbuffers5Table8GetFieldIfEET_tS2_>
              op->builtin_options_as_LeakyReluOptions()) {
        params->alpha = leaky_relu_params->alpha();
   d63ea:	ed85 0a00 	vstr	s0, [r5]
   d63ee:	e07f      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d63f0:	4628      	mov	r0, r5
   d63f2:	f7ff f95f 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d63f6:	4605      	mov	r5, r0
  }
  const SquaredDifferenceOptions *builtin_options_as_SquaredDifferenceOptions() const {
    return builtin_options_type() == BuiltinOptions_SquaredDifferenceOptions ? static_cast<const SquaredDifferenceOptions *>(builtin_options()) : nullptr;
  }
  const MirrorPadOptions *builtin_options_as_MirrorPadOptions() const {
    return builtin_options_type() == BuiltinOptions_MirrorPadOptions ? static_cast<const MirrorPadOptions *>(builtin_options()) : nullptr;
   d63f8:	4620      	mov	r0, r4
   d63fa:	f7ff f909 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d63fe:	284d      	cmp	r0, #77	; 0x4d
   d6400:	d176      	bne.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d6402:	4620      	mov	r0, r4
   d6404:	f7ff f939 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      break;
    }
    case BuiltinOperator_MIRROR_PAD: {
      auto params = safe_allocator.Allocate<TfLiteMirrorPaddingParams>();
      const auto* mirror_pad_params = op->builtin_options_as_MirrorPadOptions();
      if (mirror_pad_params != nullptr) {
   d6408:	2800      	cmp	r0, #0
   d640a:	d071      	beq.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef MirrorPadOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_MODE = 4
  };
  MirrorPadMode mode() const {
    return static_cast<MirrorPadMode>(GetField<int8_t>(VT_MODE, 0));
   d640c:	2200      	movs	r2, #0
   d640e:	2104      	movs	r1, #4
   d6410:	f7ff f90e 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->mode =
            mirror_pad_params->mode() == tflite::MirrorPadMode_REFLECT
                ? TfLiteMirrorPaddingMode::kTfLiteMirrorPaddingReflect
                : TfLiteMirrorPaddingMode::kTfLiteMirrorPaddingSymmetric;
   d6414:	b2c0      	uxtb	r0, r0
   d6416:	2800      	cmp	r0, #0
   d6418:	bf0c      	ite	eq
   d641a:	2301      	moveq	r3, #1
   d641c:	2302      	movne	r3, #2
   d641e:	702b      	strb	r3, [r5, #0]
   d6420:	e066      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d6422:	4628      	mov	r0, r5
   d6424:	f7ff f946 	bl	d56b4 <_ZN6tflite20BuiltinDataAllocator11AllocatePODI18TfLiteUniqueParamsEEPT_v>
   d6428:	4605      	mov	r5, r0
  }
  const SplitVOptions *builtin_options_as_SplitVOptions() const {
    return builtin_options_type() == BuiltinOptions_SplitVOptions ? static_cast<const SplitVOptions *>(builtin_options()) : nullptr;
  }
  const UniqueOptions *builtin_options_as_UniqueOptions() const {
    return builtin_options_type() == BuiltinOptions_UniqueOptions ? static_cast<const UniqueOptions *>(builtin_options()) : nullptr;
   d642a:	4620      	mov	r0, r4
   d642c:	f7ff f8f0 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6430:	2850      	cmp	r0, #80	; 0x50
   d6432:	d15d      	bne.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d6434:	4620      	mov	r0, r4
   d6436:	f7ff f920 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      break;
    }
    case BuiltinOperator_UNIQUE: {
      auto params = safe_allocator.Allocate<TfLiteUniqueParams>();
      const auto* unique_params = op->builtin_options_as_UniqueOptions();
      if (unique_params != nullptr) {
   d643a:	2800      	cmp	r0, #0
   d643c:	d058      	beq.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  typedef UniqueOptionsT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_IDX_OUT_TYPE = 4
  };
  TensorType idx_out_type() const {
    return static_cast<TensorType>(GetField<int8_t>(VT_IDX_OUT_TYPE, 2));
   d643e:	2202      	movs	r2, #2
   d6440:	2104      	movs	r1, #4
   d6442:	f7ff f8f5 	bl	d5630 <_ZNK11flatbuffers5Table8GetFieldIaEET_tS2_>
        params->index_out_type =
            unique_params->idx_out_type() == tflite::TensorType_INT64
                ? TfLiteType::kTfLiteInt64
                : TfLiteType::kTfLiteInt32;
   d6446:	b2c0      	uxtb	r0, r0
   d6448:	2804      	cmp	r0, #4
   d644a:	bf0c      	ite	eq
   d644c:	2304      	moveq	r3, #4
   d644e:	2302      	movne	r3, #2
   d6450:	702b      	strb	r3, [r5, #0]
   d6452:	e04d      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      : allocator_(allocator) {}

  template <typename T>
  BuiltinDataPtr<T> Allocate() {
    return BuiltinDataPtr<T>(allocator_->AllocatePOD<T>(),
                             BuiltinDataDeleter(allocator_));
   d6454:	4628      	mov	r0, r5
   d6456:	f7ff f931 	bl	d56bc <_ZN6tflite20BuiltinDataAllocator11AllocatePODI27TfLiteReverseSequenceParamsEEPT_v>
   d645a:	4605      	mov	r5, r0
  }
  const RankOptions *builtin_options_as_RankOptions() const {
    return builtin_options_type() == BuiltinOptions_RankOptions ? static_cast<const RankOptions *>(builtin_options()) : nullptr;
  }
  const ReverseSequenceOptions *builtin_options_as_ReverseSequenceOptions() const {
    return builtin_options_type() == BuiltinOptions_ReverseSequenceOptions ? static_cast<const ReverseSequenceOptions *>(builtin_options()) : nullptr;
   d645c:	4620      	mov	r0, r4
   d645e:	f7ff f8d7 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6462:	2857      	cmp	r0, #87	; 0x57
   d6464:	d144      	bne.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d6466:	4620      	mov	r0, r4
   d6468:	f7ff f907 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_REVERSE_SEQUENCE: {
      auto params = safe_allocator.Allocate<TfLiteReverseSequenceParams>();
      if (const auto* reverse_seq_params =
   d646c:	4604      	mov	r4, r0
   d646e:	2800      	cmp	r0, #0
   d6470:	d03e      	beq.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_SEQ_DIM = 4,
    VT_BATCH_DIM = 6
  };
  int32_t seq_dim() const {
    return GetField<int32_t>(VT_SEQ_DIM, 0);
   d6472:	2200      	movs	r2, #0
   d6474:	2104      	movs	r1, #4
   d6476:	f7ff f8d1 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t batch_dim() const {
    return GetField<int32_t>(VT_BATCH_DIM, 0);
   d647a:	2200      	movs	r2, #0
              op->builtin_options_as_ReverseSequenceOptions()) {
        params->seq_dim = reverse_seq_params->seq_dim();
   d647c:	6028      	str	r0, [r5, #0]
   d647e:	2106      	movs	r1, #6
   d6480:	4620      	mov	r0, r4
   d6482:	f7ff f8cb 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->batch_dim = reverse_seq_params->batch_dim();
   d6486:	6068      	str	r0, [r5, #4]
   d6488:	e032      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      }
      *builtin_data = reinterpret_cast<void*>(params.release());
      break;
    }
    case BuiltinOperator_IF: {
      TfLiteIfParams* params = allocator->AllocatePOD<TfLiteIfParams>();
   d648a:	4628      	mov	r0, r5
   d648c:	f7ff f916 	bl	d56bc <_ZN6tflite20BuiltinDataAllocator11AllocatePODI27TfLiteReverseSequenceParamsEEPT_v>
   d6490:	4605      	mov	r5, r0
  }
  const HardSwishOptions *builtin_options_as_HardSwishOptions() const {
    return builtin_options_type() == BuiltinOptions_HardSwishOptions ? static_cast<const HardSwishOptions *>(builtin_options()) : nullptr;
  }
  const IfOptions *builtin_options_as_IfOptions() const {
    return builtin_options_type() == BuiltinOptions_IfOptions ? static_cast<const IfOptions *>(builtin_options()) : nullptr;
   d6492:	4620      	mov	r0, r4
   d6494:	f7ff f8bc 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d6498:	285c      	cmp	r0, #92	; 0x5c
   d649a:	d129      	bne.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d649c:	4620      	mov	r0, r4
   d649e:	f7ff f8ec 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      if (const auto* if_params = op->builtin_options_as_IfOptions()) {
   d64a2:	4604      	mov	r4, r0
   d64a4:	b320      	cbz	r0, d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_THEN_SUBGRAPH_INDEX = 4,
    VT_ELSE_SUBGRAPH_INDEX = 6
  };
  int32_t then_subgraph_index() const {
    return GetField<int32_t>(VT_THEN_SUBGRAPH_INDEX, 0);
   d64a6:	2200      	movs	r2, #0
   d64a8:	2104      	movs	r1, #4
   d64aa:	f7ff f8b7 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t else_subgraph_index() const {
    return GetField<int32_t>(VT_ELSE_SUBGRAPH_INDEX, 0);
   d64ae:	2200      	movs	r2, #0
        params->then_subgraph_index = if_params->then_subgraph_index();
   d64b0:	6028      	str	r0, [r5, #0]
   d64b2:	2106      	movs	r1, #6
   d64b4:	4620      	mov	r0, r4
   d64b6:	f7ff f8b1 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->else_subgraph_index = if_params->else_subgraph_index();
   d64ba:	6068      	str	r0, [r5, #4]
   d64bc:	e018      	b.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
      }
      *builtin_data = reinterpret_cast<void*>(params);
      break;
    }
    case BuiltinOperator_WHILE: {
      TfLiteWhileParams* params = allocator->AllocatePOD<TfLiteWhileParams>();
   d64be:	4628      	mov	r0, r5
   d64c0:	f7ff f8fc 	bl	d56bc <_ZN6tflite20BuiltinDataAllocator11AllocatePODI27TfLiteReverseSequenceParamsEEPT_v>
   d64c4:	4605      	mov	r5, r0
  }
  const IfOptions *builtin_options_as_IfOptions() const {
    return builtin_options_type() == BuiltinOptions_IfOptions ? static_cast<const IfOptions *>(builtin_options()) : nullptr;
  }
  const WhileOptions *builtin_options_as_WhileOptions() const {
    return builtin_options_type() == BuiltinOptions_WhileOptions ? static_cast<const WhileOptions *>(builtin_options()) : nullptr;
   d64c6:	4620      	mov	r0, r4
   d64c8:	f7ff f8a2 	bl	d5610 <_ZNK6tflite8Operator20builtin_options_typeEv>
   d64cc:	285d      	cmp	r0, #93	; 0x5d
   d64ce:	d10f      	bne.n	d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
   d64d0:	4620      	mov	r0, r4
   d64d2:	f7ff f8d2 	bl	d567a <_ZNK6tflite8Operator15builtin_optionsEv>
      if (const auto* while_params = op->builtin_options_as_WhileOptions()) {
   d64d6:	4604      	mov	r4, r0
   d64d8:	b150      	cbz	r0, d64f0 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv+0xe2c>
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_COND_SUBGRAPH_INDEX = 4,
    VT_BODY_SUBGRAPH_INDEX = 6
  };
  int32_t cond_subgraph_index() const {
    return GetField<int32_t>(VT_COND_SUBGRAPH_INDEX, 0);
   d64da:	2200      	movs	r2, #0
   d64dc:	2104      	movs	r1, #4
   d64de:	f7ff f89d 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
  }
  int32_t body_subgraph_index() const {
    return GetField<int32_t>(VT_BODY_SUBGRAPH_INDEX, 0);
   d64e2:	2200      	movs	r2, #0
        params->cond_subgraph_index = while_params->cond_subgraph_index();
   d64e4:	6028      	str	r0, [r5, #0]
   d64e6:	2106      	movs	r1, #6
   d64e8:	4620      	mov	r0, r4
   d64ea:	f7ff f897 	bl	d561c <_ZNK11flatbuffers5Table8GetFieldIlEET_tS2_>
        params->body_subgraph_index = while_params->body_subgraph_index();
   d64ee:	6068      	str	r0, [r5, #4]
      }
      *builtin_data = reinterpret_cast<void*>(params);
   d64f0:	6035      	str	r5, [r6, #0]
    case BuiltinOperator_QUANTIZE:
    case BuiltinOperator_NON_MAX_SUPPRESSION_V4:
    case BuiltinOperator_NON_MAX_SUPPRESSION_V5:
      break;
  }
  return kTfLiteOk;
   d64f2:	2000      	movs	r0, #0
}  // NOLINT[readability/fn_size]
   d64f4:	b002      	add	sp, #8
   d64f6:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   d64fa:	bf00      	nop
   d64fc:	000ea14f 	.word	0x000ea14f
   d6500:	00000000 	.word	0x00000000

000d6504 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration>:

namespace tflite {

TfLiteStatus GetRegistrationFromOpCode(
    const OperatorCode* opcode, const OpResolver& op_resolver,
    ErrorReporter* error_reporter, const TfLiteRegistration** registration) {
   d6504:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
   d6508:	461f      	mov	r7, r3
  TfLiteStatus status = kTfLiteOk;
  *registration = nullptr;
   d650a:	2300      	movs	r3, #0

namespace tflite {

TfLiteStatus GetRegistrationFromOpCode(
    const OperatorCode* opcode, const OpResolver& op_resolver,
    ErrorReporter* error_reporter, const TfLiteRegistration** registration) {
   d650c:	460e      	mov	r6, r1
  TfLiteStatus status = kTfLiteOk;
  *registration = nullptr;
   d650e:	603b      	str	r3, [r7, #0]
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
    auto field_offset = GetOptionalFieldOffset(field);
   d6510:	2104      	movs	r1, #4

namespace tflite {

TfLiteStatus GetRegistrationFromOpCode(
    const OperatorCode* opcode, const OpResolver& op_resolver,
    ErrorReporter* error_reporter, const TfLiteRegistration** registration) {
   d6512:	4605      	mov	r5, r0
   d6514:	4690      	mov	r8, r2
   d6516:	f7ff f83b 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d651a:	b100      	cbz	r0, d651e <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0x1a>
   d651c:	5628      	ldrsb	r0, [r5, r0]
    VT_BUILTIN_CODE = 4,
    VT_CUSTOM_CODE = 6,
    VT_VERSION = 8
  };
  BuiltinOperator builtin_code() const {
    return static_cast<BuiltinOperator>(GetField<int8_t>(VT_BUILTIN_CODE, 0));
   d651e:	b2c4      	uxtb	r4, r0
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
    auto field_offset = GetOptionalFieldOffset(field);
   d6520:	2108      	movs	r1, #8
   d6522:	4628      	mov	r0, r5
   d6524:	f7ff f834 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d6528:	b110      	cbz	r0, d6530 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0x2c>
   d652a:	f855 9000 	ldr.w	r9, [r5, r0]
   d652e:	e001      	b.n	d6534 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0x30>
   d6530:	f04f 0901 	mov.w	r9, #1
  TfLiteStatus status = kTfLiteOk;
  *registration = nullptr;
  auto builtin_code = opcode->builtin_code();
  int version = opcode->version();

  if (builtin_code > BuiltinOperator_MAX ||
   d6534:	2c79      	cmp	r4, #121	; 0x79
   d6536:	d905      	bls.n	d6544 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0x40>
      builtin_code < BuiltinOperator_MIN) {
    error_reporter->Report(
        "Op builtin_code out of range: %d. Are you using old TFLite binary "
        "with newer model?",
        builtin_code);
   d6538:	4622      	mov	r2, r4
   d653a:	491b      	ldr	r1, [pc, #108]	; (d65a8 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0xa4>)
   d653c:	4640      	mov	r0, r8
   d653e:	f7fe ffd5 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
   d6542:	e01f      	b.n	d6584 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0x80>
    status = kTfLiteError;
  } else if (builtin_code != BuiltinOperator_CUSTOM) {
   d6544:	2c20      	cmp	r4, #32
   d6546:	d010      	beq.n	d656a <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0x66>
    *registration = op_resolver.FindOp(builtin_code, version);
   d6548:	6833      	ldr	r3, [r6, #0]
   d654a:	464a      	mov	r2, r9
   d654c:	681b      	ldr	r3, [r3, #0]
   d654e:	4621      	mov	r1, r4
   d6550:	4630      	mov	r0, r6
   d6552:	4798      	blx	r3
   d6554:	6038      	str	r0, [r7, #0]
    if (*registration == nullptr) {
   d6556:	bb20      	cbnz	r0, d65a2 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0x9e>
      error_reporter->Report(
          "Didn't find op for builtin opcode '%s' version '%d'\n",
          EnumNameBuiltinOperator(builtin_code), version);
   d6558:	4a14      	ldr	r2, [pc, #80]	; (d65ac <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0xa8>)
   d655a:	4915      	ldr	r1, [pc, #84]	; (d65b0 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0xac>)
   d655c:	f852 2024 	ldr.w	r2, [r2, r4, lsl #2]
   d6560:	464b      	mov	r3, r9
   d6562:	4640      	mov	r0, r8
   d6564:	f7fe ffc2 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
   d6568:	e00c      	b.n	d6584 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0x80>
  }

  template<typename P> P GetPointer(voffset_t field) {
    auto field_offset = GetOptionalFieldOffset(field);
   d656a:	2106      	movs	r1, #6
   d656c:	4628      	mov	r0, r5
   d656e:	f7ff f80f 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    auto p = data_ + field_offset;
   d6572:	182a      	adds	r2, r5, r0
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
   d6574:	b110      	cbz	r0, d657c <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0x78>
   d6576:	5829      	ldr	r1, [r5, r0]
      status = kTfLiteError;
    }
  } else if (!opcode->custom_code()) {
   d6578:	1851      	adds	r1, r2, r1
   d657a:	d106      	bne.n	d658a <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0x86>
    error_reporter->Report(
        "Operator with CUSTOM builtin_code has no custom_code.\n");
   d657c:	490d      	ldr	r1, [pc, #52]	; (d65b4 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration+0xb0>)
   d657e:	4640      	mov	r0, r8
   d6580:	f7fe ffb4 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    status = kTfLiteError;
   d6584:	2001      	movs	r0, #1
   d6586:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
  } else {
    const char* name = opcode->custom_code()->c_str();
    *registration = op_resolver.FindOp(name, version);
   d658a:	6833      	ldr	r3, [r6, #0]
   d658c:	464a      	mov	r2, r9
   d658e:	685b      	ldr	r3, [r3, #4]
   d6590:	3104      	adds	r1, #4
   d6592:	4630      	mov	r0, r6
   d6594:	4798      	blx	r3
   d6596:	6038      	str	r0, [r7, #0]
      builtin_code < BuiltinOperator_MIN) {
    error_reporter->Report(
        "Op builtin_code out of range: %d. Are you using old TFLite binary "
        "with newer model?",
        builtin_code);
    status = kTfLiteError;
   d6598:	fab0 f080 	clz	r0, r0
   d659c:	0940      	lsrs	r0, r0, #5
   d659e:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
namespace tflite {

TfLiteStatus GetRegistrationFromOpCode(
    const OperatorCode* opcode, const OpResolver& op_resolver,
    ErrorReporter* error_reporter, const TfLiteRegistration** registration) {
  TfLiteStatus status = kTfLiteOk;
   d65a2:	2000      	movs	r0, #0
      // while preparing ops.
      status = kTfLiteError;
    }
  }
  return status;
}
   d65a4:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
   d65a8:	000ea368 	.word	0x000ea368
   d65ac:	000ea17c 	.word	0x000ea17c
   d65b0:	000ea3bc 	.word	0x000ea3bc
   d65b4:	000ea3f1 	.word	0x000ea3f1

000d65b8 <_ZN6tflite19ResetVariableTensorEP12TfLiteTensor>:

#include <string.h>

namespace tflite {

TfLiteStatus ResetVariableTensor(TfLiteTensor* tensor) {
   d65b8:	b530      	push	{r4, r5, lr}
  if (!tensor->is_variable) {
   d65ba:	f890 302d 	ldrb.w	r3, [r0, #45]	; 0x2d
   d65be:	b16b      	cbz	r3, d65dc <_ZN6tflite19ResetVariableTensorEP12TfLiteTensor+0x24>
    return kTfLiteOk;
  }
  // TODO(b/115961645): Implement - If a variable tensor has a buffer, reset it
  // to the value of the buffer.
  int value = 0;
  if (tensor->type == kTfLiteInt8) {
   d65c0:	7803      	ldrb	r3, [r0, #0]
#if __ANDROID__ || defined(__x86_64__) || defined(__i386__) || \
    defined(__i386) || defined(__x86__) || defined(__X86__) || \
    defined(_X86_) || defined(_M_IX86) || defined(_M_X64)
  memset(tensor->data.raw, value, tensor->bytes);
#else
  char* raw_ptr = tensor->data.raw;
   d65c2:	6844      	ldr	r4, [r0, #4]
    return kTfLiteOk;
  }
  // TODO(b/115961645): Implement - If a variable tensor has a buffer, reset it
  // to the value of the buffer.
  int value = 0;
  if (tensor->type == kTfLiteInt8) {
   d65c4:	2b09      	cmp	r3, #9
    value = tensor->params.zero_point;
   d65c6:	bf0c      	ite	eq
   d65c8:	6901      	ldreq	r1, [r0, #16]
  if (!tensor->is_variable) {
    return kTfLiteOk;
  }
  // TODO(b/115961645): Implement - If a variable tensor has a buffer, reset it
  // to the value of the buffer.
  int value = 0;
   d65ca:	2100      	movne	r1, #0
#if __ANDROID__ || defined(__x86_64__) || defined(__i386__) || \
    defined(__i386) || defined(__x86__) || defined(__X86__) || \
    defined(_X86_) || defined(_M_IX86) || defined(_M_X64)
  memset(tensor->data.raw, value, tensor->bytes);
#else
  char* raw_ptr = tensor->data.raw;
   d65cc:	4623      	mov	r3, r4
  for (int i = 0; i < tensor->bytes; ++i) {
   d65ce:	6985      	ldr	r5, [r0, #24]
   d65d0:	1b1a      	subs	r2, r3, r4
   d65d2:	4295      	cmp	r5, r2
   d65d4:	d902      	bls.n	d65dc <_ZN6tflite19ResetVariableTensorEP12TfLiteTensor+0x24>
    *raw_ptr = value;
   d65d6:	f803 1b01 	strb.w	r1, [r3], #1
    defined(__i386) || defined(__x86__) || defined(__X86__) || \
    defined(_X86_) || defined(_M_IX86) || defined(_M_X64)
  memset(tensor->data.raw, value, tensor->bytes);
#else
  char* raw_ptr = tensor->data.raw;
  for (int i = 0; i < tensor->bytes; ++i) {
   d65da:	e7f8      	b.n	d65ce <_ZN6tflite19ResetVariableTensorEP12TfLiteTensor+0x16>
    *raw_ptr = value;
    raw_ptr++;
  }
#endif
  return kTfLiteOk;
}
   d65dc:	2000      	movs	r0, #0
   d65de:	bd30      	pop	{r4, r5, pc}

000d65e0 <_ZN12_GLOBAL__N_19StrCatStrEPciPKc>:
  return start;
}

// Appends a string to a string, in-place. You need to pass in the maximum
// string length as the second argument.
char* StrCatStr(char* main, int main_max_length, const char* to_append) {
   d65e0:	b530      	push	{r4, r5, lr}
   d65e2:	4604      	mov	r4, r0
   d65e4:	4623      	mov	r3, r4
   d65e6:	3401      	adds	r4, #1
  char* current = main;
  while (*current != 0) {
   d65e8:	781d      	ldrb	r5, [r3, #0]
   d65ea:	2d00      	cmp	r5, #0
   d65ec:	d1fa      	bne.n	d65e4 <_ZN12_GLOBAL__N_19StrCatStrEPciPKc+0x4>
    ++current;
  }
  char* current_end = main + (main_max_length - 1);
   d65ee:	3901      	subs	r1, #1
   d65f0:	4408      	add	r0, r1
   d65f2:	3a01      	subs	r2, #1
  while ((*to_append != 0) && (current < current_end)) {
   d65f4:	f812 1f01 	ldrb.w	r1, [r2, #1]!
   d65f8:	b121      	cbz	r1, d6604 <_ZN12_GLOBAL__N_19StrCatStrEPciPKc+0x24>
   d65fa:	4283      	cmp	r3, r0
   d65fc:	d202      	bcs.n	d6604 <_ZN12_GLOBAL__N_19StrCatStrEPciPKc+0x24>
    *current = *to_append;
   d65fe:	f803 1b01 	strb.w	r1, [r3], #1
  char* current = main;
  while (*current != 0) {
    ++current;
  }
  char* current_end = main + (main_max_length - 1);
  while ((*to_append != 0) && (current < current_end)) {
   d6602:	e7f7      	b.n	d65f4 <_ZN12_GLOBAL__N_19StrCatStrEPciPKc+0x14>
    *current = *to_append;
    ++current;
    ++to_append;
  }
  *current = 0;
   d6604:	2200      	movs	r2, #0
   d6606:	701a      	strb	r2, [r3, #0]
  return current;
}
   d6608:	4618      	mov	r0, r3
   d660a:	bd30      	pop	{r4, r5, pc}

000d660c <_ZN12_GLOBAL__N_122FastUInt32ToBufferLeftEmPci>:

// Populates the provided buffer with an ASCII representation of the number.
char* FastUInt32ToBufferLeft(uint32_t i, char* buffer, int base) {
   d660c:	b530      	push	{r4, r5, lr}
   d660e:	4603      	mov	r3, r0
   d6610:	460c      	mov	r4, r1
  char* start = buffer;
  do {
    int32_t digit = i % base;
   d6612:	fbb3 f5f2 	udiv	r5, r3, r2
   d6616:	fb02 3315 	mls	r3, r2, r5, r3
    char character;
    if (digit < 10) {
   d661a:	2b09      	cmp	r3, #9
      character = '0' + digit;
   d661c:	bfd4      	ite	le
   d661e:	3330      	addle	r3, #48	; 0x30
    } else {
      character = 'a' + (digit - 10);
   d6620:	3357      	addgt	r3, #87	; 0x57
    }
    *buffer++ = character;
   d6622:	4620      	mov	r0, r4
    int32_t digit = i % base;
    char character;
    if (digit < 10) {
      character = '0' + digit;
    } else {
      character = 'a' + (digit - 10);
   d6624:	b2db      	uxtb	r3, r3
    }
    *buffer++ = character;
   d6626:	f800 3b01 	strb.w	r3, [r0], #1
    i /= base;
   d662a:	462b      	mov	r3, r5
  } while (i > 0);
   d662c:	b10d      	cbz	r5, d6632 <_ZN12_GLOBAL__N_122FastUInt32ToBufferLeftEmPci+0x26>
   d662e:	4604      	mov	r4, r0
   d6630:	e7ef      	b.n	d6612 <_ZN12_GLOBAL__N_122FastUInt32ToBufferLeftEmPci+0x6>
  *buffer = 0;
   d6632:	7065      	strb	r5, [r4, #1]

// Reverses a zero-terminated string in-place.
char* ReverseStringInPlace(char* start, char* end) {
  char* p1 = start;
  char* p2 = end - 1;
  while (p1 < p2) {
   d6634:	42a1      	cmp	r1, r4
   d6636:	d206      	bcs.n	d6646 <_ZN12_GLOBAL__N_122FastUInt32ToBufferLeftEmPci+0x3a>
    char tmp = *p1;
   d6638:	780b      	ldrb	r3, [r1, #0]
    *p1++ = *p2;
   d663a:	7822      	ldrb	r2, [r4, #0]
   d663c:	f801 2b01 	strb.w	r2, [r1], #1
    *p2-- = tmp;
   d6640:	f804 3901 	strb.w	r3, [r4], #-1
   d6644:	e7f6      	b.n	d6634 <_ZN12_GLOBAL__N_122FastUInt32ToBufferLeftEmPci+0x28>
    i /= base;
  } while (i > 0);
  *buffer = 0;
  ReverseStringInPlace(start, buffer);
  return buffer;
}
   d6646:	bd30      	pop	{r4, r5, pc}

000d6648 <DebugLogInt32>:
  return current;
}

}  // namespace

extern "C" void DebugLogInt32(int32_t i) {
   d6648:	b500      	push	{lr}
}

// Populates the provided buffer with an ASCII representation of the number.
char* FastInt32ToBufferLeft(int32_t i, char* buffer) {
  uint32_t u = i;
  if (i < 0) {
   d664a:	2800      	cmp	r0, #0
  return current;
}

}  // namespace

extern "C" void DebugLogInt32(int32_t i) {
   d664c:	b08d      	sub	sp, #52	; 0x34

// Populates the provided buffer with an ASCII representation of the number.
char* FastInt32ToBufferLeft(int32_t i, char* buffer) {
  uint32_t u = i;
  if (i < 0) {
    *buffer++ = '-';
   d664e:	bfbd      	ittte	lt
   d6650:	232d      	movlt	r3, #45	; 0x2d
    u = -u;
   d6652:	4240      	neglt	r0, r0

// Populates the provided buffer with an ASCII representation of the number.
char* FastInt32ToBufferLeft(int32_t i, char* buffer) {
  uint32_t u = i;
  if (i < 0) {
    *buffer++ = '-';
   d6654:	f10d 0101 	addlt.w	r1, sp, #1
}

// Populates the provided buffer with an ASCII representation of the number.
char* FastInt32ToBufferLeft(int32_t i, char* buffer) {
  uint32_t u = i;
  if (i < 0) {
   d6658:	4669      	movge	r1, sp
    *buffer++ = '-';
    u = -u;
  }
  return FastUInt32ToBufferLeft(u, buffer, 10);
   d665a:	f04f 020a 	mov.w	r2, #10

// Populates the provided buffer with an ASCII representation of the number.
char* FastInt32ToBufferLeft(int32_t i, char* buffer) {
  uint32_t u = i;
  if (i < 0) {
    *buffer++ = '-';
   d665e:	bfb8      	it	lt
   d6660:	f88d 3000 	strblt.w	r3, [sp]
    u = -u;
  }
  return FastUInt32ToBufferLeft(u, buffer, 10);
   d6664:	f7ff ffd2 	bl	d660c <_ZN12_GLOBAL__N_122FastUInt32ToBufferLeftEmPci>
}  // namespace

extern "C" void DebugLogInt32(int32_t i) {
  char number_string[kFastToBufferSize];
  FastInt32ToBufferLeft(i, number_string);
  DebugLog(number_string);
   d6668:	4668      	mov	r0, sp
   d666a:	f000 ff61 	bl	d7530 <DebugLog>
}
   d666e:	b00d      	add	sp, #52	; 0x34
   d6670:	f85d fb04 	ldr.w	pc, [sp], #4

000d6674 <DebugLogFloat>:
  char number_string[kFastToBufferSize];
  FastUInt32ToBufferLeft(i, number_string, 16);
  DebugLog(number_string);
}

extern "C" void DebugLogFloat(float i) {
   d6674:	b5f0      	push	{r4, r5, r6, r7, lr}
  const uint32_t sign_mask = 0x80000000;
  const uint32_t exponent_mask = 0x7f800000;
  const int32_t exponent_shift = 23;
  const int32_t exponent_bias = 127;
  const uint32_t fraction_mask = 0x007fffff;
  const uint32_t u = *reinterpret_cast<uint32_t*>(&f);
   d6676:	ee10 3a10 	vmov	r3, s0
  char number_string[kFastToBufferSize];
  FastUInt32ToBufferLeft(i, number_string, 16);
  DebugLog(number_string);
}

extern "C" void DebugLogFloat(float i) {
   d667a:	b09d      	sub	sp, #116	; 0x74
  const uint32_t u = *reinterpret_cast<uint32_t*>(&f);
  const int32_t exponent =
      ((u & exponent_mask) >> exponent_shift) - exponent_bias;
  const uint32_t fraction = (u & fraction_mask);
  // Expect ~0x2B1B9D3 for fraction.
  if (u & sign_mask) {
   d667c:	2b00      	cmp	r3, #0
  const int32_t exponent_shift = 23;
  const int32_t exponent_bias = 127;
  const uint32_t fraction_mask = 0x007fffff;
  const uint32_t u = *reinterpret_cast<uint32_t*>(&f);
  const int32_t exponent =
      ((u & exponent_mask) >> exponent_shift) - exponent_bias;
   d667e:	f3c3 54c7 	ubfx	r4, r3, #23, #8
  const uint32_t fraction = (u & fraction_mask);
   d6682:	f3c3 0716 	ubfx	r7, r3, #0, #23
  // Expect ~0x2B1B9D3 for fraction.
  if (u & sign_mask) {
    *current = '-';
   d6686:	bfbb      	ittet	lt
   d6688:	232d      	movlt	r3, #45	; 0x2d
   d668a:	f88d 3010 	strblt.w	r3, [sp, #16]
// Populates the provided buffer with ASCII representation of the float number.
// Avoids the use of any floating point instructions (since these aren't
// supported on many microcontrollers) and as a consequence prints values with
// power-of-two exponents.
char* FastFloatToBufferLeft(float f, char* buffer) {
  char* current = buffer;
   d668e:	ab04      	addge	r3, sp, #16
      ((u & exponent_mask) >> exponent_shift) - exponent_bias;
  const uint32_t fraction = (u & fraction_mask);
  // Expect ~0x2B1B9D3 for fraction.
  if (u & sign_mask) {
    *current = '-';
    current += 1;
   d6690:	f10d 0311 	addlt.w	r3, sp, #17
  const int32_t exponent_shift = 23;
  const int32_t exponent_bias = 127;
  const uint32_t fraction_mask = 0x007fffff;
  const uint32_t u = *reinterpret_cast<uint32_t*>(&f);
  const int32_t exponent =
      ((u & exponent_mask) >> exponent_shift) - exponent_bias;
   d6694:	3c7f      	subs	r4, #127	; 0x7f
  // Expect ~0x2B1B9D3 for fraction.
  if (u & sign_mask) {
    *current = '-';
    current += 1;
  }
  *current = 0;
   d6696:	2200      	movs	r2, #0
  // These are special cases for infinities and not-a-numbers.
  if (exponent == 128) {
   d6698:	2c80      	cmp	r4, #128	; 0x80
  // Expect ~0x2B1B9D3 for fraction.
  if (u & sign_mask) {
    *current = '-';
    current += 1;
  }
  *current = 0;
   d669a:	701a      	strb	r2, [r3, #0]
  // These are special cases for infinities and not-a-numbers.
  if (exponent == 128) {
   d669c:	d108      	bne.n	d66b0 <DebugLogFloat+0x3c>
   d669e:	f10d 013f 	add.w	r1, sp, #63	; 0x3f
    if (fraction == 0) {
   d66a2:	b90f      	cbnz	r7, d66a8 <DebugLogFloat+0x34>
      current = StrCatStr(current, (current_end - current), "Inf");
   d66a4:	4a2a      	ldr	r2, [pc, #168]	; (d6750 <DebugLogFloat+0xdc>)
   d66a6:	e000      	b.n	d66aa <DebugLogFloat+0x36>
      return current;
    } else {
      current = StrCatStr(current, (current_end - current), "NaN");
   d66a8:	4a2a      	ldr	r2, [pc, #168]	; (d6754 <DebugLogFloat+0xe0>)
   d66aa:	1ac9      	subs	r1, r1, r3
   d66ac:	4618      	mov	r0, r3
   d66ae:	e047      	b.n	d6740 <DebugLogFloat+0xcc>
  // We can approximate this using multiply-adds and right-shifts using the
  // values in this array. The 1. portion of the number string is printed out
  // in a fixed way before the fraction, below.
  const int32_t scale_shifts_size = 13;
  const int8_t scale_shifts[13] = {3,  4,  8,  11, 13, 14, 17,
                                   18, 19, 20, 21, 22, 23};
   d66b0:	4a29      	ldr	r2, [pc, #164]	; (d6758 <DebugLogFloat+0xe4>)
   d66b2:	466d      	mov	r5, sp
   d66b4:	f102 0c08 	add.w	ip, r2, #8
   d66b8:	46ee      	mov	lr, sp
   d66ba:	6810      	ldr	r0, [r2, #0]
   d66bc:	6851      	ldr	r1, [r2, #4]
   d66be:	462e      	mov	r6, r5
   d66c0:	c603      	stmia	r6!, {r0, r1}
   d66c2:	3208      	adds	r2, #8
   d66c4:	4562      	cmp	r2, ip
   d66c6:	4635      	mov	r5, r6
   d66c8:	d1f7      	bne.n	d66ba <DebugLogFloat+0x46>
   d66ca:	6810      	ldr	r0, [r2, #0]
   d66cc:	7912      	ldrb	r2, [r2, #4]
   d66ce:	6030      	str	r0, [r6, #0]
   d66d0:	7132      	strb	r2, [r6, #4]
  uint32_t scaled_fraction = fraction;
   d66d2:	4638      	mov	r0, r7
  for (int i = 0; i < scale_shifts_size; ++i) {
   d66d4:	2200      	movs	r2, #0
    scaled_fraction += (fraction >> scale_shifts[i]);
   d66d6:	f91e 1002 	ldrsb.w	r1, [lr, r2]
  // in a fixed way before the fraction, below.
  const int32_t scale_shifts_size = 13;
  const int8_t scale_shifts[13] = {3,  4,  8,  11, 13, 14, 17,
                                   18, 19, 20, 21, 22, 23};
  uint32_t scaled_fraction = fraction;
  for (int i = 0; i < scale_shifts_size; ++i) {
   d66da:	3201      	adds	r2, #1
    scaled_fraction += (fraction >> scale_shifts[i]);
   d66dc:	fa27 f101 	lsr.w	r1, r7, r1
  // in a fixed way before the fraction, below.
  const int32_t scale_shifts_size = 13;
  const int8_t scale_shifts[13] = {3,  4,  8,  11, 13, 14, 17,
                                   18, 19, 20, 21, 22, 23};
  uint32_t scaled_fraction = fraction;
  for (int i = 0; i < scale_shifts_size; ++i) {
   d66e0:	2a0d      	cmp	r2, #13
    scaled_fraction += (fraction >> scale_shifts[i]);
   d66e2:	4408      	add	r0, r1
  // in a fixed way before the fraction, below.
  const int32_t scale_shifts_size = 13;
  const int8_t scale_shifts[13] = {3,  4,  8,  11, 13, 14, 17,
                                   18, 19, 20, 21, 22, 23};
  uint32_t scaled_fraction = fraction;
  for (int i = 0; i < scale_shifts_size; ++i) {
   d66e4:	d1f7      	bne.n	d66d6 <DebugLogFloat+0x62>
    scaled_fraction += (fraction >> scale_shifts[i]);
  }
  *current = '1';
   d66e6:	2231      	movs	r2, #49	; 0x31
   d66e8:	701a      	strb	r2, [r3, #0]
  current += 1;
  *current = '.';
   d66ea:	222e      	movs	r2, #46	; 0x2e
  current += 1;
   d66ec:	1c9e      	adds	r6, r3, #2
  for (int i = 0; i < scale_shifts_size; ++i) {
    scaled_fraction += (fraction >> scale_shifts[i]);
  }
  *current = '1';
  current += 1;
  *current = '.';
   d66ee:	705a      	strb	r2, [r3, #1]
  current += 1;
  *current = 0;
  current = StrCatUInt32(current, (current_end - current), scaled_fraction, 10);
   d66f0:	f10d 053f 	add.w	r5, sp, #63	; 0x3f
  }
  *current = '1';
  current += 1;
  *current = '.';
  current += 1;
  *current = 0;
   d66f4:	2200      	movs	r2, #0
   d66f6:	709a      	strb	r2, [r3, #2]
  current = StrCatUInt32(current, (current_end - current), scaled_fraction, 10);
   d66f8:	1baf      	subs	r7, r5, r6
}

// Converts a number to a string and appends it to another.
char* StrCatUInt32(char* main, int main_max_length, uint32_t number, int base) {
  char number_string[kFastToBufferSize];
  FastUInt32ToBufferLeft(number, number_string, base);
   d66fa:	220a      	movs	r2, #10
   d66fc:	a910      	add	r1, sp, #64	; 0x40
   d66fe:	f7ff ff85 	bl	d660c <_ZN12_GLOBAL__N_122FastUInt32ToBufferLeftEmPci>
  return StrCatStr(main, main_max_length, number_string);
   d6702:	aa10      	add	r2, sp, #64	; 0x40
   d6704:	4639      	mov	r1, r7
   d6706:	4630      	mov	r0, r6
   d6708:	f7ff ff6a 	bl	d65e0 <_ZN12_GLOBAL__N_19StrCatStrEPciPKc>
  current += 1;
  *current = '.';
  current += 1;
  *current = 0;
  current = StrCatUInt32(current, (current_end - current), scaled_fraction, 10);
  current = StrCatStr(current, (current_end - current), "*2^");
   d670c:	4a13      	ldr	r2, [pc, #76]	; (d675c <DebugLogFloat+0xe8>)
   d670e:	1a29      	subs	r1, r5, r0
   d6710:	f7ff ff66 	bl	d65e0 <_ZN12_GLOBAL__N_19StrCatStrEPciPKc>
}

// Populates the provided buffer with an ASCII representation of the number.
char* FastInt32ToBufferLeft(int32_t i, char* buffer) {
  uint32_t u = i;
  if (i < 0) {
   d6714:	2c00      	cmp	r4, #0
    *buffer++ = '-';
    u = -u;
   d6716:	bfb8      	it	lt
   d6718:	4264      	neglt	r4, r4
  current += 1;
  *current = '.';
  current += 1;
  *current = 0;
  current = StrCatUInt32(current, (current_end - current), scaled_fraction, 10);
  current = StrCatStr(current, (current_end - current), "*2^");
   d671a:	4606      	mov	r6, r0
  current = StrCatInt32(current, (current_end - current), exponent);
   d671c:	eba5 0500 	sub.w	r5, r5, r0

// Populates the provided buffer with an ASCII representation of the number.
char* FastInt32ToBufferLeft(int32_t i, char* buffer) {
  uint32_t u = i;
  if (i < 0) {
    *buffer++ = '-';
   d6720:	bfba      	itte	lt
   d6722:	232d      	movlt	r3, #45	; 0x2d
   d6724:	f10d 0141 	addlt.w	r1, sp, #65	; 0x41
}

// Populates the provided buffer with an ASCII representation of the number.
char* FastInt32ToBufferLeft(int32_t i, char* buffer) {
  uint32_t u = i;
  if (i < 0) {
   d6728:	a910      	addge	r1, sp, #64	; 0x40
    *buffer++ = '-';
    u = -u;
  }
  return FastUInt32ToBufferLeft(u, buffer, 10);
   d672a:	f04f 020a 	mov.w	r2, #10
   d672e:	4620      	mov	r0, r4

// Populates the provided buffer with an ASCII representation of the number.
char* FastInt32ToBufferLeft(int32_t i, char* buffer) {
  uint32_t u = i;
  if (i < 0) {
    *buffer++ = '-';
   d6730:	bfb8      	it	lt
   d6732:	f88d 3040 	strblt.w	r3, [sp, #64]	; 0x40
    u = -u;
  }
  return FastUInt32ToBufferLeft(u, buffer, 10);
   d6736:	f7ff ff69 	bl	d660c <_ZN12_GLOBAL__N_122FastUInt32ToBufferLeftEmPci>

// Converts a number to a string and appends it to another.
char* StrCatInt32(char* main, int main_max_length, int32_t number) {
  char number_string[kFastToBufferSize];
  FastInt32ToBufferLeft(number, number_string);
  return StrCatStr(main, main_max_length, number_string);
   d673a:	aa10      	add	r2, sp, #64	; 0x40
   d673c:	4629      	mov	r1, r5
   d673e:	4630      	mov	r0, r6
   d6740:	f7ff ff4e 	bl	d65e0 <_ZN12_GLOBAL__N_19StrCatStrEPciPKc>
}

extern "C" void DebugLogFloat(float i) {
  char number_string[kFastToBufferSize];
  FastFloatToBufferLeft(i, number_string);
  DebugLog(number_string);
   d6744:	a804      	add	r0, sp, #16
   d6746:	f000 fef3 	bl	d7530 <DebugLog>
}
   d674a:	b01d      	add	sp, #116	; 0x74
   d674c:	bdf0      	pop	{r4, r5, r6, r7, pc}
   d674e:	bf00      	nop
   d6750:	000ea8d0 	.word	0x000ea8d0
   d6754:	000ea8d4 	.word	0x000ea8d4
   d6758:	000ea8c3 	.word	0x000ea8c3
   d675c:	000ea8d8 	.word	0x000ea8d8

000d6760 <_ZN6tflite14AlignPointerUpEPhj>:

uint8_t* AlignPointerUp(uint8_t* data, size_t alignment) {
  size_t data_as_size_t = reinterpret_cast<size_t>(data);
  uint8_t* aligned_result = reinterpret_cast<uint8_t*>(
      ((data_as_size_t + (alignment - 1)) / alignment) * alignment);
  return aligned_result;
   d6760:	1e4b      	subs	r3, r1, #1
   d6762:	4418      	add	r0, r3
   d6764:	fbb0 f0f1 	udiv	r0, r0, r1
}
   d6768:	4348      	muls	r0, r1
   d676a:	4770      	bx	lr

000d676c <_ZN6tflite16AlignPointerDownEPhj>:

uint8_t* AlignPointerDown(uint8_t* data, size_t alignment) {
  size_t data_as_size_t = reinterpret_cast<size_t>(data);
  uint8_t* aligned_result =
      reinterpret_cast<uint8_t*>((data_as_size_t / alignment) * alignment);
  return aligned_result;
   d676c:	fbb0 f0f1 	udiv	r0, r0, r1
}
   d6770:	4348      	muls	r0, r1
   d6772:	4770      	bx	lr

000d6774 <_ZN6tflite11AlignSizeUpEjj>:

size_t AlignSizeUp(size_t size, size_t alignment) {
  size_t aligned_size = (((size + (alignment - 1)) / alignment) * alignment);
  return aligned_size;
   d6774:	3801      	subs	r0, #1
   d6776:	4408      	add	r0, r1
   d6778:	fbb0 f0f1 	udiv	r0, r0, r1
}
   d677c:	4348      	muls	r0, r1
   d677e:	4770      	bx	lr

000d6780 <_ZN6tflite16TfLiteTypeSizeOfE10TfLiteTypePjPNS_13ErrorReporterE>:

TfLiteStatus TfLiteTypeSizeOf(TfLiteType type, size_t* size,
                              ErrorReporter* reporter) {
   d6780:	b538      	push	{r3, r4, r5, lr}
  switch (type) {
   d6782:	1e43      	subs	r3, r0, #1
  size_t aligned_size = (((size + (alignment - 1)) / alignment) * alignment);
  return aligned_size;
}

TfLiteStatus TfLiteTypeSizeOf(TfLiteType type, size_t* size,
                              ErrorReporter* reporter) {
   d6784:	4604      	mov	r4, r0
   d6786:	4615      	mov	r5, r2
  switch (type) {
   d6788:	2b08      	cmp	r3, #8
   d678a:	d810      	bhi.n	d67ae <_ZN6tflite16TfLiteTypeSizeOfE10TfLiteTypePjPNS_13ErrorReporterE+0x2e>
   d678c:	e8df f003 	tbb	[pc, r3]
   d6790:	0d0b0909 	.word	0x0d0b0909
   d6794:	0d050b0f 	.word	0x0d050b0f
   d6798:	0b          	.byte	0x0b
   d6799:	00          	.byte	0x00
    case kTfLiteFloat32:
      *size = sizeof(float);
      break;
    case kTfLiteInt16:
      *size = sizeof(int16_t);
   d679a:	2302      	movs	r3, #2
   d679c:	600b      	str	r3, [r1, #0]
    default:
      reporter->Report("Type %s (%d) not is not supported",
                       TfLiteTypeGetName(type), type);
      return kTfLiteError;
  }
  return kTfLiteOk;
   d679e:	2000      	movs	r0, #0
    case kTfLiteFloat32:
      *size = sizeof(float);
      break;
    case kTfLiteInt16:
      *size = sizeof(int16_t);
      break;
   d67a0:	bd38      	pop	{r3, r4, r5, pc}
    case kTfLiteInt32:
      *size = sizeof(int32_t);
   d67a2:	2304      	movs	r3, #4
   d67a4:	e7fa      	b.n	d679c <_ZN6tflite16TfLiteTypeSizeOfE10TfLiteTypePjPNS_13ErrorReporterE+0x1c>
      break;
    case kTfLiteInt64:
      *size = sizeof(int64_t);
      break;
    case kTfLiteBool:
      *size = sizeof(bool);
   d67a6:	2301      	movs	r3, #1
   d67a8:	e7f8      	b.n	d679c <_ZN6tflite16TfLiteTypeSizeOfE10TfLiteTypePjPNS_13ErrorReporterE+0x1c>
      break;
    case kTfLiteComplex64:
      *size = sizeof(float) * 2;
   d67aa:	2308      	movs	r3, #8
   d67ac:	e7f6      	b.n	d679c <_ZN6tflite16TfLiteTypeSizeOfE10TfLiteTypePjPNS_13ErrorReporterE+0x1c>
      break;
    default:
      reporter->Report("Type %s (%d) not is not supported",
   d67ae:	f7fd fcbd 	bl	d412c <TfLiteTypeGetName>
                       TfLiteTypeGetName(type), type);
   d67b2:	4623      	mov	r3, r4
   d67b4:	4602      	mov	r2, r0
   d67b6:	4903      	ldr	r1, [pc, #12]	; (d67c4 <_ZN6tflite16TfLiteTypeSizeOfE10TfLiteTypePjPNS_13ErrorReporterE+0x44>)
   d67b8:	4628      	mov	r0, r5
   d67ba:	f7fe fe97 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
   d67be:	2001      	movs	r0, #1
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   d67c0:	bd38      	pop	{r3, r4, r5, pc}
   d67c2:	bf00      	nop
   d67c4:	000ea8dc 	.word	0x000ea8dc

000d67c8 <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE>:

TfLiteStatus BytesRequiredForTensor(const tflite::Tensor& flatbuffer_tensor,
                                    size_t* bytes, size_t* type_size,
                                    ErrorReporter* error_reporter) {
   d67c8:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
   d67cc:	460d      	mov	r5, r1
// "tables" use an offset table (possibly shared) that allows fields to be
// omitted and added at will, but uses an extra indirection to read.
class Table {
 public:
  const uint8_t *GetVTable() const {
    return data_ - ReadScalar<soffset_t>(data_);
   d67ce:	6801      	ldr	r1, [r0, #0]
   d67d0:	1a41      	subs	r1, r0, r1
   d67d2:	461f      	mov	r7, r3
   d67d4:	f8b1 e000 	ldrh.w	lr, [r1]
   d67d8:	4616      	mov	r6, r2
  int element_count = 1;
  for (size_t n = 0; n < flatbuffer_tensor.shape()->Length(); ++n) {
   d67da:	2300      	movs	r3, #0
}

TfLiteStatus BytesRequiredForTensor(const tflite::Tensor& flatbuffer_tensor,
                                    size_t* bytes, size_t* type_size,
                                    ErrorReporter* error_reporter) {
  int element_count = 1;
   d67dc:	2401      	movs	r4, #1
    auto vtable = GetVTable();
    // The first element is the size of the vtable (fields + type id + itself).
    auto vtsize = ReadScalar<voffset_t>(vtable);
    // If the field we're accessing is outside the vtable, we're reading older
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
   d67de:	f1be 0f04 	cmp.w	lr, #4
   d67e2:	bf8c      	ite	hi
   d67e4:	888a      	ldrhhi	r2, [r1, #4]
   d67e6:	2200      	movls	r2, #0
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
  }

  template<typename P> P GetPointer(voffset_t field) {
    auto field_offset = GetOptionalFieldOffset(field);
    auto p = data_ + field_offset;
   d67e8:	eb00 0802 	add.w	r8, r0, r2
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
   d67ec:	b362      	cbz	r2, d6848 <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x80>
   d67ee:	f850 c002 	ldr.w	ip, [r0, r2]
   d67f2:	eb08 020c 	add.w	r2, r8, ip
  for (size_t n = 0; n < flatbuffer_tensor.shape()->Length(); ++n) {
   d67f6:	f858 c00c 	ldr.w	ip, [r8, ip]
   d67fa:	4563      	cmp	r3, ip
   d67fc:	d205      	bcs.n	d680a <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x42>
template<typename T> struct IndirectHelper {
  typedef T return_type;
  typedef T mutable_return_type;
  static const size_t element_stride = sizeof(T);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    return EndianScalar((reinterpret_cast<const T *>(p))[i]);
   d67fe:	eb02 0283 	add.w	r2, r2, r3, lsl #2
   d6802:	3301      	adds	r3, #1
    element_count *= flatbuffer_tensor.shape()->Get(n);
   d6804:	6852      	ldr	r2, [r2, #4]
   d6806:	4354      	muls	r4, r2

TfLiteStatus BytesRequiredForTensor(const tflite::Tensor& flatbuffer_tensor,
                                    size_t* bytes, size_t* type_size,
                                    ErrorReporter* error_reporter) {
  int element_count = 1;
  for (size_t n = 0; n < flatbuffer_tensor.shape()->Length(); ++n) {
   d6808:	e7e9      	b.n	d67de <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x16>
    auto vtable = GetVTable();
    // The first element is the size of the vtable (fields + type id + itself).
    auto vtsize = ReadScalar<voffset_t>(vtable);
    // If the field we're accessing is outside the vtable, we're reading older
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
   d680a:	f1be 0f06 	cmp.w	lr, #6
   d680e:	d903      	bls.n	d6818 <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x50>
   d6810:	88ca      	ldrh	r2, [r1, #6]
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
    auto field_offset = GetOptionalFieldOffset(field);
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d6812:	b11a      	cbz	r2, d681c <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x54>
   d6814:	5680      	ldrsb	r0, [r0, r2]
   d6816:	e002      	b.n	d681e <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x56>
   d6818:	2000      	movs	r0, #0
   d681a:	e000      	b.n	d681e <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x56>
   d681c:	4610      	mov	r0, r2
    element_count *= flatbuffer_tensor.shape()->Get(n);
  }

  TfLiteType tf_lite_type;
  TF_LITE_ENSURE_STATUS(ConvertTensorType(flatbuffer_tensor.type(),
   d681e:	463a      	mov	r2, r7
   d6820:	f10d 0107 	add.w	r1, sp, #7
   d6824:	b2c0      	uxtb	r0, r0
   d6826:	f7fe febb 	bl	d55a0 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE>
   d682a:	b108      	cbz	r0, d6830 <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x68>
   d682c:	2001      	movs	r0, #1
   d682e:	e00d      	b.n	d684c <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x84>
                                          &tf_lite_type, error_reporter));
  TF_LITE_ENSURE_STATUS(
   d6830:	463a      	mov	r2, r7
   d6832:	4631      	mov	r1, r6
   d6834:	f89d 0007 	ldrb.w	r0, [sp, #7]
   d6838:	f7ff ffa2 	bl	d6780 <_ZN6tflite16TfLiteTypeSizeOfE10TfLiteTypePjPNS_13ErrorReporterE>
   d683c:	2800      	cmp	r0, #0
   d683e:	d1f5      	bne.n	d682c <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x64>
      TfLiteTypeSizeOf(tf_lite_type, type_size, error_reporter));
  *bytes = element_count * (*type_size);
   d6840:	6833      	ldr	r3, [r6, #0]
   d6842:	435c      	muls	r4, r3
   d6844:	602c      	str	r4, [r5, #0]
  return kTfLiteOk;
   d6846:	e001      	b.n	d684c <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE+0x84>
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d6848:	6813      	ldr	r3, [r2, #0]
   d684a:	deff      	udf	#255	; 0xff
}
   d684c:	b002      	add	sp, #8
   d684e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

000d6852 <_ZNK6tflite6Tensor11is_variableEv>:
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  const QuantizationParameters *quantization() const {
    return GetPointer<const QuantizationParameters *>(VT_QUANTIZATION);
  }
  bool is_variable() const {
   d6852:	b510      	push	{r4, lr}
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
    auto field_offset = GetOptionalFieldOffset(field);
   d6854:	210e      	movs	r1, #14
   d6856:	4604      	mov	r4, r0
   d6858:	f7fe fe9a 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d685c:	b100      	cbz	r0, d6860 <_ZNK6tflite6Tensor11is_variableEv+0xe>
   d685e:	5c20      	ldrb	r0, [r4, r0]
    return GetField<uint8_t>(VT_IS_VARIABLE, 0) != 0;
  }
   d6860:	3000      	adds	r0, #0
   d6862:	bf18      	it	ne
   d6864:	2001      	movne	r0, #1
   d6866:	bd10      	pop	{r4, pc}

000d6868 <_ZNK11flatbuffers6VectorIfE3GetEm>:
  uoffset_t Length() const { return size(); }

  typedef typename IndirectHelper<T>::return_type return_type;
  typedef typename IndirectHelper<T>::mutable_return_type mutable_return_type;

  return_type Get(uoffset_t i) const {
   d6868:	b508      	push	{r3, lr}
    FLATBUFFERS_ASSERT(i < size());
   d686a:	6803      	ldr	r3, [r0, #0]
   d686c:	4299      	cmp	r1, r3
   d686e:	d305      	bcc.n	d687c <_ZNK11flatbuffers6VectorIfE3GetEm+0x14>
   d6870:	4b05      	ldr	r3, [pc, #20]	; (d6888 <_ZNK11flatbuffers6VectorIfE3GetEm+0x20>)
   d6872:	4a06      	ldr	r2, [pc, #24]	; (d688c <_ZNK11flatbuffers6VectorIfE3GetEm+0x24>)
   d6874:	4806      	ldr	r0, [pc, #24]	; (d6890 <_ZNK11flatbuffers6VectorIfE3GetEm+0x28>)
   d6876:	21ed      	movs	r1, #237	; 0xed
   d6878:	f00e fe4c 	bl	e5514 <__assert_func>
template<typename T> struct IndirectHelper {
  typedef T return_type;
  typedef T mutable_return_type;
  static const size_t element_stride = sizeof(T);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    return EndianScalar((reinterpret_cast<const T *>(p))[i]);
   d687c:	eb00 0081 	add.w	r0, r0, r1, lsl #2
  typedef typename IndirectHelper<T>::mutable_return_type mutable_return_type;

  return_type Get(uoffset_t i) const {
    FLATBUFFERS_ASSERT(i < size());
    return IndirectHelper<T>::Read(Data(), i);
  }
   d6880:	ed90 0a01 	vldr	s0, [r0, #4]
   d6884:	bd08      	pop	{r3, pc}
   d6886:	bf00      	nop
   d6888:	000e9ff2 	.word	0x000e9ff2
   d688c:	000eacc8 	.word	0x000eacc8
   d6890:	000e9ffd 	.word	0x000e9ffd

000d6894 <_ZNK11flatbuffers6VectorIlE3GetEm>:
  uoffset_t Length() const { return size(); }

  typedef typename IndirectHelper<T>::return_type return_type;
  typedef typename IndirectHelper<T>::mutable_return_type mutable_return_type;

  return_type Get(uoffset_t i) const {
   d6894:	b508      	push	{r3, lr}
    FLATBUFFERS_ASSERT(i < size());
   d6896:	6803      	ldr	r3, [r0, #0]
   d6898:	4299      	cmp	r1, r3
   d689a:	d305      	bcc.n	d68a8 <_ZNK11flatbuffers6VectorIlE3GetEm+0x14>
   d689c:	4b04      	ldr	r3, [pc, #16]	; (d68b0 <_ZNK11flatbuffers6VectorIlE3GetEm+0x1c>)
   d689e:	4a05      	ldr	r2, [pc, #20]	; (d68b4 <_ZNK11flatbuffers6VectorIlE3GetEm+0x20>)
   d68a0:	4805      	ldr	r0, [pc, #20]	; (d68b8 <_ZNK11flatbuffers6VectorIlE3GetEm+0x24>)
   d68a2:	21ed      	movs	r1, #237	; 0xed
   d68a4:	f00e fe36 	bl	e5514 <__assert_func>
template<typename T> struct IndirectHelper {
  typedef T return_type;
  typedef T mutable_return_type;
  static const size_t element_stride = sizeof(T);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    return EndianScalar((reinterpret_cast<const T *>(p))[i]);
   d68a8:	eb00 0081 	add.w	r0, r0, r1, lsl #2
  typedef typename IndirectHelper<T>::mutable_return_type mutable_return_type;

  return_type Get(uoffset_t i) const {
    FLATBUFFERS_ASSERT(i < size());
    return IndirectHelper<T>::Read(Data(), i);
  }
   d68ac:	6840      	ldr	r0, [r0, #4]
   d68ae:	bd08      	pop	{r3, pc}
   d68b0:	000e9ff2 	.word	0x000e9ff2
   d68b4:	000ea8fe 	.word	0x000ea8fe
   d68b8:	000e9ffd 	.word	0x000e9ffd

000d68bc <_ZNK11flatbuffers6VectorINS_6OffsetIN6tflite6TensorEEEE3GetEm>:
  uoffset_t Length() const { return size(); }

  typedef typename IndirectHelper<T>::return_type return_type;
  typedef typename IndirectHelper<T>::mutable_return_type mutable_return_type;

  return_type Get(uoffset_t i) const {
   d68bc:	b508      	push	{r3, lr}
    FLATBUFFERS_ASSERT(i < size());
   d68be:	6803      	ldr	r3, [r0, #0]
   d68c0:	4299      	cmp	r1, r3
   d68c2:	d305      	bcc.n	d68d0 <_ZNK11flatbuffers6VectorINS_6OffsetIN6tflite6TensorEEEE3GetEm+0x14>
   d68c4:	4b06      	ldr	r3, [pc, #24]	; (d68e0 <_ZNK11flatbuffers6VectorINS_6OffsetIN6tflite6TensorEEEE3GetEm+0x24>)
   d68c6:	4a07      	ldr	r2, [pc, #28]	; (d68e4 <_ZNK11flatbuffers6VectorINS_6OffsetIN6tflite6TensorEEEE3GetEm+0x28>)
   d68c8:	4807      	ldr	r0, [pc, #28]	; (d68e8 <_ZNK11flatbuffers6VectorINS_6OffsetIN6tflite6TensorEEEE3GetEm+0x2c>)
   d68ca:	21ed      	movs	r1, #237	; 0xed
   d68cc:	f00e fe22 	bl	e5514 <__assert_func>
    return const_cast<mutable_return_type>(IndirectHelper<T>::Read(Data(), i));
  }

  // The raw data in little endian format. Use with care.
  const uint8_t *Data() const {
    return reinterpret_cast<const uint8_t *>(&length_ + 1);
   d68d0:	3004      	adds	r0, #4
template<typename T> struct IndirectHelper<Offset<T>> {
  typedef const T *return_type;
  typedef T *mutable_return_type;
  static const size_t element_stride = sizeof(uoffset_t);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    p += i * sizeof(uoffset_t);
   d68d2:	eb00 0281 	add.w	r2, r0, r1, lsl #2
  typedef typename IndirectHelper<T>::return_type return_type;
  typedef typename IndirectHelper<T>::mutable_return_type mutable_return_type;

  return_type Get(uoffset_t i) const {
    FLATBUFFERS_ASSERT(i < size());
    return IndirectHelper<T>::Read(Data(), i);
   d68d6:	f850 0021 	ldr.w	r0, [r0, r1, lsl #2]
  }
   d68da:	4410      	add	r0, r2
   d68dc:	bd08      	pop	{r3, pc}
   d68de:	bf00      	nop
   d68e0:	000e9ff2 	.word	0x000e9ff2
   d68e4:	000eaac6 	.word	0x000eaac6
   d68e8:	000e9ffd 	.word	0x000e9ffd

000d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>:
  template<typename T> T GetField(voffset_t field, T defaultval) const {
    auto field_offset = GetOptionalFieldOffset(field);
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
  }

  template<typename P> P GetPointer(voffset_t field) {
   d68ec:	b510      	push	{r4, lr}
   d68ee:	4604      	mov	r4, r0
    auto field_offset = GetOptionalFieldOffset(field);
   d68f0:	f7fe fe4e 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    auto p = data_ + field_offset;
   d68f4:	1822      	adds	r2, r4, r0
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
   d68f6:	b108      	cbz	r0, d68fc <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t+0x10>
   d68f8:	5823      	ldr	r3, [r4, r0]
   d68fa:	18d0      	adds	r0, r2, r3
  }
   d68fc:	bd10      	pop	{r4, pc}
	...

000d6900 <_ZN6tflite14MicroAllocatorC1EP13TfLiteContextPKNS_5ModelEPhjPNS_13ErrorReporterE>:
// requirement for SIMD extensions.
constexpr int kBufferAlignment = 16;

}  // namespace

MicroAllocator::MicroAllocator(TfLiteContext* context, const Model* model,
   d6900:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   d6904:	9e07      	ldr	r6, [sp, #28]
// though we have enough information about lifetimes of the tensors to do so.
// This makes it pretty wasteful, so we should use a more intelligent method.
class SimpleMemoryAllocator {
 public:
  SimpleMemoryAllocator(uint8_t* buffer, size_t buffer_size)
      : data_size_(0), data_size_max_(buffer_size), data_(buffer) {}
   d6906:	60c3      	str	r3, [r0, #12]
   d6908:	460f      	mov	r7, r1
   d690a:	2500      	movs	r5, #0
   d690c:	9906      	ldr	r1, [sp, #24]
   d690e:	6081      	str	r1, [r0, #8]
    : model_(model),
      memory_allocator_(tensor_arena, arena_size),
      error_reporter_(error_reporter),
      context_(context),
      arena_(tensor_arena),
      arena_size_(arena_size) {
   d6910:	6183      	str	r3, [r0, #24]
   d6912:	61c1      	str	r1, [r0, #28]
   d6914:	6002      	str	r2, [r0, #0]
   d6916:	6045      	str	r5, [r0, #4]
   d6918:	6106      	str	r6, [r0, #16]
   d691a:	6147      	str	r7, [r0, #20]
// requirement for SIMD extensions.
constexpr int kBufferAlignment = 16;

}  // namespace

MicroAllocator::MicroAllocator(TfLiteContext* context, const Model* model,
   d691c:	4604      	mov	r4, r0
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d691e:	2108      	movs	r1, #8
   d6920:	4610      	mov	r0, r2
   d6922:	f7ff ffe3 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
      error_reporter_(error_reporter),
      context_(context),
      arena_(tensor_arena),
      arena_size_(arena_size) {
  auto* subgraphs = model->subgraphs();
  if (subgraphs->size() != 1) {
   d6926:	6803      	ldr	r3, [r0, #0]
   d6928:	2b01      	cmp	r3, #1
   d692a:	d004      	beq.n	d6936 <_ZN6tflite14MicroAllocatorC1EP13TfLiteContextPKNS_5ModelEPhjPNS_13ErrorReporterE+0x36>
    error_reporter->Report("Only 1 subgraph is currently supported.\n");
   d692c:	4917      	ldr	r1, [pc, #92]	; (d698c <_ZN6tflite14MicroAllocatorC1EP13TfLiteContextPKNS_5ModelEPhjPNS_13ErrorReporterE+0x8c>)
   d692e:	4630      	mov	r0, r6
   d6930:	f7fe fddc 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    return;
   d6934:	e026      	b.n	d6984 <_ZN6tflite14MicroAllocatorC1EP13TfLiteContextPKNS_5ModelEPhjPNS_13ErrorReporterE+0x84>
  typedef const T *return_type;
  typedef T *mutable_return_type;
  static const size_t element_stride = sizeof(uoffset_t);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    p += i * sizeof(uoffset_t);
    return reinterpret_cast<return_type>(p + ReadScalar<uoffset_t>(p));
   d6936:	6843      	ldr	r3, [r0, #4]
    return const_cast<mutable_return_type>(IndirectHelper<T>::Read(Data(), i));
  }

  // The raw data in little endian format. Use with care.
  const uint8_t *Data() const {
    return reinterpret_cast<const uint8_t *>(&length_ + 1);
   d6938:	1d06      	adds	r6, r0, #4
  typedef const T *return_type;
  typedef T *mutable_return_type;
  static const size_t element_stride = sizeof(uoffset_t);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    p += i * sizeof(uoffset_t);
    return reinterpret_cast<return_type>(p + ReadScalar<uoffset_t>(p));
   d693a:	441e      	add	r6, r3
  }
  subgraph_ = (*subgraphs)[0];
   d693c:	6226      	str	r6, [r4, #32]
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d693e:	2104      	movs	r1, #4
   d6940:	4630      	mov	r0, r6
   d6942:	f7ff ffd3 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
   d6946:	210a      	movs	r1, #10
   d6948:	4680      	mov	r8, r0
  tensors_ = subgraph_->tensors();
   d694a:	62a0      	str	r0, [r4, #40]	; 0x28
   d694c:	4630      	mov	r0, r6
   d694e:	f7ff ffcd 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
  operators_ = subgraph_->operators();
   d6952:	6260      	str	r0, [r4, #36]	; 0x24
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d6954:	f8d8 3000 	ldr.w	r3, [r8]

  context_->tensors_size = tensors_->size();
   d6958:	603b      	str	r3, [r7, #0]
  context_->tensors =
      reinterpret_cast<TfLiteTensor*>(memory_allocator_.AllocateFromTail(
          sizeof(TfLiteTensor) * context_->tensors_size, 4));
   d695a:	6967      	ldr	r7, [r4, #20]
  tensors_ = subgraph_->tensors();
  operators_ = subgraph_->operators();

  context_->tensors_size = tensors_->size();
  context_->tensors =
      reinterpret_cast<TfLiteTensor*>(memory_allocator_.AllocateFromTail(
   d695c:	6839      	ldr	r1, [r7, #0]
   d695e:	2204      	movs	r2, #4
   d6960:	2638      	movs	r6, #56	; 0x38
   d6962:	4371      	muls	r1, r6
   d6964:	18a0      	adds	r0, r4, r2
   d6966:	f000 fdce 	bl	d7506 <_ZN6tflite21SimpleMemoryAllocator16AllocateFromTailEjj>
          sizeof(TfLiteTensor) * context_->tensors_size, 4));

  // Null all inputs so we can later perform a null check to avoid re-allocating
  // registered pre-allocated inputs.
  for (size_t i = 0; i < context_->tensors_size; ++i) {
   d696a:	462b      	mov	r3, r5
  operators_ = subgraph_->operators();

  context_->tensors_size = tensors_->size();
  context_->tensors =
      reinterpret_cast<TfLiteTensor*>(memory_allocator_.AllocateFromTail(
          sizeof(TfLiteTensor) * context_->tensors_size, 4));
   d696c:	60b8      	str	r0, [r7, #8]

  // Null all inputs so we can later perform a null check to avoid re-allocating
  // registered pre-allocated inputs.
  for (size_t i = 0; i < context_->tensors_size; ++i) {
    context_->tensors[i].data.raw = nullptr;
   d696e:	4629      	mov	r1, r5
      reinterpret_cast<TfLiteTensor*>(memory_allocator_.AllocateFromTail(
          sizeof(TfLiteTensor) * context_->tensors_size, 4));

  // Null all inputs so we can later perform a null check to avoid re-allocating
  // registered pre-allocated inputs.
  for (size_t i = 0; i < context_->tensors_size; ++i) {
   d6970:	6962      	ldr	r2, [r4, #20]
   d6972:	6810      	ldr	r0, [r2, #0]
   d6974:	4283      	cmp	r3, r0
   d6976:	d205      	bcs.n	d6984 <_ZN6tflite14MicroAllocatorC1EP13TfLiteContextPKNS_5ModelEPhjPNS_13ErrorReporterE+0x84>
    context_->tensors[i].data.raw = nullptr;
   d6978:	6892      	ldr	r2, [r2, #8]
   d697a:	fb06 2203 	mla	r2, r6, r3, r2
      reinterpret_cast<TfLiteTensor*>(memory_allocator_.AllocateFromTail(
          sizeof(TfLiteTensor) * context_->tensors_size, 4));

  // Null all inputs so we can later perform a null check to avoid re-allocating
  // registered pre-allocated inputs.
  for (size_t i = 0; i < context_->tensors_size; ++i) {
   d697e:	3301      	adds	r3, #1
    context_->tensors[i].data.raw = nullptr;
   d6980:	6051      	str	r1, [r2, #4]
      reinterpret_cast<TfLiteTensor*>(memory_allocator_.AllocateFromTail(
          sizeof(TfLiteTensor) * context_->tensors_size, 4));

  // Null all inputs so we can later perform a null check to avoid re-allocating
  // registered pre-allocated inputs.
  for (size_t i = 0; i < context_->tensors_size; ++i) {
   d6982:	e7f5      	b.n	d6970 <_ZN6tflite14MicroAllocatorC1EP13TfLiteContextPKNS_5ModelEPhjPNS_13ErrorReporterE+0x70>
    context_->tensors[i].data.raw = nullptr;
  }
}
   d6984:	4620      	mov	r0, r4
   d6986:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   d698a:	bf00      	nop
   d698c:	000eabbc 	.word	0x000eabbc

000d6990 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh>:

TfLiteStatus MicroAllocator::InitializeRuntimeTensor(
    const tflite::Tensor& flatbuffer_tensor,
    const flatbuffers::Vector<flatbuffers::Offset<Buffer>>* buffers,
    ErrorReporter* error_reporter, TfLiteTensor* result,
    uint8_t* preallocated_buffer) {
   d6990:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d6994:	460d      	mov	r5, r1
   d6996:	b087      	sub	sp, #28
   d6998:	4607      	mov	r7, r0
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
    auto field_offset = GetOptionalFieldOffset(field);
   d699a:	2106      	movs	r1, #6
   d699c:	4628      	mov	r0, r5
   d699e:	4616      	mov	r6, r2
   d69a0:	4698      	mov	r8, r3
   d69a2:	9c10      	ldr	r4, [sp, #64]	; 0x40
   d69a4:	f8dd 9044 	ldr.w	r9, [sp, #68]	; 0x44
   d69a8:	f7fe fdf2 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d69ac:	b100      	cbz	r0, d69b0 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x20>
   d69ae:	5628      	ldrsb	r0, [r5, r0]
  // Make sure the serialized type is one we know how to deal with, and convert
  // it from a flatbuffer enum into a constant used by the kernel C API.
  TF_LITE_ENSURE_STATUS(ConvertTensorType(flatbuffer_tensor.type(),
   d69b0:	4642      	mov	r2, r8
   d69b2:	4621      	mov	r1, r4
   d69b4:	b2c0      	uxtb	r0, r0
   d69b6:	f7fe fdf3 	bl	d55a0 <_ZN6tflite17ConvertTensorTypeENS_10TensorTypeEP10TfLiteTypePNS_13ErrorReporterE>
   d69ba:	4682      	mov	sl, r0
   d69bc:	2800      	cmp	r0, #0
   d69be:	f040 80e2 	bne.w	d6b86 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1f6>
                                          &result->type, error_reporter));
  // Make sure we remember if the serialized tensor is designated as a variable.
  result->is_variable = flatbuffer_tensor.is_variable();
   d69c2:	4628      	mov	r0, r5
   d69c4:	f7ff ff45 	bl	d6852 <_ZNK6tflite6Tensor11is_variableEv>
  // We need to figure out where the actual contents of this tensor are stored
  // in memory. We'll check to see if there's a serialized buffer (pretty much
  // the same as a constant op in TensorFlow) associated with this tensor first,
  // and if there is update the runtime structure to point to its location in
  // memory.
  result->data.raw = nullptr;
   d69c8:	f8c4 a004 	str.w	sl, [r4, #4]
  // Make sure the serialized type is one we know how to deal with, and convert
  // it from a flatbuffer enum into a constant used by the kernel C API.
  TF_LITE_ENSURE_STATUS(ConvertTensorType(flatbuffer_tensor.type(),
                                          &result->type, error_reporter));
  // Make sure we remember if the serialized tensor is designated as a variable.
  result->is_variable = flatbuffer_tensor.is_variable();
   d69cc:	f884 002d 	strb.w	r0, [r4, #45]	; 0x2d
  // in memory. We'll check to see if there's a serialized buffer (pretty much
  // the same as a constant op in TensorFlow) associated with this tensor first,
  // and if there is update the runtime structure to point to its location in
  // memory.
  result->data.raw = nullptr;
  result->bytes = 0;
   d69d0:	f8c4 a018 	str.w	sl, [r4, #24]
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
    auto field_offset = GetOptionalFieldOffset(field);
   d69d4:	2108      	movs	r1, #8
   d69d6:	4628      	mov	r0, r5
   d69d8:	f7fe fdda 	bl	d5590 <_ZNK11flatbuffers5Table22GetOptionalFieldOffsetEt>
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d69dc:	b100      	cbz	r0, d69e0 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x50>
   d69de:	5828      	ldr	r0, [r5, r0]

  typedef typename IndirectHelper<T>::return_type return_type;
  typedef typename IndirectHelper<T>::mutable_return_type mutable_return_type;

  return_type Get(uoffset_t i) const {
    FLATBUFFERS_ASSERT(i < size());
   d69e0:	6833      	ldr	r3, [r6, #0]
   d69e2:	4283      	cmp	r3, r0
   d69e4:	d802      	bhi.n	d69ec <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x5c>
   d69e6:	4b74      	ldr	r3, [pc, #464]	; (d6bb8 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x228>)
   d69e8:	4a74      	ldr	r2, [pc, #464]	; (d6bbc <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x22c>)
   d69ea:	e0ac      	b.n	d6b46 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1b6>
    return const_cast<mutable_return_type>(IndirectHelper<T>::Read(Data(), i));
  }

  // The raw data in little endian format. Use with care.
  const uint8_t *Data() const {
    return reinterpret_cast<const uint8_t *>(&length_ + 1);
   d69ec:	3604      	adds	r6, #4
template<typename T> struct IndirectHelper<Offset<T>> {
  typedef const T *return_type;
  typedef T *mutable_return_type;
  static const size_t element_stride = sizeof(uoffset_t);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    p += i * sizeof(uoffset_t);
   d69ee:	eb06 0380 	add.w	r3, r6, r0, lsl #2
    return reinterpret_cast<return_type>(p + ReadScalar<uoffset_t>(p));
   d69f2:	f856 0020 	ldr.w	r0, [r6, r0, lsl #2]
  // First see if there's any buffer information in the serialized tensor.
  if (auto* buffer = (*buffers)[flatbuffer_tensor.buffer()]) {
   d69f6:	1818      	adds	r0, r3, r0
   d69f8:	d009      	beq.n	d6a0e <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x7e>
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d69fa:	2104      	movs	r1, #4
   d69fc:	f7ff ff76 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
    // If we've found a buffer, does it have any data?
    if (auto* array = buffer->data()) {
   d6a00:	b128      	cbz	r0, d6a0e <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x7e>
      // If it has any data, is the data size larger than zero?
      if (size_t array_size = array->size()) {
   d6a02:	6803      	ldr	r3, [r0, #0]
   d6a04:	b11b      	cbz	r3, d6a0e <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x7e>
    return const_cast<mutable_return_type>(IndirectHelper<T>::Read(Data(), i));
  }

  // The raw data in little endian format. Use with care.
  const uint8_t *Data() const {
    return reinterpret_cast<const uint8_t *>(&length_ + 1);
   d6a06:	3004      	adds	r0, #4
        // We've found a buffer with valid data, so update the runtime tensor
        // data structure to point to it.
        result->data.raw =
            const_cast<char*>(reinterpret_cast<const char*>(array->data()));
        // We set the data from a serialized buffer, so record tha.
        result->allocation_type = kTfLiteMmapRo;
   d6a08:	2301      	movs	r3, #1
      // If it has any data, is the data size larger than zero?
      if (size_t array_size = array->size()) {
        // We've found a buffer with valid data, so update the runtime tensor
        // data structure to point to it.
        result->data.raw =
            const_cast<char*>(reinterpret_cast<const char*>(array->data()));
   d6a0a:	6060      	str	r0, [r4, #4]
        // We set the data from a serialized buffer, so record tha.
        result->allocation_type = kTfLiteMmapRo;
   d6a0c:	7523      	strb	r3, [r4, #20]
    // it less ambiguous.
  }

  // TODO(petewarden): Some of these paths aren't getting enough testing
  // coverage, so we should figure out some tests that exercise them.
  if (!result->data.raw) {
   d6a0e:	6863      	ldr	r3, [r4, #4]
   d6a10:	b933      	cbnz	r3, d6a20 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x90>
    // The tensor contents haven't been set from a serialized buffer, so
    // make a note that they will be allocated from memory. The actual
    // allocation won't happen until later.
    result->allocation_type = kTfLiteArenaRw;
   d6a12:	2302      	movs	r3, #2
   d6a14:	7523      	strb	r3, [r4, #20]
    if (preallocated_buffer != nullptr) {
   d6a16:	f1b9 0f00 	cmp.w	r9, #0
   d6a1a:	d001      	beq.n	d6a20 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x90>
      // If the client is supplying memory for the contents of the tensor
      // themselves, use it.
      // TODO(petewarden): Should we store the fact this is a client-allocated
      // buffer?
      result->data.raw = reinterpret_cast<char*>(preallocated_buffer);
   d6a1c:	f8c4 9004 	str.w	r9, [r4, #4]
    }
  }

  // Figure out what the size in bytes of the buffer is and store it.
  size_t type_size;
  TF_LITE_ENSURE_STATUS(BytesRequiredForTensor(
   d6a20:	4643      	mov	r3, r8
   d6a22:	aa05      	add	r2, sp, #20
   d6a24:	f104 0118 	add.w	r1, r4, #24
   d6a28:	4628      	mov	r0, r5
   d6a2a:	f7ff fecd 	bl	d67c8 <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE>
   d6a2e:	4606      	mov	r6, r0
   d6a30:	2800      	cmp	r0, #0
   d6a32:	f040 80a8 	bne.w	d6b86 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1f6>
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d6a36:	2104      	movs	r1, #4
   d6a38:	4628      	mov	r0, r5
   d6a3a:	f7ff ff57 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
      flatbuffer_tensor, &result->bytes, &type_size, error_reporter));
  // Copy the shape of the tensor from the serialized data into the runtime
  // form. We have to allocate memory for this.
  result->dims =
      reinterpret_cast<TfLiteIntArray*>(memory_allocator_.AllocateFromTail(
   d6a3e:	6801      	ldr	r1, [r0, #0]
   d6a40:	f107 0b04 	add.w	fp, r7, #4
   d6a44:	3101      	adds	r1, #1
   d6a46:	2204      	movs	r2, #4
   d6a48:	0089      	lsls	r1, r1, #2
   d6a4a:	4658      	mov	r0, fp
   d6a4c:	f000 fd5b 	bl	d7506 <_ZN6tflite21SimpleMemoryAllocator16AllocateFromTailEjj>
   d6a50:	2104      	movs	r1, #4
   d6a52:	4607      	mov	r7, r0
          sizeof(int) * (flatbuffer_tensor.shape()->Length() + 1),
          sizeof(int)));
   d6a54:	60a0      	str	r0, [r4, #8]
   d6a56:	4628      	mov	r0, r5
   d6a58:	f7ff ff48 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
  result->dims->size = flatbuffer_tensor.shape()->Length();
   d6a5c:	6803      	ldr	r3, [r0, #0]
   d6a5e:	603b      	str	r3, [r7, #0]
  for (size_t n = 0; n < flatbuffer_tensor.shape()->Length(); ++n) {
   d6a60:	4637      	mov	r7, r6
   d6a62:	2104      	movs	r1, #4
   d6a64:	4628      	mov	r0, r5
   d6a66:	f7ff ff41 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
   d6a6a:	6803      	ldr	r3, [r0, #0]
   d6a6c:	42bb      	cmp	r3, r7
   d6a6e:	d90a      	bls.n	d6a86 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0xf6>
    result->dims->data[n] = flatbuffer_tensor.shape()->Get(n);
   d6a70:	f8d4 8008 	ldr.w	r8, [r4, #8]
   d6a74:	4639      	mov	r1, r7
   d6a76:	f7ff ff0d 	bl	d6894 <_ZNK11flatbuffers6VectorIlE3GetEm>
   d6a7a:	eb08 0887 	add.w	r8, r8, r7, lsl #2
  result->dims =
      reinterpret_cast<TfLiteIntArray*>(memory_allocator_.AllocateFromTail(
          sizeof(int) * (flatbuffer_tensor.shape()->Length() + 1),
          sizeof(int)));
  result->dims->size = flatbuffer_tensor.shape()->Length();
  for (size_t n = 0; n < flatbuffer_tensor.shape()->Length(); ++n) {
   d6a7e:	3701      	adds	r7, #1
    result->dims->data[n] = flatbuffer_tensor.shape()->Get(n);
   d6a80:	f8c8 0004 	str.w	r0, [r8, #4]
   d6a84:	e7ed      	b.n	d6a62 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0xd2>
   d6a86:	210c      	movs	r1, #12
   d6a88:	4628      	mov	r0, r5
   d6a8a:	f7ff ff2f 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
  }
  // Copy the quantization information from the serialized data.
  const auto* src_quantization = flatbuffer_tensor.quantization();
  if (src_quantization && src_quantization->scale() &&
      (src_quantization->scale()->size() > 0) &&
      src_quantization->zero_point() &&
   d6a8e:	4607      	mov	r7, r0
   d6a90:	2800      	cmp	r0, #0
   d6a92:	d066      	beq.n	d6b62 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1d2>
   d6a94:	2108      	movs	r1, #8
   d6a96:	f7ff ff29 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
  for (size_t n = 0; n < flatbuffer_tensor.shape()->Length(); ++n) {
    result->dims->data[n] = flatbuffer_tensor.shape()->Get(n);
  }
  // Copy the quantization information from the serialized data.
  const auto* src_quantization = flatbuffer_tensor.quantization();
  if (src_quantization && src_quantization->scale() &&
   d6a9a:	4680      	mov	r8, r0
   d6a9c:	2800      	cmp	r0, #0
   d6a9e:	d060      	beq.n	d6b62 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1d2>
   d6aa0:	6803      	ldr	r3, [r0, #0]
   d6aa2:	2b00      	cmp	r3, #0
   d6aa4:	d05d      	beq.n	d6b62 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1d2>
   d6aa6:	210a      	movs	r1, #10
   d6aa8:	4638      	mov	r0, r7
   d6aaa:	f7ff ff1f 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
      (src_quantization->scale()->size() > 0) &&
   d6aae:	2800      	cmp	r0, #0
   d6ab0:	d057      	beq.n	d6b62 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1d2>
      src_quantization->zero_point() &&
   d6ab2:	6803      	ldr	r3, [r0, #0]
   d6ab4:	2b00      	cmp	r3, #0
   d6ab6:	d054      	beq.n	d6b62 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1d2>
      (src_quantization->zero_point()->size() > 0)) {
    result->params.scale = src_quantization->scale()->Get(0);
   d6ab8:	4640      	mov	r0, r8
   d6aba:	2100      	movs	r1, #0
   d6abc:	f7ff fed4 	bl	d6868 <_ZNK11flatbuffers6VectorIfE3GetEm>
   d6ac0:	f104 090f 	add.w	r9, r4, #15
   d6ac4:	ed84 0a03 	vstr	s0, [r4, #12]
    // This magic handles issues with little-endianness.
    for (unsigned int b = 0; b < sizeof(int64_t); ++b)
   d6ac8:	f04f 0800 	mov.w	r8, #0
   d6acc:	210a      	movs	r1, #10
   d6ace:	4638      	mov	r0, r7
   d6ad0:	f7ff ff0c 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
      *(reinterpret_cast<char*>(&result->params.zero_point) + b) =
          *(reinterpret_cast<const char*>(
                src_quantization->zero_point()->Data()) +
            b);
   d6ad4:	4440      	add	r0, r8
      (src_quantization->scale()->size() > 0) &&
      src_quantization->zero_point() &&
      (src_quantization->zero_point()->size() > 0)) {
    result->params.scale = src_quantization->scale()->Get(0);
    // This magic handles issues with little-endianness.
    for (unsigned int b = 0; b < sizeof(int64_t); ++b)
   d6ad6:	f108 0801 	add.w	r8, r8, #1
      *(reinterpret_cast<char*>(&result->params.zero_point) + b) =
          *(reinterpret_cast<const char*>(
                src_quantization->zero_point()->Data()) +
            b);
   d6ada:	7903      	ldrb	r3, [r0, #4]
   d6adc:	f809 3f01 	strb.w	r3, [r9, #1]!
      (src_quantization->scale()->size() > 0) &&
      src_quantization->zero_point() &&
      (src_quantization->zero_point()->size() > 0)) {
    result->params.scale = src_quantization->scale()->Get(0);
    // This magic handles issues with little-endianness.
    for (unsigned int b = 0; b < sizeof(int64_t); ++b)
   d6ae0:	f1b8 0f08 	cmp.w	r8, #8
   d6ae4:	d1f2      	bne.n	d6acc <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x13c>
   d6ae6:	4641      	mov	r1, r8
   d6ae8:	4638      	mov	r0, r7
   d6aea:	f7ff feff 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
    // Populate per-channel quantization params.
    int channels = src_quantization->scale()->size();
    TfLiteAffineQuantization* quantization =
        reinterpret_cast<TfLiteAffineQuantization*>(
            memory_allocator_.AllocateFromTail(sizeof(TfLiteAffineQuantization),
                                               sizeof(int)));
   d6aee:	2204      	movs	r2, #4
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d6af0:	f8d0 8000 	ldr.w	r8, [r0]
   d6af4:	210c      	movs	r1, #12
   d6af6:	4658      	mov	r0, fp
   d6af8:	f000 fd05 	bl	d7506 <_ZN6tflite21SimpleMemoryAllocator16AllocateFromTailEjj>
    int* zero_point_array =
        reinterpret_cast<int*>(memory_allocator_.AllocateFromTail(
   d6afc:	ea4f 0388 	mov.w	r3, r8, lsl #2
   d6b00:	f103 0904 	add.w	r9, r3, #4
            channels * sizeof(int) + sizeof(int), sizeof(int)));
   d6b04:	4649      	mov	r1, r9
    // Populate per-channel quantization params.
    int channels = src_quantization->scale()->size();
    TfLiteAffineQuantization* quantization =
        reinterpret_cast<TfLiteAffineQuantization*>(
            memory_allocator_.AllocateFromTail(sizeof(TfLiteAffineQuantization),
                                               sizeof(int)));
   d6b06:	9001      	str	r0, [sp, #4]
    int* zero_point_array =
        reinterpret_cast<int*>(memory_allocator_.AllocateFromTail(
            channels * sizeof(int) + sizeof(int), sizeof(int)));
   d6b08:	2204      	movs	r2, #4
   d6b0a:	4658      	mov	r0, fp
   d6b0c:	f000 fcfb 	bl	d7506 <_ZN6tflite21SimpleMemoryAllocator16AllocateFromTailEjj>
    int* scale_array =
        reinterpret_cast<int*>(memory_allocator_.AllocateFromTail(
            channels * sizeof(float) + sizeof(int), sizeof(int)));
   d6b10:	4649      	mov	r1, r9
        reinterpret_cast<TfLiteAffineQuantization*>(
            memory_allocator_.AllocateFromTail(sizeof(TfLiteAffineQuantization),
                                               sizeof(int)));
    int* zero_point_array =
        reinterpret_cast<int*>(memory_allocator_.AllocateFromTail(
            channels * sizeof(int) + sizeof(int), sizeof(int)));
   d6b12:	4682      	mov	sl, r0
    int* scale_array =
        reinterpret_cast<int*>(memory_allocator_.AllocateFromTail(
            channels * sizeof(float) + sizeof(int), sizeof(int)));
   d6b14:	2204      	movs	r2, #4
   d6b16:	4658      	mov	r0, fp
   d6b18:	f000 fcf5 	bl	d7506 <_ZN6tflite21SimpleMemoryAllocator16AllocateFromTailEjj>
    zero_point_array[0] = channels;
    scale_array[0] = channels;
   d6b1c:	4681      	mov	r9, r0
        reinterpret_cast<int*>(memory_allocator_.AllocateFromTail(
            channels * sizeof(int) + sizeof(int), sizeof(int)));
    int* scale_array =
        reinterpret_cast<int*>(memory_allocator_.AllocateFromTail(
            channels * sizeof(float) + sizeof(int), sizeof(int)));
    zero_point_array[0] = channels;
   d6b1e:	f8ca 8000 	str.w	r8, [sl]
    scale_array[0] = channels;
   d6b22:	f849 8b04 	str.w	r8, [r9], #4
    int* zero_point_array =
        reinterpret_cast<int*>(memory_allocator_.AllocateFromTail(
            channels * sizeof(int) + sizeof(int), sizeof(int)));
    int* scale_array =
        reinterpret_cast<int*>(memory_allocator_.AllocateFromTail(
            channels * sizeof(float) + sizeof(int), sizeof(int)));
   d6b26:	9002      	str	r0, [sp, #8]
   d6b28:	f8cd a00c 	str.w	sl, [sp, #12]
    zero_point_array[0] = channels;
    scale_array[0] = channels;
    int* zero_point_data = &zero_point_array[1];
    float* scale_data = reinterpret_cast<float*>(&scale_array[1]);
    for (int i = 0; i < channels; i++) {
   d6b2c:	f04f 0b00 	mov.w	fp, #0
   d6b30:	45d8      	cmp	r8, fp
   d6b32:	dd0c      	ble.n	d6b4e <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1be>
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d6b34:	210a      	movs	r1, #10
   d6b36:	4638      	mov	r0, r7
   d6b38:	f7ff fed8 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>

  typedef typename IndirectHelper<T>::return_type return_type;
  typedef typename IndirectHelper<T>::mutable_return_type mutable_return_type;

  return_type Get(uoffset_t i) const {
    FLATBUFFERS_ASSERT(i < size());
   d6b3c:	6801      	ldr	r1, [r0, #0]
   d6b3e:	458b      	cmp	fp, r1
   d6b40:	d323      	bcc.n	d6b8a <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1fa>
   d6b42:	4b1d      	ldr	r3, [pc, #116]	; (d6bb8 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x228>)
   d6b44:	4a1e      	ldr	r2, [pc, #120]	; (d6bc0 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x230>)
   d6b46:	481f      	ldr	r0, [pc, #124]	; (d6bc4 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x234>)
   d6b48:	21ed      	movs	r1, #237	; 0xed
   d6b4a:	f00e fce3 	bl	e5514 <__assert_func>
      zero_point_data[i] = src_quantization->zero_point()->Get(i);
      scale_data[i] = src_quantization->scale()->Get(i);
    }
    quantization->scale = reinterpret_cast<TfLiteFloatArray*>(scale_array);
   d6b4e:	9b01      	ldr	r3, [sp, #4]
   d6b50:	461a      	mov	r2, r3
   d6b52:	9b02      	ldr	r3, [sp, #8]
   d6b54:	6013      	str	r3, [r2, #0]
    quantization->zero_point =
        reinterpret_cast<TfLiteIntArray*>(zero_point_array);

    result->quantization = {kTfLiteAffineQuantization, quantization};
   d6b56:	2301      	movs	r3, #1
      zero_point_data[i] = src_quantization->zero_point()->Get(i);
      scale_data[i] = src_quantization->scale()->Get(i);
    }
    quantization->scale = reinterpret_cast<TfLiteFloatArray*>(scale_array);
    quantization->zero_point =
        reinterpret_cast<TfLiteIntArray*>(zero_point_array);
   d6b58:	f8c2 a004 	str.w	sl, [r2, #4]

    result->quantization = {kTfLiteAffineQuantization, quantization};
   d6b5c:	f884 3030 	strb.w	r3, [r4, #48]	; 0x30
   d6b60:	6362      	str	r2, [r4, #52]	; 0x34
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d6b62:	210a      	movs	r1, #10
   d6b64:	4628      	mov	r0, r5
   d6b66:	f7ff fec1 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
  }
  // Copy the name, if there is one.
  if (flatbuffer_tensor.name()->c_str() != nullptr) {
   d6b6a:	3004      	adds	r0, #4
    result->name = flatbuffer_tensor.name()->c_str();
  } else {
    result->name = "<No name>";
   d6b6c:	bf04      	itt	eq
   d6b6e:	4b16      	ldreq	r3, [pc, #88]	; (d6bc8 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x238>)
   d6b70:	6223      	streq	r3, [r4, #32]
  }
  // These aren't used by the micro flavor of TFL, so set them to defaults.
  result->allocation = nullptr;
   d6b72:	f04f 0300 	mov.w	r3, #0

    result->quantization = {kTfLiteAffineQuantization, quantization};
  }
  // Copy the name, if there is one.
  if (flatbuffer_tensor.name()->c_str() != nullptr) {
    result->name = flatbuffer_tensor.name()->c_str();
   d6b76:	bf18      	it	ne
   d6b78:	6220      	strne	r0, [r4, #32]
  } else {
    result->name = "<No name>";
  }
  // These aren't used by the micro flavor of TFL, so set them to defaults.
  result->allocation = nullptr;
   d6b7a:	61e3      	str	r3, [r4, #28]
  result->delegate = nullptr;
   d6b7c:	6263      	str	r3, [r4, #36]	; 0x24
  result->buffer_handle = 0;
   d6b7e:	62a3      	str	r3, [r4, #40]	; 0x28
  result->data_is_stale = false;
   d6b80:	f884 302c 	strb.w	r3, [r4, #44]	; 0x2c
   d6b84:	e014      	b.n	d6bb0 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x220>
    const flatbuffers::Vector<flatbuffers::Offset<Buffer>>* buffers,
    ErrorReporter* error_reporter, TfLiteTensor* result,
    uint8_t* preallocated_buffer) {
  // Make sure the serialized type is one we know how to deal with, and convert
  // it from a flatbuffer enum into a constant used by the kernel C API.
  TF_LITE_ENSURE_STATUS(ConvertTensorType(flatbuffer_tensor.type(),
   d6b86:	2601      	movs	r6, #1
   d6b88:	e012      	b.n	d6bb0 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x220>
template<typename T> struct IndirectHelper {
  typedef T return_type;
  typedef T mutable_return_type;
  static const size_t element_stride = sizeof(T);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    return EndianScalar((reinterpret_cast<const T *>(p))[i]);
   d6b8a:	eb00 00cb 	add.w	r0, r0, fp, lsl #3
    zero_point_array[0] = channels;
    scale_array[0] = channels;
    int* zero_point_data = &zero_point_array[1];
    float* scale_data = reinterpret_cast<float*>(&scale_array[1]);
    for (int i = 0; i < channels; i++) {
      zero_point_data[i] = src_quantization->zero_point()->Get(i);
   d6b8e:	9b03      	ldr	r3, [sp, #12]
   d6b90:	6841      	ldr	r1, [r0, #4]
   d6b92:	f843 1f04 	str.w	r1, [r3, #4]!
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d6b96:	4638      	mov	r0, r7
   d6b98:	2108      	movs	r1, #8
   d6b9a:	9303      	str	r3, [sp, #12]
   d6b9c:	f7ff fea6 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
      scale_data[i] = src_quantization->scale()->Get(i);
   d6ba0:	4659      	mov	r1, fp
   d6ba2:	f7ff fe61 	bl	d6868 <_ZNK11flatbuffers6VectorIfE3GetEm>
            channels * sizeof(float) + sizeof(int), sizeof(int)));
    zero_point_array[0] = channels;
    scale_array[0] = channels;
    int* zero_point_data = &zero_point_array[1];
    float* scale_data = reinterpret_cast<float*>(&scale_array[1]);
    for (int i = 0; i < channels; i++) {
   d6ba6:	f10b 0b01 	add.w	fp, fp, #1
      zero_point_data[i] = src_quantization->zero_point()->Get(i);
      scale_data[i] = src_quantization->scale()->Get(i);
   d6baa:	eca9 0a01 	vstmia	r9!, {s0}
   d6bae:	e7bf      	b.n	d6b30 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh+0x1a0>
  result->allocation = nullptr;
  result->delegate = nullptr;
  result->buffer_handle = 0;
  result->data_is_stale = false;
  return kTfLiteOk;
}
   d6bb0:	4630      	mov	r0, r6
   d6bb2:	b007      	add	sp, #28
   d6bb4:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   d6bb8:	000e9ff2 	.word	0x000e9ff2
   d6bbc:	000ead90 	.word	0x000ead90
   d6bc0:	000eae86 	.word	0x000eae86
   d6bc4:	000e9ffd 	.word	0x000e9ffd
   d6bc8:	000eabe5 	.word	0x000eabe5

000d6bcc <_ZN6tflite14MicroAllocator15AllocateTensorsEv>:
  const auto* tensor = tensors_->Get(tensor_index);
  return InitializeRuntimeTensor(*tensor, buffers, error_reporter_,
                                 &context_->tensors[tensor_index], buffer);
}

TfLiteStatus MicroAllocator::AllocateTensors() {
   d6bcc:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d6bd0:	6a83      	ldr	r3, [r0, #40]	; 0x28
   d6bd2:	f8d3 9000 	ldr.w	r9, [r3]

  // It would be better not to allocate this memory for the lifetime of the
  // model, but we don't have a straightforward way to avoid it.
  TensorInfo* tensor_info =
      reinterpret_cast<TensorInfo*>(memory_allocator_.AllocateFromTail(
          sizeof(TensorInfo) * tensors_size, sizeof(TensorInfo)));
   d6bd6:	2214      	movs	r2, #20
  const auto* tensor = tensors_->Get(tensor_index);
  return InitializeRuntimeTensor(*tensor, buffers, error_reporter_,
                                 &context_->tensors[tensor_index], buffer);
}

TfLiteStatus MicroAllocator::AllocateTensors() {
   d6bd8:	b091      	sub	sp, #68	; 0x44

  // It would be better not to allocate this memory for the lifetime of the
  // model, but we don't have a straightforward way to avoid it.
  TensorInfo* tensor_info =
      reinterpret_cast<TensorInfo*>(memory_allocator_.AllocateFromTail(
          sizeof(TensorInfo) * tensors_size, sizeof(TensorInfo)));
   d6bda:	fb02 f109 	mul.w	r1, r2, r9
  const auto* tensor = tensors_->Get(tensor_index);
  return InitializeRuntimeTensor(*tensor, buffers, error_reporter_,
                                 &context_->tensors[tensor_index], buffer);
}

TfLiteStatus MicroAllocator::AllocateTensors() {
   d6bde:	4604      	mov	r4, r0

  // It would be better not to allocate this memory for the lifetime of the
  // model, but we don't have a straightforward way to avoid it.
  TensorInfo* tensor_info =
      reinterpret_cast<TensorInfo*>(memory_allocator_.AllocateFromTail(
          sizeof(TensorInfo) * tensors_size, sizeof(TensorInfo)));
   d6be0:	3004      	adds	r0, #4
   d6be2:	f000 fc90 	bl	d7506 <_ZN6tflite21SimpleMemoryAllocator16AllocateFromTailEjj>
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d6be6:	210c      	movs	r1, #12
   d6be8:	4605      	mov	r5, r0
   d6bea:	6820      	ldr	r0, [r4, #0]
   d6bec:	f7ff fe7e 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
   d6bf0:	f105 0710 	add.w	r7, r5, #16

  const flatbuffers::Vector<flatbuffers::Offset<Buffer>>* buffers =
      model_->buffers();

  // Set up the runtime data structures for all tensors.
  for (size_t i = 0; i < tensors_size; ++i) {
   d6bf4:	f04f 0800 	mov.w	r8, #0
   d6bf8:	9002      	str	r0, [sp, #8]
   d6bfa:	463e      	mov	r6, r7
    const bool is_variable = current->flatbuffer_tensor->is_variable();
    if (is_variable) {
      current->first_created = 0;
      current->last_used = operators_->size();
    } else {
      current->first_created = -1;
   d6bfc:	f04f 3aff 	mov.w	sl, #4294967295	; 0xffffffff
    TensorInfo* current = &tensor_info[i];
    current->flatbuffer_tensor = &(*(tensors_->Get(i)));
    current->runtime_tensor = &context_->tensors[i];
    const bool is_variable = current->flatbuffer_tensor->is_variable();
    if (is_variable) {
      current->first_created = 0;
   d6c00:	46c3      	mov	fp, r8

  const flatbuffers::Vector<flatbuffers::Offset<Buffer>>* buffers =
      model_->buffers();

  // Set up the runtime data structures for all tensors.
  for (size_t i = 0; i < tensors_size; ++i) {
   d6c02:	45c8      	cmp	r8, r9
   d6c04:	d104      	bne.n	d6c10 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x44>
   d6c06:	2600      	movs	r6, #0
  }

  // First go through the inputs and figure out if they need to be allocated.
  for (size_t i = 0; i < subgraph_->inputs()->size(); ++i) {
    const int tensor_index = subgraph_->inputs()->Get(i);
    TensorInfo* current = &tensor_info[tensor_index];
   d6c08:	f04f 0914 	mov.w	r9, #20
    // Check for pre-allocated inputs.
    current->needs_allocating = (current->runtime_tensor->data.raw == nullptr);
    current->first_created = 0;
   d6c0c:	46b0      	mov	r8, r6
   d6c0e:	e03e      	b.n	d6c8e <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0xc2>
      model_->buffers();

  // Set up the runtime data structures for all tensors.
  for (size_t i = 0; i < tensors_size; ++i) {
    TensorInfo* current = &tensor_info[i];
    current->flatbuffer_tensor = &(*(tensors_->Get(i)));
   d6c10:	6aa0      	ldr	r0, [r4, #40]	; 0x28
   d6c12:	4641      	mov	r1, r8
   d6c14:	f7ff fe52 	bl	d68bc <_ZNK11flatbuffers6VectorINS_6OffsetIN6tflite6TensorEEEE3GetEm>
   d6c18:	f846 0c10 	str.w	r0, [r6, #-16]
    current->runtime_tensor = &context_->tensors[i];
   d6c1c:	6963      	ldr	r3, [r4, #20]
   d6c1e:	689b      	ldr	r3, [r3, #8]
   d6c20:	2238      	movs	r2, #56	; 0x38
   d6c22:	fb02 3308 	mla	r3, r2, r8, r3
   d6c26:	f846 3c0c 	str.w	r3, [r6, #-12]
   d6c2a:	9303      	str	r3, [sp, #12]
    const bool is_variable = current->flatbuffer_tensor->is_variable();
   d6c2c:	f7ff fe11 	bl	d6852 <_ZNK6tflite6Tensor11is_variableEv>
    if (is_variable) {
   d6c30:	9b03      	ldr	r3, [sp, #12]
   d6c32:	b130      	cbz	r0, d6c42 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x76>
      current->first_created = 0;
   d6c34:	f846 bc08 	str.w	fp, [r6, #-8]
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d6c38:	6a62      	ldr	r2, [r4, #36]	; 0x24
      current->last_used = operators_->size();
   d6c3a:	6812      	ldr	r2, [r2, #0]
   d6c3c:	f846 2c04 	str.w	r2, [r6, #-4]
   d6c40:	e003      	b.n	d6c4a <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x7e>
    } else {
      current->first_created = -1;
   d6c42:	f846 ac08 	str.w	sl, [r6, #-8]
      current->last_used = -1;
   d6c46:	f846 ac04 	str.w	sl, [r6, #-4]
    }
    current->needs_allocating = false;
   d6c4a:	f886 b000 	strb.w	fp, [r6]
    // Preallocated inputs have already been set up earlier, so skip them.
    const bool is_preallocated_input =
        (current->runtime_tensor->data.raw != nullptr);
    if (!is_preallocated_input) {
   d6c4e:	685a      	ldr	r2, [r3, #4]
   d6c50:	b11a      	cbz	r2, d6c5a <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x8e>

  const flatbuffers::Vector<flatbuffers::Offset<Buffer>>* buffers =
      model_->buffers();

  // Set up the runtime data structures for all tensors.
  for (size_t i = 0; i < tensors_size; ++i) {
   d6c52:	f108 0801 	add.w	r8, r8, #1
   d6c56:	3614      	adds	r6, #20
   d6c58:	e7d3      	b.n	d6c02 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x36>
    current->needs_allocating = false;
    // Preallocated inputs have already been set up earlier, so skip them.
    const bool is_preallocated_input =
        (current->runtime_tensor->data.raw != nullptr);
    if (!is_preallocated_input) {
      TF_LITE_ENSURE_STATUS(InitializeRuntimeTensor(
   d6c5a:	9201      	str	r2, [sp, #4]
   d6c5c:	9300      	str	r3, [sp, #0]
   d6c5e:	6923      	ldr	r3, [r4, #16]
   d6c60:	9a02      	ldr	r2, [sp, #8]
   d6c62:	f856 1c10 	ldr.w	r1, [r6, #-16]
   d6c66:	4620      	mov	r0, r4
   d6c68:	f7ff fe92 	bl	d6990 <_ZN6tflite14MicroAllocator23InitializeRuntimeTensorERKNS_6TensorEPKN11flatbuffers6VectorINS4_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensorPh>
   d6c6c:	2800      	cmp	r0, #0
   d6c6e:	d0f0      	beq.n	d6c52 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x86>
   d6c70:	e101      	b.n	d6e76 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2aa>
    }
  }

  // First go through the inputs and figure out if they need to be allocated.
  for (size_t i = 0; i < subgraph_->inputs()->size(); ++i) {
    const int tensor_index = subgraph_->inputs()->Get(i);
   d6c72:	4631      	mov	r1, r6
   d6c74:	f7ff fe0e 	bl	d6894 <_ZNK11flatbuffers6VectorIlE3GetEm>
    TensorInfo* current = &tensor_info[tensor_index];
   d6c78:	fb09 5000 	mla	r0, r9, r0, r5
          current->runtime_tensor, nullptr));
    }
  }

  // First go through the inputs and figure out if they need to be allocated.
  for (size_t i = 0; i < subgraph_->inputs()->size(); ++i) {
   d6c7c:	3601      	adds	r6, #1
    const int tensor_index = subgraph_->inputs()->Get(i);
    TensorInfo* current = &tensor_info[tensor_index];
    // Check for pre-allocated inputs.
    current->needs_allocating = (current->runtime_tensor->data.raw == nullptr);
   d6c7e:	6843      	ldr	r3, [r0, #4]
   d6c80:	685b      	ldr	r3, [r3, #4]
    current->first_created = 0;
   d6c82:	f8c0 8008 	str.w	r8, [r0, #8]
  // First go through the inputs and figure out if they need to be allocated.
  for (size_t i = 0; i < subgraph_->inputs()->size(); ++i) {
    const int tensor_index = subgraph_->inputs()->Get(i);
    TensorInfo* current = &tensor_info[tensor_index];
    // Check for pre-allocated inputs.
    current->needs_allocating = (current->runtime_tensor->data.raw == nullptr);
   d6c86:	fab3 f383 	clz	r3, r3
   d6c8a:	095b      	lsrs	r3, r3, #5
   d6c8c:	7403      	strb	r3, [r0, #16]
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d6c8e:	2106      	movs	r1, #6
   d6c90:	6a20      	ldr	r0, [r4, #32]
   d6c92:	f7ff fe2b 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
          current->runtime_tensor, nullptr));
    }
  }

  // First go through the inputs and figure out if they need to be allocated.
  for (size_t i = 0; i < subgraph_->inputs()->size(); ++i) {
   d6c96:	6803      	ldr	r3, [r0, #0]
   d6c98:	429e      	cmp	r6, r3
   d6c9a:	d3ea      	bcc.n	d6c72 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0xa6>
   d6c9c:	2600      	movs	r6, #0

  // Mark all outputs as persistent to the end of the invocation.
  for (size_t i = 0; i < subgraph_->outputs()->size(); ++i) {
    const int tensor_index = subgraph_->outputs()->Get(i);
    TensorInfo* current = &tensor_info[tensor_index];
    current->last_used = operators_->size() - 1;
   d6c9e:	f04f 0914 	mov.w	r9, #20
   d6ca2:	2108      	movs	r1, #8
   d6ca4:	6a20      	ldr	r0, [r4, #32]
   d6ca6:	f7ff fe21 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
    current->needs_allocating = (current->runtime_tensor->data.raw == nullptr);
    current->first_created = 0;
  }

  // Mark all outputs as persistent to the end of the invocation.
  for (size_t i = 0; i < subgraph_->outputs()->size(); ++i) {
   d6caa:	6803      	ldr	r3, [r0, #0]
   d6cac:	f8d4 8024 	ldr.w	r8, [r4, #36]	; 0x24
   d6cb0:	429e      	cmp	r6, r3
   d6cb2:	d20a      	bcs.n	d6cca <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0xfe>
    const int tensor_index = subgraph_->outputs()->Get(i);
   d6cb4:	4631      	mov	r1, r6
   d6cb6:	f7ff fded 	bl	d6894 <_ZNK11flatbuffers6VectorIlE3GetEm>
    TensorInfo* current = &tensor_info[tensor_index];
    current->last_used = operators_->size() - 1;
   d6cba:	f8d8 3000 	ldr.w	r3, [r8]
   d6cbe:	fb09 5000 	mla	r0, r9, r0, r5
   d6cc2:	3b01      	subs	r3, #1
   d6cc4:	60c3      	str	r3, [r0, #12]
    current->needs_allocating = (current->runtime_tensor->data.raw == nullptr);
    current->first_created = 0;
  }

  // Mark all outputs as persistent to the end of the invocation.
  for (size_t i = 0; i < subgraph_->outputs()->size(); ++i) {
   d6cc6:	3601      	adds	r6, #1
   d6cc8:	e7eb      	b.n	d6ca2 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0xd6>
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d6cca:	f8d8 6000 	ldr.w	r6, [r8]
    TensorInfo* current = &tensor_info[tensor_index];
    current->last_used = operators_->size() - 1;
  }

  // Figure out when the first and last use of each tensor is.
  for (int i = (operators_->size() - 1); i >= 0; --i) {
   d6cce:	f106 38ff 	add.w	r8, r6, #4294967295	; 0xffffffff
   d6cd2:	f106 4680 	add.w	r6, r6, #1073741824	; 0x40000000
   d6cd6:	3e01      	subs	r6, #1
   d6cd8:	00b6      	lsls	r6, r6, #2
    const auto* op = operators_->Get(i);
    for (size_t n = 0; n < op->inputs()->size(); ++n) {
      const int tensor_index = op->inputs()->Get(n);
      TensorInfo* current = &tensor_info[tensor_index];
   d6cda:	f04f 0914 	mov.w	r9, #20
    TensorInfo* current = &tensor_info[tensor_index];
    current->last_used = operators_->size() - 1;
  }

  // Figure out when the first and last use of each tensor is.
  for (int i = (operators_->size() - 1); i >= 0; --i) {
   d6cde:	f1b8 0f00 	cmp.w	r8, #0
   d6ce2:	da03      	bge.n	d6cec <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x120>
   d6ce4:	462b      	mov	r3, r5
   d6ce6:	2200      	movs	r2, #0
          "Logic error in memory planner, tensor %d has an invalid lifetime",
          i);
      return kTfLiteError;
    }
    if (!is_read_only && !is_preallocated_input) {
      current->needs_allocating = true;
   d6ce8:	2001      	movs	r0, #1
   d6cea:	e04c      	b.n	d6d86 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x1ba>
    current->last_used = operators_->size() - 1;
  }

  // Figure out when the first and last use of each tensor is.
  for (int i = (operators_->size() - 1); i >= 0; --i) {
    const auto* op = operators_->Get(i);
   d6cec:	6a63      	ldr	r3, [r4, #36]	; 0x24

  typedef typename IndirectHelper<T>::return_type return_type;
  typedef typename IndirectHelper<T>::mutable_return_type mutable_return_type;

  return_type Get(uoffset_t i) const {
    FLATBUFFERS_ASSERT(i < size());
   d6cee:	681a      	ldr	r2, [r3, #0]
   d6cf0:	4590      	cmp	r8, r2
   d6cf2:	d305      	bcc.n	d6d00 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x134>
   d6cf4:	4b66      	ldr	r3, [pc, #408]	; (d6e90 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2c4>)
   d6cf6:	4a67      	ldr	r2, [pc, #412]	; (d6e94 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2c8>)
   d6cf8:	4867      	ldr	r0, [pc, #412]	; (d6e98 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2cc>)
   d6cfa:	21ed      	movs	r1, #237	; 0xed
   d6cfc:	f00e fc0a 	bl	e5514 <__assert_func>
    return const_cast<mutable_return_type>(IndirectHelper<T>::Read(Data(), i));
  }

  // The raw data in little endian format. Use with care.
  const uint8_t *Data() const {
    return reinterpret_cast<const uint8_t *>(&length_ + 1);
   d6d00:	3304      	adds	r3, #4
template<typename T> struct IndirectHelper<Offset<T>> {
  typedef const T *return_type;
  typedef T *mutable_return_type;
  static const size_t element_stride = sizeof(uoffset_t);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    p += i * sizeof(uoffset_t);
   d6d02:	eb03 0b06 	add.w	fp, r3, r6
    return reinterpret_cast<return_type>(p + ReadScalar<uoffset_t>(p));
   d6d06:	599b      	ldr	r3, [r3, r6]
    for (size_t n = 0; n < op->inputs()->size(); ++n) {
   d6d08:	f04f 0a00 	mov.w	sl, #0
   d6d0c:	449b      	add	fp, r3
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d6d0e:	2106      	movs	r1, #6
   d6d10:	4658      	mov	r0, fp
   d6d12:	f7ff fdeb 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
   d6d16:	6803      	ldr	r3, [r0, #0]
   d6d18:	459a      	cmp	sl, r3
   d6d1a:	d302      	bcc.n	d6d22 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x156>
   d6d1c:	f04f 0a00 	mov.w	sl, #0
   d6d20:	e01a      	b.n	d6d58 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x18c>
      const int tensor_index = op->inputs()->Get(n);
   d6d22:	4651      	mov	r1, sl
   d6d24:	f7ff fdb6 	bl	d6894 <_ZNK11flatbuffers6VectorIlE3GetEm>
      TensorInfo* current = &tensor_info[tensor_index];
   d6d28:	fb09 5000 	mla	r0, r9, r0, r5
      if ((current->last_used == -1) || (current->last_used > i)) {
   d6d2c:	68c3      	ldr	r3, [r0, #12]
   d6d2e:	1c59      	adds	r1, r3, #1
   d6d30:	d001      	beq.n	d6d36 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x16a>
   d6d32:	4598      	cmp	r8, r3
   d6d34:	da01      	bge.n	d6d3a <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x16e>
        current->last_used = i;
   d6d36:	f8c0 800c 	str.w	r8, [r0, #12]
  }

  // Figure out when the first and last use of each tensor is.
  for (int i = (operators_->size() - 1); i >= 0; --i) {
    const auto* op = operators_->Get(i);
    for (size_t n = 0; n < op->inputs()->size(); ++n) {
   d6d3a:	f10a 0a01 	add.w	sl, sl, #1
   d6d3e:	e7e6      	b.n	d6d0e <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x142>
      if ((current->last_used == -1) || (current->last_used > i)) {
        current->last_used = i;
      }
    }
    for (size_t n = 0; n < op->outputs()->size(); ++n) {
      const int tensor_index = op->outputs()->Get(n);
   d6d40:	4651      	mov	r1, sl
   d6d42:	f7ff fda7 	bl	d6894 <_ZNK11flatbuffers6VectorIlE3GetEm>
      TensorInfo* current = &tensor_info[tensor_index];
   d6d46:	fb09 5000 	mla	r0, r9, r0, r5
      if ((current->first_created == -1) || (current->first_created < i)) {
   d6d4a:	6883      	ldr	r3, [r0, #8]
   d6d4c:	1c5a      	adds	r2, r3, #1
   d6d4e:	d00b      	beq.n	d6d68 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x19c>
   d6d50:	4598      	cmp	r8, r3
   d6d52:	dc09      	bgt.n	d6d68 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x19c>
      TensorInfo* current = &tensor_info[tensor_index];
      if ((current->last_used == -1) || (current->last_used > i)) {
        current->last_used = i;
      }
    }
    for (size_t n = 0; n < op->outputs()->size(); ++n) {
   d6d54:	f10a 0a01 	add.w	sl, sl, #1
   d6d58:	2108      	movs	r1, #8
   d6d5a:	4658      	mov	r0, fp
   d6d5c:	f7ff fdc6 	bl	d68ec <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite6BufferEEEEEEET_t>
   d6d60:	6803      	ldr	r3, [r0, #0]
   d6d62:	459a      	cmp	sl, r3
   d6d64:	d3ec      	bcc.n	d6d40 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x174>
   d6d66:	e002      	b.n	d6d6e <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x1a2>
      const int tensor_index = op->outputs()->Get(n);
      TensorInfo* current = &tensor_info[tensor_index];
      if ((current->first_created == -1) || (current->first_created < i)) {
        current->first_created = i;
   d6d68:	f8c0 8008 	str.w	r8, [r0, #8]
   d6d6c:	e7f2      	b.n	d6d54 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x188>
    TensorInfo* current = &tensor_info[tensor_index];
    current->last_used = operators_->size() - 1;
  }

  // Figure out when the first and last use of each tensor is.
  for (int i = (operators_->size() - 1); i >= 0; --i) {
   d6d6e:	f108 38ff 	add.w	r8, r8, #4294967295	; 0xffffffff
   d6d72:	3e04      	subs	r6, #4
   d6d74:	e7b3      	b.n	d6cde <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x112>

  // Work out which tensors need to be allocated.
  for (size_t i = 0; i < tensors_->size(); ++i) {
    TensorInfo* current = &tensor_info[i];
    const bool is_read_only =
        (current->first_created == -1) && (current->last_used != -1);
   d6d76:	6899      	ldr	r1, [r3, #8]
   d6d78:	3101      	adds	r1, #1
   d6d7a:	68d9      	ldr	r1, [r3, #12]
   d6d7c:	d175      	bne.n	d6e6a <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x29e>
   d6d7e:	3101      	adds	r1, #1
   d6d80:	d075      	beq.n	d6e6e <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2a2>
      }
    }
  }

  // Work out which tensors need to be allocated.
  for (size_t i = 0; i < tensors_->size(); ++i) {
   d6d82:	3201      	adds	r2, #1
   d6d84:	3314      	adds	r3, #20
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d6d86:	6aa1      	ldr	r1, [r4, #40]	; 0x28
   d6d88:	6809      	ldr	r1, [r1, #0]
   d6d8a:	428a      	cmp	r2, r1
   d6d8c:	d3f3      	bcc.n	d6d76 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x1aa>
    if (!is_read_only && !is_preallocated_input) {
      current->needs_allocating = true;
    }
  }

  uint8_t* aligned_arena = AlignPointerUp(arena_, kBufferAlignment);
   d6d8e:	2110      	movs	r1, #16
   d6d90:	69a0      	ldr	r0, [r4, #24]
   d6d92:	f7ff fce5 	bl	d6760 <_ZN6tflite14AlignPointerUpEPhj>
  const size_t alignment_loss = (aligned_arena - arena_);

  int remaining_arena_size =
      arena_size_ - (memory_allocator_.GetDataSize() + alignment_loss);
   d6d96:	69e3      	ldr	r3, [r4, #28]
   d6d98:	6866      	ldr	r6, [r4, #4]
   d6d9a:	1b9e      	subs	r6, r3, r6
   d6d9c:	69a3      	ldr	r3, [r4, #24]
   d6d9e:	1ac3      	subs	r3, r0, r3
   d6da0:	1af6      	subs	r6, r6, r3
  GreedyMemoryPlanner planner(aligned_arena, remaining_arena_size);
   d6da2:	4601      	mov	r1, r0
    if (!is_read_only && !is_preallocated_input) {
      current->needs_allocating = true;
    }
  }

  uint8_t* aligned_arena = AlignPointerUp(arena_, kBufferAlignment);
   d6da4:	4680      	mov	r8, r0
  const size_t alignment_loss = (aligned_arena - arena_);

  int remaining_arena_size =
      arena_size_ - (memory_allocator_.GetDataSize() + alignment_loss);
  GreedyMemoryPlanner planner(aligned_arena, remaining_arena_size);
   d6da6:	4632      	mov	r2, r6
   d6da8:	a806      	add	r0, sp, #24
   d6daa:	f00d fd3d 	bl	e4828 <_ZN6tflite19GreedyMemoryPlannerC1EPhi>

  // Add the tensors to our allocation plan.
  for (size_t i = 0; i < tensors_->size(); ++i) {
   d6dae:	f04f 0900 	mov.w	r9, #0
   d6db2:	6aa3      	ldr	r3, [r4, #40]	; 0x28
   d6db4:	681b      	ldr	r3, [r3, #0]
   d6db6:	4599      	cmp	r9, r3
   d6db8:	d21b      	bcs.n	d6df2 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x226>
    TensorInfo* current = &tensor_info[i];
    if (current->needs_allocating) {
   d6dba:	783b      	ldrb	r3, [r7, #0]
   d6dbc:	b1ab      	cbz	r3, d6dea <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x21e>
      size_t bytes_required;
      size_t type_size;
      TF_LITE_ENSURE_STATUS(BytesRequiredForTensor(*current->flatbuffer_tensor,
   d6dbe:	6923      	ldr	r3, [r4, #16]
   d6dc0:	f857 0c10 	ldr.w	r0, [r7, #-16]
   d6dc4:	aa05      	add	r2, sp, #20
   d6dc6:	a904      	add	r1, sp, #16
   d6dc8:	f7ff fcfe 	bl	d67c8 <_ZN6tflite22BytesRequiredForTensorERKNS_6TensorEPjS3_PNS_13ErrorReporterE>
   d6dcc:	bb00      	cbnz	r0, d6e10 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x244>
                                                   &bytes_required, &type_size,
                                                   error_reporter_));
      size_t aligned_bytes_required =
          AlignSizeUp(bytes_required, kBufferAlignment);
   d6dce:	2110      	movs	r1, #16
   d6dd0:	9804      	ldr	r0, [sp, #16]
   d6dd2:	f7ff fccf 	bl	d6774 <_ZN6tflite11AlignSizeUpEjj>
      planner.AddBuffer(error_reporter_, aligned_bytes_required,
                        current->first_created, current->last_used);
   d6dd6:	f857 3c04 	ldr.w	r3, [r7, #-4]
   d6dda:	9300      	str	r3, [sp, #0]
   d6ddc:	4602      	mov	r2, r0
   d6dde:	f857 3c08 	ldr.w	r3, [r7, #-8]
   d6de2:	6921      	ldr	r1, [r4, #16]
   d6de4:	a806      	add	r0, sp, #24
   d6de6:	f00d fce3 	bl	e47b0 <_ZN6tflite19GreedyMemoryPlanner9AddBufferEPNS_13ErrorReporterEiii>
  int remaining_arena_size =
      arena_size_ - (memory_allocator_.GetDataSize() + alignment_loss);
  GreedyMemoryPlanner planner(aligned_arena, remaining_arena_size);

  // Add the tensors to our allocation plan.
  for (size_t i = 0; i < tensors_->size(); ++i) {
   d6dea:	f109 0901 	add.w	r9, r9, #1
   d6dee:	3714      	adds	r7, #20
   d6df0:	e7df      	b.n	d6db2 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x1e6>
                        current->first_created, current->last_used);
    }
  }

  // Make sure we have enough room.
  if (planner.GetMaximumMemorySize() > remaining_arena_size) {
   d6df2:	a806      	add	r0, sp, #24
   d6df4:	f00d fe01 	bl	e49fa <_ZN6tflite19GreedyMemoryPlanner20GetMaximumMemorySizeEv>
   d6df8:	4286      	cmp	r6, r0
   d6dfa:	da0b      	bge.n	d6e14 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x248>
    error_reporter_->Report(
   d6dfc:	a806      	add	r0, sp, #24
   d6dfe:	6924      	ldr	r4, [r4, #16]
   d6e00:	f00d fdfb 	bl	e49fa <_ZN6tflite19GreedyMemoryPlanner20GetMaximumMemorySizeEv>
        "Arena size is too small for activation buffers. Needed %d but only %d "
        "was available.",
        planner.GetMaximumMemorySize(), remaining_arena_size);
   d6e04:	4633      	mov	r3, r6
   d6e06:	4602      	mov	r2, r0
   d6e08:	4924      	ldr	r1, [pc, #144]	; (d6e9c <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2d0>)
   d6e0a:	4620      	mov	r0, r4
   d6e0c:	f7fe fb6e 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    return kTfLiteError;
   d6e10:	2401      	movs	r4, #1
   d6e12:	e026      	b.n	d6e62 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x296>
   d6e14:	2600      	movs	r6, #0
   d6e16:	4637      	mov	r7, r6
   d6e18:	6aa3      	ldr	r3, [r4, #40]	; 0x28
  }

  // Figure out the actual memory addresses for each buffer, based on the plan.
  int planner_index = 0;
  for (size_t i = 0; i < tensors_->size(); ++i) {
   d6e1a:	681b      	ldr	r3, [r3, #0]
   d6e1c:	429e      	cmp	r6, r3
   d6e1e:	d21f      	bcs.n	d6e60 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x294>
    TensorInfo* current = &tensor_info[i];
    if (current->needs_allocating) {
   d6e20:	7c2b      	ldrb	r3, [r5, #16]
   d6e22:	b163      	cbz	r3, d6e3e <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x272>
      int offset;
      TF_LITE_ENSURE_STATUS(
   d6e24:	ab05      	add	r3, sp, #20
   d6e26:	463a      	mov	r2, r7
   d6e28:	6921      	ldr	r1, [r4, #16]
   d6e2a:	a806      	add	r0, sp, #24
   d6e2c:	f00d fe00 	bl	e4a30 <_ZN6tflite19GreedyMemoryPlanner18GetOffsetForBufferEPNS_13ErrorReporterEiPi>
   d6e30:	2800      	cmp	r0, #0
   d6e32:	d1ed      	bne.n	d6e10 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x244>
          planner.GetOffsetForBuffer(error_reporter_, planner_index, &offset));
      current->runtime_tensor->data.uint8 = aligned_arena + offset;
   d6e34:	9b05      	ldr	r3, [sp, #20]
   d6e36:	686a      	ldr	r2, [r5, #4]
   d6e38:	4443      	add	r3, r8
   d6e3a:	6053      	str	r3, [r2, #4]
      ++planner_index;
   d6e3c:	3701      	adds	r7, #1
    }
    // Set default value for variable tensors:
    if (current->flatbuffer_tensor->is_variable()) {
   d6e3e:	6828      	ldr	r0, [r5, #0]
   d6e40:	f7ff fd07 	bl	d6852 <_ZNK6tflite6Tensor11is_variableEv>
   d6e44:	b148      	cbz	r0, d6e5a <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x28e>
      if (current->runtime_tensor->data.uint8 == nullptr) {
   d6e46:	6868      	ldr	r0, [r5, #4]
   d6e48:	6843      	ldr	r3, [r0, #4]
   d6e4a:	b923      	cbnz	r3, d6e56 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x28a>
        error_reporter_->Report("Variable is not allocated");
   d6e4c:	4914      	ldr	r1, [pc, #80]	; (d6ea0 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2d4>)
   d6e4e:	6920      	ldr	r0, [r4, #16]
   d6e50:	f7fe fb4c 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
   d6e54:	e7dc      	b.n	d6e10 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x244>
        return kTfLiteError;
      }
      tflite::ResetVariableTensor(current->runtime_tensor);
   d6e56:	f7ff fbaf 	bl	d65b8 <_ZN6tflite19ResetVariableTensorEP12TfLiteTensor>
    return kTfLiteError;
  }

  // Figure out the actual memory addresses for each buffer, based on the plan.
  int planner_index = 0;
  for (size_t i = 0; i < tensors_->size(); ++i) {
   d6e5a:	3601      	adds	r6, #1
   d6e5c:	3514      	adds	r5, #20
   d6e5e:	e7db      	b.n	d6e18 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x24c>
      }
      tflite::ResetVariableTensor(current->runtime_tensor);
    }
  }

  return kTfLiteOk;
   d6e60:	2400      	movs	r4, #0
  uint8_t* aligned_arena = AlignPointerUp(arena_, kBufferAlignment);
  const size_t alignment_loss = (aligned_arena - arena_);

  int remaining_arena_size =
      arena_size_ - (memory_allocator_.GetDataSize() + alignment_loss);
  GreedyMemoryPlanner planner(aligned_arena, remaining_arena_size);
   d6e62:	a806      	add	r0, sp, #24
   d6e64:	f00d fc9a 	bl	e479c <_ZN6tflite19GreedyMemoryPlannerD1Ev>
   d6e68:	e00e      	b.n	d6e88 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2bc>
        (current->first_created == -1) && (current->last_used != -1);
    const bool is_preallocated_input =
        (current->runtime_tensor->data.raw != nullptr);
    const bool has_partial_lifetime =
        !is_read_only &&
        ((current->first_created == -1) || (current->last_used == -1));
   d6e6a:	3101      	adds	r1, #1
   d6e6c:	d105      	bne.n	d6e7a <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2ae>
    if (has_partial_lifetime) {
      error_reporter_->Report(
          "Logic error in memory planner, tensor %d has an invalid lifetime",
          i);
   d6e6e:	490d      	ldr	r1, [pc, #52]	; (d6ea4 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2d8>)
   d6e70:	6920      	ldr	r0, [r4, #16]
   d6e72:	f7fe fb3b 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
      return kTfLiteError;
   d6e76:	2401      	movs	r4, #1
   d6e78:	e006      	b.n	d6e88 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x2bc>
  for (size_t i = 0; i < tensors_->size(); ++i) {
    TensorInfo* current = &tensor_info[i];
    const bool is_read_only =
        (current->first_created == -1) && (current->last_used != -1);
    const bool is_preallocated_input =
        (current->runtime_tensor->data.raw != nullptr);
   d6e7a:	6859      	ldr	r1, [r3, #4]
      error_reporter_->Report(
          "Logic error in memory planner, tensor %d has an invalid lifetime",
          i);
      return kTfLiteError;
    }
    if (!is_read_only && !is_preallocated_input) {
   d6e7c:	6849      	ldr	r1, [r1, #4]
   d6e7e:	2900      	cmp	r1, #0
   d6e80:	f47f af7f 	bne.w	d6d82 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x1b6>
      current->needs_allocating = true;
   d6e84:	7418      	strb	r0, [r3, #16]
   d6e86:	e77c      	b.n	d6d82 <_ZN6tflite14MicroAllocator15AllocateTensorsEv+0x1b6>
      tflite::ResetVariableTensor(current->runtime_tensor);
    }
  }

  return kTfLiteOk;
}
   d6e88:	4620      	mov	r0, r4
   d6e8a:	b011      	add	sp, #68	; 0x44
   d6e8c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   d6e90:	000e9ff2 	.word	0x000e9ff2
   d6e94:	000ea9cc 	.word	0x000ea9cc
   d6e98:	000e9ffd 	.word	0x000e9ffd
   d6e9c:	000eac18 	.word	0x000eac18
   d6ea0:	000eac6d 	.word	0x000eac6d
   d6ea4:	000eac87 	.word	0x000eac87

000d6ea8 <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list>:
  }
  DebugLog("\r\n");
}
}  // namespace

int MicroErrorReporter::Report(const char* format, va_list args) {
   d6ea8:	b5f0      	push	{r4, r5, r6, r7, lr}
namespace tflite {
namespace {
void DebugLogPrintf(const char* format, va_list args) {
  const int output_cache_size = 64;
  char output_cache[output_cache_size + 1];
  int output_cache_index = 0;
   d6eaa:	2300      	movs	r3, #0
  }
  DebugLog("\r\n");
}
}  // namespace

int MicroErrorReporter::Report(const char* format, va_list args) {
   d6eac:	b093      	sub	sp, #76	; 0x4c
   d6eae:	460d      	mov	r5, r1
   d6eb0:	4614      	mov	r4, r2
    } else {
      output_cache[output_cache_index] = *current;
      output_cache_index += 1;
    }
    if (output_cache_index >= output_cache_size) {
      output_cache[output_cache_index] = 0;
   d6eb2:	461f      	mov	r7, r3
void DebugLogPrintf(const char* format, va_list args) {
  const int output_cache_size = 64;
  char output_cache[output_cache_size + 1];
  int output_cache_index = 0;
  const char* current = format;
  while (*current != 0) {
   d6eb4:	782a      	ldrb	r2, [r5, #0]
   d6eb6:	2a00      	cmp	r2, #0
   d6eb8:	d041      	beq.n	d6f3e <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x96>
    if (*current == '%') {
   d6eba:	2a25      	cmp	r2, #37	; 0x25
   d6ebc:	d12e      	bne.n	d6f1c <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x74>
      const char next = *(current + 1);
   d6ebe:	786e      	ldrb	r6, [r5, #1]
      if ((next == 'd') || (next == 's') || (next == 'f')) {
   d6ec0:	f006 02fd 	and.w	r2, r6, #253	; 0xfd
   d6ec4:	2a64      	cmp	r2, #100	; 0x64
   d6ec6:	d001      	beq.n	d6ecc <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x24>
   d6ec8:	2e73      	cmp	r6, #115	; 0x73
   d6eca:	d12c      	bne.n	d6f26 <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x7e>
        current += 1;
   d6ecc:	3501      	adds	r5, #1
        if (output_cache_index > 0) {
   d6ece:	b133      	cbz	r3, d6ede <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x36>
          output_cache[output_cache_index] = 0;
   d6ed0:	aa12      	add	r2, sp, #72	; 0x48
   d6ed2:	4413      	add	r3, r2
          DebugLog(output_cache);
   d6ed4:	a801      	add	r0, sp, #4
    if (*current == '%') {
      const char next = *(current + 1);
      if ((next == 'd') || (next == 's') || (next == 'f')) {
        current += 1;
        if (output_cache_index > 0) {
          output_cache[output_cache_index] = 0;
   d6ed6:	f803 7c44 	strb.w	r7, [r3, #-68]
          DebugLog(output_cache);
   d6eda:	f000 fb29 	bl	d7530 <DebugLog>
          output_cache_index = 0;
        }
        if (next == 'd') {
   d6ede:	2e64      	cmp	r6, #100	; 0x64
   d6ee0:	d104      	bne.n	d6eec <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x44>
          DebugLogInt32(va_arg(args, int));
   d6ee2:	6820      	ldr	r0, [r4, #0]
   d6ee4:	1d26      	adds	r6, r4, #4
   d6ee6:	f7ff fbaf 	bl	d6648 <DebugLogInt32>
   d6eea:	e005      	b.n	d6ef8 <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x50>
        } else if (next == 's') {
   d6eec:	2e73      	cmp	r6, #115	; 0x73
   d6eee:	d105      	bne.n	d6efc <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x54>
          DebugLog(va_arg(args, char*));
   d6ef0:	6820      	ldr	r0, [r4, #0]
   d6ef2:	1d26      	adds	r6, r4, #4
   d6ef4:	f000 fb1c 	bl	d7530 <DebugLog>
   d6ef8:	4634      	mov	r4, r6
   d6efa:	e01d      	b.n	d6f38 <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x90>
        } else if (next == 'f') {
   d6efc:	2e66      	cmp	r6, #102	; 0x66
   d6efe:	d11b      	bne.n	d6f38 <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x90>
          DebugLogFloat(va_arg(args, double));
   d6f00:	1de2      	adds	r2, r4, #7
   d6f02:	f022 0207 	bic.w	r2, r2, #7
   d6f06:	e9d2 0100 	ldrd	r0, r1, [r2]
   d6f0a:	f102 0408 	add.w	r4, r2, #8
   d6f0e:	f011 fd6b 	bl	e89e8 <__aeabi_d2f>
   d6f12:	ee00 0a10 	vmov	s0, r0
   d6f16:	f7ff fbad 	bl	d6674 <DebugLogFloat>
   d6f1a:	e00d      	b.n	d6f38 <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x90>
        }
      }
    } else {
      output_cache[output_cache_index] = *current;
   d6f1c:	a912      	add	r1, sp, #72	; 0x48
   d6f1e:	4419      	add	r1, r3
      output_cache_index += 1;
   d6f20:	3301      	adds	r3, #1
        } else if (next == 'f') {
          DebugLogFloat(va_arg(args, double));
        }
      }
    } else {
      output_cache[output_cache_index] = *current;
   d6f22:	f801 2c44 	strb.w	r2, [r1, #-68]
      output_cache_index += 1;
    }
    if (output_cache_index >= output_cache_size) {
   d6f26:	2b3f      	cmp	r3, #63	; 0x3f
   d6f28:	dd07      	ble.n	d6f3a <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0x92>
      output_cache[output_cache_index] = 0;
   d6f2a:	aa12      	add	r2, sp, #72	; 0x48
   d6f2c:	4413      	add	r3, r2
      DebugLog(output_cache);
   d6f2e:	a801      	add	r0, sp, #4
    } else {
      output_cache[output_cache_index] = *current;
      output_cache_index += 1;
    }
    if (output_cache_index >= output_cache_size) {
      output_cache[output_cache_index] = 0;
   d6f30:	f803 7c44 	strb.w	r7, [r3, #-68]
      DebugLog(output_cache);
   d6f34:	f000 fafc 	bl	d7530 <DebugLog>
      output_cache_index = 0;
   d6f38:	2300      	movs	r3, #0
    }
    current += 1;
   d6f3a:	3501      	adds	r5, #1
   d6f3c:	e7ba      	b.n	d6eb4 <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0xc>
  }
  if (output_cache_index > 0) {
   d6f3e:	b133      	cbz	r3, d6f4e <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0xa6>
    output_cache[output_cache_index] = 0;
   d6f40:	a912      	add	r1, sp, #72	; 0x48
   d6f42:	440b      	add	r3, r1
    DebugLog(output_cache);
   d6f44:	a801      	add	r0, sp, #4
      output_cache_index = 0;
    }
    current += 1;
  }
  if (output_cache_index > 0) {
    output_cache[output_cache_index] = 0;
   d6f46:	f803 2c44 	strb.w	r2, [r3, #-68]
    DebugLog(output_cache);
   d6f4a:	f000 faf1 	bl	d7530 <DebugLog>
    output_cache_index = 0;
  }
  DebugLog("\r\n");
   d6f4e:	4803      	ldr	r0, [pc, #12]	; (d6f5c <_ZN6tflite18MicroErrorReporter6ReportEPKcSt9__va_list+0xb4>)
   d6f50:	f000 faee 	bl	d7530 <DebugLog>
}  // namespace

int MicroErrorReporter::Report(const char* format, va_list args) {
  DebugLogPrintf(format, args);
  return 0;
}
   d6f54:	2000      	movs	r0, #0
   d6f56:	b013      	add	sp, #76	; 0x4c
   d6f58:	bdf0      	pop	{r4, r5, r6, r7, pc}
   d6f5a:	bf00      	nop
   d6f5c:	000eaf74 	.word	0x000eaf74

000d6f60 <_ZN6tflite12_GLOBAL__N_118StackDataAllocator8AllocateEj>:
namespace {
const int kStackDataAllocatorSize = 128;
class StackDataAllocator : public BuiltinDataAllocator {
 public:
  void* Allocate(size_t size) override {
    if (size > kStackDataAllocatorSize) {
   d6f60:	2980      	cmp	r1, #128	; 0x80
      return nullptr;
    } else {
      return data_;
   d6f62:	bf94      	ite	ls
   d6f64:	3004      	addls	r0, #4
const int kStackDataAllocatorSize = 128;
class StackDataAllocator : public BuiltinDataAllocator {
 public:
  void* Allocate(size_t size) override {
    if (size > kStackDataAllocatorSize) {
      return nullptr;
   d6f66:	2000      	movhi	r0, #0
    } else {
      return data_;
    }
  }
   d6f68:	4770      	bx	lr

000d6f6a <_ZN6tflite12_GLOBAL__N_118StackDataAllocator10DeallocateEPv>:
  void Deallocate(void* data) override {
   d6f6a:	4770      	bx	lr

000d6f6c <_ZN6tflite12_GLOBAL__N_118StackDataAllocatorD1Ev>:
#include "tensorflow/lite/experimental/micro/compatibility.h"

namespace tflite {
namespace {
const int kStackDataAllocatorSize = 128;
class StackDataAllocator : public BuiltinDataAllocator {
   d6f6c:	4770      	bx	lr

000d6f6e <_ZN6tflite12_GLOBAL__N_113ReportOpErrorEP13TfLiteContextPKcz>:
  } else {
    return EnumNameBuiltinOperator(BuiltinOperator(registration->builtin_code));
  }
}

void ReportOpError(struct TfLiteContext* context, const char* format, ...) {
   d6f6e:	b40e      	push	{r1, r2, r3}
   d6f70:	b503      	push	{r0, r1, lr}
  MicroInterpreter* interpreter =
      static_cast<MicroInterpreter*>(context->impl_);
   d6f72:	68c3      	ldr	r3, [r0, #12]
   d6f74:	6898      	ldr	r0, [r3, #8]
  } else {
    return EnumNameBuiltinOperator(BuiltinOperator(registration->builtin_code));
  }
}

void ReportOpError(struct TfLiteContext* context, const char* format, ...) {
   d6f76:	aa03      	add	r2, sp, #12
  MicroInterpreter* interpreter =
      static_cast<MicroInterpreter*>(context->impl_);
  va_list args;
  va_start(args, format);
  interpreter->error_reporter()->Report(format, args);
   d6f78:	6803      	ldr	r3, [r0, #0]
  } else {
    return EnumNameBuiltinOperator(BuiltinOperator(registration->builtin_code));
  }
}

void ReportOpError(struct TfLiteContext* context, const char* format, ...) {
   d6f7a:	f852 1b04 	ldr.w	r1, [r2], #4
  MicroInterpreter* interpreter =
      static_cast<MicroInterpreter*>(context->impl_);
  va_list args;
  va_start(args, format);
   d6f7e:	9201      	str	r2, [sp, #4]
  interpreter->error_reporter()->Report(format, args);
   d6f80:	689b      	ldr	r3, [r3, #8]
   d6f82:	4798      	blx	r3
  va_end(args);
}
   d6f84:	b002      	add	sp, #8
   d6f86:	f85d eb04 	ldr.w	lr, [sp], #4
   d6f8a:	b003      	add	sp, #12
   d6f8c:	4770      	bx	lr

000d6f8e <_ZN6tflite12_GLOBAL__N_118StackDataAllocatorD0Ev>:
#include "tensorflow/lite/experimental/micro/compatibility.h"

namespace tflite {
namespace {
const int kStackDataAllocatorSize = 128;
class StackDataAllocator : public BuiltinDataAllocator {
   d6f8e:	b510      	push	{r4, lr}
   d6f90:	2184      	movs	r1, #132	; 0x84
   d6f92:	4604      	mov	r4, r0
   d6f94:	f00f f90d 	bl	e61b2 <_ZdlPvj>
   d6f98:	4620      	mov	r0, r4
   d6f9a:	bd10      	pop	{r4, pc}

000d6f9c <_ZN6tflite16MicroInterpreter15AllocateTensorsEv>:
TfLiteStatus MicroInterpreter::RegisterPreallocatedInput(uint8_t* buffer,
                                                         size_t input_index) {
  return allocator_.RegisterPreallocatedInput(buffer, input_index);
}

TfLiteStatus MicroInterpreter::AllocateTensors() {
   d6f9c:	b510      	push	{r4, lr}
   d6f9e:	4604      	mov	r4, r0
  TfLiteStatus status = allocator_.AllocateTensors();
   d6fa0:	3044      	adds	r0, #68	; 0x44
   d6fa2:	f7ff fe13 	bl	d6bcc <_ZN6tflite14MicroAllocator15AllocateTensorsEv>
   d6fa6:	2301      	movs	r3, #1
  TF_LITE_ENSURE_OK(&context_, status);
   d6fa8:	b910      	cbnz	r0, d6fb0 <_ZN6tflite16MicroInterpreter15AllocateTensorsEv+0x14>
  tensors_allocated_ = true;
   d6faa:	f884 3070 	strb.w	r3, [r4, #112]	; 0x70
  return kTfLiteOk;
   d6fae:	bd10      	pop	{r4, pc}
  return allocator_.RegisterPreallocatedInput(buffer, input_index);
}

TfLiteStatus MicroInterpreter::AllocateTensors() {
  TfLiteStatus status = allocator_.AllocateTensors();
  TF_LITE_ENSURE_OK(&context_, status);
   d6fb0:	4618      	mov	r0, r3
  tensors_allocated_ = true;
  return kTfLiteOk;
}
   d6fb2:	bd10      	pop	{r4, pc}

000d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>:
// "tables" use an offset table (possibly shared) that allows fields to be
// omitted and added at will, but uses an extra indirection to read.
class Table {
 public:
  const uint8_t *GetVTable() const {
    return data_ - ReadScalar<soffset_t>(data_);
   d6fb4:	6803      	ldr	r3, [r0, #0]
   d6fb6:	1ac3      	subs	r3, r0, r3
    auto vtable = GetVTable();
    // The first element is the size of the vtable (fields + type id + itself).
    auto vtsize = ReadScalar<voffset_t>(vtable);
    // If the field we're accessing is outside the vtable, we're reading older
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
   d6fb8:	881a      	ldrh	r2, [r3, #0]
   d6fba:	428a      	cmp	r2, r1
   d6fbc:	bf8c      	ite	hi
   d6fbe:	5a5b      	ldrhhi	r3, [r3, r1]
   d6fc0:	2300      	movls	r3, #0
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
  }

  template<typename P> P GetPointer(voffset_t field) {
    auto field_offset = GetOptionalFieldOffset(field);
    auto p = data_ + field_offset;
   d6fc2:	18c2      	adds	r2, r0, r3
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
   d6fc4:	b113      	cbz	r3, d6fcc <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t+0x18>
   d6fc6:	58c3      	ldr	r3, [r0, r3]
   d6fc8:	18d0      	adds	r0, r2, r3
   d6fca:	4770      	bx	lr
   d6fcc:	4618      	mov	r0, r3
  }
   d6fce:	4770      	bx	lr

000d6fd0 <_ZN6tflite16MicroInterpreterC1EPKNS_5ModelERKNS_10OpResolverEPhjPNS_13ErrorReporterE>:
  va_end(args);
}

}  // namespace

MicroInterpreter::MicroInterpreter(const Model* model,
   d6fd0:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
   d6fd4:	4604      	mov	r4, r0
   d6fd6:	9d09      	ldr	r5, [sp, #36]	; 0x24
      op_resolver_(op_resolver),
      error_reporter_(error_reporter),
      context_(),
      allocator_(&context_, model_, tensor_arena, tensor_arena_size,
                 error_reporter_),
      tensors_allocated_(false) {
   d6fd8:	6021      	str	r1, [r4, #0]
   d6fda:	f100 070c 	add.w	r7, r0, #12
  va_end(args);
}

}  // namespace

MicroInterpreter::MicroInterpreter(const Model* model,
   d6fde:	460e      	mov	r6, r1
      op_resolver_(op_resolver),
      error_reporter_(error_reporter),
      context_(),
      allocator_(&context_, model_, tensor_arena, tensor_arena_size,
                 error_reporter_),
      tensors_allocated_(false) {
   d6fe0:	6042      	str	r2, [r0, #4]
   d6fe2:	6085      	str	r5, [r0, #8]
   d6fe4:	2238      	movs	r2, #56	; 0x38
   d6fe6:	2100      	movs	r1, #0
   d6fe8:	4638      	mov	r0, r7
  va_end(args);
}

}  // namespace

MicroInterpreter::MicroInterpreter(const Model* model,
   d6fea:	4698      	mov	r8, r3
      op_resolver_(op_resolver),
      error_reporter_(error_reporter),
      context_(),
      allocator_(&context_, model_, tensor_arena, tensor_arena_size,
                 error_reporter_),
      tensors_allocated_(false) {
   d6fec:	f011 fdc4 	bl	e8b78 <memset>
   d6ff0:	9b08      	ldr	r3, [sp, #32]
   d6ff2:	9300      	str	r3, [sp, #0]
   d6ff4:	4632      	mov	r2, r6
   d6ff6:	4639      	mov	r1, r7
   d6ff8:	4643      	mov	r3, r8
   d6ffa:	9501      	str	r5, [sp, #4]
   d6ffc:	f104 0044 	add.w	r0, r4, #68	; 0x44
   d7000:	2700      	movs	r7, #0
   d7002:	f7ff fc7d 	bl	d6900 <_ZN6tflite14MicroAllocatorC1EP13TfLiteContextPKNS_5ModelEPhjPNS_13ErrorReporterE>
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d7006:	4630      	mov	r0, r6
   d7008:	f884 7070 	strb.w	r7, [r4, #112]	; 0x70
   d700c:	2108      	movs	r1, #8
   d700e:	f7ff ffd1 	bl	d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>
  auto* subgraphs = model->subgraphs();
  if (subgraphs->size() != 1) {
   d7012:	6806      	ldr	r6, [r0, #0]
   d7014:	2e01      	cmp	r6, #1
   d7016:	d007      	beq.n	d7028 <_ZN6tflite16MicroInterpreterC1EPKNS_5ModelERKNS_10OpResolverEPhjPNS_13ErrorReporterE+0x58>
    error_reporter->Report("Only 1 subgraph is currently supported.\n");
   d7018:	490f      	ldr	r1, [pc, #60]	; (d7058 <_ZN6tflite16MicroInterpreterC1EPKNS_5ModelERKNS_10OpResolverEPhjPNS_13ErrorReporterE+0x88>)
   d701a:	4628      	mov	r0, r5
   d701c:	f7fe fa66 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    initialization_status_ = kTfLiteError;
   d7020:	2301      	movs	r3, #1
   d7022:	f884 3071 	strb.w	r3, [r4, #113]	; 0x71
    return;
   d7026:	e013      	b.n	d7050 <_ZN6tflite16MicroInterpreterC1EPKNS_5ModelERKNS_10OpResolverEPhjPNS_13ErrorReporterE+0x80>
  typedef const T *return_type;
  typedef T *mutable_return_type;
  static const size_t element_stride = sizeof(uoffset_t);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    p += i * sizeof(uoffset_t);
    return reinterpret_cast<return_type>(p + ReadScalar<uoffset_t>(p));
   d7028:	6843      	ldr	r3, [r0, #4]
    return const_cast<mutable_return_type>(IndirectHelper<T>::Read(Data(), i));
  }

  // The raw data in little endian format. Use with care.
  const uint8_t *Data() const {
    return reinterpret_cast<const uint8_t *>(&length_ + 1);
   d702a:	1d05      	adds	r5, r0, #4
  typedef const T *return_type;
  typedef T *mutable_return_type;
  static const size_t element_stride = sizeof(uoffset_t);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    p += i * sizeof(uoffset_t);
    return reinterpret_cast<return_type>(p + ReadScalar<uoffset_t>(p));
   d702c:	441d      	add	r5, r3
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d702e:	2104      	movs	r1, #4
  }
  subgraph_ = (*subgraphs)[0];
   d7030:	67e5      	str	r5, [r4, #124]	; 0x7c
   d7032:	4628      	mov	r0, r5
   d7034:	f7ff ffbe 	bl	d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>
   d7038:	210a      	movs	r1, #10
  tensors_ = subgraph_->tensors();
   d703a:	6760      	str	r0, [r4, #116]	; 0x74
   d703c:	4628      	mov	r0, r5
   d703e:	f7ff ffb9 	bl	d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>
  operators_ = subgraph_->operators();

  context_.impl_ = static_cast<void*>(this);
  context_.ReportError = ReportOpError;
   d7042:	4b06      	ldr	r3, [pc, #24]	; (d705c <_ZN6tflite16MicroInterpreterC1EPKNS_5ModelERKNS_10OpResolverEPhjPNS_13ErrorReporterE+0x8c>)
    initialization_status_ = kTfLiteError;
    return;
  }
  subgraph_ = (*subgraphs)[0];
  tensors_ = subgraph_->tensors();
  operators_ = subgraph_->operators();
   d7044:	67a0      	str	r0, [r4, #120]	; 0x78

  context_.impl_ = static_cast<void*>(this);
   d7046:	61a4      	str	r4, [r4, #24]
  context_.ReportError = ReportOpError;
   d7048:	6223      	str	r3, [r4, #32]
  context_.recommended_num_threads = 1;
   d704a:	6326      	str	r6, [r4, #48]	; 0x30
      if (thisTensor->allocation_type == kTfLiteMmapRo)
        CorrectTensorEndianness(thisTensor);
    }
  }

  initialization_status_ = kTfLiteOk;
   d704c:	f884 7071 	strb.w	r7, [r4, #113]	; 0x71
}
   d7050:	4620      	mov	r0, r4
   d7052:	b002      	add	sp, #8
   d7054:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   d7058:	000eabbc 	.word	0x000eabbc
   d705c:	000d6f6f 	.word	0x000d6f6f

000d7060 <_ZN6tflite16MicroInterpreter6outputEj>:
    return nullptr;
  }
  return &(context_.tensors[inputs->Get(index)]);
}

TfLiteTensor* MicroInterpreter::output(size_t index) {
   d7060:	b538      	push	{r3, r4, r5, lr}
   d7062:	460d      	mov	r5, r1
   d7064:	4604      	mov	r4, r0
   d7066:	2108      	movs	r1, #8
   d7068:	6fc0      	ldr	r0, [r0, #124]	; 0x7c
   d706a:	f7ff ffa3 	bl	d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d706e:	6803      	ldr	r3, [r0, #0]
  const flatbuffers::Vector<int32_t>* outputs = subgraph_->outputs();
  const size_t length = outputs->size();
  if ((index < 0) || (index >= outputs->size())) {
   d7070:	42ab      	cmp	r3, r5
   d7072:	d806      	bhi.n	d7082 <_ZN6tflite16MicroInterpreter6outputEj+0x22>
    error_reporter_->Report("Output index %d out of range (length is %d)",
                            index, length);
   d7074:	462a      	mov	r2, r5
   d7076:	4907      	ldr	r1, [pc, #28]	; (d7094 <_ZN6tflite16MicroInterpreter6outputEj+0x34>)
   d7078:	68a0      	ldr	r0, [r4, #8]
   d707a:	f7fe fa37 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    return nullptr;
   d707e:	2000      	movs	r0, #0
   d7080:	bd38      	pop	{r3, r4, r5, pc}
  }
  return &(context_.tensors[outputs->Get(index)]);
   d7082:	4629      	mov	r1, r5
   d7084:	f7ff fc06 	bl	d6894 <_ZNK11flatbuffers6VectorIlE3GetEm>
   d7088:	6962      	ldr	r2, [r4, #20]
   d708a:	2338      	movs	r3, #56	; 0x38
   d708c:	fb03 2000 	mla	r0, r3, r0, r2
}
   d7090:	bd38      	pop	{r3, r4, r5, pc}
   d7092:	bf00      	nop
   d7094:	000eafa3 	.word	0x000eafa3

000d7098 <_ZN6tflite16MicroInterpreter5inputEj>:
    }
  }
  return status;
}

TfLiteTensor* MicroInterpreter::input(size_t index) {
   d7098:	b538      	push	{r3, r4, r5, lr}
   d709a:	460d      	mov	r5, r1
   d709c:	4604      	mov	r4, r0
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d709e:	2106      	movs	r1, #6
   d70a0:	6fc0      	ldr	r0, [r0, #124]	; 0x7c
   d70a2:	f7ff ff87 	bl	d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d70a6:	6803      	ldr	r3, [r0, #0]
  const flatbuffers::Vector<int32_t>* inputs = subgraph_->inputs();
  const size_t length = inputs->size();
  if ((index < 0) || (index >= length)) {
   d70a8:	429d      	cmp	r5, r3
   d70aa:	d306      	bcc.n	d70ba <_ZN6tflite16MicroInterpreter5inputEj+0x22>
    error_reporter_->Report("Input index %d out of range (length is %d)", index,
                            length);
   d70ac:	462a      	mov	r2, r5
   d70ae:	4907      	ldr	r1, [pc, #28]	; (d70cc <_ZN6tflite16MicroInterpreter5inputEj+0x34>)
   d70b0:	68a0      	ldr	r0, [r4, #8]
   d70b2:	f7fe fa1b 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    return nullptr;
   d70b6:	2000      	movs	r0, #0
   d70b8:	bd38      	pop	{r3, r4, r5, pc}
  }
  return &(context_.tensors[inputs->Get(index)]);
   d70ba:	4629      	mov	r1, r5
   d70bc:	f7ff fbea 	bl	d6894 <_ZNK11flatbuffers6VectorIlE3GetEm>
   d70c0:	6962      	ldr	r2, [r4, #20]
   d70c2:	2338      	movs	r3, #56	; 0x38
   d70c4:	fb03 2000 	mla	r0, r3, r0, r2
}
   d70c8:	bd38      	pop	{r3, r4, r5, pc}
   d70ca:	bf00      	nop
   d70cc:	000eafcf 	.word	0x000eafcf

000d70d0 <_ZN6tflite16MicroInterpreter6InvokeEv>:
  TF_LITE_ENSURE_OK(&context_, status);
  tensors_allocated_ = true;
  return kTfLiteOk;
}

TfLiteStatus MicroInterpreter::Invoke() {
   d70d0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  if (initialization_status_ != kTfLiteOk) {
   d70d4:	f890 5071 	ldrb.w	r5, [r0, #113]	; 0x71
  TF_LITE_ENSURE_OK(&context_, status);
  tensors_allocated_ = true;
  return kTfLiteOk;
}

TfLiteStatus MicroInterpreter::Invoke() {
   d70d8:	b0c5      	sub	sp, #276	; 0x114
   d70da:	4604      	mov	r4, r0
  if (initialization_status_ != kTfLiteOk) {
   d70dc:	b125      	cbz	r5, d70e8 <_ZN6tflite16MicroInterpreter6InvokeEv+0x18>
    error_reporter_->Report("Invoke() called after initialization failed\n");
   d70de:	4976      	ldr	r1, [pc, #472]	; (d72b8 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1e8>)
   d70e0:	6880      	ldr	r0, [r0, #8]
   d70e2:	f7fe fa03 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
   d70e6:	e0a2      	b.n	d722e <_ZN6tflite16MicroInterpreter6InvokeEv+0x15e>
    return kTfLiteError;
  }

  // Ensure tensors are allocated before the interpreter is invoked to avoid
  // difficult to debug segfaults.
  if (!tensors_allocated_) {
   d70e8:	f890 3070 	ldrb.w	r3, [r0, #112]	; 0x70
   d70ec:	b90b      	cbnz	r3, d70f2 <_ZN6tflite16MicroInterpreter6InvokeEv+0x22>
    AllocateTensors();
   d70ee:	f7ff ff55 	bl	d6f9c <_ZN6tflite16MicroInterpreter15AllocateTensorsEv>
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d70f2:	2106      	movs	r1, #6
   d70f4:	6820      	ldr	r0, [r4, #0]
   d70f6:	f7ff ff5d 	bl	d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>
  }
  TfLiteStatus status = kTfLiteOk;
  auto opcodes = model_->operator_codes();
  for (size_t i = 0; i < operators_->size(); ++i) {
   d70fa:	2600      	movs	r6, #0
    return const_cast<mutable_return_type>(IndirectHelper<T>::Read(Data(), i));
  }

  // The raw data in little endian format. Use with care.
  const uint8_t *Data() const {
    return reinterpret_cast<const uint8_t *>(&length_ + 1);
   d70fc:	1d03      	adds	r3, r0, #4
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d70fe:	4683      	mov	fp, r0
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
    auto field_offset = GetOptionalFieldOffset(field);
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d7100:	46b2      	mov	sl, r6
    return const_cast<mutable_return_type>(IndirectHelper<T>::Read(Data(), i));
  }

  // The raw data in little endian format. Use with care.
  const uint8_t *Data() const {
    return reinterpret_cast<const uint8_t *>(&length_ + 1);
   d7102:	9304      	str	r3, [sp, #16]
   d7104:	6fa3      	ldr	r3, [r4, #120]	; 0x78
   d7106:	681a      	ldr	r2, [r3, #0]
   d7108:	4296      	cmp	r6, r2
   d710a:	f080 80d1 	bcs.w	d72b0 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1e0>
   d710e:	3304      	adds	r3, #4
template<typename T> struct IndirectHelper<Offset<T>> {
  typedef const T *return_type;
  typedef T *mutable_return_type;
  static const size_t element_stride = sizeof(uoffset_t);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    p += i * sizeof(uoffset_t);
   d7110:	eb03 0286 	add.w	r2, r3, r6, lsl #2
    return reinterpret_cast<return_type>(p + ReadScalar<uoffset_t>(p));
   d7114:	f853 3026 	ldr.w	r3, [r3, r6, lsl #2]
   d7118:	18d7      	adds	r7, r2, r3
// "tables" use an offset table (possibly shared) that allows fields to be
// omitted and added at will, but uses an extra indirection to read.
class Table {
 public:
  const uint8_t *GetVTable() const {
    return data_ - ReadScalar<soffset_t>(data_);
   d711a:	58d3      	ldr	r3, [r2, r3]
   d711c:	1afb      	subs	r3, r7, r3
    auto vtable = GetVTable();
    // The first element is the size of the vtable (fields + type id + itself).
    auto vtsize = ReadScalar<voffset_t>(vtable);
    // If the field we're accessing is outside the vtable, we're reading older
    // data, so it's the same as if the offset was 0 (not present).
    return field < vtsize ? ReadScalar<voffset_t>(vtable + field) : 0;
   d711e:	881a      	ldrh	r2, [r3, #0]
   d7120:	2a04      	cmp	r2, #4
   d7122:	d904      	bls.n	d712e <_ZN6tflite16MicroInterpreter6InvokeEv+0x5e>
   d7124:	889b      	ldrh	r3, [r3, #4]
  }

  template<typename T> T GetField(voffset_t field, T defaultval) const {
    auto field_offset = GetOptionalFieldOffset(field);
    return field_offset ? ReadScalar<T>(data_ + field_offset) : defaultval;
   d7126:	b12b      	cbz	r3, d7134 <_ZN6tflite16MicroInterpreter6InvokeEv+0x64>
   d7128:	f857 8003 	ldr.w	r8, [r7, r3]
   d712c:	e003      	b.n	d7136 <_ZN6tflite16MicroInterpreter6InvokeEv+0x66>
   d712e:	f04f 0800 	mov.w	r8, #0
   d7132:	e000      	b.n	d7136 <_ZN6tflite16MicroInterpreter6InvokeEv+0x66>
   d7134:	4698      	mov	r8, r3
    const auto* op = operators_->Get(i);
    size_t index = op->opcode_index();
    if (index < 0 || index >= opcodes->size()) {
   d7136:	f8db 3000 	ldr.w	r3, [fp]
   d713a:	4543      	cmp	r3, r8
   d713c:	d802      	bhi.n	d7144 <_ZN6tflite16MicroInterpreter6InvokeEv+0x74>
      error_reporter_->Report("Missing registration for opcode_index %d\n",
                              index);
   d713e:	4642      	mov	r2, r8
   d7140:	495e      	ldr	r1, [pc, #376]	; (d72bc <_ZN6tflite16MicroInterpreter6InvokeEv+0x1ec>)
   d7142:	e025      	b.n	d7190 <_ZN6tflite16MicroInterpreter6InvokeEv+0xc0>
template<typename T> struct IndirectHelper<Offset<T>> {
  typedef const T *return_type;
  typedef T *mutable_return_type;
  static const size_t element_stride = sizeof(uoffset_t);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    p += i * sizeof(uoffset_t);
   d7144:	9b04      	ldr	r3, [sp, #16]
      return kTfLiteError;
    }
    auto opcode = (*opcodes)[index];
    const TfLiteRegistration* registration = nullptr;
    status = GetRegistrationFromOpCode(opcode, op_resolver_, error_reporter_,
                                       &registration);
   d7146:	68a2      	ldr	r2, [r4, #8]
    return reinterpret_cast<return_type>(p + ReadScalar<uoffset_t>(p));
   d7148:	f853 e028 	ldr.w	lr, [r3, r8, lsl #2]
   d714c:	6861      	ldr	r1, [r4, #4]
template<typename T> struct IndirectHelper<Offset<T>> {
  typedef const T *return_type;
  typedef T *mutable_return_type;
  static const size_t element_stride = sizeof(uoffset_t);
  static return_type Read(const uint8_t *p, uoffset_t i) {
    p += i * sizeof(uoffset_t);
   d714e:	eb03 0088 	add.w	r0, r3, r8, lsl #2
      error_reporter_->Report("Missing registration for opcode_index %d\n",
                              index);
      return kTfLiteError;
    }
    auto opcode = (*opcodes)[index];
    const TfLiteRegistration* registration = nullptr;
   d7152:	ab44      	add	r3, sp, #272	; 0x110
    status = GetRegistrationFromOpCode(opcode, op_resolver_, error_reporter_,
                                       &registration);
   d7154:	4470      	add	r0, lr
      error_reporter_->Report("Missing registration for opcode_index %d\n",
                              index);
      return kTfLiteError;
    }
    auto opcode = (*opcodes)[index];
    const TfLiteRegistration* registration = nullptr;
   d7156:	f843 adf4 	str.w	sl, [r3, #-244]!
    status = GetRegistrationFromOpCode(opcode, op_resolver_, error_reporter_,
                                       &registration);
   d715a:	f7ff f9d3 	bl	d6504 <_ZN6tflite25GetRegistrationFromOpCodeEPKNS_12OperatorCodeERKNS_10OpResolverEPNS_13ErrorReporterEPPK18TfLiteRegistration>
    if (status != kTfLiteOk) {
   d715e:	2800      	cmp	r0, #0
   d7160:	d167      	bne.n	d7232 <_ZN6tflite16MicroInterpreter6InvokeEv+0x162>
      return status;
    }
    if (registration == nullptr) {
   d7162:	9b07      	ldr	r3, [sp, #28]
   d7164:	b913      	cbnz	r3, d716c <_ZN6tflite16MicroInterpreter6InvokeEv+0x9c>
      error_reporter_->Report("Skipping op for opcode_index %d\n", index);
   d7166:	4642      	mov	r2, r8
   d7168:	4955      	ldr	r1, [pc, #340]	; (d72c0 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1f0>)
   d716a:	e011      	b.n	d7190 <_ZN6tflite16MicroInterpreter6InvokeEv+0xc0>
      return kTfLiteError;
    }
    BuiltinOperator op_type =
        static_cast<BuiltinOperator>(registration->builtin_code);
   d716c:	f893 8014 	ldrb.w	r8, [r3, #20]

    if (op_type != BuiltinOperator_CUSTOM && op->custom_options()) {
   d7170:	f1b8 0f20 	cmp.w	r8, #32
   d7174:	d010      	beq.n	d7198 <_ZN6tflite16MicroInterpreter6InvokeEv+0xc8>
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d7176:	210e      	movs	r1, #14
   d7178:	4638      	mov	r0, r7
   d717a:	f7ff ff1b 	bl	d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>
   d717e:	b158      	cbz	r0, d7198 <_ZN6tflite16MicroInterpreter6InvokeEv+0xc8>
  };
  return names;
}

inline const char *EnumNameBuiltinOperator(BuiltinOperator e) {
  if (e < BuiltinOperator_ADD || e > BuiltinOperator_NON_MAX_SUPPRESSION_V5) return "";
   d7180:	f1b8 0f79 	cmp.w	r8, #121	; 0x79
   d7184:	f200 8092 	bhi.w	d72ac <_ZN6tflite16MicroInterpreter6InvokeEv+0x1dc>
  const size_t index = static_cast<size_t>(e);
  return EnumNamesBuiltinOperator()[index];
   d7188:	4b4e      	ldr	r3, [pc, #312]	; (d72c4 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1f4>)
   d718a:	f853 2028 	ldr.w	r2, [r3, r8, lsl #2]
      error_reporter_->Report(
          "Unsupported behavior: found builtin operator %s with custom "
          "options.\n",
          EnumNameBuiltinOperator(op_type));
   d718e:	494e      	ldr	r1, [pc, #312]	; (d72c8 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1f8>)
   d7190:	68a0      	ldr	r0, [r4, #8]
   d7192:	f7fe f9ab 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
   d7196:	e04a      	b.n	d722e <_ZN6tflite16MicroInterpreter6InvokeEv+0x15e>
#include "tensorflow/lite/experimental/micro/compatibility.h"

namespace tflite {
namespace {
const int kStackDataAllocatorSize = 128;
class StackDataAllocator : public BuiltinDataAllocator {
   d7198:	4b4c      	ldr	r3, [pc, #304]	; (d72cc <_ZN6tflite16MicroInterpreter6InvokeEv+0x1fc>)
   d719a:	9323      	str	r3, [sp, #140]	; 0x8c
   d719c:	210e      	movs	r1, #14
   d719e:	4638      	mov	r0, r7
      return kTfLiteError;
    }
    StackDataAllocator stack_data_allocator;
    const char* custom_data = nullptr;
    size_t custom_data_size = 0;
    unsigned char* builtin_data = nullptr;
   d71a0:	f8cd a020 	str.w	sl, [sp, #32]
   d71a4:	f7ff ff06 	bl	d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>
    if (op->custom_options()) {
   d71a8:	2800      	cmp	r0, #0
   d71aa:	d044      	beq.n	d7236 <_ZN6tflite16MicroInterpreter6InvokeEv+0x166>
    return const_cast<mutable_return_type>(IndirectHelper<T>::Read(Data(), i));
  }

  // The raw data in little endian format. Use with care.
  const uint8_t *Data() const {
    return reinterpret_cast<const uint8_t *>(&length_ + 1);
   d71ac:	1d03      	adds	r3, r0, #4
  typedef VectorIterator<T, typename IndirectHelper<T>::return_type>
      const_iterator;
  typedef VectorReverseIterator<iterator> reverse_iterator;
  typedef VectorReverseIterator<const_iterator> const_reverse_iterator;

  uoffset_t size() const { return EndianScalar(length_); }
   d71ae:	f8d0 9000 	ldr.w	r9, [r0]
    return const_cast<mutable_return_type>(IndirectHelper<T>::Read(Data(), i));
  }

  // The raw data in little endian format. Use with care.
  const uint8_t *Data() const {
    return reinterpret_cast<const uint8_t *>(&length_ + 1);
   d71b2:	9303      	str	r3, [sp, #12]
                                        (void**)(&builtin_data)));
    }

    const char* init_data;
    size_t init_data_size;
    if (registration->builtin_code == BuiltinOperator_CUSTOM) {
   d71b4:	9807      	ldr	r0, [sp, #28]
   d71b6:	6942      	ldr	r2, [r0, #20]
    } else {
      init_data = reinterpret_cast<const char*>(builtin_data);
      init_data_size = 0;
    }
    void* user_data = nullptr;
    if (registration->init) {
   d71b8:	6803      	ldr	r3, [r0, #0]
                                        (void**)(&builtin_data)));
    }

    const char* init_data;
    size_t init_data_size;
    if (registration->builtin_code == BuiltinOperator_CUSTOM) {
   d71ba:	2a20      	cmp	r2, #32
      init_data = custom_data;
      init_data_size = custom_data_size;
    } else {
      init_data = reinterpret_cast<const char*>(builtin_data);
   d71bc:	bf15      	itete	ne
   d71be:	9908      	ldrne	r1, [sp, #32]
    }

    const char* init_data;
    size_t init_data_size;
    if (registration->builtin_code == BuiltinOperator_CUSTOM) {
      init_data = custom_data;
   d71c0:	9903      	ldreq	r1, [sp, #12]
      init_data_size = custom_data_size;
    } else {
      init_data = reinterpret_cast<const char*>(builtin_data);
      init_data_size = 0;
   d71c2:	2200      	movne	r2, #0

    const char* init_data;
    size_t init_data_size;
    if (registration->builtin_code == BuiltinOperator_CUSTOM) {
      init_data = custom_data;
      init_data_size = custom_data_size;
   d71c4:	464a      	moveq	r2, r9
    } else {
      init_data = reinterpret_cast<const char*>(builtin_data);
      init_data_size = 0;
    }
    void* user_data = nullptr;
    if (registration->init) {
   d71c6:	2b00      	cmp	r3, #0
   d71c8:	d042      	beq.n	d7250 <_ZN6tflite16MicroInterpreter6InvokeEv+0x180>
      user_data = registration->init(&context_, init_data, init_data_size);
   d71ca:	f104 000c 	add.w	r0, r4, #12
   d71ce:	4798      	blx	r3
   d71d0:	4680      	mov	r8, r0
    auto p = data_ + field_offset;
    return field_offset ? reinterpret_cast<P>(p + ReadScalar<uoffset_t>(p))
                        : nullptr;
  }
  template<typename P> P GetPointer(voffset_t field) const {
    return const_cast<Table *>(this)->GetPointer<P>(field);
   d71d2:	2106      	movs	r1, #6
   d71d4:	4638      	mov	r0, r7
   d71d6:	f7ff feed 	bl	d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>
   d71da:	2108      	movs	r1, #8
   d71dc:	9005      	str	r0, [sp, #20]
   d71de:	4638      	mov	r0, r7
   d71e0:	f7ff fee8 	bl	d6fb4 <_ZN11flatbuffers5Table10GetPointerIPKNS_6VectorINS_6OffsetIN6tflite8SubGraphEEEEEEET_t>
    TfLiteIntArray* temporaries_array =
        reinterpret_cast<TfLiteIntArray*>(temporaries_data);
    temporaries_array->size = 0;

    TfLiteNode node;
    node.inputs = inputs_array;
   d71e4:	9a05      	ldr	r2, [sp, #20]
    node.outputs = outputs_array;
    node.temporaries = temporaries_array;
    node.user_data = user_data;
    node.builtin_data = reinterpret_cast<void*>(builtin_data);
    node.custom_initial_data = custom_data;
   d71e6:	9b03      	ldr	r3, [sp, #12]
    TfLiteIntArray* temporaries_array =
        reinterpret_cast<TfLiteIntArray*>(temporaries_data);
    temporaries_array->size = 0;

    TfLiteNode node;
    node.inputs = inputs_array;
   d71e8:	9209      	str	r2, [sp, #36]	; 0x24
    node.outputs = outputs_array;
    node.temporaries = temporaries_array;
   d71ea:	aa12      	add	r2, sp, #72	; 0x48
   d71ec:	920c      	str	r2, [sp, #48]	; 0x30
    node.user_data = user_data;
    node.builtin_data = reinterpret_cast<void*>(builtin_data);
    node.custom_initial_data = custom_data;
   d71ee:	930f      	str	r3, [sp, #60]	; 0x3c
    TfLiteNode node;
    node.inputs = inputs_array;
    node.outputs = outputs_array;
    node.temporaries = temporaries_array;
    node.user_data = user_data;
    node.builtin_data = reinterpret_cast<void*>(builtin_data);
   d71f0:	9a08      	ldr	r2, [sp, #32]
    node.custom_initial_data = custom_data;
    node.custom_initial_data_size = custom_data_size;
    node.delegate = nullptr;
    if (registration->prepare) {
   d71f2:	9b07      	ldr	r3, [sp, #28]

    TfLiteNode node;
    node.inputs = inputs_array;
    node.outputs = outputs_array;
    node.temporaries = temporaries_array;
    node.user_data = user_data;
   d71f4:	f8cd 8034 	str.w	r8, [sp, #52]	; 0x34
    node.builtin_data = reinterpret_cast<void*>(builtin_data);
   d71f8:	920e      	str	r2, [sp, #56]	; 0x38
    node.custom_initial_data = custom_data;
    node.custom_initial_data_size = custom_data_size;
   d71fa:	f8cd 9040 	str.w	r9, [sp, #64]	; 0x40
    node.delegate = nullptr;
   d71fe:	f8cd a044 	str.w	sl, [sp, #68]	; 0x44
    if (registration->prepare) {
   d7202:	689b      	ldr	r3, [r3, #8]

    const int kMaxTemporaries = 16;
    int temporaries_data[kMaxTemporaries + 1];
    TfLiteIntArray* temporaries_array =
        reinterpret_cast<TfLiteIntArray*>(temporaries_data);
    temporaries_array->size = 0;
   d7204:	f8cd a048 	str.w	sl, [sp, #72]	; 0x48

    TfLiteNode node;
    node.inputs = inputs_array;
    node.outputs = outputs_array;
   d7208:	900a      	str	r0, [sp, #40]	; 0x28
    node.user_data = user_data;
    node.builtin_data = reinterpret_cast<void*>(builtin_data);
    node.custom_initial_data = custom_data;
    node.custom_initial_data_size = custom_data_size;
    node.delegate = nullptr;
    if (registration->prepare) {
   d720a:	b35b      	cbz	r3, d7264 <_ZN6tflite16MicroInterpreter6InvokeEv+0x194>
      TfLiteStatus prepare_status = registration->prepare(&context_, &node);
   d720c:	a909      	add	r1, sp, #36	; 0x24
   d720e:	f104 000c 	add.w	r0, r4, #12
   d7212:	4798      	blx	r3
      if (prepare_status != kTfLiteOk) {
   d7214:	4601      	mov	r1, r0
   d7216:	b328      	cbz	r0, d7264 <_ZN6tflite16MicroInterpreter6InvokeEv+0x194>
        error_reporter_->Report(
   d7218:	9a07      	ldr	r2, [sp, #28]
   d721a:	68a0      	ldr	r0, [r4, #8]

  TF_LITE_REMOVE_VIRTUAL_DELETE
};

const char* OpNameFromRegistration(const TfLiteRegistration* registration) {
  if (registration->builtin_code == BuiltinOperator_CUSTOM) {
   d721c:	6953      	ldr	r3, [r2, #20]
   d721e:	2b20      	cmp	r3, #32
   d7220:	d118      	bne.n	d7254 <_ZN6tflite16MicroInterpreter6InvokeEv+0x184>
    return registration->custom_name;
   d7222:	6992      	ldr	r2, [r2, #24]
    if (registration->prepare) {
      TfLiteStatus prepare_status = registration->prepare(&context_, &node);
      if (prepare_status != kTfLiteOk) {
        error_reporter_->Report(
            "Node %s (number %d) failed to prepare with status %d",
            OpNameFromRegistration(registration), i, prepare_status);
   d7224:	9100      	str	r1, [sp, #0]
   d7226:	492a      	ldr	r1, [pc, #168]	; (d72d0 <_ZN6tflite16MicroInterpreter6InvokeEv+0x200>)
   d7228:	4633      	mov	r3, r6
    if (registration->invoke) {
      TfLiteStatus invoke_status = registration->invoke(&context_, &node);
      if (invoke_status != kTfLiteOk) {
        error_reporter_->Report(
            "Node %s (number %d) failed to invoke with status %d",
            OpNameFromRegistration(registration), i, invoke_status);
   d722a:	f7fe f95f 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    if (op_type != BuiltinOperator_CUSTOM && op->custom_options()) {
      error_reporter_->Report(
          "Unsupported behavior: found builtin operator %s with custom "
          "options.\n",
          EnumNameBuiltinOperator(op_type));
      return kTfLiteError;
   d722e:	2501      	movs	r5, #1
   d7230:	e03e      	b.n	d72b0 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1e0>
      return kTfLiteError;
    }
    auto opcode = (*opcodes)[index];
    const TfLiteRegistration* registration = nullptr;
    status = GetRegistrationFromOpCode(opcode, op_resolver_, error_reporter_,
                                       &registration);
   d7232:	4605      	mov	r5, r0
   d7234:	e03c      	b.n	d72b0 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1e0>
    unsigned char* builtin_data = nullptr;
    if (op->custom_options()) {
      custom_data = reinterpret_cast<const char*>(op->custom_options()->data());
      custom_data_size = op->custom_options()->size();
    } else {
      TF_LITE_ENSURE_STATUS(ParseOpData(op, op_type, error_reporter_,
   d7236:	ab08      	add	r3, sp, #32
   d7238:	9300      	str	r3, [sp, #0]
   d723a:	68a2      	ldr	r2, [r4, #8]
   d723c:	ab23      	add	r3, sp, #140	; 0x8c
   d723e:	4641      	mov	r1, r8
   d7240:	4638      	mov	r0, r7
   d7242:	f7fe fa3f 	bl	d56c4 <_ZN6tflite11ParseOpDataEPKNS_8OperatorENS_15BuiltinOperatorEPNS_13ErrorReporterEPNS_20BuiltinDataAllocatorEPPv>
   d7246:	2800      	cmp	r0, #0
   d7248:	d1f1      	bne.n	d722e <_ZN6tflite16MicroInterpreter6InvokeEv+0x15e>
          EnumNameBuiltinOperator(op_type));
      return kTfLiteError;
    }
    StackDataAllocator stack_data_allocator;
    const char* custom_data = nullptr;
    size_t custom_data_size = 0;
   d724a:	4681      	mov	r9, r0
          "options.\n",
          EnumNameBuiltinOperator(op_type));
      return kTfLiteError;
    }
    StackDataAllocator stack_data_allocator;
    const char* custom_data = nullptr;
   d724c:	9003      	str	r0, [sp, #12]
   d724e:	e7b1      	b.n	d71b4 <_ZN6tflite16MicroInterpreter6InvokeEv+0xe4>
      init_data_size = custom_data_size;
    } else {
      init_data = reinterpret_cast<const char*>(builtin_data);
      init_data_size = 0;
    }
    void* user_data = nullptr;
   d7250:	4698      	mov	r8, r3
   d7252:	e7be      	b.n	d71d2 <_ZN6tflite16MicroInterpreter6InvokeEv+0x102>
  };
  return names;
}

inline const char *EnumNameBuiltinOperator(BuiltinOperator e) {
  if (e < BuiltinOperator_ADD || e > BuiltinOperator_NON_MAX_SUPPRESSION_V5) return "";
   d7254:	b2db      	uxtb	r3, r3
   d7256:	2b79      	cmp	r3, #121	; 0x79
  const size_t index = static_cast<size_t>(e);
  return EnumNamesBuiltinOperator()[index];
   d7258:	bf96      	itet	ls
   d725a:	4a1a      	ldrls	r2, [pc, #104]	; (d72c4 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1f4>)
  };
  return names;
}

inline const char *EnumNameBuiltinOperator(BuiltinOperator e) {
  if (e < BuiltinOperator_ADD || e > BuiltinOperator_NON_MAX_SUPPRESSION_V5) return "";
   d725c:	4a1d      	ldrhi	r2, [pc, #116]	; (d72d4 <_ZN6tflite16MicroInterpreter6InvokeEv+0x204>)
  const size_t index = static_cast<size_t>(e);
  return EnumNamesBuiltinOperator()[index];
   d725e:	f852 2023 	ldrls.w	r2, [r2, r3, lsl #2]
   d7262:	e7df      	b.n	d7224 <_ZN6tflite16MicroInterpreter6InvokeEv+0x154>
            OpNameFromRegistration(registration), i, prepare_status);
        return kTfLiteError;
      }
    }

    if (registration->invoke) {
   d7264:	9b07      	ldr	r3, [sp, #28]
   d7266:	68db      	ldr	r3, [r3, #12]
   d7268:	b1bb      	cbz	r3, d729a <_ZN6tflite16MicroInterpreter6InvokeEv+0x1ca>
      TfLiteStatus invoke_status = registration->invoke(&context_, &node);
   d726a:	a909      	add	r1, sp, #36	; 0x24
   d726c:	f104 000c 	add.w	r0, r4, #12
   d7270:	4798      	blx	r3
      if (invoke_status != kTfLiteOk) {
   d7272:	4601      	mov	r1, r0
   d7274:	b188      	cbz	r0, d729a <_ZN6tflite16MicroInterpreter6InvokeEv+0x1ca>
        error_reporter_->Report(
   d7276:	9a07      	ldr	r2, [sp, #28]
   d7278:	68a0      	ldr	r0, [r4, #8]

  TF_LITE_REMOVE_VIRTUAL_DELETE
};

const char* OpNameFromRegistration(const TfLiteRegistration* registration) {
  if (registration->builtin_code == BuiltinOperator_CUSTOM) {
   d727a:	6953      	ldr	r3, [r2, #20]
   d727c:	2b20      	cmp	r3, #32
   d727e:	d101      	bne.n	d7284 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1b4>
    return registration->custom_name;
   d7280:	6992      	ldr	r2, [r2, #24]
   d7282:	e006      	b.n	d7292 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1c2>
  };
  return names;
}

inline const char *EnumNameBuiltinOperator(BuiltinOperator e) {
  if (e < BuiltinOperator_ADD || e > BuiltinOperator_NON_MAX_SUPPRESSION_V5) return "";
   d7284:	b2db      	uxtb	r3, r3
   d7286:	2b79      	cmp	r3, #121	; 0x79
  const size_t index = static_cast<size_t>(e);
  return EnumNamesBuiltinOperator()[index];
   d7288:	bf96      	itet	ls
   d728a:	4a0e      	ldrls	r2, [pc, #56]	; (d72c4 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1f4>)
  };
  return names;
}

inline const char *EnumNameBuiltinOperator(BuiltinOperator e) {
  if (e < BuiltinOperator_ADD || e > BuiltinOperator_NON_MAX_SUPPRESSION_V5) return "";
   d728c:	4a11      	ldrhi	r2, [pc, #68]	; (d72d4 <_ZN6tflite16MicroInterpreter6InvokeEv+0x204>)
  const size_t index = static_cast<size_t>(e);
  return EnumNamesBuiltinOperator()[index];
   d728e:	f852 2023 	ldrls.w	r2, [r2, r3, lsl #2]
    if (registration->invoke) {
      TfLiteStatus invoke_status = registration->invoke(&context_, &node);
      if (invoke_status != kTfLiteOk) {
        error_reporter_->Report(
            "Node %s (number %d) failed to invoke with status %d",
            OpNameFromRegistration(registration), i, invoke_status);
   d7292:	9100      	str	r1, [sp, #0]
   d7294:	4633      	mov	r3, r6
   d7296:	4910      	ldr	r1, [pc, #64]	; (d72d8 <_ZN6tflite16MicroInterpreter6InvokeEv+0x208>)
   d7298:	e7c7      	b.n	d722a <_ZN6tflite16MicroInterpreter6InvokeEv+0x15a>
        return kTfLiteError;
      }
    }

    if (registration->free) {
   d729a:	9b07      	ldr	r3, [sp, #28]
   d729c:	685b      	ldr	r3, [r3, #4]
   d729e:	b11b      	cbz	r3, d72a8 <_ZN6tflite16MicroInterpreter6InvokeEv+0x1d8>
      registration->free(&context_, user_data);
   d72a0:	4641      	mov	r1, r8
   d72a2:	f104 000c 	add.w	r0, r4, #12
   d72a6:	4798      	blx	r3
  if (!tensors_allocated_) {
    AllocateTensors();
  }
  TfLiteStatus status = kTfLiteOk;
  auto opcodes = model_->operator_codes();
  for (size_t i = 0; i < operators_->size(); ++i) {
   d72a8:	3601      	adds	r6, #1
   d72aa:	e72b      	b.n	d7104 <_ZN6tflite16MicroInterpreter6InvokeEv+0x34>
  };
  return names;
}

inline const char *EnumNameBuiltinOperator(BuiltinOperator e) {
  if (e < BuiltinOperator_ADD || e > BuiltinOperator_NON_MAX_SUPPRESSION_V5) return "";
   d72ac:	4a09      	ldr	r2, [pc, #36]	; (d72d4 <_ZN6tflite16MicroInterpreter6InvokeEv+0x204>)
   d72ae:	e76e      	b.n	d718e <_ZN6tflite16MicroInterpreter6InvokeEv+0xbe>
    if (registration->free) {
      registration->free(&context_, user_data);
    }
  }
  return status;
}
   d72b0:	4628      	mov	r0, r5
   d72b2:	b045      	add	sp, #276	; 0x114
   d72b4:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   d72b8:	000eaffa 	.word	0x000eaffa
   d72bc:	000eb027 	.word	0x000eb027
   d72c0:	000eb051 	.word	0x000eb051
   d72c4:	000ea17c 	.word	0x000ea17c
   d72c8:	000eb072 	.word	0x000eb072
   d72cc:	000eb12c 	.word	0x000eb12c
   d72d0:	000eb0b8 	.word	0x000eb0b8
   d72d4:	000eaf76 	.word	0x000eaf76
   d72d8:	000eb0ed 	.word	0x000eb0ed

000d72dc <_ZNK6tflite22MicroMutableOpResolver6FindOpENS_15BuiltinOperatorEi>:
#include "tensorflow/lite/experimental/micro/micro_mutable_op_resolver.h"

namespace tflite {

const TfLiteRegistration* MicroMutableOpResolver::FindOp(
    tflite::BuiltinOperator op, int version) const {
   d72dc:	b570      	push	{r4, r5, r6, lr}
  for (int i = 0; i < registrations_len_; ++i) {
   d72de:	f241 0304 	movw	r3, #4100	; 0x1004
   d72e2:	2400      	movs	r4, #0
   d72e4:	58c5      	ldr	r5, [r0, r3]
   d72e6:	4603      	mov	r3, r0
   d72e8:	42ac      	cmp	r4, r5
   d72ea:	da0c      	bge.n	d7306 <_ZNK6tflite22MicroMutableOpResolver6FindOpENS_15BuiltinOperatorEi+0x2a>
    const TfLiteRegistration& registration = registrations_[i];
    if ((registration.builtin_code == op) &&
   d72ec:	699e      	ldr	r6, [r3, #24]
   d72ee:	428e      	cmp	r6, r1
   d72f0:	d106      	bne.n	d7300 <_ZNK6tflite22MicroMutableOpResolver6FindOpENS_15BuiltinOperatorEi+0x24>
   d72f2:	6a1e      	ldr	r6, [r3, #32]
   d72f4:	4296      	cmp	r6, r2
   d72f6:	d103      	bne.n	d7300 <_ZNK6tflite22MicroMutableOpResolver6FindOpENS_15BuiltinOperatorEi+0x24>
namespace tflite {

const TfLiteRegistration* MicroMutableOpResolver::FindOp(
    tflite::BuiltinOperator op, int version) const {
  for (int i = 0; i < registrations_len_; ++i) {
    const TfLiteRegistration& registration = registrations_[i];
   d72f8:	eb00 1044 	add.w	r0, r0, r4, lsl #5
   d72fc:	3004      	adds	r0, #4
   d72fe:	bd70      	pop	{r4, r5, r6, pc}

namespace tflite {

const TfLiteRegistration* MicroMutableOpResolver::FindOp(
    tflite::BuiltinOperator op, int version) const {
  for (int i = 0; i < registrations_len_; ++i) {
   d7300:	3401      	adds	r4, #1
   d7302:	3320      	adds	r3, #32
   d7304:	e7f0      	b.n	d72e8 <_ZNK6tflite22MicroMutableOpResolver6FindOpENS_15BuiltinOperatorEi+0xc>
    if ((registration.builtin_code == op) &&
        (registration.version == version)) {
      return &registration;
    }
  }
  return nullptr;
   d7306:	2000      	movs	r0, #0
}
   d7308:	bd70      	pop	{r4, r5, r6, pc}

000d730a <_ZNK6tflite22MicroMutableOpResolver6FindOpEPKci>:

const TfLiteRegistration* MicroMutableOpResolver::FindOp(const char* op,
                                                         int version) const {
   d730a:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
  for (int i = 0; i < registrations_len_; ++i) {
   d730e:	f241 0304 	movw	r3, #4100	; 0x1004
  }
  return nullptr;
}

const TfLiteRegistration* MicroMutableOpResolver::FindOp(const char* op,
                                                         int version) const {
   d7312:	4604      	mov	r4, r0
  for (int i = 0; i < registrations_len_; ++i) {
   d7314:	58c7      	ldr	r7, [r0, r3]
  }
  return nullptr;
}

const TfLiteRegistration* MicroMutableOpResolver::FindOp(const char* op,
                                                         int version) const {
   d7316:	4688      	mov	r8, r1
   d7318:	4691      	mov	r9, r2
   d731a:	4605      	mov	r5, r0
  for (int i = 0; i < registrations_len_; ++i) {
   d731c:	2600      	movs	r6, #0
   d731e:	42be      	cmp	r6, r7
   d7320:	da12      	bge.n	d7348 <_ZNK6tflite22MicroMutableOpResolver6FindOpEPKci+0x3e>
    const TfLiteRegistration& registration = registrations_[i];
    if ((registration.builtin_code == BuiltinOperator_CUSTOM) &&
   d7322:	69ab      	ldr	r3, [r5, #24]
   d7324:	2b20      	cmp	r3, #32
   d7326:	d10c      	bne.n	d7342 <_ZNK6tflite22MicroMutableOpResolver6FindOpEPKci+0x38>
        (strcmp(registration.custom_name, op) == 0) &&
   d7328:	4641      	mov	r1, r8
   d732a:	69e8      	ldr	r0, [r5, #28]
   d732c:	f011 fc54 	bl	e8bd8 <strcmp>

const TfLiteRegistration* MicroMutableOpResolver::FindOp(const char* op,
                                                         int version) const {
  for (int i = 0; i < registrations_len_; ++i) {
    const TfLiteRegistration& registration = registrations_[i];
    if ((registration.builtin_code == BuiltinOperator_CUSTOM) &&
   d7330:	b938      	cbnz	r0, d7342 <_ZNK6tflite22MicroMutableOpResolver6FindOpEPKci+0x38>
        (strcmp(registration.custom_name, op) == 0) &&
   d7332:	6a2b      	ldr	r3, [r5, #32]
   d7334:	454b      	cmp	r3, r9
   d7336:	d104      	bne.n	d7342 <_ZNK6tflite22MicroMutableOpResolver6FindOpEPKci+0x38>
}

const TfLiteRegistration* MicroMutableOpResolver::FindOp(const char* op,
                                                         int version) const {
  for (int i = 0; i < registrations_len_; ++i) {
    const TfLiteRegistration& registration = registrations_[i];
   d7338:	eb04 1046 	add.w	r0, r4, r6, lsl #5
   d733c:	3004      	adds	r0, #4
   d733e:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
  return nullptr;
}

const TfLiteRegistration* MicroMutableOpResolver::FindOp(const char* op,
                                                         int version) const {
  for (int i = 0; i < registrations_len_; ++i) {
   d7342:	3601      	adds	r6, #1
   d7344:	3520      	adds	r5, #32
   d7346:	e7ea      	b.n	d731e <_ZNK6tflite22MicroMutableOpResolver6FindOpEPKci+0x14>
        (strcmp(registration.custom_name, op) == 0) &&
        (registration.version == version)) {
      return &registration;
    }
  }
  return nullptr;
   d7348:	2000      	movs	r0, #0
}
   d734a:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}

000d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>:

void MicroMutableOpResolver::AddBuiltin(tflite::BuiltinOperator op,
                                        TfLiteRegistration* registration,
                                        int min_version, int max_version) {
  for (int version = min_version; version <= max_version; ++version) {
    if (registrations_len_ >= TFLITE_REGISTRATIONS_MAX) {
   d734e:	f500 5c80 	add.w	ip, r0, #4096	; 0x1000
  return nullptr;
}

void MicroMutableOpResolver::AddBuiltin(tflite::BuiltinOperator op,
                                        TfLiteRegistration* registration,
                                        int min_version, int max_version) {
   d7352:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
  for (int version = min_version; version <= max_version; ++version) {
    if (registrations_len_ >= TFLITE_REGISTRATIONS_MAX) {
   d7356:	f10c 0c04 	add.w	ip, ip, #4
  return nullptr;
}

void MicroMutableOpResolver::AddBuiltin(tflite::BuiltinOperator op,
                                        TfLiteRegistration* registration,
                                        int min_version, int max_version) {
   d735a:	4680      	mov	r8, r0
   d735c:	4689      	mov	r9, r1
   d735e:	4692      	mov	sl, r2
   d7360:	461f      	mov	r7, r3
  for (int version = min_version; version <= max_version; ++version) {
   d7362:	9b08      	ldr	r3, [sp, #32]
   d7364:	429f      	cmp	r7, r3
   d7366:	dc15      	bgt.n	d7394 <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii+0x46>
    if (registrations_len_ >= TFLITE_REGISTRATIONS_MAX) {
   d7368:	f8dc 6000 	ldr.w	r6, [ip]
   d736c:	2e7f      	cmp	r6, #127	; 0x7f
   d736e:	dc11      	bgt.n	d7394 <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii+0x46>
      // TODO(petewarden) - Add error reporting hooks so we can report this!
      return;
    }
    TfLiteRegistration* new_registration = &registrations_[registrations_len_];
    registrations_len_ += 1;
   d7370:	1c73      	adds	r3, r6, #1
   d7372:	f8cc 3000 	str.w	r3, [ip]

    *new_registration = *registration;
   d7376:	4655      	mov	r5, sl
   d7378:	cd0f      	ldmia	r5!, {r0, r1, r2, r3}
   d737a:	eb08 1646 	add.w	r6, r8, r6, lsl #5
   d737e:	1d34      	adds	r4, r6, #4
   d7380:	c40f      	stmia	r4!, {r0, r1, r2, r3}
   d7382:	e895 000f 	ldmia.w	r5, {r0, r1, r2, r3}
   d7386:	e884 000f 	stmia.w	r4, {r0, r1, r2, r3}
    new_registration->builtin_code = op;
    new_registration->version = version;
   d738a:	6237      	str	r7, [r6, #32]
    }
    TfLiteRegistration* new_registration = &registrations_[registrations_len_];
    registrations_len_ += 1;

    *new_registration = *registration;
    new_registration->builtin_code = op;
   d738c:	f8c6 9018 	str.w	r9, [r6, #24]
}

void MicroMutableOpResolver::AddBuiltin(tflite::BuiltinOperator op,
                                        TfLiteRegistration* registration,
                                        int min_version, int max_version) {
  for (int version = min_version; version <= max_version; ++version) {
   d7390:	3701      	adds	r7, #1
   d7392:	e7e6      	b.n	d7362 <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii+0x14>
   d7394:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}

000d7398 <_ZN6tflite12ElementCountERK14TfLiteIntArray>:
static const int8_t kAsymmetricInt8Max = 127;
static const int kSymmetricInt8Scale = kAsymmetricInt8Max;

}  // namespace

int ElementCount(const TfLiteIntArray& dims) {
   d7398:	b510      	push	{r4, lr}
   d739a:	4603      	mov	r3, r0
  int result = 1;
  for (int i = 0; i < dims.size; ++i) {
   d739c:	6804      	ldr	r4, [r0, #0]
   d739e:	2200      	movs	r2, #0
static const int kSymmetricInt8Scale = kAsymmetricInt8Max;

}  // namespace

int ElementCount(const TfLiteIntArray& dims) {
  int result = 1;
   d73a0:	2001      	movs	r0, #1
  for (int i = 0; i < dims.size; ++i) {
   d73a2:	42a2      	cmp	r2, r4
   d73a4:	da04      	bge.n	d73b0 <_ZN6tflite12ElementCountERK14TfLiteIntArray+0x18>
    result *= dims.data[i];
   d73a6:	f853 1f04 	ldr.w	r1, [r3, #4]!

}  // namespace

int ElementCount(const TfLiteIntArray& dims) {
  int result = 1;
  for (int i = 0; i < dims.size; ++i) {
   d73aa:	3201      	adds	r2, #1
    result *= dims.data[i];
   d73ac:	4348      	muls	r0, r1

}  // namespace

int ElementCount(const TfLiteIntArray& dims) {
  int result = 1;
  for (int i = 0; i < dims.size; ++i) {
   d73ae:	e7f8      	b.n	d73a2 <_ZN6tflite12ElementCountERK14TfLiteIntArray+0xa>
    result *= dims.data[i];
  }
  return result;
}
   d73b0:	bd10      	pop	{r4, pc}
	...

000d73b4 <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf>:

void SignedSymmetricPerChannelQuantize(const float* values,
                                       TfLiteIntArray* dims,
                                       int quantized_dimension,
                                       int8_t* quantized_values,
                                       float* scaling_factors) {
   d73b4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d73b8:	ed2d 8b04 	vpush	{d8-d9}
   d73bc:	b087      	sub	sp, #28
   d73be:	4688      	mov	r8, r1
   d73c0:	4693      	mov	fp, r2
   d73c2:	4682      	mov	sl, r0
  int input_size = ElementCount(*dims);
   d73c4:	4608      	mov	r0, r1

void SignedSymmetricPerChannelQuantize(const float* values,
                                       TfLiteIntArray* dims,
                                       int quantized_dimension,
                                       int8_t* quantized_values,
                                       float* scaling_factors) {
   d73c6:	9302      	str	r3, [sp, #8]
  int input_size = ElementCount(*dims);
   d73c8:	f7ff ffe6 	bl	d7398 <_ZN6tflite12ElementCountERK14TfLiteIntArray>
  int channel_count = dims->data[quantized_dimension];
   d73cc:	eb08 038b 	add.w	r3, r8, fp, lsl #2
   d73d0:	9f14      	ldr	r7, [sp, #80]	; 0x50
   d73d2:	685b      	ldr	r3, [r3, #4]
      int idx = channel * channel_stride + i * stride;
      min = fminf(min, values[idx]);
      max = fmaxf(max, values[idx]);
    }
    scaling_factors[channel] =
        fmaxf(fabs(min), fabs(max)) / kSymmetricInt8Scale;
   d73d4:	eddf 9a40 	vldr	s19, [pc, #256]	; d74d8 <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x124>
                                       TfLiteIntArray* dims,
                                       int quantized_dimension,
                                       int8_t* quantized_values,
                                       float* scaling_factors) {
  int input_size = ElementCount(*dims);
  int channel_count = dims->data[quantized_dimension];
   d73d8:	9301      	str	r3, [sp, #4]
  int per_channel_size = input_size / channel_count;
  for (int channel = 0; channel < channel_count; channel++) {
   d73da:	2500      	movs	r5, #0
                                       int quantized_dimension,
                                       int8_t* quantized_values,
                                       float* scaling_factors) {
  int input_size = ElementCount(*dims);
  int channel_count = dims->data[quantized_dimension];
  int per_channel_size = input_size / channel_count;
   d73dc:	fb90 f6f3 	sdiv	r6, r0, r3
  for (int channel = 0; channel < channel_count; channel++) {
   d73e0:	9b01      	ldr	r3, [sp, #4]
   d73e2:	429d      	cmp	r5, r3
   d73e4:	da73      	bge.n	d74ce <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x11a>
   d73e6:	4641      	mov	r1, r8
   d73e8:	2200      	movs	r2, #0
   d73ea:	f04f 0901 	mov.w	r9, #1
    float min = 0;
    float max = 0;
    int stride = 1;
    for (int i = 0; i < quantized_dimension; i++) {
   d73ee:	455a      	cmp	r2, fp
   d73f0:	da05      	bge.n	d73fe <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x4a>
      stride *= dims->data[i];
   d73f2:	f851 0f04 	ldr.w	r0, [r1, #4]!
  int per_channel_size = input_size / channel_count;
  for (int channel = 0; channel < channel_count; channel++) {
    float min = 0;
    float max = 0;
    int stride = 1;
    for (int i = 0; i < quantized_dimension; i++) {
   d73f6:	3201      	adds	r2, #1
      stride *= dims->data[i];
   d73f8:	fb00 f909 	mul.w	r9, r0, r9
  int per_channel_size = input_size / channel_count;
  for (int channel = 0; channel < channel_count; channel++) {
    float min = 0;
    float max = 0;
    int stride = 1;
    for (int i = 0; i < quantized_dimension; i++) {
   d73fc:	e7f7      	b.n	d73ee <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x3a>
  int input_size = ElementCount(*dims);
  int channel_count = dims->data[quantized_dimension];
  int per_channel_size = input_size / channel_count;
  for (int channel = 0; channel < channel_count; channel++) {
    float min = 0;
    float max = 0;
   d73fe:	ed9f 8a37 	vldr	s16, [pc, #220]	; d74dc <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x128>
      stride *= dims->data[i];
    }
    int channel_stride = per_channel_size / stride;
    // Calculate scales for each channel.
    for (int i = 0; i < per_channel_size; i++) {
      int idx = channel * channel_stride + i * stride;
   d7402:	fb96 f4f9 	sdiv	r4, r6, r9
   d7406:	436c      	muls	r4, r5
   d7408:	ea4f 0089 	mov.w	r0, r9, lsl #2
   d740c:	eb0a 0284 	add.w	r2, sl, r4, lsl #2
    for (int i = 0; i < quantized_dimension; i++) {
      stride *= dims->data[i];
    }
    int channel_stride = per_channel_size / stride;
    // Calculate scales for each channel.
    for (int i = 0; i < per_channel_size; i++) {
   d7410:	2100      	movs	r1, #0
                                       float* scaling_factors) {
  int input_size = ElementCount(*dims);
  int channel_count = dims->data[quantized_dimension];
  int per_channel_size = input_size / channel_count;
  for (int channel = 0; channel < channel_count; channel++) {
    float min = 0;
   d7412:	eef0 8a48 	vmov.f32	s17, s16
    for (int i = 0; i < quantized_dimension; i++) {
      stride *= dims->data[i];
    }
    int channel_stride = per_channel_size / stride;
    // Calculate scales for each channel.
    for (int i = 0; i < per_channel_size; i++) {
   d7416:	42b1      	cmp	r1, r6
   d7418:	9005      	str	r0, [sp, #20]
   d741a:	9104      	str	r1, [sp, #16]
   d741c:	da18      	bge.n	d7450 <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x9c>
      int idx = channel * channel_stride + i * stride;
      min = fminf(min, values[idx]);
   d741e:	ed92 9a00 	vldr	s18, [r2]
   d7422:	9203      	str	r2, [sp, #12]
   d7424:	eef0 0a49 	vmov.f32	s1, s18
   d7428:	eeb0 0a68 	vmov.f32	s0, s17
   d742c:	f00f fa1e 	bl	e686c <fminf>
      max = fmaxf(max, values[idx]);
   d7430:	eef0 0a49 	vmov.f32	s1, s18
    }
    int channel_stride = per_channel_size / stride;
    // Calculate scales for each channel.
    for (int i = 0; i < per_channel_size; i++) {
      int idx = channel * channel_stride + i * stride;
      min = fminf(min, values[idx]);
   d7434:	eef0 8a40 	vmov.f32	s17, s0
      max = fmaxf(max, values[idx]);
   d7438:	eeb0 0a48 	vmov.f32	s0, s16
   d743c:	f00f f9f8 	bl	e6830 <fmaxf>
    for (int i = 0; i < quantized_dimension; i++) {
      stride *= dims->data[i];
    }
    int channel_stride = per_channel_size / stride;
    // Calculate scales for each channel.
    for (int i = 0; i < per_channel_size; i++) {
   d7440:	9904      	ldr	r1, [sp, #16]
   d7442:	9a03      	ldr	r2, [sp, #12]
   d7444:	9805      	ldr	r0, [sp, #20]
      int idx = channel * channel_stride + i * stride;
      min = fminf(min, values[idx]);
      max = fmaxf(max, values[idx]);
   d7446:	eeb0 8a40 	vmov.f32	s16, s0
    for (int i = 0; i < quantized_dimension; i++) {
      stride *= dims->data[i];
    }
    int channel_stride = per_channel_size / stride;
    // Calculate scales for each channel.
    for (int i = 0; i < per_channel_size; i++) {
   d744a:	3101      	adds	r1, #1
   d744c:	4402      	add	r2, r0
   d744e:	e7e2      	b.n	d7416 <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x62>
      int idx = channel * channel_stride + i * stride;
      min = fminf(min, values[idx]);
      max = fmaxf(max, values[idx]);
    }
    scaling_factors[channel] =
        fmaxf(fabs(min), fabs(max)) / kSymmetricInt8Scale;
   d7450:	eef0 0ac8 	vabs.f32	s1, s16
   d7454:	eeb0 0ae8 	vabs.f32	s0, s17
   d7458:	f00f f9ea 	bl	e6830 <fmaxf>
   d745c:	ee80 0a29 	vdiv.f32	s0, s0, s19
      int idx = channel * channel_stride + i * stride;
      const int32_t quantized_value =
          static_cast<int32_t>(roundf(values[idx] / scaling_factors[channel]));
      // Clamp: just in case some odd numeric offset.
      quantized_values[idx] = fminf(
          kSymmetricInt8Scale, fmaxf(-kSymmetricInt8Scale, quantized_value));
   d7460:	9b02      	ldr	r3, [sp, #8]
   d7462:	ebc9 0004 	rsb	r0, r9, r4
      int idx = channel * channel_stride + i * stride;
      min = fminf(min, values[idx]);
      max = fmaxf(max, values[idx]);
    }
    scaling_factors[channel] =
        fmaxf(fabs(min), fabs(max)) / kSymmetricInt8Scale;
   d7466:	2200      	movs	r2, #0
      int idx = channel * channel_stride + i * stride;
      const int32_t quantized_value =
          static_cast<int32_t>(roundf(values[idx] / scaling_factors[channel]));
      // Clamp: just in case some odd numeric offset.
      quantized_values[idx] = fminf(
          kSymmetricInt8Scale, fmaxf(-kSymmetricInt8Scale, quantized_value));
   d7468:	ebc9 0404 	rsb	r4, r9, r4
   d746c:	0080      	lsls	r0, r0, #2
      min = fminf(min, values[idx]);
      max = fmaxf(max, values[idx]);
    }
    scaling_factors[channel] =
        fmaxf(fabs(min), fabs(max)) / kSymmetricInt8Scale;
    for (int i = 0; i < per_channel_size; i++) {
   d746e:	4611      	mov	r1, r2
      int idx = channel * channel_stride + i * stride;
      const int32_t quantized_value =
          static_cast<int32_t>(roundf(values[idx] / scaling_factors[channel]));
      // Clamp: just in case some odd numeric offset.
      quantized_values[idx] = fminf(
          kSymmetricInt8Scale, fmaxf(-kSymmetricInt8Scale, quantized_value));
   d7470:	441c      	add	r4, r3
      int idx = channel * channel_stride + i * stride;
      min = fminf(min, values[idx]);
      max = fmaxf(max, values[idx]);
    }
    scaling_factors[channel] =
        fmaxf(fabs(min), fabs(max)) / kSymmetricInt8Scale;
   d7472:	eca7 0a01 	vstmia	r7!, {s0}
    for (int i = 0; i < per_channel_size; i++) {
   d7476:	42b1      	cmp	r1, r6
   d7478:	444a      	add	r2, r9
   d747a:	9105      	str	r1, [sp, #20]
   d747c:	da25      	bge.n	d74ca <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x116>
      int idx = channel * channel_stride + i * stride;
      const int32_t quantized_value =
          static_cast<int32_t>(roundf(values[idx] / scaling_factors[channel]));
   d747e:	eb00 0e82 	add.w	lr, r0, r2, lsl #2
   d7482:	44d6      	add	lr, sl
   d7484:	ed9e 0a00 	vldr	s0, [lr]
   d7488:	ed57 7a01 	vldr	s15, [r7, #-4]
   d748c:	9204      	str	r2, [sp, #16]
   d748e:	ee80 0a27 	vdiv.f32	s0, s0, s15
   d7492:	9003      	str	r0, [sp, #12]
   d7494:	f00f fa24 	bl	e68e0 <roundf>
      // Clamp: just in case some odd numeric offset.
      quantized_values[idx] = fminf(
   d7498:	eefd 0ac0 	vcvt.s32.f32	s1, s0
   d749c:	ed9f 0a10 	vldr	s0, [pc, #64]	; d74e0 <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x12c>
   d74a0:	eef8 0ae0 	vcvt.f32.s32	s1, s1
   d74a4:	f00f f9c4 	bl	e6830 <fmaxf>
   d74a8:	eef0 0a40 	vmov.f32	s1, s0
   d74ac:	ed9f 0a0a 	vldr	s0, [pc, #40]	; d74d8 <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x124>
   d74b0:	f00f f9dc 	bl	e686c <fminf>
          kSymmetricInt8Scale, fmaxf(-kSymmetricInt8Scale, quantized_value));
   d74b4:	eefd 7ac0 	vcvt.s32.f32	s15, s0
   d74b8:	9a04      	ldr	r2, [sp, #16]
      min = fminf(min, values[idx]);
      max = fmaxf(max, values[idx]);
    }
    scaling_factors[channel] =
        fmaxf(fabs(min), fabs(max)) / kSymmetricInt8Scale;
    for (int i = 0; i < per_channel_size; i++) {
   d74ba:	9905      	ldr	r1, [sp, #20]
   d74bc:	9803      	ldr	r0, [sp, #12]
      int idx = channel * channel_stride + i * stride;
      const int32_t quantized_value =
          static_cast<int32_t>(roundf(values[idx] / scaling_factors[channel]));
      // Clamp: just in case some odd numeric offset.
      quantized_values[idx] = fminf(
          kSymmetricInt8Scale, fmaxf(-kSymmetricInt8Scale, quantized_value));
   d74be:	ee17 ea90 	vmov	lr, s15
      min = fminf(min, values[idx]);
      max = fmaxf(max, values[idx]);
    }
    scaling_factors[channel] =
        fmaxf(fabs(min), fabs(max)) / kSymmetricInt8Scale;
    for (int i = 0; i < per_channel_size; i++) {
   d74c2:	3101      	adds	r1, #1
      int idx = channel * channel_stride + i * stride;
      const int32_t quantized_value =
          static_cast<int32_t>(roundf(values[idx] / scaling_factors[channel]));
      // Clamp: just in case some odd numeric offset.
      quantized_values[idx] = fminf(
          kSymmetricInt8Scale, fmaxf(-kSymmetricInt8Scale, quantized_value));
   d74c4:	f804 e002 	strb.w	lr, [r4, r2]
      min = fminf(min, values[idx]);
      max = fmaxf(max, values[idx]);
    }
    scaling_factors[channel] =
        fmaxf(fabs(min), fabs(max)) / kSymmetricInt8Scale;
    for (int i = 0; i < per_channel_size; i++) {
   d74c8:	e7d5      	b.n	d7476 <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0xc2>
                                       int8_t* quantized_values,
                                       float* scaling_factors) {
  int input_size = ElementCount(*dims);
  int channel_count = dims->data[quantized_dimension];
  int per_channel_size = input_size / channel_count;
  for (int channel = 0; channel < channel_count; channel++) {
   d74ca:	3501      	adds	r5, #1
   d74cc:	e788      	b.n	d73e0 <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf+0x2c>
      // Clamp: just in case some odd numeric offset.
      quantized_values[idx] = fminf(
          kSymmetricInt8Scale, fmaxf(-kSymmetricInt8Scale, quantized_value));
    }
  }
}
   d74ce:	b007      	add	sp, #28
   d74d0:	ecbd 8b04 	vpop	{d8-d9}
   d74d4:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   d74d8:	42fe0000 	.word	0x42fe0000
   d74dc:	00000000 	.word	0x00000000
   d74e0:	c2fe0000 	.word	0xc2fe0000

000d74e4 <_ZN6tflite19SymmetricDequantizeEPKaifPf>:
                          scaling_factor);
}

void SymmetricDequantize(const int8_t* values, const int size,
                         const float dequantization_scale,
                         float* dequantized_values) {
   d74e4:	b510      	push	{r4, lr}
   d74e6:	4603      	mov	r3, r0
  for (int i = 0; i < size; ++i) {
   d74e8:	1a1c      	subs	r4, r3, r0
   d74ea:	42a1      	cmp	r1, r4
   d74ec:	dd0a      	ble.n	d7504 <_ZN6tflite19SymmetricDequantizeEPKaifPf+0x20>
    dequantized_values[i] = values[i] * dequantization_scale;
   d74ee:	f913 4b01 	ldrsb.w	r4, [r3], #1
   d74f2:	ee07 4a90 	vmov	s15, r4
   d74f6:	eef8 7ae7 	vcvt.f32.s32	s15, s15
   d74fa:	ee67 7a80 	vmul.f32	s15, s15, s0
   d74fe:	ece2 7a01 	vstmia	r2!, {s15}
}

void SymmetricDequantize(const int8_t* values, const int size,
                         const float dequantization_scale,
                         float* dequantized_values) {
  for (int i = 0; i < size; ++i) {
   d7502:	e7f1      	b.n	d74e8 <_ZN6tflite19SymmetricDequantizeEPKaifPf+0x4>
   d7504:	bd10      	pop	{r4, pc}

000d7506 <_ZN6tflite21SimpleMemoryAllocator16AllocateFromTailEjj>:
#include "tensorflow/lite/experimental/micro/memory_helpers.h"

namespace tflite {

uint8_t* SimpleMemoryAllocator::AllocateFromTail(size_t size,
                                                 size_t alignment) {
   d7506:	b538      	push	{r3, r4, r5, lr}
  uint8_t* previous_free = (data_ + data_size_max_) - data_size_;
   d7508:	6804      	ldr	r4, [r0, #0]
   d750a:	6843      	ldr	r3, [r0, #4]
   d750c:	1b1b      	subs	r3, r3, r4
   d750e:	6884      	ldr	r4, [r0, #8]
   d7510:	441c      	add	r4, r3
#include "tensorflow/lite/experimental/micro/memory_helpers.h"

namespace tflite {

uint8_t* SimpleMemoryAllocator::AllocateFromTail(size_t size,
                                                 size_t alignment) {
   d7512:	4605      	mov	r5, r0
  uint8_t* previous_free = (data_ + data_size_max_) - data_size_;
  uint8_t* current_data = previous_free - size;
  uint8_t* aligned_result = AlignPointerDown(current_data, alignment);
   d7514:	1a60      	subs	r0, r4, r1
   d7516:	4611      	mov	r1, r2
   d7518:	f7ff f928 	bl	d676c <_ZN6tflite16AlignPointerDownEPhj>
  size_t aligned_size = (previous_free - aligned_result);
  if ((data_size_ + aligned_size) > data_size_max_) {
   d751c:	682b      	ldr	r3, [r5, #0]
   d751e:	1a24      	subs	r4, r4, r0
   d7520:	441c      	add	r4, r3
   d7522:	686b      	ldr	r3, [r5, #4]
   d7524:	429c      	cmp	r4, r3
    // TODO(petewarden): Add error reporting beyond returning null!
    return nullptr;
  }
  data_size_ += aligned_size;
   d7526:	bf94      	ite	ls
   d7528:	602c      	strls	r4, [r5, #0]
  uint8_t* current_data = previous_free - size;
  uint8_t* aligned_result = AlignPointerDown(current_data, alignment);
  size_t aligned_size = (previous_free - aligned_result);
  if ((data_size_ + aligned_size) > data_size_max_) {
    // TODO(petewarden): Add error reporting beyond returning null!
    return nullptr;
   d752a:	2000      	movhi	r0, #0
  }
  data_size_ += aligned_size;
  return aligned_result;
}
   d752c:	bd38      	pop	{r3, r4, r5, pc}
	...

000d7530 <DebugLog>:
#define DEBUG_SERIAL_OBJECT (Serial)
#endif

// On Arduino platforms, we set up a serial port and write to it for debug
// logging.
extern "C" void DebugLog(const char* s) {
   d7530:	b538      	push	{r3, r4, r5, lr}
  static bool is_initialized = false;
  if (!is_initialized) {
   d7532:	4c09      	ldr	r4, [pc, #36]	; (d7558 <DebugLog+0x28>)
   d7534:	7823      	ldrb	r3, [r4, #0]
#define DEBUG_SERIAL_OBJECT (Serial)
#endif

// On Arduino platforms, we set up a serial port and write to it for debug
// logging.
extern "C" void DebugLog(const char* s) {
   d7536:	4605      	mov	r5, r0
  static bool is_initialized = false;
  if (!is_initialized) {
   d7538:	b93b      	cbnz	r3, d754a <DebugLog+0x1a>
    DEBUG_SERIAL_OBJECT.begin(9600);
   d753a:	f00e fce7 	bl	e5f0c <_Z16_fetch_usbserialv>
   d753e:	f44f 5116 	mov.w	r1, #9600	; 0x2580
   d7542:	f00e fcd7 	bl	e5ef4 <_ZN9USBSerial5beginEl>
    is_initialized = true;
   d7546:	2301      	movs	r3, #1
   d7548:	7023      	strb	r3, [r4, #0]
  }
  DEBUG_SERIAL_OBJECT.print(s);
   d754a:	f00e fcdf 	bl	e5f0c <_Z16_fetch_usbserialv>
   d754e:	4629      	mov	r1, r5
}
   d7550:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
  static bool is_initialized = false;
  if (!is_initialized) {
    DEBUG_SERIAL_OBJECT.begin(9600);
    is_initialized = true;
  }
  DEBUG_SERIAL_OBJECT.print(s);
   d7554:	f00e baba 	b.w	e5acc <_ZN5Print5printEPKc>
   d7558:	2003dbc4 	.word	0x2003dbc4

000d755c <_GLOBAL__sub_I_DebugLog>:
   d755c:	f00d bde6 	b.w	e512c <HAL_Pin_Map>

000d7560 <_ZN6tflite3ops5micro3add4InitEP13TfLiteContextPKcj>:
  int32 output_offset;
};

void* Init(TfLiteContext* context, const char* buffer, size_t length) {
  return nullptr;
}
   d7560:	2000      	movs	r0, #0
   d7562:	4770      	bx	lr

000d7564 <_ZN6tflite3ops5micro3add4FreeEP13TfLiteContextPv>:

void Free(TfLiteContext* context, void* buffer) {}
   d7564:	4770      	bx	lr

000d7566 <_ZN6tflite3ops5micro3add7PrepareEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   d7566:	2000      	movs	r0, #0
   d7568:	4770      	bx	lr

000d756a <_ZN6tflite12RuntimeShapeD1Ev>:
  bool operator==(const RuntimeShape& comp) const {
    return this->size_ == comp.size_ &&
           std::memcmp(DimsData(), comp.DimsData(), size_ * sizeof(int32)) == 0;
  }

  ~RuntimeShape() {
   d756a:	b510      	push	{r4, lr}
    if (size_ > kMaxSmallSize) {
   d756c:	6803      	ldr	r3, [r0, #0]
   d756e:	2b04      	cmp	r3, #4
  bool operator==(const RuntimeShape& comp) const {
    return this->size_ == comp.size_ &&
           std::memcmp(DimsData(), comp.DimsData(), size_ * sizeof(int32)) == 0;
  }

  ~RuntimeShape() {
   d7570:	4604      	mov	r4, r0
    if (size_ > kMaxSmallSize) {
   d7572:	dd03      	ble.n	d757c <_ZN6tflite12RuntimeShapeD1Ev+0x12>
#ifdef TF_LITE_STATIC_MEMORY
      TFLITE_CHECK(false && "No shape resizing supported on this platform");
#else   // TF_LITE_STATIC_MEMORY
      delete[] dims_pointer_;
   d7574:	6840      	ldr	r0, [r0, #4]
   d7576:	b108      	cbz	r0, d757c <_ZN6tflite12RuntimeShapeD1Ev+0x12>
   d7578:	f7fc fd93 	bl	d40a2 <_ZdaPv>
#endif  // TF_LITE_STATIC_MEMORY
    }
  }
   d757c:	4620      	mov	r0, r4
   d757e:	bd10      	pop	{r4, pc}

000d7580 <_ZNK6tflite12RuntimeShape4DimsEi>:

  inline int32 DimensionsCount() const { return size_; }
  inline int32 Dims(int i) const {
    TFLITE_DCHECK_GE(i, 0);
   d7580:	2900      	cmp	r1, #0
#endif  // TF_LITE_STATIC_MEMORY
    }
  }

  inline int32 DimensionsCount() const { return size_; }
  inline int32 Dims(int i) const {
   d7582:	b508      	push	{r3, lr}
    TFLITE_DCHECK_GE(i, 0);
   d7584:	da01      	bge.n	d758a <_ZNK6tflite12RuntimeShape4DimsEi+0xa>
   d7586:	f00d ffb5 	bl	e54f4 <abort>
    TFLITE_DCHECK_LT(i, size_);
   d758a:	6803      	ldr	r3, [r0, #0]
   d758c:	428b      	cmp	r3, r1
   d758e:	ddfa      	ble.n	d7586 <_ZNK6tflite12RuntimeShape4DimsEi+0x6>
    return size_ > kMaxSmallSize ? dims_pointer_[i] : dims_[i];
   d7590:	2b04      	cmp	r3, #4
   d7592:	bfc7      	ittee	gt
   d7594:	6843      	ldrgt	r3, [r0, #4]
   d7596:	f853 0021 	ldrgt.w	r0, [r3, r1, lsl #2]
   d759a:	eb00 0081 	addle.w	r0, r0, r1, lsl #2
   d759e:	6840      	ldrle	r0, [r0, #4]
  }
   d75a0:	bd08      	pop	{r3, pc}

000d75a2 <_ZN6tflite12RuntimeShape6SetDimEil>:
  inline void SetDim(int i, int32 val) {
    TFLITE_DCHECK_GE(i, 0);
   d75a2:	2900      	cmp	r1, #0
  inline int32 Dims(int i) const {
    TFLITE_DCHECK_GE(i, 0);
    TFLITE_DCHECK_LT(i, size_);
    return size_ > kMaxSmallSize ? dims_pointer_[i] : dims_[i];
  }
  inline void SetDim(int i, int32 val) {
   d75a4:	b508      	push	{r3, lr}
    TFLITE_DCHECK_GE(i, 0);
   d75a6:	da01      	bge.n	d75ac <_ZN6tflite12RuntimeShape6SetDimEil+0xa>
   d75a8:	f00d ffa4 	bl	e54f4 <abort>
    TFLITE_DCHECK_LT(i, size_);
   d75ac:	6803      	ldr	r3, [r0, #0]
   d75ae:	428b      	cmp	r3, r1
   d75b0:	ddfa      	ble.n	d75a8 <_ZN6tflite12RuntimeShape6SetDimEil+0x6>
    if (size_ > kMaxSmallSize) {
   d75b2:	2b04      	cmp	r3, #4
      dims_pointer_[i] = val;
   d75b4:	bfcb      	itete	gt
   d75b6:	6843      	ldrgt	r3, [r0, #4]
    } else {
      dims_[i] = val;
   d75b8:	eb00 0081 	addle.w	r0, r0, r1, lsl #2
  }
  inline void SetDim(int i, int32 val) {
    TFLITE_DCHECK_GE(i, 0);
    TFLITE_DCHECK_LT(i, size_);
    if (size_ > kMaxSmallSize) {
      dims_pointer_[i] = val;
   d75bc:	f843 2021 	strgt.w	r2, [r3, r1, lsl #2]
    } else {
      dims_[i] = val;
   d75c0:	6042      	strle	r2, [r0, #4]
   d75c2:	bd08      	pop	{r3, pc}

000d75c4 <_ZN6tflite12RuntimeShape6ResizeEi>:
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  // The caller must ensure that the shape is no bigger than 4-D.
  inline const int32* DimsDataUpTo4D() const { return dims_; }

  inline void Resize(int dimensions_count) {
   d75c4:	b538      	push	{r3, r4, r5, lr}
    if (size_ > kMaxSmallSize) {
   d75c6:	6803      	ldr	r3, [r0, #0]
   d75c8:	2b04      	cmp	r3, #4
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  // The caller must ensure that the shape is no bigger than 4-D.
  inline const int32* DimsDataUpTo4D() const { return dims_; }

  inline void Resize(int dimensions_count) {
   d75ca:	4605      	mov	r5, r0
   d75cc:	460c      	mov	r4, r1
    if (size_ > kMaxSmallSize) {
   d75ce:	dd03      	ble.n	d75d8 <_ZN6tflite12RuntimeShape6ResizeEi+0x14>
#ifdef TF_LITE_STATIC_MEMORY
      TFLITE_CHECK(false && "No shape resizing supported on this platform");
#else   // TF_LITE_STATIC_MEMORY
      delete[] dims_pointer_;
   d75d0:	6840      	ldr	r0, [r0, #4]
   d75d2:	b108      	cbz	r0, d75d8 <_ZN6tflite12RuntimeShape6ResizeEi+0x14>
   d75d4:	f7fc fd65 	bl	d40a2 <_ZdaPv>
#endif  // TF_LITE_STATIC_MEMORY
    }
    size_ = dimensions_count;
    if (dimensions_count > kMaxSmallSize) {
   d75d8:	2c04      	cmp	r4, #4
      TFLITE_CHECK(false && "No shape resizing supported on this platform");
#else   // TF_LITE_STATIC_MEMORY
      delete[] dims_pointer_;
#endif  // TF_LITE_STATIC_MEMORY
    }
    size_ = dimensions_count;
   d75da:	602c      	str	r4, [r5, #0]
    if (dimensions_count > kMaxSmallSize) {
   d75dc:	dd08      	ble.n	d75f0 <_ZN6tflite12RuntimeShape6ResizeEi+0x2c>
#ifdef TF_LITE_STATIC_MEMORY
      TFLITE_CHECK(false && "No shape resizing supported on this platform");
#else   // TF_LITE_STATIC_MEMORY
      dims_pointer_ = new int32[dimensions_count];
   d75de:	f1b4 5ffe 	cmp.w	r4, #532676608	; 0x1fc00000
   d75e2:	bfd4      	ite	le
   d75e4:	00a0      	lslle	r0, r4, #2
   d75e6:	f04f 30ff 	movgt.w	r0, #4294967295	; 0xffffffff
   d75ea:	f7fc fd56 	bl	d409a <_Znaj>
   d75ee:	6068      	str	r0, [r5, #4]
   d75f0:	bd38      	pop	{r3, r4, r5, pc}

000d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>:

 private:
  // For use only by ExtendedShape(), written to guarantee (return-value) copy
  // elision in C++17.
  // This creates a shape padded to the desired size with the specified value.
  RuntimeShape(int new_shape_size, const RuntimeShape& shape, int pad_value)
   d75f2:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
      : size_(0) {
   d75f6:	2500      	movs	r5, #0
   d75f8:	6005      	str	r5, [r0, #0]

 private:
  // For use only by ExtendedShape(), written to guarantee (return-value) copy
  // elision in C++17.
  // This creates a shape padded to the desired size with the specified value.
  RuntimeShape(int new_shape_size, const RuntimeShape& shape, int pad_value)
   d75fa:	4698      	mov	r8, r3
      : size_(0) {
    // If the following check fails, it is likely because a 4D-only kernel is
    // being used with an array of larger dimension count.
    TFLITE_CHECK_GE(new_shape_size, shape.DimensionsCount());
   d75fc:	6813      	ldr	r3, [r2, #0]
   d75fe:	428b      	cmp	r3, r1

 private:
  // For use only by ExtendedShape(), written to guarantee (return-value) copy
  // elision in C++17.
  // This creates a shape padded to the desired size with the specified value.
  RuntimeShape(int new_shape_size, const RuntimeShape& shape, int pad_value)
   d7600:	4606      	mov	r6, r0
   d7602:	460f      	mov	r7, r1
   d7604:	4614      	mov	r4, r2
      : size_(0) {
    // If the following check fails, it is likely because a 4D-only kernel is
    // being used with an array of larger dimension count.
    TFLITE_CHECK_GE(new_shape_size, shape.DimensionsCount());
   d7606:	dd01      	ble.n	d760c <_ZN6tflite12RuntimeShapeC1EiRKS0_i+0x1a>
   d7608:	f00d ff74 	bl	e54f4 <abort>
    Resize(new_shape_size);
   d760c:	f7ff ffda 	bl	d75c4 <_ZN6tflite12RuntimeShape6ResizeEi>
    const int size_increase = new_shape_size - shape.DimensionsCount();
   d7610:	6820      	ldr	r0, [r4, #0]
   d7612:	1a3f      	subs	r7, r7, r0
    for (int i = 0; i < size_increase; ++i) {
   d7614:	42bd      	cmp	r5, r7
   d7616:	da06      	bge.n	d7626 <_ZN6tflite12RuntimeShapeC1EiRKS0_i+0x34>
      SetDim(i, pad_value);
   d7618:	4629      	mov	r1, r5
   d761a:	4642      	mov	r2, r8
   d761c:	4630      	mov	r0, r6
   d761e:	f7ff ffc0 	bl	d75a2 <_ZN6tflite12RuntimeShape6SetDimEil>
    // If the following check fails, it is likely because a 4D-only kernel is
    // being used with an array of larger dimension count.
    TFLITE_CHECK_GE(new_shape_size, shape.DimensionsCount());
    Resize(new_shape_size);
    const int size_increase = new_shape_size - shape.DimensionsCount();
    for (int i = 0; i < size_increase; ++i) {
   d7622:	3501      	adds	r5, #1
   d7624:	e7f6      	b.n	d7614 <_ZN6tflite12RuntimeShapeC1EiRKS0_i+0x22>
      dims_[i] = val;
    }
  }

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   d7626:	6833      	ldr	r3, [r6, #0]
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   d7628:	6822      	ldr	r2, [r4, #0]
      dims_[i] = val;
    }
  }

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   d762a:	2b04      	cmp	r3, #4
   d762c:	bfcc      	ite	gt
   d762e:	6870      	ldrgt	r0, [r6, #4]
   d7630:	1d30      	addle	r0, r6, #4
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   d7632:	2a04      	cmp	r2, #4
    Resize(new_shape_size);
    const int size_increase = new_shape_size - shape.DimensionsCount();
    for (int i = 0; i < size_increase; ++i) {
      SetDim(i, pad_value);
    }
    std::memcpy(DimsData() + size_increase, shape.DimsData(),
   d7634:	eb00 0087 	add.w	r0, r0, r7, lsl #2

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   d7638:	bfcc      	ite	gt
   d763a:	6861      	ldrgt	r1, [r4, #4]
   d763c:	1d21      	addle	r1, r4, #4
    const int size_increase = new_shape_size - shape.DimensionsCount();
    for (int i = 0; i < size_increase; ++i) {
      SetDim(i, pad_value);
    }
    std::memcpy(DimsData() + size_increase, shape.DimsData(),
                sizeof(int32) * shape.DimensionsCount());
   d763e:	0092      	lsls	r2, r2, #2
   d7640:	f011 fa8f 	bl	e8b62 <memcpy>
  }
   d7644:	4630      	mov	r0, r6
   d7646:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

000d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>:
    }
  }
  return offset;
}

inline int Offset(const RuntimeShape& shape, int i0, int i1, int i2, int i3) {
   d764a:	b570      	push	{r4, r5, r6, lr}
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), 4);
   d764c:	6805      	ldr	r5, [r0, #0]
    }
  }
  return offset;
}

inline int Offset(const RuntimeShape& shape, int i0, int i1, int i2, int i3) {
   d764e:	9c04      	ldr	r4, [sp, #16]
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), 4);
   d7650:	2d04      	cmp	r5, #4
   d7652:	d001      	beq.n	d7658 <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii+0xe>
   d7654:	f00d ff4e 	bl	e54f4 <abort>
  const int* dims_data = reinterpret_cast<const int*>(shape.DimsDataUpTo4D());
  TFLITE_DCHECK(i0 >= 0 && i0 < dims_data[0]);
   d7658:	2900      	cmp	r1, #0
   d765a:	dbfb      	blt.n	d7654 <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii+0xa>
   d765c:	6845      	ldr	r5, [r0, #4]
   d765e:	42a9      	cmp	r1, r5
   d7660:	daf8      	bge.n	d7654 <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii+0xa>
  TFLITE_DCHECK(i1 >= 0 && i1 < dims_data[1]);
   d7662:	2a00      	cmp	r2, #0
   d7664:	dbf6      	blt.n	d7654 <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii+0xa>
   d7666:	6886      	ldr	r6, [r0, #8]
   d7668:	42b2      	cmp	r2, r6
   d766a:	daf3      	bge.n	d7654 <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii+0xa>
  TFLITE_DCHECK(i2 >= 0 && i2 < dims_data[2]);
   d766c:	2b00      	cmp	r3, #0
   d766e:	dbf1      	blt.n	d7654 <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii+0xa>
   d7670:	68c5      	ldr	r5, [r0, #12]
   d7672:	42ab      	cmp	r3, r5
   d7674:	daee      	bge.n	d7654 <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii+0xa>
  TFLITE_DCHECK(i3 >= 0 && i3 < dims_data[3]);
   d7676:	2c00      	cmp	r4, #0
   d7678:	dbec      	blt.n	d7654 <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii+0xa>
   d767a:	6900      	ldr	r0, [r0, #16]
   d767c:	4284      	cmp	r4, r0
   d767e:	dae9      	bge.n	d7654 <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii+0xa>
  return ((i0 * dims_data[1] + i1) * dims_data[2] + i2) * dims_data[3] + i3;
   d7680:	fb06 2101 	mla	r1, r6, r1, r2
   d7684:	fb05 3301 	mla	r3, r5, r1, r3
}
   d7688:	fb00 4003 	mla	r0, r0, r3, r4
   d768c:	bd70      	pop	{r4, r5, r6, pc}

000d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>:
  return shape.FlatSize();
}

inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0,
                            const RuntimeShape& check_shape_1) {
   d768e:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
   d7692:	6805      	ldr	r5, [r0, #0]
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   d7694:	680b      	ldr	r3, [r1, #0]
   d7696:	429d      	cmp	r5, r3
  return shape.FlatSize();
}

inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0,
                            const RuntimeShape& check_shape_1) {
   d7698:	4604      	mov	r4, r0
   d769a:	4688      	mov	r8, r1
   d769c:	4617      	mov	r7, r2
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   d769e:	d101      	bne.n	d76a4 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_+0x16>
   d76a0:	2600      	movs	r6, #0
   d76a2:	e00d      	b.n	d76c0 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_+0x32>
   d76a4:	f00d ff26 	bl	e54f4 <abort>
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   d76a8:	4631      	mov	r1, r6
   d76aa:	4620      	mov	r0, r4
   d76ac:	f7ff ff68 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d76b0:	4631      	mov	r1, r6
   d76b2:	4681      	mov	r9, r0
   d76b4:	4640      	mov	r0, r8
   d76b6:	f7ff ff63 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d76ba:	4581      	cmp	r9, r0
   d76bc:	d1f2      	bne.n	d76a4 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_+0x16>
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0,
                            const RuntimeShape& check_shape_1) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   d76be:	3601      	adds	r6, #1
   d76c0:	42ae      	cmp	r6, r5
   d76c2:	dbf1      	blt.n	d76a8 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_+0x1a>

// Flat size calculation, checking that dimensions match with one or more other
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   d76c4:	683b      	ldr	r3, [r7, #0]
   d76c6:	429d      	cmp	r5, r3
   d76c8:	d1ec      	bne.n	d76a4 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_+0x16>
   d76ca:	2600      	movs	r6, #0
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   d76cc:	42b5      	cmp	r5, r6
   d76ce:	dd0c      	ble.n	d76ea <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_+0x5c>
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   d76d0:	4631      	mov	r1, r6
   d76d2:	4620      	mov	r0, r4
   d76d4:	f7ff ff54 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d76d8:	4631      	mov	r1, r6
   d76da:	4680      	mov	r8, r0
   d76dc:	4638      	mov	r0, r7
   d76de:	f7ff ff4f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d76e2:	4580      	cmp	r8, r0
   d76e4:	d1de      	bne.n	d76a4 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_+0x16>
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   d76e6:	3601      	adds	r6, #1
   d76e8:	e7f0      	b.n	d76cc <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_+0x3e>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   d76ea:	2d04      	cmp	r5, #4
   d76ec:	bfcc      	ite	gt
   d76ee:	6864      	ldrgt	r4, [r4, #4]
   d76f0:	3404      	addle	r4, #4
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   d76f2:	2300      	movs	r3, #0
  }

  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
   d76f4:	2001      	movs	r0, #1
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   d76f6:	429d      	cmp	r5, r3
   d76f8:	dd04      	ble.n	d7704 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_+0x76>
      buffer_size *= dims_data[i];
   d76fa:	f854 2023 	ldr.w	r2, [r4, r3, lsl #2]
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   d76fe:	3301      	adds	r3, #1
      buffer_size *= dims_data[i];
   d7700:	4350      	muls	r0, r2
   d7702:	e7f8      	b.n	d76f6 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_+0x68>
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
  }
  return MatchingFlatSize(shape, check_shape_1);
}
   d7704:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}

000d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>:
// This function implements the same computation as the ARMv7 NEON VQRDMULH
// instruction.
template <>
inline std::int32_t SaturatingRoundingDoublingHighMul(std::int32_t a,
                                                      std::int32_t b) {
  bool overflow = a == b && a == std::numeric_limits<std::int32_t>::min();
   d7708:	4288      	cmp	r0, r1
  }
#endif
}

inline int32 MultiplyByQuantizedMultiplierSmallerThanOneExp(
    int32 x, int32 quantized_multiplier, int left_shift) {
   d770a:	b570      	push	{r4, r5, r6, lr}
   d770c:	d104      	bne.n	d7718 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x10>
   d770e:	f100 4300 	add.w	r3, r0, #2147483648	; 0x80000000
   d7712:	425e      	negs	r6, r3
   d7714:	415e      	adcs	r6, r3
   d7716:	e000      	b.n	d771a <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x12>
   d7718:	2600      	movs	r6, #0
  std::int64_t a_64(a);
  std::int64_t b_64(b);
  std::int64_t ab_64 = a_64 * b_64;
   d771a:	fb80 4501 	smull	r4, r5, r0, r1
  std::int32_t nudge = ab_64 >= 0 ? (1 << 30) : (1 - (1 << 30));
   d771e:	2c00      	cmp	r4, #0
   d7720:	f175 0300 	sbcs.w	r3, r5, #0
   d7724:	4b1c      	ldr	r3, [pc, #112]	; (d7798 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x90>)
   d7726:	bfa8      	it	ge
   d7728:	f04f 4380 	movge.w	r3, #1073741824	; 0x40000000
  std::int32_t ab_x2_high32 =
      static_cast<std::int32_t>((ab_64 + nudge) / (1ll << 31));
  return overflow ? std::numeric_limits<std::int32_t>::max() : ab_x2_high32;
   d772c:	b97e      	cbnz	r6, d774e <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x46>
  std::int64_t a_64(a);
  std::int64_t b_64(b);
  std::int64_t ab_64 = a_64 * b_64;
  std::int32_t nudge = ab_64 >= 0 ? (1 << 30) : (1 - (1 << 30));
  std::int32_t ab_x2_high32 =
      static_cast<std::int32_t>((ab_64 + nudge) / (1ll << 31));
   d772e:	18e4      	adds	r4, r4, r3
   d7730:	eb45 75e3 	adc.w	r5, r5, r3, asr #31
   d7734:	2c00      	cmp	r4, #0
   d7736:	f175 0300 	sbcs.w	r3, r5, #0
   d773a:	da04      	bge.n	d7746 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x3e>
   d773c:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
   d7740:	2100      	movs	r1, #0
   d7742:	1824      	adds	r4, r4, r0
   d7744:	414d      	adcs	r5, r1
   d7746:	0fe4      	lsrs	r4, r4, #31
   d7748:	ea44 0445 	orr.w	r4, r4, r5, lsl #1
   d774c:	e001      	b.n	d7752 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x4a>
  return overflow ? std::numeric_limits<std::int32_t>::max() : ab_x2_high32;
   d774e:	f06f 4400 	mvn.w	r4, #2147483648	; 0x80000000
  using gemmlowp::RoundingDivideByPOT;
  using gemmlowp::SaturatingRoundingDoublingHighMul;
  return RoundingDivideByPOT(
   d7752:	4255      	negs	r5, r2

// Correctly-rounded-to-nearest division by a power-of-two.
// Also known as a rounding arithmetic right shift.
template <typename IntegerType>
inline IntegerType RoundingDivideByPOT(IntegerType x, int exponent) {
  assert(exponent >= 0);
   d7754:	2d00      	cmp	r5, #0
   d7756:	da04      	bge.n	d7762 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x5a>
   d7758:	4b10      	ldr	r3, [pc, #64]	; (d779c <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x94>)
   d775a:	4a11      	ldr	r2, [pc, #68]	; (d77a0 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x98>)
   d775c:	f44f 71b3 	mov.w	r1, #358	; 0x166
   d7760:	e005      	b.n	d776e <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x66>
  assert(exponent <= 31);
   d7762:	2d1f      	cmp	r5, #31
   d7764:	dd06      	ble.n	d7774 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x6c>
   d7766:	4b0f      	ldr	r3, [pc, #60]	; (d77a4 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x9c>)
   d7768:	4a0d      	ldr	r2, [pc, #52]	; (d77a0 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0x98>)
   d776a:	f240 1167 	movw	r1, #359	; 0x167
   d776e:	480e      	ldr	r0, [pc, #56]	; (d77a8 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli+0xa0>)
   d7770:	f00d fed0 	bl	e5514 <__assert_func>
  const IntegerType mask = Dup<IntegerType>((1ll << exponent) - 1);
   d7774:	462a      	mov	r2, r5
   d7776:	2001      	movs	r0, #1
   d7778:	2100      	movs	r1, #0
   d777a:	f010 fc8f 	bl	e809c <__aeabi_llsl>
   d777e:	3801      	subs	r0, #1
      SaturatingRoundingDoublingHighMul(x, quantized_multiplier), -left_shift);
   d7780:	ea00 0304 	and.w	r3, r0, r4
   d7784:	1040      	asrs	r0, r0, #1
   d7786:	eb00 70d4 	add.w	r0, r0, r4, lsr #31
   d778a:	412c      	asrs	r4, r5
}
   d778c:	4283      	cmp	r3, r0
   d778e:	bfd4      	ite	le
   d7790:	4620      	movle	r0, r4
   d7792:	1c60      	addgt	r0, r4, #1
   d7794:	bd70      	pop	{r4, r5, r6, pc}
   d7796:	bf00      	nop
   d7798:	c0000001 	.word	0xc0000001
   d779c:	000eb13c 	.word	0x000eb13c
   d77a0:	000eb230 	.word	0x000eb230
   d77a4:	000eb1ee 	.word	0x000eb1ee
   d77a8:	000eb14a 	.word	0x000eb14a

000d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>:
// DO NOT USE THIS FUNCTION FOR NEW FUNCTIONALITY BEYOND IMPLEMENTING
// BROADCASTING.
//
// Same as Offset(), except takes as NdArrayDesc<N> instead of Dims<N>.
inline int SubscriptToIndex(const NdArrayDesc<4>& desc, int i0, int i1, int i2,
                            int i3) {
   d77ac:	b570      	push	{r4, r5, r6, lr}
  TFLITE_DCHECK(i0 >= 0 && i0 < desc.extents[0]);
   d77ae:	2900      	cmp	r1, #0
// DO NOT USE THIS FUNCTION FOR NEW FUNCTIONALITY BEYOND IMPLEMENTING
// BROADCASTING.
//
// Same as Offset(), except takes as NdArrayDesc<N> instead of Dims<N>.
inline int SubscriptToIndex(const NdArrayDesc<4>& desc, int i0, int i1, int i2,
                            int i3) {
   d77b0:	9c04      	ldr	r4, [sp, #16]
  TFLITE_DCHECK(i0 >= 0 && i0 < desc.extents[0]);
   d77b2:	db02      	blt.n	d77ba <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii+0xe>
   d77b4:	6805      	ldr	r5, [r0, #0]
   d77b6:	42a9      	cmp	r1, r5
   d77b8:	db01      	blt.n	d77be <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii+0x12>
   d77ba:	f00d fe9b 	bl	e54f4 <abort>
  TFLITE_DCHECK(i1 >= 0 && i1 < desc.extents[1]);
   d77be:	2a00      	cmp	r2, #0
   d77c0:	dbfb      	blt.n	d77ba <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii+0xe>
   d77c2:	6845      	ldr	r5, [r0, #4]
   d77c4:	42aa      	cmp	r2, r5
   d77c6:	daf8      	bge.n	d77ba <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii+0xe>
  TFLITE_DCHECK(i2 >= 0 && i2 < desc.extents[2]);
   d77c8:	2b00      	cmp	r3, #0
   d77ca:	dbf6      	blt.n	d77ba <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii+0xe>
   d77cc:	6885      	ldr	r5, [r0, #8]
   d77ce:	42ab      	cmp	r3, r5
   d77d0:	daf3      	bge.n	d77ba <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii+0xe>
  TFLITE_DCHECK(i3 >= 0 && i3 < desc.extents[3]);
   d77d2:	2c00      	cmp	r4, #0
   d77d4:	dbf1      	blt.n	d77ba <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii+0xe>
   d77d6:	68c5      	ldr	r5, [r0, #12]
   d77d8:	42ac      	cmp	r4, r5
   d77da:	daee      	bge.n	d77ba <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii+0xe>
  return i0 * desc.strides[0] + i1 * desc.strides[1] + i2 * desc.strides[2] +
         i3 * desc.strides[3];
   d77dc:	6945      	ldr	r5, [r0, #20]
   d77de:	6906      	ldr	r6, [r0, #16]
   d77e0:	4355      	muls	r5, r2
   d77e2:	6982      	ldr	r2, [r0, #24]
   d77e4:	69c0      	ldr	r0, [r0, #28]
   d77e6:	fb06 5101 	mla	r1, r6, r1, r5
   d77ea:	fb02 1303 	mla	r3, r2, r3, r1
}
   d77ee:	fb00 3004 	mla	r0, r0, r4, r3
   d77f2:	bd70      	pop	{r4, r5, r6, pc}

000d77f4 <_ZN6tflite13reference_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph>:
}

inline void Add(const ArithmeticParams& params,
                const RuntimeShape& input1_shape, const uint8* input1_data,
                const RuntimeShape& input2_shape, const uint8* input2_data,
                const RuntimeShape& output_shape, uint8* output_data) {
   d77f4:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d77f8:	4604      	mov	r4, r0
   d77fa:	4690      	mov	r8, r2
   d77fc:	4608      	mov	r0, r1
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
   d77fe:	6b22      	ldr	r2, [r4, #48]	; 0x30
   d7800:	6ae1      	ldr	r1, [r4, #44]	; 0x2c
}

inline void Add(const ArithmeticParams& params,
                const RuntimeShape& input1_shape, const uint8* input1_data,
                const RuntimeShape& input2_shape, const uint8* input2_data,
                const RuntimeShape& output_shape, uint8* output_data) {
   d7802:	9f0a      	ldr	r7, [sp, #40]	; 0x28
   d7804:	9e0c      	ldr	r6, [sp, #48]	; 0x30
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
   d7806:	4291      	cmp	r1, r2
   d7808:	dd01      	ble.n	d780e <_ZN6tflite13reference_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x1a>

inline void Add(const ArithmeticParams& params,
                const RuntimeShape& input1_shape, const uint8* input1_data,
                const RuntimeShape& input2_shape, const uint8* input2_data,
                const RuntimeShape& output_shape, uint8* output_data) {
  TFLITE_DCHECK_LE(params.quantized_activation_min,
   d780a:	f00d fe73 	bl	e54f4 <abort>
                   params.quantized_activation_max);
  const int flat_size =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   d780e:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   d7810:	4619      	mov	r1, r3
   d7812:	f7ff ff3c 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>

  TFLITE_DCHECK_GT(params.input1_offset, -256);
   d7816:	6862      	ldr	r2, [r4, #4]
   d7818:	f112 0fff 	cmn.w	r2, #255	; 0xff
                const RuntimeShape& input2_shape, const uint8* input2_data,
                const RuntimeShape& output_shape, uint8* output_data) {
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
  const int flat_size =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   d781c:	4681      	mov	r9, r0

  TFLITE_DCHECK_GT(params.input1_offset, -256);
   d781e:	dbf4      	blt.n	d780a <_ZN6tflite13reference_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x16>
  TFLITE_DCHECK_GT(params.input2_offset, -256);
  TFLITE_DCHECK_LT(params.input1_offset, 256);
   d7820:	2aff      	cmp	r2, #255	; 0xff
                   params.quantized_activation_max);
  const int flat_size =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);

  TFLITE_DCHECK_GT(params.input1_offset, -256);
  TFLITE_DCHECK_GT(params.input2_offset, -256);
   d7822:	68a3      	ldr	r3, [r4, #8]
  TFLITE_DCHECK_LT(params.input1_offset, 256);
   d7824:	dcf1      	bgt.n	d780a <_ZN6tflite13reference_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x16>
  TFLITE_DCHECK_LT(params.input2_offset, 256);
   d7826:	33ff      	adds	r3, #255	; 0xff
   d7828:	f5b3 7fff 	cmp.w	r3, #510	; 0x1fe
   d782c:	d8ed      	bhi.n	d780a <_ZN6tflite13reference_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x16>
   d782e:	2500      	movs	r5, #0
  TFLITE_DCHECK_GT(params.input1_offset, -256);
  TFLITE_DCHECK_GT(params.input2_offset, -256);
  TFLITE_DCHECK_LT(params.input1_offset, 256);
  TFLITE_DCHECK_LT(params.input2_offset, 256);

  for (int i = 0; i < size; ++i) {
   d7830:	45a9      	cmp	r9, r5
   d7832:	dd28      	ble.n	d7886 <_ZN6tflite13reference_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x92>
    const int32 input1_val = params.input1_offset + input1_data[i];
    const int32 input2_val = params.input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << params.left_shift);
    const int32 shifted_input2_val = input2_val * (1 << params.left_shift);
   d7834:	f817 a005 	ldrb.w	sl, [r7, r5]
   d7838:	68a3      	ldr	r3, [r4, #8]
  TFLITE_DCHECK_LT(params.input2_offset, 256);

  for (int i = 0; i < size; ++i) {
    const int32 input1_val = params.input1_offset + input1_data[i];
    const int32 input2_val = params.input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << params.left_shift);
   d783a:	69a0      	ldr	r0, [r4, #24]
    const int32 shifted_input2_val = input2_val * (1 << params.left_shift);
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, params.input1_multiplier, params.input1_shift);
   d783c:	f818 2005 	ldrb.w	r2, [r8, r5]
   d7840:	69e1      	ldr	r1, [r4, #28]

  for (int i = 0; i < size; ++i) {
    const int32 input1_val = params.input1_offset + input1_data[i];
    const int32 input2_val = params.input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << params.left_shift);
    const int32 shifted_input2_val = input2_val * (1 << params.left_shift);
   d7842:	4453      	add	r3, sl
   d7844:	fa03 fa00 	lsl.w	sl, r3, r0
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, params.input1_multiplier, params.input1_shift);
   d7848:	6863      	ldr	r3, [r4, #4]
   d784a:	4413      	add	r3, r2
   d784c:	fa03 f000 	lsl.w	r0, r3, r0
   d7850:	6a22      	ldr	r2, [r4, #32]
   d7852:	f7ff ff59 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, params.input2_multiplier, params.input2_shift);
   d7856:	6aa2      	ldr	r2, [r4, #40]	; 0x28
   d7858:	6a61      	ldr	r1, [r4, #36]	; 0x24
    const int32 input2_val = params.input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << params.left_shift);
    const int32 shifted_input2_val = input2_val * (1 << params.left_shift);
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, params.input1_multiplier, params.input1_shift);
   d785a:	4683      	mov	fp, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, params.input2_multiplier, params.input2_shift);
   d785c:	4650      	mov	r0, sl
   d785e:	f7ff ff53 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    const int32 raw_sum = scaled_input1_val + scaled_input2_val;
    const int32 raw_output =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
   d7862:	6962      	ldr	r2, [r4, #20]
   d7864:	6921      	ldr	r1, [r4, #16]
   d7866:	4458      	add	r0, fp
   d7868:	f7ff ff4e 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
            raw_sum, params.output_multiplier, params.output_shift) +
        params.output_offset;
    const int32 clamped_output =
        std::min(params.quantized_activation_max,
                 std::max(params.quantized_activation_min, raw_output));
    output_data[i] = static_cast<uint8>(clamped_output);
   d786c:	68e3      	ldr	r3, [r4, #12]
   d786e:	4418      	add	r0, r3
   d7870:	6ae3      	ldr	r3, [r4, #44]	; 0x2c
   d7872:	4298      	cmp	r0, r3
   d7874:	bfb8      	it	lt
   d7876:	4618      	movlt	r0, r3
   d7878:	6b23      	ldr	r3, [r4, #48]	; 0x30
   d787a:	4283      	cmp	r3, r0
   d787c:	bfa8      	it	ge
   d787e:	4603      	movge	r3, r0
   d7880:	5573      	strb	r3, [r6, r5]
  TFLITE_DCHECK_GT(params.input1_offset, -256);
  TFLITE_DCHECK_GT(params.input2_offset, -256);
  TFLITE_DCHECK_LT(params.input1_offset, 256);
  TFLITE_DCHECK_LT(params.input2_offset, 256);

  for (int i = 0; i < size; ++i) {
   d7882:	3501      	adds	r5, #1
   d7884:	e7d4      	b.n	d7830 <_ZN6tflite13reference_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x3c>
   d7886:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d788a <_ZN6tflite21reference_integer_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa>:
}

inline void Add(const ArithmeticParams& params,
                const RuntimeShape& input1_shape, const int8_t* input1_data,
                const RuntimeShape& input2_shape, const int8_t* input2_data,
                const RuntimeShape& output_shape, int8_t* output_data) {
   d788a:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d788e:	4604      	mov	r4, r0
   d7890:	4690      	mov	r8, r2
   d7892:	4608      	mov	r0, r1
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
   d7894:	6b22      	ldr	r2, [r4, #48]	; 0x30
   d7896:	6ae1      	ldr	r1, [r4, #44]	; 0x2c
}

inline void Add(const ArithmeticParams& params,
                const RuntimeShape& input1_shape, const int8_t* input1_data,
                const RuntimeShape& input2_shape, const int8_t* input2_data,
                const RuntimeShape& output_shape, int8_t* output_data) {
   d7898:	9f0a      	ldr	r7, [sp, #40]	; 0x28
   d789a:	9e0c      	ldr	r6, [sp, #48]	; 0x30
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
   d789c:	4291      	cmp	r1, r2
   d789e:	dd01      	ble.n	d78a4 <_ZN6tflite21reference_integer_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x1a>

inline void Add(const ArithmeticParams& params,
                const RuntimeShape& input1_shape, const int8_t* input1_data,
                const RuntimeShape& input2_shape, const int8_t* input2_data,
                const RuntimeShape& output_shape, int8_t* output_data) {
  TFLITE_DCHECK_LE(params.quantized_activation_min,
   d78a0:	f00d fe28 	bl	e54f4 <abort>
                   params.quantized_activation_max);
  const int flat_size =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   d78a4:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   d78a6:	4619      	mov	r1, r3
   d78a8:	f7ff fef1 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>

  const int32_t int8_max_value = std::numeric_limits<int8_t>::max();
  TFLITE_DCHECK_GE(params.input1_offset, -1 * int8_max_value);
   d78ac:	6862      	ldr	r2, [r4, #4]
   d78ae:	f112 0f7f 	cmn.w	r2, #127	; 0x7f
                const RuntimeShape& input2_shape, const int8_t* input2_data,
                const RuntimeShape& output_shape, int8_t* output_data) {
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
  const int flat_size =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   d78b2:	4681      	mov	r9, r0

  const int32_t int8_max_value = std::numeric_limits<int8_t>::max();
  TFLITE_DCHECK_GE(params.input1_offset, -1 * int8_max_value);
   d78b4:	dbf4      	blt.n	d78a0 <_ZN6tflite21reference_integer_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x16>
  TFLITE_DCHECK_GE(params.input2_offset, -1 * int8_max_value);
  TFLITE_DCHECK_LE(params.input1_offset, int8_max_value);
   d78b6:	2a7f      	cmp	r2, #127	; 0x7f
  const int flat_size =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);

  const int32_t int8_max_value = std::numeric_limits<int8_t>::max();
  TFLITE_DCHECK_GE(params.input1_offset, -1 * int8_max_value);
  TFLITE_DCHECK_GE(params.input2_offset, -1 * int8_max_value);
   d78b8:	68a3      	ldr	r3, [r4, #8]
  TFLITE_DCHECK_LE(params.input1_offset, int8_max_value);
   d78ba:	dcf1      	bgt.n	d78a0 <_ZN6tflite21reference_integer_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x16>
  TFLITE_DCHECK_LE(params.input2_offset, int8_max_value);
   d78bc:	337f      	adds	r3, #127	; 0x7f
   d78be:	2bfe      	cmp	r3, #254	; 0xfe
   d78c0:	d8ee      	bhi.n	d78a0 <_ZN6tflite21reference_integer_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x16>
   d78c2:	2500      	movs	r5, #0
  TFLITE_DCHECK_GE(params.input1_offset, -1 * int8_max_value);
  TFLITE_DCHECK_GE(params.input2_offset, -1 * int8_max_value);
  TFLITE_DCHECK_LE(params.input1_offset, int8_max_value);
  TFLITE_DCHECK_LE(params.input2_offset, int8_max_value);

  for (int i = 0; i < size; ++i) {
   d78c4:	45a9      	cmp	r9, r5
   d78c6:	dd28      	ble.n	d791a <_ZN6tflite21reference_integer_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x90>
    const int32 input1_val = params.input1_offset + input1_data[i];
    const int32 input2_val = params.input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << params.left_shift);
    const int32 shifted_input2_val = input2_val * (1 << params.left_shift);
   d78c8:	f917 a005 	ldrsb.w	sl, [r7, r5]
   d78cc:	68a3      	ldr	r3, [r4, #8]
  TFLITE_DCHECK_LE(params.input2_offset, int8_max_value);

  for (int i = 0; i < size; ++i) {
    const int32 input1_val = params.input1_offset + input1_data[i];
    const int32 input2_val = params.input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << params.left_shift);
   d78ce:	69a0      	ldr	r0, [r4, #24]
    const int32 shifted_input2_val = input2_val * (1 << params.left_shift);
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, params.input1_multiplier, params.input1_shift);
   d78d0:	f918 2005 	ldrsb.w	r2, [r8, r5]
   d78d4:	69e1      	ldr	r1, [r4, #28]

  for (int i = 0; i < size; ++i) {
    const int32 input1_val = params.input1_offset + input1_data[i];
    const int32 input2_val = params.input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << params.left_shift);
    const int32 shifted_input2_val = input2_val * (1 << params.left_shift);
   d78d6:	4453      	add	r3, sl
   d78d8:	fa03 fa00 	lsl.w	sl, r3, r0
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, params.input1_multiplier, params.input1_shift);
   d78dc:	6863      	ldr	r3, [r4, #4]
   d78de:	4413      	add	r3, r2
   d78e0:	fa03 f000 	lsl.w	r0, r3, r0
   d78e4:	6a22      	ldr	r2, [r4, #32]
   d78e6:	f7ff ff0f 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, params.input2_multiplier, params.input2_shift);
   d78ea:	6aa2      	ldr	r2, [r4, #40]	; 0x28
   d78ec:	6a61      	ldr	r1, [r4, #36]	; 0x24
    const int32 input2_val = params.input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << params.left_shift);
    const int32 shifted_input2_val = input2_val * (1 << params.left_shift);
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, params.input1_multiplier, params.input1_shift);
   d78ee:	4683      	mov	fp, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, params.input2_multiplier, params.input2_shift);
   d78f0:	4650      	mov	r0, sl
   d78f2:	f7ff ff09 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    const int32 raw_sum = scaled_input1_val + scaled_input2_val;
    const int32 raw_output =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
   d78f6:	6962      	ldr	r2, [r4, #20]
   d78f8:	6921      	ldr	r1, [r4, #16]
   d78fa:	4458      	add	r0, fp
   d78fc:	f7ff ff04 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
            raw_sum, params.output_multiplier, params.output_shift) +
        params.output_offset;
    const int32 clamped_output =
        std::min(params.quantized_activation_max,
                 std::max(params.quantized_activation_min, raw_output));
    output_data[i] = static_cast<int8_t>(clamped_output);
   d7900:	68e3      	ldr	r3, [r4, #12]
   d7902:	4418      	add	r0, r3
   d7904:	6ae3      	ldr	r3, [r4, #44]	; 0x2c
   d7906:	4298      	cmp	r0, r3
   d7908:	bfb8      	it	lt
   d790a:	4618      	movlt	r0, r3
   d790c:	6b23      	ldr	r3, [r4, #48]	; 0x30
   d790e:	4283      	cmp	r3, r0
   d7910:	bfa8      	it	ge
   d7912:	4603      	movge	r3, r0
   d7914:	5573      	strb	r3, [r6, r5]
  TFLITE_DCHECK_GE(params.input1_offset, -1 * int8_max_value);
  TFLITE_DCHECK_GE(params.input2_offset, -1 * int8_max_value);
  TFLITE_DCHECK_LE(params.input1_offset, int8_max_value);
  TFLITE_DCHECK_LE(params.input2_offset, int8_max_value);

  for (int i = 0; i < size; ++i) {
   d7916:	3501      	adds	r5, #1
   d7918:	e7d4      	b.n	d78c4 <_ZN6tflite21reference_integer_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x3a>
   d791a:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d791e <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE>:
//
// Returns true iff there is some sort of broadcast, which includes five-fold
// patterns and falling back to generic broadcast.
inline bool ProcessBroadcastShapes(const RuntimeShape& shape0,
                                   const RuntimeShape& shape1,
                                   tflite::ArithmeticParams* params) {
   d791e:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
   d7922:	b091      	sub	sp, #68	; 0x44
   d7924:	6804      	ldr	r4, [r0, #0]
   d7926:	680b      	ldr	r3, [r1, #0]
      dims_pointer_ = new int32[dimensions_count];
#endif  // TF_LITE_STATIC_MEMORY
    }
  }

  RuntimeShape(int shape_size, int32 value) : size_(0) {
   d7928:	af10      	add	r7, sp, #64	; 0x40
   d792a:	2600      	movs	r6, #0
   d792c:	429c      	cmp	r4, r3
   d792e:	f847 6d3c 	str.w	r6, [r7, #-60]!
   d7932:	bfb8      	it	lt
   d7934:	461c      	movlt	r4, r3
  const int dims_count =
      std::max(shape0.DimensionsCount(), shape1.DimensionsCount());

  params->broadcast_category = BroadcastableOpCategory::kGenericBroadcast;
   d7936:	2304      	movs	r3, #4
//
// Returns true iff there is some sort of broadcast, which includes five-fold
// patterns and falling back to generic broadcast.
inline bool ProcessBroadcastShapes(const RuntimeShape& shape0,
                                   const RuntimeShape& shape1,
                                   tflite::ArithmeticParams* params) {
   d7938:	4681      	mov	r9, r0
   d793a:	4688      	mov	r8, r1
  const int dims_count =
      std::max(shape0.DimensionsCount(), shape1.DimensionsCount());

  params->broadcast_category = BroadcastableOpCategory::kGenericBroadcast;
   d793c:	7013      	strb	r3, [r2, #0]
    Resize(shape_size);
   d793e:	4621      	mov	r1, r4
   d7940:	4638      	mov	r0, r7
//
// Returns true iff there is some sort of broadcast, which includes five-fold
// patterns and falling back to generic broadcast.
inline bool ProcessBroadcastShapes(const RuntimeShape& shape0,
                                   const RuntimeShape& shape1,
                                   tflite::ArithmeticParams* params) {
   d7942:	4615      	mov	r5, r2
   d7944:	f7ff fe3e 	bl	d75c4 <_ZN6tflite12RuntimeShape6ResizeEi>
    for (int i = 0; i < shape_size; ++i) {
   d7948:	42a6      	cmp	r6, r4
   d794a:	da06      	bge.n	d795a <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x3c>
      SetDim(i, value);
   d794c:	4631      	mov	r1, r6
   d794e:	2201      	movs	r2, #1
   d7950:	4638      	mov	r0, r7
   d7952:	f7ff fe26 	bl	d75a2 <_ZN6tflite12RuntimeShape6SetDimEil>
    }
  }

  RuntimeShape(int shape_size, int32 value) : size_(0) {
    Resize(shape_size);
    for (int i = 0; i < shape_size; ++i) {
   d7956:	3601      	adds	r6, #1
   d7958:	e7f6      	b.n	d7948 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x2a>
  // (a) as Dims<4>-dependent code is eliminated, the reliance on this should be
  // reduced, and (b) some kernels are stricly 4-D, but then the shapes of their
  // inputs should already be 4-D, so this function should not be needed.
  inline static RuntimeShape ExtendedShape(int new_shape_size,
                                           const RuntimeShape& shape) {
    return RuntimeShape(new_shape_size, shape, 1);
   d795a:	2301      	movs	r3, #1
   d795c:	464a      	mov	r2, r9
   d795e:	4621      	mov	r1, r4
   d7960:	a806      	add	r0, sp, #24
   d7962:	f7ff fe46 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d7966:	2301      	movs	r3, #1
   d7968:	4642      	mov	r2, r8
   d796a:	4621      	mov	r1, r4
   d796c:	a80b      	add	r0, sp, #44	; 0x2c
   d796e:	f7ff fe40 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
    }
    std::memcpy(DimsData(), other.DimsData(), sizeof(int32) * size_);
  }

  bool operator==(const RuntimeShape& comp) const {
    return this->size_ == comp.size_ &&
   d7972:	9a06      	ldr	r2, [sp, #24]
   d7974:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   d7976:	429a      	cmp	r2, r3
   d7978:	d10d      	bne.n	d7996 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x78>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   d797a:	2a04      	cmp	r2, #4
   d797c:	bfc7      	ittee	gt
   d797e:	9807      	ldrgt	r0, [sp, #28]
   d7980:	990c      	ldrgt	r1, [sp, #48]	; 0x30
   d7982:	a807      	addle	r0, sp, #28
   d7984:	a90c      	addle	r1, sp, #48	; 0x30
    std::memcpy(DimsData(), other.DimsData(), sizeof(int32) * size_);
  }

  bool operator==(const RuntimeShape& comp) const {
    return this->size_ == comp.size_ &&
           std::memcmp(DimsData(), comp.DimsData(), size_ * sizeof(int32)) == 0;
   d7986:	0092      	lsls	r2, r2, #2
   d7988:	f011 f8dc 	bl	e8b44 <memcmp>
    }
    std::memcpy(DimsData(), other.DimsData(), sizeof(int32) * size_);
  }

  bool operator==(const RuntimeShape& comp) const {
    return this->size_ == comp.size_ &&
   d798c:	b918      	cbnz	r0, d7996 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x78>
  auto extended_shape0 = RuntimeShape::ExtendedShape(dims_count, shape0);
  auto extended_shape1 = RuntimeShape::ExtendedShape(dims_count, shape1);

  // Check for "exact" match, implicitly accepting any scalar shapes.
  if (extended_shape0 == extended_shape1) {
    params->broadcast_category = BroadcastableOpCategory::kNonBroadcast;
   d798e:	2301      	movs	r3, #1
   d7990:	702b      	strb	r3, [r5, #0]

  if (params->broadcast_category !=
          BroadcastableOpCategory::kFirstInputBroadcastsFast &&
      params->broadcast_category !=
          BroadcastableOpCategory::kSecondInputBroadcastsFast) {
    return false;
   d7992:	2400      	movs	r4, #0
   d7994:	e08c      	b.n	d7ab0 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x192>
  if (extended_shape0 == extended_shape1) {
    params->broadcast_category = BroadcastableOpCategory::kNonBroadcast;
    return false;
  }

  for (int i = dims_count - 1; i >= 0; --i) {
   d7996:	3c01      	subs	r4, #1
   d7998:	4626      	mov	r6, r4
   d799a:	2e00      	cmp	r6, #0
   d799c:	db13      	blt.n	d79c6 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0xa8>
    if (extended_shape0.Dims(i) == extended_shape1.Dims(i)) {
   d799e:	4631      	mov	r1, r6
   d79a0:	a806      	add	r0, sp, #24
   d79a2:	f7ff fded 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d79a6:	4631      	mov	r1, r6
   d79a8:	4680      	mov	r8, r0
   d79aa:	a80b      	add	r0, sp, #44	; 0x2c
   d79ac:	f7ff fde8 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d79b0:	4580      	cmp	r8, r0
   d79b2:	d04d      	beq.n	d7a50 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x132>
      continue;
    } else if (extended_shape0.Dims(i) == 1) {
   d79b4:	f1b8 0f01 	cmp.w	r8, #1
   d79b8:	d101      	bne.n	d79be <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0xa0>
      params->broadcast_category =
          BroadcastableOpCategory::kFirstInputBroadcastsFast;
   d79ba:	2302      	movs	r3, #2
   d79bc:	e002      	b.n	d79c4 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0xa6>
      break;
    } else if (extended_shape1.Dims(i) == 1) {
   d79be:	2801      	cmp	r0, #1
   d79c0:	d143      	bne.n	d7a4a <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x12c>
      params->broadcast_category =
          BroadcastableOpCategory::kSecondInputBroadcastsFast;
   d79c2:	2303      	movs	r3, #3
   d79c4:	702b      	strb	r3, [r5, #0]
      params->broadcast_category = BroadcastableOpCategory::kGenericBroadcast;
      return true;
    }
  }

  if (params->broadcast_category !=
   d79c6:	782b      	ldrb	r3, [r5, #0]
   d79c8:	1e9a      	subs	r2, r3, #2
   d79ca:	2a01      	cmp	r2, #1
   d79cc:	d8e1      	bhi.n	d7992 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x74>
  // From this point it is assumed contractually that corresponding dimensions
  // in shape0 and shape1 are either (a) equal or (b) one or other equals 1.
  const bool swap_inputs = params->broadcast_category ==
                           BroadcastableOpCategory::kSecondInputBroadcastsFast;
  const RuntimeShape* shape_a =
      swap_inputs ? &extended_shape1 : &extended_shape0;
   d79ce:	2b03      	cmp	r3, #3
  const RuntimeShape* shape_b =
      swap_inputs ? &extended_shape0 : &extended_shape1;

  int i = dims_count - 1;
  params->broadcast_shape[0] = 1;
   d79d0:	f04f 0301 	mov.w	r3, #1
  // From this point it is assumed contractually that corresponding dimensions
  // in shape0 and shape1 are either (a) equal or (b) one or other equals 1.
  const bool swap_inputs = params->broadcast_category ==
                           BroadcastableOpCategory::kSecondInputBroadcastsFast;
  const RuntimeShape* shape_a =
      swap_inputs ? &extended_shape1 : &extended_shape0;
   d79d4:	bf07      	ittee	eq
   d79d6:	f10d 082c 	addeq.w	r8, sp, #44	; 0x2c
  const RuntimeShape* shape_b =
      swap_inputs ? &extended_shape0 : &extended_shape1;
   d79da:	ae06      	addeq	r6, sp, #24
  // From this point it is assumed contractually that corresponding dimensions
  // in shape0 and shape1 are either (a) equal or (b) one or other equals 1.
  const bool swap_inputs = params->broadcast_category ==
                           BroadcastableOpCategory::kSecondInputBroadcastsFast;
  const RuntimeShape* shape_a =
      swap_inputs ? &extended_shape1 : &extended_shape0;
   d79dc:	f10d 0818 	addne.w	r8, sp, #24
  const RuntimeShape* shape_b =
      swap_inputs ? &extended_shape0 : &extended_shape1;
   d79e0:	ae0b      	addne	r6, sp, #44	; 0x2c

  int i = dims_count - 1;
  params->broadcast_shape[0] = 1;
   d79e2:	63eb      	str	r3, [r5, #60]	; 0x3c
  params->broadcast_shape[1] = 1;
   d79e4:	642b      	str	r3, [r5, #64]	; 0x40
  params->broadcast_shape[2] = 1;
   d79e6:	646b      	str	r3, [r5, #68]	; 0x44
  params->broadcast_shape[3] = 1;
   d79e8:	64ab      	str	r3, [r5, #72]	; 0x48
  params->broadcast_shape[4] = 1;
   d79ea:	64eb      	str	r3, [r5, #76]	; 0x4c
  // y_0 is greedy: include dims if both or neither equal 1: in other words,
  // test for equality rather than (shape_a->Dims(i) != 1).
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
   d79ec:	2c00      	cmp	r4, #0
   d79ee:	db5e      	blt.n	d7aae <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x190>
   d79f0:	4621      	mov	r1, r4
   d79f2:	4640      	mov	r0, r8
   d79f4:	f7ff fdc4 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d79f8:	4621      	mov	r1, r4
   d79fa:	4681      	mov	r9, r0
   d79fc:	4630      	mov	r0, r6
   d79fe:	f7ff fdbf 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7a02:	4581      	cmp	r9, r0
   d7a04:	d026      	beq.n	d7a54 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x136>
    params->broadcast_shape[4] *= shape_b->Dims(i);
    --i;
  }
  // Here either input_a or input_b has dim of 1 (if i >= 0).  If it is input_b
  // that has the unit dimension, the next two loops are not entered.
  while (i >= 0 && shape_a->Dims(i) == 1) {
   d7a06:	4621      	mov	r1, r4
   d7a08:	4640      	mov	r0, r8
   d7a0a:	f7ff fdb9 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7a0e:	2801      	cmp	r0, #1
   d7a10:	d026      	beq.n	d7a60 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x142>
    params->broadcast_shape[3] *= shape_b->Dims(i);
    --i;
  }
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
   d7a12:	4621      	mov	r1, r4
   d7a14:	4640      	mov	r0, r8
   d7a16:	f7ff fdb3 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7a1a:	4621      	mov	r1, r4
   d7a1c:	4681      	mov	r9, r0
   d7a1e:	4630      	mov	r0, r6
   d7a20:	f7ff fdae 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7a24:	4581      	cmp	r9, r0
   d7a26:	d027      	beq.n	d7a78 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x15a>
    params->broadcast_shape[2] *= shape_a->Dims(i);
    --i;
  }
  // Here either input_a or input_b has dim of 1 (if i >= 0).
  while (i >= 0 && shape_b->Dims(i) == 1) {
   d7a28:	4621      	mov	r1, r4
   d7a2a:	4630      	mov	r0, r6
   d7a2c:	f7ff fda8 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7a30:	2801      	cmp	r0, #1
   d7a32:	d029      	beq.n	d7a88 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x16a>
    params->broadcast_shape[1] *= shape_a->Dims(i);
    --i;
  }
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
   d7a34:	4621      	mov	r1, r4
   d7a36:	4640      	mov	r0, r8
   d7a38:	f7ff fda2 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7a3c:	4621      	mov	r1, r4
   d7a3e:	4681      	mov	r9, r0
   d7a40:	4630      	mov	r0, r6
   d7a42:	f7ff fd9d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7a46:	4581      	cmp	r9, r0
   d7a48:	d02a      	beq.n	d7aa0 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x182>
          BroadcastableOpCategory::kSecondInputBroadcastsFast;
      break;
    } else {
      // This case is erroneous: there is a dimension that does not match and
      // is not a broadcast from one shape to the other.
      params->broadcast_category = BroadcastableOpCategory::kGenericBroadcast;
   d7a4a:	2304      	movs	r3, #4
   d7a4c:	702b      	strb	r3, [r5, #0]
   d7a4e:	e02e      	b.n	d7aae <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x190>
  if (extended_shape0 == extended_shape1) {
    params->broadcast_category = BroadcastableOpCategory::kNonBroadcast;
    return false;
  }

  for (int i = dims_count - 1; i >= 0; --i) {
   d7a50:	3e01      	subs	r6, #1
   d7a52:	e7a2      	b.n	d799a <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x7c>
  params->broadcast_shape[3] = 1;
  params->broadcast_shape[4] = 1;
  // y_0 is greedy: include dims if both or neither equal 1: in other words,
  // test for equality rather than (shape_a->Dims(i) != 1).
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
    params->broadcast_shape[4] *= shape_b->Dims(i);
   d7a54:	6ceb      	ldr	r3, [r5, #76]	; 0x4c
   d7a56:	fb09 f303 	mul.w	r3, r9, r3
   d7a5a:	64eb      	str	r3, [r5, #76]	; 0x4c
    --i;
   d7a5c:	3c01      	subs	r4, #1
  params->broadcast_shape[2] = 1;
  params->broadcast_shape[3] = 1;
  params->broadcast_shape[4] = 1;
  // y_0 is greedy: include dims if both or neither equal 1: in other words,
  // test for equality rather than (shape_a->Dims(i) != 1).
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
   d7a5e:	e7c5      	b.n	d79ec <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0xce>
    --i;
  }
  // Here either input_a or input_b has dim of 1 (if i >= 0).  If it is input_b
  // that has the unit dimension, the next two loops are not entered.
  while (i >= 0 && shape_a->Dims(i) == 1) {
    params->broadcast_shape[3] *= shape_b->Dims(i);
   d7a60:	4621      	mov	r1, r4
   d7a62:	4630      	mov	r0, r6
   d7a64:	f7ff fd8c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7a68:	6cab      	ldr	r3, [r5, #72]	; 0x48
    params->broadcast_shape[4] *= shape_b->Dims(i);
    --i;
  }
  // Here either input_a or input_b has dim of 1 (if i >= 0).  If it is input_b
  // that has the unit dimension, the next two loops are not entered.
  while (i >= 0 && shape_a->Dims(i) == 1) {
   d7a6a:	f114 34ff 	adds.w	r4, r4, #4294967295	; 0xffffffff
    params->broadcast_shape[3] *= shape_b->Dims(i);
   d7a6e:	fb00 f003 	mul.w	r0, r0, r3
   d7a72:	64a8      	str	r0, [r5, #72]	; 0x48
    params->broadcast_shape[4] *= shape_b->Dims(i);
    --i;
  }
  // Here either input_a or input_b has dim of 1 (if i >= 0).  If it is input_b
  // that has the unit dimension, the next two loops are not entered.
  while (i >= 0 && shape_a->Dims(i) == 1) {
   d7a74:	d2c7      	bcs.n	d7a06 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0xe8>
   d7a76:	e01a      	b.n	d7aae <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x190>
    params->broadcast_shape[3] *= shape_b->Dims(i);
    --i;
  }
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
    params->broadcast_shape[2] *= shape_a->Dims(i);
   d7a78:	6c6b      	ldr	r3, [r5, #68]	; 0x44
  // that has the unit dimension, the next two loops are not entered.
  while (i >= 0 && shape_a->Dims(i) == 1) {
    params->broadcast_shape[3] *= shape_b->Dims(i);
    --i;
  }
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
   d7a7a:	f114 34ff 	adds.w	r4, r4, #4294967295	; 0xffffffff
    params->broadcast_shape[2] *= shape_a->Dims(i);
   d7a7e:	fb09 f303 	mul.w	r3, r9, r3
   d7a82:	646b      	str	r3, [r5, #68]	; 0x44
  // that has the unit dimension, the next two loops are not entered.
  while (i >= 0 && shape_a->Dims(i) == 1) {
    params->broadcast_shape[3] *= shape_b->Dims(i);
    --i;
  }
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
   d7a84:	d2c5      	bcs.n	d7a12 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0xf4>
   d7a86:	e012      	b.n	d7aae <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x190>
    params->broadcast_shape[2] *= shape_a->Dims(i);
    --i;
  }
  // Here either input_a or input_b has dim of 1 (if i >= 0).
  while (i >= 0 && shape_b->Dims(i) == 1) {
    params->broadcast_shape[1] *= shape_a->Dims(i);
   d7a88:	4621      	mov	r1, r4
   d7a8a:	4640      	mov	r0, r8
   d7a8c:	f7ff fd78 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7a90:	6c2b      	ldr	r3, [r5, #64]	; 0x40
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
    params->broadcast_shape[2] *= shape_a->Dims(i);
    --i;
  }
  // Here either input_a or input_b has dim of 1 (if i >= 0).
  while (i >= 0 && shape_b->Dims(i) == 1) {
   d7a92:	f114 34ff 	adds.w	r4, r4, #4294967295	; 0xffffffff
    params->broadcast_shape[1] *= shape_a->Dims(i);
   d7a96:	fb00 f003 	mul.w	r0, r0, r3
   d7a9a:	6428      	str	r0, [r5, #64]	; 0x40
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
    params->broadcast_shape[2] *= shape_a->Dims(i);
    --i;
  }
  // Here either input_a or input_b has dim of 1 (if i >= 0).
  while (i >= 0 && shape_b->Dims(i) == 1) {
   d7a9c:	d2c4      	bcs.n	d7a28 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x10a>
   d7a9e:	e006      	b.n	d7aae <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x190>
    params->broadcast_shape[1] *= shape_a->Dims(i);
    --i;
  }
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
    params->broadcast_shape[0] *= shape_b->Dims(i);
   d7aa0:	6beb      	ldr	r3, [r5, #60]	; 0x3c
  // Here either input_a or input_b has dim of 1 (if i >= 0).
  while (i >= 0 && shape_b->Dims(i) == 1) {
    params->broadcast_shape[1] *= shape_a->Dims(i);
    --i;
  }
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
   d7aa2:	f114 34ff 	adds.w	r4, r4, #4294967295	; 0xffffffff
    params->broadcast_shape[0] *= shape_b->Dims(i);
   d7aa6:	fb09 f303 	mul.w	r3, r9, r3
   d7aaa:	63eb      	str	r3, [r5, #60]	; 0x3c
  // Here either input_a or input_b has dim of 1 (if i >= 0).
  while (i >= 0 && shape_b->Dims(i) == 1) {
    params->broadcast_shape[1] *= shape_a->Dims(i);
    --i;
  }
  while (i >= 0 && shape_a->Dims(i) == shape_b->Dims(i)) {
   d7aac:	d2c2      	bcs.n	d7a34 <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE+0x116>
  // Rarer case is when the broadcast dimensions cannot be handled by a fivefold
  // loop.
  if (i >= 0) {
    params->broadcast_category = BroadcastableOpCategory::kGenericBroadcast;
  }
  return true;
   d7aae:	2401      	movs	r4, #1

  params->broadcast_category = BroadcastableOpCategory::kGenericBroadcast;
  RuntimeShape scalar_shape(dims_count, 1);

  auto extended_shape0 = RuntimeShape::ExtendedShape(dims_count, shape0);
  auto extended_shape1 = RuntimeShape::ExtendedShape(dims_count, shape1);
   d7ab0:	a80b      	add	r0, sp, #44	; 0x2c
   d7ab2:	f7ff fd5a 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      std::max(shape0.DimensionsCount(), shape1.DimensionsCount());

  params->broadcast_category = BroadcastableOpCategory::kGenericBroadcast;
  RuntimeShape scalar_shape(dims_count, 1);

  auto extended_shape0 = RuntimeShape::ExtendedShape(dims_count, shape0);
   d7ab6:	a806      	add	r0, sp, #24
   d7ab8:	f7ff fd57 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                                   tflite::ArithmeticParams* params) {
  const int dims_count =
      std::max(shape0.DimensionsCount(), shape1.DimensionsCount());

  params->broadcast_category = BroadcastableOpCategory::kGenericBroadcast;
  RuntimeShape scalar_shape(dims_count, 1);
   d7abc:	4638      	mov	r0, r7
   d7abe:	f7ff fd54 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  // loop.
  if (i >= 0) {
    params->broadcast_category = BroadcastableOpCategory::kGenericBroadcast;
  }
  return true;
}
   d7ac2:	4620      	mov	r0, r4
   d7ac4:	b011      	add	sp, #68	; 0x44
   d7ac6:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}

000d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>:
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
}

inline RuntimeShape GetTensorShape(const TfLiteTensor* tensor) {
   d7aca:	b570      	push	{r4, r5, r6, lr}
   d7acc:	4604      	mov	r4, r0
  if (tensor == nullptr) {
   d7ace:	b909      	cbnz	r1, d7ad4 <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor+0xa>
  // larger shapes are separately allocated.
  static constexpr int kMaxSmallSize = 4;

  RuntimeShape& operator=(RuntimeShape const&) = delete;

  RuntimeShape() : size_(0) {}
   d7ad0:	6001      	str	r1, [r0, #0]
   d7ad2:	e010      	b.n	d7af6 <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor+0x2c>
    return RuntimeShape();
  }

  TfLiteIntArray* dims = tensor->dims;
  const int dims_size = dims->size;
   d7ad4:	688d      	ldr	r5, [r1, #8]
   d7ad6:	f855 6b04 	ldr.w	r6, [r5], #4
    for (int i = 0; i < shape_size; ++i) {
      SetDim(i, value);
    }
  }

  RuntimeShape(int dimensions_count, const int32* dims_data) : size_(0) {
   d7ada:	2300      	movs	r3, #0
   d7adc:	6003      	str	r3, [r0, #0]
#endif  // TF_LITE_STATIC_MEMORY
    }
  }

  inline void ReplaceWith(int dimensions_count, const int32* dims_data) {
    Resize(dimensions_count);
   d7ade:	4631      	mov	r1, r6
   d7ae0:	f7ff fd70 	bl	d75c4 <_ZN6tflite12RuntimeShape6ResizeEi>
      dims_[i] = val;
    }
  }

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   d7ae4:	6823      	ldr	r3, [r4, #0]
   d7ae6:	2b04      	cmp	r3, #4
   d7ae8:	bfcc      	ite	gt
   d7aea:	6860      	ldrgt	r0, [r4, #4]
   d7aec:	1d20      	addle	r0, r4, #4
  }

  inline void ReplaceWith(int dimensions_count, const int32* dims_data) {
    Resize(dimensions_count);
    int32* dst_dims = DimsData();
    std::memcpy(dst_dims, dims_data, dimensions_count * sizeof(int32));
   d7aee:	00b2      	lsls	r2, r6, #2
   d7af0:	4629      	mov	r1, r5
   d7af2:	f011 f836 	bl	e8b62 <memcpy>
  const int32_t* dims_data = reinterpret_cast<const int32_t*>(dims->data);
  return RuntimeShape(dims_size, dims_data);
}
   d7af6:	4620      	mov	r0, r4
   d7af8:	bd70      	pop	{r4, r5, r6, pc}
	...

000d7afc <_ZN6tflite3ops5micro3add15CalculateOpDataEP13TfLiteContextP15TfLiteAddParamsPK12TfLiteTensorS9_PS7_PNS2_6OpDataE>:

TfLiteStatus CalculateOpData(TfLiteContext* context, TfLiteAddParams* params,
                             const TfLiteTensor* input1,
                             const TfLiteTensor* input2, TfLiteTensor* output,
                             OpData* data) {
   d7afc:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
  data->requires_broadcast = !HaveSameShapes(input1, input2);
   d7b00:	4610      	mov	r0, r2
}

TfLiteStatus CalculateOpData(TfLiteContext* context, TfLiteAddParams* params,
                             const TfLiteTensor* input1,
                             const TfLiteTensor* input2, TfLiteTensor* output,
                             OpData* data) {
   d7b02:	ed2d 8b06 	vpush	{d8-d10}
   d7b06:	4688      	mov	r8, r1
  data->requires_broadcast = !HaveSameShapes(input1, input2);
   d7b08:	4619      	mov	r1, r3
}

TfLiteStatus CalculateOpData(TfLiteContext* context, TfLiteAddParams* params,
                             const TfLiteTensor* input1,
                             const TfLiteTensor* input2, TfLiteTensor* output,
                             OpData* data) {
   d7b0a:	461e      	mov	r6, r3
   d7b0c:	9d0e      	ldr	r5, [sp, #56]	; 0x38
   d7b0e:	9c0f      	ldr	r4, [sp, #60]	; 0x3c
   d7b10:	4617      	mov	r7, r2
  data->requires_broadcast = !HaveSameShapes(input1, input2);
   d7b12:	f00d f9c1 	bl	e4e98 <_ZN6tflite14HaveSameShapesEPK12TfLiteTensorS2_>
   d7b16:	f080 0001 	eor.w	r0, r0, #1
   d7b1a:	7020      	strb	r0, [r4, #0]

  if (output->type == kTfLiteUInt8 || output->type == kTfLiteInt8) {
   d7b1c:	782b      	ldrb	r3, [r5, #0]
   d7b1e:	2b03      	cmp	r3, #3
   d7b20:	d001      	beq.n	d7b26 <_ZN6tflite3ops5micro3add15CalculateOpDataEP13TfLiteContextP15TfLiteAddParamsPK12TfLiteTensorS9_PS7_PNS2_6OpDataE+0x2a>
   d7b22:	2b09      	cmp	r3, #9
   d7b24:	d16f      	bne.n	d7c06 <_ZN6tflite3ops5micro3add15CalculateOpDataEP13TfLiteContextP15TfLiteAddParamsPK12TfLiteTensorS9_PS7_PNS2_6OpDataE+0x10a>
    // 8bit -> 8bit general quantized path, with general rescalings
    data->input1_offset = -input1->params.zero_point;
   d7b26:	693b      	ldr	r3, [r7, #16]
   d7b28:	425b      	negs	r3, r3
   d7b2a:	62a3      	str	r3, [r4, #40]	; 0x28
    data->input2_offset = -input2->params.zero_point;
   d7b2c:	6933      	ldr	r3, [r6, #16]
   d7b2e:	425b      	negs	r3, r3
   d7b30:	62e3      	str	r3, [r4, #44]	; 0x2c
    data->output_offset = output->params.zero_point;
   d7b32:	692b      	ldr	r3, [r5, #16]
   d7b34:	6323      	str	r3, [r4, #48]	; 0x30
    data->left_shift = 20;
   d7b36:	2314      	movs	r3, #20
   d7b38:	6263      	str	r3, [r4, #36]	; 0x24
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
   d7b3a:	ed97 8a03 	vldr	s16, [r7, #12]
   d7b3e:	edd6 8a03 	vldr	s17, [r6, #12]
    const double twice_max_input_scale =
        2 * std::max(input1->params.scale, input2->params.scale);
   d7b42:	eeb4 8ae8 	vcmpe.f32	s16, s17
   d7b46:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d7b4a:	bf54      	ite	pl
   d7b4c:	eef0 7a48 	vmovpl.f32	s15, s16
   d7b50:	eef0 7a68 	vmovmi.f32	s15, s17
   d7b54:	ee77 7aa7 	vadd.f32	s15, s15, s15
        input2->params.scale / twice_max_input_scale;
    const double real_output_multiplier =
        twice_max_input_scale /
        ((1 << data->left_shift) * output->params.scale);

    QuantizeMultiplierSmallerThanOneExp(
   d7b58:	f104 0a04 	add.w	sl, r4, #4
    data->input1_offset = -input1->params.zero_point;
    data->input2_offset = -input2->params.zero_point;
    data->output_offset = output->params.zero_point;
    data->left_shift = 20;
    const double twice_max_input_scale =
        2 * std::max(input1->params.scale, input2->params.scale);
   d7b5c:	ee17 0a90 	vmov	r0, s15
   d7b60:	f010 fc0c 	bl	e837c <__aeabi_f2d>
   d7b64:	4606      	mov	r6, r0
   d7b66:	460f      	mov	r7, r1
    const double real_input1_multiplier =
        input1->params.scale / twice_max_input_scale;
    const double real_input2_multiplier =
        input2->params.scale / twice_max_input_scale;
   d7b68:	ee18 0a90 	vmov	r0, s17
   d7b6c:	f010 fc06 	bl	e837c <__aeabi_f2d>
   d7b70:	4632      	mov	r2, r6
   d7b72:	463b      	mov	r3, r7
   d7b74:	f010 fd80 	bl	e8678 <__aeabi_ddiv>
    const double real_output_multiplier =
        twice_max_input_scale /
        ((1 << data->left_shift) * output->params.scale);
   d7b78:	ed95 7a03 	vldr	s14, [r5, #12]
   d7b7c:	eddf 7a24 	vldr	s15, [pc, #144]	; d7c10 <_ZN6tflite3ops5micro3add15CalculateOpDataEP13TfLiteContextP15TfLiteAddParamsPK12TfLiteTensorS9_PS7_PNS2_6OpDataE+0x114>
   d7b80:	ee67 7a27 	vmul.f32	s15, s14, s15
    const double twice_max_input_scale =
        2 * std::max(input1->params.scale, input2->params.scale);
    const double real_input1_multiplier =
        input1->params.scale / twice_max_input_scale;
    const double real_input2_multiplier =
        input2->params.scale / twice_max_input_scale;
   d7b84:	ec41 0b1a 	vmov	d10, r0, r1
    const double real_output_multiplier =
        twice_max_input_scale /
        ((1 << data->left_shift) * output->params.scale);
   d7b88:	ee17 0a90 	vmov	r0, s15
   d7b8c:	f010 fbf6 	bl	e837c <__aeabi_f2d>
   d7b90:	4602      	mov	r2, r0
   d7b92:	460b      	mov	r3, r1
   d7b94:	4630      	mov	r0, r6
   d7b96:	4639      	mov	r1, r7
   d7b98:	f010 fd6e 	bl	e8678 <__aeabi_ddiv>
   d7b9c:	ec41 0b19 	vmov	d9, r0, r1

    QuantizeMultiplierSmallerThanOneExp(
        real_input1_multiplier, &data->input1_multiplier, &data->input1_shift);
   d7ba0:	ee18 0a10 	vmov	r0, s16
   d7ba4:	f010 fbea 	bl	e837c <__aeabi_f2d>
   d7ba8:	4632      	mov	r2, r6
   d7baa:	463b      	mov	r3, r7
   d7bac:	f010 fd64 	bl	e8678 <__aeabi_ddiv>
        input2->params.scale / twice_max_input_scale;
    const double real_output_multiplier =
        twice_max_input_scale /
        ((1 << data->left_shift) * output->params.scale);

    QuantizeMultiplierSmallerThanOneExp(
   d7bb0:	f104 0914 	add.w	r9, r4, #20
        real_input1_multiplier, &data->input1_multiplier, &data->input1_shift);
   d7bb4:	ec41 0b10 	vmov	d0, r0, r1
   d7bb8:	4651      	mov	r1, sl
   d7bba:	4648      	mov	r0, r9
   d7bbc:	f00d f9e0 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>

    QuantizeMultiplierSmallerThanOneExp(
        real_input2_multiplier, &data->input2_multiplier, &data->input2_shift);
   d7bc0:	eeb0 0a4a 	vmov.f32	s0, s20
   d7bc4:	eef0 0a6a 	vmov.f32	s1, s21
   d7bc8:	f104 0108 	add.w	r1, r4, #8
   d7bcc:	f104 0018 	add.w	r0, r4, #24
   d7bd0:	f00d f9d6 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>

    QuantizeMultiplierSmallerThanOneExp(
        real_output_multiplier, &data->output_multiplier, &data->output_shift);
   d7bd4:	eeb0 0a49 	vmov.f32	s0, s18
   d7bd8:	eef0 0a69 	vmov.f32	s1, s19
   d7bdc:	f104 0120 	add.w	r1, r4, #32
   d7be0:	f104 001c 	add.w	r0, r4, #28
   d7be4:	f00d f9cc 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>

    if (output->type == kTfLiteUInt8) {
   d7be8:	782b      	ldrb	r3, [r5, #0]
   d7bea:	f898 0000 	ldrb.w	r0, [r8]
   d7bee:	2b03      	cmp	r3, #3
      CalculateActivationRangeUint8(params->activation, output,
                                    &data->output_activation_min,
                                    &data->output_activation_max);
   d7bf0:	4629      	mov	r1, r5
   d7bf2:	f104 0310 	add.w	r3, r4, #16
   d7bf6:	f104 020c 	add.w	r2, r4, #12
        real_input2_multiplier, &data->input2_multiplier, &data->input2_shift);

    QuantizeMultiplierSmallerThanOneExp(
        real_output_multiplier, &data->output_multiplier, &data->output_shift);

    if (output->type == kTfLiteUInt8) {
   d7bfa:	d102      	bne.n	d7c02 <_ZN6tflite3ops5micro3add15CalculateOpDataEP13TfLiteContextP15TfLiteAddParamsPK12TfLiteTensorS9_PS7_PNS2_6OpDataE+0x106>
      CalculateActivationRangeUint8(params->activation, output,
                                    &data->output_activation_min,
                                    &data->output_activation_max);
   d7bfc:	f00d f846 	bl	e4c8c <_ZN6tflite29CalculateActivationRangeUint8E21TfLiteFusedActivationP12TfLiteTensorPlS3_>
   d7c00:	e001      	b.n	d7c06 <_ZN6tflite3ops5micro3add15CalculateOpDataEP13TfLiteContextP15TfLiteAddParamsPK12TfLiteTensorS9_PS7_PNS2_6OpDataE+0x10a>
    } else {
      CalculateActivationRangeInt8(params->activation, output,
                                   &data->output_activation_min,
                                   &data->output_activation_max);
   d7c02:	f00d f93d 	bl	e4e80 <_ZN6tflite28CalculateActivationRangeInt8E21TfLiteFusedActivationP12TfLiteTensorPlS3_>
    }
  }

  return kTfLiteOk;
}
   d7c06:	ecbd 8b06 	vpop	{d8-d10}
   d7c0a:	2000      	movs	r0, #0
   d7c0c:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
   d7c10:	49800000 	.word	0x49800000

000d7c14 <_ZN6tflite3ops5micro12Register_ADDEv>:
}  // namespace add

TfLiteRegistration* Register_ADD() {
  static TfLiteRegistration r = {add::Init, add::Free, add::Prepare, add::Eval};
  return &r;
}
   d7c14:	4800      	ldr	r0, [pc, #0]	; (d7c18 <_ZN6tflite3ops5micro12Register_ADDEv+0x4>)
   d7c16:	4770      	bx	lr
   d7c18:	2003bd10 	.word	0x2003bd10

000d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>:
    }
  }
}

template <int N>
inline void NdArrayDescsForElementwiseBroadcast(
   d7c1c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   d7c20:	460e      	mov	r6, r1
   d7c22:	b08a      	sub	sp, #40	; 0x28
   d7c24:	461d      	mov	r5, r3
    const RuntimeShape& input0_shape, const RuntimeShape& input1_shape,
    NdArrayDesc<N>* desc0_out, NdArrayDesc<N>* desc1_out) {
  TFLITE_DCHECK(desc0_out != nullptr);
   d7c26:	4614      	mov	r4, r2
   d7c28:	b90a      	cbnz	r2, d7c2e <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_+0x12>
   d7c2a:	f00d fc63 	bl	e54f4 <abort>
  TFLITE_DCHECK(desc1_out != nullptr);
   d7c2e:	2b00      	cmp	r3, #0
   d7c30:	d0fb      	beq.n	d7c2a <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_+0xe>
  // (a) as Dims<4>-dependent code is eliminated, the reliance on this should be
  // reduced, and (b) some kernels are stricly 4-D, but then the shapes of their
  // inputs should already be 4-D, so this function should not be needed.
  inline static RuntimeShape ExtendedShape(int new_shape_size,
                                           const RuntimeShape& shape) {
    return RuntimeShape(new_shape_size, shape, 1);
   d7c32:	4602      	mov	r2, r0
   d7c34:	2301      	movs	r3, #1
   d7c36:	2104      	movs	r1, #4
   d7c38:	4668      	mov	r0, sp
   d7c3a:	f7ff fcda 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d7c3e:	4632      	mov	r2, r6
   d7c40:	2301      	movs	r3, #1
   d7c42:	2104      	movs	r1, #4
   d7c44:	a805      	add	r0, sp, #20
   d7c46:	f7ff fcd4 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
  auto extended_input0_shape = RuntimeShape::ExtendedShape(N, input0_shape);
  auto extended_input1_shape = RuntimeShape::ExtendedShape(N, input1_shape);

  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
  int desc1_stride = 1;
   d7c4a:	f04f 0901 	mov.w	r9, #1
   d7c4e:	46a0      	mov	r8, r4
   d7c50:	462f      	mov	r7, r5
  for (int i = N - 1; i >= 0; --i) {
   d7c52:	2603      	movs	r6, #3

  auto extended_input0_shape = RuntimeShape::ExtendedShape(N, input0_shape);
  auto extended_input1_shape = RuntimeShape::ExtendedShape(N, input1_shape);

  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
   d7c54:	46ca      	mov	sl, r9
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
   d7c56:	4631      	mov	r1, r6
   d7c58:	4668      	mov	r0, sp
   d7c5a:	f7ff fc91 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    desc0_out->strides[i] = desc0_stride;
   d7c5e:	f8c8 a01c 	str.w	sl, [r8, #28]

  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
   d7c62:	f8c8 000c 	str.w	r0, [r8, #12]
    desc0_out->strides[i] = desc0_stride;
    desc0_stride *= extended_input0_shape.Dims(i);
   d7c66:	4631      	mov	r1, r6
   d7c68:	4668      	mov	r0, sp
   d7c6a:	f7ff fc89 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    desc1_out->extents[i] = extended_input1_shape.Dims(i);
   d7c6e:	4631      	mov	r1, r6
  int desc0_stride = 1;
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
    desc0_out->strides[i] = desc0_stride;
    desc0_stride *= extended_input0_shape.Dims(i);
   d7c70:	fb00 fa0a 	mul.w	sl, r0, sl
    desc1_out->extents[i] = extended_input1_shape.Dims(i);
   d7c74:	a805      	add	r0, sp, #20
   d7c76:	f7ff fc83 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    desc1_out->strides[i] = desc1_stride;
   d7c7a:	f8c7 901c 	str.w	r9, [r7, #28]
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
    desc0_out->strides[i] = desc0_stride;
    desc0_stride *= extended_input0_shape.Dims(i);
    desc1_out->extents[i] = extended_input1_shape.Dims(i);
   d7c7e:	60f8      	str	r0, [r7, #12]
    desc1_out->strides[i] = desc1_stride;
    desc1_stride *= extended_input1_shape.Dims(i);
   d7c80:	4631      	mov	r1, r6
   d7c82:	a805      	add	r0, sp, #20
   d7c84:	f7ff fc7c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  auto extended_input1_shape = RuntimeShape::ExtendedShape(N, input1_shape);

  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
   d7c88:	3e01      	subs	r6, #1
   d7c8a:	1c73      	adds	r3, r6, #1
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
    desc0_out->strides[i] = desc0_stride;
    desc0_stride *= extended_input0_shape.Dims(i);
    desc1_out->extents[i] = extended_input1_shape.Dims(i);
    desc1_out->strides[i] = desc1_stride;
    desc1_stride *= extended_input1_shape.Dims(i);
   d7c8c:	fb00 f909 	mul.w	r9, r0, r9
   d7c90:	f1a8 0804 	sub.w	r8, r8, #4
   d7c94:	f1a7 0704 	sub.w	r7, r7, #4
  auto extended_input1_shape = RuntimeShape::ExtendedShape(N, input1_shape);

  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
   d7c98:	d1dd      	bne.n	d7c56 <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_+0x3a>
   d7c9a:	2600      	movs	r6, #0
   d7c9c:	3510      	adds	r5, #16
   d7c9e:	3410      	adds	r4, #16
   d7ca0:	46b0      	mov	r8, r6

  // Walk over each dimension. If the extents are equal do nothing.
  // Otherwise, set the desc with extent 1 to have extent equal to the other and
  // stride 0.
  for (int i = 0; i < N; ++i) {
    const int extent0 = extended_input0_shape.Dims(i);
   d7ca2:	4631      	mov	r1, r6
   d7ca4:	4668      	mov	r0, sp
   d7ca6:	f7ff fc6b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    const int extent1 = extended_input1_shape.Dims(i);
   d7caa:	4631      	mov	r1, r6

  // Walk over each dimension. If the extents are equal do nothing.
  // Otherwise, set the desc with extent 1 to have extent equal to the other and
  // stride 0.
  for (int i = 0; i < N; ++i) {
    const int extent0 = extended_input0_shape.Dims(i);
   d7cac:	4607      	mov	r7, r0
    const int extent1 = extended_input1_shape.Dims(i);
   d7cae:	a805      	add	r0, sp, #20
   d7cb0:	f7ff fc66 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    if (extent0 != extent1) {
   d7cb4:	4287      	cmp	r7, r0
   d7cb6:	d00c      	beq.n	d7cd2 <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_+0xb6>
      if (extent0 == 1) {
   d7cb8:	2f01      	cmp	r7, #1
   d7cba:	d104      	bne.n	d7cc6 <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_+0xaa>
        desc0_out->strides[i] = 0;
   d7cbc:	f8c4 8000 	str.w	r8, [r4]
        desc0_out->extents[i] = extent1;
   d7cc0:	f844 0c10 	str.w	r0, [r4, #-16]
   d7cc4:	e005      	b.n	d7cd2 <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_+0xb6>
      } else {
        TFLITE_DCHECK_EQ(extent1, 1);
   d7cc6:	2801      	cmp	r0, #1
   d7cc8:	d1af      	bne.n	d7c2a <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_+0xe>
        desc1_out->strides[i] = 0;
   d7cca:	f8c5 8000 	str.w	r8, [r5]
        desc1_out->extents[i] = extent0;
   d7cce:	f845 7c10 	str.w	r7, [r5, #-16]
  }

  // Walk over each dimension. If the extents are equal do nothing.
  // Otherwise, set the desc with extent 1 to have extent equal to the other and
  // stride 0.
  for (int i = 0; i < N; ++i) {
   d7cd2:	3601      	adds	r6, #1
   d7cd4:	2e04      	cmp	r6, #4
   d7cd6:	f105 0504 	add.w	r5, r5, #4
   d7cda:	f104 0404 	add.w	r4, r4, #4
   d7cde:	d1e0      	bne.n	d7ca2 <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_+0x86>
    NdArrayDesc<N>* desc0_out, NdArrayDesc<N>* desc1_out) {
  TFLITE_DCHECK(desc0_out != nullptr);
  TFLITE_DCHECK(desc1_out != nullptr);

  auto extended_input0_shape = RuntimeShape::ExtendedShape(N, input0_shape);
  auto extended_input1_shape = RuntimeShape::ExtendedShape(N, input1_shape);
   d7ce0:	a805      	add	r0, sp, #20
   d7ce2:	f7ff fc42 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
    const RuntimeShape& input0_shape, const RuntimeShape& input1_shape,
    NdArrayDesc<N>* desc0_out, NdArrayDesc<N>* desc1_out) {
  TFLITE_DCHECK(desc0_out != nullptr);
  TFLITE_DCHECK(desc1_out != nullptr);

  auto extended_input0_shape = RuntimeShape::ExtendedShape(N, input0_shape);
   d7ce6:	4668      	mov	r0, sp
   d7ce8:	f7ff fc3f 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
        desc1_out->strides[i] = 0;
        desc1_out->extents[i] = extent0;
      }
    }
  }
}
   d7cec:	b00a      	add	sp, #40	; 0x28
   d7cee:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}

000d7cf2 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_Pf>:
                               const RuntimeShape& input1_shape,
                               const float* input1_data,
                               const RuntimeShape& input2_shape,
                               const float* input2_data,
                               const RuntimeShape& output_shape,
                               float* output_data) {
   d7cf2:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d7cf6:	b09b      	sub	sp, #108	; 0x6c
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
   d7cf8:	ad0a      	add	r5, sp, #40	; 0x28
                               const RuntimeShape& input1_shape,
                               const float* input1_data,
                               const RuntimeShape& input2_shape,
                               const float* input2_data,
                               const RuntimeShape& output_shape,
                               float* output_data) {
   d7cfa:	9203      	str	r2, [sp, #12]
   d7cfc:	4683      	mov	fp, r0
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
   d7cfe:	462a      	mov	r2, r5
                               const RuntimeShape& input1_shape,
                               const float* input1_data,
                               const RuntimeShape& input2_shape,
                               const float* input2_data,
                               const RuntimeShape& output_shape,
                               float* output_data) {
   d7d00:	4608      	mov	r0, r1
   d7d02:	4619      	mov	r1, r3
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
   d7d04:	ab12      	add	r3, sp, #72	; 0x48
   d7d06:	f7ff ff89 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
   d7d0a:	2301      	movs	r3, #1
   d7d0c:	9a25      	ldr	r2, [sp, #148]	; 0x94
   d7d0e:	2104      	movs	r1, #4
   d7d10:	a805      	add	r0, sp, #20
   d7d12:	f7ff fc6e 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
  // first dimension has smallest stride.
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   d7d16:	2400      	movs	r4, #0
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          output_data[Offset(extended_output_shape, b, y, x, c)] =
              ActivationFunctionWithMinMax(
                  input1_data[SubscriptToIndex(desc1, b, y, x, c)] +
   d7d18:	462f      	mov	r7, r5
  // first dimension has smallest stride.
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   d7d1a:	2100      	movs	r1, #0
   d7d1c:	a805      	add	r0, sp, #20
   d7d1e:	f7ff fc2f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7d22:	4284      	cmp	r4, r0
   d7d24:	da61      	bge.n	d7dea <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_Pf+0xf8>
   d7d26:	2500      	movs	r5, #0
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
   d7d28:	f10d 0914 	add.w	r9, sp, #20
   d7d2c:	2101      	movs	r1, #1
   d7d2e:	4648      	mov	r0, r9
   d7d30:	f7ff fc26 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7d34:	4285      	cmp	r5, r0
   d7d36:	da56      	bge.n	d7de6 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_Pf+0xf4>
   d7d38:	f04f 0800 	mov.w	r8, #0
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
   d7d3c:	464e      	mov	r6, r9
   d7d3e:	2102      	movs	r1, #2
   d7d40:	4630      	mov	r0, r6
   d7d42:	f7ff fc1d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7d46:	4580      	cmp	r8, r0
   d7d48:	da4b      	bge.n	d7de2 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_Pf+0xf0>
   d7d4a:	f04f 0900 	mov.w	r9, #0
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
   d7d4e:	2103      	movs	r1, #3
   d7d50:	4630      	mov	r0, r6
   d7d52:	f7ff fc15 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7d56:	4581      	cmp	r9, r0
   d7d58:	da40      	bge.n	d7ddc <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_Pf+0xea>
          output_data[Offset(extended_output_shape, b, y, x, c)] =
   d7d5a:	f8cd 9000 	str.w	r9, [sp]
   d7d5e:	4643      	mov	r3, r8
   d7d60:	462a      	mov	r2, r5
   d7d62:	4621      	mov	r1, r4
   d7d64:	4630      	mov	r0, r6
   d7d66:	f7ff fc70 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   d7d6a:	9b26      	ldr	r3, [sp, #152]	; 0x98
              ActivationFunctionWithMinMax(
                  input1_data[SubscriptToIndex(desc1, b, y, x, c)] +
   d7d6c:	f8cd 9000 	str.w	r9, [sp]
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          output_data[Offset(extended_output_shape, b, y, x, c)] =
   d7d70:	eb03 0380 	add.w	r3, r3, r0, lsl #2
   d7d74:	9302      	str	r3, [sp, #8]
              ActivationFunctionWithMinMax(
                  input1_data[SubscriptToIndex(desc1, b, y, x, c)] +
   d7d76:	462a      	mov	r2, r5
   d7d78:	4643      	mov	r3, r8
   d7d7a:	4621      	mov	r1, r4
   d7d7c:	4638      	mov	r0, r7
   d7d7e:	f7ff fd15 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                      input2_data[SubscriptToIndex(desc2, b, y, x, c)],
   d7d82:	f8cd 9000 	str.w	r9, [sp]
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          output_data[Offset(extended_output_shape, b, y, x, c)] =
              ActivationFunctionWithMinMax(
                  input1_data[SubscriptToIndex(desc1, b, y, x, c)] +
   d7d86:	4682      	mov	sl, r0
                      input2_data[SubscriptToIndex(desc2, b, y, x, c)],
   d7d88:	4643      	mov	r3, r8
   d7d8a:	462a      	mov	r2, r5
   d7d8c:	4621      	mov	r1, r4
   d7d8e:	a812      	add	r0, sp, #72	; 0x48
   d7d90:	f7ff fd0c 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          output_data[Offset(extended_output_shape, b, y, x, c)] =
              ActivationFunctionWithMinMax(
   d7d94:	9b03      	ldr	r3, [sp, #12]
                  input1_data[SubscriptToIndex(desc1, b, y, x, c)] +
                      input2_data[SubscriptToIndex(desc2, b, y, x, c)],
                  params.float_activation_min, params.float_activation_max);
   d7d96:	eddb 6a0e 	vldr	s13, [fp, #56]	; 0x38
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          output_data[Offset(extended_output_shape, b, y, x, c)] =
              ActivationFunctionWithMinMax(
   d7d9a:	eb03 0a8a 	add.w	sl, r3, sl, lsl #2
   d7d9e:	9b24      	ldr	r3, [sp, #144]	; 0x90
   d7da0:	edda 7a00 	vldr	s15, [sl]
   d7da4:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   d7da8:	ed90 7a00 	vldr	s14, [r0]
                  input1_data[SubscriptToIndex(desc1, b, y, x, c)] +
                      input2_data[SubscriptToIndex(desc2, b, y, x, c)],
                  params.float_activation_min, params.float_activation_max);
   d7dac:	9b02      	ldr	r3, [sp, #8]
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          output_data[Offset(extended_output_shape, b, y, x, c)] =
              ActivationFunctionWithMinMax(
   d7dae:	ee37 7a87 	vadd.f32	s14, s15, s14
                  input1_data[SubscriptToIndex(desc1, b, y, x, c)] +
                      input2_data[SubscriptToIndex(desc2, b, y, x, c)],
                  params.float_activation_min, params.float_activation_max);
   d7db2:	eddb 7a0d 	vldr	s15, [fp, #52]	; 0x34
	return __b;
      return __a;
   d7db6:	eeb4 7ae7 	vcmpe.f32	s14, s15
   d7dba:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d7dbe:	bf58      	it	pl
   d7dc0:	eef0 7a47 	vmovpl.f32	s15, s14
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
   d7dc4:	eef4 6a67 	vcmp.f32	s13, s15
   d7dc8:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d7dcc:	bf48      	it	mi
   d7dce:	eef0 7a66 	vmovmi.f32	s15, s13
   d7dd2:	edc3 7a00 	vstr	s15, [r3]
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
   d7dd6:	f109 0901 	add.w	r9, r9, #1
   d7dda:	e7b8      	b.n	d7d4e <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_Pf+0x5c>
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
   d7ddc:	f108 0801 	add.w	r8, r8, #1
   d7de0:	e7ad      	b.n	d7d3e <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_Pf+0x4c>
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
   d7de2:	3501      	adds	r5, #1
   d7de4:	e7a0      	b.n	d7d28 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_Pf+0x36>
  // first dimension has smallest stride.
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   d7de6:	3401      	adds	r4, #1
   d7de8:	e797      	b.n	d7d1a <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_Pf+0x28>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
  const RuntimeShape extended_output_shape =
      RuntimeShape::ExtendedShape(4, output_shape);
   d7dea:	a805      	add	r0, sp, #20
   d7dec:	f7ff fbbd 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                  params.float_activation_min, params.float_activation_max);
        }
      }
    }
  }
}
   d7df0:	b01b      	add	sp, #108	; 0x6c
   d7df2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	...

000d7df8 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_>:
  return kTfLiteOk;
}

void EvalAdd(TfLiteContext* context, TfLiteNode* node, TfLiteAddParams* params,
             const OpData* data, const TfLiteTensor* input1,
             const TfLiteTensor* input2, TfLiteTensor* output) {
   d7df8:	b5f0      	push	{r4, r5, r6, r7, lr}
  float output_activation_min, output_activation_max;
  CalculateActivationRange(params->activation, &output_activation_min,
   d7dfa:	7812      	ldrb	r2, [r2, #0]
  return kTfLiteOk;
}

void EvalAdd(TfLiteContext* context, TfLiteNode* node, TfLiteAddParams* params,
             const OpData* data, const TfLiteTensor* input1,
             const TfLiteTensor* input2, TfLiteTensor* output) {
   d7dfc:	b0a9      	sub	sp, #164	; 0xa4
// Calculates the useful range of an activation layer given its activation
// tensor.a
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
   d7dfe:	2a01      	cmp	r2, #1
   d7e00:	9e2e      	ldr	r6, [sp, #184]	; 0xb8
   d7e02:	9d2f      	ldr	r5, [sp, #188]	; 0xbc
   d7e04:	9c30      	ldr	r4, [sp, #192]	; 0xc0
   d7e06:	d011      	beq.n	d7e2c <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x34>
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
   d7e08:	2a03      	cmp	r2, #3
   d7e0a:	d012      	beq.n	d7e32 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x3a>
  } else if (activation == kTfLiteActRelu1) {
    *activation_min = -1;
    *activation_max = 1;
  } else {
    *activation_min = std::numeric_limits<T>::lowest();
    *activation_max = std::numeric_limits<T>::max();
   d7e0c:	ed9f 7a3c 	vldr	s14, [pc, #240]	; d7f00 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x108>
   d7e10:	eddf 6a3c 	vldr	s13, [pc, #240]	; d7f04 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x10c>
   d7e14:	2a02      	cmp	r2, #2
   d7e16:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   d7e1a:	bf18      	it	ne
   d7e1c:	eef0 7a47 	vmovne.f32	s15, s14
   d7e20:	eebf 7a00 	vmov.f32	s14, #240	; 0xbf800000 -1.0
   d7e24:	bf18      	it	ne
   d7e26:	eeb0 7a66 	vmovne.f32	s14, s13
   d7e2a:	e006      	b.n	d7e3a <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x42>
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
   d7e2c:	eddf 7a34 	vldr	s15, [pc, #208]	; d7f00 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x108>
   d7e30:	e001      	b.n	d7e36 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x3e>
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
    *activation_max = 6;
   d7e32:	eef1 7a08 	vmov.f32	s15, #24	; 0x40c00000  6.0
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
   d7e36:	ed9f 7a34 	vldr	s14, [pc, #208]	; d7f08 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x110>
#define TF_LITE_ADD(opname)                                                   \
  reference_ops::opname(op_params, GetTensorShape(input1),                    \
                        GetTensorData<float>(input1), GetTensorShape(input2), \
                        GetTensorData<float>(input2), GetTensorShape(output), \
                        GetTensorData<float>(output))
  if (data->requires_broadcast) {
   d7e3a:	781b      	ldrb	r3, [r3, #0]
  int output_shift;
};

template <typename P>
inline void SetActivationParams(float min, float max, P* params) {
  params->float_activation_min = min;
   d7e3c:	ed8d 7a21 	vstr	s14, [sp, #132]	; 0x84
  params->float_activation_max = max;
   d7e40:	edcd 7a22 	vstr	s15, [sp, #136]	; 0x88
   d7e44:	af0f      	add	r7, sp, #60	; 0x3c
    TF_LITE_ADD(BroadcastAdd4DSlow);
   d7e46:	4631      	mov	r1, r6
   d7e48:	a805      	add	r0, sp, #20
#define TF_LITE_ADD(opname)                                                   \
  reference_ops::opname(op_params, GetTensorShape(input1),                    \
                        GetTensorData<float>(input1), GetTensorShape(input2), \
                        GetTensorData<float>(input2), GetTensorShape(output), \
                        GetTensorData<float>(output))
  if (data->requires_broadcast) {
   d7e4a:	b1cb      	cbz	r3, d7e80 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x88>
    TF_LITE_ADD(BroadcastAdd4DSlow);
   d7e4c:	f7ff fe3d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   d7e50:	b106      	cbz	r6, d7e54 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x5c>
   d7e52:	6876      	ldr	r6, [r6, #4]
   d7e54:	4629      	mov	r1, r5
   d7e56:	a80a      	add	r0, sp, #40	; 0x28
   d7e58:	f7ff fe37 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d7e5c:	b105      	cbz	r5, d7e60 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x68>
   d7e5e:	686d      	ldr	r5, [r5, #4]
   d7e60:	4621      	mov	r1, r4
   d7e62:	4638      	mov	r0, r7
   d7e64:	f7ff fe31 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   d7e68:	b104      	cbz	r4, d7e6c <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x74>
   d7e6a:	6864      	ldr	r4, [r4, #4]
   d7e6c:	9402      	str	r4, [sp, #8]
   d7e6e:	e88d 00a0 	stmia.w	sp, {r5, r7}
   d7e72:	ab0a      	add	r3, sp, #40	; 0x28
   d7e74:	4632      	mov	r2, r6
   d7e76:	a905      	add	r1, sp, #20
   d7e78:	a814      	add	r0, sp, #80	; 0x50
   d7e7a:	f7ff ff3a 	bl	d7cf2 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_Pf>
   d7e7e:	e033      	b.n	d7ee8 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0xf0>
  } else {
    TF_LITE_ADD(Add);
   d7e80:	f7ff fe23 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   d7e84:	b106      	cbz	r6, d7e88 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x90>
   d7e86:	6876      	ldr	r6, [r6, #4]
   d7e88:	4629      	mov	r1, r5
   d7e8a:	a80a      	add	r0, sp, #40	; 0x28
   d7e8c:	f7ff fe1d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d7e90:	b105      	cbz	r5, d7e94 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x9c>
   d7e92:	686d      	ldr	r5, [r5, #4]
   d7e94:	4621      	mov	r1, r4
   d7e96:	4638      	mov	r0, r7
   d7e98:	f7ff fe17 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   d7e9c:	b104      	cbz	r4, d7ea0 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0xa8>
   d7e9e:	6864      	ldr	r4, [r4, #4]

inline void Add(const ArithmeticParams& params,
                const RuntimeShape& input1_shape, const float* input1_data,
                const RuntimeShape& input2_shape, const float* input2_data,
                const RuntimeShape& output_shape, float* output_data) {
  const int size = MatchingFlatSize(input1_shape, input2_shape, output_shape);
   d7ea0:	463a      	mov	r2, r7
   d7ea2:	a90a      	add	r1, sp, #40	; 0x28
   d7ea4:	a805      	add	r0, sp, #20
   d7ea6:	f7ff fbf2 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
  for (int i = 0; i < size; i++) {
   d7eaa:	2300      	movs	r3, #0
   d7eac:	4298      	cmp	r0, r3
   d7eae:	dd1b      	ble.n	d7ee8 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0xf0>
    auto x = input1_data[i] + input2_data[i];
   d7eb0:	ecf6 7a01 	vldmia	r6!, {s15}
   d7eb4:	ecb5 7a01 	vldmia	r5!, {s14}
    output_data[i] = ActivationFunctionWithMinMax(
        x, params.float_activation_min, params.float_activation_max);
   d7eb8:	eddd 6a22 	vldr	s13, [sp, #136]	; 0x88
                const RuntimeShape& input1_shape, const float* input1_data,
                const RuntimeShape& input2_shape, const float* input2_data,
                const RuntimeShape& output_shape, float* output_data) {
  const int size = MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int i = 0; i < size; i++) {
    auto x = input1_data[i] + input2_data[i];
   d7ebc:	ee37 7a87 	vadd.f32	s14, s15, s14
    output_data[i] = ActivationFunctionWithMinMax(
        x, params.float_activation_min, params.float_activation_max);
   d7ec0:	eddd 7a21 	vldr	s15, [sp, #132]	; 0x84
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
	return __b;
      return __a;
   d7ec4:	eeb4 7ae7 	vcmpe.f32	s14, s15
   d7ec8:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d7ecc:	bf58      	it	pl
   d7ece:	eef0 7a47 	vmovpl.f32	s15, s14
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
   d7ed2:	eef4 6a67 	vcmp.f32	s13, s15
   d7ed6:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d7eda:	bf48      	it	mi
   d7edc:	eef0 7a66 	vmovmi.f32	s15, s13
   d7ee0:	ece4 7a01 	vstmia	r4!, {s15}
inline void Add(const ArithmeticParams& params,
                const RuntimeShape& input1_shape, const float* input1_data,
                const RuntimeShape& input2_shape, const float* input2_data,
                const RuntimeShape& output_shape, float* output_data) {
  const int size = MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int i = 0; i < size; i++) {
   d7ee4:	3301      	adds	r3, #1
   d7ee6:	e7e1      	b.n	d7eac <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0xb4>
   d7ee8:	4638      	mov	r0, r7
   d7eea:	f7ff fb3e 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   d7eee:	a80a      	add	r0, sp, #40	; 0x28
   d7ef0:	f7ff fb3b 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   d7ef4:	a805      	add	r0, sp, #20
   d7ef6:	f7ff fb38 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  }
#undef TF_LITE_ADD
}
   d7efa:	b029      	add	sp, #164	; 0xa4
   d7efc:	bdf0      	pop	{r4, r5, r6, r7, pc}
   d7efe:	bf00      	nop
   d7f00:	7f7fffff 	.word	0x7f7fffff
   d7f04:	ff7fffff 	.word	0xff7fffff
   d7f08:	00000000 	.word	0x00000000

000d7f0c <_ZN6tflite21reference_integer_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa>:
                               const RuntimeShape& input1_shape,
                               const int8_t* input1_data,
                               const RuntimeShape& input2_shape,
                               const int8_t* input2_data,
                               const RuntimeShape& output_shape,
                               int8_t* output_data) {
   d7f0c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d7f10:	b09b      	sub	sp, #108	; 0x6c
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
   d7f12:	ae0a      	add	r6, sp, #40	; 0x28
                               const RuntimeShape& input1_shape,
                               const int8_t* input1_data,
                               const RuntimeShape& input2_shape,
                               const int8_t* input2_data,
                               const RuntimeShape& output_shape,
                               int8_t* output_data) {
   d7f14:	4604      	mov	r4, r0
   d7f16:	4693      	mov	fp, r2
   d7f18:	4608      	mov	r0, r1
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
   d7f1a:	4632      	mov	r2, r6
                               const RuntimeShape& input1_shape,
                               const int8_t* input1_data,
                               const RuntimeShape& input2_shape,
                               const int8_t* input2_data,
                               const RuntimeShape& output_shape,
                               int8_t* output_data) {
   d7f1c:	4619      	mov	r1, r3
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
   d7f1e:	ab12      	add	r3, sp, #72	; 0x48
   d7f20:	f7ff fe7c 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
  // (a) as Dims<4>-dependent code is eliminated, the reliance on this should be
  // reduced, and (b) some kernels are stricly 4-D, but then the shapes of their
  // inputs should already be 4-D, so this function should not be needed.
  inline static RuntimeShape ExtendedShape(int new_shape_size,
                                           const RuntimeShape& shape) {
    return RuntimeShape(new_shape_size, shape, 1);
   d7f24:	2301      	movs	r3, #1
   d7f26:	9a25      	ldr	r2, [sp, #148]	; 0x94
   d7f28:	2104      	movs	r1, #4
   d7f2a:	a805      	add	r0, sp, #20
   d7f2c:	f7ff fb61 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
  // first dimension has smallest stride.
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   d7f30:	2500      	movs	r5, #0
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          const int32_t input1_val =
              params.input1_offset +
              input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   d7f32:	9602      	str	r6, [sp, #8]
  // first dimension has smallest stride.
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   d7f34:	2100      	movs	r1, #0
   d7f36:	a805      	add	r0, sp, #20
   d7f38:	f7ff fb22 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7f3c:	4285      	cmp	r5, r0
   d7f3e:	da65      	bge.n	d800c <_ZN6tflite21reference_integer_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x100>
   d7f40:	2600      	movs	r6, #0
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
   d7f42:	f10d 0814 	add.w	r8, sp, #20
   d7f46:	2101      	movs	r1, #1
   d7f48:	4640      	mov	r0, r8
   d7f4a:	f7ff fb19 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7f4e:	4286      	cmp	r6, r0
   d7f50:	da5a      	bge.n	d8008 <_ZN6tflite21reference_integer_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0xfc>
   d7f52:	2700      	movs	r7, #0
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
   d7f54:	2102      	movs	r1, #2
   d7f56:	4640      	mov	r0, r8
   d7f58:	f7ff fb12 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7f5c:	4287      	cmp	r7, r0
   d7f5e:	da51      	bge.n	d8004 <_ZN6tflite21reference_integer_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0xf8>
   d7f60:	f04f 0900 	mov.w	r9, #0
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
   d7f64:	2103      	movs	r1, #3
   d7f66:	4640      	mov	r0, r8
   d7f68:	f7ff fb0a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d7f6c:	4581      	cmp	r9, r0
   d7f6e:	da47      	bge.n	d8000 <_ZN6tflite21reference_integer_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0xf4>
          const int32_t input1_val =
              params.input1_offset +
              input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   d7f70:	f8cd 9000 	str.w	r9, [sp]
   d7f74:	463b      	mov	r3, r7
   d7f76:	4632      	mov	r2, r6
   d7f78:	4629      	mov	r1, r5
   d7f7a:	9802      	ldr	r0, [sp, #8]
   d7f7c:	f7ff fc16 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   d7f80:	6863      	ldr	r3, [r4, #4]
   d7f82:	f91b a000 	ldrsb.w	sl, [fp, r0]
          const int32_t input2_val =
              params.input2_offset +
              input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   d7f86:	f8cd 9000 	str.w	r9, [sp]
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          const int32_t input1_val =
              params.input1_offset +
              input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   d7f8a:	449a      	add	sl, r3
          const int32_t input2_val =
              params.input2_offset +
              input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   d7f8c:	4632      	mov	r2, r6
   d7f8e:	463b      	mov	r3, r7
   d7f90:	4629      	mov	r1, r5
   d7f92:	a812      	add	r0, sp, #72	; 0x48
   d7f94:	f7ff fc0a 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32_t shifted_input1_val =
              input1_val * (1 << params.left_shift);
          const int32_t shifted_input2_val =
              input2_val * (1 << params.left_shift);
   d7f98:	9b24      	ldr	r3, [sp, #144]	; 0x90
              input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32_t input2_val =
              params.input2_offset +
              input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32_t shifted_input1_val =
              input1_val * (1 << params.left_shift);
   d7f9a:	f8d4 e018 	ldr.w	lr, [r4, #24]
          const int32_t shifted_input2_val =
              input2_val * (1 << params.left_shift);
   d7f9e:	561a      	ldrsb	r2, [r3, r0]
   d7fa0:	68a3      	ldr	r3, [r4, #8]
          const int32_t scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, params.input1_multiplier,
                  params.input1_shift);
   d7fa2:	69e1      	ldr	r1, [r4, #28]
              params.input2_offset +
              input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32_t shifted_input1_val =
              input1_val * (1 << params.left_shift);
          const int32_t shifted_input2_val =
              input2_val * (1 << params.left_shift);
   d7fa4:	4413      	add	r3, r2
   d7fa6:	fa03 f30e 	lsl.w	r3, r3, lr
          const int32_t scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, params.input1_multiplier,
                  params.input1_shift);
   d7faa:	fa0a f00e 	lsl.w	r0, sl, lr
   d7fae:	6a22      	ldr	r2, [r4, #32]
              params.input2_offset +
              input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32_t shifted_input1_val =
              input1_val * (1 << params.left_shift);
          const int32_t shifted_input2_val =
              input2_val * (1 << params.left_shift);
   d7fb0:	9303      	str	r3, [sp, #12]
          const int32_t scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, params.input1_multiplier,
                  params.input1_shift);
   d7fb2:	f7ff fba9 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32_t scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, params.input2_multiplier,
                  params.input2_shift);
   d7fb6:	9b03      	ldr	r3, [sp, #12]
   d7fb8:	6aa2      	ldr	r2, [r4, #40]	; 0x28
   d7fba:	6a61      	ldr	r1, [r4, #36]	; 0x24
          const int32_t shifted_input2_val =
              input2_val * (1 << params.left_shift);
          const int32_t scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, params.input1_multiplier,
                  params.input1_shift);
   d7fbc:	4682      	mov	sl, r0
          const int32_t scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, params.input2_multiplier,
                  params.input2_shift);
   d7fbe:	4618      	mov	r0, r3
   d7fc0:	f7ff fba2 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32_t raw_sum = scaled_input1_val + scaled_input2_val;
          const int32_t raw_output =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
   d7fc4:	6962      	ldr	r2, [r4, #20]
   d7fc6:	6921      	ldr	r1, [r4, #16]
   d7fc8:	4450      	add	r0, sl
   d7fca:	f7ff fb9d 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
   d7fce:	68e3      	ldr	r3, [r4, #12]
                  raw_sum, params.output_multiplier, params.output_shift) +
              params.output_offset;
          const int32_t clamped_output =
              std::min(params.quantized_activation_max,
                       std::max(params.quantized_activation_min, raw_output));
          output_data[Offset(extended_output_shape, b, y, x, c)] =
   d7fd0:	f8cd 9000 	str.w	r9, [sp]
   d7fd4:	4418      	add	r0, r3
   d7fd6:	6ae3      	ldr	r3, [r4, #44]	; 0x2c
   d7fd8:	4283      	cmp	r3, r0
   d7fda:	bfb8      	it	lt
   d7fdc:	4603      	movlt	r3, r0
   d7fde:	6b20      	ldr	r0, [r4, #48]	; 0x30
   d7fe0:	4283      	cmp	r3, r0
   d7fe2:	bfa8      	it	ge
   d7fe4:	4603      	movge	r3, r0
   d7fe6:	469a      	mov	sl, r3
   d7fe8:	4632      	mov	r2, r6
   d7fea:	463b      	mov	r3, r7
   d7fec:	4629      	mov	r1, r5
   d7fee:	4640      	mov	r0, r8
   d7ff0:	f7ff fb2b 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              static_cast<int8_t>(clamped_output);
   d7ff4:	9b26      	ldr	r3, [sp, #152]	; 0x98
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
   d7ff6:	f109 0901 	add.w	r9, r9, #1
              params.output_offset;
          const int32_t clamped_output =
              std::min(params.quantized_activation_max,
                       std::max(params.quantized_activation_min, raw_output));
          output_data[Offset(extended_output_shape, b, y, x, c)] =
              static_cast<int8_t>(clamped_output);
   d7ffa:	f803 a000 	strb.w	sl, [r3, r0]
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
   d7ffe:	e7b1      	b.n	d7f64 <_ZN6tflite21reference_integer_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x58>
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
   d8000:	3701      	adds	r7, #1
   d8002:	e7a7      	b.n	d7f54 <_ZN6tflite21reference_integer_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x48>
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
   d8004:	3601      	adds	r6, #1
   d8006:	e79c      	b.n	d7f42 <_ZN6tflite21reference_integer_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x36>
  // first dimension has smallest stride.
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   d8008:	3501      	adds	r5, #1
   d800a:	e793      	b.n	d7f34 <_ZN6tflite21reference_integer_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa+0x28>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
  const RuntimeShape extended_output_shape =
      RuntimeShape::ExtendedShape(4, output_shape);
   d800c:	a805      	add	r0, sp, #20
   d800e:	f7ff faac 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              static_cast<int8_t>(clamped_output);
        }
      }
    }
  }
}
   d8012:	b01b      	add	sp, #108	; 0x6c
   d8014:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d8018 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph>:
                               const RuntimeShape& input1_shape,
                               const uint8* input1_data,
                               const RuntimeShape& input2_shape,
                               const uint8* input2_data,
                               const RuntimeShape& output_shape,
                               uint8* output_data) {
   d8018:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d801c:	b09b      	sub	sp, #108	; 0x6c
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
   d801e:	ae0a      	add	r6, sp, #40	; 0x28
                               const RuntimeShape& input1_shape,
                               const uint8* input1_data,
                               const RuntimeShape& input2_shape,
                               const uint8* input2_data,
                               const RuntimeShape& output_shape,
                               uint8* output_data) {
   d8020:	4604      	mov	r4, r0
   d8022:	4693      	mov	fp, r2
   d8024:	4608      	mov	r0, r1
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
   d8026:	4632      	mov	r2, r6
                               const RuntimeShape& input1_shape,
                               const uint8* input1_data,
                               const RuntimeShape& input2_shape,
                               const uint8* input2_data,
                               const RuntimeShape& output_shape,
                               uint8* output_data) {
   d8028:	4619      	mov	r1, r3
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
   d802a:	ab12      	add	r3, sp, #72	; 0x48
   d802c:	f7ff fdf6 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
   d8030:	2301      	movs	r3, #1
   d8032:	9a25      	ldr	r2, [sp, #148]	; 0x94
   d8034:	2104      	movs	r1, #4
   d8036:	a805      	add	r0, sp, #20
   d8038:	f7ff fadb 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
  // first dimension has smallest stride.
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   d803c:	2500      	movs	r5, #0
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          const int32 input1_val =
              params.input1_offset +
              input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   d803e:	9602      	str	r6, [sp, #8]
  // first dimension has smallest stride.
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   d8040:	2100      	movs	r1, #0
   d8042:	a805      	add	r0, sp, #20
   d8044:	f7ff fa9c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8048:	4285      	cmp	r5, r0
   d804a:	da65      	bge.n	d8118 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x100>
   d804c:	2600      	movs	r6, #0
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
   d804e:	f10d 0814 	add.w	r8, sp, #20
   d8052:	2101      	movs	r1, #1
   d8054:	4640      	mov	r0, r8
   d8056:	f7ff fa93 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d805a:	4286      	cmp	r6, r0
   d805c:	da5a      	bge.n	d8114 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0xfc>
   d805e:	2700      	movs	r7, #0
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
   d8060:	2102      	movs	r1, #2
   d8062:	4640      	mov	r0, r8
   d8064:	f7ff fa8c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8068:	4287      	cmp	r7, r0
   d806a:	da51      	bge.n	d8110 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0xf8>
   d806c:	f04f 0900 	mov.w	r9, #0
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
   d8070:	2103      	movs	r1, #3
   d8072:	4640      	mov	r0, r8
   d8074:	f7ff fa84 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8078:	4581      	cmp	r9, r0
   d807a:	da47      	bge.n	d810c <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0xf4>
          const int32 input1_val =
              params.input1_offset +
              input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   d807c:	f8cd 9000 	str.w	r9, [sp]
   d8080:	463b      	mov	r3, r7
   d8082:	4632      	mov	r2, r6
   d8084:	4629      	mov	r1, r5
   d8086:	9802      	ldr	r0, [sp, #8]
   d8088:	f7ff fb90 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   d808c:	6863      	ldr	r3, [r4, #4]
   d808e:	f81b a000 	ldrb.w	sl, [fp, r0]
          const int32 input2_val =
              params.input2_offset +
              input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   d8092:	f8cd 9000 	str.w	r9, [sp]
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          const int32 input1_val =
              params.input1_offset +
              input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   d8096:	449a      	add	sl, r3
          const int32 input2_val =
              params.input2_offset +
              input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   d8098:	4632      	mov	r2, r6
   d809a:	463b      	mov	r3, r7
   d809c:	4629      	mov	r1, r5
   d809e:	a812      	add	r0, sp, #72	; 0x48
   d80a0:	f7ff fb84 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val =
              input1_val * (1 << params.left_shift);
          const int32 shifted_input2_val =
              input2_val * (1 << params.left_shift);
   d80a4:	9b24      	ldr	r3, [sp, #144]	; 0x90
              input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              params.input2_offset +
              input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val =
              input1_val * (1 << params.left_shift);
   d80a6:	f8d4 e018 	ldr.w	lr, [r4, #24]
          const int32 shifted_input2_val =
              input2_val * (1 << params.left_shift);
   d80aa:	5c1a      	ldrb	r2, [r3, r0]
   d80ac:	68a3      	ldr	r3, [r4, #8]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, params.input1_multiplier,
                  params.input1_shift);
   d80ae:	69e1      	ldr	r1, [r4, #28]
              params.input2_offset +
              input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val =
              input1_val * (1 << params.left_shift);
          const int32 shifted_input2_val =
              input2_val * (1 << params.left_shift);
   d80b0:	4413      	add	r3, r2
   d80b2:	fa03 f30e 	lsl.w	r3, r3, lr
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, params.input1_multiplier,
                  params.input1_shift);
   d80b6:	fa0a f00e 	lsl.w	r0, sl, lr
   d80ba:	6a22      	ldr	r2, [r4, #32]
              params.input2_offset +
              input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val =
              input1_val * (1 << params.left_shift);
          const int32 shifted_input2_val =
              input2_val * (1 << params.left_shift);
   d80bc:	9303      	str	r3, [sp, #12]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, params.input1_multiplier,
                  params.input1_shift);
   d80be:	f7ff fb23 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, params.input2_multiplier,
                  params.input2_shift);
   d80c2:	9b03      	ldr	r3, [sp, #12]
   d80c4:	6aa2      	ldr	r2, [r4, #40]	; 0x28
   d80c6:	6a61      	ldr	r1, [r4, #36]	; 0x24
          const int32 shifted_input2_val =
              input2_val * (1 << params.left_shift);
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, params.input1_multiplier,
                  params.input1_shift);
   d80c8:	4682      	mov	sl, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, params.input2_multiplier,
                  params.input2_shift);
   d80ca:	4618      	mov	r0, r3
   d80cc:	f7ff fb1c 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 raw_sum = scaled_input1_val + scaled_input2_val;
          const int32 raw_output =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
   d80d0:	6962      	ldr	r2, [r4, #20]
   d80d2:	6921      	ldr	r1, [r4, #16]
   d80d4:	4450      	add	r0, sl
   d80d6:	f7ff fb17 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
   d80da:	68e3      	ldr	r3, [r4, #12]
                  raw_sum, params.output_multiplier, params.output_shift) +
              params.output_offset;
          const int32 clamped_output =
              std::min(params.quantized_activation_max,
                       std::max(params.quantized_activation_min, raw_output));
          output_data[Offset(extended_output_shape, b, y, x, c)] =
   d80dc:	f8cd 9000 	str.w	r9, [sp]
   d80e0:	4418      	add	r0, r3
   d80e2:	6ae3      	ldr	r3, [r4, #44]	; 0x2c
   d80e4:	4283      	cmp	r3, r0
   d80e6:	bfb8      	it	lt
   d80e8:	4603      	movlt	r3, r0
   d80ea:	6b20      	ldr	r0, [r4, #48]	; 0x30
   d80ec:	4283      	cmp	r3, r0
   d80ee:	bfa8      	it	ge
   d80f0:	4603      	movge	r3, r0
   d80f2:	469a      	mov	sl, r3
   d80f4:	4632      	mov	r2, r6
   d80f6:	463b      	mov	r3, r7
   d80f8:	4629      	mov	r1, r5
   d80fa:	4640      	mov	r0, r8
   d80fc:	f7ff faa5 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              static_cast<uint8>(clamped_output);
   d8100:	9b26      	ldr	r3, [sp, #152]	; 0x98
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
   d8102:	f109 0901 	add.w	r9, r9, #1
              params.output_offset;
          const int32 clamped_output =
              std::min(params.quantized_activation_max,
                       std::max(params.quantized_activation_min, raw_output));
          output_data[Offset(extended_output_shape, b, y, x, c)] =
              static_cast<uint8>(clamped_output);
   d8106:	f803 a000 	strb.w	sl, [r3, r0]
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
   d810a:	e7b1      	b.n	d8070 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x58>
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
   d810c:	3701      	adds	r7, #1
   d810e:	e7a7      	b.n	d8060 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x48>
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
   d8110:	3601      	adds	r6, #1
   d8112:	e79c      	b.n	d804e <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x36>
  // first dimension has smallest stride.
  //
  // We name our variables by their Tensorflow convention, but generate C code
  // nesting loops such that the innermost loop has the smallest stride for the
  // best cache behavior.
  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   d8114:	3501      	adds	r5, #1
   d8116:	e793      	b.n	d8040 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x28>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input1_shape, input2_shape, &desc1,
                                      &desc2);
  const RuntimeShape extended_output_shape =
      RuntimeShape::ExtendedShape(4, output_shape);
   d8118:	a805      	add	r0, sp, #20
   d811a:	f7ff fa26 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              static_cast<uint8>(clamped_output);
        }
      }
    }
  }
}
   d811e:	b01b      	add	sp, #108	; 0x6c
   d8120:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d8124 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4>:

TfLiteStatus EvalAddQuantized(TfLiteContext* context, TfLiteNode* node,
   d8124:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   d8128:	b0a8      	sub	sp, #160	; 0xa0
   d812a:	461e      	mov	r6, r3
                              const TfLiteTensor* input1,
                              const TfLiteTensor* input2,
                              TfLiteTensor* output) {
  if (output->type == kTfLiteUInt8 || output->type == kTfLiteInt8) {
    tflite::ArithmeticParams op_params;
    op_params.left_shift = data->left_shift;
   d812c:	6a43      	ldr	r3, [r0, #36]	; 0x24
   d812e:	931a      	str	r3, [sp, #104]	; 0x68
    op_params.input1_offset = data->input1_offset;
   d8130:	6a83      	ldr	r3, [r0, #40]	; 0x28
   d8132:	9315      	str	r3, [sp, #84]	; 0x54
    op_params.input1_multiplier = data->input1_multiplier;
   d8134:	6943      	ldr	r3, [r0, #20]
   d8136:	931b      	str	r3, [sp, #108]	; 0x6c
    op_params.input1_shift = data->input1_shift;
   d8138:	6843      	ldr	r3, [r0, #4]
   d813a:	931c      	str	r3, [sp, #112]	; 0x70
    op_params.input2_offset = data->input2_offset;
   d813c:	6ac3      	ldr	r3, [r0, #44]	; 0x2c
   d813e:	9316      	str	r3, [sp, #88]	; 0x58
    op_params.input2_multiplier = data->input2_multiplier;
   d8140:	6983      	ldr	r3, [r0, #24]
   d8142:	931d      	str	r3, [sp, #116]	; 0x74
    op_params.input2_shift = data->input2_shift;
   d8144:	6883      	ldr	r3, [r0, #8]
   d8146:	931e      	str	r3, [sp, #120]	; 0x78
    op_params.output_offset = data->output_offset;
   d8148:	6b03      	ldr	r3, [r0, #48]	; 0x30
   d814a:	9317      	str	r3, [sp, #92]	; 0x5c
    op_params.output_multiplier = data->output_multiplier;
   d814c:	69c3      	ldr	r3, [r0, #28]
   d814e:	9318      	str	r3, [sp, #96]	; 0x60
    op_params.output_shift = data->output_shift;
   d8150:	6a03      	ldr	r3, [r0, #32]
   d8152:	9319      	str	r3, [sp, #100]	; 0x64
    TF_LITE_ADD(Add);
  }
#undef TF_LITE_ADD
}

TfLiteStatus EvalAddQuantized(TfLiteContext* context, TfLiteNode* node,
   d8154:	4614      	mov	r4, r2
    op_params.input2_shift = data->input2_shift;
    op_params.output_offset = data->output_offset;
    op_params.output_multiplier = data->output_multiplier;
    op_params.output_shift = data->output_shift;
    SetActivationParams(data->output_activation_min,
                        data->output_activation_max, &op_params);
   d8156:	6903      	ldr	r3, [r0, #16]
  params->float_activation_max = max;
}

template <typename P>
inline void SetActivationParams(int32 min, int32 max, P* params) {
  params->quantized_activation_min = min;
   d8158:	68c2      	ldr	r2, [r0, #12]
  params->quantized_activation_max = max;
   d815a:	9320      	str	r3, [sp, #128]	; 0x80
    bool need_broadcast = reference_ops::ProcessBroadcastShapes(
        GetTensorShape(input1), GetTensorShape(input2), &op_params);
   d815c:	a80f      	add	r0, sp, #60	; 0x3c
    TF_LITE_ADD(Add);
  }
#undef TF_LITE_ADD
}

TfLiteStatus EvalAddQuantized(TfLiteContext* context, TfLiteNode* node,
   d815e:	460d      	mov	r5, r1
  params->float_activation_max = max;
}

template <typename P>
inline void SetActivationParams(int32 min, int32 max, P* params) {
  params->quantized_activation_min = min;
   d8160:	921f      	str	r2, [sp, #124]	; 0x7c
    op_params.output_multiplier = data->output_multiplier;
    op_params.output_shift = data->output_shift;
    SetActivationParams(data->output_activation_min,
                        data->output_activation_max, &op_params);
    bool need_broadcast = reference_ops::ProcessBroadcastShapes(
        GetTensorShape(input1), GetTensorShape(input2), &op_params);
   d8162:	f7ff fcb2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d8166:	4621      	mov	r1, r4
   d8168:	a80a      	add	r0, sp, #40	; 0x28
   d816a:	f7ff fcae 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d816e:	a90a      	add	r1, sp, #40	; 0x28
   d8170:	aa14      	add	r2, sp, #80	; 0x50
   d8172:	a80f      	add	r0, sp, #60	; 0x3c
   d8174:	f7ff fbd3 	bl	d791e <_ZN6tflite13reference_ops22ProcessBroadcastShapesERKNS_12RuntimeShapeES3_PNS_16ArithmeticParamsE>
   d8178:	4680      	mov	r8, r0
   d817a:	a80a      	add	r0, sp, #40	; 0x28
   d817c:	f7ff f9f5 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   d8180:	a80f      	add	r0, sp, #60	; 0x3c
   d8182:	f7ff f9f2 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
#define TF_LITE_ADD(type, opname, dtype)                             \
  type::opname(op_params, GetTensorShape(input1),                    \
               GetTensorData<dtype>(input1), GetTensorShape(input2), \
               GetTensorData<dtype>(input2), GetTensorShape(output), \
               GetTensorData<dtype>(output));
    if (output->type == kTfLiteInt8) {
   d8186:	7833      	ldrb	r3, [r6, #0]
   d8188:	2b09      	cmp	r3, #9
      if (need_broadcast) {
        TF_LITE_ADD(reference_integer_ops, BroadcastAdd4DSlow, int8_t);
   d818a:	4629      	mov	r1, r5
   d818c:	a80f      	add	r0, sp, #60	; 0x3c
   d818e:	af05      	add	r7, sp, #20
#define TF_LITE_ADD(type, opname, dtype)                             \
  type::opname(op_params, GetTensorShape(input1),                    \
               GetTensorData<dtype>(input1), GetTensorShape(input2), \
               GetTensorData<dtype>(input2), GetTensorShape(output), \
               GetTensorData<dtype>(output));
    if (output->type == kTfLiteInt8) {
   d8190:	d134      	bne.n	d81fc <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0xd8>
      if (need_broadcast) {
   d8192:	f1b8 0f00 	cmp.w	r8, #0
   d8196:	d018      	beq.n	d81ca <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0xa6>
        TF_LITE_ADD(reference_integer_ops, BroadcastAdd4DSlow, int8_t);
   d8198:	f7ff fc97 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   d819c:	b105      	cbz	r5, d81a0 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0x7c>
   d819e:	686d      	ldr	r5, [r5, #4]
   d81a0:	4621      	mov	r1, r4
   d81a2:	a80a      	add	r0, sp, #40	; 0x28
   d81a4:	f7ff fc91 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d81a8:	b104      	cbz	r4, d81ac <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0x88>
   d81aa:	6864      	ldr	r4, [r4, #4]
   d81ac:	4631      	mov	r1, r6
   d81ae:	4638      	mov	r0, r7
   d81b0:	f7ff fc8b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d81b4:	6873      	ldr	r3, [r6, #4]
   d81b6:	9302      	str	r3, [sp, #8]
   d81b8:	e88d 0090 	stmia.w	sp, {r4, r7}
   d81bc:	ab0a      	add	r3, sp, #40	; 0x28
   d81be:	462a      	mov	r2, r5
   d81c0:	a90f      	add	r1, sp, #60	; 0x3c
   d81c2:	a814      	add	r0, sp, #80	; 0x50
   d81c4:	f7ff fea2 	bl	d7f0c <_ZN6tflite21reference_integer_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa>
   d81c8:	e04c      	b.n	d8264 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0x140>
      } else {
        TF_LITE_ADD(reference_integer_ops, Add, int8_t);
   d81ca:	f7ff fc7e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d81ce:	b105      	cbz	r5, d81d2 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0xae>
   d81d0:	686d      	ldr	r5, [r5, #4]
   d81d2:	4621      	mov	r1, r4
   d81d4:	a80a      	add	r0, sp, #40	; 0x28
   d81d6:	f7ff fc78 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d81da:	b104      	cbz	r4, d81de <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0xba>
   d81dc:	6864      	ldr	r4, [r4, #4]
   d81de:	4631      	mov	r1, r6
   d81e0:	4638      	mov	r0, r7
   d81e2:	f7ff fc72 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d81e6:	6873      	ldr	r3, [r6, #4]
   d81e8:	9302      	str	r3, [sp, #8]
   d81ea:	e88d 0090 	stmia.w	sp, {r4, r7}
   d81ee:	ab0a      	add	r3, sp, #40	; 0x28
   d81f0:	462a      	mov	r2, r5
   d81f2:	a90f      	add	r1, sp, #60	; 0x3c
   d81f4:	a814      	add	r0, sp, #80	; 0x50
   d81f6:	f7ff fb48 	bl	d788a <_ZN6tflite21reference_integer_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_Pa>
   d81fa:	e033      	b.n	d8264 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0x140>
      }
    } else {
      if (need_broadcast) {
   d81fc:	f1b8 0f00 	cmp.w	r8, #0
   d8200:	d018      	beq.n	d8234 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0x110>
        TF_LITE_ADD(reference_ops, BroadcastAdd4DSlow, uint8_t);
   d8202:	f7ff fc62 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d8206:	b105      	cbz	r5, d820a <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0xe6>
   d8208:	686d      	ldr	r5, [r5, #4]
   d820a:	4621      	mov	r1, r4
   d820c:	a80a      	add	r0, sp, #40	; 0x28
   d820e:	f7ff fc5c 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d8212:	b104      	cbz	r4, d8216 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0xf2>
   d8214:	6864      	ldr	r4, [r4, #4]
   d8216:	4631      	mov	r1, r6
   d8218:	4638      	mov	r0, r7
   d821a:	f7ff fc56 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d821e:	6873      	ldr	r3, [r6, #4]
   d8220:	9302      	str	r3, [sp, #8]
   d8222:	e88d 0090 	stmia.w	sp, {r4, r7}
   d8226:	ab0a      	add	r3, sp, #40	; 0x28
   d8228:	462a      	mov	r2, r5
   d822a:	a90f      	add	r1, sp, #60	; 0x3c
   d822c:	a814      	add	r0, sp, #80	; 0x50
   d822e:	f7ff fef3 	bl	d8018 <_ZN6tflite13reference_ops18BroadcastAdd4DSlowERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph>
   d8232:	e017      	b.n	d8264 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0x140>
      } else {
        TF_LITE_ADD(reference_ops, Add, uint8_t);
   d8234:	f7ff fc49 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d8238:	b105      	cbz	r5, d823c <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0x118>
   d823a:	686d      	ldr	r5, [r5, #4]
   d823c:	4621      	mov	r1, r4
   d823e:	a80a      	add	r0, sp, #40	; 0x28
   d8240:	f7ff fc43 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d8244:	b104      	cbz	r4, d8248 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4+0x124>
   d8246:	6864      	ldr	r4, [r4, #4]
   d8248:	4631      	mov	r1, r6
   d824a:	4638      	mov	r0, r7
   d824c:	f7ff fc3d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d8250:	6873      	ldr	r3, [r6, #4]
   d8252:	9302      	str	r3, [sp, #8]
   d8254:	e88d 0090 	stmia.w	sp, {r4, r7}
   d8258:	ab0a      	add	r3, sp, #40	; 0x28
   d825a:	462a      	mov	r2, r5
   d825c:	a90f      	add	r1, sp, #60	; 0x3c
   d825e:	a814      	add	r0, sp, #80	; 0x50
   d8260:	f7ff fac8 	bl	d77f4 <_ZN6tflite13reference_ops3AddERKNS_16ArithmeticParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph>
   d8264:	4638      	mov	r0, r7
   d8266:	f7ff f980 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   d826a:	a80a      	add	r0, sp, #40	; 0x28
   d826c:	f7ff f97d 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   d8270:	a80f      	add	r0, sp, #60	; 0x3c
   d8272:	f7ff f97a 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
    }
#undef TF_LITE_ADD
  }

  return kTfLiteOk;
}
   d8276:	b028      	add	sp, #160	; 0xa0
   d8278:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

000d827c <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_>:

TfLiteStatus EvalAddQuantized(TfLiteContext* context, TfLiteNode* node,
                              TfLiteAddParams* params, const OpData* data,
                              const TfLiteTensor* input1,
                              const TfLiteTensor* input2,
                              TfLiteTensor* output) {
   d827c:	b508      	push	{r3, lr}
   d827e:	4618      	mov	r0, r3
   d8280:	9b04      	ldr	r3, [sp, #16]
  if (output->type == kTfLiteUInt8 || output->type == kTfLiteInt8) {
   d8282:	781a      	ldrb	r2, [r3, #0]
   d8284:	2a03      	cmp	r2, #3
   d8286:	d001      	beq.n	d828c <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x10>
   d8288:	2a09      	cmp	r2, #9
   d828a:	d103      	bne.n	d8294 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_+0x18>
   d828c:	9a03      	ldr	r2, [sp, #12]
   d828e:	9902      	ldr	r1, [sp, #8]
   d8290:	f7ff ff48 	bl	d8124 <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_.part.4>
    }
#undef TF_LITE_ADD
  }

  return kTfLiteOk;
}
   d8294:	2000      	movs	r0, #0
   d8296:	bd08      	pop	{r3, pc}

000d8298 <_ZN6tflite3ops5micro3add4EvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   d8298:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d829c:	680a      	ldr	r2, [r1, #0]
   d829e:	f8d0 8008 	ldr.w	r8, [r0, #8]
  auto* params = reinterpret_cast<TfLiteAddParams*>(node->builtin_data);
   d82a2:	f8d1 9014 	ldr.w	r9, [r1, #20]
  }

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   d82a6:	460f      	mov	r7, r1
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   d82a8:	6851      	ldr	r1, [r2, #4]
   d82aa:	6892      	ldr	r2, [r2, #8]
   d82ac:	b095      	sub	sp, #84	; 0x54
   d82ae:	2338      	movs	r3, #56	; 0x38
   d82b0:	fb03 8202 	mla	r2, r3, r2, r8
   d82b4:	9204      	str	r2, [sp, #16]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   d82b6:	687a      	ldr	r2, [r7, #4]
   d82b8:	6854      	ldr	r4, [r2, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   d82ba:	fb03 8b01 	mla	fp, r3, r1, r8
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   d82be:	4363      	muls	r3, r4
   d82c0:	eb08 0403 	add.w	r4, r8, r3
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  OpData data;
  TF_LITE_ENSURE_STATUS(
   d82c4:	f10d 0a1c 	add.w	sl, sp, #28
   d82c8:	9305      	str	r3, [sp, #20]
   d82ca:	e88d 0410 	stmia.w	sp, {r4, sl}
   d82ce:	9b04      	ldr	r3, [sp, #16]
   d82d0:	465a      	mov	r2, fp
   d82d2:	4649      	mov	r1, r9
  }

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   d82d4:	4606      	mov	r6, r0
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  OpData data;
  TF_LITE_ENSURE_STATUS(
   d82d6:	f7ff fc11 	bl	d7afc <_ZN6tflite3ops5micro3add15CalculateOpDataEP13TfLiteContextP15TfLiteAddParamsPK12TfLiteTensorS9_PS7_PNS2_6OpDataE>
   d82da:	4605      	mov	r5, r0
   d82dc:	bb38      	cbnz	r0, d832e <_ZN6tflite3ops5micro3add4EvalEP13TfLiteContextP10TfLiteNode+0x96>
      CalculateOpData(context, params, input1, input2, output, &data));

  if (output->type == kTfLiteFloat32) {
   d82de:	9b05      	ldr	r3, [sp, #20]
   d82e0:	f818 3003 	ldrb.w	r3, [r8, r3]
   d82e4:	2b01      	cmp	r3, #1
   d82e6:	d10b      	bne.n	d8300 <_ZN6tflite3ops5micro3add4EvalEP13TfLiteContextP10TfLiteNode+0x68>
    EvalAdd(context, node, params, &data, input1, input2, output);
   d82e8:	9b04      	ldr	r3, [sp, #16]
   d82ea:	9301      	str	r3, [sp, #4]
   d82ec:	9402      	str	r4, [sp, #8]
   d82ee:	f8cd b000 	str.w	fp, [sp]
   d82f2:	4653      	mov	r3, sl
   d82f4:	464a      	mov	r2, r9
   d82f6:	4639      	mov	r1, r7
   d82f8:	4630      	mov	r0, r6
   d82fa:	f7ff fd7d 	bl	d7df8 <_ZN6tflite3ops5micro3add7EvalAddEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_>
   d82fe:	e017      	b.n	d8330 <_ZN6tflite3ops5micro3add4EvalEP13TfLiteContextP10TfLiteNode+0x98>
  } else if (output->type == kTfLiteUInt8 || output->type == kTfLiteInt8) {
   d8300:	2b03      	cmp	r3, #3
   d8302:	d001      	beq.n	d8308 <_ZN6tflite3ops5micro3add4EvalEP13TfLiteContextP10TfLiteNode+0x70>
   d8304:	2b09      	cmp	r3, #9
   d8306:	d10e      	bne.n	d8326 <_ZN6tflite3ops5micro3add4EvalEP13TfLiteContextP10TfLiteNode+0x8e>
    TF_LITE_ENSURE_OK(context, EvalAddQuantized(context, node, params, &data,
   d8308:	9b04      	ldr	r3, [sp, #16]
   d830a:	9301      	str	r3, [sp, #4]
   d830c:	9402      	str	r4, [sp, #8]
   d830e:	f8cd b000 	str.w	fp, [sp]
   d8312:	4653      	mov	r3, sl
   d8314:	464a      	mov	r2, r9
   d8316:	4639      	mov	r1, r7
   d8318:	4630      	mov	r0, r6
   d831a:	f7ff ffaf 	bl	d827c <_ZN6tflite3ops5micro3add16EvalAddQuantizedEP13TfLiteContextP10TfLiteNodeP15TfLiteAddParamsPKNS2_6OpDataEPK12TfLiteTensorSE_PSC_>
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  OpData data;
  TF_LITE_ENSURE_STATUS(
   d831e:	1c05      	adds	r5, r0, #0
   d8320:	bf18      	it	ne
   d8322:	2501      	movne	r5, #1
   d8324:	e004      	b.n	d8330 <_ZN6tflite3ops5micro3add4EvalEP13TfLiteContextP10TfLiteNode+0x98>
  } else if (output->type == kTfLiteUInt8 || output->type == kTfLiteInt8) {
    TF_LITE_ENSURE_OK(context, EvalAddQuantized(context, node, params, &data,
                                                input1, input2, output));
  } else {
    context->ReportError(context,
                         "Inputs and outputs not all float|uint8|int8 types.");
   d8326:	6973      	ldr	r3, [r6, #20]
   d8328:	4903      	ldr	r1, [pc, #12]	; (d8338 <_ZN6tflite3ops5micro3add4EvalEP13TfLiteContextP10TfLiteNode+0xa0>)
   d832a:	4630      	mov	r0, r6
   d832c:	4798      	blx	r3
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  OpData data;
  TF_LITE_ENSURE_STATUS(
   d832e:	2501      	movs	r5, #1
                         "Inputs and outputs not all float|uint8|int8 types.");
    return kTfLiteError;
  }

  return kTfLiteOk;
}
   d8330:	4628      	mov	r0, r5
   d8332:	b015      	add	sp, #84	; 0x54
   d8334:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   d8338:	000eb1fd 	.word	0x000eb1fd

000d833c <_ZN6tflite3ops5micro14AllOpsResolverC1Ev>:
#define TFLITE_REGISTRATIONS_MAX (128)
#endif

namespace tflite {

class MicroMutableOpResolver : public OpResolver {
   d833c:	f241 0304 	movw	r3, #4100	; 0x1004
TfLiteRegistration* Register_UNPACK();
TfLiteRegistration* Register_NEG();
TfLiteRegistration* Register_ADD();
TfLiteRegistration* Register_QUANTIZE();
TfLiteRegistration* Register_DEQUANTIZE();
AllOpsResolver::AllOpsResolver() {
   d8340:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
   d8342:	2700      	movs	r7, #0
   d8344:	50c7      	str	r7, [r0, r3]
   d8346:	4bbd      	ldr	r3, [pc, #756]	; (d863c <_ZN6tflite3ops5micro14AllOpsResolverC1Ev+0x300>)
   d8348:	6003      	str	r3, [r0, #0]
   d834a:	4605      	mov	r5, r0
  AddBuiltin(BuiltinOperator_DEPTHWISE_CONV_2D, Register_DEPTHWISE_CONV_2D());
   d834c:	f00b fc1a 	bl	e3b84 <_ZN6tflite3ops5micro26Register_DEPTHWISE_CONV_2DEv>
   d8350:	2401      	movs	r4, #1
   d8352:	4623      	mov	r3, r4
   d8354:	4602      	mov	r2, r0
   d8356:	2104      	movs	r1, #4
   d8358:	4628      	mov	r0, r5
   d835a:	9400      	str	r4, [sp, #0]
   d835c:	f7fe fff7 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_FULLY_CONNECTED, Register_FULLY_CONNECTED(),
   d8360:	f006 f948 	bl	de5f4 <_ZN6tflite3ops5micro24Register_FULLY_CONNECTEDEv>
             /* min_version */ 1,
             /* max_version */ 4);
   d8364:	2604      	movs	r6, #4
   d8366:	4623      	mov	r3, r4
   d8368:	4602      	mov	r2, r0
   d836a:	2109      	movs	r1, #9
   d836c:	4628      	mov	r0, r5
   d836e:	9600      	str	r6, [sp, #0]
   d8370:	f7fe ffed 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_MAX_POOL_2D, Register_MAX_POOL_2D());
   d8374:	f008 f840 	bl	e03f8 <_ZN6tflite3ops5micro20Register_MAX_POOL_2DEv>
   d8378:	4623      	mov	r3, r4
   d837a:	4602      	mov	r2, r0
   d837c:	2111      	movs	r1, #17
   d837e:	4628      	mov	r0, r5
   d8380:	9400      	str	r4, [sp, #0]
   d8382:	f7fe ffe4 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_SOFTMAX, Register_SOFTMAX());
   d8386:	f008 fef9 	bl	e117c <_ZN6tflite3ops5micro16Register_SOFTMAXEv>
   d838a:	4623      	mov	r3, r4
   d838c:	4602      	mov	r2, r0
   d838e:	2119      	movs	r1, #25
   d8390:	4628      	mov	r0, r5
   d8392:	9400      	str	r4, [sp, #0]
   d8394:	f7fe ffdb 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_LOGISTIC, Register_LOGISTIC());
   d8398:	f006 fb66 	bl	dea68 <_ZN6tflite3ops5micro17Register_LOGISTICEv>
   d839c:	4623      	mov	r3, r4
   d839e:	4602      	mov	r2, r0
   d83a0:	210e      	movs	r1, #14
   d83a2:	4628      	mov	r0, r5
   d83a4:	9400      	str	r4, [sp, #0]
   d83a6:	f7fe ffd2 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_SVDF, Register_SVDF());
   d83aa:	f00a ffad 	bl	e3308 <_ZN6tflite3ops5micro13Register_SVDFEv>
   d83ae:	4623      	mov	r3, r4
   d83b0:	4602      	mov	r2, r0
   d83b2:	211b      	movs	r1, #27
   d83b4:	4628      	mov	r0, r5
   d83b6:	9400      	str	r4, [sp, #0]
   d83b8:	f7fe ffc9 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_CONV_2D, Register_CONV_2D());
   d83bc:	f005 fb08 	bl	dd9d0 <_ZN6tflite3ops5micro16Register_CONV_2DEv>
   d83c0:	4623      	mov	r3, r4
   d83c2:	4602      	mov	r2, r0
   d83c4:	2103      	movs	r1, #3
   d83c6:	4628      	mov	r0, r5
   d83c8:	9400      	str	r4, [sp, #0]
   d83ca:	f7fe ffc0 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_AVERAGE_POOL_2D, Register_AVERAGE_POOL_2D());
   d83ce:	f008 f80f 	bl	e03f0 <_ZN6tflite3ops5micro24Register_AVERAGE_POOL_2DEv>
   d83d2:	4623      	mov	r3, r4
   d83d4:	4602      	mov	r2, r0
   d83d6:	4621      	mov	r1, r4
   d83d8:	4628      	mov	r0, r5
   d83da:	9400      	str	r4, [sp, #0]
   d83dc:	f7fe ffb7 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_ABS, Register_ABS());
   d83e0:	f005 fd4a 	bl	dde78 <_ZN6tflite3ops5micro12Register_ABSEv>
   d83e4:	4623      	mov	r3, r4
   d83e6:	4602      	mov	r2, r0
   d83e8:	2165      	movs	r1, #101	; 0x65
   d83ea:	4628      	mov	r0, r5
   d83ec:	9400      	str	r4, [sp, #0]
   d83ee:	f7fe ffae 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_SIN, Register_SIN());
   d83f2:	f005 fd45 	bl	dde80 <_ZN6tflite3ops5micro12Register_SINEv>
   d83f6:	4623      	mov	r3, r4
   d83f8:	4602      	mov	r2, r0
   d83fa:	2142      	movs	r1, #66	; 0x42
   d83fc:	4628      	mov	r0, r5
   d83fe:	9400      	str	r4, [sp, #0]
   d8400:	f7fe ffa5 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_COS, Register_COS());
   d8404:	f005 fd40 	bl	dde88 <_ZN6tflite3ops5micro12Register_COSEv>
   d8408:	4623      	mov	r3, r4
   d840a:	4602      	mov	r2, r0
   d840c:	216c      	movs	r1, #108	; 0x6c
   d840e:	4628      	mov	r0, r5
   d8410:	9400      	str	r4, [sp, #0]
   d8412:	f7fe ff9c 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_LOG, Register_LOG());
   d8416:	f005 fd3b 	bl	dde90 <_ZN6tflite3ops5micro12Register_LOGEv>
   d841a:	4623      	mov	r3, r4
   d841c:	4602      	mov	r2, r0
   d841e:	2149      	movs	r1, #73	; 0x49
   d8420:	4628      	mov	r0, r5
   d8422:	9400      	str	r4, [sp, #0]
   d8424:	f7fe ff93 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_SQRT, Register_SQRT());
   d8428:	f005 fd36 	bl	dde98 <_ZN6tflite3ops5micro13Register_SQRTEv>
   d842c:	4623      	mov	r3, r4
   d842e:	4602      	mov	r2, r0
   d8430:	214b      	movs	r1, #75	; 0x4b
   d8432:	4628      	mov	r0, r5
   d8434:	9400      	str	r4, [sp, #0]
   d8436:	f7fe ff8a 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_RSQRT, Register_RSQRT());
   d843a:	f005 fd31 	bl	ddea0 <_ZN6tflite3ops5micro14Register_RSQRTEv>
   d843e:	4623      	mov	r3, r4
   d8440:	4602      	mov	r2, r0
   d8442:	214c      	movs	r1, #76	; 0x4c
   d8444:	4628      	mov	r0, r5
   d8446:	9400      	str	r4, [sp, #0]
   d8448:	f7fe ff81 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_SQUARE, Register_SQUARE());
   d844c:	f005 fd2c 	bl	ddea8 <_ZN6tflite3ops5micro15Register_SQUAREEv>
   d8450:	4623      	mov	r3, r4
   d8452:	4602      	mov	r2, r0
   d8454:	215c      	movs	r1, #92	; 0x5c
   d8456:	4628      	mov	r0, r5
   d8458:	9400      	str	r4, [sp, #0]
   d845a:	f7fe ff78 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_PRELU, Register_PRELU());
   d845e:	f007 ffd1 	bl	e0404 <_ZN6tflite3ops5micro14Register_PRELUEv>
   d8462:	4623      	mov	r3, r4
   d8464:	4602      	mov	r2, r0
   d8466:	2136      	movs	r1, #54	; 0x36
   d8468:	4628      	mov	r0, r5
   d846a:	9400      	str	r4, [sp, #0]
   d846c:	f7fe ff6f 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_FLOOR, Register_FLOOR());
   d8470:	f005 fd8e 	bl	ddf90 <_ZN6tflite3ops5micro14Register_FLOOREv>
   d8474:	4623      	mov	r3, r4
   d8476:	4602      	mov	r2, r0
   d8478:	2108      	movs	r1, #8
   d847a:	4628      	mov	r0, r5
   d847c:	9400      	str	r4, [sp, #0]
   d847e:	f7fe ff66 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_MAXIMUM, Register_MAXIMUM());
   d8482:	f006 fb2f 	bl	deae4 <_ZN6tflite3ops5micro16Register_MAXIMUMEv>
   d8486:	4623      	mov	r3, r4
   d8488:	4602      	mov	r2, r0
   d848a:	2137      	movs	r1, #55	; 0x37
   d848c:	4628      	mov	r0, r5
   d848e:	9400      	str	r4, [sp, #0]
   d8490:	f7fe ff5d 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_MINIMUM, Register_MINIMUM());
   d8494:	f006 fb2a 	bl	deaec <_ZN6tflite3ops5micro16Register_MINIMUMEv>
   d8498:	4623      	mov	r3, r4
   d849a:	4602      	mov	r2, r0
   d849c:	2139      	movs	r1, #57	; 0x39
   d849e:	4628      	mov	r0, r5
   d84a0:	9400      	str	r4, [sp, #0]
   d84a2:	f7fe ff54 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_ARG_MAX, Register_ARG_MAX());
   d84a6:	f000 f8cd 	bl	d8644 <_ZN6tflite3ops5micro16Register_ARG_MAXEv>
   d84aa:	4623      	mov	r3, r4
   d84ac:	4602      	mov	r2, r0
   d84ae:	2138      	movs	r1, #56	; 0x38
   d84b0:	4628      	mov	r0, r5
   d84b2:	9400      	str	r4, [sp, #0]
   d84b4:	f7fe ff4b 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_ARG_MIN, Register_ARG_MIN());
   d84b8:	f000 f8c8 	bl	d864c <_ZN6tflite3ops5micro16Register_ARG_MINEv>
   d84bc:	4623      	mov	r3, r4
   d84be:	4602      	mov	r2, r0
   d84c0:	214f      	movs	r1, #79	; 0x4f
   d84c2:	4628      	mov	r0, r5
   d84c4:	9400      	str	r4, [sp, #0]
   d84c6:	f7fe ff42 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_LOGICAL_OR, Register_LOGICAL_OR());
   d84ca:	f006 f8a1 	bl	de610 <_ZN6tflite3ops5micro19Register_LOGICAL_OREv>
   d84ce:	4623      	mov	r3, r4
   d84d0:	4602      	mov	r2, r0
   d84d2:	2154      	movs	r1, #84	; 0x54
   d84d4:	4628      	mov	r0, r5
   d84d6:	9400      	str	r4, [sp, #0]
   d84d8:	f7fe ff39 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_LOGICAL_AND, Register_LOGICAL_AND());
   d84dc:	f006 f89c 	bl	de618 <_ZN6tflite3ops5micro20Register_LOGICAL_ANDEv>
   d84e0:	4623      	mov	r3, r4
   d84e2:	4602      	mov	r2, r0
   d84e4:	2156      	movs	r1, #86	; 0x56
   d84e6:	4628      	mov	r0, r5
   d84e8:	9400      	str	r4, [sp, #0]
   d84ea:	f7fe ff30 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_LOGICAL_NOT, Register_LOGICAL_NOT());
   d84ee:	f005 fcdf 	bl	ddeb0 <_ZN6tflite3ops5micro20Register_LOGICAL_NOTEv>
   d84f2:	4623      	mov	r3, r4
   d84f4:	4602      	mov	r2, r0
   d84f6:	2157      	movs	r1, #87	; 0x57
   d84f8:	4628      	mov	r0, r5
   d84fa:	9400      	str	r4, [sp, #0]
   d84fc:	f7fe ff27 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_RESHAPE, Register_RESHAPE());
   d8500:	f008 fb7a 	bl	e0bf8 <_ZN6tflite3ops5micro16Register_RESHAPEEv>
   d8504:	4623      	mov	r3, r4
   d8506:	4602      	mov	r2, r0
   d8508:	2116      	movs	r1, #22
   d850a:	4628      	mov	r0, r5
   d850c:	9400      	str	r4, [sp, #0]
   d850e:	f7fe ff1e 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_EQUAL, Register_EQUAL());
   d8512:	f000 fd53 	bl	d8fbc <_ZN6tflite3ops5micro14Register_EQUALEv>
   d8516:	4623      	mov	r3, r4
   d8518:	4602      	mov	r2, r0
   d851a:	2147      	movs	r1, #71	; 0x47
   d851c:	4628      	mov	r0, r5
   d851e:	9400      	str	r4, [sp, #0]
   d8520:	f7fe ff15 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_NOT_EQUAL, Register_NOT_EQUAL());
   d8524:	f000 fd4e 	bl	d8fc4 <_ZN6tflite3ops5micro18Register_NOT_EQUALEv>
   d8528:	4623      	mov	r3, r4
   d852a:	4602      	mov	r2, r0
   d852c:	2148      	movs	r1, #72	; 0x48
   d852e:	4628      	mov	r0, r5
   d8530:	9400      	str	r4, [sp, #0]
   d8532:	f7fe ff0c 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_GREATER, Register_GREATER());
   d8536:	f000 fd49 	bl	d8fcc <_ZN6tflite3ops5micro16Register_GREATEREv>
   d853a:	4623      	mov	r3, r4
   d853c:	4602      	mov	r2, r0
   d853e:	213d      	movs	r1, #61	; 0x3d
   d8540:	4628      	mov	r0, r5
   d8542:	9400      	str	r4, [sp, #0]
   d8544:	f7fe ff03 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_GREATER_EQUAL, Register_GREATER_EQUAL());
   d8548:	f000 fd44 	bl	d8fd4 <_ZN6tflite3ops5micro22Register_GREATER_EQUALEv>
   d854c:	4623      	mov	r3, r4
   d854e:	4602      	mov	r2, r0
   d8550:	213e      	movs	r1, #62	; 0x3e
   d8552:	4628      	mov	r0, r5
   d8554:	9400      	str	r4, [sp, #0]
   d8556:	f7fe fefa 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_LESS, Register_LESS());
   d855a:	f000 fd3f 	bl	d8fdc <_ZN6tflite3ops5micro13Register_LESSEv>
   d855e:	4623      	mov	r3, r4
   d8560:	4602      	mov	r2, r0
   d8562:	213a      	movs	r1, #58	; 0x3a
   d8564:	4628      	mov	r0, r5
   d8566:	9400      	str	r4, [sp, #0]
   d8568:	f7fe fef1 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_LESS_EQUAL, Register_LESS_EQUAL());
   d856c:	f000 fd3a 	bl	d8fe4 <_ZN6tflite3ops5micro19Register_LESS_EQUALEv>
   d8570:	4623      	mov	r3, r4
   d8572:	4602      	mov	r2, r0
   d8574:	213f      	movs	r1, #63	; 0x3f
   d8576:	4628      	mov	r0, r5
   d8578:	9400      	str	r4, [sp, #0]
   d857a:	f7fe fee8 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_CEIL, Register_CEIL());
   d857e:	f000 fd19 	bl	d8fb4 <_ZN6tflite3ops5micro13Register_CEILEv>
   d8582:	4623      	mov	r3, r4
   d8584:	4602      	mov	r2, r0
   d8586:	2168      	movs	r1, #104	; 0x68
   d8588:	4628      	mov	r0, r5
   d858a:	9400      	str	r4, [sp, #0]
   d858c:	f7fe fedf 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_ROUND, Register_ROUND());
   d8590:	f008 fc5e 	bl	e0e50 <_ZN6tflite3ops5micro14Register_ROUNDEv>
   d8594:	4623      	mov	r3, r4
   d8596:	4602      	mov	r2, r0
   d8598:	2174      	movs	r1, #116	; 0x74
   d859a:	4628      	mov	r0, r5
   d859c:	9400      	str	r4, [sp, #0]
   d859e:	f7fe fed6 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_STRIDED_SLICE, Register_STRIDED_SLICE());
   d85a2:	f009 fe37 	bl	e2214 <_ZN6tflite3ops5micro22Register_STRIDED_SLICEEv>
   d85a6:	4623      	mov	r3, r4
   d85a8:	4602      	mov	r2, r0
   d85aa:	212d      	movs	r1, #45	; 0x2d
   d85ac:	4628      	mov	r0, r5
   d85ae:	9400      	str	r4, [sp, #0]
   d85b0:	f7fe fecd 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_PACK, Register_PACK());
   d85b4:	f007 f926 	bl	df804 <_ZN6tflite3ops5micro13Register_PACKEv>
   d85b8:	4623      	mov	r3, r4
   d85ba:	4602      	mov	r2, r0
   d85bc:	2153      	movs	r1, #83	; 0x53
   d85be:	4628      	mov	r0, r5
   d85c0:	9400      	str	r4, [sp, #0]
   d85c2:	f7fe fec4 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_SPLIT, Register_SPLIT(),
   d85c6:	f009 f913 	bl	e17f0 <_ZN6tflite3ops5micro14Register_SPLITEv>
             /* min_version */ 1,
             /* max_version */ 3);
   d85ca:	2303      	movs	r3, #3
   d85cc:	4602      	mov	r2, r0
   d85ce:	9300      	str	r3, [sp, #0]
   d85d0:	2131      	movs	r1, #49	; 0x31
   d85d2:	4623      	mov	r3, r4
   d85d4:	4628      	mov	r0, r5
   d85d6:	f7fe feba 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_UNPACK, Register_UNPACK());
   d85da:	f00b f87d 	bl	e36d8 <_ZN6tflite3ops5micro15Register_UNPACKEv>
   d85de:	4623      	mov	r3, r4
   d85e0:	4602      	mov	r2, r0
   d85e2:	2158      	movs	r1, #88	; 0x58
   d85e4:	4628      	mov	r0, r5
   d85e6:	9400      	str	r4, [sp, #0]
   d85e8:	f7fe feb1 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_NEG, Register_NEG());
   d85ec:	f006 fecc 	bl	df388 <_ZN6tflite3ops5micro12Register_NEGEv>
   d85f0:	4623      	mov	r3, r4
   d85f2:	4602      	mov	r2, r0
   d85f4:	213b      	movs	r1, #59	; 0x3b
   d85f6:	4628      	mov	r0, r5
   d85f8:	9400      	str	r4, [sp, #0]
   d85fa:	f7fe fea8 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_ADD, Register_ADD());
   d85fe:	f7ff fb09 	bl	d7c14 <_ZN6tflite3ops5micro12Register_ADDEv>
   d8602:	4623      	mov	r3, r4
   d8604:	4602      	mov	r2, r0
   d8606:	4639      	mov	r1, r7
   d8608:	4628      	mov	r0, r5
   d860a:	9400      	str	r4, [sp, #0]
   d860c:	f7fe fe9f 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_QUANTIZE, Register_QUANTIZE(), 1, 4);
   d8610:	f008 fa0e 	bl	e0a30 <_ZN6tflite3ops5micro17Register_QUANTIZEEv>
   d8614:	4623      	mov	r3, r4
   d8616:	4602      	mov	r2, r0
   d8618:	2172      	movs	r1, #114	; 0x72
   d861a:	4628      	mov	r0, r5
   d861c:	9600      	str	r6, [sp, #0]
   d861e:	f7fe fe96 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
  AddBuiltin(BuiltinOperator_DEQUANTIZE, Register_DEQUANTIZE(), 1, 4);
   d8622:	f005 fadd 	bl	ddbe0 <_ZN6tflite3ops5micro19Register_DEQUANTIZEEv>
   d8626:	9600      	str	r6, [sp, #0]
   d8628:	4602      	mov	r2, r0
   d862a:	4623      	mov	r3, r4
   d862c:	4628      	mov	r0, r5
   d862e:	2106      	movs	r1, #6
   d8630:	f7fe fe8d 	bl	d734e <_ZN6tflite22MicroMutableOpResolver10AddBuiltinENS_15BuiltinOperatorEP18TfLiteRegistrationii>
}
   d8634:	4628      	mov	r0, r5
   d8636:	b003      	add	sp, #12
   d8638:	bdf0      	pop	{r4, r5, r6, r7, pc}
   d863a:	bf00      	nop
   d863c:	000eb294 	.word	0x000eb294

000d8640 <_ZN6tflite3ops5micro11arg_min_max7PrepareEP13TfLiteContextP10TfLiteNode>:
constexpr int kAxis = 1;
constexpr int kOutputTensor = 0;

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   d8640:	2000      	movs	r0, #0
   d8642:	4770      	bx	lr

000d8644 <_ZN6tflite3ops5micro16Register_ARG_MAXEv>:

TfLiteRegistration* Register_ARG_MAX() {
  static TfLiteRegistration r = {nullptr, nullptr, arg_min_max::Prepare,
                                 arg_min_max::ArgMaxEval};
  return &r;
}
   d8644:	4800      	ldr	r0, [pc, #0]	; (d8648 <_ZN6tflite3ops5micro16Register_ARG_MAXEv+0x4>)
   d8646:	4770      	bx	lr
   d8648:	2003bd30 	.word	0x2003bd30

000d864c <_ZN6tflite3ops5micro16Register_ARG_MINEv>:

TfLiteRegistration* Register_ARG_MIN() {
  static TfLiteRegistration r = {nullptr, nullptr, arg_min_max::Prepare,
                                 arg_min_max::ArgMinEval};
  return &r;
}
   d864c:	4800      	ldr	r0, [pc, #0]	; (d8650 <_ZN6tflite3ops5micro16Register_ARG_MINEv+0x4>)
   d864e:	4770      	bx	lr
   d8650:	2003bd50 	.word	0x2003bd50

000d8654 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>:
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d8654:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d8658:	6805      	ldr	r5, [r0, #0]
   d865a:	b087      	sub	sp, #28
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d865c:	2d00      	cmp	r5, #0
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d865e:	4606      	mov	r6, r0
   d8660:	9105      	str	r1, [sp, #20]
   d8662:	461f      	mov	r7, r3
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d8664:	dc01      	bgt.n	d866a <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x16>
   d8666:	f00c ff45 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(input1_shape.DimensionsCount() - 1,
   d866a:	6839      	ldr	r1, [r7, #0]
   d866c:	1e6b      	subs	r3, r5, #1
   d866e:	428b      	cmp	r3, r1
   d8670:	d1f9      	bne.n	d8666 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
   d8672:	6814      	ldr	r4, [r2, #0]
  if (axis < 0) {
   d8674:	2c00      	cmp	r4, #0
    axis += input1_shape.DimensionsCount();
   d8676:	bfb8      	it	lt
   d8678:	1964      	addlt	r4, r4, r5
  }
  const int axis_size = input1_shape.Dims(axis);
   d867a:	4621      	mov	r1, r4
   d867c:	f7fe ff80 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d8680:	f04f 0a00 	mov.w	sl, #0
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
  if (axis < 0) {
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);
   d8684:	4680      	mov	r8, r0

  int outer_size = 1;
   d8686:	f04f 0901 	mov.w	r9, #1
  for (int i = 0; i < axis; ++i) {
   d868a:	4554      	cmp	r4, sl
   d868c:	dd0f      	ble.n	d86ae <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x5a>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
   d868e:	4651      	mov	r1, sl
   d8690:	4630      	mov	r0, r6
   d8692:	f7fe ff75 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8696:	4651      	mov	r1, sl
   d8698:	4683      	mov	fp, r0
   d869a:	4638      	mov	r0, r7
   d869c:	f7fe ff70 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d86a0:	4583      	cmp	fp, r0
   d86a2:	d1e0      	bne.n	d8666 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    outer_size *= input1_shape.Dims(i);
   d86a4:	fb0b f909 	mul.w	r9, fp, r9
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d86a8:	f10a 0a01 	add.w	sl, sl, #1
   d86ac:	e7ed      	b.n	d868a <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x36>
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d86ae:	f104 0a01 	add.w	sl, r4, #1
  for (int i = 0; i < axis; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
   d86b2:	2401      	movs	r4, #1
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d86b4:	45aa      	cmp	sl, r5
   d86b6:	da10      	bge.n	d86da <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x86>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
   d86b8:	4651      	mov	r1, sl
   d86ba:	4630      	mov	r0, r6
   d86bc:	f7fe ff60 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d86c0:	f10a 31ff 	add.w	r1, sl, #4294967295	; 0xffffffff
   d86c4:	4683      	mov	fp, r0
   d86c6:	4638      	mov	r0, r7
   d86c8:	f7fe ff5a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d86cc:	4583      	cmp	fp, r0
   d86ce:	d1ca      	bne.n	d8666 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    inner_size *= input1_shape.Dims(i);
   d86d0:	fb0b f404 	mul.w	r4, fp, r4
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d86d4:	f10a 0a01 	add.w	sl, sl, #1
   d86d8:	e7ec      	b.n	d86b4 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x60>
   d86da:	fb04 f308 	mul.w	r3, r4, r8
   d86de:	9304      	str	r3, [sp, #16]
   d86e0:	f8dd e040 	ldr.w	lr, [sp, #64]	; 0x40
   d86e4:	2300      	movs	r3, #0
   d86e6:	ea4f 0a84 	mov.w	sl, r4, lsl #2
   d86ea:	461f      	mov	r7, r3
   d86ec:	469c      	mov	ip, r3
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d86ee:	45e1      	cmp	r9, ip
   d86f0:	dd31      	ble.n	d8756 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x102>
   d86f2:	9a05      	ldr	r2, [sp, #20]
   d86f4:	eb02 0183 	add.w	r1, r2, r3, lsl #2
   d86f8:	fb07 4204 	mla	r2, r7, r4, r4
   d86fc:	1ad2      	subs	r2, r2, r3
   d86fe:	0092      	lsls	r2, r2, #2
   d8700:	9202      	str	r2, [sp, #8]
   d8702:	2000      	movs	r0, #0
    for (int inner = 0; inner < inner_size; ++inner) {
   d8704:	4284      	cmp	r4, r0
   d8706:	dd1f      	ble.n	d8748 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xf4>
   d8708:	9a02      	ldr	r2, [sp, #8]
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
   d870a:	edd1 7a00 	vldr	s15, [r1]
   d870e:	188a      	adds	r2, r1, r2
   d8710:	2500      	movs	r5, #0
   d8712:	9203      	str	r2, [sp, #12]
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d8714:	2601      	movs	r6, #1
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
   d8716:	9501      	str	r5, [sp, #4]
      for (int i = 1; i < axis_size; ++i) {
   d8718:	4546      	cmp	r6, r8
   d871a:	da0f      	bge.n	d873c <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xe8>
   d871c:	9a03      	ldr	r2, [sp, #12]
   d871e:	eb02 0b05 	add.w	fp, r2, r5
   d8722:	ed9b 7a00 	vldr	s14, [fp]
        const auto& curr_value =
            input1_data[(outer * axis_size + i) * inner_size + inner];
        if (cmp(curr_value, min_max_value)) {
   d8726:	eef4 7ac7 	vcmpe.f32	s15, s14
   d872a:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d872e:	bf44      	itt	mi
   d8730:	9601      	strmi	r6, [sp, #4]
          min_max_value = curr_value;
   d8732:	eef0 7a47 	vmovmi.f32	s15, s14
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d8736:	3601      	adds	r6, #1
   d8738:	4455      	add	r5, sl
   d873a:	e7ed      	b.n	d8718 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xc4>
        if (cmp(curr_value, min_max_value)) {
          min_max_value = curr_value;
          min_max_index = static_cast<T2>(i);
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
   d873c:	9a01      	ldr	r2, [sp, #4]
   d873e:	f84e 2020 	str.w	r2, [lr, r0, lsl #2]
   d8742:	3104      	adds	r1, #4
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
   d8744:	3001      	adds	r0, #1
   d8746:	e7dd      	b.n	d8704 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xb0>
   d8748:	9a04      	ldr	r2, [sp, #16]
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d874a:	f10c 0c01 	add.w	ip, ip, #1
   d874e:	44d6      	add	lr, sl
   d8750:	4447      	add	r7, r8
   d8752:	4413      	add	r3, r2
   d8754:	e7cb      	b.n	d86ee <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x9a>
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
    }
  }
}
   d8756:	b007      	add	sp, #28
   d8758:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d875c <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>:
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d875c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d8760:	6805      	ldr	r5, [r0, #0]
   d8762:	b087      	sub	sp, #28
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d8764:	2d00      	cmp	r5, #0
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d8766:	4606      	mov	r6, r0
   d8768:	9105      	str	r1, [sp, #20]
   d876a:	461f      	mov	r7, r3
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d876c:	dc01      	bgt.n	d8772 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x16>
   d876e:	f00c fec1 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(input1_shape.DimensionsCount() - 1,
   d8772:	6839      	ldr	r1, [r7, #0]
   d8774:	1e6b      	subs	r3, r5, #1
   d8776:	428b      	cmp	r3, r1
   d8778:	d1f9      	bne.n	d876e <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
   d877a:	6814      	ldr	r4, [r2, #0]
  if (axis < 0) {
   d877c:	2c00      	cmp	r4, #0
    axis += input1_shape.DimensionsCount();
   d877e:	bfb8      	it	lt
   d8780:	1964      	addlt	r4, r4, r5
  }
  const int axis_size = input1_shape.Dims(axis);
   d8782:	4621      	mov	r1, r4
   d8784:	f7fe fefc 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d8788:	f04f 0a00 	mov.w	sl, #0
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
  if (axis < 0) {
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);
   d878c:	4680      	mov	r8, r0

  int outer_size = 1;
   d878e:	f04f 0901 	mov.w	r9, #1
  for (int i = 0; i < axis; ++i) {
   d8792:	4554      	cmp	r4, sl
   d8794:	dd0f      	ble.n	d87b6 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x5a>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
   d8796:	4651      	mov	r1, sl
   d8798:	4630      	mov	r0, r6
   d879a:	f7fe fef1 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d879e:	4651      	mov	r1, sl
   d87a0:	4683      	mov	fp, r0
   d87a2:	4638      	mov	r0, r7
   d87a4:	f7fe feec 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d87a8:	4583      	cmp	fp, r0
   d87aa:	d1e0      	bne.n	d876e <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    outer_size *= input1_shape.Dims(i);
   d87ac:	fb0b f909 	mul.w	r9, fp, r9
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d87b0:	f10a 0a01 	add.w	sl, sl, #1
   d87b4:	e7ed      	b.n	d8792 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x36>
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d87b6:	f104 0a01 	add.w	sl, r4, #1
  for (int i = 0; i < axis; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
   d87ba:	2401      	movs	r4, #1
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d87bc:	45aa      	cmp	sl, r5
   d87be:	da10      	bge.n	d87e2 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x86>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
   d87c0:	4651      	mov	r1, sl
   d87c2:	4630      	mov	r0, r6
   d87c4:	f7fe fedc 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d87c8:	f10a 31ff 	add.w	r1, sl, #4294967295	; 0xffffffff
   d87cc:	4683      	mov	fp, r0
   d87ce:	4638      	mov	r0, r7
   d87d0:	f7fe fed6 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d87d4:	4583      	cmp	fp, r0
   d87d6:	d1ca      	bne.n	d876e <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    inner_size *= input1_shape.Dims(i);
   d87d8:	fb0b f404 	mul.w	r4, fp, r4
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d87dc:	f10a 0a01 	add.w	sl, sl, #1
   d87e0:	e7ec      	b.n	d87bc <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x60>
   d87e2:	fb04 f308 	mul.w	r3, r4, r8
   d87e6:	9304      	str	r3, [sp, #16]
   d87e8:	f8dd e040 	ldr.w	lr, [sp, #64]	; 0x40
   d87ec:	2300      	movs	r3, #0
   d87ee:	ea4f 0a84 	mov.w	sl, r4, lsl #2
   d87f2:	461f      	mov	r7, r3
   d87f4:	469c      	mov	ip, r3
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d87f6:	45e1      	cmp	r9, ip
   d87f8:	dd31      	ble.n	d885e <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x102>
   d87fa:	9a05      	ldr	r2, [sp, #20]
   d87fc:	eb02 0183 	add.w	r1, r2, r3, lsl #2
   d8800:	fb07 4204 	mla	r2, r7, r4, r4
   d8804:	1ad2      	subs	r2, r2, r3
   d8806:	0092      	lsls	r2, r2, #2
   d8808:	9202      	str	r2, [sp, #8]
   d880a:	2000      	movs	r0, #0
    for (int inner = 0; inner < inner_size; ++inner) {
   d880c:	4284      	cmp	r4, r0
   d880e:	dd1f      	ble.n	d8850 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xf4>
   d8810:	9a02      	ldr	r2, [sp, #8]
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
   d8812:	edd1 7a00 	vldr	s15, [r1]
   d8816:	188a      	adds	r2, r1, r2
   d8818:	2500      	movs	r5, #0
   d881a:	9203      	str	r2, [sp, #12]
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d881c:	2601      	movs	r6, #1
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
   d881e:	9501      	str	r5, [sp, #4]
      for (int i = 1; i < axis_size; ++i) {
   d8820:	4546      	cmp	r6, r8
   d8822:	da0f      	bge.n	d8844 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xe8>
   d8824:	9a03      	ldr	r2, [sp, #12]
   d8826:	eb02 0b05 	add.w	fp, r2, r5
   d882a:	ed9b 7a00 	vldr	s14, [fp]
        const auto& curr_value =
            input1_data[(outer * axis_size + i) * inner_size + inner];
        if (cmp(curr_value, min_max_value)) {
   d882e:	eef4 7ac7 	vcmpe.f32	s15, s14
   d8832:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d8836:	bfc4      	itt	gt
   d8838:	9601      	strgt	r6, [sp, #4]
          min_max_value = curr_value;
   d883a:	eef0 7a47 	vmovgt.f32	s15, s14
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d883e:	3601      	adds	r6, #1
   d8840:	4455      	add	r5, sl
   d8842:	e7ed      	b.n	d8820 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xc4>
        if (cmp(curr_value, min_max_value)) {
          min_max_value = curr_value;
          min_max_index = static_cast<T2>(i);
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
   d8844:	9a01      	ldr	r2, [sp, #4]
   d8846:	f84e 2020 	str.w	r2, [lr, r0, lsl #2]
   d884a:	3104      	adds	r1, #4
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
   d884c:	3001      	adds	r0, #1
   d884e:	e7dd      	b.n	d880c <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xb0>
   d8850:	9a04      	ldr	r2, [sp, #16]
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d8852:	f10c 0c01 	add.w	ip, ip, #1
   d8856:	44d6      	add	lr, sl
   d8858:	4447      	add	r7, r8
   d885a:	4413      	add	r3, r2
   d885c:	e7cb      	b.n	d87f6 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x9a>
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
    }
  }
}
   d885e:	b007      	add	sp, #28
   d8860:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d8864 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>:
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d8864:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d8868:	6806      	ldr	r6, [r0, #0]
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d886a:	2e00      	cmp	r6, #0
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d886c:	b087      	sub	sp, #28
   d886e:	4681      	mov	r9, r0
   d8870:	460f      	mov	r7, r1
   d8872:	469a      	mov	sl, r3
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d8874:	dc01      	bgt.n	d887a <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x16>
   d8876:	f00c fe3d 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(input1_shape.DimensionsCount() - 1,
   d887a:	f8da 1000 	ldr.w	r1, [sl]
   d887e:	1e73      	subs	r3, r6, #1
   d8880:	428b      	cmp	r3, r1
   d8882:	d1f8      	bne.n	d8876 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
   d8884:	6814      	ldr	r4, [r2, #0]
  if (axis < 0) {
   d8886:	2c00      	cmp	r4, #0
    axis += input1_shape.DimensionsCount();
   d8888:	bfb8      	it	lt
   d888a:	19a4      	addlt	r4, r4, r6
  }
  const int axis_size = input1_shape.Dims(axis);
   d888c:	4621      	mov	r1, r4
   d888e:	f7fe fe77 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d8892:	f04f 0b00 	mov.w	fp, #0
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
  if (axis < 0) {
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);
   d8896:	4605      	mov	r5, r0

  int outer_size = 1;
   d8898:	f04f 0801 	mov.w	r8, #1
  for (int i = 0; i < axis; ++i) {
   d889c:	455c      	cmp	r4, fp
   d889e:	dd10      	ble.n	d88c2 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x5e>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
   d88a0:	4659      	mov	r1, fp
   d88a2:	4648      	mov	r0, r9
   d88a4:	f7fe fe6c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d88a8:	4659      	mov	r1, fp
   d88aa:	9001      	str	r0, [sp, #4]
   d88ac:	4650      	mov	r0, sl
   d88ae:	f7fe fe67 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d88b2:	9b01      	ldr	r3, [sp, #4]
   d88b4:	4283      	cmp	r3, r0
   d88b6:	d1de      	bne.n	d8876 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    outer_size *= input1_shape.Dims(i);
   d88b8:	fb03 f808 	mul.w	r8, r3, r8
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d88bc:	f10b 0b01 	add.w	fp, fp, #1
   d88c0:	e7ec      	b.n	d889c <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x38>
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d88c2:	f104 0b01 	add.w	fp, r4, #1
  for (int i = 0; i < axis; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
   d88c6:	2401      	movs	r4, #1
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d88c8:	45b3      	cmp	fp, r6
   d88ca:	da10      	bge.n	d88ee <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x8a>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
   d88cc:	4659      	mov	r1, fp
   d88ce:	4648      	mov	r0, r9
   d88d0:	f7fe fe56 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d88d4:	f10b 31ff 	add.w	r1, fp, #4294967295	; 0xffffffff
   d88d8:	9001      	str	r0, [sp, #4]
   d88da:	4650      	mov	r0, sl
   d88dc:	f7fe fe50 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d88e0:	9b01      	ldr	r3, [sp, #4]
   d88e2:	4283      	cmp	r3, r0
   d88e4:	d1c7      	bne.n	d8876 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    inner_size *= input1_shape.Dims(i);
   d88e6:	435c      	muls	r4, r3
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d88e8:	f10b 0b01 	add.w	fp, fp, #1
   d88ec:	e7ec      	b.n	d88c8 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x64>
   d88ee:	00a3      	lsls	r3, r4, #2
   d88f0:	9302      	str	r3, [sp, #8]
   d88f2:	2200      	movs	r2, #0
   d88f4:	fb05 f304 	mul.w	r3, r5, r4
   d88f8:	f8dd e040 	ldr.w	lr, [sp, #64]	; 0x40
   d88fc:	9304      	str	r3, [sp, #16]
   d88fe:	9701      	str	r7, [sp, #4]
   d8900:	4694      	mov	ip, r2
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d8902:	45e0      	cmp	r8, ip
   d8904:	dd29      	ble.n	d895a <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xf6>
   d8906:	fb02 4304 	mla	r3, r2, r4, r4
   d890a:	9305      	str	r3, [sp, #20]
   d890c:	2300      	movs	r3, #0
    for (int inner = 0; inner < inner_size; ++inner) {
   d890e:	429c      	cmp	r4, r3
   d8910:	dd19      	ble.n	d8946 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xe2>
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
   d8912:	9901      	ldr	r1, [sp, #4]
   d8914:	f811 a003 	ldrb.w	sl, [r1, r3]
   d8918:	9905      	ldr	r1, [sp, #20]
   d891a:	1859      	adds	r1, r3, r1
   d891c:	1879      	adds	r1, r7, r1
   d891e:	9103      	str	r1, [sp, #12]
   d8920:	2100      	movs	r1, #0
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d8922:	2001      	movs	r0, #1
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
   d8924:	4689      	mov	r9, r1
      for (int i = 1; i < axis_size; ++i) {
   d8926:	42a8      	cmp	r0, r5
   d8928:	da09      	bge.n	d893e <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xda>
   d892a:	9e03      	ldr	r6, [sp, #12]
   d892c:	f816 b001 	ldrb.w	fp, [r6, r1]
        const auto& curr_value =
            input1_data[(outer * axis_size + i) * inner_size + inner];
        if (cmp(curr_value, min_max_value)) {
   d8930:	45da      	cmp	sl, fp
   d8932:	bf3c      	itt	cc
   d8934:	4681      	movcc	r9, r0
   d8936:	46da      	movcc	sl, fp
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d8938:	3001      	adds	r0, #1
   d893a:	4421      	add	r1, r4
   d893c:	e7f3      	b.n	d8926 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xc2>
        if (cmp(curr_value, min_max_value)) {
          min_max_value = curr_value;
          min_max_index = static_cast<T2>(i);
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
   d893e:	f84e 9023 	str.w	r9, [lr, r3, lsl #2]
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
   d8942:	3301      	adds	r3, #1
   d8944:	e7e3      	b.n	d890e <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xaa>
   d8946:	9b02      	ldr	r3, [sp, #8]
   d8948:	9901      	ldr	r1, [sp, #4]
   d894a:	449e      	add	lr, r3
   d894c:	9b04      	ldr	r3, [sp, #16]
   d894e:	4419      	add	r1, r3
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d8950:	f10c 0c01 	add.w	ip, ip, #1
   d8954:	9101      	str	r1, [sp, #4]
   d8956:	442a      	add	r2, r5
   d8958:	e7d3      	b.n	d8902 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x9e>
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
    }
  }
}
   d895a:	b007      	add	sp, #28
   d895c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d8960 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>:
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d8960:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d8964:	6806      	ldr	r6, [r0, #0]
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d8966:	2e00      	cmp	r6, #0
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d8968:	b087      	sub	sp, #28
   d896a:	4681      	mov	r9, r0
   d896c:	460f      	mov	r7, r1
   d896e:	469a      	mov	sl, r3
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d8970:	dc01      	bgt.n	d8976 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x16>
   d8972:	f00c fdbf 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(input1_shape.DimensionsCount() - 1,
   d8976:	f8da 1000 	ldr.w	r1, [sl]
   d897a:	1e73      	subs	r3, r6, #1
   d897c:	428b      	cmp	r3, r1
   d897e:	d1f8      	bne.n	d8972 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
   d8980:	6814      	ldr	r4, [r2, #0]
  if (axis < 0) {
   d8982:	2c00      	cmp	r4, #0
    axis += input1_shape.DimensionsCount();
   d8984:	bfb8      	it	lt
   d8986:	19a4      	addlt	r4, r4, r6
  }
  const int axis_size = input1_shape.Dims(axis);
   d8988:	4621      	mov	r1, r4
   d898a:	f7fe fdf9 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d898e:	f04f 0b00 	mov.w	fp, #0
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
  if (axis < 0) {
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);
   d8992:	4605      	mov	r5, r0

  int outer_size = 1;
   d8994:	f04f 0801 	mov.w	r8, #1
  for (int i = 0; i < axis; ++i) {
   d8998:	455c      	cmp	r4, fp
   d899a:	dd10      	ble.n	d89be <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x5e>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
   d899c:	4659      	mov	r1, fp
   d899e:	4648      	mov	r0, r9
   d89a0:	f7fe fdee 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d89a4:	4659      	mov	r1, fp
   d89a6:	9001      	str	r0, [sp, #4]
   d89a8:	4650      	mov	r0, sl
   d89aa:	f7fe fde9 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d89ae:	9b01      	ldr	r3, [sp, #4]
   d89b0:	4283      	cmp	r3, r0
   d89b2:	d1de      	bne.n	d8972 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    outer_size *= input1_shape.Dims(i);
   d89b4:	fb03 f808 	mul.w	r8, r3, r8
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d89b8:	f10b 0b01 	add.w	fp, fp, #1
   d89bc:	e7ec      	b.n	d8998 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x38>
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d89be:	f104 0b01 	add.w	fp, r4, #1
  for (int i = 0; i < axis; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
   d89c2:	2401      	movs	r4, #1
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d89c4:	45b3      	cmp	fp, r6
   d89c6:	da10      	bge.n	d89ea <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x8a>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
   d89c8:	4659      	mov	r1, fp
   d89ca:	4648      	mov	r0, r9
   d89cc:	f7fe fdd8 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d89d0:	f10b 31ff 	add.w	r1, fp, #4294967295	; 0xffffffff
   d89d4:	9001      	str	r0, [sp, #4]
   d89d6:	4650      	mov	r0, sl
   d89d8:	f7fe fdd2 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d89dc:	9b01      	ldr	r3, [sp, #4]
   d89de:	4283      	cmp	r3, r0
   d89e0:	d1c7      	bne.n	d8972 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    inner_size *= input1_shape.Dims(i);
   d89e2:	435c      	muls	r4, r3
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d89e4:	f10b 0b01 	add.w	fp, fp, #1
   d89e8:	e7ec      	b.n	d89c4 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x64>
   d89ea:	00a3      	lsls	r3, r4, #2
   d89ec:	9302      	str	r3, [sp, #8]
   d89ee:	2200      	movs	r2, #0
   d89f0:	fb05 f304 	mul.w	r3, r5, r4
   d89f4:	f8dd e040 	ldr.w	lr, [sp, #64]	; 0x40
   d89f8:	9304      	str	r3, [sp, #16]
   d89fa:	9701      	str	r7, [sp, #4]
   d89fc:	4694      	mov	ip, r2
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d89fe:	45e0      	cmp	r8, ip
   d8a00:	dd29      	ble.n	d8a56 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xf6>
   d8a02:	fb02 4304 	mla	r3, r2, r4, r4
   d8a06:	9305      	str	r3, [sp, #20]
   d8a08:	2300      	movs	r3, #0
    for (int inner = 0; inner < inner_size; ++inner) {
   d8a0a:	429c      	cmp	r4, r3
   d8a0c:	dd19      	ble.n	d8a42 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xe2>
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
   d8a0e:	9901      	ldr	r1, [sp, #4]
   d8a10:	f811 a003 	ldrb.w	sl, [r1, r3]
   d8a14:	9905      	ldr	r1, [sp, #20]
   d8a16:	1859      	adds	r1, r3, r1
   d8a18:	1879      	adds	r1, r7, r1
   d8a1a:	9103      	str	r1, [sp, #12]
   d8a1c:	2100      	movs	r1, #0
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d8a1e:	2001      	movs	r0, #1
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
   d8a20:	4689      	mov	r9, r1
      for (int i = 1; i < axis_size; ++i) {
   d8a22:	42a8      	cmp	r0, r5
   d8a24:	da09      	bge.n	d8a3a <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xda>
   d8a26:	9e03      	ldr	r6, [sp, #12]
   d8a28:	f816 b001 	ldrb.w	fp, [r6, r1]
        const auto& curr_value =
            input1_data[(outer * axis_size + i) * inner_size + inner];
        if (cmp(curr_value, min_max_value)) {
   d8a2c:	45da      	cmp	sl, fp
   d8a2e:	bf84      	itt	hi
   d8a30:	4681      	movhi	r9, r0
   d8a32:	46da      	movhi	sl, fp
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d8a34:	3001      	adds	r0, #1
   d8a36:	4421      	add	r1, r4
   d8a38:	e7f3      	b.n	d8a22 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xc2>
        if (cmp(curr_value, min_max_value)) {
          min_max_value = curr_value;
          min_max_index = static_cast<T2>(i);
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
   d8a3a:	f84e 9023 	str.w	r9, [lr, r3, lsl #2]
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
   d8a3e:	3301      	adds	r3, #1
   d8a40:	e7e3      	b.n	d8a0a <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xaa>
   d8a42:	9b02      	ldr	r3, [sp, #8]
   d8a44:	9901      	ldr	r1, [sp, #4]
   d8a46:	449e      	add	lr, r3
   d8a48:	9b04      	ldr	r3, [sp, #16]
   d8a4a:	4419      	add	r1, r3
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d8a4c:	f10c 0c01 	add.w	ip, ip, #1
   d8a50:	9101      	str	r1, [sp, #4]
   d8a52:	442a      	add	r2, r5
   d8a54:	e7d3      	b.n	d89fe <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x9e>
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
    }
  }
}
   d8a56:	b007      	add	sp, #28
   d8a58:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d8a5c <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>:
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d8a5c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d8a60:	6806      	ldr	r6, [r0, #0]
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d8a62:	2e00      	cmp	r6, #0
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d8a64:	b087      	sub	sp, #28
   d8a66:	4681      	mov	r9, r0
   d8a68:	460f      	mov	r7, r1
   d8a6a:	469a      	mov	sl, r3
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d8a6c:	dc01      	bgt.n	d8a72 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x16>
   d8a6e:	f00c fd41 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(input1_shape.DimensionsCount() - 1,
   d8a72:	f8da 1000 	ldr.w	r1, [sl]
   d8a76:	1e73      	subs	r3, r6, #1
   d8a78:	428b      	cmp	r3, r1
   d8a7a:	d1f8      	bne.n	d8a6e <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
   d8a7c:	6814      	ldr	r4, [r2, #0]
  if (axis < 0) {
   d8a7e:	2c00      	cmp	r4, #0
    axis += input1_shape.DimensionsCount();
   d8a80:	bfb8      	it	lt
   d8a82:	19a4      	addlt	r4, r4, r6
  }
  const int axis_size = input1_shape.Dims(axis);
   d8a84:	4621      	mov	r1, r4
   d8a86:	f7fe fd7b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d8a8a:	f04f 0b00 	mov.w	fp, #0
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
  if (axis < 0) {
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);
   d8a8e:	4605      	mov	r5, r0

  int outer_size = 1;
   d8a90:	f04f 0801 	mov.w	r8, #1
  for (int i = 0; i < axis; ++i) {
   d8a94:	455c      	cmp	r4, fp
   d8a96:	dd10      	ble.n	d8aba <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x5e>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
   d8a98:	4659      	mov	r1, fp
   d8a9a:	4648      	mov	r0, r9
   d8a9c:	f7fe fd70 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8aa0:	4659      	mov	r1, fp
   d8aa2:	9001      	str	r0, [sp, #4]
   d8aa4:	4650      	mov	r0, sl
   d8aa6:	f7fe fd6b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8aaa:	9b01      	ldr	r3, [sp, #4]
   d8aac:	4283      	cmp	r3, r0
   d8aae:	d1de      	bne.n	d8a6e <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    outer_size *= input1_shape.Dims(i);
   d8ab0:	fb03 f808 	mul.w	r8, r3, r8
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d8ab4:	f10b 0b01 	add.w	fp, fp, #1
   d8ab8:	e7ec      	b.n	d8a94 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x38>
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d8aba:	f104 0b01 	add.w	fp, r4, #1
  for (int i = 0; i < axis; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
   d8abe:	2401      	movs	r4, #1
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d8ac0:	45b3      	cmp	fp, r6
   d8ac2:	da10      	bge.n	d8ae6 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x8a>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
   d8ac4:	4659      	mov	r1, fp
   d8ac6:	4648      	mov	r0, r9
   d8ac8:	f7fe fd5a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8acc:	f10b 31ff 	add.w	r1, fp, #4294967295	; 0xffffffff
   d8ad0:	9001      	str	r0, [sp, #4]
   d8ad2:	4650      	mov	r0, sl
   d8ad4:	f7fe fd54 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8ad8:	9b01      	ldr	r3, [sp, #4]
   d8ada:	4283      	cmp	r3, r0
   d8adc:	d1c7      	bne.n	d8a6e <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    inner_size *= input1_shape.Dims(i);
   d8ade:	435c      	muls	r4, r3
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d8ae0:	f10b 0b01 	add.w	fp, fp, #1
   d8ae4:	e7ec      	b.n	d8ac0 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x64>
   d8ae6:	00a3      	lsls	r3, r4, #2
   d8ae8:	9302      	str	r3, [sp, #8]
   d8aea:	2200      	movs	r2, #0
   d8aec:	fb05 f304 	mul.w	r3, r5, r4
   d8af0:	f8dd e040 	ldr.w	lr, [sp, #64]	; 0x40
   d8af4:	9304      	str	r3, [sp, #16]
   d8af6:	9701      	str	r7, [sp, #4]
   d8af8:	4694      	mov	ip, r2
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d8afa:	45e0      	cmp	r8, ip
   d8afc:	dd29      	ble.n	d8b52 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xf6>
   d8afe:	fb02 4304 	mla	r3, r2, r4, r4
   d8b02:	9305      	str	r3, [sp, #20]
   d8b04:	2300      	movs	r3, #0
    for (int inner = 0; inner < inner_size; ++inner) {
   d8b06:	429c      	cmp	r4, r3
   d8b08:	dd19      	ble.n	d8b3e <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xe2>
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
   d8b0a:	9901      	ldr	r1, [sp, #4]
   d8b0c:	f911 a003 	ldrsb.w	sl, [r1, r3]
   d8b10:	9905      	ldr	r1, [sp, #20]
   d8b12:	1859      	adds	r1, r3, r1
   d8b14:	1879      	adds	r1, r7, r1
   d8b16:	9103      	str	r1, [sp, #12]
   d8b18:	2100      	movs	r1, #0
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d8b1a:	2001      	movs	r0, #1
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
   d8b1c:	4689      	mov	r9, r1
      for (int i = 1; i < axis_size; ++i) {
   d8b1e:	42a8      	cmp	r0, r5
   d8b20:	da09      	bge.n	d8b36 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xda>
   d8b22:	9e03      	ldr	r6, [sp, #12]
   d8b24:	f916 b001 	ldrsb.w	fp, [r6, r1]
        const auto& curr_value =
            input1_data[(outer * axis_size + i) * inner_size + inner];
        if (cmp(curr_value, min_max_value)) {
   d8b28:	45da      	cmp	sl, fp
   d8b2a:	bfbc      	itt	lt
   d8b2c:	4681      	movlt	r9, r0
   d8b2e:	46da      	movlt	sl, fp
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d8b30:	3001      	adds	r0, #1
   d8b32:	4421      	add	r1, r4
   d8b34:	e7f3      	b.n	d8b1e <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xc2>
        if (cmp(curr_value, min_max_value)) {
          min_max_value = curr_value;
          min_max_index = static_cast<T2>(i);
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
   d8b36:	f84e 9023 	str.w	r9, [lr, r3, lsl #2]
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
   d8b3a:	3301      	adds	r3, #1
   d8b3c:	e7e3      	b.n	d8b06 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xaa>
   d8b3e:	9b02      	ldr	r3, [sp, #8]
   d8b40:	9901      	ldr	r1, [sp, #4]
   d8b42:	449e      	add	lr, r3
   d8b44:	9b04      	ldr	r3, [sp, #16]
   d8b46:	4419      	add	r1, r3
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d8b48:	f10c 0c01 	add.w	ip, ip, #1
   d8b4c:	9101      	str	r1, [sp, #4]
   d8b4e:	442a      	add	r2, r5
   d8b50:	e7d3      	b.n	d8afa <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x9e>
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
    }
  }
}
   d8b52:	b007      	add	sp, #28
   d8b54:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d8b58 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>:
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d8b58:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d8b5c:	6806      	ldr	r6, [r0, #0]
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d8b5e:	2e00      	cmp	r6, #0
namespace tflite {

namespace reference_ops {

template <typename T1, typename T2, typename T3, typename Cmp>
void ArgMinMax(const RuntimeShape& input1_shape, const T1* input1_data,
   d8b60:	b087      	sub	sp, #28
   d8b62:	4681      	mov	r9, r0
   d8b64:	460f      	mov	r7, r1
   d8b66:	469a      	mov	sl, r3
               const T3* input2_data, const RuntimeShape& output_shape,
               T2* output_data, const Cmp& cmp) {
  TFLITE_DCHECK_GT(input1_shape.DimensionsCount(), 0);
   d8b68:	dc01      	bgt.n	d8b6e <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x16>
   d8b6a:	f00c fcc3 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(input1_shape.DimensionsCount() - 1,
   d8b6e:	f8da 1000 	ldr.w	r1, [sl]
   d8b72:	1e73      	subs	r3, r6, #1
   d8b74:	428b      	cmp	r3, r1
   d8b76:	d1f8      	bne.n	d8b6a <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
   d8b78:	6814      	ldr	r4, [r2, #0]
  if (axis < 0) {
   d8b7a:	2c00      	cmp	r4, #0
    axis += input1_shape.DimensionsCount();
   d8b7c:	bfb8      	it	lt
   d8b7e:	19a4      	addlt	r4, r4, r6
  }
  const int axis_size = input1_shape.Dims(axis);
   d8b80:	4621      	mov	r1, r4
   d8b82:	f7fe fcfd 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d8b86:	f04f 0b00 	mov.w	fp, #0
                   output_shape.DimensionsCount());
  int axis = input2_data[0];
  if (axis < 0) {
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);
   d8b8a:	4605      	mov	r5, r0

  int outer_size = 1;
   d8b8c:	f04f 0801 	mov.w	r8, #1
  for (int i = 0; i < axis; ++i) {
   d8b90:	455c      	cmp	r4, fp
   d8b92:	dd10      	ble.n	d8bb6 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x5e>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
   d8b94:	4659      	mov	r1, fp
   d8b96:	4648      	mov	r0, r9
   d8b98:	f7fe fcf2 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8b9c:	4659      	mov	r1, fp
   d8b9e:	9001      	str	r0, [sp, #4]
   d8ba0:	4650      	mov	r0, sl
   d8ba2:	f7fe fced 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8ba6:	9b01      	ldr	r3, [sp, #4]
   d8ba8:	4283      	cmp	r3, r0
   d8baa:	d1de      	bne.n	d8b6a <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    outer_size *= input1_shape.Dims(i);
   d8bac:	fb03 f808 	mul.w	r8, r3, r8
    axis += input1_shape.DimensionsCount();
  }
  const int axis_size = input1_shape.Dims(axis);

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   d8bb0:	f10b 0b01 	add.w	fp, fp, #1
   d8bb4:	e7ec      	b.n	d8b90 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x38>
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d8bb6:	f104 0b01 	add.w	fp, r4, #1
  for (int i = 0; i < axis; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i));
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
   d8bba:	2401      	movs	r4, #1
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d8bbc:	45b3      	cmp	fp, r6
   d8bbe:	da10      	bge.n	d8be2 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x8a>
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
   d8bc0:	4659      	mov	r1, fp
   d8bc2:	4648      	mov	r0, r9
   d8bc4:	f7fe fcdc 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8bc8:	f10b 31ff 	add.w	r1, fp, #4294967295	; 0xffffffff
   d8bcc:	9001      	str	r0, [sp, #4]
   d8bce:	4650      	mov	r0, sl
   d8bd0:	f7fe fcd6 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8bd4:	9b01      	ldr	r3, [sp, #4]
   d8bd6:	4283      	cmp	r3, r0
   d8bd8:	d1c7      	bne.n	d8b6a <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x12>
    inner_size *= input1_shape.Dims(i);
   d8bda:	435c      	muls	r4, r3
    outer_size *= input1_shape.Dims(i);
  }

  int inner_size = 1;
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
   d8bdc:	f10b 0b01 	add.w	fp, fp, #1
   d8be0:	e7ec      	b.n	d8bbc <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x64>
   d8be2:	00a3      	lsls	r3, r4, #2
   d8be4:	9302      	str	r3, [sp, #8]
   d8be6:	2200      	movs	r2, #0
   d8be8:	fb05 f304 	mul.w	r3, r5, r4
   d8bec:	f8dd e040 	ldr.w	lr, [sp, #64]	; 0x40
   d8bf0:	9304      	str	r3, [sp, #16]
   d8bf2:	9701      	str	r7, [sp, #4]
   d8bf4:	4694      	mov	ip, r2
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d8bf6:	45e0      	cmp	r8, ip
   d8bf8:	dd29      	ble.n	d8c4e <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xf6>
   d8bfa:	fb02 4304 	mla	r3, r2, r4, r4
   d8bfe:	9305      	str	r3, [sp, #20]
   d8c00:	2300      	movs	r3, #0
    for (int inner = 0; inner < inner_size; ++inner) {
   d8c02:	429c      	cmp	r4, r3
   d8c04:	dd19      	ble.n	d8c3a <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xe2>
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
   d8c06:	9901      	ldr	r1, [sp, #4]
   d8c08:	f911 a003 	ldrsb.w	sl, [r1, r3]
   d8c0c:	9905      	ldr	r1, [sp, #20]
   d8c0e:	1859      	adds	r1, r3, r1
   d8c10:	1879      	adds	r1, r7, r1
   d8c12:	9103      	str	r1, [sp, #12]
   d8c14:	2100      	movs	r1, #0
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d8c16:	2001      	movs	r0, #1
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
   d8c18:	4689      	mov	r9, r1
      for (int i = 1; i < axis_size; ++i) {
   d8c1a:	42a8      	cmp	r0, r5
   d8c1c:	da09      	bge.n	d8c32 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xda>
   d8c1e:	9e03      	ldr	r6, [sp, #12]
   d8c20:	f916 b001 	ldrsb.w	fp, [r6, r1]
        const auto& curr_value =
            input1_data[(outer * axis_size + i) * inner_size + inner];
        if (cmp(curr_value, min_max_value)) {
   d8c24:	45da      	cmp	sl, fp
   d8c26:	bfc4      	itt	gt
   d8c28:	4681      	movgt	r9, r0
   d8c2a:	46da      	movgt	sl, fp
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
      auto min_max_value = input1_data[outer * axis_size * inner_size + inner];
      T2 min_max_index = 0;
      for (int i = 1; i < axis_size; ++i) {
   d8c2c:	3001      	adds	r0, #1
   d8c2e:	4421      	add	r1, r4
   d8c30:	e7f3      	b.n	d8c1a <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xc2>
        if (cmp(curr_value, min_max_value)) {
          min_max_value = curr_value;
          min_max_index = static_cast<T2>(i);
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
   d8c32:	f84e 9023 	str.w	r9, [lr, r3, lsl #2]
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
    for (int inner = 0; inner < inner_size; ++inner) {
   d8c36:	3301      	adds	r3, #1
   d8c38:	e7e3      	b.n	d8c02 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0xaa>
   d8c3a:	9b02      	ldr	r3, [sp, #8]
   d8c3c:	9901      	ldr	r1, [sp, #4]
   d8c3e:	449e      	add	lr, r3
   d8c40:	9b04      	ldr	r3, [sp, #16]
   d8c42:	4419      	add	r1, r3
  const int dims_count = input1_shape.DimensionsCount();
  for (int i = axis + 1; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(input1_shape.Dims(i), output_shape.Dims(i - 1));
    inner_size *= input1_shape.Dims(i);
  }
  for (int outer = 0; outer < outer_size; ++outer) {
   d8c44:	f10c 0c01 	add.w	ip, ip, #1
   d8c48:	9101      	str	r1, [sp, #4]
   d8c4a:	442a      	add	r2, r5
   d8c4c:	e7d3      	b.n	d8bf6 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_+0x9e>
        }
      }
      output_data[outer * inner_size + inner] = min_max_index;
    }
  }
}
   d8c4e:	b007      	add	sp, #28
   d8c50:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d8c54 <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb>:
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
                             output_shape, output_data, micro::Less());
  }
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node, bool is_arg_max) {
   d8c54:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   d8c58:	680e      	ldr	r6, [r1, #0]
   d8c5a:	4604      	mov	r4, r0
   d8c5c:	4617      	mov	r7, r2
   d8c5e:	6882      	ldr	r2, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   d8c60:	68b0      	ldr	r0, [r6, #8]
   d8c62:	2338      	movs	r3, #56	; 0x38
   d8c64:	4358      	muls	r0, r3
   d8c66:	eb02 0800 	add.w	r8, r2, r0

#define TF_LITE_ARG_MIN_MAX(data_type, axis_type, output_type)            \
  ArgMinMaxHelper(GetTensorShape(input), GetTensorData<data_type>(input), \
                  GetTensorData<axis_type>(axis), GetTensorShape(output), \
                  GetTensorData<output_type>(output), is_arg_max)
  if (axis->type == kTfLiteInt32) {
   d8c6a:	5c10      	ldrb	r0, [r2, r0]
   d8c6c:	2802      	cmp	r0, #2
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
                             output_shape, output_data, micro::Less());
  }
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node, bool is_arg_max) {
   d8c6e:	b08e      	sub	sp, #56	; 0x38

#define TF_LITE_ARG_MIN_MAX(data_type, axis_type, output_type)            \
  ArgMinMaxHelper(GetTensorShape(input), GetTensorData<data_type>(input), \
                  GetTensorData<axis_type>(axis), GetTensorShape(output), \
                  GetTensorData<output_type>(output), is_arg_max)
  if (axis->type == kTfLiteInt32) {
   d8c70:	d16b      	bne.n	d8d4a <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xf6>
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   d8c72:	6849      	ldr	r1, [r1, #4]
   d8c74:	6849      	ldr	r1, [r1, #4]
   d8c76:	4359      	muls	r1, r3
   d8c78:	1855      	adds	r5, r2, r1
    if (output->type == kTfLiteInt32) {
   d8c7a:	5c50      	ldrb	r0, [r2, r1]
   d8c7c:	2802      	cmp	r0, #2
   d8c7e:	d164      	bne.n	d8d4a <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xf6>
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   d8c80:	6871      	ldr	r1, [r6, #4]
   d8c82:	434b      	muls	r3, r1
   d8c84:	18d6      	adds	r6, r2, r3
      switch (input->type) {
   d8c86:	5cd0      	ldrb	r0, [r2, r3]
   d8c88:	2803      	cmp	r0, #3
   d8c8a:	d01d      	beq.n	d8cc8 <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0x74>
   d8c8c:	2809      	cmp	r0, #9
   d8c8e:	d035      	beq.n	d8cfc <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xa8>
   d8c90:	2801      	cmp	r0, #1
   d8c92:	d154      	bne.n	d8d3e <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xea>
        case kTfLiteFloat32:
          TF_LITE_ARG_MIN_MAX(float, int32_t, int32_t);
   d8c94:	4631      	mov	r1, r6
   d8c96:	a804      	add	r0, sp, #16
   d8c98:	f7fe ff17 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   d8c9c:	6874      	ldr	r4, [r6, #4]
   d8c9e:	f8d8 6004 	ldr.w	r6, [r8, #4]
   d8ca2:	4629      	mov	r1, r5
   d8ca4:	a809      	add	r0, sp, #36	; 0x24
   d8ca6:	f7fe ff10 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   d8caa:	686b      	ldr	r3, [r5, #4]
inline void ArgMinMaxHelper(const RuntimeShape& input1_shape,
                            const T1* input1_data, const T3* input2_data,
                            const RuntimeShape& output_shape, T2* output_data,
                            bool is_arg_max) {
  if (is_arg_max) {
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
   d8cac:	9300      	str	r3, [sp, #0]
   d8cae:	aa03      	add	r2, sp, #12
   d8cb0:	9201      	str	r2, [sp, #4]
   d8cb2:	ab09      	add	r3, sp, #36	; 0x24
   d8cb4:	4632      	mov	r2, r6
   d8cb6:	4621      	mov	r1, r4
   d8cb8:	a804      	add	r0, sp, #16
template <typename T1, typename T2, typename T3>
inline void ArgMinMaxHelper(const RuntimeShape& input1_shape,
                            const T1* input1_data, const T3* input2_data,
                            const RuntimeShape& output_shape, T2* output_data,
                            bool is_arg_max) {
  if (is_arg_max) {
   d8cba:	b117      	cbz	r7, d8cc2 <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0x6e>
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
   d8cbc:	f7ff fcca 	bl	d8654 <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>
   d8cc0:	e035      	b.n	d8d2e <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xda>
                             output_shape, output_data, micro::Greater());
  } else {
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
   d8cc2:	f7ff fd4b 	bl	d875c <_ZN6tflite13reference_ops9ArgMinMaxIfllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>
   d8cc6:	e032      	b.n	d8d2e <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xda>
      switch (input->type) {
        case kTfLiteFloat32:
          TF_LITE_ARG_MIN_MAX(float, int32_t, int32_t);
          break;
        case kTfLiteUInt8:
          TF_LITE_ARG_MIN_MAX(uint8_t, int32_t, int32_t);
   d8cc8:	4631      	mov	r1, r6
   d8cca:	a804      	add	r0, sp, #16
   d8ccc:	f7fe fefd 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   d8cd0:	6874      	ldr	r4, [r6, #4]
   d8cd2:	f8d8 6004 	ldr.w	r6, [r8, #4]
   d8cd6:	4629      	mov	r1, r5
   d8cd8:	a809      	add	r0, sp, #36	; 0x24
   d8cda:	f7fe fef6 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   d8cde:	686b      	ldr	r3, [r5, #4]
inline void ArgMinMaxHelper(const RuntimeShape& input1_shape,
                            const T1* input1_data, const T3* input2_data,
                            const RuntimeShape& output_shape, T2* output_data,
                            bool is_arg_max) {
  if (is_arg_max) {
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
   d8ce0:	9300      	str	r3, [sp, #0]
   d8ce2:	aa03      	add	r2, sp, #12
   d8ce4:	9201      	str	r2, [sp, #4]
   d8ce6:	ab09      	add	r3, sp, #36	; 0x24
   d8ce8:	4632      	mov	r2, r6
   d8cea:	4621      	mov	r1, r4
   d8cec:	a804      	add	r0, sp, #16
template <typename T1, typename T2, typename T3>
inline void ArgMinMaxHelper(const RuntimeShape& input1_shape,
                            const T1* input1_data, const T3* input2_data,
                            const RuntimeShape& output_shape, T2* output_data,
                            bool is_arg_max) {
  if (is_arg_max) {
   d8cee:	b117      	cbz	r7, d8cf6 <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xa2>
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
   d8cf0:	f7ff fdb8 	bl	d8864 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>
   d8cf4:	e01b      	b.n	d8d2e <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xda>
                             output_shape, output_data, micro::Greater());
  } else {
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
   d8cf6:	f7ff fe33 	bl	d8960 <_ZN6tflite13reference_ops9ArgMinMaxIhllNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>
   d8cfa:	e018      	b.n	d8d2e <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xda>
          break;
        case kTfLiteUInt8:
          TF_LITE_ARG_MIN_MAX(uint8_t, int32_t, int32_t);
          break;
        case kTfLiteInt8:
          TF_LITE_ARG_MIN_MAX(int8_t, int32_t, int32_t);
   d8cfc:	4631      	mov	r1, r6
   d8cfe:	a804      	add	r0, sp, #16
   d8d00:	f7fe fee3 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   d8d04:	6874      	ldr	r4, [r6, #4]
   d8d06:	f8d8 6004 	ldr.w	r6, [r8, #4]
   d8d0a:	4629      	mov	r1, r5
   d8d0c:	a809      	add	r0, sp, #36	; 0x24
   d8d0e:	f7fe fedc 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   d8d12:	686b      	ldr	r3, [r5, #4]
inline void ArgMinMaxHelper(const RuntimeShape& input1_shape,
                            const T1* input1_data, const T3* input2_data,
                            const RuntimeShape& output_shape, T2* output_data,
                            bool is_arg_max) {
  if (is_arg_max) {
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
   d8d14:	9300      	str	r3, [sp, #0]
   d8d16:	aa03      	add	r2, sp, #12
   d8d18:	9201      	str	r2, [sp, #4]
   d8d1a:	ab09      	add	r3, sp, #36	; 0x24
   d8d1c:	4632      	mov	r2, r6
   d8d1e:	4621      	mov	r1, r4
   d8d20:	a804      	add	r0, sp, #16
template <typename T1, typename T2, typename T3>
inline void ArgMinMaxHelper(const RuntimeShape& input1_shape,
                            const T1* input1_data, const T3* input2_data,
                            const RuntimeShape& output_shape, T2* output_data,
                            bool is_arg_max) {
  if (is_arg_max) {
   d8d22:	b117      	cbz	r7, d8d2a <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xd6>
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
   d8d24:	f7ff fe9a 	bl	d8a5c <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro7GreaterEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>
   d8d28:	e001      	b.n	d8d2e <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0xda>
                             output_shape, output_data, micro::Greater());
  } else {
    reference_ops::ArgMinMax(input1_shape, input1_data, input2_data,
   d8d2a:	f7ff ff15 	bl	d8b58 <_ZN6tflite13reference_ops9ArgMinMaxIallNS_3ops5micro4LessEEEvRKNS_12RuntimeShapeEPKT_PKT1_S7_PT0_RKT2_>
          break;
        case kTfLiteUInt8:
          TF_LITE_ARG_MIN_MAX(uint8_t, int32_t, int32_t);
          break;
        case kTfLiteInt8:
          TF_LITE_ARG_MIN_MAX(int8_t, int32_t, int32_t);
   d8d2e:	a809      	add	r0, sp, #36	; 0x24
   d8d30:	f7fe fc1b 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   d8d34:	a804      	add	r0, sp, #16
   d8d36:	f7fe fc18 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
    return kTfLiteError;
  }

#undef TF_LITE_ARG_MIN_MAX

  return kTfLiteOk;
   d8d3a:	2000      	movs	r0, #0
        case kTfLiteUInt8:
          TF_LITE_ARG_MIN_MAX(uint8_t, int32_t, int32_t);
          break;
        case kTfLiteInt8:
          TF_LITE_ARG_MIN_MAX(int8_t, int32_t, int32_t);
          break;
   d8d3c:	e00d      	b.n	d8d5a <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0x106>
        default:
          context->ReportError(context,
   d8d3e:	6965      	ldr	r5, [r4, #20]
   d8d40:	f7fb f9f4 	bl	d412c <TfLiteTypeGetName>
                               "Only float32, uint8 and int8 are "
                               "supported currently, got %s.",
                               TfLiteTypeGetName(input->type));
   d8d44:	4906      	ldr	r1, [pc, #24]	; (d8d60 <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0x10c>)
   d8d46:	4602      	mov	r2, r0
   d8d48:	e004      	b.n	d8d54 <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0x100>
                           "Only int32 are supported currently, got %s.",
                           TfLiteTypeGetName(output->type));
      return kTfLiteError;
    }
  } else {
    context->ReportError(context, "Only int32 are supported currently, got %s.",
   d8d4a:	6965      	ldr	r5, [r4, #20]
   d8d4c:	f7fb f9ee 	bl	d412c <TfLiteTypeGetName>
                         TfLiteTypeGetName(axis->type));
   d8d50:	4904      	ldr	r1, [pc, #16]	; (d8d64 <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb+0x110>)
   d8d52:	4602      	mov	r2, r0
   d8d54:	4620      	mov	r0, r4
   d8d56:	47a8      	blx	r5
    return kTfLiteError;
   d8d58:	2001      	movs	r0, #1
  }

#undef TF_LITE_ARG_MIN_MAX

  return kTfLiteOk;
}
   d8d5a:	b00e      	add	sp, #56	; 0x38
   d8d5c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   d8d60:	000eb2a4 	.word	0x000eb2a4
   d8d64:	000eb2e2 	.word	0x000eb2e2

000d8d68 <_ZN6tflite3ops5micro11arg_min_max10ArgMinEvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus ArgMinEval(TfLiteContext* context, TfLiteNode* node) {
  return Eval(context, node, false);
   d8d68:	2200      	movs	r2, #0
   d8d6a:	f7ff bf73 	b.w	d8c54 <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb>

000d8d6e <_ZN6tflite3ops5micro11arg_min_max10ArgMaxEvalEP13TfLiteContextP10TfLiteNode>:
}

TfLiteStatus ArgMaxEval(TfLiteContext* context, TfLiteNode* node) {
  return Eval(context, node, true);
   d8d6e:	2201      	movs	r2, #1
   d8d70:	f7ff bf70 	b.w	d8c54 <_ZN6tflite3ops5micro11arg_min_max4EvalEP13TfLiteContextP10TfLiteNodeb>

000d8d74 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode>:
namespace ceil {

constexpr int kInputTensor = 0;
constexpr int kOutputTensor = 0;

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   d8d74:	b5f0      	push	{r4, r5, r6, r7, lr}
   d8d76:	680b      	ldr	r3, [r1, #0]
}
inline const TfLiteTensor* GetIntermediates(TfLiteContext* context,
                                            TfLiteNode* node, int index) {
  return &context->tensors[node->intermediates->data[index]];
}
inline int NumInputs(const TfLiteNode* node) { return node->inputs->size; }
   d8d78:	681e      	ldr	r6, [r3, #0]
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
   d8d7a:	2e01      	cmp	r6, #1
namespace ceil {

constexpr int kInputTensor = 0;
constexpr int kOutputTensor = 0;

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   d8d7c:	b085      	sub	sp, #20
   d8d7e:	4605      	mov	r5, r0
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
   d8d80:	d009      	beq.n	d8d96 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x22>
   d8d82:	4b3b      	ldr	r3, [pc, #236]	; (d8e70 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0xfc>)
   d8d84:	9301      	str	r3, [sp, #4]
   d8d86:	2401      	movs	r4, #1
   d8d88:	4b3a      	ldr	r3, [pc, #232]	; (d8e74 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x100>)
   d8d8a:	9300      	str	r3, [sp, #0]
   d8d8c:	9403      	str	r4, [sp, #12]
   d8d8e:	9602      	str	r6, [sp, #8]
   d8d90:	6945      	ldr	r5, [r0, #20]
   d8d92:	2321      	movs	r3, #33	; 0x21
   d8d94:	e01e      	b.n	d8dd4 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x60>
   d8d96:	f8d1 e004 	ldr.w	lr, [r1, #4]
inline int NumOutputs(const TfLiteNode* node) { return node->outputs->size; }
   d8d9a:	f8de 4000 	ldr.w	r4, [lr]
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
   d8d9e:	2c01      	cmp	r4, #1
   d8da0:	d008      	beq.n	d8db4 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x40>
   d8da2:	4b33      	ldr	r3, [pc, #204]	; (d8e70 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0xfc>)
   d8da4:	9301      	str	r3, [sp, #4]
   d8da6:	4b34      	ldr	r3, [pc, #208]	; (d8e78 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x104>)
   d8da8:	9300      	str	r3, [sp, #0]
   d8daa:	9603      	str	r6, [sp, #12]
   d8dac:	9402      	str	r4, [sp, #8]
   d8dae:	6944      	ldr	r4, [r0, #20]
   d8db0:	2322      	movs	r3, #34	; 0x22
   d8db2:	e022      	b.n	d8dfa <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x86>
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   d8db4:	6859      	ldr	r1, [r3, #4]
   d8db6:	6882      	ldr	r2, [r0, #8]
   d8db8:	2338      	movs	r3, #56	; 0x38
   d8dba:	4359      	muls	r1, r3
   d8dbc:	1857      	adds	r7, r2, r1
  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);
   d8dbe:	5c56      	ldrb	r6, [r2, r1]
   d8dc0:	2e01      	cmp	r6, #1
   d8dc2:	d00b      	beq.n	d8ddc <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x68>
   d8dc4:	4b2d      	ldr	r3, [pc, #180]	; (d8e7c <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x108>)
   d8dc6:	9301      	str	r3, [sp, #4]
   d8dc8:	4b2d      	ldr	r3, [pc, #180]	; (d8e80 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x10c>)
   d8dca:	9300      	str	r3, [sp, #0]
   d8dcc:	9403      	str	r4, [sp, #12]
   d8dce:	9602      	str	r6, [sp, #8]
   d8dd0:	6945      	ldr	r5, [r0, #20]
   d8dd2:	2323      	movs	r3, #35	; 0x23
   d8dd4:	4a2b      	ldr	r2, [pc, #172]	; (d8e84 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x110>)
   d8dd6:	492c      	ldr	r1, [pc, #176]	; (d8e88 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x114>)
   d8dd8:	47a8      	blx	r5
   d8dda:	e042      	b.n	d8e62 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0xee>
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   d8ddc:	f8de 1004 	ldr.w	r1, [lr, #4]
   d8de0:	434b      	muls	r3, r1
   d8de2:	18d1      	adds	r1, r2, r3
  TF_LITE_ENSURE_EQ(context, output->type, input->type);
   d8de4:	5cd4      	ldrb	r4, [r2, r3]
   d8de6:	2c01      	cmp	r4, #1
   d8de8:	d00a      	beq.n	d8e00 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x8c>
   d8dea:	4b25      	ldr	r3, [pc, #148]	; (d8e80 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x10c>)
   d8dec:	9301      	str	r3, [sp, #4]
   d8dee:	4b27      	ldr	r3, [pc, #156]	; (d8e8c <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x118>)
   d8df0:	9300      	str	r3, [sp, #0]
   d8df2:	9603      	str	r6, [sp, #12]
   d8df4:	9402      	str	r4, [sp, #8]
   d8df6:	6944      	ldr	r4, [r0, #20]
   d8df8:	2324      	movs	r3, #36	; 0x24
   d8dfa:	4a22      	ldr	r2, [pc, #136]	; (d8e84 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x110>)
   d8dfc:	4922      	ldr	r1, [pc, #136]	; (d8e88 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x114>)
   d8dfe:	e02f      	b.n	d8e60 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0xec>
  TF_LITE_ENSURE_EQ(context, output->bytes, input->bytes);
   d8e00:	698b      	ldr	r3, [r1, #24]
   d8e02:	69ba      	ldr	r2, [r7, #24]
   d8e04:	4293      	cmp	r3, r2
   d8e06:	d008      	beq.n	d8e1a <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0xa6>
   d8e08:	9302      	str	r3, [sp, #8]
   d8e0a:	4b21      	ldr	r3, [pc, #132]	; (d8e90 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x11c>)
   d8e0c:	9301      	str	r3, [sp, #4]
   d8e0e:	4b21      	ldr	r3, [pc, #132]	; (d8e94 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x120>)
   d8e10:	9300      	str	r3, [sp, #0]
   d8e12:	9203      	str	r2, [sp, #12]
   d8e14:	6945      	ldr	r5, [r0, #20]
   d8e16:	2325      	movs	r3, #37	; 0x25
   d8e18:	e7dc      	b.n	d8dd4 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x60>
  TF_LITE_ENSURE_EQ(context, output->dims->size, input->dims->size);
   d8e1a:	688b      	ldr	r3, [r1, #8]
   d8e1c:	68ba      	ldr	r2, [r7, #8]
   d8e1e:	681e      	ldr	r6, [r3, #0]
   d8e20:	6811      	ldr	r1, [r2, #0]
   d8e22:	428e      	cmp	r6, r1
   d8e24:	d008      	beq.n	d8e38 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0xc4>
   d8e26:	4b1c      	ldr	r3, [pc, #112]	; (d8e98 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x124>)
   d8e28:	9301      	str	r3, [sp, #4]
   d8e2a:	4b1c      	ldr	r3, [pc, #112]	; (d8e9c <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x128>)
   d8e2c:	9300      	str	r3, [sp, #0]
   d8e2e:	9103      	str	r1, [sp, #12]
   d8e30:	9602      	str	r6, [sp, #8]
   d8e32:	6945      	ldr	r5, [r0, #20]
   d8e34:	2326      	movs	r3, #38	; 0x26
   d8e36:	e7cd      	b.n	d8dd4 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x60>
   d8e38:	2100      	movs	r1, #0
  for (int i = 0; i < output->dims->size; ++i) {
   d8e3a:	42b1      	cmp	r1, r6
   d8e3c:	da15      	bge.n	d8e6a <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0xf6>
    TF_LITE_ENSURE_EQ(context, output->dims->data[i], input->dims->data[i]);
   d8e3e:	f853 0f04 	ldr.w	r0, [r3, #4]!
   d8e42:	f852 4f04 	ldr.w	r4, [r2, #4]!
   d8e46:	42a0      	cmp	r0, r4
   d8e48:	d00d      	beq.n	d8e66 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0xf2>
   d8e4a:	4b15      	ldr	r3, [pc, #84]	; (d8ea0 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x12c>)
   d8e4c:	9301      	str	r3, [sp, #4]
   d8e4e:	4b15      	ldr	r3, [pc, #84]	; (d8ea4 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x130>)
   d8e50:	9002      	str	r0, [sp, #8]
   d8e52:	9300      	str	r3, [sp, #0]
   d8e54:	9403      	str	r4, [sp, #12]
   d8e56:	696c      	ldr	r4, [r5, #20]
   d8e58:	4a0a      	ldr	r2, [pc, #40]	; (d8e84 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x110>)
   d8e5a:	490b      	ldr	r1, [pc, #44]	; (d8e88 <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0x114>)
   d8e5c:	2328      	movs	r3, #40	; 0x28
   d8e5e:	4628      	mov	r0, r5
   d8e60:	47a0      	blx	r4
   d8e62:	2001      	movs	r0, #1
   d8e64:	e002      	b.n	d8e6c <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0xf8>
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);
  TF_LITE_ENSURE_EQ(context, output->type, input->type);
  TF_LITE_ENSURE_EQ(context, output->bytes, input->bytes);
  TF_LITE_ENSURE_EQ(context, output->dims->size, input->dims->size);
  for (int i = 0; i < output->dims->size; ++i) {
   d8e66:	3101      	adds	r1, #1
   d8e68:	e7e7      	b.n	d8e3a <_ZN6tflite3ops5micro4ceil7PrepareEP13TfLiteContextP10TfLiteNode+0xc6>
    TF_LITE_ENSURE_EQ(context, output->dims->data[i], input->dims->data[i]);
  }
  return kTfLiteOk;
   d8e6a:	2000      	movs	r0, #0
}
   d8e6c:	b005      	add	sp, #20
   d8e6e:	bdf0      	pop	{r4, r5, r6, r7, pc}
   d8e70:	000ecdd6 	.word	0x000ecdd6
   d8e74:	000eb3d3 	.word	0x000eb3d3
   d8e78:	000eb3e3 	.word	0x000eb3e3
   d8e7c:	000ebc41 	.word	0x000ebc41
   d8e80:	000eb3f4 	.word	0x000eb3f4
   d8e84:	000eb30e 	.word	0x000eb30e
   d8e88:	000eb3b9 	.word	0x000eb3b9
   d8e8c:	000eb400 	.word	0x000eb400
   d8e90:	000eb40d 	.word	0x000eb40d
   d8e94:	000eb41a 	.word	0x000eb41a
   d8e98:	000eb428 	.word	0x000eb428
   d8e9c:	000eb43a 	.word	0x000eb43a
   d8ea0:	000eb44d 	.word	0x000eb44d
   d8ea4:	000eb462 	.word	0x000eb462

000d8ea8 <_ZN6tflite12RuntimeShape11ReplaceWithEiPKl>:
      dims_pointer_ = new int32[dimensions_count];
#endif  // TF_LITE_STATIC_MEMORY
    }
  }

  inline void ReplaceWith(int dimensions_count, const int32* dims_data) {
   d8ea8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
  }
  // The caller must ensure that the shape is no bigger than 4-D.
  inline const int32* DimsDataUpTo4D() const { return dims_; }

  inline void Resize(int dimensions_count) {
    if (size_ > kMaxSmallSize) {
   d8eaa:	6803      	ldr	r3, [r0, #0]
   d8eac:	2b04      	cmp	r3, #4
      dims_pointer_ = new int32[dimensions_count];
#endif  // TF_LITE_STATIC_MEMORY
    }
  }

  inline void ReplaceWith(int dimensions_count, const int32* dims_data) {
   d8eae:	4604      	mov	r4, r0
   d8eb0:	460d      	mov	r5, r1
   d8eb2:	4617      	mov	r7, r2
  }
  // The caller must ensure that the shape is no bigger than 4-D.
  inline const int32* DimsDataUpTo4D() const { return dims_; }

  inline void Resize(int dimensions_count) {
    if (size_ > kMaxSmallSize) {
   d8eb4:	dd03      	ble.n	d8ebe <_ZN6tflite12RuntimeShape11ReplaceWithEiPKl+0x16>
#ifdef TF_LITE_STATIC_MEMORY
      TFLITE_CHECK(false && "No shape resizing supported on this platform");
#else   // TF_LITE_STATIC_MEMORY
      delete[] dims_pointer_;
   d8eb6:	6840      	ldr	r0, [r0, #4]
   d8eb8:	b108      	cbz	r0, d8ebe <_ZN6tflite12RuntimeShape11ReplaceWithEiPKl+0x16>
   d8eba:	f7fb f8f2 	bl	d40a2 <_ZdaPv>
#endif  // TF_LITE_STATIC_MEMORY
    }
    size_ = dimensions_count;
    if (dimensions_count > kMaxSmallSize) {
   d8ebe:	2d04      	cmp	r5, #4
      TFLITE_CHECK(false && "No shape resizing supported on this platform");
#else   // TF_LITE_STATIC_MEMORY
      delete[] dims_pointer_;
#endif  // TF_LITE_STATIC_MEMORY
    }
    size_ = dimensions_count;
   d8ec0:	6025      	str	r5, [r4, #0]
   d8ec2:	ea4f 0685 	mov.w	r6, r5, lsl #2
    if (dimensions_count > kMaxSmallSize) {
   d8ec6:	dd08      	ble.n	d8eda <_ZN6tflite12RuntimeShape11ReplaceWithEiPKl+0x32>
#ifdef TF_LITE_STATIC_MEMORY
      TFLITE_CHECK(false && "No shape resizing supported on this platform");
#else   // TF_LITE_STATIC_MEMORY
      dims_pointer_ = new int32[dimensions_count];
   d8ec8:	f1b5 5ffe 	cmp.w	r5, #532676608	; 0x1fc00000
   d8ecc:	bfd4      	ite	le
   d8ece:	4630      	movle	r0, r6
   d8ed0:	f04f 30ff 	movgt.w	r0, #4294967295	; 0xffffffff
   d8ed4:	f7fb f8e1 	bl	d409a <_Znaj>
   d8ed8:	6060      	str	r0, [r4, #4]
      dims_[i] = val;
    }
  }

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   d8eda:	6823      	ldr	r3, [r4, #0]
   d8edc:	2b04      	cmp	r3, #4
   d8ede:	bfcc      	ite	gt
   d8ee0:	6860      	ldrgt	r0, [r4, #4]
   d8ee2:	1d20      	addle	r0, r4, #4
  }

  inline void ReplaceWith(int dimensions_count, const int32* dims_data) {
    Resize(dimensions_count);
    int32* dst_dims = DimsData();
    std::memcpy(dst_dims, dims_data, dimensions_count * sizeof(int32));
   d8ee4:	4632      	mov	r2, r6
   d8ee6:	4639      	mov	r1, r7
  }
   d8ee8:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
  }

  inline void ReplaceWith(int dimensions_count, const int32* dims_data) {
    Resize(dimensions_count);
    int32* dst_dims = DimsData();
    std::memcpy(dst_dims, dims_data, dimensions_count * sizeof(int32));
   d8eec:	f00f be39 	b.w	e8b62 <memcpy>

000d8ef0 <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   d8ef0:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   d8ef4:	680a      	ldr	r2, [r1, #0]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   d8ef6:	6849      	ldr	r1, [r1, #4]
   d8ef8:	6883      	ldr	r3, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   d8efa:	6855      	ldr	r5, [r2, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   d8efc:	684c      	ldr	r4, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   d8efe:	2238      	movs	r2, #56	; 0x38
   d8f00:	fb02 3505 	mla	r5, r2, r5, r3
   d8f04:	b08a      	sub	sp, #40	; 0x28
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   d8f06:	fb02 3404 	mla	r4, r2, r4, r3
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
}

inline RuntimeShape GetTensorShape(const TfLiteTensor* tensor) {
  if (tensor == nullptr) {
   d8f0a:	b90d      	cbnz	r5, d8f10 <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x20>
  // larger shapes are separately allocated.
  static constexpr int kMaxSmallSize = 4;

  RuntimeShape& operator=(RuntimeShape const&) = delete;

  RuntimeShape() : size_(0) {}
   d8f0c:	9500      	str	r5, [sp, #0]
   d8f0e:	e009      	b.n	d8f24 <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x34>
    return RuntimeShape();
  }

  TfLiteIntArray* dims = tensor->dims;
  const int dims_size = dims->size;
   d8f10:	68aa      	ldr	r2, [r5, #8]
    for (int i = 0; i < shape_size; ++i) {
      SetDim(i, value);
    }
  }

  RuntimeShape(int dimensions_count, const int32* dims_data) : size_(0) {
   d8f12:	a80a      	add	r0, sp, #40	; 0x28
   d8f14:	2300      	movs	r3, #0
   d8f16:	f852 1b04 	ldr.w	r1, [r2], #4
   d8f1a:	f840 3d28 	str.w	r3, [r0, #-40]!
    ReplaceWith(dimensions_count, dims_data);
   d8f1e:	f7ff ffc3 	bl	d8ea8 <_ZN6tflite12RuntimeShape11ReplaceWithEiPKl>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   d8f22:	686d      	ldr	r5, [r5, #4]
}

inline RuntimeShape GetTensorShape(const TfLiteTensor* tensor) {
  if (tensor == nullptr) {
   d8f24:	b90c      	cbnz	r4, d8f2a <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x3a>
  // larger shapes are separately allocated.
  static constexpr int kMaxSmallSize = 4;

  RuntimeShape& operator=(RuntimeShape const&) = delete;

  RuntimeShape() : size_(0) {}
   d8f26:	9405      	str	r4, [sp, #20]
   d8f28:	e009      	b.n	d8f3e <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x4e>
    return RuntimeShape();
  }

  TfLiteIntArray* dims = tensor->dims;
  const int dims_size = dims->size;
   d8f2a:	68a2      	ldr	r2, [r4, #8]
    for (int i = 0; i < shape_size; ++i) {
      SetDim(i, value);
    }
  }

  RuntimeShape(int dimensions_count, const int32* dims_data) : size_(0) {
   d8f2c:	a80a      	add	r0, sp, #40	; 0x28
   d8f2e:	2300      	movs	r3, #0
   d8f30:	f852 1b04 	ldr.w	r1, [r2], #4
   d8f34:	f840 3d14 	str.w	r3, [r0, #-20]!
    ReplaceWith(dimensions_count, dims_data);
   d8f38:	f7ff ffb6 	bl	d8ea8 <_ZN6tflite12RuntimeShape11ReplaceWithEiPKl>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   d8f3c:	6864      	ldr	r4, [r4, #4]
   d8f3e:	9f00      	ldr	r7, [sp, #0]

// Flat size calculation, checking that dimensions match with one or more other
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   d8f40:	9b05      	ldr	r3, [sp, #20]
   d8f42:	429f      	cmp	r7, r3
   d8f44:	d101      	bne.n	d8f4a <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x5a>
   d8f46:	2600      	movs	r6, #0
   d8f48:	e00d      	b.n	d8f66 <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x76>
   d8f4a:	f00c fad3 	bl	e54f4 <abort>
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   d8f4e:	4631      	mov	r1, r6
   d8f50:	4668      	mov	r0, sp
   d8f52:	f7fe fb15 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8f56:	4631      	mov	r1, r6
   d8f58:	4680      	mov	r8, r0
   d8f5a:	a805      	add	r0, sp, #20
   d8f5c:	f7fe fb10 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d8f60:	4580      	cmp	r8, r0
   d8f62:	d1f2      	bne.n	d8f4a <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x5a>
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   d8f64:	3601      	adds	r6, #1
   d8f66:	42b7      	cmp	r7, r6
   d8f68:	dcf1      	bgt.n	d8f4e <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x5e>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   d8f6a:	2f04      	cmp	r7, #4
   d8f6c:	bfcc      	ite	gt
   d8f6e:	9a01      	ldrgt	r2, [sp, #4]
   d8f70:	aa01      	addle	r2, sp, #4
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   d8f72:	2300      	movs	r3, #0
  }

  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
   d8f74:	f04f 0801 	mov.w	r8, #1
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   d8f78:	429f      	cmp	r7, r3
   d8f7a:	dd05      	ble.n	d8f88 <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x98>
      buffer_size *= dims_data[i];
   d8f7c:	f852 1023 	ldr.w	r1, [r2, r3, lsl #2]
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   d8f80:	3301      	adds	r3, #1
      buffer_size *= dims_data[i];
   d8f82:	fb01 f808 	mul.w	r8, r1, r8
   d8f86:	e7f7      	b.n	d8f78 <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x88>
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   d8f88:	2600      	movs	r6, #0

inline void Ceil(const RuntimeShape& input_shape, const float* input_data,
                 const RuntimeShape& output_shape, float* output_data) {
  const int flat_size = MatchingFlatSize(input_shape, output_shape);

  for (int i = 0; i < flat_size; ++i) {
   d8f8a:	4546      	cmp	r6, r8
   d8f8c:	da07      	bge.n	d8f9e <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0xae>
  using ::ceil;

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  ceil(float __x)
  { return __builtin_ceilf(__x); }
   d8f8e:	ecb5 0a01 	vldmia	r5!, {s0}
   d8f92:	f00d fb77 	bl	e6684 <ceilf>
   d8f96:	3601      	adds	r6, #1
    output_data[i] = std::ceil(input_data[i]);
   d8f98:	eca4 0a01 	vstmia	r4!, {s0}
   d8f9c:	e7f5      	b.n	d8f8a <_ZN6tflite3ops5micro4ceil4EvalEP13TfLiteContextP10TfLiteNode+0x9a>
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  reference_ops::Ceil(GetTensorShape(input), GetTensorData<float>(input),
                      GetTensorShape(output), GetTensorData<float>(output));
   d8f9e:	a805      	add	r0, sp, #20
   d8fa0:	f7fe fae3 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  reference_ops::Ceil(GetTensorShape(input), GetTensorData<float>(input),
   d8fa4:	4668      	mov	r0, sp
   d8fa6:	f7fe fae0 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                      GetTensorShape(output), GetTensorData<float>(output));

  return kTfLiteOk;
}
   d8faa:	2000      	movs	r0, #0
   d8fac:	b00a      	add	sp, #40	; 0x28
   d8fae:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	...

000d8fb4 <_ZN6tflite3ops5micro13Register_CEILEv>:

TfLiteRegistration* Register_CEIL() {
  static TfLiteRegistration r = {/*init=*/nullptr,
                                 /*free=*/nullptr, ceil::Prepare, ceil::Eval};
  return &r;
}
   d8fb4:	4800      	ldr	r0, [pc, #0]	; (d8fb8 <_ZN6tflite3ops5micro13Register_CEILEv+0x4>)
   d8fb6:	4770      	bx	lr
   d8fb8:	2003bd70 	.word	0x2003bd70

000d8fbc <_ZN6tflite3ops5micro14Register_EQUALEv>:

TfLiteRegistration* Register_EQUAL() {
  static TfLiteRegistration r = {nullptr, nullptr, nullptr,
                                 comparisons::EqualEval};
  return &r;
}
   d8fbc:	4800      	ldr	r0, [pc, #0]	; (d8fc0 <_ZN6tflite3ops5micro14Register_EQUALEv+0x4>)
   d8fbe:	4770      	bx	lr
   d8fc0:	2003bdb0 	.word	0x2003bdb0

000d8fc4 <_ZN6tflite3ops5micro18Register_NOT_EQUALEv>:

TfLiteRegistration* Register_NOT_EQUAL() {
  static TfLiteRegistration r = {nullptr, nullptr, nullptr,
                                 comparisons::NotEqualEval};
  return &r;
}
   d8fc4:	4800      	ldr	r0, [pc, #0]	; (d8fc8 <_ZN6tflite3ops5micro18Register_NOT_EQUALEv+0x4>)
   d8fc6:	4770      	bx	lr
   d8fc8:	2003bdf0 	.word	0x2003bdf0

000d8fcc <_ZN6tflite3ops5micro16Register_GREATEREv>:

TfLiteRegistration* Register_GREATER() {
  static TfLiteRegistration r = {nullptr, nullptr, nullptr,
                                 comparisons::GreaterEval};
  return &r;
}
   d8fcc:	4800      	ldr	r0, [pc, #0]	; (d8fd0 <_ZN6tflite3ops5micro16Register_GREATEREv+0x4>)
   d8fce:	4770      	bx	lr
   d8fd0:	2003bd90 	.word	0x2003bd90

000d8fd4 <_ZN6tflite3ops5micro22Register_GREATER_EQUALEv>:

TfLiteRegistration* Register_GREATER_EQUAL() {
  static TfLiteRegistration r = {nullptr, nullptr, nullptr,
                                 comparisons::GreaterEqualEval};
  return &r;
}
   d8fd4:	4800      	ldr	r0, [pc, #0]	; (d8fd8 <_ZN6tflite3ops5micro22Register_GREATER_EQUALEv+0x4>)
   d8fd6:	4770      	bx	lr
   d8fd8:	2003be10 	.word	0x2003be10

000d8fdc <_ZN6tflite3ops5micro13Register_LESSEv>:

TfLiteRegistration* Register_LESS() {
  static TfLiteRegistration r = {nullptr, nullptr, nullptr,
                                 comparisons::LessEval};
  return &r;
}
   d8fdc:	4800      	ldr	r0, [pc, #0]	; (d8fe0 <_ZN6tflite3ops5micro13Register_LESSEv+0x4>)
   d8fde:	4770      	bx	lr
   d8fe0:	2003bdd0 	.word	0x2003bdd0

000d8fe4 <_ZN6tflite3ops5micro19Register_LESS_EQUALEv>:

TfLiteRegistration* Register_LESS_EQUAL() {
  static TfLiteRegistration r = {nullptr, nullptr, nullptr,
                                 comparisons::LessEqualEval};
  return &r;
}
   d8fe4:	4800      	ldr	r0, [pc, #0]	; (d8fe8 <_ZN6tflite3ops5micro19Register_LESS_EQUALEv+0x4>)
   d8fe6:	4770      	bx	lr
   d8fe8:	2003be30 	.word	0x2003be30

000d8fec <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d8fec:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d8ff0:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d8ff2:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d8ff4:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d8ff6:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d8ff8:	4691      	mov	r9, r2
   d8ffa:	460c      	mov	r4, r1
   d8ffc:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d8ffe:	dd01      	ble.n	d9004 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9000:	f00c fa78 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9004:	682b      	ldr	r3, [r5, #0]
   d9006:	2b04      	cmp	r3, #4
   d9008:	dcfa      	bgt.n	d9000 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d900a:	6813      	ldr	r3, [r2, #0]
   d900c:	2b04      	cmp	r3, #4
   d900e:	dcf7      	bgt.n	d9000 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  // (a) as Dims<4>-dependent code is eliminated, the reliance on this should be
  // reduced, and (b) some kernels are stricly 4-D, but then the shapes of their
  // inputs should already be 4-D, so this function should not be needed.
  inline static RuntimeShape ExtendedShape(int new_shape_size,
                                           const RuntimeShape& shape) {
    return RuntimeShape(new_shape_size, shape, 1);
   d9010:	2301      	movs	r3, #1
   d9012:	2104      	movs	r1, #4
   d9014:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d9016:	f10d 0820 	add.w	r8, sp, #32
   d901a:	f7fe faea 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d901e:	4620      	mov	r0, r4
   d9020:	ab10      	add	r3, sp, #64	; 0x40
   d9022:	4642      	mov	r2, r8
   d9024:	4629      	mov	r1, r5
   d9026:	f7fe fdf9 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d902a:	2400      	movs	r4, #0
   d902c:	2100      	movs	r1, #0
   d902e:	a803      	add	r0, sp, #12
   d9030:	f7fe faa6 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9034:	4284      	cmp	r4, r0
   d9036:	da3d      	bge.n	d90b4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc8>
   d9038:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d903a:	2101      	movs	r1, #1
   d903c:	a803      	add	r0, sp, #12
   d903e:	f7fe fa9f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9042:	4285      	cmp	r5, r0
   d9044:	da34      	bge.n	d90b0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc4>
   d9046:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9048:	2102      	movs	r1, #2
   d904a:	a803      	add	r0, sp, #12
   d904c:	f7fe fa98 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9050:	4286      	cmp	r6, r0
   d9052:	da2b      	bge.n	d90ac <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc0>
   d9054:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9056:	2103      	movs	r1, #3
   d9058:	a803      	add	r0, sp, #12
   d905a:	f7fe fa91 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d905e:	4287      	cmp	r7, r0
   d9060:	da22      	bge.n	d90a8 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xbc>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9062:	9700      	str	r7, [sp, #0]
   d9064:	4633      	mov	r3, r6
   d9066:	462a      	mov	r2, r5
   d9068:	4621      	mov	r1, r4
   d906a:	a803      	add	r0, sp, #12
   d906c:	f7fe faed 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9070:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9072:	4682      	mov	sl, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9074:	4633      	mov	r3, r6
   d9076:	462a      	mov	r2, r5
   d9078:	4621      	mov	r1, r4
   d907a:	4640      	mov	r0, r8
   d907c:	f7fe fb96 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9080:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9082:	4683      	mov	fp, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9084:	4633      	mov	r3, r6
   d9086:	462a      	mov	r2, r5
   d9088:	4621      	mov	r1, r4
   d908a:	a810      	add	r0, sp, #64	; 0x40
   d908c:	f7fe fb8e 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9090:	9a22      	ldr	r2, [sp, #136]	; 0x88
   d9092:	f819 300b 	ldrb.w	r3, [r9, fp]
   d9096:	5c12      	ldrb	r2, [r2, r0]
   d9098:	1a9a      	subs	r2, r3, r2
   d909a:	4253      	negs	r3, r2
   d909c:	4153      	adcs	r3, r2
   d909e:	9a24      	ldr	r2, [sp, #144]	; 0x90
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d90a0:	3701      	adds	r7, #1
          output_data[Offset(output_shape, b, y, x, c)] =
   d90a2:	f802 300a 	strb.w	r3, [r2, sl]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d90a6:	e7d6      	b.n	d9056 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d90a8:	3601      	adds	r6, #1
   d90aa:	e7cd      	b.n	d9048 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d90ac:	3501      	adds	r5, #1
   d90ae:	e7c4      	b.n	d903a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d90b0:	3401      	adds	r4, #1
   d90b2:	e7bb      	b.n	d902c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d90b4:	a803      	add	r0, sp, #12
   d90b6:	f7fe fa58 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d90ba:	b019      	add	sp, #100	; 0x64
   d90bc:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d90c0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d90c0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d90c4:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d90c6:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d90c8:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d90ca:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d90cc:	4692      	mov	sl, r2
   d90ce:	460c      	mov	r4, r1
   d90d0:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d90d2:	dd01      	ble.n	d90d8 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d90d4:	f00c fa0e 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d90d8:	682b      	ldr	r3, [r5, #0]
   d90da:	2b04      	cmp	r3, #4
   d90dc:	dcfa      	bgt.n	d90d4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d90de:	6813      	ldr	r3, [r2, #0]
   d90e0:	2b04      	cmp	r3, #4
   d90e2:	dcf7      	bgt.n	d90d4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d90e4:	2301      	movs	r3, #1
   d90e6:	2104      	movs	r1, #4
   d90e8:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d90ea:	f10d 0820 	add.w	r8, sp, #32
   d90ee:	f7fe fa80 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d90f2:	4620      	mov	r0, r4
   d90f4:	ab10      	add	r3, sp, #64	; 0x40
   d90f6:	4642      	mov	r2, r8
   d90f8:	4629      	mov	r1, r5
   d90fa:	f7fe fd8f 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d90fe:	2400      	movs	r4, #0
   d9100:	2100      	movs	r1, #0
   d9102:	a803      	add	r0, sp, #12
   d9104:	f7fe fa3c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9108:	4284      	cmp	r4, r0
   d910a:	da46      	bge.n	d919a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xda>
   d910c:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d910e:	2101      	movs	r1, #1
   d9110:	a803      	add	r0, sp, #12
   d9112:	f7fe fa35 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9116:	4285      	cmp	r5, r0
   d9118:	da3d      	bge.n	d9196 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd6>
   d911a:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d911c:	2102      	movs	r1, #2
   d911e:	a803      	add	r0, sp, #12
   d9120:	f7fe fa2e 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9124:	4286      	cmp	r6, r0
   d9126:	da34      	bge.n	d9192 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd2>
   d9128:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d912a:	2103      	movs	r1, #3
   d912c:	a803      	add	r0, sp, #12
   d912e:	f7fe fa27 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9132:	4287      	cmp	r7, r0
   d9134:	da2b      	bge.n	d918e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xce>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9136:	9700      	str	r7, [sp, #0]
   d9138:	4633      	mov	r3, r6
   d913a:	462a      	mov	r2, r5
   d913c:	4621      	mov	r1, r4
   d913e:	a803      	add	r0, sp, #12
   d9140:	f7fe fa83 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9144:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9146:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9148:	4633      	mov	r3, r6
   d914a:	462a      	mov	r2, r5
   d914c:	4621      	mov	r1, r4
   d914e:	4640      	mov	r0, r8
   d9150:	f7fe fb2c 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9154:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9156:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9158:	4633      	mov	r3, r6
   d915a:	462a      	mov	r2, r5
   d915c:	4621      	mov	r1, r4
   d915e:	a810      	add	r0, sp, #64	; 0x40
   d9160:	f7fe fb24 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9164:	9b22      	ldr	r3, [sp, #136]	; 0x88

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9166:	9a24      	ldr	r2, [sp, #144]	; 0x90
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9168:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   d916c:	eb0a 0989 	add.w	r9, sl, r9, lsl #2

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9170:	ed99 7a00 	vldr	s14, [r9]
   d9174:	edd0 7a00 	vldr	s15, [r0]
   d9178:	eeb4 7a67 	vcmp.f32	s14, s15
   d917c:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d9180:	bf0c      	ite	eq
   d9182:	2301      	moveq	r3, #1
   d9184:	2300      	movne	r3, #0
   d9186:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d918a:	3701      	adds	r7, #1
   d918c:	e7cd      	b.n	d912a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d918e:	3601      	adds	r6, #1
   d9190:	e7c4      	b.n	d911c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9192:	3501      	adds	r5, #1
   d9194:	e7bb      	b.n	d910e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9196:	3401      	adds	r4, #1
   d9198:	e7b2      	b.n	d9100 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d919a:	a803      	add	r0, sp, #12
   d919c:	f7fe f9e5 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d91a0:	b019      	add	sp, #100	; 0x64
   d91a2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d91a6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d91a6:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d91aa:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d91ac:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d91ae:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d91b0:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d91b2:	4691      	mov	r9, r2
   d91b4:	460c      	mov	r4, r1
   d91b6:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d91b8:	dd01      	ble.n	d91be <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d91ba:	f00c f99b 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d91be:	682b      	ldr	r3, [r5, #0]
   d91c0:	2b04      	cmp	r3, #4
   d91c2:	dcfa      	bgt.n	d91ba <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d91c4:	6813      	ldr	r3, [r2, #0]
   d91c6:	2b04      	cmp	r3, #4
   d91c8:	dcf7      	bgt.n	d91ba <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d91ca:	2301      	movs	r3, #1
   d91cc:	2104      	movs	r1, #4
   d91ce:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d91d0:	f10d 0820 	add.w	r8, sp, #32
   d91d4:	f7fe fa0d 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d91d8:	4620      	mov	r0, r4
   d91da:	ab10      	add	r3, sp, #64	; 0x40
   d91dc:	4642      	mov	r2, r8
   d91de:	4629      	mov	r1, r5
   d91e0:	f7fe fd1c 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d91e4:	2400      	movs	r4, #0
   d91e6:	2100      	movs	r1, #0
   d91e8:	a803      	add	r0, sp, #12
   d91ea:	f7fe f9c9 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d91ee:	4284      	cmp	r4, r0
   d91f0:	da3e      	bge.n	d9270 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xca>
   d91f2:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d91f4:	2101      	movs	r1, #1
   d91f6:	a803      	add	r0, sp, #12
   d91f8:	f7fe f9c2 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d91fc:	4285      	cmp	r5, r0
   d91fe:	da35      	bge.n	d926c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc6>
   d9200:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9202:	2102      	movs	r1, #2
   d9204:	a803      	add	r0, sp, #12
   d9206:	f7fe f9bb 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d920a:	4286      	cmp	r6, r0
   d920c:	da2c      	bge.n	d9268 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc2>
   d920e:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9210:	2103      	movs	r1, #3
   d9212:	a803      	add	r0, sp, #12
   d9214:	f7fe f9b4 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9218:	4287      	cmp	r7, r0
   d921a:	da23      	bge.n	d9264 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xbe>
          output_data[Offset(output_shape, b, y, x, c)] =
   d921c:	9700      	str	r7, [sp, #0]
   d921e:	4633      	mov	r3, r6
   d9220:	462a      	mov	r2, r5
   d9222:	4621      	mov	r1, r4
   d9224:	a803      	add	r0, sp, #12
   d9226:	f7fe fa10 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d922a:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d922c:	4682      	mov	sl, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d922e:	4633      	mov	r3, r6
   d9230:	462a      	mov	r2, r5
   d9232:	4621      	mov	r1, r4
   d9234:	4640      	mov	r0, r8
   d9236:	f7fe fab9 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d923a:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d923c:	4683      	mov	fp, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d923e:	4633      	mov	r3, r6
   d9240:	462a      	mov	r2, r5
   d9242:	4621      	mov	r1, r4
   d9244:	a810      	add	r0, sp, #64	; 0x40
   d9246:	f7fe fab1 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d924a:	9a22      	ldr	r2, [sp, #136]	; 0x88
   d924c:	f859 302b 	ldr.w	r3, [r9, fp, lsl #2]
   d9250:	f852 2020 	ldr.w	r2, [r2, r0, lsl #2]
   d9254:	1a9a      	subs	r2, r3, r2
   d9256:	4253      	negs	r3, r2
   d9258:	4153      	adcs	r3, r2
   d925a:	9a24      	ldr	r2, [sp, #144]	; 0x90
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d925c:	3701      	adds	r7, #1
          output_data[Offset(output_shape, b, y, x, c)] =
   d925e:	f802 300a 	strb.w	r3, [r2, sl]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9262:	e7d5      	b.n	d9210 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9264:	3601      	adds	r6, #1
   d9266:	e7cc      	b.n	d9202 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9268:	3501      	adds	r5, #1
   d926a:	e7c3      	b.n	d91f4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d926c:	3401      	adds	r4, #1
   d926e:	e7ba      	b.n	d91e6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9270:	a803      	add	r0, sp, #12
   d9272:	f7fe f97a 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d9276:	b019      	add	sp, #100	; 0x64
   d9278:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d927c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d927c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9280:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9282:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9284:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9286:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9288:	4692      	mov	sl, r2
   d928a:	460c      	mov	r4, r1
   d928c:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d928e:	dd01      	ble.n	d9294 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9290:	f00c f930 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9294:	682b      	ldr	r3, [r5, #0]
   d9296:	2b04      	cmp	r3, #4
   d9298:	dcfa      	bgt.n	d9290 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d929a:	6813      	ldr	r3, [r2, #0]
   d929c:	2b04      	cmp	r3, #4
   d929e:	dcf7      	bgt.n	d9290 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d92a0:	2301      	movs	r3, #1
   d92a2:	2104      	movs	r1, #4
   d92a4:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d92a6:	f10d 0820 	add.w	r8, sp, #32
   d92aa:	f7fe f9a2 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d92ae:	4620      	mov	r0, r4
   d92b0:	ab10      	add	r3, sp, #64	; 0x40
   d92b2:	4642      	mov	r2, r8
   d92b4:	4629      	mov	r1, r5
   d92b6:	f7fe fcb1 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d92ba:	2400      	movs	r4, #0
   d92bc:	2100      	movs	r1, #0
   d92be:	a803      	add	r0, sp, #12
   d92c0:	f7fe f95e 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d92c4:	4284      	cmp	r4, r0
   d92c6:	da45      	bge.n	d9354 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd8>
   d92c8:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d92ca:	2101      	movs	r1, #1
   d92cc:	a803      	add	r0, sp, #12
   d92ce:	f7fe f957 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d92d2:	4285      	cmp	r5, r0
   d92d4:	da3c      	bge.n	d9350 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd4>
   d92d6:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d92d8:	2102      	movs	r1, #2
   d92da:	a803      	add	r0, sp, #12
   d92dc:	f7fe f950 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d92e0:	4286      	cmp	r6, r0
   d92e2:	da33      	bge.n	d934c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd0>
   d92e4:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d92e6:	2103      	movs	r1, #3
   d92e8:	a803      	add	r0, sp, #12
   d92ea:	f7fe f949 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d92ee:	4287      	cmp	r7, r0
   d92f0:	da2a      	bge.n	d9348 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xcc>
          output_data[Offset(output_shape, b, y, x, c)] =
   d92f2:	9700      	str	r7, [sp, #0]
   d92f4:	4633      	mov	r3, r6
   d92f6:	462a      	mov	r2, r5
   d92f8:	4621      	mov	r1, r4
   d92fa:	a803      	add	r0, sp, #12
   d92fc:	f7fe f9a5 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9300:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9302:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9304:	4633      	mov	r3, r6
   d9306:	462a      	mov	r2, r5
   d9308:	4621      	mov	r1, r4
   d930a:	4640      	mov	r0, r8
   d930c:	f7fe fa4e 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9310:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9312:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9314:	4633      	mov	r3, r6
   d9316:	462a      	mov	r2, r5
   d9318:	4621      	mov	r1, r4
   d931a:	a810      	add	r0, sp, #64	; 0x40
   d931c:	f7fe fa46 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9320:	9b22      	ldr	r3, [sp, #136]	; 0x88
   d9322:	eb0a 09c9 	add.w	r9, sl, r9, lsl #3
   d9326:	eb03 03c0 	add.w	r3, r3, r0, lsl #3

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d932a:	e9d3 2300 	ldrd	r2, r3, [r3]
   d932e:	e9d9 0100 	ldrd	r0, r1, [r9]
   d9332:	4299      	cmp	r1, r3
   d9334:	bf08      	it	eq
   d9336:	4290      	cmpeq	r0, r2
   d9338:	9a24      	ldr	r2, [sp, #144]	; 0x90
   d933a:	bf0c      	ite	eq
   d933c:	2301      	moveq	r3, #1
   d933e:	2300      	movne	r3, #0
   d9340:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9344:	3701      	adds	r7, #1
   d9346:	e7ce      	b.n	d92e6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9348:	3601      	adds	r6, #1
   d934a:	e7c5      	b.n	d92d8 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d934c:	3501      	adds	r5, #1
   d934e:	e7bc      	b.n	d92ca <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9350:	3401      	adds	r4, #1
   d9352:	e7b3      	b.n	d92bc <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9354:	a803      	add	r0, sp, #12
   d9356:	f7fe f908 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d935a:	b019      	add	sp, #100	; 0x64
   d935c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9360 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9360:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9364:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9366:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9368:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d936a:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d936c:	4691      	mov	r9, r2
   d936e:	460c      	mov	r4, r1
   d9370:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9372:	dd01      	ble.n	d9378 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9374:	f00c f8be 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9378:	682b      	ldr	r3, [r5, #0]
   d937a:	2b04      	cmp	r3, #4
   d937c:	dcfa      	bgt.n	d9374 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d937e:	6813      	ldr	r3, [r2, #0]
   d9380:	2b04      	cmp	r3, #4
   d9382:	dcf7      	bgt.n	d9374 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9384:	2301      	movs	r3, #1
   d9386:	2104      	movs	r1, #4
   d9388:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d938a:	f10d 0820 	add.w	r8, sp, #32
   d938e:	f7fe f930 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9392:	4620      	mov	r0, r4
   d9394:	ab10      	add	r3, sp, #64	; 0x40
   d9396:	4642      	mov	r2, r8
   d9398:	4629      	mov	r1, r5
   d939a:	f7fe fc3f 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d939e:	2400      	movs	r4, #0
   d93a0:	2100      	movs	r1, #0
   d93a2:	a803      	add	r0, sp, #12
   d93a4:	f7fe f8ec 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d93a8:	4284      	cmp	r4, r0
   d93aa:	da3b      	bge.n	d9424 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc4>
   d93ac:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d93ae:	2101      	movs	r1, #1
   d93b0:	a803      	add	r0, sp, #12
   d93b2:	f7fe f8e5 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d93b6:	4285      	cmp	r5, r0
   d93b8:	da32      	bge.n	d9420 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc0>
   d93ba:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d93bc:	2102      	movs	r1, #2
   d93be:	a803      	add	r0, sp, #12
   d93c0:	f7fe f8de 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d93c4:	4286      	cmp	r6, r0
   d93c6:	da29      	bge.n	d941c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xbc>
   d93c8:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d93ca:	2103      	movs	r1, #3
   d93cc:	a803      	add	r0, sp, #12
   d93ce:	f7fe f8d7 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d93d2:	4287      	cmp	r7, r0
   d93d4:	da20      	bge.n	d9418 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xb8>
          output_data[Offset(output_shape, b, y, x, c)] =
   d93d6:	9700      	str	r7, [sp, #0]
   d93d8:	4633      	mov	r3, r6
   d93da:	462a      	mov	r2, r5
   d93dc:	4621      	mov	r1, r4
   d93de:	a803      	add	r0, sp, #12
   d93e0:	f7fe f933 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d93e4:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d93e6:	4682      	mov	sl, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d93e8:	4633      	mov	r3, r6
   d93ea:	462a      	mov	r2, r5
   d93ec:	4621      	mov	r1, r4
   d93ee:	4640      	mov	r0, r8
   d93f0:	f7fe f9dc 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d93f4:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d93f6:	4683      	mov	fp, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d93f8:	4633      	mov	r3, r6
   d93fa:	462a      	mov	r2, r5
   d93fc:	4621      	mov	r1, r4
   d93fe:	a810      	add	r0, sp, #64	; 0x40
   d9400:	f7fe f9d4 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9404:	9b22      	ldr	r3, [sp, #136]	; 0x88
   d9406:	f819 200b 	ldrb.w	r2, [r9, fp]
   d940a:	5c1b      	ldrb	r3, [r3, r0]
   d940c:	4053      	eors	r3, r2
   d940e:	9a24      	ldr	r2, [sp, #144]	; 0x90
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9410:	3701      	adds	r7, #1
          output_data[Offset(output_shape, b, y, x, c)] =
   d9412:	f802 300a 	strb.w	r3, [r2, sl]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9416:	e7d8      	b.n	d93ca <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9418:	3601      	adds	r6, #1
   d941a:	e7cf      	b.n	d93bc <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d941c:	3501      	adds	r5, #1
   d941e:	e7c6      	b.n	d93ae <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9420:	3401      	adds	r4, #1
   d9422:	e7bd      	b.n	d93a0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9424:	a803      	add	r0, sp, #12
   d9426:	f7fe f8a0 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d942a:	b019      	add	sp, #100	; 0x64
   d942c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9430 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9430:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9434:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9436:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9438:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d943a:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d943c:	4692      	mov	sl, r2
   d943e:	460c      	mov	r4, r1
   d9440:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9442:	dd01      	ble.n	d9448 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9444:	f00c f856 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9448:	682b      	ldr	r3, [r5, #0]
   d944a:	2b04      	cmp	r3, #4
   d944c:	dcfa      	bgt.n	d9444 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d944e:	6813      	ldr	r3, [r2, #0]
   d9450:	2b04      	cmp	r3, #4
   d9452:	dcf7      	bgt.n	d9444 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9454:	2301      	movs	r3, #1
   d9456:	2104      	movs	r1, #4
   d9458:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d945a:	f10d 0820 	add.w	r8, sp, #32
   d945e:	f7fe f8c8 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9462:	4620      	mov	r0, r4
   d9464:	ab10      	add	r3, sp, #64	; 0x40
   d9466:	4642      	mov	r2, r8
   d9468:	4629      	mov	r1, r5
   d946a:	f7fe fbd7 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d946e:	2400      	movs	r4, #0
   d9470:	2100      	movs	r1, #0
   d9472:	a803      	add	r0, sp, #12
   d9474:	f7fe f884 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9478:	4284      	cmp	r4, r0
   d947a:	da46      	bge.n	d950a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xda>
   d947c:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d947e:	2101      	movs	r1, #1
   d9480:	a803      	add	r0, sp, #12
   d9482:	f7fe f87d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9486:	4285      	cmp	r5, r0
   d9488:	da3d      	bge.n	d9506 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd6>
   d948a:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d948c:	2102      	movs	r1, #2
   d948e:	a803      	add	r0, sp, #12
   d9490:	f7fe f876 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9494:	4286      	cmp	r6, r0
   d9496:	da34      	bge.n	d9502 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd2>
   d9498:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d949a:	2103      	movs	r1, #3
   d949c:	a803      	add	r0, sp, #12
   d949e:	f7fe f86f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d94a2:	4287      	cmp	r7, r0
   d94a4:	da2b      	bge.n	d94fe <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xce>
          output_data[Offset(output_shape, b, y, x, c)] =
   d94a6:	9700      	str	r7, [sp, #0]
   d94a8:	4633      	mov	r3, r6
   d94aa:	462a      	mov	r2, r5
   d94ac:	4621      	mov	r1, r4
   d94ae:	a803      	add	r0, sp, #12
   d94b0:	f7fe f8cb 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d94b4:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d94b6:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d94b8:	4633      	mov	r3, r6
   d94ba:	462a      	mov	r2, r5
   d94bc:	4621      	mov	r1, r4
   d94be:	4640      	mov	r0, r8
   d94c0:	f7fe f974 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d94c4:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d94c6:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d94c8:	4633      	mov	r3, r6
   d94ca:	462a      	mov	r2, r5
   d94cc:	4621      	mov	r1, r4
   d94ce:	a810      	add	r0, sp, #64	; 0x40
   d94d0:	f7fe f96c 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d94d4:	9b22      	ldr	r3, [sp, #136]	; 0x88

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d94d6:	9a24      	ldr	r2, [sp, #144]	; 0x90
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d94d8:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   d94dc:	eb0a 0989 	add.w	r9, sl, r9, lsl #2

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d94e0:	ed99 7a00 	vldr	s14, [r9]
   d94e4:	edd0 7a00 	vldr	s15, [r0]
   d94e8:	eeb4 7a67 	vcmp.f32	s14, s15
   d94ec:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d94f0:	bf14      	ite	ne
   d94f2:	2301      	movne	r3, #1
   d94f4:	2300      	moveq	r3, #0
   d94f6:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d94fa:	3701      	adds	r7, #1
   d94fc:	e7cd      	b.n	d949a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d94fe:	3601      	adds	r6, #1
   d9500:	e7c4      	b.n	d948c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9502:	3501      	adds	r5, #1
   d9504:	e7bb      	b.n	d947e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9506:	3401      	adds	r4, #1
   d9508:	e7b2      	b.n	d9470 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d950a:	a803      	add	r0, sp, #12
   d950c:	f7fe f82d 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d9510:	b019      	add	sp, #100	; 0x64
   d9512:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9516 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9516:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d951a:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d951c:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d951e:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9520:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9522:	4691      	mov	r9, r2
   d9524:	460c      	mov	r4, r1
   d9526:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9528:	dd01      	ble.n	d952e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d952a:	f00b ffe3 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d952e:	682b      	ldr	r3, [r5, #0]
   d9530:	2b04      	cmp	r3, #4
   d9532:	dcfa      	bgt.n	d952a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d9534:	6813      	ldr	r3, [r2, #0]
   d9536:	2b04      	cmp	r3, #4
   d9538:	dcf7      	bgt.n	d952a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d953a:	2301      	movs	r3, #1
   d953c:	2104      	movs	r1, #4
   d953e:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d9540:	f10d 0820 	add.w	r8, sp, #32
   d9544:	f7fe f855 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9548:	4620      	mov	r0, r4
   d954a:	ab10      	add	r3, sp, #64	; 0x40
   d954c:	4642      	mov	r2, r8
   d954e:	4629      	mov	r1, r5
   d9550:	f7fe fb64 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9554:	2400      	movs	r4, #0
   d9556:	2100      	movs	r1, #0
   d9558:	a803      	add	r0, sp, #12
   d955a:	f7fe f811 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d955e:	4284      	cmp	r4, r0
   d9560:	da3e      	bge.n	d95e0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xca>
   d9562:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9564:	2101      	movs	r1, #1
   d9566:	a803      	add	r0, sp, #12
   d9568:	f7fe f80a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d956c:	4285      	cmp	r5, r0
   d956e:	da35      	bge.n	d95dc <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc6>
   d9570:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9572:	2102      	movs	r1, #2
   d9574:	a803      	add	r0, sp, #12
   d9576:	f7fe f803 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d957a:	4286      	cmp	r6, r0
   d957c:	da2c      	bge.n	d95d8 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc2>
   d957e:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9580:	2103      	movs	r1, #3
   d9582:	a803      	add	r0, sp, #12
   d9584:	f7fd fffc 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9588:	4287      	cmp	r7, r0
   d958a:	da23      	bge.n	d95d4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xbe>
          output_data[Offset(output_shape, b, y, x, c)] =
   d958c:	9700      	str	r7, [sp, #0]
   d958e:	4633      	mov	r3, r6
   d9590:	462a      	mov	r2, r5
   d9592:	4621      	mov	r1, r4
   d9594:	a803      	add	r0, sp, #12
   d9596:	f7fe f858 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d959a:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d959c:	4682      	mov	sl, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d959e:	4633      	mov	r3, r6
   d95a0:	462a      	mov	r2, r5
   d95a2:	4621      	mov	r1, r4
   d95a4:	4640      	mov	r0, r8
   d95a6:	f7fe f901 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d95aa:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d95ac:	4683      	mov	fp, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d95ae:	4633      	mov	r3, r6
   d95b0:	462a      	mov	r2, r5
   d95b2:	4621      	mov	r1, r4
   d95b4:	a810      	add	r0, sp, #64	; 0x40
   d95b6:	f7fe f8f9 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d95ba:	9a22      	ldr	r2, [sp, #136]	; 0x88
   d95bc:	f859 302b 	ldr.w	r3, [r9, fp, lsl #2]
   d95c0:	f852 2020 	ldr.w	r2, [r2, r0, lsl #2]
   d95c4:	1a9b      	subs	r3, r3, r2
   d95c6:	9a24      	ldr	r2, [sp, #144]	; 0x90
   d95c8:	bf18      	it	ne
   d95ca:	2301      	movne	r3, #1
   d95cc:	f802 300a 	strb.w	r3, [r2, sl]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d95d0:	3701      	adds	r7, #1
   d95d2:	e7d5      	b.n	d9580 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d95d4:	3601      	adds	r6, #1
   d95d6:	e7cc      	b.n	d9572 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d95d8:	3501      	adds	r5, #1
   d95da:	e7c3      	b.n	d9564 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d95dc:	3401      	adds	r4, #1
   d95de:	e7ba      	b.n	d9556 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d95e0:	a803      	add	r0, sp, #12
   d95e2:	f7fd ffc2 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d95e6:	b019      	add	sp, #100	; 0x64
   d95e8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d95ec <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d95ec:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d95f0:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d95f2:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d95f4:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d95f6:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d95f8:	4692      	mov	sl, r2
   d95fa:	460c      	mov	r4, r1
   d95fc:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d95fe:	dd01      	ble.n	d9604 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9600:	f00b ff78 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9604:	682b      	ldr	r3, [r5, #0]
   d9606:	2b04      	cmp	r3, #4
   d9608:	dcfa      	bgt.n	d9600 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d960a:	6813      	ldr	r3, [r2, #0]
   d960c:	2b04      	cmp	r3, #4
   d960e:	dcf7      	bgt.n	d9600 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9610:	2301      	movs	r3, #1
   d9612:	2104      	movs	r1, #4
   d9614:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d9616:	f10d 0820 	add.w	r8, sp, #32
   d961a:	f7fd ffea 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d961e:	4620      	mov	r0, r4
   d9620:	ab10      	add	r3, sp, #64	; 0x40
   d9622:	4642      	mov	r2, r8
   d9624:	4629      	mov	r1, r5
   d9626:	f7fe faf9 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d962a:	2400      	movs	r4, #0
   d962c:	2100      	movs	r1, #0
   d962e:	a803      	add	r0, sp, #12
   d9630:	f7fd ffa6 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9634:	4284      	cmp	r4, r0
   d9636:	da45      	bge.n	d96c4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd8>
   d9638:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d963a:	2101      	movs	r1, #1
   d963c:	a803      	add	r0, sp, #12
   d963e:	f7fd ff9f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9642:	4285      	cmp	r5, r0
   d9644:	da3c      	bge.n	d96c0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd4>
   d9646:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9648:	2102      	movs	r1, #2
   d964a:	a803      	add	r0, sp, #12
   d964c:	f7fd ff98 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9650:	4286      	cmp	r6, r0
   d9652:	da33      	bge.n	d96bc <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd0>
   d9654:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9656:	2103      	movs	r1, #3
   d9658:	a803      	add	r0, sp, #12
   d965a:	f7fd ff91 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d965e:	4287      	cmp	r7, r0
   d9660:	da2a      	bge.n	d96b8 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xcc>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9662:	9700      	str	r7, [sp, #0]
   d9664:	4633      	mov	r3, r6
   d9666:	462a      	mov	r2, r5
   d9668:	4621      	mov	r1, r4
   d966a:	a803      	add	r0, sp, #12
   d966c:	f7fd ffed 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9670:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9672:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9674:	4633      	mov	r3, r6
   d9676:	462a      	mov	r2, r5
   d9678:	4621      	mov	r1, r4
   d967a:	4640      	mov	r0, r8
   d967c:	f7fe f896 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9680:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9682:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9684:	4633      	mov	r3, r6
   d9686:	462a      	mov	r2, r5
   d9688:	4621      	mov	r1, r4
   d968a:	a810      	add	r0, sp, #64	; 0x40
   d968c:	f7fe f88e 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9690:	9b22      	ldr	r3, [sp, #136]	; 0x88
   d9692:	eb0a 09c9 	add.w	r9, sl, r9, lsl #3
   d9696:	eb03 03c0 	add.w	r3, r3, r0, lsl #3

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d969a:	e9d3 2300 	ldrd	r2, r3, [r3]
   d969e:	e9d9 0100 	ldrd	r0, r1, [r9]
   d96a2:	4299      	cmp	r1, r3
   d96a4:	bf08      	it	eq
   d96a6:	4290      	cmpeq	r0, r2
   d96a8:	9a24      	ldr	r2, [sp, #144]	; 0x90
   d96aa:	bf14      	ite	ne
   d96ac:	2301      	movne	r3, #1
   d96ae:	2300      	moveq	r3, #0
   d96b0:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d96b4:	3701      	adds	r7, #1
   d96b6:	e7ce      	b.n	d9656 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d96b8:	3601      	adds	r6, #1
   d96ba:	e7c5      	b.n	d9648 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d96bc:	3501      	adds	r5, #1
   d96be:	e7bc      	b.n	d963a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d96c0:	3401      	adds	r4, #1
   d96c2:	e7b3      	b.n	d962c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d96c4:	a803      	add	r0, sp, #12
   d96c6:	f7fd ff50 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d96ca:	b019      	add	sp, #100	; 0x64
   d96cc:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d96d0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d96d0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d96d4:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d96d6:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d96d8:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d96da:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d96dc:	4692      	mov	sl, r2
   d96de:	460c      	mov	r4, r1
   d96e0:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d96e2:	dd01      	ble.n	d96e8 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d96e4:	f00b ff06 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d96e8:	682b      	ldr	r3, [r5, #0]
   d96ea:	2b04      	cmp	r3, #4
   d96ec:	dcfa      	bgt.n	d96e4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d96ee:	6813      	ldr	r3, [r2, #0]
   d96f0:	2b04      	cmp	r3, #4
   d96f2:	dcf7      	bgt.n	d96e4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d96f4:	2301      	movs	r3, #1
   d96f6:	2104      	movs	r1, #4
   d96f8:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d96fa:	f10d 0820 	add.w	r8, sp, #32
   d96fe:	f7fd ff78 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9702:	4620      	mov	r0, r4
   d9704:	ab10      	add	r3, sp, #64	; 0x40
   d9706:	4642      	mov	r2, r8
   d9708:	4629      	mov	r1, r5
   d970a:	f7fe fa87 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d970e:	2400      	movs	r4, #0
   d9710:	2100      	movs	r1, #0
   d9712:	a803      	add	r0, sp, #12
   d9714:	f7fd ff34 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9718:	4284      	cmp	r4, r0
   d971a:	da46      	bge.n	d97aa <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xda>
   d971c:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d971e:	2101      	movs	r1, #1
   d9720:	a803      	add	r0, sp, #12
   d9722:	f7fd ff2d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9726:	4285      	cmp	r5, r0
   d9728:	da3d      	bge.n	d97a6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd6>
   d972a:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d972c:	2102      	movs	r1, #2
   d972e:	a803      	add	r0, sp, #12
   d9730:	f7fd ff26 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9734:	4286      	cmp	r6, r0
   d9736:	da34      	bge.n	d97a2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd2>
   d9738:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d973a:	2103      	movs	r1, #3
   d973c:	a803      	add	r0, sp, #12
   d973e:	f7fd ff1f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9742:	4287      	cmp	r7, r0
   d9744:	da2b      	bge.n	d979e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xce>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9746:	9700      	str	r7, [sp, #0]
   d9748:	4633      	mov	r3, r6
   d974a:	462a      	mov	r2, r5
   d974c:	4621      	mov	r1, r4
   d974e:	a803      	add	r0, sp, #12
   d9750:	f7fd ff7b 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9754:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9756:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9758:	4633      	mov	r3, r6
   d975a:	462a      	mov	r2, r5
   d975c:	4621      	mov	r1, r4
   d975e:	4640      	mov	r0, r8
   d9760:	f7fe f824 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9764:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9766:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9768:	4633      	mov	r3, r6
   d976a:	462a      	mov	r2, r5
   d976c:	4621      	mov	r1, r4
   d976e:	a810      	add	r0, sp, #64	; 0x40
   d9770:	f7fe f81c 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9774:	9b22      	ldr	r3, [sp, #136]	; 0x88

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9776:	9a24      	ldr	r2, [sp, #144]	; 0x90
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9778:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   d977c:	eb0a 0989 	add.w	r9, sl, r9, lsl #2

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9780:	ed99 7a00 	vldr	s14, [r9]
   d9784:	edd0 7a00 	vldr	s15, [r0]
   d9788:	eeb4 7ae7 	vcmpe.f32	s14, s15
   d978c:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d9790:	bfcc      	ite	gt
   d9792:	2301      	movgt	r3, #1
   d9794:	2300      	movle	r3, #0
   d9796:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d979a:	3701      	adds	r7, #1
   d979c:	e7cd      	b.n	d973a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d979e:	3601      	adds	r6, #1
   d97a0:	e7c4      	b.n	d972c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d97a2:	3501      	adds	r5, #1
   d97a4:	e7bb      	b.n	d971e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d97a6:	3401      	adds	r4, #1
   d97a8:	e7b2      	b.n	d9710 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d97aa:	a803      	add	r0, sp, #12
   d97ac:	f7fd fedd 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d97b0:	b019      	add	sp, #100	; 0x64
   d97b2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d97b6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d97b6:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d97ba:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d97bc:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d97be:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d97c0:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d97c2:	4691      	mov	r9, r2
   d97c4:	460c      	mov	r4, r1
   d97c6:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d97c8:	dd01      	ble.n	d97ce <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d97ca:	f00b fe93 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d97ce:	682b      	ldr	r3, [r5, #0]
   d97d0:	2b04      	cmp	r3, #4
   d97d2:	dcfa      	bgt.n	d97ca <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d97d4:	6813      	ldr	r3, [r2, #0]
   d97d6:	2b04      	cmp	r3, #4
   d97d8:	dcf7      	bgt.n	d97ca <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d97da:	2301      	movs	r3, #1
   d97dc:	2104      	movs	r1, #4
   d97de:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d97e0:	f10d 0820 	add.w	r8, sp, #32
   d97e4:	f7fd ff05 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d97e8:	4620      	mov	r0, r4
   d97ea:	ab10      	add	r3, sp, #64	; 0x40
   d97ec:	4642      	mov	r2, r8
   d97ee:	4629      	mov	r1, r5
   d97f0:	f7fe fa14 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d97f4:	2400      	movs	r4, #0
   d97f6:	2100      	movs	r1, #0
   d97f8:	a803      	add	r0, sp, #12
   d97fa:	f7fd fec1 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d97fe:	4284      	cmp	r4, r0
   d9800:	da3f      	bge.n	d9882 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xcc>
   d9802:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9804:	2101      	movs	r1, #1
   d9806:	a803      	add	r0, sp, #12
   d9808:	f7fd feba 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d980c:	4285      	cmp	r5, r0
   d980e:	da36      	bge.n	d987e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc8>
   d9810:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9812:	2102      	movs	r1, #2
   d9814:	a803      	add	r0, sp, #12
   d9816:	f7fd feb3 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d981a:	4286      	cmp	r6, r0
   d981c:	da2d      	bge.n	d987a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc4>
   d981e:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9820:	2103      	movs	r1, #3
   d9822:	a803      	add	r0, sp, #12
   d9824:	f7fd feac 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9828:	4287      	cmp	r7, r0
   d982a:	da24      	bge.n	d9876 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc0>
          output_data[Offset(output_shape, b, y, x, c)] =
   d982c:	9700      	str	r7, [sp, #0]
   d982e:	4633      	mov	r3, r6
   d9830:	462a      	mov	r2, r5
   d9832:	4621      	mov	r1, r4
   d9834:	a803      	add	r0, sp, #12
   d9836:	f7fd ff08 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d983a:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d983c:	4682      	mov	sl, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d983e:	4633      	mov	r3, r6
   d9840:	462a      	mov	r2, r5
   d9842:	4621      	mov	r1, r4
   d9844:	4640      	mov	r0, r8
   d9846:	f7fd ffb1 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d984a:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d984c:	4683      	mov	fp, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d984e:	4633      	mov	r3, r6
   d9850:	462a      	mov	r2, r5
   d9852:	4621      	mov	r1, r4
   d9854:	a810      	add	r0, sp, #64	; 0x40
   d9856:	f7fd ffa9 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d985a:	9a22      	ldr	r2, [sp, #136]	; 0x88
   d985c:	f859 302b 	ldr.w	r3, [r9, fp, lsl #2]
   d9860:	f852 2020 	ldr.w	r2, [r2, r0, lsl #2]
   d9864:	4293      	cmp	r3, r2
   d9866:	9a24      	ldr	r2, [sp, #144]	; 0x90
   d9868:	bfd4      	ite	le
   d986a:	2300      	movle	r3, #0
   d986c:	2301      	movgt	r3, #1
   d986e:	f802 300a 	strb.w	r3, [r2, sl]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9872:	3701      	adds	r7, #1
   d9874:	e7d4      	b.n	d9820 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9876:	3601      	adds	r6, #1
   d9878:	e7cb      	b.n	d9812 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d987a:	3501      	adds	r5, #1
   d987c:	e7c2      	b.n	d9804 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d987e:	3401      	adds	r4, #1
   d9880:	e7b9      	b.n	d97f6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9882:	a803      	add	r0, sp, #12
   d9884:	f7fd fe71 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d9888:	b019      	add	sp, #100	; 0x64
   d988a:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d988e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d988e:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9892:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9894:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9896:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9898:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d989a:	4692      	mov	sl, r2
   d989c:	460c      	mov	r4, r1
   d989e:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d98a0:	dd01      	ble.n	d98a6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d98a2:	f00b fe27 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d98a6:	682b      	ldr	r3, [r5, #0]
   d98a8:	2b04      	cmp	r3, #4
   d98aa:	dcfa      	bgt.n	d98a2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d98ac:	6813      	ldr	r3, [r2, #0]
   d98ae:	2b04      	cmp	r3, #4
   d98b0:	dcf7      	bgt.n	d98a2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d98b2:	2301      	movs	r3, #1
   d98b4:	2104      	movs	r1, #4
   d98b6:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d98b8:	f10d 0820 	add.w	r8, sp, #32
   d98bc:	f7fd fe99 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d98c0:	4620      	mov	r0, r4
   d98c2:	ab10      	add	r3, sp, #64	; 0x40
   d98c4:	4642      	mov	r2, r8
   d98c6:	4629      	mov	r1, r5
   d98c8:	f7fe f9a8 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d98cc:	2400      	movs	r4, #0
   d98ce:	2100      	movs	r1, #0
   d98d0:	a803      	add	r0, sp, #12
   d98d2:	f7fd fe55 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d98d6:	4284      	cmp	r4, r0
   d98d8:	da45      	bge.n	d9966 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd8>
   d98da:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d98dc:	2101      	movs	r1, #1
   d98de:	a803      	add	r0, sp, #12
   d98e0:	f7fd fe4e 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d98e4:	4285      	cmp	r5, r0
   d98e6:	da3c      	bge.n	d9962 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd4>
   d98e8:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d98ea:	2102      	movs	r1, #2
   d98ec:	a803      	add	r0, sp, #12
   d98ee:	f7fd fe47 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d98f2:	4286      	cmp	r6, r0
   d98f4:	da33      	bge.n	d995e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd0>
   d98f6:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d98f8:	2103      	movs	r1, #3
   d98fa:	a803      	add	r0, sp, #12
   d98fc:	f7fd fe40 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9900:	4287      	cmp	r7, r0
   d9902:	da2a      	bge.n	d995a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xcc>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9904:	9700      	str	r7, [sp, #0]
   d9906:	4633      	mov	r3, r6
   d9908:	462a      	mov	r2, r5
   d990a:	4621      	mov	r1, r4
   d990c:	a803      	add	r0, sp, #12
   d990e:	f7fd fe9c 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9912:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9914:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9916:	4633      	mov	r3, r6
   d9918:	462a      	mov	r2, r5
   d991a:	4621      	mov	r1, r4
   d991c:	4640      	mov	r0, r8
   d991e:	f7fd ff45 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9922:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9924:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9926:	4633      	mov	r3, r6
   d9928:	462a      	mov	r2, r5
   d992a:	4621      	mov	r1, r4
   d992c:	a810      	add	r0, sp, #64	; 0x40
   d992e:	f7fd ff3d 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9932:	9b22      	ldr	r3, [sp, #136]	; 0x88
   d9934:	eb0a 09c9 	add.w	r9, sl, r9, lsl #3
   d9938:	eb03 00c0 	add.w	r0, r3, r0, lsl #3

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d993c:	e9d0 0100 	ldrd	r0, r1, [r0]
   d9940:	e9d9 2300 	ldrd	r2, r3, [r9]
   d9944:	4290      	cmp	r0, r2
   d9946:	eb71 0303 	sbcs.w	r3, r1, r3
   d994a:	9a24      	ldr	r2, [sp, #144]	; 0x90
   d994c:	bfb4      	ite	lt
   d994e:	2301      	movlt	r3, #1
   d9950:	2300      	movge	r3, #0
   d9952:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9956:	3701      	adds	r7, #1
   d9958:	e7ce      	b.n	d98f8 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d995a:	3601      	adds	r6, #1
   d995c:	e7c5      	b.n	d98ea <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d995e:	3501      	adds	r5, #1
   d9960:	e7bc      	b.n	d98dc <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9962:	3401      	adds	r4, #1
   d9964:	e7b3      	b.n	d98ce <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9966:	a803      	add	r0, sp, #12
   d9968:	f7fd fdff 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d996c:	b019      	add	sp, #100	; 0x64
   d996e:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9972 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9972:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9976:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9978:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d997a:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d997c:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d997e:	4692      	mov	sl, r2
   d9980:	460c      	mov	r4, r1
   d9982:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9984:	dd01      	ble.n	d998a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9986:	f00b fdb5 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d998a:	682b      	ldr	r3, [r5, #0]
   d998c:	2b04      	cmp	r3, #4
   d998e:	dcfa      	bgt.n	d9986 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d9990:	6813      	ldr	r3, [r2, #0]
   d9992:	2b04      	cmp	r3, #4
   d9994:	dcf7      	bgt.n	d9986 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9996:	2301      	movs	r3, #1
   d9998:	2104      	movs	r1, #4
   d999a:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d999c:	f10d 0820 	add.w	r8, sp, #32
   d99a0:	f7fd fe27 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d99a4:	4620      	mov	r0, r4
   d99a6:	ab10      	add	r3, sp, #64	; 0x40
   d99a8:	4642      	mov	r2, r8
   d99aa:	4629      	mov	r1, r5
   d99ac:	f7fe f936 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d99b0:	2400      	movs	r4, #0
   d99b2:	2100      	movs	r1, #0
   d99b4:	a803      	add	r0, sp, #12
   d99b6:	f7fd fde3 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d99ba:	4284      	cmp	r4, r0
   d99bc:	da46      	bge.n	d9a4c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xda>
   d99be:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d99c0:	2101      	movs	r1, #1
   d99c2:	a803      	add	r0, sp, #12
   d99c4:	f7fd fddc 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d99c8:	4285      	cmp	r5, r0
   d99ca:	da3d      	bge.n	d9a48 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd6>
   d99cc:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d99ce:	2102      	movs	r1, #2
   d99d0:	a803      	add	r0, sp, #12
   d99d2:	f7fd fdd5 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d99d6:	4286      	cmp	r6, r0
   d99d8:	da34      	bge.n	d9a44 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd2>
   d99da:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d99dc:	2103      	movs	r1, #3
   d99de:	a803      	add	r0, sp, #12
   d99e0:	f7fd fdce 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d99e4:	4287      	cmp	r7, r0
   d99e6:	da2b      	bge.n	d9a40 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xce>
          output_data[Offset(output_shape, b, y, x, c)] =
   d99e8:	9700      	str	r7, [sp, #0]
   d99ea:	4633      	mov	r3, r6
   d99ec:	462a      	mov	r2, r5
   d99ee:	4621      	mov	r1, r4
   d99f0:	a803      	add	r0, sp, #12
   d99f2:	f7fd fe2a 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d99f6:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d99f8:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d99fa:	4633      	mov	r3, r6
   d99fc:	462a      	mov	r2, r5
   d99fe:	4621      	mov	r1, r4
   d9a00:	4640      	mov	r0, r8
   d9a02:	f7fd fed3 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9a06:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9a08:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9a0a:	4633      	mov	r3, r6
   d9a0c:	462a      	mov	r2, r5
   d9a0e:	4621      	mov	r1, r4
   d9a10:	a810      	add	r0, sp, #64	; 0x40
   d9a12:	f7fd fecb 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9a16:	9b22      	ldr	r3, [sp, #136]	; 0x88

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9a18:	9a24      	ldr	r2, [sp, #144]	; 0x90
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9a1a:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   d9a1e:	eb0a 0989 	add.w	r9, sl, r9, lsl #2

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9a22:	ed99 7a00 	vldr	s14, [r9]
   d9a26:	edd0 7a00 	vldr	s15, [r0]
   d9a2a:	eeb4 7ae7 	vcmpe.f32	s14, s15
   d9a2e:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d9a32:	bfac      	ite	ge
   d9a34:	2301      	movge	r3, #1
   d9a36:	2300      	movlt	r3, #0
   d9a38:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9a3c:	3701      	adds	r7, #1
   d9a3e:	e7cd      	b.n	d99dc <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9a40:	3601      	adds	r6, #1
   d9a42:	e7c4      	b.n	d99ce <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9a44:	3501      	adds	r5, #1
   d9a46:	e7bb      	b.n	d99c0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9a48:	3401      	adds	r4, #1
   d9a4a:	e7b2      	b.n	d99b2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9a4c:	a803      	add	r0, sp, #12
   d9a4e:	f7fd fd8c 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d9a52:	b019      	add	sp, #100	; 0x64
   d9a54:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9a58 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9a58:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9a5c:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9a5e:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9a60:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9a62:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9a64:	4691      	mov	r9, r2
   d9a66:	460c      	mov	r4, r1
   d9a68:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9a6a:	dd01      	ble.n	d9a70 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9a6c:	f00b fd42 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9a70:	682b      	ldr	r3, [r5, #0]
   d9a72:	2b04      	cmp	r3, #4
   d9a74:	dcfa      	bgt.n	d9a6c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d9a76:	6813      	ldr	r3, [r2, #0]
   d9a78:	2b04      	cmp	r3, #4
   d9a7a:	dcf7      	bgt.n	d9a6c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9a7c:	2301      	movs	r3, #1
   d9a7e:	2104      	movs	r1, #4
   d9a80:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d9a82:	f10d 0820 	add.w	r8, sp, #32
   d9a86:	f7fd fdb4 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9a8a:	4620      	mov	r0, r4
   d9a8c:	ab10      	add	r3, sp, #64	; 0x40
   d9a8e:	4642      	mov	r2, r8
   d9a90:	4629      	mov	r1, r5
   d9a92:	f7fe f8c3 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9a96:	2400      	movs	r4, #0
   d9a98:	2100      	movs	r1, #0
   d9a9a:	a803      	add	r0, sp, #12
   d9a9c:	f7fd fd70 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9aa0:	4284      	cmp	r4, r0
   d9aa2:	da3f      	bge.n	d9b24 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xcc>
   d9aa4:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9aa6:	2101      	movs	r1, #1
   d9aa8:	a803      	add	r0, sp, #12
   d9aaa:	f7fd fd69 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9aae:	4285      	cmp	r5, r0
   d9ab0:	da36      	bge.n	d9b20 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc8>
   d9ab2:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9ab4:	2102      	movs	r1, #2
   d9ab6:	a803      	add	r0, sp, #12
   d9ab8:	f7fd fd62 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9abc:	4286      	cmp	r6, r0
   d9abe:	da2d      	bge.n	d9b1c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc4>
   d9ac0:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9ac2:	2103      	movs	r1, #3
   d9ac4:	a803      	add	r0, sp, #12
   d9ac6:	f7fd fd5b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9aca:	4287      	cmp	r7, r0
   d9acc:	da24      	bge.n	d9b18 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc0>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9ace:	9700      	str	r7, [sp, #0]
   d9ad0:	4633      	mov	r3, r6
   d9ad2:	462a      	mov	r2, r5
   d9ad4:	4621      	mov	r1, r4
   d9ad6:	a803      	add	r0, sp, #12
   d9ad8:	f7fd fdb7 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9adc:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9ade:	4682      	mov	sl, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9ae0:	4633      	mov	r3, r6
   d9ae2:	462a      	mov	r2, r5
   d9ae4:	4621      	mov	r1, r4
   d9ae6:	4640      	mov	r0, r8
   d9ae8:	f7fd fe60 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9aec:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9aee:	4683      	mov	fp, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9af0:	4633      	mov	r3, r6
   d9af2:	462a      	mov	r2, r5
   d9af4:	4621      	mov	r1, r4
   d9af6:	a810      	add	r0, sp, #64	; 0x40
   d9af8:	f7fd fe58 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9afc:	9a22      	ldr	r2, [sp, #136]	; 0x88
   d9afe:	f859 302b 	ldr.w	r3, [r9, fp, lsl #2]
   d9b02:	f852 2020 	ldr.w	r2, [r2, r0, lsl #2]
   d9b06:	4293      	cmp	r3, r2
   d9b08:	9a24      	ldr	r2, [sp, #144]	; 0x90
   d9b0a:	bfb4      	ite	lt
   d9b0c:	2300      	movlt	r3, #0
   d9b0e:	2301      	movge	r3, #1
   d9b10:	f802 300a 	strb.w	r3, [r2, sl]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9b14:	3701      	adds	r7, #1
   d9b16:	e7d4      	b.n	d9ac2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9b18:	3601      	adds	r6, #1
   d9b1a:	e7cb      	b.n	d9ab4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9b1c:	3501      	adds	r5, #1
   d9b1e:	e7c2      	b.n	d9aa6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9b20:	3401      	adds	r4, #1
   d9b22:	e7b9      	b.n	d9a98 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9b24:	a803      	add	r0, sp, #12
   d9b26:	f7fd fd20 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d9b2a:	b019      	add	sp, #100	; 0x64
   d9b2c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9b30 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9b30:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9b34:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9b36:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9b38:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9b3a:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9b3c:	4692      	mov	sl, r2
   d9b3e:	460c      	mov	r4, r1
   d9b40:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9b42:	dd01      	ble.n	d9b48 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9b44:	f00b fcd6 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9b48:	682b      	ldr	r3, [r5, #0]
   d9b4a:	2b04      	cmp	r3, #4
   d9b4c:	dcfa      	bgt.n	d9b44 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d9b4e:	6813      	ldr	r3, [r2, #0]
   d9b50:	2b04      	cmp	r3, #4
   d9b52:	dcf7      	bgt.n	d9b44 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9b54:	2301      	movs	r3, #1
   d9b56:	2104      	movs	r1, #4
   d9b58:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d9b5a:	f10d 0820 	add.w	r8, sp, #32
   d9b5e:	f7fd fd48 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9b62:	4620      	mov	r0, r4
   d9b64:	ab10      	add	r3, sp, #64	; 0x40
   d9b66:	4642      	mov	r2, r8
   d9b68:	4629      	mov	r1, r5
   d9b6a:	f7fe f857 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9b6e:	2400      	movs	r4, #0
   d9b70:	2100      	movs	r1, #0
   d9b72:	a803      	add	r0, sp, #12
   d9b74:	f7fd fd04 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9b78:	4284      	cmp	r4, r0
   d9b7a:	da45      	bge.n	d9c08 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd8>
   d9b7c:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9b7e:	2101      	movs	r1, #1
   d9b80:	a803      	add	r0, sp, #12
   d9b82:	f7fd fcfd 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9b86:	4285      	cmp	r5, r0
   d9b88:	da3c      	bge.n	d9c04 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd4>
   d9b8a:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9b8c:	2102      	movs	r1, #2
   d9b8e:	a803      	add	r0, sp, #12
   d9b90:	f7fd fcf6 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9b94:	4286      	cmp	r6, r0
   d9b96:	da33      	bge.n	d9c00 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd0>
   d9b98:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9b9a:	2103      	movs	r1, #3
   d9b9c:	a803      	add	r0, sp, #12
   d9b9e:	f7fd fcef 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9ba2:	4287      	cmp	r7, r0
   d9ba4:	da2a      	bge.n	d9bfc <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xcc>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9ba6:	9700      	str	r7, [sp, #0]
   d9ba8:	4633      	mov	r3, r6
   d9baa:	462a      	mov	r2, r5
   d9bac:	4621      	mov	r1, r4
   d9bae:	a803      	add	r0, sp, #12
   d9bb0:	f7fd fd4b 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9bb4:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9bb6:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9bb8:	4633      	mov	r3, r6
   d9bba:	462a      	mov	r2, r5
   d9bbc:	4621      	mov	r1, r4
   d9bbe:	4640      	mov	r0, r8
   d9bc0:	f7fd fdf4 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9bc4:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9bc6:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9bc8:	4633      	mov	r3, r6
   d9bca:	462a      	mov	r2, r5
   d9bcc:	4621      	mov	r1, r4
   d9bce:	a810      	add	r0, sp, #64	; 0x40
   d9bd0:	f7fd fdec 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9bd4:	9b22      	ldr	r3, [sp, #136]	; 0x88
   d9bd6:	eb0a 09c9 	add.w	r9, sl, r9, lsl #3
   d9bda:	eb03 03c0 	add.w	r3, r3, r0, lsl #3

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9bde:	e9d3 2300 	ldrd	r2, r3, [r3]
   d9be2:	e9d9 0100 	ldrd	r0, r1, [r9]
   d9be6:	4290      	cmp	r0, r2
   d9be8:	eb71 0303 	sbcs.w	r3, r1, r3
   d9bec:	9a24      	ldr	r2, [sp, #144]	; 0x90
   d9bee:	bfac      	ite	ge
   d9bf0:	2301      	movge	r3, #1
   d9bf2:	2300      	movlt	r3, #0
   d9bf4:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9bf8:	3701      	adds	r7, #1
   d9bfa:	e7ce      	b.n	d9b9a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9bfc:	3601      	adds	r6, #1
   d9bfe:	e7c5      	b.n	d9b8c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9c00:	3501      	adds	r5, #1
   d9c02:	e7bc      	b.n	d9b7e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9c04:	3401      	adds	r4, #1
   d9c06:	e7b3      	b.n	d9b70 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9c08:	a803      	add	r0, sp, #12
   d9c0a:	f7fd fcae 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d9c0e:	b019      	add	sp, #100	; 0x64
   d9c10:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9c14 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9c14:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9c18:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9c1a:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9c1c:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9c1e:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9c20:	4692      	mov	sl, r2
   d9c22:	460c      	mov	r4, r1
   d9c24:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9c26:	dd01      	ble.n	d9c2c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9c28:	f00b fc64 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9c2c:	682b      	ldr	r3, [r5, #0]
   d9c2e:	2b04      	cmp	r3, #4
   d9c30:	dcfa      	bgt.n	d9c28 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d9c32:	6813      	ldr	r3, [r2, #0]
   d9c34:	2b04      	cmp	r3, #4
   d9c36:	dcf7      	bgt.n	d9c28 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9c38:	2301      	movs	r3, #1
   d9c3a:	2104      	movs	r1, #4
   d9c3c:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d9c3e:	f10d 0820 	add.w	r8, sp, #32
   d9c42:	f7fd fcd6 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9c46:	4620      	mov	r0, r4
   d9c48:	ab10      	add	r3, sp, #64	; 0x40
   d9c4a:	4642      	mov	r2, r8
   d9c4c:	4629      	mov	r1, r5
   d9c4e:	f7fd ffe5 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9c52:	2400      	movs	r4, #0
   d9c54:	2100      	movs	r1, #0
   d9c56:	a803      	add	r0, sp, #12
   d9c58:	f7fd fc92 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9c5c:	4284      	cmp	r4, r0
   d9c5e:	da46      	bge.n	d9cee <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xda>
   d9c60:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9c62:	2101      	movs	r1, #1
   d9c64:	a803      	add	r0, sp, #12
   d9c66:	f7fd fc8b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9c6a:	4285      	cmp	r5, r0
   d9c6c:	da3d      	bge.n	d9cea <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd6>
   d9c6e:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9c70:	2102      	movs	r1, #2
   d9c72:	a803      	add	r0, sp, #12
   d9c74:	f7fd fc84 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9c78:	4286      	cmp	r6, r0
   d9c7a:	da34      	bge.n	d9ce6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd2>
   d9c7c:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9c7e:	2103      	movs	r1, #3
   d9c80:	a803      	add	r0, sp, #12
   d9c82:	f7fd fc7d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9c86:	4287      	cmp	r7, r0
   d9c88:	da2b      	bge.n	d9ce2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xce>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9c8a:	9700      	str	r7, [sp, #0]
   d9c8c:	4633      	mov	r3, r6
   d9c8e:	462a      	mov	r2, r5
   d9c90:	4621      	mov	r1, r4
   d9c92:	a803      	add	r0, sp, #12
   d9c94:	f7fd fcd9 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9c98:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9c9a:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9c9c:	4633      	mov	r3, r6
   d9c9e:	462a      	mov	r2, r5
   d9ca0:	4621      	mov	r1, r4
   d9ca2:	4640      	mov	r0, r8
   d9ca4:	f7fd fd82 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9ca8:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9caa:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9cac:	4633      	mov	r3, r6
   d9cae:	462a      	mov	r2, r5
   d9cb0:	4621      	mov	r1, r4
   d9cb2:	a810      	add	r0, sp, #64	; 0x40
   d9cb4:	f7fd fd7a 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9cb8:	9b22      	ldr	r3, [sp, #136]	; 0x88

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9cba:	9a24      	ldr	r2, [sp, #144]	; 0x90
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9cbc:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   d9cc0:	eb0a 0989 	add.w	r9, sl, r9, lsl #2

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9cc4:	ed99 7a00 	vldr	s14, [r9]
   d9cc8:	edd0 7a00 	vldr	s15, [r0]
   d9ccc:	eeb4 7ae7 	vcmpe.f32	s14, s15
   d9cd0:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d9cd4:	bf4c      	ite	mi
   d9cd6:	2301      	movmi	r3, #1
   d9cd8:	2300      	movpl	r3, #0
   d9cda:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9cde:	3701      	adds	r7, #1
   d9ce0:	e7cd      	b.n	d9c7e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9ce2:	3601      	adds	r6, #1
   d9ce4:	e7c4      	b.n	d9c70 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9ce6:	3501      	adds	r5, #1
   d9ce8:	e7bb      	b.n	d9c62 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9cea:	3401      	adds	r4, #1
   d9cec:	e7b2      	b.n	d9c54 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9cee:	a803      	add	r0, sp, #12
   d9cf0:	f7fd fc3b 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d9cf4:	b019      	add	sp, #100	; 0x64
   d9cf6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9cfa <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9cfa:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9cfe:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9d00:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9d02:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9d04:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9d06:	4691      	mov	r9, r2
   d9d08:	460c      	mov	r4, r1
   d9d0a:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9d0c:	dd01      	ble.n	d9d12 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9d0e:	f00b fbf1 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9d12:	682b      	ldr	r3, [r5, #0]
   d9d14:	2b04      	cmp	r3, #4
   d9d16:	dcfa      	bgt.n	d9d0e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d9d18:	6813      	ldr	r3, [r2, #0]
   d9d1a:	2b04      	cmp	r3, #4
   d9d1c:	dcf7      	bgt.n	d9d0e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9d1e:	2301      	movs	r3, #1
   d9d20:	2104      	movs	r1, #4
   d9d22:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d9d24:	f10d 0820 	add.w	r8, sp, #32
   d9d28:	f7fd fc63 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9d2c:	4620      	mov	r0, r4
   d9d2e:	ab10      	add	r3, sp, #64	; 0x40
   d9d30:	4642      	mov	r2, r8
   d9d32:	4629      	mov	r1, r5
   d9d34:	f7fd ff72 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9d38:	2400      	movs	r4, #0
   d9d3a:	2100      	movs	r1, #0
   d9d3c:	a803      	add	r0, sp, #12
   d9d3e:	f7fd fc1f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9d42:	4284      	cmp	r4, r0
   d9d44:	da3f      	bge.n	d9dc6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xcc>
   d9d46:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9d48:	2101      	movs	r1, #1
   d9d4a:	a803      	add	r0, sp, #12
   d9d4c:	f7fd fc18 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9d50:	4285      	cmp	r5, r0
   d9d52:	da36      	bge.n	d9dc2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc8>
   d9d54:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9d56:	2102      	movs	r1, #2
   d9d58:	a803      	add	r0, sp, #12
   d9d5a:	f7fd fc11 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9d5e:	4286      	cmp	r6, r0
   d9d60:	da2d      	bge.n	d9dbe <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc4>
   d9d62:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9d64:	2103      	movs	r1, #3
   d9d66:	a803      	add	r0, sp, #12
   d9d68:	f7fd fc0a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9d6c:	4287      	cmp	r7, r0
   d9d6e:	da24      	bge.n	d9dba <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc0>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9d70:	9700      	str	r7, [sp, #0]
   d9d72:	4633      	mov	r3, r6
   d9d74:	462a      	mov	r2, r5
   d9d76:	4621      	mov	r1, r4
   d9d78:	a803      	add	r0, sp, #12
   d9d7a:	f7fd fc66 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9d7e:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9d80:	4682      	mov	sl, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9d82:	4633      	mov	r3, r6
   d9d84:	462a      	mov	r2, r5
   d9d86:	4621      	mov	r1, r4
   d9d88:	4640      	mov	r0, r8
   d9d8a:	f7fd fd0f 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9d8e:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9d90:	4683      	mov	fp, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9d92:	4633      	mov	r3, r6
   d9d94:	462a      	mov	r2, r5
   d9d96:	4621      	mov	r1, r4
   d9d98:	a810      	add	r0, sp, #64	; 0x40
   d9d9a:	f7fd fd07 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9d9e:	9a22      	ldr	r2, [sp, #136]	; 0x88
   d9da0:	f859 302b 	ldr.w	r3, [r9, fp, lsl #2]
   d9da4:	f852 2020 	ldr.w	r2, [r2, r0, lsl #2]
   d9da8:	4293      	cmp	r3, r2
   d9daa:	9a24      	ldr	r2, [sp, #144]	; 0x90
   d9dac:	bfac      	ite	ge
   d9dae:	2300      	movge	r3, #0
   d9db0:	2301      	movlt	r3, #1
   d9db2:	f802 300a 	strb.w	r3, [r2, sl]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9db6:	3701      	adds	r7, #1
   d9db8:	e7d4      	b.n	d9d64 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9dba:	3601      	adds	r6, #1
   d9dbc:	e7cb      	b.n	d9d56 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9dbe:	3501      	adds	r5, #1
   d9dc0:	e7c2      	b.n	d9d48 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9dc2:	3401      	adds	r4, #1
   d9dc4:	e7b9      	b.n	d9d3a <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9dc6:	a803      	add	r0, sp, #12
   d9dc8:	f7fd fbcf 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d9dcc:	b019      	add	sp, #100	; 0x64
   d9dce:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9dd2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9dd2:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9dd6:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9dd8:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9dda:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9ddc:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9dde:	4692      	mov	sl, r2
   d9de0:	460c      	mov	r4, r1
   d9de2:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9de4:	dd01      	ble.n	d9dea <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9de6:	f00b fb85 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9dea:	682b      	ldr	r3, [r5, #0]
   d9dec:	2b04      	cmp	r3, #4
   d9dee:	dcfa      	bgt.n	d9de6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d9df0:	6813      	ldr	r3, [r2, #0]
   d9df2:	2b04      	cmp	r3, #4
   d9df4:	dcf7      	bgt.n	d9de6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9df6:	2301      	movs	r3, #1
   d9df8:	2104      	movs	r1, #4
   d9dfa:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d9dfc:	f10d 0820 	add.w	r8, sp, #32
   d9e00:	f7fd fbf7 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9e04:	4620      	mov	r0, r4
   d9e06:	ab10      	add	r3, sp, #64	; 0x40
   d9e08:	4642      	mov	r2, r8
   d9e0a:	4629      	mov	r1, r5
   d9e0c:	f7fd ff06 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9e10:	2400      	movs	r4, #0
   d9e12:	2100      	movs	r1, #0
   d9e14:	a803      	add	r0, sp, #12
   d9e16:	f7fd fbb3 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9e1a:	4284      	cmp	r4, r0
   d9e1c:	da45      	bge.n	d9eaa <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd8>
   d9e1e:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9e20:	2101      	movs	r1, #1
   d9e22:	a803      	add	r0, sp, #12
   d9e24:	f7fd fbac 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9e28:	4285      	cmp	r5, r0
   d9e2a:	da3c      	bge.n	d9ea6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd4>
   d9e2c:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9e2e:	2102      	movs	r1, #2
   d9e30:	a803      	add	r0, sp, #12
   d9e32:	f7fd fba5 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9e36:	4286      	cmp	r6, r0
   d9e38:	da33      	bge.n	d9ea2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd0>
   d9e3a:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9e3c:	2103      	movs	r1, #3
   d9e3e:	a803      	add	r0, sp, #12
   d9e40:	f7fd fb9e 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9e44:	4287      	cmp	r7, r0
   d9e46:	da2a      	bge.n	d9e9e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xcc>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9e48:	9700      	str	r7, [sp, #0]
   d9e4a:	4633      	mov	r3, r6
   d9e4c:	462a      	mov	r2, r5
   d9e4e:	4621      	mov	r1, r4
   d9e50:	a803      	add	r0, sp, #12
   d9e52:	f7fd fbfa 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9e56:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9e58:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9e5a:	4633      	mov	r3, r6
   d9e5c:	462a      	mov	r2, r5
   d9e5e:	4621      	mov	r1, r4
   d9e60:	4640      	mov	r0, r8
   d9e62:	f7fd fca3 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9e66:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9e68:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9e6a:	4633      	mov	r3, r6
   d9e6c:	462a      	mov	r2, r5
   d9e6e:	4621      	mov	r1, r4
   d9e70:	a810      	add	r0, sp, #64	; 0x40
   d9e72:	f7fd fc9b 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9e76:	9b22      	ldr	r3, [sp, #136]	; 0x88
   d9e78:	eb0a 09c9 	add.w	r9, sl, r9, lsl #3
   d9e7c:	eb03 03c0 	add.w	r3, r3, r0, lsl #3

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9e80:	e9d3 2300 	ldrd	r2, r3, [r3]
   d9e84:	e9d9 0100 	ldrd	r0, r1, [r9]
   d9e88:	4290      	cmp	r0, r2
   d9e8a:	eb71 0303 	sbcs.w	r3, r1, r3
   d9e8e:	9a24      	ldr	r2, [sp, #144]	; 0x90
   d9e90:	bfb4      	ite	lt
   d9e92:	2301      	movlt	r3, #1
   d9e94:	2300      	movge	r3, #0
   d9e96:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9e9a:	3701      	adds	r7, #1
   d9e9c:	e7ce      	b.n	d9e3c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9e9e:	3601      	adds	r6, #1
   d9ea0:	e7c5      	b.n	d9e2e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9ea2:	3501      	adds	r5, #1
   d9ea4:	e7bc      	b.n	d9e20 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9ea6:	3401      	adds	r4, #1
   d9ea8:	e7b3      	b.n	d9e12 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9eaa:	a803      	add	r0, sp, #12
   d9eac:	f7fd fb5d 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d9eb0:	b019      	add	sp, #100	; 0x64
   d9eb2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9eb6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9eb6:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9eba:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9ebc:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9ebe:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9ec0:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9ec2:	4692      	mov	sl, r2
   d9ec4:	460c      	mov	r4, r1
   d9ec6:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9ec8:	dd01      	ble.n	d9ece <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9eca:	f00b fb13 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9ece:	682b      	ldr	r3, [r5, #0]
   d9ed0:	2b04      	cmp	r3, #4
   d9ed2:	dcfa      	bgt.n	d9eca <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d9ed4:	6813      	ldr	r3, [r2, #0]
   d9ed6:	2b04      	cmp	r3, #4
   d9ed8:	dcf7      	bgt.n	d9eca <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9eda:	2301      	movs	r3, #1
   d9edc:	2104      	movs	r1, #4
   d9ede:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d9ee0:	f10d 0820 	add.w	r8, sp, #32
   d9ee4:	f7fd fb85 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9ee8:	4620      	mov	r0, r4
   d9eea:	ab10      	add	r3, sp, #64	; 0x40
   d9eec:	4642      	mov	r2, r8
   d9eee:	4629      	mov	r1, r5
   d9ef0:	f7fd fe94 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9ef4:	2400      	movs	r4, #0
   d9ef6:	2100      	movs	r1, #0
   d9ef8:	a803      	add	r0, sp, #12
   d9efa:	f7fd fb41 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9efe:	4284      	cmp	r4, r0
   d9f00:	da46      	bge.n	d9f90 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xda>
   d9f02:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9f04:	2101      	movs	r1, #1
   d9f06:	a803      	add	r0, sp, #12
   d9f08:	f7fd fb3a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9f0c:	4285      	cmp	r5, r0
   d9f0e:	da3d      	bge.n	d9f8c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd6>
   d9f10:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9f12:	2102      	movs	r1, #2
   d9f14:	a803      	add	r0, sp, #12
   d9f16:	f7fd fb33 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9f1a:	4286      	cmp	r6, r0
   d9f1c:	da34      	bge.n	d9f88 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd2>
   d9f1e:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9f20:	2103      	movs	r1, #3
   d9f22:	a803      	add	r0, sp, #12
   d9f24:	f7fd fb2c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9f28:	4287      	cmp	r7, r0
   d9f2a:	da2b      	bge.n	d9f84 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xce>
          output_data[Offset(output_shape, b, y, x, c)] =
   d9f2c:	9700      	str	r7, [sp, #0]
   d9f2e:	4633      	mov	r3, r6
   d9f30:	462a      	mov	r2, r5
   d9f32:	4621      	mov	r1, r4
   d9f34:	a803      	add	r0, sp, #12
   d9f36:	f7fd fb88 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9f3a:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9f3c:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9f3e:	4633      	mov	r3, r6
   d9f40:	462a      	mov	r2, r5
   d9f42:	4621      	mov	r1, r4
   d9f44:	4640      	mov	r0, r8
   d9f46:	f7fd fc31 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9f4a:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9f4c:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   d9f4e:	4633      	mov	r3, r6
   d9f50:	462a      	mov	r2, r5
   d9f52:	4621      	mov	r1, r4
   d9f54:	a810      	add	r0, sp, #64	; 0x40
   d9f56:	f7fd fc29 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9f5a:	9b22      	ldr	r3, [sp, #136]	; 0x88

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9f5c:	9a24      	ldr	r2, [sp, #144]	; 0x90
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   d9f5e:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   d9f62:	eb0a 0989 	add.w	r9, sl, r9, lsl #2

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   d9f66:	ed99 7a00 	vldr	s14, [r9]
   d9f6a:	edd0 7a00 	vldr	s15, [r0]
   d9f6e:	eeb4 7ae7 	vcmpe.f32	s14, s15
   d9f72:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   d9f76:	bf94      	ite	ls
   d9f78:	2301      	movls	r3, #1
   d9f7a:	2300      	movhi	r3, #0
   d9f7c:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   d9f80:	3701      	adds	r7, #1
   d9f82:	e7cd      	b.n	d9f20 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9f84:	3601      	adds	r6, #1
   d9f86:	e7c4      	b.n	d9f12 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9f88:	3501      	adds	r5, #1
   d9f8a:	e7bb      	b.n	d9f04 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9f8c:	3401      	adds	r4, #1
   d9f8e:	e7b2      	b.n	d9ef6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   d9f90:	a803      	add	r0, sp, #12
   d9f92:	f7fd faea 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   d9f96:	b019      	add	sp, #100	; 0x64
   d9f98:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000d9f9c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9f9c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   d9fa0:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9fa2:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9fa4:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9fa6:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   d9fa8:	4691      	mov	r9, r2
   d9faa:	460c      	mov	r4, r1
   d9fac:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   d9fae:	dd01      	ble.n	d9fb4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   d9fb0:	f00b faa0 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   d9fb4:	682b      	ldr	r3, [r5, #0]
   d9fb6:	2b04      	cmp	r3, #4
   d9fb8:	dcfa      	bgt.n	d9fb0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   d9fba:	6813      	ldr	r3, [r2, #0]
   d9fbc:	2b04      	cmp	r3, #4
   d9fbe:	dcf7      	bgt.n	d9fb0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   d9fc0:	2301      	movs	r3, #1
   d9fc2:	2104      	movs	r1, #4
   d9fc4:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   d9fc6:	f10d 0820 	add.w	r8, sp, #32
   d9fca:	f7fd fb12 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   d9fce:	4620      	mov	r0, r4
   d9fd0:	ab10      	add	r3, sp, #64	; 0x40
   d9fd2:	4642      	mov	r2, r8
   d9fd4:	4629      	mov	r1, r5
   d9fd6:	f7fd fe21 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   d9fda:	2400      	movs	r4, #0
   d9fdc:	2100      	movs	r1, #0
   d9fde:	a803      	add	r0, sp, #12
   d9fe0:	f7fd face 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9fe4:	4284      	cmp	r4, r0
   d9fe6:	da3f      	bge.n	da068 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xcc>
   d9fe8:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   d9fea:	2101      	movs	r1, #1
   d9fec:	a803      	add	r0, sp, #12
   d9fee:	f7fd fac7 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   d9ff2:	4285      	cmp	r5, r0
   d9ff4:	da36      	bge.n	da064 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc8>
   d9ff6:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   d9ff8:	2102      	movs	r1, #2
   d9ffa:	a803      	add	r0, sp, #12
   d9ffc:	f7fd fac0 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da000:	4286      	cmp	r6, r0
   da002:	da2d      	bge.n	da060 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc4>
   da004:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da006:	2103      	movs	r1, #3
   da008:	a803      	add	r0, sp, #12
   da00a:	f7fd fab9 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da00e:	4287      	cmp	r7, r0
   da010:	da24      	bge.n	da05c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xc0>
          output_data[Offset(output_shape, b, y, x, c)] =
   da012:	9700      	str	r7, [sp, #0]
   da014:	4633      	mov	r3, r6
   da016:	462a      	mov	r2, r5
   da018:	4621      	mov	r1, r4
   da01a:	a803      	add	r0, sp, #12
   da01c:	f7fd fb15 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   da020:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   da022:	4682      	mov	sl, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   da024:	4633      	mov	r3, r6
   da026:	462a      	mov	r2, r5
   da028:	4621      	mov	r1, r4
   da02a:	4640      	mov	r0, r8
   da02c:	f7fd fbbe 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   da030:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   da032:	4683      	mov	fp, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   da034:	4633      	mov	r3, r6
   da036:	462a      	mov	r2, r5
   da038:	4621      	mov	r1, r4
   da03a:	a810      	add	r0, sp, #64	; 0x40
   da03c:	f7fd fbb6 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   da040:	9a22      	ldr	r2, [sp, #136]	; 0x88
   da042:	f859 302b 	ldr.w	r3, [r9, fp, lsl #2]
   da046:	f852 2020 	ldr.w	r2, [r2, r0, lsl #2]
   da04a:	4293      	cmp	r3, r2
   da04c:	9a24      	ldr	r2, [sp, #144]	; 0x90
   da04e:	bfcc      	ite	gt
   da050:	2300      	movgt	r3, #0
   da052:	2301      	movle	r3, #1
   da054:	f802 300a 	strb.w	r3, [r2, sl]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da058:	3701      	adds	r7, #1
   da05a:	e7d4      	b.n	da006 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   da05c:	3601      	adds	r6, #1
   da05e:	e7cb      	b.n	d9ff8 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   da060:	3501      	adds	r5, #1
   da062:	e7c2      	b.n	d9fea <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da064:	3401      	adds	r4, #1
   da066:	e7b9      	b.n	d9fdc <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   da068:	a803      	add	r0, sp, #12
   da06a:	f7fd fa7e 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   da06e:	b019      	add	sp, #100	; 0x64
   da070:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000da074 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   da074:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   da078:	461d      	mov	r5, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da07a:	680b      	ldr	r3, [r1, #0]
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   da07c:	b099      	sub	sp, #100	; 0x64
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da07e:	2b04      	cmp	r3, #4
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
  }
}

template <typename T, ComparisonFn<T> F>
inline void BroadcastComparison4DSlowImpl(
   da080:	4692      	mov	sl, r2
   da082:	460c      	mov	r4, r1
   da084:	9a23      	ldr	r2, [sp, #140]	; 0x8c
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da086:	dd01      	ble.n	da08c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x18>
   da088:	f00b fa34 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   da08c:	682b      	ldr	r3, [r5, #0]
   da08e:	2b04      	cmp	r3, #4
   da090:	dcfa      	bgt.n	da088 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   da092:	6813      	ldr	r3, [r2, #0]
   da094:	2b04      	cmp	r3, #4
   da096:	dcf7      	bgt.n	da088 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x14>
   da098:	2301      	movs	r3, #1
   da09a:	2104      	movs	r1, #4
   da09c:	a803      	add	r0, sp, #12
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   da09e:	f10d 0820 	add.w	r8, sp, #32
   da0a2:	f7fd faa6 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   da0a6:	4620      	mov	r0, r4
   da0a8:	ab10      	add	r3, sp, #64	; 0x40
   da0aa:	4642      	mov	r2, r8
   da0ac:	4629      	mov	r1, r5
   da0ae:	f7fd fdb5 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da0b2:	2400      	movs	r4, #0
   da0b4:	2100      	movs	r1, #0
   da0b6:	a803      	add	r0, sp, #12
   da0b8:	f7fd fa62 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da0bc:	4284      	cmp	r4, r0
   da0be:	da45      	bge.n	da14c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd8>
   da0c0:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   da0c2:	2101      	movs	r1, #1
   da0c4:	a803      	add	r0, sp, #12
   da0c6:	f7fd fa5b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da0ca:	4285      	cmp	r5, r0
   da0cc:	da3c      	bge.n	da148 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd4>
   da0ce:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   da0d0:	2102      	movs	r1, #2
   da0d2:	a803      	add	r0, sp, #12
   da0d4:	f7fd fa54 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da0d8:	4286      	cmp	r6, r0
   da0da:	da33      	bge.n	da144 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xd0>
   da0dc:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da0de:	2103      	movs	r1, #3
   da0e0:	a803      	add	r0, sp, #12
   da0e2:	f7fd fa4d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da0e6:	4287      	cmp	r7, r0
   da0e8:	da2a      	bge.n	da140 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0xcc>
          output_data[Offset(output_shape, b, y, x, c)] =
   da0ea:	9700      	str	r7, [sp, #0]
   da0ec:	4633      	mov	r3, r6
   da0ee:	462a      	mov	r2, r5
   da0f0:	4621      	mov	r1, r4
   da0f2:	a803      	add	r0, sp, #12
   da0f4:	f7fd faa9 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   da0f8:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   da0fa:	4683      	mov	fp, r0
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   da0fc:	4633      	mov	r3, r6
   da0fe:	462a      	mov	r2, r5
   da100:	4621      	mov	r1, r4
   da102:	4640      	mov	r0, r8
   da104:	f7fd fb52 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   da108:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   da10a:	4681      	mov	r9, r0
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
   da10c:	4633      	mov	r3, r6
   da10e:	462a      	mov	r2, r5
   da110:	4621      	mov	r1, r4
   da112:	a810      	add	r0, sp, #64	; 0x40
   da114:	f7fd fb4a 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
              F(input1_data[SubscriptToIndex(desc1, b, y, x, c)],
   da118:	9b22      	ldr	r3, [sp, #136]	; 0x88
   da11a:	eb0a 09c9 	add.w	r9, sl, r9, lsl #3
   da11e:	eb03 00c0 	add.w	r0, r3, r0, lsl #3

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          output_data[Offset(output_shape, b, y, x, c)] =
   da122:	e9d0 0100 	ldrd	r0, r1, [r0]
   da126:	e9d9 2300 	ldrd	r2, r3, [r9]
   da12a:	4290      	cmp	r0, r2
   da12c:	eb71 0303 	sbcs.w	r3, r1, r3
   da130:	9a24      	ldr	r2, [sp, #144]	; 0x90
   da132:	bfac      	ite	ge
   da134:	2301      	movge	r3, #1
   da136:	2300      	movlt	r3, #0
   da138:	f802 300b 	strb.w	r3, [r2, fp]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da13c:	3701      	adds	r7, #1
   da13e:	e7ce      	b.n	da0de <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6a>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   da140:	3601      	adds	r6, #1
   da142:	e7c5      	b.n	da0d0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5c>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   da144:	3501      	adds	r5, #1
   da146:	e7bc      	b.n	da0c2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x4e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da148:	3401      	adds	r4, #1
   da14a:	e7b3      	b.n	da0b4 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x40>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   da14c:	a803      	add	r0, sp, #12
   da14e:	f7fd fa0c 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                input2_data[SubscriptToIndex(desc2, b, y, x, c)]);
        }
      }
    }
  }
}
   da152:	b019      	add	sp, #100	; 0x64
   da154:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000da158 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   da158:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   da15c:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da15e:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   da160:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da162:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   da164:	9208      	str	r2, [sp, #32]
   da166:	4604      	mov	r4, r0
   da168:	460e      	mov	r6, r1
   da16a:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da16c:	dd01      	ble.n	da172 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   da16e:	f00b f9c1 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   da172:	683b      	ldr	r3, [r7, #0]
   da174:	2b04      	cmp	r3, #4
   da176:	dcfa      	bgt.n	da16e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   da178:	6813      	ldr	r3, [r2, #0]
   da17a:	2b04      	cmp	r3, #4
   da17c:	dcf7      	bgt.n	da16e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   da17e:	2301      	movs	r3, #1
   da180:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   da182:	ad10      	add	r5, sp, #64	; 0x40
   da184:	a80b      	add	r0, sp, #44	; 0x2c
   da186:	f7fd fa34 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   da18a:	ab18      	add	r3, sp, #96	; 0x60
   da18c:	462a      	mov	r2, r5
   da18e:	4639      	mov	r1, r7
   da190:	4630      	mov	r0, r6
   da192:	f7fd fd43 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   da196:	6863      	ldr	r3, [r4, #4]
   da198:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   da19a:	68a3      	ldr	r3, [r4, #8]
   da19c:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   da19e:	68e3      	ldr	r3, [r4, #12]
   da1a0:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   da1a2:	6923      	ldr	r3, [r4, #16]
   da1a4:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   da1a6:	6963      	ldr	r3, [r4, #20]
   da1a8:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   da1aa:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   da1ac:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   da1b0:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da1b2:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   da1b4:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da1b6:	2100      	movs	r1, #0
   da1b8:	a80b      	add	r0, sp, #44	; 0x2c
   da1ba:	f7fd f9e1 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da1be:	4284      	cmp	r4, r0
   da1c0:	da59      	bge.n	da276 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11e>
   da1c2:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   da1c4:	af0b      	add	r7, sp, #44	; 0x2c
   da1c6:	2101      	movs	r1, #1
   da1c8:	4638      	mov	r0, r7
   da1ca:	f7fd f9d9 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da1ce:	4285      	cmp	r5, r0
   da1d0:	da4f      	bge.n	da272 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11a>
   da1d2:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   da1d4:	2102      	movs	r1, #2
   da1d6:	4638      	mov	r0, r7
   da1d8:	f7fd f9d2 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da1dc:	4286      	cmp	r6, r0
   da1de:	da46      	bge.n	da26e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x116>
   da1e0:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da1e4:	2103      	movs	r1, #3
   da1e6:	4638      	mov	r0, r7
   da1e8:	f7fd f9ca 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da1ec:	4580      	cmp	r8, r0
   da1ee:	da3c      	bge.n	da26a <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x112>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   da1f0:	f8cd 8000 	str.w	r8, [sp]
   da1f4:	4633      	mov	r3, r6
   da1f6:	462a      	mov	r2, r5
   da1f8:	4621      	mov	r1, r4
   da1fa:	9809      	ldr	r0, [sp, #36]	; 0x24
   da1fc:	f7fd fad6 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   da200:	9b08      	ldr	r3, [sp, #32]
   da202:	f813 9000 	ldrb.w	r9, [r3, r0]
   da206:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   da208:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   da20c:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   da20e:	462a      	mov	r2, r5
   da210:	4633      	mov	r3, r6
   da212:	4621      	mov	r1, r4
   da214:	a818      	add	r0, sp, #96	; 0x60
   da216:	f7fd fac9 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da21a:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da21c:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da21e:	f813 b000 	ldrb.w	fp, [r3, r0]
   da222:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da224:	9903      	ldr	r1, [sp, #12]
   da226:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da22a:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da22c:	f7fd fa6c 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da230:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da234:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   da236:	9a07      	ldr	r2, [sp, #28]
   da238:	9906      	ldr	r1, [sp, #24]
   da23a:	4658      	mov	r0, fp
   da23c:	f7fd fa64 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   da240:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   da244:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   da246:	4633      	mov	r3, r6
   da248:	462a      	mov	r2, r5
   da24a:	4621      	mov	r1, r4
   da24c:	4638      	mov	r0, r7
   da24e:	f7fd f9fc 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   da252:	ebcb 0309 	rsb	r3, fp, r9
   da256:	f1d3 0900 	rsbs	r9, r3, #0
   da25a:	eb49 0903 	adc.w	r9, r9, r3
   da25e:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da260:	f108 0801 	add.w	r8, r8, #1
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
          output_data[Offset(output_shape, b, y, x, c)] =
   da264:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da268:	e7bc      	b.n	da1e4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   da26a:	3601      	adds	r6, #1
   da26c:	e7b2      	b.n	da1d4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   da26e:	3501      	adds	r5, #1
   da270:	e7a8      	b.n	da1c4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da272:	3401      	adds	r4, #1
   da274:	e79f      	b.n	da1b6 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   da276:	a80b      	add	r0, sp, #44	; 0x2c
   da278:	f7fd f977 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   da27c:	b021      	add	sp, #132	; 0x84
   da27e:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000da282 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   da282:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   da286:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da288:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   da28a:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da28c:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   da28e:	9208      	str	r2, [sp, #32]
   da290:	4604      	mov	r4, r0
   da292:	460e      	mov	r6, r1
   da294:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da296:	dd01      	ble.n	da29c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   da298:	f00b f92c 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   da29c:	683b      	ldr	r3, [r7, #0]
   da29e:	2b04      	cmp	r3, #4
   da2a0:	dcfa      	bgt.n	da298 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   da2a2:	6813      	ldr	r3, [r2, #0]
   da2a4:	2b04      	cmp	r3, #4
   da2a6:	dcf7      	bgt.n	da298 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   da2a8:	2301      	movs	r3, #1
   da2aa:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   da2ac:	ad10      	add	r5, sp, #64	; 0x40
   da2ae:	a80b      	add	r0, sp, #44	; 0x2c
   da2b0:	f7fd f99f 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   da2b4:	ab18      	add	r3, sp, #96	; 0x60
   da2b6:	462a      	mov	r2, r5
   da2b8:	4639      	mov	r1, r7
   da2ba:	4630      	mov	r0, r6
   da2bc:	f7fd fcae 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   da2c0:	6863      	ldr	r3, [r4, #4]
   da2c2:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   da2c4:	68a3      	ldr	r3, [r4, #8]
   da2c6:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   da2c8:	68e3      	ldr	r3, [r4, #12]
   da2ca:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   da2cc:	6923      	ldr	r3, [r4, #16]
   da2ce:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   da2d0:	6963      	ldr	r3, [r4, #20]
   da2d2:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   da2d4:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   da2d6:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   da2da:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da2dc:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   da2de:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da2e0:	2100      	movs	r1, #0
   da2e2:	a80b      	add	r0, sp, #44	; 0x2c
   da2e4:	f7fd f94c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da2e8:	4284      	cmp	r4, r0
   da2ea:	da59      	bge.n	da3a0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11e>
   da2ec:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   da2ee:	af0b      	add	r7, sp, #44	; 0x2c
   da2f0:	2101      	movs	r1, #1
   da2f2:	4638      	mov	r0, r7
   da2f4:	f7fd f944 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da2f8:	4285      	cmp	r5, r0
   da2fa:	da4f      	bge.n	da39c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11a>
   da2fc:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   da2fe:	2102      	movs	r1, #2
   da300:	4638      	mov	r0, r7
   da302:	f7fd f93d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da306:	4286      	cmp	r6, r0
   da308:	da46      	bge.n	da398 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x116>
   da30a:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da30e:	2103      	movs	r1, #3
   da310:	4638      	mov	r0, r7
   da312:	f7fd f935 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da316:	4580      	cmp	r8, r0
   da318:	da3c      	bge.n	da394 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x112>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   da31a:	f8cd 8000 	str.w	r8, [sp]
   da31e:	4633      	mov	r3, r6
   da320:	462a      	mov	r2, r5
   da322:	4621      	mov	r1, r4
   da324:	9809      	ldr	r0, [sp, #36]	; 0x24
   da326:	f7fd fa41 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   da32a:	9b08      	ldr	r3, [sp, #32]
   da32c:	f913 9000 	ldrsb.w	r9, [r3, r0]
   da330:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   da332:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   da336:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   da338:	462a      	mov	r2, r5
   da33a:	4633      	mov	r3, r6
   da33c:	4621      	mov	r1, r4
   da33e:	a818      	add	r0, sp, #96	; 0x60
   da340:	f7fd fa34 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da344:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da346:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da348:	f913 b000 	ldrsb.w	fp, [r3, r0]
   da34c:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da34e:	9903      	ldr	r1, [sp, #12]
   da350:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da354:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da356:	f7fd f9d7 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da35a:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da35e:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   da360:	9a07      	ldr	r2, [sp, #28]
   da362:	9906      	ldr	r1, [sp, #24]
   da364:	4658      	mov	r0, fp
   da366:	f7fd f9cf 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   da36a:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   da36e:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   da370:	4633      	mov	r3, r6
   da372:	462a      	mov	r2, r5
   da374:	4621      	mov	r1, r4
   da376:	4638      	mov	r0, r7
   da378:	f7fd f967 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   da37c:	ebcb 0309 	rsb	r3, fp, r9
   da380:	f1d3 0900 	rsbs	r9, r3, #0
   da384:	eb49 0903 	adc.w	r9, r9, r3
   da388:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da38a:	f108 0801 	add.w	r8, r8, #1
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
          output_data[Offset(output_shape, b, y, x, c)] =
   da38e:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da392:	e7bc      	b.n	da30e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   da394:	3601      	adds	r6, #1
   da396:	e7b2      	b.n	da2fe <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   da398:	3501      	adds	r5, #1
   da39a:	e7a8      	b.n	da2ee <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da39c:	3401      	adds	r4, #1
   da39e:	e79f      	b.n	da2e0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   da3a0:	a80b      	add	r0, sp, #44	; 0x2c
   da3a2:	f7fd f8e2 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   da3a6:	b021      	add	sp, #132	; 0x84
   da3a8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000da3ac <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode>:
              op_params, GetTensorShape(input1), GetTensorData<type>(input1), \
              GetTensorShape(input2), GetTensorData<type>(input2),            \
              GetTensorShape(output), GetTensorData<bool>(output));           \
  }

TfLiteStatus EqualEval(TfLiteContext* context, TfLiteNode* node) {
   da3ac:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   da3b0:	680a      	ldr	r2, [r1, #0]
   da3b2:	f8d0 9008 	ldr.w	r9, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   da3b6:	6895      	ldr	r5, [r2, #8]
   da3b8:	4682      	mov	sl, r0
   da3ba:	6850      	ldr	r0, [r2, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   da3bc:	684a      	ldr	r2, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   da3be:	2338      	movs	r3, #56	; 0x38
   da3c0:	fb03 f800 	mul.w	r8, r3, r0
   da3c4:	fb03 9505 	mla	r5, r3, r5, r9
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   da3c8:	6854      	ldr	r4, [r2, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   da3ca:	eb09 0608 	add.w	r6, r9, r8
   da3ce:	b0ab      	sub	sp, #172	; 0xac
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   da3d0:	4629      	mov	r1, r5
   da3d2:	4630      	mov	r0, r6
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   da3d4:	fb03 9404 	mla	r4, r3, r4, r9
   da3d8:	f00a fd5e 	bl	e4e98 <_ZN6tflite14HaveSameShapesEPK12TfLiteTensorS2_>
  switch (input1->type) {
   da3dc:	f819 2008 	ldrb.w	r2, [r9, r8]

TfLiteStatus EqualEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   da3e0:	f080 0001 	eor.w	r0, r0, #1
  switch (input1->type) {
   da3e4:	1e53      	subs	r3, r2, #1

TfLiteStatus EqualEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   da3e6:	b2c7      	uxtb	r7, r0
  switch (input1->type) {
   da3e8:	2b08      	cmp	r3, #8
   da3ea:	f200 8274 	bhi.w	da8d6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x52a>
   da3ee:	e8df f013 	tbh	[pc, r3, lsl #1]
   da3f2:	0057      	.short	0x0057
   da3f4:	013f00a5 	.word	0x013f00a5
   da3f8:	027200f1 	.word	0x027200f1
   da3fc:	02720009 	.word	0x02720009
   da400:	01d30272 	.word	0x01d30272
   da404:	f10d 0874 	add.w	r8, sp, #116	; 0x74
    case kTfLiteBool:
      TF_LITE_COMPARISON(bool, Equal, requires_broadcast);
   da408:	4631      	mov	r1, r6
   da40a:	b1cf      	cbz	r7, da440 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x94>
   da40c:	a813      	add	r0, sp, #76	; 0x4c
   da40e:	f7fd fb5c 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da412:	4629      	mov	r1, r5
   da414:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da416:	6876      	ldr	r6, [r6, #4]
   da418:	f7fd fb57 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da41c:	b105      	cbz	r5, da420 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x74>
   da41e:	686d      	ldr	r5, [r5, #4]
   da420:	4621      	mov	r1, r4
   da422:	4640      	mov	r0, r8
   da424:	f7fd fb51 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da428:	b104      	cbz	r4, da42c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x80>
   da42a:	6864      	ldr	r4, [r4, #4]
      bool* output_data) {                                                     \
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
   da42c:	9402      	str	r4, [sp, #8]
   da42e:	e88d 0120 	stmia.w	sp, {r5, r8}
   da432:	ab18      	add	r3, sp, #96	; 0x60
   da434:	4632      	mov	r2, r6
   da436:	a913      	add	r1, sp, #76	; 0x4c
   da438:	a822      	add	r0, sp, #136	; 0x88
   da43a:	f7fe fdd7 	bl	d8fec <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_7EqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   da43e:	e1ed      	b.n	da81c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x470>
   da440:	a818      	add	r0, sp, #96	; 0x60
   da442:	f7fd fb42 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da446:	4629      	mov	r1, r5
   da448:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da44a:	6876      	ldr	r6, [r6, #4]
   da44c:	f7fd fb3d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da450:	b105      	cbz	r5, da454 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0xa8>
   da452:	686d      	ldr	r5, [r5, #4]
   da454:	4621      	mov	r1, r4
   da456:	a822      	add	r0, sp, #136	; 0x88
   da458:	f7fd fb37 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da45c:	b104      	cbz	r4, da460 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0xb4>
   da45e:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   da460:	4641      	mov	r1, r8
   da462:	aa22      	add	r2, sp, #136	; 0x88
   da464:	a818      	add	r0, sp, #96	; 0x60
   da466:	f7fd f912 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   da46a:	3d01      	subs	r5, #1
   da46c:	1e73      	subs	r3, r6, #1
   da46e:	17c1      	asrs	r1, r0, #31
   da470:	3c01      	subs	r4, #1
  for (int64_t i = 0; i < flatsize; ++i) {
   da472:	2600      	movs	r6, #0
   da474:	2700      	movs	r7, #0
   da476:	4286      	cmp	r6, r0
   da478:	eb77 0201 	sbcs.w	r2, r7, r1
   da47c:	f280 8232 	bge.w	da8e4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x538>
    output_data[i] = F(input1_data[i], input2_data[i]);
   da480:	f813 2f01 	ldrb.w	r2, [r3, #1]!
   da484:	f815 ef01 	ldrb.w	lr, [r5, #1]!
   da488:	ebce 0c02 	rsb	ip, lr, r2
   da48c:	f1dc 0200 	rsbs	r2, ip, #0
   da490:	eb42 020c 	adc.w	r2, r2, ip
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da494:	3601      	adds	r6, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   da496:	f804 2f01 	strb.w	r2, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da49a:	f147 0700 	adc.w	r7, r7, #0
   da49e:	e7ea      	b.n	da476 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0xca>
   da4a0:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteFloat32:
      TF_LITE_COMPARISON(float, Equal, requires_broadcast);
   da4a4:	4631      	mov	r1, r6
   da4a6:	b1cf      	cbz	r7, da4dc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x130>
   da4a8:	a813      	add	r0, sp, #76	; 0x4c
   da4aa:	f7fd fb0e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da4ae:	4629      	mov	r1, r5
   da4b0:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da4b2:	6876      	ldr	r6, [r6, #4]
   da4b4:	f7fd fb09 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da4b8:	b105      	cbz	r5, da4bc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x110>
   da4ba:	686d      	ldr	r5, [r5, #4]
   da4bc:	4621      	mov	r1, r4
   da4be:	4640      	mov	r0, r8
   da4c0:	f7fd fb03 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da4c4:	b104      	cbz	r4, da4c8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x11c>
   da4c6:	6864      	ldr	r4, [r4, #4]
      bool* output_data) {                                                     \
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
   da4c8:	9402      	str	r4, [sp, #8]
   da4ca:	e88d 0120 	stmia.w	sp, {r5, r8}
   da4ce:	ab18      	add	r3, sp, #96	; 0x60
   da4d0:	4632      	mov	r2, r6
   da4d2:	a913      	add	r1, sp, #76	; 0x4c
   da4d4:	a822      	add	r0, sp, #136	; 0x88
   da4d6:	f7fe fdf3 	bl	d90c0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_7EqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   da4da:	e19f      	b.n	da81c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x470>
   da4dc:	a818      	add	r0, sp, #96	; 0x60
   da4de:	f7fd faf4 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da4e2:	4629      	mov	r1, r5
   da4e4:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da4e6:	6876      	ldr	r6, [r6, #4]
   da4e8:	f7fd faef 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da4ec:	b105      	cbz	r5, da4f0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x144>
   da4ee:	686d      	ldr	r5, [r5, #4]
   da4f0:	4621      	mov	r1, r4
   da4f2:	a822      	add	r0, sp, #136	; 0x88
   da4f4:	f7fd fae9 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da4f8:	b104      	cbz	r4, da4fc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x150>
   da4fa:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   da4fc:	4641      	mov	r1, r8
   da4fe:	aa22      	add	r2, sp, #136	; 0x88
   da500:	a818      	add	r0, sp, #96	; 0x60
   da502:	f7fd f8c4 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   da506:	3c01      	subs	r4, #1
   da508:	4633      	mov	r3, r6
   da50a:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   da50c:	2600      	movs	r6, #0
   da50e:	2700      	movs	r7, #0
   da510:	4286      	cmp	r6, r0
   da512:	eb77 0201 	sbcs.w	r2, r7, r1
   da516:	f280 81e5 	bge.w	da8e4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x538>
    output_data[i] = F(input1_data[i], input2_data[i]);
   da51a:	ecb3 7a01 	vldmia	r3!, {s14}
   da51e:	ecf5 7a01 	vldmia	r5!, {s15}
   da522:	eeb4 7a67 	vcmp.f32	s14, s15
   da526:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   da52a:	bf0c      	ite	eq
   da52c:	2201      	moveq	r2, #1
   da52e:	2200      	movne	r2, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da530:	3601      	adds	r6, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   da532:	f804 2f01 	strb.w	r2, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da536:	f147 0700 	adc.w	r7, r7, #0
   da53a:	e7e9      	b.n	da510 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x164>
   da53c:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, Equal, requires_broadcast);
   da540:	4631      	mov	r1, r6
   da542:	b1cf      	cbz	r7, da578 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x1cc>
   da544:	a813      	add	r0, sp, #76	; 0x4c
   da546:	f7fd fac0 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da54a:	4629      	mov	r1, r5
   da54c:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da54e:	6876      	ldr	r6, [r6, #4]
   da550:	f7fd fabb 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da554:	b105      	cbz	r5, da558 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x1ac>
   da556:	686d      	ldr	r5, [r5, #4]
   da558:	4621      	mov	r1, r4
   da55a:	4640      	mov	r0, r8
   da55c:	f7fd fab5 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da560:	b104      	cbz	r4, da564 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x1b8>
   da562:	6864      	ldr	r4, [r4, #4]
      bool* output_data) {                                                     \
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
   da564:	9402      	str	r4, [sp, #8]
   da566:	e88d 0120 	stmia.w	sp, {r5, r8}
   da56a:	ab18      	add	r3, sp, #96	; 0x60
   da56c:	4632      	mov	r2, r6
   da56e:	a913      	add	r1, sp, #76	; 0x4c
   da570:	a822      	add	r0, sp, #136	; 0x88
   da572:	f7fe fe18 	bl	d91a6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   da576:	e151      	b.n	da81c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x470>
   da578:	a818      	add	r0, sp, #96	; 0x60
   da57a:	f7fd faa6 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da57e:	4629      	mov	r1, r5
   da580:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da582:	6876      	ldr	r6, [r6, #4]
   da584:	f7fd faa1 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da588:	b105      	cbz	r5, da58c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x1e0>
   da58a:	686d      	ldr	r5, [r5, #4]
   da58c:	4621      	mov	r1, r4
   da58e:	a822      	add	r0, sp, #136	; 0x88
   da590:	f7fd fa9b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da594:	b104      	cbz	r4, da598 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x1ec>
   da596:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   da598:	aa22      	add	r2, sp, #136	; 0x88
   da59a:	4641      	mov	r1, r8
   da59c:	a818      	add	r0, sp, #96	; 0x60
   da59e:	f7fd f876 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   da5a2:	3c01      	subs	r4, #1
   da5a4:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   da5a6:	2200      	movs	r2, #0
   da5a8:	2300      	movs	r3, #0
   da5aa:	4282      	cmp	r2, r0
   da5ac:	eb73 0701 	sbcs.w	r7, r3, r1
   da5b0:	f280 8198 	bge.w	da8e4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x538>
    output_data[i] = F(input1_data[i], input2_data[i]);
   da5b4:	f856 7022 	ldr.w	r7, [r6, r2, lsl #2]
   da5b8:	f855 e022 	ldr.w	lr, [r5, r2, lsl #2]
   da5bc:	ebce 0e07 	rsb	lr, lr, r7
   da5c0:	f1de 0700 	rsbs	r7, lr, #0
   da5c4:	eb47 070e 	adc.w	r7, r7, lr
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da5c8:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   da5ca:	f804 7f01 	strb.w	r7, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da5ce:	f143 0300 	adc.w	r3, r3, #0
   da5d2:	e7ea      	b.n	da5aa <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x1fe>
   da5d4:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, Equal, requires_broadcast);
   da5d8:	4631      	mov	r1, r6
   da5da:	b1cf      	cbz	r7, da610 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x264>
   da5dc:	a813      	add	r0, sp, #76	; 0x4c
   da5de:	f7fd fa74 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da5e2:	4629      	mov	r1, r5
   da5e4:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da5e6:	6876      	ldr	r6, [r6, #4]
   da5e8:	f7fd fa6f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da5ec:	b105      	cbz	r5, da5f0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x244>
   da5ee:	686d      	ldr	r5, [r5, #4]
   da5f0:	4621      	mov	r1, r4
   da5f2:	4640      	mov	r0, r8
   da5f4:	f7fd fa69 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da5f8:	b104      	cbz	r4, da5fc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x250>
   da5fa:	6864      	ldr	r4, [r4, #4]
      bool* output_data) {                                                     \
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
   da5fc:	9402      	str	r4, [sp, #8]
   da5fe:	e88d 0120 	stmia.w	sp, {r5, r8}
   da602:	ab18      	add	r3, sp, #96	; 0x60
   da604:	4632      	mov	r2, r6
   da606:	a913      	add	r1, sp, #76	; 0x4c
   da608:	a822      	add	r0, sp, #136	; 0x88
   da60a:	f7fe fe37 	bl	d927c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_7EqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   da60e:	e105      	b.n	da81c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x470>
   da610:	a818      	add	r0, sp, #96	; 0x60
   da612:	f7fd fa5a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da616:	4629      	mov	r1, r5
   da618:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da61a:	6876      	ldr	r6, [r6, #4]
   da61c:	f7fd fa55 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da620:	b105      	cbz	r5, da624 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x278>
   da622:	686d      	ldr	r5, [r5, #4]
   da624:	4621      	mov	r1, r4
   da626:	a822      	add	r0, sp, #136	; 0x88
   da628:	f7fd fa4f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da62c:	b104      	cbz	r4, da630 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x284>
   da62e:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   da630:	aa22      	add	r2, sp, #136	; 0x88
   da632:	4641      	mov	r1, r8
   da634:	a818      	add	r0, sp, #96	; 0x60
   da636:	f7fd f82a 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   da63a:	3d08      	subs	r5, #8
   da63c:	17c1      	asrs	r1, r0, #31
   da63e:	f1a6 0e08 	sub.w	lr, r6, #8
   da642:	3c01      	subs	r4, #1
  for (int64_t i = 0; i < flatsize; ++i) {
   da644:	2200      	movs	r2, #0
   da646:	2300      	movs	r3, #0
   da648:	4282      	cmp	r2, r0
   da64a:	eb73 0601 	sbcs.w	r6, r3, r1
   da64e:	f280 8149 	bge.w	da8e4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x538>
    output_data[i] = F(input1_data[i], input2_data[i]);
   da652:	e9f5 6702 	ldrd	r6, r7, [r5, #8]!
   da656:	e9fe ab02 	ldrd	sl, fp, [lr, #8]!
   da65a:	45bb      	cmp	fp, r7
   da65c:	bf06      	itte	eq
   da65e:	45b2      	cmpeq	sl, r6
   da660:	2601      	moveq	r6, #1
   da662:	2600      	movne	r6, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da664:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   da666:	f804 6f01 	strb.w	r6, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da66a:	f143 0300 	adc.w	r3, r3, #0
   da66e:	e7eb      	b.n	da648 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x29c>
            GetTensorData<input_dtype>(input2), GetTensorShape(output),        \
            GetTensorData<bool>(output));                                      \
      }                                                                        \
    }                                                                          \
  }
TF_LITE_QUANTIZE_COMPARISON(Equal);
   da670:	6933      	ldr	r3, [r6, #16]
   da672:	68f0      	ldr	r0, [r6, #12]
   da674:	f1c3 0900 	rsb	r9, r3, #0
   da678:	692b      	ldr	r3, [r5, #16]
   da67a:	f1c3 0800 	rsb	r8, r3, #0
   da67e:	f00d fe7d 	bl	e837c <__aeabi_f2d>
   da682:	ec41 0b10 	vmov	d0, r0, r1
   da686:	a910      	add	r1, sp, #64	; 0x40
   da688:	a80f      	add	r0, sp, #60	; 0x3c
   da68a:	f00a fc79 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   da68e:	68e8      	ldr	r0, [r5, #12]
   da690:	f00d fe74 	bl	e837c <__aeabi_f2d>
   da694:	ec41 0b10 	vmov	d0, r0, r1
   da698:	a912      	add	r1, sp, #72	; 0x48
   da69a:	a811      	add	r0, sp, #68	; 0x44
   da69c:	f00a fc70 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   da6a0:	2308      	movs	r3, #8
   da6a2:	9322      	str	r3, [sp, #136]	; 0x88
   da6a4:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   da6a6:	9324      	str	r3, [sp, #144]	; 0x90
   da6a8:	9b10      	ldr	r3, [sp, #64]	; 0x40
   da6aa:	9325      	str	r3, [sp, #148]	; 0x94
   da6ac:	9b11      	ldr	r3, [sp, #68]	; 0x44
   da6ae:	9327      	str	r3, [sp, #156]	; 0x9c
   da6b0:	9b12      	ldr	r3, [sp, #72]	; 0x48
   da6b2:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   da6b6:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   da6ba:	9328      	str	r3, [sp, #160]	; 0xa0
   da6bc:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   da6c0:	4631      	mov	r1, r6
   da6c2:	a813      	add	r0, sp, #76	; 0x4c
   da6c4:	b1bf      	cbz	r7, da6f6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x34a>
   da6c6:	f7fd fa00 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da6ca:	4629      	mov	r1, r5
   da6cc:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da6ce:	6876      	ldr	r6, [r6, #4]
   da6d0:	f7fd f9fb 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da6d4:	4621      	mov	r1, r4
   da6d6:	4640      	mov	r0, r8
   da6d8:	686d      	ldr	r5, [r5, #4]
   da6da:	f7fd f9f6 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da6de:	b104      	cbz	r4, da6e2 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x336>
   da6e0:	6864      	ldr	r4, [r4, #4]
      bool* output_data) {                                                     \
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
   da6e2:	9402      	str	r4, [sp, #8]
   da6e4:	e88d 0120 	stmia.w	sp, {r5, r8}
   da6e8:	ab18      	add	r3, sp, #96	; 0x60
   da6ea:	4632      	mov	r2, r6
   da6ec:	a913      	add	r1, sp, #76	; 0x4c
   da6ee:	a822      	add	r0, sp, #136	; 0x88
   da6f0:	f7ff fd32 	bl	da158 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   da6f4:	e092      	b.n	da81c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x470>
   da6f6:	f7fd f9e8 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da6fa:	6873      	ldr	r3, [r6, #4]
   da6fc:	9305      	str	r3, [sp, #20]
   da6fe:	4629      	mov	r1, r5
   da700:	a818      	add	r0, sp, #96	; 0x60
   da702:	f7fd f9e2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da706:	4621      	mov	r1, r4
   da708:	4640      	mov	r0, r8
   da70a:	f8d5 b004 	ldr.w	fp, [r5, #4]
   da70e:	f7fd f9dc 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da712:	b104      	cbz	r4, da716 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x36a>
   da714:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   da716:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   da718:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   da71a:	9b24      	ldr	r3, [sp, #144]	; 0x90
   da71c:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   da71e:	9b25      	ldr	r3, [sp, #148]	; 0x94
   da720:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   da722:	9b26      	ldr	r3, [sp, #152]	; 0x98
   da724:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   da726:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   da728:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   da72a:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   da72c:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   da72e:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   da730:	a918      	add	r1, sp, #96	; 0x60
   da732:	a813      	add	r0, sp, #76	; 0x4c
   da734:	f7fc ffab 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   da738:	4602      	mov	r2, r0
   da73a:	17c3      	asrs	r3, r0, #31
   da73c:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   da740:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da742:	f04f 0800 	mov.w	r8, #0
   da746:	f04f 0900 	mov.w	r9, #0
   da74a:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   da74e:	4590      	cmp	r8, r2
   da750:	eb79 0303 	sbcs.w	r3, r9, r3
   da754:	f280 80b4 	bge.w	da8c0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x514>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da758:	f81b 5008 	ldrb.w	r5, [fp, r8]
   da75c:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   da75e:	9a08      	ldr	r2, [sp, #32]
   da760:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da762:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   da764:	9b05      	ldr	r3, [sp, #20]
   da766:	f813 0008 	ldrb.w	r0, [r3, r8]
   da76a:	9b06      	ldr	r3, [sp, #24]
   da76c:	4418      	add	r0, r3
   da76e:	40b8      	lsls	r0, r7
   da770:	f7fc ffca 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da774:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   da776:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   da778:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   da77a:	990a      	ldr	r1, [sp, #40]	; 0x28
   da77c:	4628      	mov	r0, r5
   da77e:	f7fc ffc3 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   da782:	ebc0 020a 	rsb	r2, r0, sl
   da786:	4250      	negs	r0, r2
   da788:	4150      	adcs	r0, r2
   da78a:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da78e:	f118 0801 	adds.w	r8, r8, #1
   da792:	f149 0900 	adc.w	r9, r9, #0
   da796:	e7d8      	b.n	da74a <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x39e>
   da798:	6933      	ldr	r3, [r6, #16]
   da79a:	68f0      	ldr	r0, [r6, #12]
   da79c:	f1c3 0900 	rsb	r9, r3, #0
   da7a0:	692b      	ldr	r3, [r5, #16]
   da7a2:	f1c3 0800 	rsb	r8, r3, #0
   da7a6:	f00d fde9 	bl	e837c <__aeabi_f2d>
   da7aa:	ec41 0b10 	vmov	d0, r0, r1
   da7ae:	a910      	add	r1, sp, #64	; 0x40
   da7b0:	a80f      	add	r0, sp, #60	; 0x3c
   da7b2:	f00a fbe5 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   da7b6:	68e8      	ldr	r0, [r5, #12]
   da7b8:	f00d fde0 	bl	e837c <__aeabi_f2d>
   da7bc:	ec41 0b10 	vmov	d0, r0, r1
   da7c0:	a912      	add	r1, sp, #72	; 0x48
   da7c2:	a811      	add	r0, sp, #68	; 0x44
   da7c4:	f00a fbdc 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   da7c8:	2308      	movs	r3, #8
   da7ca:	9322      	str	r3, [sp, #136]	; 0x88
   da7cc:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   da7ce:	9324      	str	r3, [sp, #144]	; 0x90
   da7d0:	9b10      	ldr	r3, [sp, #64]	; 0x40
   da7d2:	9325      	str	r3, [sp, #148]	; 0x94
   da7d4:	9b11      	ldr	r3, [sp, #68]	; 0x44
   da7d6:	9327      	str	r3, [sp, #156]	; 0x9c
   da7d8:	9b12      	ldr	r3, [sp, #72]	; 0x48
   da7da:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   da7de:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   da7e2:	9328      	str	r3, [sp, #160]	; 0xa0
   da7e4:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   da7e8:	4631      	mov	r1, r6
   da7ea:	a813      	add	r0, sp, #76	; 0x4c
   da7ec:	b1c7      	cbz	r7, da820 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x474>
   da7ee:	f7fd f96c 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da7f2:	4629      	mov	r1, r5
   da7f4:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da7f6:	6876      	ldr	r6, [r6, #4]
   da7f8:	f7fd f967 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da7fc:	4621      	mov	r1, r4
   da7fe:	4640      	mov	r0, r8
   da800:	686d      	ldr	r5, [r5, #4]
   da802:	f7fd f962 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da806:	b104      	cbz	r4, da80a <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x45e>
   da808:	6864      	ldr	r4, [r4, #4]
      bool* output_data) {                                                     \
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
   da80a:	9402      	str	r4, [sp, #8]
   da80c:	e88d 0120 	stmia.w	sp, {r5, r8}
   da810:	ab18      	add	r3, sp, #96	; 0x60
   da812:	4632      	mov	r2, r6
   da814:	a913      	add	r1, sp, #76	; 0x4c
   da816:	a822      	add	r0, sp, #136	; 0x88
   da818:	f7ff fd33 	bl	da282 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_7EqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   da81c:	4640      	mov	r0, r8
   da81e:	e050      	b.n	da8c2 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x516>
   da820:	f7fd f953 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   da824:	6873      	ldr	r3, [r6, #4]
   da826:	9305      	str	r3, [sp, #20]
   da828:	4629      	mov	r1, r5
   da82a:	a818      	add	r0, sp, #96	; 0x60
   da82c:	f7fd f94d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   da830:	4621      	mov	r1, r4
   da832:	4640      	mov	r0, r8
   da834:	f8d5 b004 	ldr.w	fp, [r5, #4]
   da838:	f7fd f947 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   da83c:	b104      	cbz	r4, da840 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x494>
   da83e:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   da840:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   da842:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   da844:	9b24      	ldr	r3, [sp, #144]	; 0x90
   da846:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   da848:	9b25      	ldr	r3, [sp, #148]	; 0x94
   da84a:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   da84c:	9b26      	ldr	r3, [sp, #152]	; 0x98
   da84e:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   da850:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   da852:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   da854:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   da856:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   da858:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   da85a:	a918      	add	r1, sp, #96	; 0x60
   da85c:	a813      	add	r0, sp, #76	; 0x4c
   da85e:	f7fc ff16 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   da862:	4602      	mov	r2, r0
   da864:	17c3      	asrs	r3, r0, #31
   da866:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   da86a:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da86c:	f04f 0800 	mov.w	r8, #0
   da870:	f04f 0900 	mov.w	r9, #0
   da874:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   da878:	4590      	cmp	r8, r2
   da87a:	eb79 0303 	sbcs.w	r3, r9, r3
   da87e:	da1f      	bge.n	da8c0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x514>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da880:	f91b 5008 	ldrsb.w	r5, [fp, r8]
   da884:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   da886:	9a08      	ldr	r2, [sp, #32]
   da888:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da88a:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   da88c:	9b05      	ldr	r3, [sp, #20]
   da88e:	f913 0008 	ldrsb.w	r0, [r3, r8]
   da892:	9b06      	ldr	r3, [sp, #24]
   da894:	4418      	add	r0, r3
   da896:	40b8      	lsls	r0, r7
   da898:	f7fc ff36 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da89c:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   da89e:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   da8a0:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   da8a2:	990a      	ldr	r1, [sp, #40]	; 0x28
   da8a4:	4628      	mov	r0, r5
   da8a6:	f7fc ff2f 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   da8aa:	ebc0 030a 	rsb	r3, r0, sl
   da8ae:	4258      	negs	r0, r3
   da8b0:	4158      	adcs	r0, r3
   da8b2:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   da8b6:	f118 0801 	adds.w	r8, r8, #1
   da8ba:	f149 0900 	adc.w	r9, r9, #0
   da8be:	e7d9      	b.n	da874 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x4c8>
   da8c0:	a81d      	add	r0, sp, #116	; 0x74
   da8c2:	f7fc fe52 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   da8c6:	a818      	add	r0, sp, #96	; 0x60
   da8c8:	f7fc fe4f 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   da8cc:	a813      	add	r0, sp, #76	; 0x4c
   da8ce:	f7fc fe4c 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      context->ReportError(
          context, "Does not support type %d, requires bool|float|int|uint8",
          input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
   da8d2:	2000      	movs	r0, #0
   da8d4:	e00e      	b.n	da8f4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x548>
                                 requires_broadcast);
      break;
    default:
      context->ReportError(
          context, "Does not support type %d, requires bool|float|int|uint8",
          input1->type);
   da8d6:	4650      	mov	r0, sl
   da8d8:	f8da 3014 	ldr.w	r3, [sl, #20]
   da8dc:	4907      	ldr	r1, [pc, #28]	; (da8fc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x550>)
   da8de:	4798      	blx	r3
      return kTfLiteError;
   da8e0:	2001      	movs	r0, #1
   da8e2:	e007      	b.n	da8f4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x548>
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, Equal, requires_broadcast);
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, Equal, requires_broadcast);
   da8e4:	a822      	add	r0, sp, #136	; 0x88
   da8e6:	f7fc fe40 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   da8ea:	4640      	mov	r0, r8
   da8ec:	f7fc fe3d 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   da8f0:	a818      	add	r0, sp, #96	; 0x60
   da8f2:	e7ec      	b.n	da8ce <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_19EqualEvalEP13TfLiteContextP10TfLiteNode+0x522>
          context, "Does not support type %d, requires bool|float|int|uint8",
          input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   da8f4:	b02b      	add	sp, #172	; 0xac
   da8f6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   da8fa:	bf00      	nop
   da8fc:	000eb478 	.word	0x000eb478

000da900 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   da900:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   da904:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da906:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   da908:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da90a:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   da90c:	9208      	str	r2, [sp, #32]
   da90e:	4604      	mov	r4, r0
   da910:	460e      	mov	r6, r1
   da912:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   da914:	dd01      	ble.n	da91a <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   da916:	f00a fded 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   da91a:	683b      	ldr	r3, [r7, #0]
   da91c:	2b04      	cmp	r3, #4
   da91e:	dcfa      	bgt.n	da916 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   da920:	6813      	ldr	r3, [r2, #0]
   da922:	2b04      	cmp	r3, #4
   da924:	dcf7      	bgt.n	da916 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   da926:	2301      	movs	r3, #1
   da928:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   da92a:	ad10      	add	r5, sp, #64	; 0x40
   da92c:	a80b      	add	r0, sp, #44	; 0x2c
   da92e:	f7fc fe60 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   da932:	ab18      	add	r3, sp, #96	; 0x60
   da934:	462a      	mov	r2, r5
   da936:	4639      	mov	r1, r7
   da938:	4630      	mov	r0, r6
   da93a:	f7fd f96f 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   da93e:	6863      	ldr	r3, [r4, #4]
   da940:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   da942:	68a3      	ldr	r3, [r4, #8]
   da944:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   da946:	68e3      	ldr	r3, [r4, #12]
   da948:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   da94a:	6923      	ldr	r3, [r4, #16]
   da94c:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   da94e:	6963      	ldr	r3, [r4, #20]
   da950:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   da952:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   da954:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   da958:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da95a:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   da95c:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   da95e:	2100      	movs	r1, #0
   da960:	a80b      	add	r0, sp, #44	; 0x2c
   da962:	f7fc fe0d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da966:	4284      	cmp	r4, r0
   da968:	da58      	bge.n	daa1c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11c>
   da96a:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   da96c:	af0b      	add	r7, sp, #44	; 0x2c
   da96e:	2101      	movs	r1, #1
   da970:	4638      	mov	r0, r7
   da972:	f7fc fe05 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da976:	4285      	cmp	r5, r0
   da978:	da4e      	bge.n	daa18 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x118>
   da97a:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   da97c:	2102      	movs	r1, #2
   da97e:	4638      	mov	r0, r7
   da980:	f7fc fdfe 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da984:	4286      	cmp	r6, r0
   da986:	da45      	bge.n	daa14 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x114>
   da988:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   da98c:	2103      	movs	r1, #3
   da98e:	4638      	mov	r0, r7
   da990:	f7fc fdf6 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   da994:	4580      	cmp	r8, r0
   da996:	da3b      	bge.n	daa10 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x110>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   da998:	f8cd 8000 	str.w	r8, [sp]
   da99c:	4633      	mov	r3, r6
   da99e:	462a      	mov	r2, r5
   da9a0:	4621      	mov	r1, r4
   da9a2:	9809      	ldr	r0, [sp, #36]	; 0x24
   da9a4:	f7fc ff02 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   da9a8:	9b08      	ldr	r3, [sp, #32]
   da9aa:	f813 9000 	ldrb.w	r9, [r3, r0]
   da9ae:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   da9b0:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   da9b4:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   da9b6:	462a      	mov	r2, r5
   da9b8:	4633      	mov	r3, r6
   da9ba:	4621      	mov	r1, r4
   da9bc:	a818      	add	r0, sp, #96	; 0x60
   da9be:	f7fc fef5 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da9c2:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da9c4:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da9c6:	f813 b000 	ldrb.w	fp, [r3, r0]
   da9ca:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da9cc:	9903      	ldr	r1, [sp, #12]
   da9ce:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da9d2:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da9d4:	f7fc fe98 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   da9d8:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   da9dc:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   da9de:	9a07      	ldr	r2, [sp, #28]
   da9e0:	9906      	ldr	r1, [sp, #24]
   da9e2:	4658      	mov	r0, fp
   da9e4:	f7fc fe90 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   da9e8:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   da9ec:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   da9ee:	4633      	mov	r3, r6
   da9f0:	462a      	mov	r2, r5
   da9f2:	4621      	mov	r1, r4
   da9f4:	4638      	mov	r0, r7
   da9f6:	f7fc fe28 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   da9fa:	ebb9 090b 	subs.w	r9, r9, fp
   da9fe:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   daa00:	bf18      	it	ne
   daa02:	f04f 0901 	movne.w	r9, #1
   daa06:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   daa0a:	f108 0801 	add.w	r8, r8, #1
   daa0e:	e7bd      	b.n	da98c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   daa10:	3601      	adds	r6, #1
   daa12:	e7b3      	b.n	da97c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   daa14:	3501      	adds	r5, #1
   daa16:	e7a9      	b.n	da96c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   daa18:	3401      	adds	r4, #1
   daa1a:	e7a0      	b.n	da95e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   daa1c:	a80b      	add	r0, sp, #44	; 0x2c
   daa1e:	f7fc fda4 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   daa22:	b021      	add	sp, #132	; 0x84
   daa24:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000daa28 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   daa28:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   daa2c:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   daa2e:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   daa30:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   daa32:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   daa34:	9208      	str	r2, [sp, #32]
   daa36:	4604      	mov	r4, r0
   daa38:	460e      	mov	r6, r1
   daa3a:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   daa3c:	dd01      	ble.n	daa42 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   daa3e:	f00a fd59 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   daa42:	683b      	ldr	r3, [r7, #0]
   daa44:	2b04      	cmp	r3, #4
   daa46:	dcfa      	bgt.n	daa3e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   daa48:	6813      	ldr	r3, [r2, #0]
   daa4a:	2b04      	cmp	r3, #4
   daa4c:	dcf7      	bgt.n	daa3e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   daa4e:	2301      	movs	r3, #1
   daa50:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   daa52:	ad10      	add	r5, sp, #64	; 0x40
   daa54:	a80b      	add	r0, sp, #44	; 0x2c
   daa56:	f7fc fdcc 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   daa5a:	ab18      	add	r3, sp, #96	; 0x60
   daa5c:	462a      	mov	r2, r5
   daa5e:	4639      	mov	r1, r7
   daa60:	4630      	mov	r0, r6
   daa62:	f7fd f8db 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   daa66:	6863      	ldr	r3, [r4, #4]
   daa68:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   daa6a:	68a3      	ldr	r3, [r4, #8]
   daa6c:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   daa6e:	68e3      	ldr	r3, [r4, #12]
   daa70:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   daa72:	6923      	ldr	r3, [r4, #16]
   daa74:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   daa76:	6963      	ldr	r3, [r4, #20]
   daa78:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   daa7a:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   daa7c:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   daa80:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   daa82:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   daa84:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   daa86:	2100      	movs	r1, #0
   daa88:	a80b      	add	r0, sp, #44	; 0x2c
   daa8a:	f7fc fd79 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   daa8e:	4284      	cmp	r4, r0
   daa90:	da58      	bge.n	dab44 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11c>
   daa92:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   daa94:	af0b      	add	r7, sp, #44	; 0x2c
   daa96:	2101      	movs	r1, #1
   daa98:	4638      	mov	r0, r7
   daa9a:	f7fc fd71 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   daa9e:	4285      	cmp	r5, r0
   daaa0:	da4e      	bge.n	dab40 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x118>
   daaa2:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   daaa4:	2102      	movs	r1, #2
   daaa6:	4638      	mov	r0, r7
   daaa8:	f7fc fd6a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   daaac:	4286      	cmp	r6, r0
   daaae:	da45      	bge.n	dab3c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x114>
   daab0:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   daab4:	2103      	movs	r1, #3
   daab6:	4638      	mov	r0, r7
   daab8:	f7fc fd62 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   daabc:	4580      	cmp	r8, r0
   daabe:	da3b      	bge.n	dab38 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x110>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   daac0:	f8cd 8000 	str.w	r8, [sp]
   daac4:	4633      	mov	r3, r6
   daac6:	462a      	mov	r2, r5
   daac8:	4621      	mov	r1, r4
   daaca:	9809      	ldr	r0, [sp, #36]	; 0x24
   daacc:	f7fc fe6e 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   daad0:	9b08      	ldr	r3, [sp, #32]
   daad2:	f913 9000 	ldrsb.w	r9, [r3, r0]
   daad6:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   daad8:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   daadc:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   daade:	462a      	mov	r2, r5
   daae0:	4633      	mov	r3, r6
   daae2:	4621      	mov	r1, r4
   daae4:	a818      	add	r0, sp, #96	; 0x60
   daae6:	f7fc fe61 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   daaea:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   daaec:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   daaee:	f913 b000 	ldrsb.w	fp, [r3, r0]
   daaf2:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   daaf4:	9903      	ldr	r1, [sp, #12]
   daaf6:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   daafa:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   daafc:	f7fc fe04 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dab00:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dab04:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   dab06:	9a07      	ldr	r2, [sp, #28]
   dab08:	9906      	ldr	r1, [sp, #24]
   dab0a:	4658      	mov	r0, fp
   dab0c:	f7fc fdfc 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   dab10:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   dab14:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   dab16:	4633      	mov	r3, r6
   dab18:	462a      	mov	r2, r5
   dab1a:	4621      	mov	r1, r4
   dab1c:	4638      	mov	r0, r7
   dab1e:	f7fc fd94 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   dab22:	ebb9 090b 	subs.w	r9, r9, fp
   dab26:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   dab28:	bf18      	it	ne
   dab2a:	f04f 0901 	movne.w	r9, #1
   dab2e:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dab32:	f108 0801 	add.w	r8, r8, #1
   dab36:	e7bd      	b.n	daab4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dab38:	3601      	adds	r6, #1
   dab3a:	e7b3      	b.n	daaa4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dab3c:	3501      	adds	r5, #1
   dab3e:	e7a9      	b.n	daa94 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dab40:	3401      	adds	r4, #1
   dab42:	e7a0      	b.n	daa86 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   dab44:	a80b      	add	r0, sp, #44	; 0x2c
   dab46:	f7fc fd10 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   dab4a:	b021      	add	sp, #132	; 0x84
   dab4c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dab50 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode>:

// TODO(renjieliu): Refactor the logic to avoid duplications.
TfLiteStatus NotEqualEval(TfLiteContext* context, TfLiteNode* node) {
   dab50:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dab54:	680a      	ldr	r2, [r1, #0]
   dab56:	f8d0 9008 	ldr.w	r9, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dab5a:	6895      	ldr	r5, [r2, #8]
   dab5c:	4682      	mov	sl, r0
   dab5e:	6850      	ldr	r0, [r2, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dab60:	684a      	ldr	r2, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dab62:	2338      	movs	r3, #56	; 0x38
   dab64:	fb03 f800 	mul.w	r8, r3, r0
   dab68:	fb03 9505 	mla	r5, r3, r5, r9
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dab6c:	6854      	ldr	r4, [r2, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dab6e:	eb09 0608 	add.w	r6, r9, r8
   dab72:	b0ab      	sub	sp, #172	; 0xac
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dab74:	4629      	mov	r1, r5
   dab76:	4630      	mov	r0, r6
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dab78:	fb03 9404 	mla	r4, r3, r4, r9
   dab7c:	f00a f98c 	bl	e4e98 <_ZN6tflite14HaveSameShapesEPK12TfLiteTensorS2_>
  switch (input1->type) {
   dab80:	f819 2008 	ldrb.w	r2, [r9, r8]
// TODO(renjieliu): Refactor the logic to avoid duplications.
TfLiteStatus NotEqualEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dab84:	f080 0001 	eor.w	r0, r0, #1
  switch (input1->type) {
   dab88:	1e53      	subs	r3, r2, #1
// TODO(renjieliu): Refactor the logic to avoid duplications.
TfLiteStatus NotEqualEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dab8a:	b2c7      	uxtb	r7, r0
  switch (input1->type) {
   dab8c:	2b08      	cmp	r3, #8
   dab8e:	f200 826e 	bhi.w	db06e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x51e>
   dab92:	e8df f013 	tbh	[pc, r3, lsl #1]
   dab96:	0053      	.short	0x0053
   dab98:	013900a1 	.word	0x013900a1
   dab9c:	026c00eb 	.word	0x026c00eb
   daba0:	026c0009 	.word	0x026c0009
   daba4:	01cd026c 	.word	0x01cd026c
   daba8:	f10d 0874 	add.w	r8, sp, #116	; 0x74
    case kTfLiteBool:
      TF_LITE_COMPARISON(bool, NotEqual, requires_broadcast);
   dabac:	4631      	mov	r1, r6
   dabae:	b1cf      	cbz	r7, dabe4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x94>
   dabb0:	a813      	add	r0, sp, #76	; 0x4c
   dabb2:	f7fc ff8a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dabb6:	4629      	mov	r1, r5
   dabb8:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dabba:	6876      	ldr	r6, [r6, #4]
   dabbc:	f7fc ff85 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dabc0:	b105      	cbz	r5, dabc4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x74>
   dabc2:	686d      	ldr	r5, [r5, #4]
   dabc4:	4621      	mov	r1, r4
   dabc6:	4640      	mov	r0, r8
   dabc8:	f7fc ff7f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dabcc:	b104      	cbz	r4, dabd0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x80>
   dabce:	6864      	ldr	r4, [r4, #4]
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
   dabd0:	9402      	str	r4, [sp, #8]
   dabd2:	e88d 0120 	stmia.w	sp, {r5, r8}
   dabd6:	ab18      	add	r3, sp, #96	; 0x60
   dabd8:	4632      	mov	r2, r6
   dabda:	a913      	add	r1, sp, #76	; 0x4c
   dabdc:	a822      	add	r0, sp, #136	; 0x88
   dabde:	f7fe fbbf 	bl	d9360 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIbXadL_ZNS0_10NotEqualFnIbEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dabe2:	e1e7      	b.n	dafb4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x464>
   dabe4:	a818      	add	r0, sp, #96	; 0x60
   dabe6:	f7fc ff70 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dabea:	4629      	mov	r1, r5
   dabec:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dabee:	6876      	ldr	r6, [r6, #4]
   dabf0:	f7fc ff6b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dabf4:	b105      	cbz	r5, dabf8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0xa8>
   dabf6:	686d      	ldr	r5, [r5, #4]
   dabf8:	4621      	mov	r1, r4
   dabfa:	a822      	add	r0, sp, #136	; 0x88
   dabfc:	f7fc ff65 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dac00:	b104      	cbz	r4, dac04 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0xb4>
   dac02:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dac04:	4641      	mov	r1, r8
   dac06:	aa22      	add	r2, sp, #136	; 0x88
   dac08:	a818      	add	r0, sp, #96	; 0x60
   dac0a:	f7fc fd40 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dac0e:	3d01      	subs	r5, #1
   dac10:	1e73      	subs	r3, r6, #1
   dac12:	17c1      	asrs	r1, r0, #31
   dac14:	3c01      	subs	r4, #1
  for (int64_t i = 0; i < flatsize; ++i) {
   dac16:	2600      	movs	r6, #0
   dac18:	2700      	movs	r7, #0
   dac1a:	4286      	cmp	r6, r0
   dac1c:	eb77 0201 	sbcs.w	r2, r7, r1
   dac20:	f280 822c 	bge.w	db07c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x52c>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dac24:	f813 ef01 	ldrb.w	lr, [r3, #1]!
   dac28:	f815 2f01 	ldrb.w	r2, [r5, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dac2c:	3601      	adds	r6, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dac2e:	ea8e 0202 	eor.w	r2, lr, r2
   dac32:	f804 2f01 	strb.w	r2, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dac36:	f147 0700 	adc.w	r7, r7, #0
   dac3a:	e7ee      	b.n	dac1a <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0xca>
   dac3c:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteFloat32:
      TF_LITE_COMPARISON(float, NotEqual, requires_broadcast);
   dac40:	4631      	mov	r1, r6
   dac42:	b1cf      	cbz	r7, dac78 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x128>
   dac44:	a813      	add	r0, sp, #76	; 0x4c
   dac46:	f7fc ff40 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dac4a:	4629      	mov	r1, r5
   dac4c:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dac4e:	6876      	ldr	r6, [r6, #4]
   dac50:	f7fc ff3b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dac54:	b105      	cbz	r5, dac58 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x108>
   dac56:	686d      	ldr	r5, [r5, #4]
   dac58:	4621      	mov	r1, r4
   dac5a:	4640      	mov	r0, r8
   dac5c:	f7fc ff35 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dac60:	b104      	cbz	r4, dac64 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x114>
   dac62:	6864      	ldr	r4, [r4, #4]
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
   dac64:	9402      	str	r4, [sp, #8]
   dac66:	e88d 0120 	stmia.w	sp, {r5, r8}
   dac6a:	ab18      	add	r3, sp, #96	; 0x60
   dac6c:	4632      	mov	r2, r6
   dac6e:	a913      	add	r1, sp, #76	; 0x4c
   dac70:	a822      	add	r0, sp, #136	; 0x88
   dac72:	f7fe fbdd 	bl	d9430 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_10NotEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dac76:	e19d      	b.n	dafb4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x464>
   dac78:	a818      	add	r0, sp, #96	; 0x60
   dac7a:	f7fc ff26 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dac7e:	4629      	mov	r1, r5
   dac80:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dac82:	6876      	ldr	r6, [r6, #4]
   dac84:	f7fc ff21 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dac88:	b105      	cbz	r5, dac8c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x13c>
   dac8a:	686d      	ldr	r5, [r5, #4]
   dac8c:	4621      	mov	r1, r4
   dac8e:	a822      	add	r0, sp, #136	; 0x88
   dac90:	f7fc ff1b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dac94:	b104      	cbz	r4, dac98 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x148>
   dac96:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dac98:	4641      	mov	r1, r8
   dac9a:	aa22      	add	r2, sp, #136	; 0x88
   dac9c:	a818      	add	r0, sp, #96	; 0x60
   dac9e:	f7fc fcf6 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   daca2:	3c01      	subs	r4, #1
   daca4:	4633      	mov	r3, r6
   daca6:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   daca8:	2600      	movs	r6, #0
   dacaa:	2700      	movs	r7, #0
   dacac:	4286      	cmp	r6, r0
   dacae:	eb77 0201 	sbcs.w	r2, r7, r1
   dacb2:	f280 81e3 	bge.w	db07c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x52c>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dacb6:	ecb3 7a01 	vldmia	r3!, {s14}
   dacba:	ecf5 7a01 	vldmia	r5!, {s15}
   dacbe:	eeb4 7a67 	vcmp.f32	s14, s15
   dacc2:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   dacc6:	bf14      	ite	ne
   dacc8:	2201      	movne	r2, #1
   dacca:	2200      	moveq	r2, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   daccc:	3601      	adds	r6, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dacce:	f804 2f01 	strb.w	r2, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dacd2:	f147 0700 	adc.w	r7, r7, #0
   dacd6:	e7e9      	b.n	dacac <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x15c>
   dacd8:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, NotEqual, requires_broadcast);
   dacdc:	4631      	mov	r1, r6
   dacde:	b1cf      	cbz	r7, dad14 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x1c4>
   dace0:	a813      	add	r0, sp, #76	; 0x4c
   dace2:	f7fc fef2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dace6:	4629      	mov	r1, r5
   dace8:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dacea:	6876      	ldr	r6, [r6, #4]
   dacec:	f7fc feed 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dacf0:	b105      	cbz	r5, dacf4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x1a4>
   dacf2:	686d      	ldr	r5, [r5, #4]
   dacf4:	4621      	mov	r1, r4
   dacf6:	4640      	mov	r0, r8
   dacf8:	f7fc fee7 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dacfc:	b104      	cbz	r4, dad00 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x1b0>
   dacfe:	6864      	ldr	r4, [r4, #4]
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
   dad00:	9402      	str	r4, [sp, #8]
   dad02:	e88d 0120 	stmia.w	sp, {r5, r8}
   dad06:	ab18      	add	r3, sp, #96	; 0x60
   dad08:	4632      	mov	r2, r6
   dad0a:	a913      	add	r1, sp, #76	; 0x4c
   dad0c:	a822      	add	r0, sp, #136	; 0x88
   dad0e:	f7fe fc02 	bl	d9516 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dad12:	e14f      	b.n	dafb4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x464>
   dad14:	a818      	add	r0, sp, #96	; 0x60
   dad16:	f7fc fed8 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dad1a:	4629      	mov	r1, r5
   dad1c:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dad1e:	6876      	ldr	r6, [r6, #4]
   dad20:	f7fc fed3 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dad24:	b105      	cbz	r5, dad28 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x1d8>
   dad26:	686d      	ldr	r5, [r5, #4]
   dad28:	4621      	mov	r1, r4
   dad2a:	a822      	add	r0, sp, #136	; 0x88
   dad2c:	f7fc fecd 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dad30:	b104      	cbz	r4, dad34 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x1e4>
   dad32:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dad34:	aa22      	add	r2, sp, #136	; 0x88
   dad36:	4641      	mov	r1, r8
   dad38:	a818      	add	r0, sp, #96	; 0x60
   dad3a:	f7fc fca8 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dad3e:	3c01      	subs	r4, #1
   dad40:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   dad42:	2200      	movs	r2, #0
   dad44:	2300      	movs	r3, #0
   dad46:	4282      	cmp	r2, r0
   dad48:	eb73 0701 	sbcs.w	r7, r3, r1
   dad4c:	f280 8196 	bge.w	db07c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x52c>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dad50:	f856 7022 	ldr.w	r7, [r6, r2, lsl #2]
   dad54:	f855 e022 	ldr.w	lr, [r5, r2, lsl #2]
   dad58:	ebb7 070e 	subs.w	r7, r7, lr
   dad5c:	bf18      	it	ne
   dad5e:	2701      	movne	r7, #1
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dad60:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dad62:	f804 7f01 	strb.w	r7, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dad66:	f143 0300 	adc.w	r3, r3, #0
   dad6a:	e7ec      	b.n	dad46 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x1f6>
   dad6c:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, NotEqual, requires_broadcast);
   dad70:	4631      	mov	r1, r6
   dad72:	b1cf      	cbz	r7, dada8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x258>
   dad74:	a813      	add	r0, sp, #76	; 0x4c
   dad76:	f7fc fea8 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dad7a:	4629      	mov	r1, r5
   dad7c:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dad7e:	6876      	ldr	r6, [r6, #4]
   dad80:	f7fc fea3 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dad84:	b105      	cbz	r5, dad88 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x238>
   dad86:	686d      	ldr	r5, [r5, #4]
   dad88:	4621      	mov	r1, r4
   dad8a:	4640      	mov	r0, r8
   dad8c:	f7fc fe9d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dad90:	b104      	cbz	r4, dad94 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x244>
   dad92:	6864      	ldr	r4, [r4, #4]
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
   dad94:	9402      	str	r4, [sp, #8]
   dad96:	e88d 0120 	stmia.w	sp, {r5, r8}
   dad9a:	ab18      	add	r3, sp, #96	; 0x60
   dad9c:	4632      	mov	r2, r6
   dad9e:	a913      	add	r1, sp, #76	; 0x4c
   dada0:	a822      	add	r0, sp, #136	; 0x88
   dada2:	f7fe fc23 	bl	d95ec <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_10NotEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dada6:	e105      	b.n	dafb4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x464>
   dada8:	a818      	add	r0, sp, #96	; 0x60
   dadaa:	f7fc fe8e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dadae:	4629      	mov	r1, r5
   dadb0:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dadb2:	6876      	ldr	r6, [r6, #4]
   dadb4:	f7fc fe89 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dadb8:	b105      	cbz	r5, dadbc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x26c>
   dadba:	686d      	ldr	r5, [r5, #4]
   dadbc:	4621      	mov	r1, r4
   dadbe:	a822      	add	r0, sp, #136	; 0x88
   dadc0:	f7fc fe83 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dadc4:	b104      	cbz	r4, dadc8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x278>
   dadc6:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dadc8:	aa22      	add	r2, sp, #136	; 0x88
   dadca:	4641      	mov	r1, r8
   dadcc:	a818      	add	r0, sp, #96	; 0x60
   dadce:	f7fc fc5e 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dadd2:	3d08      	subs	r5, #8
   dadd4:	17c1      	asrs	r1, r0, #31
   dadd6:	f1a6 0e08 	sub.w	lr, r6, #8
   dadda:	3c01      	subs	r4, #1
  for (int64_t i = 0; i < flatsize; ++i) {
   daddc:	2200      	movs	r2, #0
   dadde:	2300      	movs	r3, #0
   dade0:	4282      	cmp	r2, r0
   dade2:	eb73 0601 	sbcs.w	r6, r3, r1
   dade6:	f280 8149 	bge.w	db07c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x52c>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dadea:	e9f5 6702 	ldrd	r6, r7, [r5, #8]!
   dadee:	e9fe ab02 	ldrd	sl, fp, [lr, #8]!
   dadf2:	45bb      	cmp	fp, r7
   dadf4:	bf0a      	itet	eq
   dadf6:	45b2      	cmpeq	sl, r6
   dadf8:	2601      	movne	r6, #1
   dadfa:	2600      	moveq	r6, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dadfc:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dadfe:	f804 6f01 	strb.w	r6, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dae02:	f143 0300 	adc.w	r3, r3, #0
   dae06:	e7eb      	b.n	dade0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x290>
            GetTensorData<bool>(output));                                      \
      }                                                                        \
    }                                                                          \
  }
TF_LITE_QUANTIZE_COMPARISON(Equal);
TF_LITE_QUANTIZE_COMPARISON(NotEqual);
   dae08:	6933      	ldr	r3, [r6, #16]
   dae0a:	68f0      	ldr	r0, [r6, #12]
   dae0c:	f1c3 0900 	rsb	r9, r3, #0
   dae10:	692b      	ldr	r3, [r5, #16]
   dae12:	f1c3 0800 	rsb	r8, r3, #0
   dae16:	f00d fab1 	bl	e837c <__aeabi_f2d>
   dae1a:	ec41 0b10 	vmov	d0, r0, r1
   dae1e:	a910      	add	r1, sp, #64	; 0x40
   dae20:	a80f      	add	r0, sp, #60	; 0x3c
   dae22:	f00a f8ad 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dae26:	68e8      	ldr	r0, [r5, #12]
   dae28:	f00d faa8 	bl	e837c <__aeabi_f2d>
   dae2c:	ec41 0b10 	vmov	d0, r0, r1
   dae30:	a912      	add	r1, sp, #72	; 0x48
   dae32:	a811      	add	r0, sp, #68	; 0x44
   dae34:	f00a f8a4 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dae38:	2308      	movs	r3, #8
   dae3a:	9322      	str	r3, [sp, #136]	; 0x88
   dae3c:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   dae3e:	9324      	str	r3, [sp, #144]	; 0x90
   dae40:	9b10      	ldr	r3, [sp, #64]	; 0x40
   dae42:	9325      	str	r3, [sp, #148]	; 0x94
   dae44:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dae46:	9327      	str	r3, [sp, #156]	; 0x9c
   dae48:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dae4a:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   dae4e:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   dae52:	9328      	str	r3, [sp, #160]	; 0xa0
   dae54:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   dae58:	4631      	mov	r1, r6
   dae5a:	a813      	add	r0, sp, #76	; 0x4c
   dae5c:	b1bf      	cbz	r7, dae8e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x33e>
   dae5e:	f7fc fe34 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dae62:	4629      	mov	r1, r5
   dae64:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dae66:	6876      	ldr	r6, [r6, #4]
   dae68:	f7fc fe2f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dae6c:	4621      	mov	r1, r4
   dae6e:	4640      	mov	r0, r8
   dae70:	686d      	ldr	r5, [r5, #4]
   dae72:	f7fc fe2a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dae76:	b104      	cbz	r4, dae7a <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x32a>
   dae78:	6864      	ldr	r4, [r4, #4]
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
   dae7a:	9402      	str	r4, [sp, #8]
   dae7c:	e88d 0120 	stmia.w	sp, {r5, r8}
   dae80:	ab18      	add	r3, sp, #96	; 0x60
   dae82:	4632      	mov	r2, r6
   dae84:	a913      	add	r1, sp, #76	; 0x4c
   dae86:	a822      	add	r0, sp, #136	; 0x88
   dae88:	f7ff fd3a 	bl	da900 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dae8c:	e092      	b.n	dafb4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x464>
   dae8e:	f7fc fe1c 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dae92:	6873      	ldr	r3, [r6, #4]
   dae94:	9305      	str	r3, [sp, #20]
   dae96:	4629      	mov	r1, r5
   dae98:	a818      	add	r0, sp, #96	; 0x60
   dae9a:	f7fc fe16 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dae9e:	4621      	mov	r1, r4
   daea0:	4640      	mov	r0, r8
   daea2:	f8d5 b004 	ldr.w	fp, [r5, #4]
   daea6:	f7fc fe10 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   daeaa:	b104      	cbz	r4, daeae <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x35e>
   daeac:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   daeae:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   daeb0:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   daeb2:	9b24      	ldr	r3, [sp, #144]	; 0x90
   daeb4:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   daeb6:	9b25      	ldr	r3, [sp, #148]	; 0x94
   daeb8:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   daeba:	9b26      	ldr	r3, [sp, #152]	; 0x98
   daebc:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   daebe:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   daec0:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   daec2:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   daec4:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   daec6:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   daec8:	a918      	add	r1, sp, #96	; 0x60
   daeca:	a813      	add	r0, sp, #76	; 0x4c
   daecc:	f7fc fbdf 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   daed0:	4602      	mov	r2, r0
   daed2:	17c3      	asrs	r3, r0, #31
   daed4:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   daed8:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   daeda:	f04f 0800 	mov.w	r8, #0
   daede:	f04f 0900 	mov.w	r9, #0
   daee2:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   daee6:	4590      	cmp	r8, r2
   daee8:	eb79 0303 	sbcs.w	r3, r9, r3
   daeec:	f280 80b4 	bge.w	db058 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x508>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   daef0:	f81b 5008 	ldrb.w	r5, [fp, r8]
   daef4:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   daef6:	9a08      	ldr	r2, [sp, #32]
   daef8:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   daefa:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   daefc:	9b05      	ldr	r3, [sp, #20]
   daefe:	f813 0008 	ldrb.w	r0, [r3, r8]
   daf02:	9b06      	ldr	r3, [sp, #24]
   daf04:	4418      	add	r0, r3
   daf06:	40b8      	lsls	r0, r7
   daf08:	f7fc fbfe 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   daf0c:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   daf0e:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   daf10:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   daf12:	990a      	ldr	r1, [sp, #40]	; 0x28
   daf14:	4628      	mov	r0, r5
   daf16:	f7fc fbf7 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   daf1a:	ebba 0000 	subs.w	r0, sl, r0
   daf1e:	bf18      	it	ne
   daf20:	2001      	movne	r0, #1
   daf22:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   daf26:	f118 0801 	adds.w	r8, r8, #1
   daf2a:	f149 0900 	adc.w	r9, r9, #0
   daf2e:	e7d8      	b.n	daee2 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x392>
   daf30:	6933      	ldr	r3, [r6, #16]
   daf32:	68f0      	ldr	r0, [r6, #12]
   daf34:	f1c3 0900 	rsb	r9, r3, #0
   daf38:	692b      	ldr	r3, [r5, #16]
   daf3a:	f1c3 0800 	rsb	r8, r3, #0
   daf3e:	f00d fa1d 	bl	e837c <__aeabi_f2d>
   daf42:	ec41 0b10 	vmov	d0, r0, r1
   daf46:	a910      	add	r1, sp, #64	; 0x40
   daf48:	a80f      	add	r0, sp, #60	; 0x3c
   daf4a:	f00a f819 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   daf4e:	68e8      	ldr	r0, [r5, #12]
   daf50:	f00d fa14 	bl	e837c <__aeabi_f2d>
   daf54:	ec41 0b10 	vmov	d0, r0, r1
   daf58:	a912      	add	r1, sp, #72	; 0x48
   daf5a:	a811      	add	r0, sp, #68	; 0x44
   daf5c:	f00a f810 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   daf60:	2308      	movs	r3, #8
   daf62:	9322      	str	r3, [sp, #136]	; 0x88
   daf64:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   daf66:	9324      	str	r3, [sp, #144]	; 0x90
   daf68:	9b10      	ldr	r3, [sp, #64]	; 0x40
   daf6a:	9325      	str	r3, [sp, #148]	; 0x94
   daf6c:	9b11      	ldr	r3, [sp, #68]	; 0x44
   daf6e:	9327      	str	r3, [sp, #156]	; 0x9c
   daf70:	9b12      	ldr	r3, [sp, #72]	; 0x48
   daf72:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   daf76:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   daf7a:	9328      	str	r3, [sp, #160]	; 0xa0
   daf7c:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   daf80:	4631      	mov	r1, r6
   daf82:	a813      	add	r0, sp, #76	; 0x4c
   daf84:	b1c7      	cbz	r7, dafb8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x468>
   daf86:	f7fc fda0 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   daf8a:	4629      	mov	r1, r5
   daf8c:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   daf8e:	6876      	ldr	r6, [r6, #4]
   daf90:	f7fc fd9b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   daf94:	4621      	mov	r1, r4
   daf96:	4640      	mov	r0, r8
   daf98:	686d      	ldr	r5, [r5, #4]
   daf9a:	f7fc fd96 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   daf9e:	b104      	cbz	r4, dafa2 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x452>
   dafa0:	6864      	ldr	r4, [r4, #4]
    BroadcastComparison4DSlowWithScaling<T, name##Fn>(                         \
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
   dafa2:	9402      	str	r4, [sp, #8]
   dafa4:	e88d 0120 	stmia.w	sp, {r5, r8}
   dafa8:	ab18      	add	r3, sp, #96	; 0x60
   dafaa:	4632      	mov	r2, r6
   dafac:	a913      	add	r1, sp, #76	; 0x4c
   dafae:	a822      	add	r0, sp, #136	; 0x88
   dafb0:	f7ff fd3a 	bl	daa28 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_10NotEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dafb4:	4640      	mov	r0, r8
   dafb6:	e050      	b.n	db05a <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x50a>
   dafb8:	f7fc fd87 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dafbc:	6873      	ldr	r3, [r6, #4]
   dafbe:	9305      	str	r3, [sp, #20]
   dafc0:	4629      	mov	r1, r5
   dafc2:	a818      	add	r0, sp, #96	; 0x60
   dafc4:	f7fc fd81 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dafc8:	4621      	mov	r1, r4
   dafca:	4640      	mov	r0, r8
   dafcc:	f8d5 b004 	ldr.w	fp, [r5, #4]
   dafd0:	f7fc fd7b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dafd4:	b104      	cbz	r4, dafd8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x488>
   dafd6:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dafd8:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   dafda:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   dafdc:	9b24      	ldr	r3, [sp, #144]	; 0x90
   dafde:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   dafe0:	9b25      	ldr	r3, [sp, #148]	; 0x94
   dafe2:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   dafe4:	9b26      	ldr	r3, [sp, #152]	; 0x98
   dafe6:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   dafe8:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   dafea:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dafec:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dafee:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   daff0:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   daff2:	a918      	add	r1, sp, #96	; 0x60
   daff4:	a813      	add	r0, sp, #76	; 0x4c
   daff6:	f7fc fb4a 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   daffa:	4602      	mov	r2, r0
   daffc:	17c3      	asrs	r3, r0, #31
   daffe:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   db002:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db004:	f04f 0800 	mov.w	r8, #0
   db008:	f04f 0900 	mov.w	r9, #0
   db00c:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   db010:	4590      	cmp	r8, r2
   db012:	eb79 0303 	sbcs.w	r3, r9, r3
   db016:	da1f      	bge.n	db058 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x508>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db018:	f91b 5008 	ldrsb.w	r5, [fp, r8]
   db01c:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   db01e:	9a08      	ldr	r2, [sp, #32]
   db020:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db022:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   db024:	9b05      	ldr	r3, [sp, #20]
   db026:	f913 0008 	ldrsb.w	r0, [r3, r8]
   db02a:	9b06      	ldr	r3, [sp, #24]
   db02c:	4418      	add	r0, r3
   db02e:	40b8      	lsls	r0, r7
   db030:	f7fc fb6a 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db034:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   db036:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   db038:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   db03a:	990a      	ldr	r1, [sp, #40]	; 0x28
   db03c:	4628      	mov	r0, r5
   db03e:	f7fc fb63 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   db042:	ebba 0000 	subs.w	r0, sl, r0
   db046:	bf18      	it	ne
   db048:	2001      	movne	r0, #1
   db04a:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db04e:	f118 0801 	adds.w	r8, r8, #1
   db052:	f149 0900 	adc.w	r9, r9, #0
   db056:	e7d9      	b.n	db00c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x4bc>
   db058:	a81d      	add	r0, sp, #116	; 0x74
   db05a:	f7fc fa86 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   db05e:	a818      	add	r0, sp, #96	; 0x60
   db060:	f7fc fa83 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   db064:	a813      	add	r0, sp, #76	; 0x4c
   db066:	f7fc fa80 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      context->ReportError(
          context, "Does not support type %d, requires bool|float|int|uint8",
          input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
   db06a:	2000      	movs	r0, #0
   db06c:	e00e      	b.n	db08c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x53c>
                                    requires_broadcast);
      break;
    default:
      context->ReportError(
          context, "Does not support type %d, requires bool|float|int|uint8",
          input1->type);
   db06e:	4650      	mov	r0, sl
   db070:	f8da 3014 	ldr.w	r3, [sl, #20]
   db074:	4907      	ldr	r1, [pc, #28]	; (db094 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x544>)
   db076:	4798      	blx	r3
      return kTfLiteError;
   db078:	2001      	movs	r0, #1
   db07a:	e007      	b.n	db08c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x53c>
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, NotEqual, requires_broadcast);
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, NotEqual, requires_broadcast);
   db07c:	a822      	add	r0, sp, #136	; 0x88
   db07e:	f7fc fa74 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   db082:	4640      	mov	r0, r8
   db084:	f7fc fa71 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   db088:	a818      	add	r0, sp, #96	; 0x60
   db08a:	e7ec      	b.n	db066 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_112NotEqualEvalEP13TfLiteContextP10TfLiteNode+0x516>
          context, "Does not support type %d, requires bool|float|int|uint8",
          input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   db08c:	b02b      	add	sp, #172	; 0xac
   db08e:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   db092:	bf00      	nop
   db094:	000eb478 	.word	0x000eb478

000db098 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db098:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   db09c:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db09e:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db0a0:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db0a2:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db0a4:	9208      	str	r2, [sp, #32]
   db0a6:	4604      	mov	r4, r0
   db0a8:	460e      	mov	r6, r1
   db0aa:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db0ac:	dd01      	ble.n	db0b2 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   db0ae:	f00a fa21 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   db0b2:	683b      	ldr	r3, [r7, #0]
   db0b4:	2b04      	cmp	r3, #4
   db0b6:	dcfa      	bgt.n	db0ae <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   db0b8:	6813      	ldr	r3, [r2, #0]
   db0ba:	2b04      	cmp	r3, #4
   db0bc:	dcf7      	bgt.n	db0ae <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   db0be:	2301      	movs	r3, #1
   db0c0:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   db0c2:	ad10      	add	r5, sp, #64	; 0x40
   db0c4:	a80b      	add	r0, sp, #44	; 0x2c
   db0c6:	f7fc fa94 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   db0ca:	ab18      	add	r3, sp, #96	; 0x60
   db0cc:	462a      	mov	r2, r5
   db0ce:	4639      	mov	r1, r7
   db0d0:	4630      	mov	r0, r6
   db0d2:	f7fc fda3 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   db0d6:	6863      	ldr	r3, [r4, #4]
   db0d8:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   db0da:	68a3      	ldr	r3, [r4, #8]
   db0dc:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   db0de:	68e3      	ldr	r3, [r4, #12]
   db0e0:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   db0e2:	6923      	ldr	r3, [r4, #16]
   db0e4:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   db0e6:	6963      	ldr	r3, [r4, #20]
   db0e8:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   db0ea:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   db0ec:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   db0f0:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db0f2:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db0f4:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db0f6:	2100      	movs	r1, #0
   db0f8:	a80b      	add	r0, sp, #44	; 0x2c
   db0fa:	f7fc fa41 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db0fe:	4284      	cmp	r4, r0
   db100:	da59      	bge.n	db1b6 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11e>
   db102:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   db104:	af0b      	add	r7, sp, #44	; 0x2c
   db106:	2101      	movs	r1, #1
   db108:	4638      	mov	r0, r7
   db10a:	f7fc fa39 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db10e:	4285      	cmp	r5, r0
   db110:	da4f      	bge.n	db1b2 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11a>
   db112:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   db114:	2102      	movs	r1, #2
   db116:	4638      	mov	r0, r7
   db118:	f7fc fa32 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db11c:	4286      	cmp	r6, r0
   db11e:	da46      	bge.n	db1ae <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x116>
   db120:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   db124:	2103      	movs	r1, #3
   db126:	4638      	mov	r0, r7
   db128:	f7fc fa2a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db12c:	4580      	cmp	r8, r0
   db12e:	da3c      	bge.n	db1aa <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x112>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db130:	f8cd 8000 	str.w	r8, [sp]
   db134:	4633      	mov	r3, r6
   db136:	462a      	mov	r2, r5
   db138:	4621      	mov	r1, r4
   db13a:	9809      	ldr	r0, [sp, #36]	; 0x24
   db13c:	f7fc fb36 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   db140:	9b08      	ldr	r3, [sp, #32]
   db142:	f813 9000 	ldrb.w	r9, [r3, r0]
   db146:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   db148:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db14c:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   db14e:	462a      	mov	r2, r5
   db150:	4633      	mov	r3, r6
   db152:	4621      	mov	r1, r4
   db154:	a818      	add	r0, sp, #96	; 0x60
   db156:	f7fc fb29 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db15a:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db15c:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db15e:	f813 b000 	ldrb.w	fp, [r3, r0]
   db162:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db164:	9903      	ldr	r1, [sp, #12]
   db166:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db16a:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db16c:	f7fc facc 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db170:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db174:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   db176:	9a07      	ldr	r2, [sp, #28]
   db178:	9906      	ldr	r1, [sp, #24]
   db17a:	4658      	mov	r0, fp
   db17c:	f7fc fac4 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   db180:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   db184:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   db186:	4633      	mov	r3, r6
   db188:	462a      	mov	r2, r5
   db18a:	4621      	mov	r1, r4
   db18c:	4638      	mov	r0, r7
   db18e:	f7fc fa5c 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   db192:	45d9      	cmp	r9, fp
   db194:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   db196:	bfd4      	ite	le
   db198:	f04f 0900 	movle.w	r9, #0
   db19c:	f04f 0901 	movgt.w	r9, #1
   db1a0:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   db1a4:	f108 0801 	add.w	r8, r8, #1
   db1a8:	e7bc      	b.n	db124 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   db1aa:	3601      	adds	r6, #1
   db1ac:	e7b2      	b.n	db114 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   db1ae:	3501      	adds	r5, #1
   db1b0:	e7a8      	b.n	db104 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db1b2:	3401      	adds	r4, #1
   db1b4:	e79f      	b.n	db0f6 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   db1b6:	a80b      	add	r0, sp, #44	; 0x2c
   db1b8:	f7fc f9d7 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   db1bc:	b021      	add	sp, #132	; 0x84
   db1be:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000db1c2 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db1c2:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   db1c6:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db1c8:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db1ca:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db1cc:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db1ce:	9208      	str	r2, [sp, #32]
   db1d0:	4604      	mov	r4, r0
   db1d2:	460e      	mov	r6, r1
   db1d4:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db1d6:	dd01      	ble.n	db1dc <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   db1d8:	f00a f98c 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   db1dc:	683b      	ldr	r3, [r7, #0]
   db1de:	2b04      	cmp	r3, #4
   db1e0:	dcfa      	bgt.n	db1d8 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   db1e2:	6813      	ldr	r3, [r2, #0]
   db1e4:	2b04      	cmp	r3, #4
   db1e6:	dcf7      	bgt.n	db1d8 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   db1e8:	2301      	movs	r3, #1
   db1ea:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   db1ec:	ad10      	add	r5, sp, #64	; 0x40
   db1ee:	a80b      	add	r0, sp, #44	; 0x2c
   db1f0:	f7fc f9ff 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   db1f4:	ab18      	add	r3, sp, #96	; 0x60
   db1f6:	462a      	mov	r2, r5
   db1f8:	4639      	mov	r1, r7
   db1fa:	4630      	mov	r0, r6
   db1fc:	f7fc fd0e 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   db200:	6863      	ldr	r3, [r4, #4]
   db202:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   db204:	68a3      	ldr	r3, [r4, #8]
   db206:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   db208:	68e3      	ldr	r3, [r4, #12]
   db20a:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   db20c:	6923      	ldr	r3, [r4, #16]
   db20e:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   db210:	6963      	ldr	r3, [r4, #20]
   db212:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   db214:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   db216:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   db21a:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db21c:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db21e:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db220:	2100      	movs	r1, #0
   db222:	a80b      	add	r0, sp, #44	; 0x2c
   db224:	f7fc f9ac 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db228:	4284      	cmp	r4, r0
   db22a:	da59      	bge.n	db2e0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11e>
   db22c:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   db22e:	af0b      	add	r7, sp, #44	; 0x2c
   db230:	2101      	movs	r1, #1
   db232:	4638      	mov	r0, r7
   db234:	f7fc f9a4 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db238:	4285      	cmp	r5, r0
   db23a:	da4f      	bge.n	db2dc <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11a>
   db23c:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   db23e:	2102      	movs	r1, #2
   db240:	4638      	mov	r0, r7
   db242:	f7fc f99d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db246:	4286      	cmp	r6, r0
   db248:	da46      	bge.n	db2d8 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x116>
   db24a:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   db24e:	2103      	movs	r1, #3
   db250:	4638      	mov	r0, r7
   db252:	f7fc f995 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db256:	4580      	cmp	r8, r0
   db258:	da3c      	bge.n	db2d4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x112>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db25a:	f8cd 8000 	str.w	r8, [sp]
   db25e:	4633      	mov	r3, r6
   db260:	462a      	mov	r2, r5
   db262:	4621      	mov	r1, r4
   db264:	9809      	ldr	r0, [sp, #36]	; 0x24
   db266:	f7fc faa1 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   db26a:	9b08      	ldr	r3, [sp, #32]
   db26c:	f913 9000 	ldrsb.w	r9, [r3, r0]
   db270:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   db272:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db276:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   db278:	462a      	mov	r2, r5
   db27a:	4633      	mov	r3, r6
   db27c:	4621      	mov	r1, r4
   db27e:	a818      	add	r0, sp, #96	; 0x60
   db280:	f7fc fa94 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db284:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db286:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db288:	f913 b000 	ldrsb.w	fp, [r3, r0]
   db28c:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db28e:	9903      	ldr	r1, [sp, #12]
   db290:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db294:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db296:	f7fc fa37 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db29a:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db29e:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   db2a0:	9a07      	ldr	r2, [sp, #28]
   db2a2:	9906      	ldr	r1, [sp, #24]
   db2a4:	4658      	mov	r0, fp
   db2a6:	f7fc fa2f 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   db2aa:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   db2ae:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   db2b0:	4633      	mov	r3, r6
   db2b2:	462a      	mov	r2, r5
   db2b4:	4621      	mov	r1, r4
   db2b6:	4638      	mov	r0, r7
   db2b8:	f7fc f9c7 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   db2bc:	45d9      	cmp	r9, fp
   db2be:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   db2c0:	bfd4      	ite	le
   db2c2:	f04f 0900 	movle.w	r9, #0
   db2c6:	f04f 0901 	movgt.w	r9, #1
   db2ca:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   db2ce:	f108 0801 	add.w	r8, r8, #1
   db2d2:	e7bc      	b.n	db24e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   db2d4:	3601      	adds	r6, #1
   db2d6:	e7b2      	b.n	db23e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   db2d8:	3501      	adds	r5, #1
   db2da:	e7a8      	b.n	db22e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db2dc:	3401      	adds	r4, #1
   db2de:	e79f      	b.n	db220 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   db2e0:	a80b      	add	r0, sp, #44	; 0x2c
   db2e2:	f7fc f942 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   db2e6:	b021      	add	sp, #132	; 0x84
   db2e8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000db2ec <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus GreaterEval(TfLiteContext* context, TfLiteNode* node) {
   db2ec:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   db2f0:	680a      	ldr	r2, [r1, #0]
   db2f2:	f8d0 9008 	ldr.w	r9, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   db2f6:	6895      	ldr	r5, [r2, #8]
   db2f8:	4682      	mov	sl, r0
   db2fa:	6850      	ldr	r0, [r2, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   db2fc:	684a      	ldr	r2, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   db2fe:	2338      	movs	r3, #56	; 0x38
   db300:	fb03 f800 	mul.w	r8, r3, r0
   db304:	fb03 9505 	mla	r5, r3, r5, r9
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   db308:	6854      	ldr	r4, [r2, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   db30a:	eb09 0608 	add.w	r6, r9, r8
   db30e:	b0ab      	sub	sp, #172	; 0xac
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   db310:	4629      	mov	r1, r5
   db312:	4630      	mov	r0, r6
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   db314:	fb03 9404 	mla	r4, r3, r4, r9
   db318:	f009 fdbe 	bl	e4e98 <_ZN6tflite14HaveSameShapesEPK12TfLiteTensorS2_>
  switch (input1->type) {
   db31c:	f819 2008 	ldrb.w	r2, [r9, r8]

TfLiteStatus GreaterEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   db320:	f080 0001 	eor.w	r0, r0, #1
  switch (input1->type) {
   db324:	1e53      	subs	r3, r2, #1

TfLiteStatus GreaterEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   db326:	b2c7      	uxtb	r7, r0
  switch (input1->type) {
   db328:	2b08      	cmp	r3, #8
   db32a:	f200 8225 	bhi.w	db778 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x48c>
   db32e:	e8df f013 	tbh	[pc, r3, lsl #1]
   db332:	0009      	.short	0x0009
   db334:	00f00057 	.word	0x00f00057
   db338:	022300a1 	.word	0x022300a1
   db33c:	02230223 	.word	0x02230223
   db340:	01840223 	.word	0x01840223
   db344:	f10d 0874 	add.w	r8, sp, #116	; 0x74
    case kTfLiteFloat32:
      TF_LITE_COMPARISON(float, Greater, requires_broadcast);
   db348:	4631      	mov	r1, r6
   db34a:	b1cf      	cbz	r7, db380 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x94>
   db34c:	a813      	add	r0, sp, #76	; 0x4c
   db34e:	f7fc fbbc 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db352:	4629      	mov	r1, r5
   db354:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   db356:	6876      	ldr	r6, [r6, #4]
   db358:	f7fc fbb7 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db35c:	b105      	cbz	r5, db360 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x74>
   db35e:	686d      	ldr	r5, [r5, #4]
   db360:	4621      	mov	r1, r4
   db362:	4640      	mov	r0, r8
   db364:	f7fc fbb1 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   db368:	b104      	cbz	r4, db36c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x80>
   db36a:	6864      	ldr	r4, [r4, #4]
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
   db36c:	9402      	str	r4, [sp, #8]
   db36e:	e88d 0120 	stmia.w	sp, {r5, r8}
   db372:	ab18      	add	r3, sp, #96	; 0x60
   db374:	4632      	mov	r2, r6
   db376:	a913      	add	r1, sp, #76	; 0x4c
   db378:	a822      	add	r0, sp, #136	; 0x88
   db37a:	f7fe f9a9 	bl	d96d0 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_9GreaterFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   db37e:	e19e      	b.n	db6be <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   db380:	a818      	add	r0, sp, #96	; 0x60
   db382:	f7fc fba2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db386:	4629      	mov	r1, r5
   db388:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   db38a:	6876      	ldr	r6, [r6, #4]
   db38c:	f7fc fb9d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db390:	b105      	cbz	r5, db394 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0xa8>
   db392:	686d      	ldr	r5, [r5, #4]
   db394:	4621      	mov	r1, r4
   db396:	a822      	add	r0, sp, #136	; 0x88
   db398:	f7fc fb97 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   db39c:	b104      	cbz	r4, db3a0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0xb4>
   db39e:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   db3a0:	4641      	mov	r1, r8
   db3a2:	aa22      	add	r2, sp, #136	; 0x88
   db3a4:	a818      	add	r0, sp, #96	; 0x60
   db3a6:	f7fc f972 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   db3aa:	3c01      	subs	r4, #1
   db3ac:	4633      	mov	r3, r6
   db3ae:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   db3b0:	2600      	movs	r6, #0
   db3b2:	2700      	movs	r7, #0
   db3b4:	4286      	cmp	r6, r0
   db3b6:	eb77 0201 	sbcs.w	r2, r7, r1
   db3ba:	f280 81e4 	bge.w	db786 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   db3be:	ecb3 7a01 	vldmia	r3!, {s14}
   db3c2:	ecf5 7a01 	vldmia	r5!, {s15}
   db3c6:	eeb4 7ae7 	vcmpe.f32	s14, s15
   db3ca:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   db3ce:	bfcc      	ite	gt
   db3d0:	2201      	movgt	r2, #1
   db3d2:	2200      	movle	r2, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db3d4:	3601      	adds	r6, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   db3d6:	f804 2f01 	strb.w	r2, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db3da:	f147 0700 	adc.w	r7, r7, #0
   db3de:	e7e9      	b.n	db3b4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0xc8>
   db3e0:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, Greater, requires_broadcast);
   db3e4:	4631      	mov	r1, r6
   db3e6:	b1cf      	cbz	r7, db41c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x130>
   db3e8:	a813      	add	r0, sp, #76	; 0x4c
   db3ea:	f7fc fb6e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db3ee:	4629      	mov	r1, r5
   db3f0:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   db3f2:	6876      	ldr	r6, [r6, #4]
   db3f4:	f7fc fb69 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db3f8:	b105      	cbz	r5, db3fc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x110>
   db3fa:	686d      	ldr	r5, [r5, #4]
   db3fc:	4621      	mov	r1, r4
   db3fe:	4640      	mov	r0, r8
   db400:	f7fc fb63 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   db404:	b104      	cbz	r4, db408 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x11c>
   db406:	6864      	ldr	r4, [r4, #4]
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
   db408:	9402      	str	r4, [sp, #8]
   db40a:	e88d 0120 	stmia.w	sp, {r5, r8}
   db40e:	ab18      	add	r3, sp, #96	; 0x60
   db410:	4632      	mov	r2, r6
   db412:	a913      	add	r1, sp, #76	; 0x4c
   db414:	a822      	add	r0, sp, #136	; 0x88
   db416:	f7fe f9ce 	bl	d97b6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   db41a:	e150      	b.n	db6be <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   db41c:	a818      	add	r0, sp, #96	; 0x60
   db41e:	f7fc fb54 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db422:	4629      	mov	r1, r5
   db424:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   db426:	6876      	ldr	r6, [r6, #4]
   db428:	f7fc fb4f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db42c:	b105      	cbz	r5, db430 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x144>
   db42e:	686d      	ldr	r5, [r5, #4]
   db430:	4621      	mov	r1, r4
   db432:	a822      	add	r0, sp, #136	; 0x88
   db434:	f7fc fb49 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   db438:	b104      	cbz	r4, db43c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x150>
   db43a:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   db43c:	aa22      	add	r2, sp, #136	; 0x88
   db43e:	4641      	mov	r1, r8
   db440:	a818      	add	r0, sp, #96	; 0x60
   db442:	f7fc f924 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   db446:	3c01      	subs	r4, #1
   db448:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   db44a:	2200      	movs	r2, #0
   db44c:	2300      	movs	r3, #0
   db44e:	4282      	cmp	r2, r0
   db450:	eb73 0701 	sbcs.w	r7, r3, r1
   db454:	f280 8197 	bge.w	db786 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   db458:	f856 7022 	ldr.w	r7, [r6, r2, lsl #2]
   db45c:	f855 e022 	ldr.w	lr, [r5, r2, lsl #2]
   db460:	4577      	cmp	r7, lr
   db462:	bfd4      	ite	le
   db464:	2700      	movle	r7, #0
   db466:	2701      	movgt	r7, #1
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db468:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   db46a:	f804 7f01 	strb.w	r7, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db46e:	f143 0300 	adc.w	r3, r3, #0
   db472:	e7ec      	b.n	db44e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x162>
   db474:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, Greater, requires_broadcast);
   db478:	4631      	mov	r1, r6
   db47a:	b1cf      	cbz	r7, db4b0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x1c4>
   db47c:	a813      	add	r0, sp, #76	; 0x4c
   db47e:	f7fc fb24 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db482:	4629      	mov	r1, r5
   db484:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   db486:	6876      	ldr	r6, [r6, #4]
   db488:	f7fc fb1f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db48c:	b105      	cbz	r5, db490 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x1a4>
   db48e:	686d      	ldr	r5, [r5, #4]
   db490:	4621      	mov	r1, r4
   db492:	4640      	mov	r0, r8
   db494:	f7fc fb19 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   db498:	b104      	cbz	r4, db49c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x1b0>
   db49a:	6864      	ldr	r4, [r4, #4]
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
   db49c:	9402      	str	r4, [sp, #8]
   db49e:	e88d 0120 	stmia.w	sp, {r5, r8}
   db4a2:	ab18      	add	r3, sp, #96	; 0x60
   db4a4:	4632      	mov	r2, r6
   db4a6:	a913      	add	r1, sp, #76	; 0x4c
   db4a8:	a822      	add	r0, sp, #136	; 0x88
   db4aa:	f7fe f9f0 	bl	d988e <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_9GreaterFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   db4ae:	e106      	b.n	db6be <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   db4b0:	a818      	add	r0, sp, #96	; 0x60
   db4b2:	f7fc fb0a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db4b6:	4629      	mov	r1, r5
   db4b8:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   db4ba:	6876      	ldr	r6, [r6, #4]
   db4bc:	f7fc fb05 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db4c0:	b105      	cbz	r5, db4c4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x1d8>
   db4c2:	686d      	ldr	r5, [r5, #4]
   db4c4:	4621      	mov	r1, r4
   db4c6:	a822      	add	r0, sp, #136	; 0x88
   db4c8:	f7fc faff 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   db4cc:	b104      	cbz	r4, db4d0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x1e4>
   db4ce:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   db4d0:	aa22      	add	r2, sp, #136	; 0x88
   db4d2:	4641      	mov	r1, r8
   db4d4:	a818      	add	r0, sp, #96	; 0x60
   db4d6:	f7fc f8da 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   db4da:	3d08      	subs	r5, #8
   db4dc:	17c1      	asrs	r1, r0, #31
   db4de:	f1a6 0e08 	sub.w	lr, r6, #8
   db4e2:	3c01      	subs	r4, #1
  for (int64_t i = 0; i < flatsize; ++i) {
   db4e4:	2200      	movs	r2, #0
   db4e6:	2300      	movs	r3, #0
   db4e8:	4282      	cmp	r2, r0
   db4ea:	eb73 0601 	sbcs.w	r6, r3, r1
   db4ee:	f280 814a 	bge.w	db786 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   db4f2:	e9fe 6702 	ldrd	r6, r7, [lr, #8]!
   db4f6:	e9f5 ab02 	ldrd	sl, fp, [r5, #8]!
   db4fa:	45b2      	cmp	sl, r6
   db4fc:	eb7b 0607 	sbcs.w	r6, fp, r7
   db500:	bfb4      	ite	lt
   db502:	2601      	movlt	r6, #1
   db504:	2600      	movge	r6, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db506:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   db508:	f804 6f01 	strb.w	r6, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db50c:	f143 0300 	adc.w	r3, r3, #0
   db510:	e7ea      	b.n	db4e8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x1fc>
      }                                                                        \
    }                                                                          \
  }
TF_LITE_QUANTIZE_COMPARISON(Equal);
TF_LITE_QUANTIZE_COMPARISON(NotEqual);
TF_LITE_QUANTIZE_COMPARISON(Greater);
   db512:	6933      	ldr	r3, [r6, #16]
   db514:	68f0      	ldr	r0, [r6, #12]
   db516:	f1c3 0900 	rsb	r9, r3, #0
   db51a:	692b      	ldr	r3, [r5, #16]
   db51c:	f1c3 0800 	rsb	r8, r3, #0
   db520:	f00c ff2c 	bl	e837c <__aeabi_f2d>
   db524:	ec41 0b10 	vmov	d0, r0, r1
   db528:	a910      	add	r1, sp, #64	; 0x40
   db52a:	a80f      	add	r0, sp, #60	; 0x3c
   db52c:	f009 fd28 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   db530:	68e8      	ldr	r0, [r5, #12]
   db532:	f00c ff23 	bl	e837c <__aeabi_f2d>
   db536:	ec41 0b10 	vmov	d0, r0, r1
   db53a:	a912      	add	r1, sp, #72	; 0x48
   db53c:	a811      	add	r0, sp, #68	; 0x44
   db53e:	f009 fd1f 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   db542:	2308      	movs	r3, #8
   db544:	9322      	str	r3, [sp, #136]	; 0x88
   db546:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   db548:	9324      	str	r3, [sp, #144]	; 0x90
   db54a:	9b10      	ldr	r3, [sp, #64]	; 0x40
   db54c:	9325      	str	r3, [sp, #148]	; 0x94
   db54e:	9b11      	ldr	r3, [sp, #68]	; 0x44
   db550:	9327      	str	r3, [sp, #156]	; 0x9c
   db552:	9b12      	ldr	r3, [sp, #72]	; 0x48
   db554:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   db558:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   db55c:	9328      	str	r3, [sp, #160]	; 0xa0
   db55e:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   db562:	4631      	mov	r1, r6
   db564:	a813      	add	r0, sp, #76	; 0x4c
   db566:	b1bf      	cbz	r7, db598 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x2ac>
   db568:	f7fc faaf 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db56c:	4629      	mov	r1, r5
   db56e:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   db570:	6876      	ldr	r6, [r6, #4]
   db572:	f7fc faaa 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db576:	4621      	mov	r1, r4
   db578:	4640      	mov	r0, r8
   db57a:	686d      	ldr	r5, [r5, #4]
   db57c:	f7fc faa5 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   db580:	b104      	cbz	r4, db584 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x298>
   db582:	6864      	ldr	r4, [r4, #4]
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
   db584:	9402      	str	r4, [sp, #8]
   db586:	e88d 0120 	stmia.w	sp, {r5, r8}
   db58a:	ab18      	add	r3, sp, #96	; 0x60
   db58c:	4632      	mov	r2, r6
   db58e:	a913      	add	r1, sp, #76	; 0x4c
   db590:	a822      	add	r0, sp, #136	; 0x88
   db592:	f7ff fd81 	bl	db098 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   db596:	e092      	b.n	db6be <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   db598:	f7fc fa97 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   db59c:	6873      	ldr	r3, [r6, #4]
   db59e:	9305      	str	r3, [sp, #20]
   db5a0:	4629      	mov	r1, r5
   db5a2:	a818      	add	r0, sp, #96	; 0x60
   db5a4:	f7fc fa91 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db5a8:	4621      	mov	r1, r4
   db5aa:	4640      	mov	r0, r8
   db5ac:	f8d5 b004 	ldr.w	fp, [r5, #4]
   db5b0:	f7fc fa8b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   db5b4:	b104      	cbz	r4, db5b8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x2cc>
   db5b6:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   db5b8:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   db5ba:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   db5bc:	9b24      	ldr	r3, [sp, #144]	; 0x90
   db5be:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   db5c0:	9b25      	ldr	r3, [sp, #148]	; 0x94
   db5c2:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   db5c4:	9b26      	ldr	r3, [sp, #152]	; 0x98
   db5c6:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   db5c8:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   db5ca:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   db5cc:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   db5ce:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   db5d0:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   db5d2:	a918      	add	r1, sp, #96	; 0x60
   db5d4:	a813      	add	r0, sp, #76	; 0x4c
   db5d6:	f7fc f85a 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   db5da:	4602      	mov	r2, r0
   db5dc:	17c3      	asrs	r3, r0, #31
   db5de:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   db5e2:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db5e4:	f04f 0800 	mov.w	r8, #0
   db5e8:	f04f 0900 	mov.w	r9, #0
   db5ec:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   db5f0:	4590      	cmp	r8, r2
   db5f2:	eb79 0303 	sbcs.w	r3, r9, r3
   db5f6:	f280 80b4 	bge.w	db762 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x476>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db5fa:	f81b 5008 	ldrb.w	r5, [fp, r8]
   db5fe:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   db600:	9a08      	ldr	r2, [sp, #32]
   db602:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db604:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   db606:	9b05      	ldr	r3, [sp, #20]
   db608:	f813 0008 	ldrb.w	r0, [r3, r8]
   db60c:	9b06      	ldr	r3, [sp, #24]
   db60e:	4418      	add	r0, r3
   db610:	40b8      	lsls	r0, r7
   db612:	f7fc f879 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db616:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   db618:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   db61a:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   db61c:	990a      	ldr	r1, [sp, #40]	; 0x28
   db61e:	4628      	mov	r0, r5
   db620:	f7fc f872 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   db624:	4582      	cmp	sl, r0
   db626:	bfd4      	ite	le
   db628:	2000      	movle	r0, #0
   db62a:	2001      	movgt	r0, #1
   db62c:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db630:	f118 0801 	adds.w	r8, r8, #1
   db634:	f149 0900 	adc.w	r9, r9, #0
   db638:	e7d8      	b.n	db5ec <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x300>
   db63a:	6933      	ldr	r3, [r6, #16]
   db63c:	68f0      	ldr	r0, [r6, #12]
   db63e:	f1c3 0900 	rsb	r9, r3, #0
   db642:	692b      	ldr	r3, [r5, #16]
   db644:	f1c3 0800 	rsb	r8, r3, #0
   db648:	f00c fe98 	bl	e837c <__aeabi_f2d>
   db64c:	ec41 0b10 	vmov	d0, r0, r1
   db650:	a910      	add	r1, sp, #64	; 0x40
   db652:	a80f      	add	r0, sp, #60	; 0x3c
   db654:	f009 fc94 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   db658:	68e8      	ldr	r0, [r5, #12]
   db65a:	f00c fe8f 	bl	e837c <__aeabi_f2d>
   db65e:	ec41 0b10 	vmov	d0, r0, r1
   db662:	a912      	add	r1, sp, #72	; 0x48
   db664:	a811      	add	r0, sp, #68	; 0x44
   db666:	f009 fc8b 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   db66a:	2308      	movs	r3, #8
   db66c:	9322      	str	r3, [sp, #136]	; 0x88
   db66e:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   db670:	9324      	str	r3, [sp, #144]	; 0x90
   db672:	9b10      	ldr	r3, [sp, #64]	; 0x40
   db674:	9325      	str	r3, [sp, #148]	; 0x94
   db676:	9b11      	ldr	r3, [sp, #68]	; 0x44
   db678:	9327      	str	r3, [sp, #156]	; 0x9c
   db67a:	9b12      	ldr	r3, [sp, #72]	; 0x48
   db67c:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   db680:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   db684:	9328      	str	r3, [sp, #160]	; 0xa0
   db686:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   db68a:	4631      	mov	r1, r6
   db68c:	a813      	add	r0, sp, #76	; 0x4c
   db68e:	b1c7      	cbz	r7, db6c2 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x3d6>
   db690:	f7fc fa1b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db694:	4629      	mov	r1, r5
   db696:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   db698:	6876      	ldr	r6, [r6, #4]
   db69a:	f7fc fa16 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db69e:	4621      	mov	r1, r4
   db6a0:	4640      	mov	r0, r8
   db6a2:	686d      	ldr	r5, [r5, #4]
   db6a4:	f7fc fa11 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   db6a8:	b104      	cbz	r4, db6ac <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x3c0>
   db6aa:	6864      	ldr	r4, [r4, #4]
        op_params, input1_shape, input1_data, input2_shape, input2_data,       \
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
   db6ac:	9402      	str	r4, [sp, #8]
   db6ae:	e88d 0120 	stmia.w	sp, {r5, r8}
   db6b2:	ab18      	add	r3, sp, #96	; 0x60
   db6b4:	4632      	mov	r2, r6
   db6b6:	a913      	add	r1, sp, #76	; 0x4c
   db6b8:	a822      	add	r0, sp, #136	; 0x88
   db6ba:	f7ff fd82 	bl	db1c2 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_9GreaterFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   db6be:	4640      	mov	r0, r8
   db6c0:	e050      	b.n	db764 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x478>
   db6c2:	f7fc fa02 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   db6c6:	6873      	ldr	r3, [r6, #4]
   db6c8:	9305      	str	r3, [sp, #20]
   db6ca:	4629      	mov	r1, r5
   db6cc:	a818      	add	r0, sp, #96	; 0x60
   db6ce:	f7fc f9fc 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   db6d2:	4621      	mov	r1, r4
   db6d4:	4640      	mov	r0, r8
   db6d6:	f8d5 b004 	ldr.w	fp, [r5, #4]
   db6da:	f7fc f9f6 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   db6de:	b104      	cbz	r4, db6e2 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x3f6>
   db6e0:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   db6e2:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   db6e4:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   db6e6:	9b24      	ldr	r3, [sp, #144]	; 0x90
   db6e8:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   db6ea:	9b25      	ldr	r3, [sp, #148]	; 0x94
   db6ec:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   db6ee:	9b26      	ldr	r3, [sp, #152]	; 0x98
   db6f0:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   db6f2:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   db6f4:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   db6f6:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   db6f8:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   db6fa:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   db6fc:	a918      	add	r1, sp, #96	; 0x60
   db6fe:	a813      	add	r0, sp, #76	; 0x4c
   db700:	f7fb ffc5 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   db704:	4602      	mov	r2, r0
   db706:	17c3      	asrs	r3, r0, #31
   db708:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   db70c:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db70e:	f04f 0800 	mov.w	r8, #0
   db712:	f04f 0900 	mov.w	r9, #0
   db716:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   db71a:	4590      	cmp	r8, r2
   db71c:	eb79 0303 	sbcs.w	r3, r9, r3
   db720:	da1f      	bge.n	db762 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x476>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db722:	f91b 5008 	ldrsb.w	r5, [fp, r8]
   db726:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   db728:	9a08      	ldr	r2, [sp, #32]
   db72a:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db72c:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   db72e:	9b05      	ldr	r3, [sp, #20]
   db730:	f913 0008 	ldrsb.w	r0, [r3, r8]
   db734:	9b06      	ldr	r3, [sp, #24]
   db736:	4418      	add	r0, r3
   db738:	40b8      	lsls	r0, r7
   db73a:	f7fb ffe5 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db73e:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   db740:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   db742:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   db744:	990a      	ldr	r1, [sp, #40]	; 0x28
   db746:	4628      	mov	r0, r5
   db748:	f7fb ffde 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   db74c:	4582      	cmp	sl, r0
   db74e:	bfd4      	ite	le
   db750:	2000      	movle	r0, #0
   db752:	2001      	movgt	r0, #1
   db754:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   db758:	f118 0801 	adds.w	r8, r8, #1
   db75c:	f149 0900 	adc.w	r9, r9, #0
   db760:	e7d9      	b.n	db716 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x42a>
   db762:	a81d      	add	r0, sp, #116	; 0x74
   db764:	f7fb ff01 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   db768:	a818      	add	r0, sp, #96	; 0x60
   db76a:	f7fb fefe 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   db76e:	a813      	add	r0, sp, #76	; 0x4c
   db770:	f7fb fefb 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      context->ReportError(context,
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
   db774:	2000      	movs	r0, #0
   db776:	e00e      	b.n	db796 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x4aa>
                                   requires_broadcast);
      break;
    default:
      context->ReportError(context,
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
   db778:	4650      	mov	r0, sl
   db77a:	f8da 3014 	ldr.w	r3, [sl, #20]
   db77e:	4907      	ldr	r1, [pc, #28]	; (db79c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x4b0>)
   db780:	4798      	blx	r3
      return kTfLiteError;
   db782:	2001      	movs	r0, #1
   db784:	e007      	b.n	db796 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x4aa>
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, Greater, requires_broadcast);
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, Greater, requires_broadcast);
   db786:	a822      	add	r0, sp, #136	; 0x88
   db788:	f7fb feef 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   db78c:	4640      	mov	r0, r8
   db78e:	f7fb feec 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   db792:	a818      	add	r0, sp, #96	; 0x60
   db794:	e7ec      	b.n	db770 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_111GreaterEvalEP13TfLiteContextP10TfLiteNode+0x484>
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   db796:	b02b      	add	sp, #172	; 0xac
   db798:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   db79c:	000eb4b0 	.word	0x000eb4b0

000db7a0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db7a0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   db7a4:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db7a6:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db7a8:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db7aa:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db7ac:	9208      	str	r2, [sp, #32]
   db7ae:	4604      	mov	r4, r0
   db7b0:	460e      	mov	r6, r1
   db7b2:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db7b4:	dd01      	ble.n	db7ba <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   db7b6:	f009 fe9d 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   db7ba:	683b      	ldr	r3, [r7, #0]
   db7bc:	2b04      	cmp	r3, #4
   db7be:	dcfa      	bgt.n	db7b6 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   db7c0:	6813      	ldr	r3, [r2, #0]
   db7c2:	2b04      	cmp	r3, #4
   db7c4:	dcf7      	bgt.n	db7b6 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   db7c6:	2301      	movs	r3, #1
   db7c8:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   db7ca:	ad10      	add	r5, sp, #64	; 0x40
   db7cc:	a80b      	add	r0, sp, #44	; 0x2c
   db7ce:	f7fb ff10 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   db7d2:	ab18      	add	r3, sp, #96	; 0x60
   db7d4:	462a      	mov	r2, r5
   db7d6:	4639      	mov	r1, r7
   db7d8:	4630      	mov	r0, r6
   db7da:	f7fc fa1f 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   db7de:	6863      	ldr	r3, [r4, #4]
   db7e0:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   db7e2:	68a3      	ldr	r3, [r4, #8]
   db7e4:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   db7e6:	68e3      	ldr	r3, [r4, #12]
   db7e8:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   db7ea:	6923      	ldr	r3, [r4, #16]
   db7ec:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   db7ee:	6963      	ldr	r3, [r4, #20]
   db7f0:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   db7f2:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   db7f4:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   db7f8:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db7fa:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db7fc:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db7fe:	2100      	movs	r1, #0
   db800:	a80b      	add	r0, sp, #44	; 0x2c
   db802:	f7fb febd 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db806:	4284      	cmp	r4, r0
   db808:	da59      	bge.n	db8be <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11e>
   db80a:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   db80c:	af0b      	add	r7, sp, #44	; 0x2c
   db80e:	2101      	movs	r1, #1
   db810:	4638      	mov	r0, r7
   db812:	f7fb feb5 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db816:	4285      	cmp	r5, r0
   db818:	da4f      	bge.n	db8ba <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11a>
   db81a:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   db81c:	2102      	movs	r1, #2
   db81e:	4638      	mov	r0, r7
   db820:	f7fb feae 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db824:	4286      	cmp	r6, r0
   db826:	da46      	bge.n	db8b6 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x116>
   db828:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   db82c:	2103      	movs	r1, #3
   db82e:	4638      	mov	r0, r7
   db830:	f7fb fea6 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db834:	4580      	cmp	r8, r0
   db836:	da3c      	bge.n	db8b2 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x112>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db838:	f8cd 8000 	str.w	r8, [sp]
   db83c:	4633      	mov	r3, r6
   db83e:	462a      	mov	r2, r5
   db840:	4621      	mov	r1, r4
   db842:	9809      	ldr	r0, [sp, #36]	; 0x24
   db844:	f7fb ffb2 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   db848:	9b08      	ldr	r3, [sp, #32]
   db84a:	f813 9000 	ldrb.w	r9, [r3, r0]
   db84e:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   db850:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db854:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   db856:	462a      	mov	r2, r5
   db858:	4633      	mov	r3, r6
   db85a:	4621      	mov	r1, r4
   db85c:	a818      	add	r0, sp, #96	; 0x60
   db85e:	f7fb ffa5 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db862:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db864:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db866:	f813 b000 	ldrb.w	fp, [r3, r0]
   db86a:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db86c:	9903      	ldr	r1, [sp, #12]
   db86e:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db872:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db874:	f7fb ff48 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db878:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db87c:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   db87e:	9a07      	ldr	r2, [sp, #28]
   db880:	9906      	ldr	r1, [sp, #24]
   db882:	4658      	mov	r0, fp
   db884:	f7fb ff40 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   db888:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   db88c:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   db88e:	4633      	mov	r3, r6
   db890:	462a      	mov	r2, r5
   db892:	4621      	mov	r1, r4
   db894:	4638      	mov	r0, r7
   db896:	f7fb fed8 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   db89a:	45d9      	cmp	r9, fp
   db89c:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   db89e:	bfb4      	ite	lt
   db8a0:	f04f 0900 	movlt.w	r9, #0
   db8a4:	f04f 0901 	movge.w	r9, #1
   db8a8:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   db8ac:	f108 0801 	add.w	r8, r8, #1
   db8b0:	e7bc      	b.n	db82c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   db8b2:	3601      	adds	r6, #1
   db8b4:	e7b2      	b.n	db81c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   db8b6:	3501      	adds	r5, #1
   db8b8:	e7a8      	b.n	db80c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db8ba:	3401      	adds	r4, #1
   db8bc:	e79f      	b.n	db7fe <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   db8be:	a80b      	add	r0, sp, #44	; 0x2c
   db8c0:	f7fb fe53 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   db8c4:	b021      	add	sp, #132	; 0x84
   db8c6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000db8ca <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db8ca:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   db8ce:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db8d0:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db8d2:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db8d4:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   db8d6:	9208      	str	r2, [sp, #32]
   db8d8:	4604      	mov	r4, r0
   db8da:	460e      	mov	r6, r1
   db8dc:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   db8de:	dd01      	ble.n	db8e4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   db8e0:	f009 fe08 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   db8e4:	683b      	ldr	r3, [r7, #0]
   db8e6:	2b04      	cmp	r3, #4
   db8e8:	dcfa      	bgt.n	db8e0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   db8ea:	6813      	ldr	r3, [r2, #0]
   db8ec:	2b04      	cmp	r3, #4
   db8ee:	dcf7      	bgt.n	db8e0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   db8f0:	2301      	movs	r3, #1
   db8f2:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   db8f4:	ad10      	add	r5, sp, #64	; 0x40
   db8f6:	a80b      	add	r0, sp, #44	; 0x2c
   db8f8:	f7fb fe7b 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   db8fc:	ab18      	add	r3, sp, #96	; 0x60
   db8fe:	462a      	mov	r2, r5
   db900:	4639      	mov	r1, r7
   db902:	4630      	mov	r0, r6
   db904:	f7fc f98a 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   db908:	6863      	ldr	r3, [r4, #4]
   db90a:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   db90c:	68a3      	ldr	r3, [r4, #8]
   db90e:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   db910:	68e3      	ldr	r3, [r4, #12]
   db912:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   db914:	6923      	ldr	r3, [r4, #16]
   db916:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   db918:	6963      	ldr	r3, [r4, #20]
   db91a:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   db91c:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   db91e:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   db922:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db924:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db926:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db928:	2100      	movs	r1, #0
   db92a:	a80b      	add	r0, sp, #44	; 0x2c
   db92c:	f7fb fe28 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db930:	4284      	cmp	r4, r0
   db932:	da59      	bge.n	db9e8 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11e>
   db934:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   db936:	af0b      	add	r7, sp, #44	; 0x2c
   db938:	2101      	movs	r1, #1
   db93a:	4638      	mov	r0, r7
   db93c:	f7fb fe20 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db940:	4285      	cmp	r5, r0
   db942:	da4f      	bge.n	db9e4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11a>
   db944:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   db946:	2102      	movs	r1, #2
   db948:	4638      	mov	r0, r7
   db94a:	f7fb fe19 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db94e:	4286      	cmp	r6, r0
   db950:	da46      	bge.n	db9e0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x116>
   db952:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   db956:	2103      	movs	r1, #3
   db958:	4638      	mov	r0, r7
   db95a:	f7fb fe11 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   db95e:	4580      	cmp	r8, r0
   db960:	da3c      	bge.n	db9dc <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x112>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db962:	f8cd 8000 	str.w	r8, [sp]
   db966:	4633      	mov	r3, r6
   db968:	462a      	mov	r2, r5
   db96a:	4621      	mov	r1, r4
   db96c:	9809      	ldr	r0, [sp, #36]	; 0x24
   db96e:	f7fb ff1d 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   db972:	9b08      	ldr	r3, [sp, #32]
   db974:	f913 9000 	ldrsb.w	r9, [r3, r0]
   db978:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   db97a:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   db97e:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   db980:	462a      	mov	r2, r5
   db982:	4633      	mov	r3, r6
   db984:	4621      	mov	r1, r4
   db986:	a818      	add	r0, sp, #96	; 0x60
   db988:	f7fb ff10 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db98c:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db98e:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db990:	f913 b000 	ldrsb.w	fp, [r3, r0]
   db994:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db996:	9903      	ldr	r1, [sp, #12]
   db998:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db99c:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db99e:	f7fb feb3 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   db9a2:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   db9a6:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   db9a8:	9a07      	ldr	r2, [sp, #28]
   db9aa:	9906      	ldr	r1, [sp, #24]
   db9ac:	4658      	mov	r0, fp
   db9ae:	f7fb feab 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   db9b2:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   db9b6:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   db9b8:	4633      	mov	r3, r6
   db9ba:	462a      	mov	r2, r5
   db9bc:	4621      	mov	r1, r4
   db9be:	4638      	mov	r0, r7
   db9c0:	f7fb fe43 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   db9c4:	45d9      	cmp	r9, fp
   db9c6:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   db9c8:	bfb4      	ite	lt
   db9ca:	f04f 0900 	movlt.w	r9, #0
   db9ce:	f04f 0901 	movge.w	r9, #1
   db9d2:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   db9d6:	f108 0801 	add.w	r8, r8, #1
   db9da:	e7bc      	b.n	db956 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   db9dc:	3601      	adds	r6, #1
   db9de:	e7b2      	b.n	db946 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   db9e0:	3501      	adds	r5, #1
   db9e2:	e7a8      	b.n	db936 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   db9e4:	3401      	adds	r4, #1
   db9e6:	e79f      	b.n	db928 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   db9e8:	a80b      	add	r0, sp, #44	; 0x2c
   db9ea:	f7fb fdbe 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   db9ee:	b021      	add	sp, #132	; 0x84
   db9f0:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000db9f4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus GreaterEqualEval(TfLiteContext* context, TfLiteNode* node) {
   db9f4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   db9f8:	680a      	ldr	r2, [r1, #0]
   db9fa:	f8d0 9008 	ldr.w	r9, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   db9fe:	6895      	ldr	r5, [r2, #8]
   dba00:	4682      	mov	sl, r0
   dba02:	6850      	ldr	r0, [r2, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dba04:	684a      	ldr	r2, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dba06:	2338      	movs	r3, #56	; 0x38
   dba08:	fb03 f800 	mul.w	r8, r3, r0
   dba0c:	fb03 9505 	mla	r5, r3, r5, r9
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dba10:	6854      	ldr	r4, [r2, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dba12:	eb09 0608 	add.w	r6, r9, r8
   dba16:	b0ab      	sub	sp, #172	; 0xac
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dba18:	4629      	mov	r1, r5
   dba1a:	4630      	mov	r0, r6
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dba1c:	fb03 9404 	mla	r4, r3, r4, r9
   dba20:	f009 fa3a 	bl	e4e98 <_ZN6tflite14HaveSameShapesEPK12TfLiteTensorS2_>
  switch (input1->type) {
   dba24:	f819 2008 	ldrb.w	r2, [r9, r8]

TfLiteStatus GreaterEqualEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dba28:	f080 0001 	eor.w	r0, r0, #1
  switch (input1->type) {
   dba2c:	1e53      	subs	r3, r2, #1

TfLiteStatus GreaterEqualEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dba2e:	b2c7      	uxtb	r7, r0
  switch (input1->type) {
   dba30:	2b08      	cmp	r3, #8
   dba32:	f200 8225 	bhi.w	dbe80 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x48c>
   dba36:	e8df f013 	tbh	[pc, r3, lsl #1]
   dba3a:	0009      	.short	0x0009
   dba3c:	00f00057 	.word	0x00f00057
   dba40:	022300a1 	.word	0x022300a1
   dba44:	02230223 	.word	0x02230223
   dba48:	01840223 	.word	0x01840223
   dba4c:	f10d 0874 	add.w	r8, sp, #116	; 0x74
    case kTfLiteFloat32:
      TF_LITE_COMPARISON(float, GreaterEqual, requires_broadcast);
   dba50:	4631      	mov	r1, r6
   dba52:	b1cf      	cbz	r7, dba88 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x94>
   dba54:	a813      	add	r0, sp, #76	; 0x4c
   dba56:	f7fc f838 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dba5a:	4629      	mov	r1, r5
   dba5c:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dba5e:	6876      	ldr	r6, [r6, #4]
   dba60:	f7fc f833 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dba64:	b105      	cbz	r5, dba68 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x74>
   dba66:	686d      	ldr	r5, [r5, #4]
   dba68:	4621      	mov	r1, r4
   dba6a:	4640      	mov	r0, r8
   dba6c:	f7fc f82d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dba70:	b104      	cbz	r4, dba74 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x80>
   dba72:	6864      	ldr	r4, [r4, #4]
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
   dba74:	9402      	str	r4, [sp, #8]
   dba76:	e88d 0120 	stmia.w	sp, {r5, r8}
   dba7a:	ab18      	add	r3, sp, #96	; 0x60
   dba7c:	4632      	mov	r2, r6
   dba7e:	a913      	add	r1, sp, #76	; 0x4c
   dba80:	a822      	add	r0, sp, #136	; 0x88
   dba82:	f7fd ff76 	bl	d9972 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_14GreaterEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dba86:	e19e      	b.n	dbdc6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dba88:	a818      	add	r0, sp, #96	; 0x60
   dba8a:	f7fc f81e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dba8e:	4629      	mov	r1, r5
   dba90:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dba92:	6876      	ldr	r6, [r6, #4]
   dba94:	f7fc f819 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dba98:	b105      	cbz	r5, dba9c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0xa8>
   dba9a:	686d      	ldr	r5, [r5, #4]
   dba9c:	4621      	mov	r1, r4
   dba9e:	a822      	add	r0, sp, #136	; 0x88
   dbaa0:	f7fc f813 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dbaa4:	b104      	cbz	r4, dbaa8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0xb4>
   dbaa6:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dbaa8:	4641      	mov	r1, r8
   dbaaa:	aa22      	add	r2, sp, #136	; 0x88
   dbaac:	a818      	add	r0, sp, #96	; 0x60
   dbaae:	f7fb fdee 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dbab2:	3c01      	subs	r4, #1
   dbab4:	4633      	mov	r3, r6
   dbab6:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   dbab8:	2600      	movs	r6, #0
   dbaba:	2700      	movs	r7, #0
   dbabc:	4286      	cmp	r6, r0
   dbabe:	eb77 0201 	sbcs.w	r2, r7, r1
   dbac2:	f280 81e4 	bge.w	dbe8e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dbac6:	ecb3 7a01 	vldmia	r3!, {s14}
   dbaca:	ecf5 7a01 	vldmia	r5!, {s15}
   dbace:	eeb4 7ae7 	vcmpe.f32	s14, s15
   dbad2:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   dbad6:	bfac      	ite	ge
   dbad8:	2201      	movge	r2, #1
   dbada:	2200      	movlt	r2, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dbadc:	3601      	adds	r6, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dbade:	f804 2f01 	strb.w	r2, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dbae2:	f147 0700 	adc.w	r7, r7, #0
   dbae6:	e7e9      	b.n	dbabc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0xc8>
   dbae8:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, GreaterEqual, requires_broadcast);
   dbaec:	4631      	mov	r1, r6
   dbaee:	b1cf      	cbz	r7, dbb24 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x130>
   dbaf0:	a813      	add	r0, sp, #76	; 0x4c
   dbaf2:	f7fb ffea 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbaf6:	4629      	mov	r1, r5
   dbaf8:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dbafa:	6876      	ldr	r6, [r6, #4]
   dbafc:	f7fb ffe5 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbb00:	b105      	cbz	r5, dbb04 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x110>
   dbb02:	686d      	ldr	r5, [r5, #4]
   dbb04:	4621      	mov	r1, r4
   dbb06:	4640      	mov	r0, r8
   dbb08:	f7fb ffdf 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dbb0c:	b104      	cbz	r4, dbb10 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x11c>
   dbb0e:	6864      	ldr	r4, [r4, #4]
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
   dbb10:	9402      	str	r4, [sp, #8]
   dbb12:	e88d 0120 	stmia.w	sp, {r5, r8}
   dbb16:	ab18      	add	r3, sp, #96	; 0x60
   dbb18:	4632      	mov	r2, r6
   dbb1a:	a913      	add	r1, sp, #76	; 0x4c
   dbb1c:	a822      	add	r0, sp, #136	; 0x88
   dbb1e:	f7fd ff9b 	bl	d9a58 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dbb22:	e150      	b.n	dbdc6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dbb24:	a818      	add	r0, sp, #96	; 0x60
   dbb26:	f7fb ffd0 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbb2a:	4629      	mov	r1, r5
   dbb2c:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dbb2e:	6876      	ldr	r6, [r6, #4]
   dbb30:	f7fb ffcb 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbb34:	b105      	cbz	r5, dbb38 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x144>
   dbb36:	686d      	ldr	r5, [r5, #4]
   dbb38:	4621      	mov	r1, r4
   dbb3a:	a822      	add	r0, sp, #136	; 0x88
   dbb3c:	f7fb ffc5 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dbb40:	b104      	cbz	r4, dbb44 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x150>
   dbb42:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dbb44:	aa22      	add	r2, sp, #136	; 0x88
   dbb46:	4641      	mov	r1, r8
   dbb48:	a818      	add	r0, sp, #96	; 0x60
   dbb4a:	f7fb fda0 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dbb4e:	3c01      	subs	r4, #1
   dbb50:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   dbb52:	2200      	movs	r2, #0
   dbb54:	2300      	movs	r3, #0
   dbb56:	4282      	cmp	r2, r0
   dbb58:	eb73 0701 	sbcs.w	r7, r3, r1
   dbb5c:	f280 8197 	bge.w	dbe8e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dbb60:	f856 7022 	ldr.w	r7, [r6, r2, lsl #2]
   dbb64:	f855 e022 	ldr.w	lr, [r5, r2, lsl #2]
   dbb68:	4577      	cmp	r7, lr
   dbb6a:	bfb4      	ite	lt
   dbb6c:	2700      	movlt	r7, #0
   dbb6e:	2701      	movge	r7, #1
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dbb70:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dbb72:	f804 7f01 	strb.w	r7, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dbb76:	f143 0300 	adc.w	r3, r3, #0
   dbb7a:	e7ec      	b.n	dbb56 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x162>
   dbb7c:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, GreaterEqual, requires_broadcast);
   dbb80:	4631      	mov	r1, r6
   dbb82:	b1cf      	cbz	r7, dbbb8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x1c4>
   dbb84:	a813      	add	r0, sp, #76	; 0x4c
   dbb86:	f7fb ffa0 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbb8a:	4629      	mov	r1, r5
   dbb8c:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dbb8e:	6876      	ldr	r6, [r6, #4]
   dbb90:	f7fb ff9b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbb94:	b105      	cbz	r5, dbb98 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x1a4>
   dbb96:	686d      	ldr	r5, [r5, #4]
   dbb98:	4621      	mov	r1, r4
   dbb9a:	4640      	mov	r0, r8
   dbb9c:	f7fb ff95 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dbba0:	b104      	cbz	r4, dbba4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x1b0>
   dbba2:	6864      	ldr	r4, [r4, #4]
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
   dbba4:	9402      	str	r4, [sp, #8]
   dbba6:	e88d 0120 	stmia.w	sp, {r5, r8}
   dbbaa:	ab18      	add	r3, sp, #96	; 0x60
   dbbac:	4632      	mov	r2, r6
   dbbae:	a913      	add	r1, sp, #76	; 0x4c
   dbbb0:	a822      	add	r0, sp, #136	; 0x88
   dbbb2:	f7fd ffbd 	bl	d9b30 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_14GreaterEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dbbb6:	e106      	b.n	dbdc6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dbbb8:	a818      	add	r0, sp, #96	; 0x60
   dbbba:	f7fb ff86 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbbbe:	4629      	mov	r1, r5
   dbbc0:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dbbc2:	6876      	ldr	r6, [r6, #4]
   dbbc4:	f7fb ff81 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbbc8:	b105      	cbz	r5, dbbcc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x1d8>
   dbbca:	686d      	ldr	r5, [r5, #4]
   dbbcc:	4621      	mov	r1, r4
   dbbce:	a822      	add	r0, sp, #136	; 0x88
   dbbd0:	f7fb ff7b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dbbd4:	b104      	cbz	r4, dbbd8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x1e4>
   dbbd6:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dbbd8:	aa22      	add	r2, sp, #136	; 0x88
   dbbda:	4641      	mov	r1, r8
   dbbdc:	a818      	add	r0, sp, #96	; 0x60
   dbbde:	f7fb fd56 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dbbe2:	3d08      	subs	r5, #8
   dbbe4:	17c1      	asrs	r1, r0, #31
   dbbe6:	f1a6 0e08 	sub.w	lr, r6, #8
   dbbea:	3c01      	subs	r4, #1
  for (int64_t i = 0; i < flatsize; ++i) {
   dbbec:	2200      	movs	r2, #0
   dbbee:	2300      	movs	r3, #0
   dbbf0:	4282      	cmp	r2, r0
   dbbf2:	eb73 0601 	sbcs.w	r6, r3, r1
   dbbf6:	f280 814a 	bge.w	dbe8e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dbbfa:	e9fe ab02 	ldrd	sl, fp, [lr, #8]!
   dbbfe:	e9f5 6702 	ldrd	r6, r7, [r5, #8]!
   dbc02:	45b2      	cmp	sl, r6
   dbc04:	eb7b 0607 	sbcs.w	r6, fp, r7
   dbc08:	bfac      	ite	ge
   dbc0a:	2601      	movge	r6, #1
   dbc0c:	2600      	movlt	r6, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dbc0e:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dbc10:	f804 6f01 	strb.w	r6, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dbc14:	f143 0300 	adc.w	r3, r3, #0
   dbc18:	e7ea      	b.n	dbbf0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x1fc>
    }                                                                          \
  }
TF_LITE_QUANTIZE_COMPARISON(Equal);
TF_LITE_QUANTIZE_COMPARISON(NotEqual);
TF_LITE_QUANTIZE_COMPARISON(Greater);
TF_LITE_QUANTIZE_COMPARISON(GreaterEqual);
   dbc1a:	6933      	ldr	r3, [r6, #16]
   dbc1c:	68f0      	ldr	r0, [r6, #12]
   dbc1e:	f1c3 0900 	rsb	r9, r3, #0
   dbc22:	692b      	ldr	r3, [r5, #16]
   dbc24:	f1c3 0800 	rsb	r8, r3, #0
   dbc28:	f00c fba8 	bl	e837c <__aeabi_f2d>
   dbc2c:	ec41 0b10 	vmov	d0, r0, r1
   dbc30:	a910      	add	r1, sp, #64	; 0x40
   dbc32:	a80f      	add	r0, sp, #60	; 0x3c
   dbc34:	f009 f9a4 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dbc38:	68e8      	ldr	r0, [r5, #12]
   dbc3a:	f00c fb9f 	bl	e837c <__aeabi_f2d>
   dbc3e:	ec41 0b10 	vmov	d0, r0, r1
   dbc42:	a912      	add	r1, sp, #72	; 0x48
   dbc44:	a811      	add	r0, sp, #68	; 0x44
   dbc46:	f009 f99b 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dbc4a:	2308      	movs	r3, #8
   dbc4c:	9322      	str	r3, [sp, #136]	; 0x88
   dbc4e:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   dbc50:	9324      	str	r3, [sp, #144]	; 0x90
   dbc52:	9b10      	ldr	r3, [sp, #64]	; 0x40
   dbc54:	9325      	str	r3, [sp, #148]	; 0x94
   dbc56:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dbc58:	9327      	str	r3, [sp, #156]	; 0x9c
   dbc5a:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dbc5c:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   dbc60:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   dbc64:	9328      	str	r3, [sp, #160]	; 0xa0
   dbc66:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   dbc6a:	4631      	mov	r1, r6
   dbc6c:	a813      	add	r0, sp, #76	; 0x4c
   dbc6e:	b1bf      	cbz	r7, dbca0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x2ac>
   dbc70:	f7fb ff2b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbc74:	4629      	mov	r1, r5
   dbc76:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dbc78:	6876      	ldr	r6, [r6, #4]
   dbc7a:	f7fb ff26 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbc7e:	4621      	mov	r1, r4
   dbc80:	4640      	mov	r0, r8
   dbc82:	686d      	ldr	r5, [r5, #4]
   dbc84:	f7fb ff21 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dbc88:	b104      	cbz	r4, dbc8c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x298>
   dbc8a:	6864      	ldr	r4, [r4, #4]
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
   dbc8c:	9402      	str	r4, [sp, #8]
   dbc8e:	e88d 0120 	stmia.w	sp, {r5, r8}
   dbc92:	ab18      	add	r3, sp, #96	; 0x60
   dbc94:	4632      	mov	r2, r6
   dbc96:	a913      	add	r1, sp, #76	; 0x4c
   dbc98:	a822      	add	r0, sp, #136	; 0x88
   dbc9a:	f7ff fd81 	bl	db7a0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dbc9e:	e092      	b.n	dbdc6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dbca0:	f7fb ff13 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dbca4:	6873      	ldr	r3, [r6, #4]
   dbca6:	9305      	str	r3, [sp, #20]
   dbca8:	4629      	mov	r1, r5
   dbcaa:	a818      	add	r0, sp, #96	; 0x60
   dbcac:	f7fb ff0d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbcb0:	4621      	mov	r1, r4
   dbcb2:	4640      	mov	r0, r8
   dbcb4:	f8d5 b004 	ldr.w	fp, [r5, #4]
   dbcb8:	f7fb ff07 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dbcbc:	b104      	cbz	r4, dbcc0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x2cc>
   dbcbe:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dbcc0:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   dbcc2:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   dbcc4:	9b24      	ldr	r3, [sp, #144]	; 0x90
   dbcc6:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   dbcc8:	9b25      	ldr	r3, [sp, #148]	; 0x94
   dbcca:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   dbccc:	9b26      	ldr	r3, [sp, #152]	; 0x98
   dbcce:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   dbcd0:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   dbcd2:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dbcd4:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dbcd6:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   dbcd8:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dbcda:	a918      	add	r1, sp, #96	; 0x60
   dbcdc:	a813      	add	r0, sp, #76	; 0x4c
   dbcde:	f7fb fcd6 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dbce2:	4602      	mov	r2, r0
   dbce4:	17c3      	asrs	r3, r0, #31
   dbce6:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   dbcea:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dbcec:	f04f 0800 	mov.w	r8, #0
   dbcf0:	f04f 0900 	mov.w	r9, #0
   dbcf4:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   dbcf8:	4590      	cmp	r8, r2
   dbcfa:	eb79 0303 	sbcs.w	r3, r9, r3
   dbcfe:	f280 80b4 	bge.w	dbe6a <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x476>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dbd02:	f81b 5008 	ldrb.w	r5, [fp, r8]
   dbd06:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dbd08:	9a08      	ldr	r2, [sp, #32]
   dbd0a:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dbd0c:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dbd0e:	9b05      	ldr	r3, [sp, #20]
   dbd10:	f813 0008 	ldrb.w	r0, [r3, r8]
   dbd14:	9b06      	ldr	r3, [sp, #24]
   dbd16:	4418      	add	r0, r3
   dbd18:	40b8      	lsls	r0, r7
   dbd1a:	f7fb fcf5 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dbd1e:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dbd20:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   dbd22:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dbd24:	990a      	ldr	r1, [sp, #40]	; 0x28
   dbd26:	4628      	mov	r0, r5
   dbd28:	f7fb fcee 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   dbd2c:	4582      	cmp	sl, r0
   dbd2e:	bfb4      	ite	lt
   dbd30:	2000      	movlt	r0, #0
   dbd32:	2001      	movge	r0, #1
   dbd34:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dbd38:	f118 0801 	adds.w	r8, r8, #1
   dbd3c:	f149 0900 	adc.w	r9, r9, #0
   dbd40:	e7d8      	b.n	dbcf4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x300>
   dbd42:	6933      	ldr	r3, [r6, #16]
   dbd44:	68f0      	ldr	r0, [r6, #12]
   dbd46:	f1c3 0900 	rsb	r9, r3, #0
   dbd4a:	692b      	ldr	r3, [r5, #16]
   dbd4c:	f1c3 0800 	rsb	r8, r3, #0
   dbd50:	f00c fb14 	bl	e837c <__aeabi_f2d>
   dbd54:	ec41 0b10 	vmov	d0, r0, r1
   dbd58:	a910      	add	r1, sp, #64	; 0x40
   dbd5a:	a80f      	add	r0, sp, #60	; 0x3c
   dbd5c:	f009 f910 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dbd60:	68e8      	ldr	r0, [r5, #12]
   dbd62:	f00c fb0b 	bl	e837c <__aeabi_f2d>
   dbd66:	ec41 0b10 	vmov	d0, r0, r1
   dbd6a:	a912      	add	r1, sp, #72	; 0x48
   dbd6c:	a811      	add	r0, sp, #68	; 0x44
   dbd6e:	f009 f907 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dbd72:	2308      	movs	r3, #8
   dbd74:	9322      	str	r3, [sp, #136]	; 0x88
   dbd76:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   dbd78:	9324      	str	r3, [sp, #144]	; 0x90
   dbd7a:	9b10      	ldr	r3, [sp, #64]	; 0x40
   dbd7c:	9325      	str	r3, [sp, #148]	; 0x94
   dbd7e:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dbd80:	9327      	str	r3, [sp, #156]	; 0x9c
   dbd82:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dbd84:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   dbd88:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   dbd8c:	9328      	str	r3, [sp, #160]	; 0xa0
   dbd8e:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   dbd92:	4631      	mov	r1, r6
   dbd94:	a813      	add	r0, sp, #76	; 0x4c
   dbd96:	b1c7      	cbz	r7, dbdca <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x3d6>
   dbd98:	f7fb fe97 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbd9c:	4629      	mov	r1, r5
   dbd9e:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dbda0:	6876      	ldr	r6, [r6, #4]
   dbda2:	f7fb fe92 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbda6:	4621      	mov	r1, r4
   dbda8:	4640      	mov	r0, r8
   dbdaa:	686d      	ldr	r5, [r5, #4]
   dbdac:	f7fb fe8d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dbdb0:	b104      	cbz	r4, dbdb4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x3c0>
   dbdb2:	6864      	ldr	r4, [r4, #4]
        output_shape, output_data);                                            \
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
   dbdb4:	9402      	str	r4, [sp, #8]
   dbdb6:	e88d 0120 	stmia.w	sp, {r5, r8}
   dbdba:	ab18      	add	r3, sp, #96	; 0x60
   dbdbc:	4632      	mov	r2, r6
   dbdbe:	a913      	add	r1, sp, #76	; 0x4c
   dbdc0:	a822      	add	r0, sp, #136	; 0x88
   dbdc2:	f7ff fd82 	bl	db8ca <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_14GreaterEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dbdc6:	4640      	mov	r0, r8
   dbdc8:	e050      	b.n	dbe6c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x478>
   dbdca:	f7fb fe7e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dbdce:	6873      	ldr	r3, [r6, #4]
   dbdd0:	9305      	str	r3, [sp, #20]
   dbdd2:	4629      	mov	r1, r5
   dbdd4:	a818      	add	r0, sp, #96	; 0x60
   dbdd6:	f7fb fe78 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dbdda:	4621      	mov	r1, r4
   dbddc:	4640      	mov	r0, r8
   dbdde:	f8d5 b004 	ldr.w	fp, [r5, #4]
   dbde2:	f7fb fe72 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dbde6:	b104      	cbz	r4, dbdea <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x3f6>
   dbde8:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dbdea:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   dbdec:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   dbdee:	9b24      	ldr	r3, [sp, #144]	; 0x90
   dbdf0:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   dbdf2:	9b25      	ldr	r3, [sp, #148]	; 0x94
   dbdf4:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   dbdf6:	9b26      	ldr	r3, [sp, #152]	; 0x98
   dbdf8:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   dbdfa:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   dbdfc:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dbdfe:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dbe00:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   dbe02:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dbe04:	a918      	add	r1, sp, #96	; 0x60
   dbe06:	a813      	add	r0, sp, #76	; 0x4c
   dbe08:	f7fb fc41 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dbe0c:	4602      	mov	r2, r0
   dbe0e:	17c3      	asrs	r3, r0, #31
   dbe10:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   dbe14:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dbe16:	f04f 0800 	mov.w	r8, #0
   dbe1a:	f04f 0900 	mov.w	r9, #0
   dbe1e:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   dbe22:	4590      	cmp	r8, r2
   dbe24:	eb79 0303 	sbcs.w	r3, r9, r3
   dbe28:	da1f      	bge.n	dbe6a <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x476>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dbe2a:	f91b 5008 	ldrsb.w	r5, [fp, r8]
   dbe2e:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dbe30:	9a08      	ldr	r2, [sp, #32]
   dbe32:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dbe34:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dbe36:	9b05      	ldr	r3, [sp, #20]
   dbe38:	f913 0008 	ldrsb.w	r0, [r3, r8]
   dbe3c:	9b06      	ldr	r3, [sp, #24]
   dbe3e:	4418      	add	r0, r3
   dbe40:	40b8      	lsls	r0, r7
   dbe42:	f7fb fc61 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dbe46:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dbe48:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   dbe4a:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dbe4c:	990a      	ldr	r1, [sp, #40]	; 0x28
   dbe4e:	4628      	mov	r0, r5
   dbe50:	f7fb fc5a 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   dbe54:	4582      	cmp	sl, r0
   dbe56:	bfb4      	ite	lt
   dbe58:	2000      	movlt	r0, #0
   dbe5a:	2001      	movge	r0, #1
   dbe5c:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dbe60:	f118 0801 	adds.w	r8, r8, #1
   dbe64:	f149 0900 	adc.w	r9, r9, #0
   dbe68:	e7d9      	b.n	dbe1e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x42a>
   dbe6a:	a81d      	add	r0, sp, #116	; 0x74
   dbe6c:	f7fb fb7d 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dbe70:	a818      	add	r0, sp, #96	; 0x60
   dbe72:	f7fb fb7a 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dbe76:	a813      	add	r0, sp, #76	; 0x4c
   dbe78:	f7fb fb77 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      context->ReportError(context,
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
   dbe7c:	2000      	movs	r0, #0
   dbe7e:	e00e      	b.n	dbe9e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x4aa>
                                        requires_broadcast);
      break;
    default:
      context->ReportError(context,
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
   dbe80:	4650      	mov	r0, sl
   dbe82:	f8da 3014 	ldr.w	r3, [sl, #20]
   dbe86:	4907      	ldr	r1, [pc, #28]	; (dbea4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x4b0>)
   dbe88:	4798      	blx	r3
      return kTfLiteError;
   dbe8a:	2001      	movs	r0, #1
   dbe8c:	e007      	b.n	dbe9e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x4aa>
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, GreaterEqual, requires_broadcast);
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, GreaterEqual, requires_broadcast);
   dbe8e:	a822      	add	r0, sp, #136	; 0x88
   dbe90:	f7fb fb6b 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dbe94:	4640      	mov	r0, r8
   dbe96:	f7fb fb68 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dbe9a:	a818      	add	r0, sp, #96	; 0x60
   dbe9c:	e7ec      	b.n	dbe78 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_116GreaterEqualEvalEP13TfLiteContextP10TfLiteNode+0x484>
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   dbe9e:	b02b      	add	sp, #172	; 0xac
   dbea0:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   dbea4:	000eb4b0 	.word	0x000eb4b0

000dbea8 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dbea8:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dbeac:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dbeae:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dbeb0:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dbeb2:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dbeb4:	9208      	str	r2, [sp, #32]
   dbeb6:	4604      	mov	r4, r0
   dbeb8:	460e      	mov	r6, r1
   dbeba:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dbebc:	dd01      	ble.n	dbec2 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   dbebe:	f009 fb19 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   dbec2:	683b      	ldr	r3, [r7, #0]
   dbec4:	2b04      	cmp	r3, #4
   dbec6:	dcfa      	bgt.n	dbebe <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   dbec8:	6813      	ldr	r3, [r2, #0]
   dbeca:	2b04      	cmp	r3, #4
   dbecc:	dcf7      	bgt.n	dbebe <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   dbece:	2301      	movs	r3, #1
   dbed0:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   dbed2:	ad10      	add	r5, sp, #64	; 0x40
   dbed4:	a80b      	add	r0, sp, #44	; 0x2c
   dbed6:	f7fb fb8c 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   dbeda:	ab18      	add	r3, sp, #96	; 0x60
   dbedc:	462a      	mov	r2, r5
   dbede:	4639      	mov	r1, r7
   dbee0:	4630      	mov	r0, r6
   dbee2:	f7fb fe9b 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dbee6:	6863      	ldr	r3, [r4, #4]
   dbee8:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   dbeea:	68a3      	ldr	r3, [r4, #8]
   dbeec:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   dbeee:	68e3      	ldr	r3, [r4, #12]
   dbef0:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   dbef2:	6923      	ldr	r3, [r4, #16]
   dbef4:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   dbef6:	6963      	ldr	r3, [r4, #20]
   dbef8:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   dbefa:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   dbefc:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dbf00:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dbf02:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dbf04:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dbf06:	2100      	movs	r1, #0
   dbf08:	a80b      	add	r0, sp, #44	; 0x2c
   dbf0a:	f7fb fb39 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dbf0e:	4284      	cmp	r4, r0
   dbf10:	da59      	bge.n	dbfc6 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11e>
   dbf12:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dbf14:	af0b      	add	r7, sp, #44	; 0x2c
   dbf16:	2101      	movs	r1, #1
   dbf18:	4638      	mov	r0, r7
   dbf1a:	f7fb fb31 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dbf1e:	4285      	cmp	r5, r0
   dbf20:	da4f      	bge.n	dbfc2 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11a>
   dbf22:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dbf24:	2102      	movs	r1, #2
   dbf26:	4638      	mov	r0, r7
   dbf28:	f7fb fb2a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dbf2c:	4286      	cmp	r6, r0
   dbf2e:	da46      	bge.n	dbfbe <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x116>
   dbf30:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dbf34:	2103      	movs	r1, #3
   dbf36:	4638      	mov	r0, r7
   dbf38:	f7fb fb22 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dbf3c:	4580      	cmp	r8, r0
   dbf3e:	da3c      	bge.n	dbfba <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x112>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dbf40:	f8cd 8000 	str.w	r8, [sp]
   dbf44:	4633      	mov	r3, r6
   dbf46:	462a      	mov	r2, r5
   dbf48:	4621      	mov	r1, r4
   dbf4a:	9809      	ldr	r0, [sp, #36]	; 0x24
   dbf4c:	f7fb fc2e 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   dbf50:	9b08      	ldr	r3, [sp, #32]
   dbf52:	f813 9000 	ldrb.w	r9, [r3, r0]
   dbf56:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   dbf58:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dbf5c:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   dbf5e:	462a      	mov	r2, r5
   dbf60:	4633      	mov	r3, r6
   dbf62:	4621      	mov	r1, r4
   dbf64:	a818      	add	r0, sp, #96	; 0x60
   dbf66:	f7fb fc21 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dbf6a:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dbf6c:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dbf6e:	f813 b000 	ldrb.w	fp, [r3, r0]
   dbf72:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dbf74:	9903      	ldr	r1, [sp, #12]
   dbf76:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dbf7a:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dbf7c:	f7fb fbc4 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dbf80:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dbf84:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   dbf86:	9a07      	ldr	r2, [sp, #28]
   dbf88:	9906      	ldr	r1, [sp, #24]
   dbf8a:	4658      	mov	r0, fp
   dbf8c:	f7fb fbbc 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   dbf90:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   dbf94:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   dbf96:	4633      	mov	r3, r6
   dbf98:	462a      	mov	r2, r5
   dbf9a:	4621      	mov	r1, r4
   dbf9c:	4638      	mov	r0, r7
   dbf9e:	f7fb fb54 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   dbfa2:	45d9      	cmp	r9, fp
   dbfa4:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   dbfa6:	bfac      	ite	ge
   dbfa8:	f04f 0900 	movge.w	r9, #0
   dbfac:	f04f 0901 	movlt.w	r9, #1
   dbfb0:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dbfb4:	f108 0801 	add.w	r8, r8, #1
   dbfb8:	e7bc      	b.n	dbf34 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dbfba:	3601      	adds	r6, #1
   dbfbc:	e7b2      	b.n	dbf24 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dbfbe:	3501      	adds	r5, #1
   dbfc0:	e7a8      	b.n	dbf14 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dbfc2:	3401      	adds	r4, #1
   dbfc4:	e79f      	b.n	dbf06 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   dbfc6:	a80b      	add	r0, sp, #44	; 0x2c
   dbfc8:	f7fb facf 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   dbfcc:	b021      	add	sp, #132	; 0x84
   dbfce:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dbfd2 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dbfd2:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dbfd6:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dbfd8:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dbfda:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dbfdc:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dbfde:	9208      	str	r2, [sp, #32]
   dbfe0:	4604      	mov	r4, r0
   dbfe2:	460e      	mov	r6, r1
   dbfe4:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dbfe6:	dd01      	ble.n	dbfec <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   dbfe8:	f009 fa84 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   dbfec:	683b      	ldr	r3, [r7, #0]
   dbfee:	2b04      	cmp	r3, #4
   dbff0:	dcfa      	bgt.n	dbfe8 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   dbff2:	6813      	ldr	r3, [r2, #0]
   dbff4:	2b04      	cmp	r3, #4
   dbff6:	dcf7      	bgt.n	dbfe8 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   dbff8:	2301      	movs	r3, #1
   dbffa:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   dbffc:	ad10      	add	r5, sp, #64	; 0x40
   dbffe:	a80b      	add	r0, sp, #44	; 0x2c
   dc000:	f7fb faf7 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   dc004:	ab18      	add	r3, sp, #96	; 0x60
   dc006:	462a      	mov	r2, r5
   dc008:	4639      	mov	r1, r7
   dc00a:	4630      	mov	r0, r6
   dc00c:	f7fb fe06 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dc010:	6863      	ldr	r3, [r4, #4]
   dc012:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   dc014:	68a3      	ldr	r3, [r4, #8]
   dc016:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   dc018:	68e3      	ldr	r3, [r4, #12]
   dc01a:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   dc01c:	6923      	ldr	r3, [r4, #16]
   dc01e:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   dc020:	6963      	ldr	r3, [r4, #20]
   dc022:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   dc024:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   dc026:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dc02a:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dc02c:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dc02e:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dc030:	2100      	movs	r1, #0
   dc032:	a80b      	add	r0, sp, #44	; 0x2c
   dc034:	f7fb faa4 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc038:	4284      	cmp	r4, r0
   dc03a:	da59      	bge.n	dc0f0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11e>
   dc03c:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dc03e:	af0b      	add	r7, sp, #44	; 0x2c
   dc040:	2101      	movs	r1, #1
   dc042:	4638      	mov	r0, r7
   dc044:	f7fb fa9c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc048:	4285      	cmp	r5, r0
   dc04a:	da4f      	bge.n	dc0ec <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11a>
   dc04c:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dc04e:	2102      	movs	r1, #2
   dc050:	4638      	mov	r0, r7
   dc052:	f7fb fa95 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc056:	4286      	cmp	r6, r0
   dc058:	da46      	bge.n	dc0e8 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x116>
   dc05a:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dc05e:	2103      	movs	r1, #3
   dc060:	4638      	mov	r0, r7
   dc062:	f7fb fa8d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc066:	4580      	cmp	r8, r0
   dc068:	da3c      	bge.n	dc0e4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x112>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dc06a:	f8cd 8000 	str.w	r8, [sp]
   dc06e:	4633      	mov	r3, r6
   dc070:	462a      	mov	r2, r5
   dc072:	4621      	mov	r1, r4
   dc074:	9809      	ldr	r0, [sp, #36]	; 0x24
   dc076:	f7fb fb99 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   dc07a:	9b08      	ldr	r3, [sp, #32]
   dc07c:	f913 9000 	ldrsb.w	r9, [r3, r0]
   dc080:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   dc082:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dc086:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   dc088:	462a      	mov	r2, r5
   dc08a:	4633      	mov	r3, r6
   dc08c:	4621      	mov	r1, r4
   dc08e:	a818      	add	r0, sp, #96	; 0x60
   dc090:	f7fb fb8c 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc094:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc096:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc098:	f913 b000 	ldrsb.w	fp, [r3, r0]
   dc09c:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc09e:	9903      	ldr	r1, [sp, #12]
   dc0a0:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc0a4:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc0a6:	f7fb fb2f 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc0aa:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc0ae:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   dc0b0:	9a07      	ldr	r2, [sp, #28]
   dc0b2:	9906      	ldr	r1, [sp, #24]
   dc0b4:	4658      	mov	r0, fp
   dc0b6:	f7fb fb27 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   dc0ba:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   dc0be:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   dc0c0:	4633      	mov	r3, r6
   dc0c2:	462a      	mov	r2, r5
   dc0c4:	4621      	mov	r1, r4
   dc0c6:	4638      	mov	r0, r7
   dc0c8:	f7fb fabf 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   dc0cc:	45d9      	cmp	r9, fp
   dc0ce:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   dc0d0:	bfac      	ite	ge
   dc0d2:	f04f 0900 	movge.w	r9, #0
   dc0d6:	f04f 0901 	movlt.w	r9, #1
   dc0da:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dc0de:	f108 0801 	add.w	r8, r8, #1
   dc0e2:	e7bc      	b.n	dc05e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dc0e4:	3601      	adds	r6, #1
   dc0e6:	e7b2      	b.n	dc04e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dc0e8:	3501      	adds	r5, #1
   dc0ea:	e7a8      	b.n	dc03e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dc0ec:	3401      	adds	r4, #1
   dc0ee:	e79f      	b.n	dc030 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   dc0f0:	a80b      	add	r0, sp, #44	; 0x2c
   dc0f2:	f7fb fa3a 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   dc0f6:	b021      	add	sp, #132	; 0x84
   dc0f8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dc0fc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus LessEval(TfLiteContext* context, TfLiteNode* node) {
   dc0fc:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dc100:	680a      	ldr	r2, [r1, #0]
   dc102:	f8d0 9008 	ldr.w	r9, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dc106:	6895      	ldr	r5, [r2, #8]
   dc108:	4682      	mov	sl, r0
   dc10a:	6850      	ldr	r0, [r2, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dc10c:	684a      	ldr	r2, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dc10e:	2338      	movs	r3, #56	; 0x38
   dc110:	fb03 f800 	mul.w	r8, r3, r0
   dc114:	fb03 9505 	mla	r5, r3, r5, r9
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dc118:	6854      	ldr	r4, [r2, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dc11a:	eb09 0608 	add.w	r6, r9, r8
   dc11e:	b0ab      	sub	sp, #172	; 0xac
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dc120:	4629      	mov	r1, r5
   dc122:	4630      	mov	r0, r6
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dc124:	fb03 9404 	mla	r4, r3, r4, r9
   dc128:	f008 feb6 	bl	e4e98 <_ZN6tflite14HaveSameShapesEPK12TfLiteTensorS2_>
  switch (input1->type) {
   dc12c:	f819 2008 	ldrb.w	r2, [r9, r8]

TfLiteStatus LessEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dc130:	f080 0001 	eor.w	r0, r0, #1
  switch (input1->type) {
   dc134:	1e53      	subs	r3, r2, #1

TfLiteStatus LessEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dc136:	b2c7      	uxtb	r7, r0
  switch (input1->type) {
   dc138:	2b08      	cmp	r3, #8
   dc13a:	f200 8225 	bhi.w	dc588 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x48c>
   dc13e:	e8df f013 	tbh	[pc, r3, lsl #1]
   dc142:	0009      	.short	0x0009
   dc144:	00f00057 	.word	0x00f00057
   dc148:	022300a1 	.word	0x022300a1
   dc14c:	02230223 	.word	0x02230223
   dc150:	01840223 	.word	0x01840223
   dc154:	f10d 0874 	add.w	r8, sp, #116	; 0x74
    case kTfLiteFloat32:
      TF_LITE_COMPARISON(float, Less, requires_broadcast);
   dc158:	4631      	mov	r1, r6
   dc15a:	b1cf      	cbz	r7, dc190 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x94>
   dc15c:	a813      	add	r0, sp, #76	; 0x4c
   dc15e:	f7fb fcb4 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc162:	4629      	mov	r1, r5
   dc164:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc166:	6876      	ldr	r6, [r6, #4]
   dc168:	f7fb fcaf 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc16c:	b105      	cbz	r5, dc170 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x74>
   dc16e:	686d      	ldr	r5, [r5, #4]
   dc170:	4621      	mov	r1, r4
   dc172:	4640      	mov	r0, r8
   dc174:	f7fb fca9 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc178:	b104      	cbz	r4, dc17c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x80>
   dc17a:	6864      	ldr	r4, [r4, #4]
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
TFLITE_COMPARISON_OP(Less);
   dc17c:	9402      	str	r4, [sp, #8]
   dc17e:	e88d 0120 	stmia.w	sp, {r5, r8}
   dc182:	ab18      	add	r3, sp, #96	; 0x60
   dc184:	4632      	mov	r2, r6
   dc186:	a913      	add	r1, sp, #76	; 0x4c
   dc188:	a822      	add	r0, sp, #136	; 0x88
   dc18a:	f7fd fd43 	bl	d9c14 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_6LessFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dc18e:	e19e      	b.n	dc4ce <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dc190:	a818      	add	r0, sp, #96	; 0x60
   dc192:	f7fb fc9a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc196:	4629      	mov	r1, r5
   dc198:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc19a:	6876      	ldr	r6, [r6, #4]
   dc19c:	f7fb fc95 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc1a0:	b105      	cbz	r5, dc1a4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0xa8>
   dc1a2:	686d      	ldr	r5, [r5, #4]
   dc1a4:	4621      	mov	r1, r4
   dc1a6:	a822      	add	r0, sp, #136	; 0x88
   dc1a8:	f7fb fc8f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc1ac:	b104      	cbz	r4, dc1b0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0xb4>
   dc1ae:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dc1b0:	4641      	mov	r1, r8
   dc1b2:	aa22      	add	r2, sp, #136	; 0x88
   dc1b4:	a818      	add	r0, sp, #96	; 0x60
   dc1b6:	f7fb fa6a 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dc1ba:	3c01      	subs	r4, #1
   dc1bc:	4633      	mov	r3, r6
   dc1be:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   dc1c0:	2600      	movs	r6, #0
   dc1c2:	2700      	movs	r7, #0
   dc1c4:	4286      	cmp	r6, r0
   dc1c6:	eb77 0201 	sbcs.w	r2, r7, r1
   dc1ca:	f280 81e4 	bge.w	dc596 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dc1ce:	ecb3 7a01 	vldmia	r3!, {s14}
   dc1d2:	ecf5 7a01 	vldmia	r5!, {s15}
   dc1d6:	eeb4 7ae7 	vcmpe.f32	s14, s15
   dc1da:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   dc1de:	bf4c      	ite	mi
   dc1e0:	2201      	movmi	r2, #1
   dc1e2:	2200      	movpl	r2, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc1e4:	3601      	adds	r6, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dc1e6:	f804 2f01 	strb.w	r2, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc1ea:	f147 0700 	adc.w	r7, r7, #0
   dc1ee:	e7e9      	b.n	dc1c4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0xc8>
   dc1f0:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, Less, requires_broadcast);
   dc1f4:	4631      	mov	r1, r6
   dc1f6:	b1cf      	cbz	r7, dc22c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x130>
   dc1f8:	a813      	add	r0, sp, #76	; 0x4c
   dc1fa:	f7fb fc66 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc1fe:	4629      	mov	r1, r5
   dc200:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc202:	6876      	ldr	r6, [r6, #4]
   dc204:	f7fb fc61 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc208:	b105      	cbz	r5, dc20c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x110>
   dc20a:	686d      	ldr	r5, [r5, #4]
   dc20c:	4621      	mov	r1, r4
   dc20e:	4640      	mov	r0, r8
   dc210:	f7fb fc5b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc214:	b104      	cbz	r4, dc218 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x11c>
   dc216:	6864      	ldr	r4, [r4, #4]
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
TFLITE_COMPARISON_OP(Less);
   dc218:	9402      	str	r4, [sp, #8]
   dc21a:	e88d 0120 	stmia.w	sp, {r5, r8}
   dc21e:	ab18      	add	r3, sp, #96	; 0x60
   dc220:	4632      	mov	r2, r6
   dc222:	a913      	add	r1, sp, #76	; 0x4c
   dc224:	a822      	add	r0, sp, #136	; 0x88
   dc226:	f7fd fd68 	bl	d9cfa <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dc22a:	e150      	b.n	dc4ce <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dc22c:	a818      	add	r0, sp, #96	; 0x60
   dc22e:	f7fb fc4c 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc232:	4629      	mov	r1, r5
   dc234:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc236:	6876      	ldr	r6, [r6, #4]
   dc238:	f7fb fc47 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc23c:	b105      	cbz	r5, dc240 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x144>
   dc23e:	686d      	ldr	r5, [r5, #4]
   dc240:	4621      	mov	r1, r4
   dc242:	a822      	add	r0, sp, #136	; 0x88
   dc244:	f7fb fc41 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc248:	b104      	cbz	r4, dc24c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x150>
   dc24a:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dc24c:	aa22      	add	r2, sp, #136	; 0x88
   dc24e:	4641      	mov	r1, r8
   dc250:	a818      	add	r0, sp, #96	; 0x60
   dc252:	f7fb fa1c 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dc256:	3c01      	subs	r4, #1
   dc258:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   dc25a:	2200      	movs	r2, #0
   dc25c:	2300      	movs	r3, #0
   dc25e:	4282      	cmp	r2, r0
   dc260:	eb73 0701 	sbcs.w	r7, r3, r1
   dc264:	f280 8197 	bge.w	dc596 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dc268:	f856 7022 	ldr.w	r7, [r6, r2, lsl #2]
   dc26c:	f855 e022 	ldr.w	lr, [r5, r2, lsl #2]
   dc270:	4577      	cmp	r7, lr
   dc272:	bfac      	ite	ge
   dc274:	2700      	movge	r7, #0
   dc276:	2701      	movlt	r7, #1
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc278:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dc27a:	f804 7f01 	strb.w	r7, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc27e:	f143 0300 	adc.w	r3, r3, #0
   dc282:	e7ec      	b.n	dc25e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x162>
   dc284:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, Less, requires_broadcast);
   dc288:	4631      	mov	r1, r6
   dc28a:	b1cf      	cbz	r7, dc2c0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x1c4>
   dc28c:	a813      	add	r0, sp, #76	; 0x4c
   dc28e:	f7fb fc1c 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc292:	4629      	mov	r1, r5
   dc294:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc296:	6876      	ldr	r6, [r6, #4]
   dc298:	f7fb fc17 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc29c:	b105      	cbz	r5, dc2a0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x1a4>
   dc29e:	686d      	ldr	r5, [r5, #4]
   dc2a0:	4621      	mov	r1, r4
   dc2a2:	4640      	mov	r0, r8
   dc2a4:	f7fb fc11 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc2a8:	b104      	cbz	r4, dc2ac <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x1b0>
   dc2aa:	6864      	ldr	r4, [r4, #4]
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
TFLITE_COMPARISON_OP(Less);
   dc2ac:	9402      	str	r4, [sp, #8]
   dc2ae:	e88d 0120 	stmia.w	sp, {r5, r8}
   dc2b2:	ab18      	add	r3, sp, #96	; 0x60
   dc2b4:	4632      	mov	r2, r6
   dc2b6:	a913      	add	r1, sp, #76	; 0x4c
   dc2b8:	a822      	add	r0, sp, #136	; 0x88
   dc2ba:	f7fd fd8a 	bl	d9dd2 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_6LessFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dc2be:	e106      	b.n	dc4ce <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dc2c0:	a818      	add	r0, sp, #96	; 0x60
   dc2c2:	f7fb fc02 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc2c6:	4629      	mov	r1, r5
   dc2c8:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc2ca:	6876      	ldr	r6, [r6, #4]
   dc2cc:	f7fb fbfd 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc2d0:	b105      	cbz	r5, dc2d4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x1d8>
   dc2d2:	686d      	ldr	r5, [r5, #4]
   dc2d4:	4621      	mov	r1, r4
   dc2d6:	a822      	add	r0, sp, #136	; 0x88
   dc2d8:	f7fb fbf7 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc2dc:	b104      	cbz	r4, dc2e0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x1e4>
   dc2de:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dc2e0:	aa22      	add	r2, sp, #136	; 0x88
   dc2e2:	4641      	mov	r1, r8
   dc2e4:	a818      	add	r0, sp, #96	; 0x60
   dc2e6:	f7fb f9d2 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dc2ea:	3d08      	subs	r5, #8
   dc2ec:	17c1      	asrs	r1, r0, #31
   dc2ee:	f1a6 0e08 	sub.w	lr, r6, #8
   dc2f2:	3c01      	subs	r4, #1
  for (int64_t i = 0; i < flatsize; ++i) {
   dc2f4:	2200      	movs	r2, #0
   dc2f6:	2300      	movs	r3, #0
   dc2f8:	4282      	cmp	r2, r0
   dc2fa:	eb73 0601 	sbcs.w	r6, r3, r1
   dc2fe:	f280 814a 	bge.w	dc596 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dc302:	e9fe ab02 	ldrd	sl, fp, [lr, #8]!
   dc306:	e9f5 6702 	ldrd	r6, r7, [r5, #8]!
   dc30a:	45b2      	cmp	sl, r6
   dc30c:	eb7b 0607 	sbcs.w	r6, fp, r7
   dc310:	bfb4      	ite	lt
   dc312:	2601      	movlt	r6, #1
   dc314:	2600      	movge	r6, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc316:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dc318:	f804 6f01 	strb.w	r6, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc31c:	f143 0300 	adc.w	r3, r3, #0
   dc320:	e7ea      	b.n	dc2f8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x1fc>
  }
TF_LITE_QUANTIZE_COMPARISON(Equal);
TF_LITE_QUANTIZE_COMPARISON(NotEqual);
TF_LITE_QUANTIZE_COMPARISON(Greater);
TF_LITE_QUANTIZE_COMPARISON(GreaterEqual);
TF_LITE_QUANTIZE_COMPARISON(Less);
   dc322:	6933      	ldr	r3, [r6, #16]
   dc324:	68f0      	ldr	r0, [r6, #12]
   dc326:	f1c3 0900 	rsb	r9, r3, #0
   dc32a:	692b      	ldr	r3, [r5, #16]
   dc32c:	f1c3 0800 	rsb	r8, r3, #0
   dc330:	f00c f824 	bl	e837c <__aeabi_f2d>
   dc334:	ec41 0b10 	vmov	d0, r0, r1
   dc338:	a910      	add	r1, sp, #64	; 0x40
   dc33a:	a80f      	add	r0, sp, #60	; 0x3c
   dc33c:	f008 fe20 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dc340:	68e8      	ldr	r0, [r5, #12]
   dc342:	f00c f81b 	bl	e837c <__aeabi_f2d>
   dc346:	ec41 0b10 	vmov	d0, r0, r1
   dc34a:	a912      	add	r1, sp, #72	; 0x48
   dc34c:	a811      	add	r0, sp, #68	; 0x44
   dc34e:	f008 fe17 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dc352:	2308      	movs	r3, #8
   dc354:	9322      	str	r3, [sp, #136]	; 0x88
   dc356:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   dc358:	9324      	str	r3, [sp, #144]	; 0x90
   dc35a:	9b10      	ldr	r3, [sp, #64]	; 0x40
   dc35c:	9325      	str	r3, [sp, #148]	; 0x94
   dc35e:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dc360:	9327      	str	r3, [sp, #156]	; 0x9c
   dc362:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dc364:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   dc368:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   dc36c:	9328      	str	r3, [sp, #160]	; 0xa0
   dc36e:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   dc372:	4631      	mov	r1, r6
   dc374:	a813      	add	r0, sp, #76	; 0x4c
   dc376:	b1bf      	cbz	r7, dc3a8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x2ac>
   dc378:	f7fb fba7 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc37c:	4629      	mov	r1, r5
   dc37e:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc380:	6876      	ldr	r6, [r6, #4]
   dc382:	f7fb fba2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc386:	4621      	mov	r1, r4
   dc388:	4640      	mov	r0, r8
   dc38a:	686d      	ldr	r5, [r5, #4]
   dc38c:	f7fb fb9d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc390:	b104      	cbz	r4, dc394 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x298>
   dc392:	6864      	ldr	r4, [r4, #4]
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
TFLITE_COMPARISON_OP(Less);
   dc394:	9402      	str	r4, [sp, #8]
   dc396:	e88d 0120 	stmia.w	sp, {r5, r8}
   dc39a:	ab18      	add	r3, sp, #96	; 0x60
   dc39c:	4632      	mov	r2, r6
   dc39e:	a913      	add	r1, sp, #76	; 0x4c
   dc3a0:	a822      	add	r0, sp, #136	; 0x88
   dc3a2:	f7ff fd81 	bl	dbea8 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dc3a6:	e092      	b.n	dc4ce <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dc3a8:	f7fb fb8f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc3ac:	6873      	ldr	r3, [r6, #4]
   dc3ae:	9305      	str	r3, [sp, #20]
   dc3b0:	4629      	mov	r1, r5
   dc3b2:	a818      	add	r0, sp, #96	; 0x60
   dc3b4:	f7fb fb89 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc3b8:	4621      	mov	r1, r4
   dc3ba:	4640      	mov	r0, r8
   dc3bc:	f8d5 b004 	ldr.w	fp, [r5, #4]
   dc3c0:	f7fb fb83 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc3c4:	b104      	cbz	r4, dc3c8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x2cc>
   dc3c6:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dc3c8:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   dc3ca:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   dc3cc:	9b24      	ldr	r3, [sp, #144]	; 0x90
   dc3ce:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   dc3d0:	9b25      	ldr	r3, [sp, #148]	; 0x94
   dc3d2:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   dc3d4:	9b26      	ldr	r3, [sp, #152]	; 0x98
   dc3d6:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   dc3d8:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   dc3da:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dc3dc:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dc3de:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   dc3e0:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dc3e2:	a918      	add	r1, sp, #96	; 0x60
   dc3e4:	a813      	add	r0, sp, #76	; 0x4c
   dc3e6:	f7fb f952 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dc3ea:	4602      	mov	r2, r0
   dc3ec:	17c3      	asrs	r3, r0, #31
   dc3ee:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   dc3f2:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc3f4:	f04f 0800 	mov.w	r8, #0
   dc3f8:	f04f 0900 	mov.w	r9, #0
   dc3fc:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   dc400:	4590      	cmp	r8, r2
   dc402:	eb79 0303 	sbcs.w	r3, r9, r3
   dc406:	f280 80b4 	bge.w	dc572 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x476>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc40a:	f81b 5008 	ldrb.w	r5, [fp, r8]
   dc40e:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dc410:	9a08      	ldr	r2, [sp, #32]
   dc412:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc414:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dc416:	9b05      	ldr	r3, [sp, #20]
   dc418:	f813 0008 	ldrb.w	r0, [r3, r8]
   dc41c:	9b06      	ldr	r3, [sp, #24]
   dc41e:	4418      	add	r0, r3
   dc420:	40b8      	lsls	r0, r7
   dc422:	f7fb f971 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc426:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dc428:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   dc42a:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dc42c:	990a      	ldr	r1, [sp, #40]	; 0x28
   dc42e:	4628      	mov	r0, r5
   dc430:	f7fb f96a 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   dc434:	4582      	cmp	sl, r0
   dc436:	bfac      	ite	ge
   dc438:	2000      	movge	r0, #0
   dc43a:	2001      	movlt	r0, #1
   dc43c:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc440:	f118 0801 	adds.w	r8, r8, #1
   dc444:	f149 0900 	adc.w	r9, r9, #0
   dc448:	e7d8      	b.n	dc3fc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x300>
   dc44a:	6933      	ldr	r3, [r6, #16]
   dc44c:	68f0      	ldr	r0, [r6, #12]
   dc44e:	f1c3 0900 	rsb	r9, r3, #0
   dc452:	692b      	ldr	r3, [r5, #16]
   dc454:	f1c3 0800 	rsb	r8, r3, #0
   dc458:	f00b ff90 	bl	e837c <__aeabi_f2d>
   dc45c:	ec41 0b10 	vmov	d0, r0, r1
   dc460:	a910      	add	r1, sp, #64	; 0x40
   dc462:	a80f      	add	r0, sp, #60	; 0x3c
   dc464:	f008 fd8c 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dc468:	68e8      	ldr	r0, [r5, #12]
   dc46a:	f00b ff87 	bl	e837c <__aeabi_f2d>
   dc46e:	ec41 0b10 	vmov	d0, r0, r1
   dc472:	a912      	add	r1, sp, #72	; 0x48
   dc474:	a811      	add	r0, sp, #68	; 0x44
   dc476:	f008 fd83 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dc47a:	2308      	movs	r3, #8
   dc47c:	9322      	str	r3, [sp, #136]	; 0x88
   dc47e:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   dc480:	9324      	str	r3, [sp, #144]	; 0x90
   dc482:	9b10      	ldr	r3, [sp, #64]	; 0x40
   dc484:	9325      	str	r3, [sp, #148]	; 0x94
   dc486:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dc488:	9327      	str	r3, [sp, #156]	; 0x9c
   dc48a:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dc48c:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   dc490:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   dc494:	9328      	str	r3, [sp, #160]	; 0xa0
   dc496:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   dc49a:	4631      	mov	r1, r6
   dc49c:	a813      	add	r0, sp, #76	; 0x4c
   dc49e:	b1c7      	cbz	r7, dc4d2 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x3d6>
   dc4a0:	f7fb fb13 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc4a4:	4629      	mov	r1, r5
   dc4a6:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc4a8:	6876      	ldr	r6, [r6, #4]
   dc4aa:	f7fb fb0e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc4ae:	4621      	mov	r1, r4
   dc4b0:	4640      	mov	r0, r8
   dc4b2:	686d      	ldr	r5, [r5, #4]
   dc4b4:	f7fb fb09 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc4b8:	b104      	cbz	r4, dc4bc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x3c0>
   dc4ba:	6864      	ldr	r4, [r4, #4]
  }
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
TFLITE_COMPARISON_OP(Less);
   dc4bc:	9402      	str	r4, [sp, #8]
   dc4be:	e88d 0120 	stmia.w	sp, {r5, r8}
   dc4c2:	ab18      	add	r3, sp, #96	; 0x60
   dc4c4:	4632      	mov	r2, r6
   dc4c6:	a913      	add	r1, sp, #76	; 0x4c
   dc4c8:	a822      	add	r0, sp, #136	; 0x88
   dc4ca:	f7ff fd82 	bl	dbfd2 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_6LessFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dc4ce:	4640      	mov	r0, r8
   dc4d0:	e050      	b.n	dc574 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x478>
   dc4d2:	f7fb fafa 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc4d6:	6873      	ldr	r3, [r6, #4]
   dc4d8:	9305      	str	r3, [sp, #20]
   dc4da:	4629      	mov	r1, r5
   dc4dc:	a818      	add	r0, sp, #96	; 0x60
   dc4de:	f7fb faf4 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc4e2:	4621      	mov	r1, r4
   dc4e4:	4640      	mov	r0, r8
   dc4e6:	f8d5 b004 	ldr.w	fp, [r5, #4]
   dc4ea:	f7fb faee 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc4ee:	b104      	cbz	r4, dc4f2 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x3f6>
   dc4f0:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dc4f2:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   dc4f4:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   dc4f6:	9b24      	ldr	r3, [sp, #144]	; 0x90
   dc4f8:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   dc4fa:	9b25      	ldr	r3, [sp, #148]	; 0x94
   dc4fc:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   dc4fe:	9b26      	ldr	r3, [sp, #152]	; 0x98
   dc500:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   dc502:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   dc504:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dc506:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dc508:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   dc50a:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dc50c:	a918      	add	r1, sp, #96	; 0x60
   dc50e:	a813      	add	r0, sp, #76	; 0x4c
   dc510:	f7fb f8bd 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dc514:	4602      	mov	r2, r0
   dc516:	17c3      	asrs	r3, r0, #31
   dc518:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   dc51c:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc51e:	f04f 0800 	mov.w	r8, #0
   dc522:	f04f 0900 	mov.w	r9, #0
   dc526:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   dc52a:	4590      	cmp	r8, r2
   dc52c:	eb79 0303 	sbcs.w	r3, r9, r3
   dc530:	da1f      	bge.n	dc572 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x476>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc532:	f91b 5008 	ldrsb.w	r5, [fp, r8]
   dc536:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dc538:	9a08      	ldr	r2, [sp, #32]
   dc53a:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc53c:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dc53e:	9b05      	ldr	r3, [sp, #20]
   dc540:	f913 0008 	ldrsb.w	r0, [r3, r8]
   dc544:	9b06      	ldr	r3, [sp, #24]
   dc546:	4418      	add	r0, r3
   dc548:	40b8      	lsls	r0, r7
   dc54a:	f7fb f8dd 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc54e:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dc550:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   dc552:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dc554:	990a      	ldr	r1, [sp, #40]	; 0x28
   dc556:	4628      	mov	r0, r5
   dc558:	f7fb f8d6 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   dc55c:	4582      	cmp	sl, r0
   dc55e:	bfac      	ite	ge
   dc560:	2000      	movge	r0, #0
   dc562:	2001      	movlt	r0, #1
   dc564:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc568:	f118 0801 	adds.w	r8, r8, #1
   dc56c:	f149 0900 	adc.w	r9, r9, #0
   dc570:	e7d9      	b.n	dc526 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x42a>
   dc572:	a81d      	add	r0, sp, #116	; 0x74
   dc574:	f7fa fff9 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dc578:	a818      	add	r0, sp, #96	; 0x60
   dc57a:	f7fa fff6 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dc57e:	a813      	add	r0, sp, #76	; 0x4c
   dc580:	f7fa fff3 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      context->ReportError(context,
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
   dc584:	2000      	movs	r0, #0
   dc586:	e00e      	b.n	dc5a6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x4aa>
                                requires_broadcast);
      break;
    default:
      context->ReportError(context,
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
   dc588:	4650      	mov	r0, sl
   dc58a:	f8da 3014 	ldr.w	r3, [sl, #20]
   dc58e:	4907      	ldr	r1, [pc, #28]	; (dc5ac <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x4b0>)
   dc590:	4798      	blx	r3
      return kTfLiteError;
   dc592:	2001      	movs	r0, #1
   dc594:	e007      	b.n	dc5a6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x4aa>
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, Less, requires_broadcast);
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, Less, requires_broadcast);
   dc596:	a822      	add	r0, sp, #136	; 0x88
   dc598:	f7fa ffe7 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dc59c:	4640      	mov	r0, r8
   dc59e:	f7fa ffe4 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dc5a2:	a818      	add	r0, sp, #96	; 0x60
   dc5a4:	e7ec      	b.n	dc580 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_18LessEvalEP13TfLiteContextP10TfLiteNode+0x484>
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   dc5a6:	b02b      	add	sp, #172	; 0xac
   dc5a8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   dc5ac:	000eb4b0 	.word	0x000eb4b0

000dc5b0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dc5b0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dc5b4:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dc5b6:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dc5b8:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dc5ba:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dc5bc:	9208      	str	r2, [sp, #32]
   dc5be:	4604      	mov	r4, r0
   dc5c0:	460e      	mov	r6, r1
   dc5c2:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dc5c4:	dd01      	ble.n	dc5ca <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   dc5c6:	f008 ff95 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   dc5ca:	683b      	ldr	r3, [r7, #0]
   dc5cc:	2b04      	cmp	r3, #4
   dc5ce:	dcfa      	bgt.n	dc5c6 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   dc5d0:	6813      	ldr	r3, [r2, #0]
   dc5d2:	2b04      	cmp	r3, #4
   dc5d4:	dcf7      	bgt.n	dc5c6 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   dc5d6:	2301      	movs	r3, #1
   dc5d8:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   dc5da:	ad10      	add	r5, sp, #64	; 0x40
   dc5dc:	a80b      	add	r0, sp, #44	; 0x2c
   dc5de:	f7fb f808 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   dc5e2:	ab18      	add	r3, sp, #96	; 0x60
   dc5e4:	462a      	mov	r2, r5
   dc5e6:	4639      	mov	r1, r7
   dc5e8:	4630      	mov	r0, r6
   dc5ea:	f7fb fb17 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dc5ee:	6863      	ldr	r3, [r4, #4]
   dc5f0:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   dc5f2:	68a3      	ldr	r3, [r4, #8]
   dc5f4:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   dc5f6:	68e3      	ldr	r3, [r4, #12]
   dc5f8:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   dc5fa:	6923      	ldr	r3, [r4, #16]
   dc5fc:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   dc5fe:	6963      	ldr	r3, [r4, #20]
   dc600:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   dc602:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   dc604:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dc608:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dc60a:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dc60c:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dc60e:	2100      	movs	r1, #0
   dc610:	a80b      	add	r0, sp, #44	; 0x2c
   dc612:	f7fa ffb5 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc616:	4284      	cmp	r4, r0
   dc618:	da59      	bge.n	dc6ce <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11e>
   dc61a:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dc61c:	af0b      	add	r7, sp, #44	; 0x2c
   dc61e:	2101      	movs	r1, #1
   dc620:	4638      	mov	r0, r7
   dc622:	f7fa ffad 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc626:	4285      	cmp	r5, r0
   dc628:	da4f      	bge.n	dc6ca <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11a>
   dc62a:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dc62c:	2102      	movs	r1, #2
   dc62e:	4638      	mov	r0, r7
   dc630:	f7fa ffa6 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc634:	4286      	cmp	r6, r0
   dc636:	da46      	bge.n	dc6c6 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x116>
   dc638:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dc63c:	2103      	movs	r1, #3
   dc63e:	4638      	mov	r0, r7
   dc640:	f7fa ff9e 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc644:	4580      	cmp	r8, r0
   dc646:	da3c      	bge.n	dc6c2 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x112>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dc648:	f8cd 8000 	str.w	r8, [sp]
   dc64c:	4633      	mov	r3, r6
   dc64e:	462a      	mov	r2, r5
   dc650:	4621      	mov	r1, r4
   dc652:	9809      	ldr	r0, [sp, #36]	; 0x24
   dc654:	f7fb f8aa 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   dc658:	9b08      	ldr	r3, [sp, #32]
   dc65a:	f813 9000 	ldrb.w	r9, [r3, r0]
   dc65e:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   dc660:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dc664:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   dc666:	462a      	mov	r2, r5
   dc668:	4633      	mov	r3, r6
   dc66a:	4621      	mov	r1, r4
   dc66c:	a818      	add	r0, sp, #96	; 0x60
   dc66e:	f7fb f89d 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc672:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc674:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc676:	f813 b000 	ldrb.w	fp, [r3, r0]
   dc67a:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc67c:	9903      	ldr	r1, [sp, #12]
   dc67e:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc682:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc684:	f7fb f840 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc688:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc68c:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   dc68e:	9a07      	ldr	r2, [sp, #28]
   dc690:	9906      	ldr	r1, [sp, #24]
   dc692:	4658      	mov	r0, fp
   dc694:	f7fb f838 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   dc698:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   dc69c:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   dc69e:	4633      	mov	r3, r6
   dc6a0:	462a      	mov	r2, r5
   dc6a2:	4621      	mov	r1, r4
   dc6a4:	4638      	mov	r0, r7
   dc6a6:	f7fa ffd0 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   dc6aa:	45d9      	cmp	r9, fp
   dc6ac:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   dc6ae:	bfcc      	ite	gt
   dc6b0:	f04f 0900 	movgt.w	r9, #0
   dc6b4:	f04f 0901 	movle.w	r9, #1
   dc6b8:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dc6bc:	f108 0801 	add.w	r8, r8, #1
   dc6c0:	e7bc      	b.n	dc63c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dc6c2:	3601      	adds	r6, #1
   dc6c4:	e7b2      	b.n	dc62c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dc6c6:	3501      	adds	r5, #1
   dc6c8:	e7a8      	b.n	dc61c <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dc6ca:	3401      	adds	r4, #1
   dc6cc:	e79f      	b.n	dc60e <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   dc6ce:	a80b      	add	r0, sp, #44	; 0x2c
   dc6d0:	f7fa ff4b 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   dc6d4:	b021      	add	sp, #132	; 0x84
   dc6d6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dc6da <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>:
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dc6da:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dc6de:	461f      	mov	r7, r3
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dc6e0:	680b      	ldr	r3, [r1, #0]
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dc6e2:	b0a1      	sub	sp, #132	; 0x84
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dc6e4:	2b04      	cmp	r3, #4
                                          input2_shape, input2_data,
                                          output_shape, output_data);
}

template <typename T, ComparisonFn<int32> F>
inline void BroadcastComparison4DSlowWithScaling(
   dc6e6:	9208      	str	r2, [sp, #32]
   dc6e8:	4604      	mov	r4, r0
   dc6ea:	460e      	mov	r6, r1
   dc6ec:	9a2b      	ldr	r2, [sp, #172]	; 0xac
    const ComparisonParams& op_params,
    const RuntimeShape& unextended_input1_shape, const T* input1_data,
    const RuntimeShape& unextended_input2_shape, const T* input2_data,
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dc6ee:	dd01      	ble.n	dc6f4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x1a>
   dc6f0:	f008 ff00 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   dc6f4:	683b      	ldr	r3, [r7, #0]
   dc6f6:	2b04      	cmp	r3, #4
   dc6f8:	dcfa      	bgt.n	dc6f0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   dc6fa:	6813      	ldr	r3, [r2, #0]
   dc6fc:	2b04      	cmp	r3, #4
   dc6fe:	dcf7      	bgt.n	dc6f0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x16>
   dc700:	2301      	movs	r3, #1
   dc702:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   dc704:	ad10      	add	r5, sp, #64	; 0x40
   dc706:	a80b      	add	r0, sp, #44	; 0x2c
   dc708:	f7fa ff73 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   dc70c:	ab18      	add	r3, sp, #96	; 0x60
   dc70e:	462a      	mov	r2, r5
   dc710:	4639      	mov	r1, r7
   dc712:	4630      	mov	r0, r6
   dc714:	f7fb fa82 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dc718:	6863      	ldr	r3, [r4, #4]
   dc71a:	9302      	str	r3, [sp, #8]
  int32 input1_multiplier = op_params.input1_multiplier;
   dc71c:	68a3      	ldr	r3, [r4, #8]
   dc71e:	9303      	str	r3, [sp, #12]
  int input1_shift = op_params.input1_shift;
   dc720:	68e3      	ldr	r3, [r4, #12]
   dc722:	9304      	str	r3, [sp, #16]
  int32 input2_offset = op_params.input2_offset;
   dc724:	6923      	ldr	r3, [r4, #16]
   dc726:	9305      	str	r3, [sp, #20]
  int32 input2_multiplier = op_params.input2_multiplier;
   dc728:	6963      	ldr	r3, [r4, #20]
   dc72a:	9306      	str	r3, [sp, #24]
  int input2_shift = op_params.input2_shift;
   dc72c:	69a3      	ldr	r3, [r4, #24]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  int left_shift = op_params.left_shift;
   dc72e:	f8d4 a000 	ldr.w	sl, [r4]
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dc732:	9307      	str	r3, [sp, #28]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dc734:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dc736:	9509      	str	r5, [sp, #36]	; 0x24
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dc738:	2100      	movs	r1, #0
   dc73a:	a80b      	add	r0, sp, #44	; 0x2c
   dc73c:	f7fa ff20 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc740:	4284      	cmp	r4, r0
   dc742:	da59      	bge.n	dc7f8 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11e>
   dc744:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dc746:	af0b      	add	r7, sp, #44	; 0x2c
   dc748:	2101      	movs	r1, #1
   dc74a:	4638      	mov	r0, r7
   dc74c:	f7fa ff18 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc750:	4285      	cmp	r5, r0
   dc752:	da4f      	bge.n	dc7f4 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x11a>
   dc754:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dc756:	2102      	movs	r1, #2
   dc758:	4638      	mov	r0, r7
   dc75a:	f7fa ff11 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc75e:	4286      	cmp	r6, r0
   dc760:	da46      	bge.n	dc7f0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x116>
   dc762:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dc766:	2103      	movs	r1, #3
   dc768:	4638      	mov	r0, r7
   dc76a:	f7fa ff09 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dc76e:	4580      	cmp	r8, r0
   dc770:	da3c      	bge.n	dc7ec <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x112>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dc772:	f8cd 8000 	str.w	r8, [sp]
   dc776:	4633      	mov	r3, r6
   dc778:	462a      	mov	r2, r5
   dc77a:	4621      	mov	r1, r4
   dc77c:	9809      	ldr	r0, [sp, #36]	; 0x24
   dc77e:	f7fb f815 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
   dc782:	9b08      	ldr	r3, [sp, #32]
   dc784:	f913 9000 	ldrsb.w	r9, [r3, r0]
   dc788:	9b02      	ldr	r3, [sp, #8]
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   dc78a:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
   dc78e:	4499      	add	r9, r3
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
   dc790:	462a      	mov	r2, r5
   dc792:	4633      	mov	r3, r6
   dc794:	4621      	mov	r1, r4
   dc796:	a818      	add	r0, sp, #96	; 0x60
   dc798:	f7fb f808 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc79c:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc79e:	9a04      	ldr	r2, [sp, #16]
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc7a0:	f913 b000 	ldrsb.w	fp, [r3, r0]
   dc7a4:	9b05      	ldr	r3, [sp, #20]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc7a6:	9903      	ldr	r1, [sp, #12]
   dc7a8:	fa09 f00a 	lsl.w	r0, r9, sl
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc7ac:	449b      	add	fp, r3
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc7ae:	f7fa ffab 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          const int32 input1_val =
              input1_offset + input1_data[SubscriptToIndex(desc1, b, y, x, c)];
          const int32 input2_val =
              input2_offset + input2_data[SubscriptToIndex(desc2, b, y, x, c)];
          const int32 shifted_input1_val = input1_val * (1 << left_shift);
          const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dc7b2:	fa0b fb0a 	lsl.w	fp, fp, sl
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
   dc7b6:	4681      	mov	r9, r0
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   dc7b8:	9a07      	ldr	r2, [sp, #28]
   dc7ba:	9906      	ldr	r1, [sp, #24]
   dc7bc:	4658      	mov	r0, fp
   dc7be:	f7fa ffa3 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
          output_data[Offset(output_shape, b, y, x, c)] =
   dc7c2:	f8cd 8000 	str.w	r8, [sp]
          const int32 scaled_input1_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input1_val, input1_multiplier, input1_shift);
          const int32 scaled_input2_val =
              MultiplyByQuantizedMultiplierSmallerThanOneExp(
                  shifted_input2_val, input2_multiplier, input2_shift);
   dc7c6:	4683      	mov	fp, r0
          output_data[Offset(output_shape, b, y, x, c)] =
   dc7c8:	4633      	mov	r3, r6
   dc7ca:	462a      	mov	r2, r5
   dc7cc:	4621      	mov	r1, r4
   dc7ce:	4638      	mov	r0, r7
   dc7d0:	f7fa ff3b 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   dc7d4:	45d9      	cmp	r9, fp
   dc7d6:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   dc7d8:	bfcc      	ite	gt
   dc7da:	f04f 0900 	movgt.w	r9, #0
   dc7de:	f04f 0901 	movle.w	r9, #1
   dc7e2:	f803 9000 	strb.w	r9, [r3, r0]
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dc7e6:	f108 0801 	add.w	r8, r8, #1
   dc7ea:	e7bc      	b.n	dc766 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x8c>
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dc7ec:	3601      	adds	r6, #1
   dc7ee:	e7b2      	b.n	dc756 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x7c>
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dc7f0:	3501      	adds	r5, #1
   dc7f2:	e7a8      	b.n	dc746 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x6c>
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dc7f4:	3401      	adds	r4, #1
   dc7f6:	e79f      	b.n	dc738 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb+0x5e>
    const RuntimeShape& unextended_output_shape, bool* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   dc7f8:	a80b      	add	r0, sp, #44	; 0x2c
   dc7fa:	f7fa feb6 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
              F(scaled_input1_val, scaled_input2_val);
        }
      }
    }
  }
}
   dc7fe:	b021      	add	sp, #132	; 0x84
   dc800:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dc804 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus LessEqualEval(TfLiteContext* context, TfLiteNode* node) {
   dc804:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dc808:	680a      	ldr	r2, [r1, #0]
   dc80a:	f8d0 9008 	ldr.w	r9, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dc80e:	6895      	ldr	r5, [r2, #8]
   dc810:	4682      	mov	sl, r0
   dc812:	6850      	ldr	r0, [r2, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dc814:	684a      	ldr	r2, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dc816:	2338      	movs	r3, #56	; 0x38
   dc818:	fb03 f800 	mul.w	r8, r3, r0
   dc81c:	fb03 9505 	mla	r5, r3, r5, r9
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dc820:	6854      	ldr	r4, [r2, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dc822:	eb09 0608 	add.w	r6, r9, r8
   dc826:	b0ab      	sub	sp, #172	; 0xac
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dc828:	4629      	mov	r1, r5
   dc82a:	4630      	mov	r0, r6
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dc82c:	fb03 9404 	mla	r4, r3, r4, r9
   dc830:	f008 fb32 	bl	e4e98 <_ZN6tflite14HaveSameShapesEPK12TfLiteTensorS2_>
  switch (input1->type) {
   dc834:	f819 2008 	ldrb.w	r2, [r9, r8]

TfLiteStatus LessEqualEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dc838:	f080 0001 	eor.w	r0, r0, #1
  switch (input1->type) {
   dc83c:	1e53      	subs	r3, r2, #1

TfLiteStatus LessEqualEval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  bool requires_broadcast = !HaveSameShapes(input1, input2);
   dc83e:	b2c7      	uxtb	r7, r0
  switch (input1->type) {
   dc840:	2b08      	cmp	r3, #8
   dc842:	f200 8225 	bhi.w	dcc90 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x48c>
   dc846:	e8df f013 	tbh	[pc, r3, lsl #1]
   dc84a:	0009      	.short	0x0009
   dc84c:	00f00057 	.word	0x00f00057
   dc850:	022300a1 	.word	0x022300a1
   dc854:	02230223 	.word	0x02230223
   dc858:	01840223 	.word	0x01840223
   dc85c:	f10d 0874 	add.w	r8, sp, #116	; 0x74
    case kTfLiteFloat32:
      TF_LITE_COMPARISON(float, LessEqual, requires_broadcast);
   dc860:	4631      	mov	r1, r6
   dc862:	b1cf      	cbz	r7, dc898 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x94>
   dc864:	a813      	add	r0, sp, #76	; 0x4c
   dc866:	f7fb f930 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc86a:	4629      	mov	r1, r5
   dc86c:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc86e:	6876      	ldr	r6, [r6, #4]
   dc870:	f7fb f92b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc874:	b105      	cbz	r5, dc878 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x74>
   dc876:	686d      	ldr	r5, [r5, #4]
   dc878:	4621      	mov	r1, r4
   dc87a:	4640      	mov	r0, r8
   dc87c:	f7fb f925 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc880:	b104      	cbz	r4, dc884 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x80>
   dc882:	6864      	ldr	r4, [r4, #4]
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
TFLITE_COMPARISON_OP(Less);
TFLITE_COMPARISON_OP(LessEqual);
   dc884:	9402      	str	r4, [sp, #8]
   dc886:	e88d 0120 	stmia.w	sp, {r5, r8}
   dc88a:	ab18      	add	r3, sp, #96	; 0x60
   dc88c:	4632      	mov	r2, r6
   dc88e:	a913      	add	r1, sp, #76	; 0x4c
   dc890:	a822      	add	r0, sp, #136	; 0x88
   dc892:	f7fd fb10 	bl	d9eb6 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIfXadL_ZNS0_11LessEqualFnIfEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dc896:	e19e      	b.n	dcbd6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dc898:	a818      	add	r0, sp, #96	; 0x60
   dc89a:	f7fb f916 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc89e:	4629      	mov	r1, r5
   dc8a0:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc8a2:	6876      	ldr	r6, [r6, #4]
   dc8a4:	f7fb f911 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc8a8:	b105      	cbz	r5, dc8ac <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0xa8>
   dc8aa:	686d      	ldr	r5, [r5, #4]
   dc8ac:	4621      	mov	r1, r4
   dc8ae:	a822      	add	r0, sp, #136	; 0x88
   dc8b0:	f7fb f90b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc8b4:	b104      	cbz	r4, dc8b8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0xb4>
   dc8b6:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dc8b8:	4641      	mov	r1, r8
   dc8ba:	aa22      	add	r2, sp, #136	; 0x88
   dc8bc:	a818      	add	r0, sp, #96	; 0x60
   dc8be:	f7fa fee6 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dc8c2:	3c01      	subs	r4, #1
   dc8c4:	4633      	mov	r3, r6
   dc8c6:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   dc8c8:	2600      	movs	r6, #0
   dc8ca:	2700      	movs	r7, #0
   dc8cc:	4286      	cmp	r6, r0
   dc8ce:	eb77 0201 	sbcs.w	r2, r7, r1
   dc8d2:	f280 81e4 	bge.w	dcc9e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dc8d6:	ecb3 7a01 	vldmia	r3!, {s14}
   dc8da:	ecf5 7a01 	vldmia	r5!, {s15}
   dc8de:	eeb4 7ae7 	vcmpe.f32	s14, s15
   dc8e2:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   dc8e6:	bf94      	ite	ls
   dc8e8:	2201      	movls	r2, #1
   dc8ea:	2200      	movhi	r2, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc8ec:	3601      	adds	r6, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dc8ee:	f804 2f01 	strb.w	r2, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc8f2:	f147 0700 	adc.w	r7, r7, #0
   dc8f6:	e7e9      	b.n	dc8cc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0xc8>
   dc8f8:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, LessEqual, requires_broadcast);
   dc8fc:	4631      	mov	r1, r6
   dc8fe:	b1cf      	cbz	r7, dc934 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x130>
   dc900:	a813      	add	r0, sp, #76	; 0x4c
   dc902:	f7fb f8e2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc906:	4629      	mov	r1, r5
   dc908:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc90a:	6876      	ldr	r6, [r6, #4]
   dc90c:	f7fb f8dd 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc910:	b105      	cbz	r5, dc914 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x110>
   dc912:	686d      	ldr	r5, [r5, #4]
   dc914:	4621      	mov	r1, r4
   dc916:	4640      	mov	r0, r8
   dc918:	f7fb f8d7 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc91c:	b104      	cbz	r4, dc920 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x11c>
   dc91e:	6864      	ldr	r4, [r4, #4]
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
TFLITE_COMPARISON_OP(Less);
TFLITE_COMPARISON_OP(LessEqual);
   dc920:	9402      	str	r4, [sp, #8]
   dc922:	e88d 0120 	stmia.w	sp, {r5, r8}
   dc926:	ab18      	add	r3, sp, #96	; 0x60
   dc928:	4632      	mov	r2, r6
   dc92a:	a913      	add	r1, sp, #76	; 0x4c
   dc92c:	a822      	add	r0, sp, #136	; 0x88
   dc92e:	f7fd fb35 	bl	d9f9c <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIlXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dc932:	e150      	b.n	dcbd6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dc934:	a818      	add	r0, sp, #96	; 0x60
   dc936:	f7fb f8c8 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc93a:	4629      	mov	r1, r5
   dc93c:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc93e:	6876      	ldr	r6, [r6, #4]
   dc940:	f7fb f8c3 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc944:	b105      	cbz	r5, dc948 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x144>
   dc946:	686d      	ldr	r5, [r5, #4]
   dc948:	4621      	mov	r1, r4
   dc94a:	a822      	add	r0, sp, #136	; 0x88
   dc94c:	f7fb f8bd 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc950:	b104      	cbz	r4, dc954 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x150>
   dc952:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dc954:	aa22      	add	r2, sp, #136	; 0x88
   dc956:	4641      	mov	r1, r8
   dc958:	a818      	add	r0, sp, #96	; 0x60
   dc95a:	f7fa fe98 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dc95e:	3c01      	subs	r4, #1
   dc960:	17c1      	asrs	r1, r0, #31
  for (int64_t i = 0; i < flatsize; ++i) {
   dc962:	2200      	movs	r2, #0
   dc964:	2300      	movs	r3, #0
   dc966:	4282      	cmp	r2, r0
   dc968:	eb73 0701 	sbcs.w	r7, r3, r1
   dc96c:	f280 8197 	bge.w	dcc9e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dc970:	f856 7022 	ldr.w	r7, [r6, r2, lsl #2]
   dc974:	f855 e022 	ldr.w	lr, [r5, r2, lsl #2]
   dc978:	4577      	cmp	r7, lr
   dc97a:	bfcc      	ite	gt
   dc97c:	2700      	movgt	r7, #0
   dc97e:	2701      	movle	r7, #1
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc980:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dc982:	f804 7f01 	strb.w	r7, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dc986:	f143 0300 	adc.w	r3, r3, #0
   dc98a:	e7ec      	b.n	dc966 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x162>
   dc98c:	f10d 0874 	add.w	r8, sp, #116	; 0x74
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, LessEqual, requires_broadcast);
   dc990:	4631      	mov	r1, r6
   dc992:	b1cf      	cbz	r7, dc9c8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x1c4>
   dc994:	a813      	add	r0, sp, #76	; 0x4c
   dc996:	f7fb f898 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc99a:	4629      	mov	r1, r5
   dc99c:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc99e:	6876      	ldr	r6, [r6, #4]
   dc9a0:	f7fb f893 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc9a4:	b105      	cbz	r5, dc9a8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x1a4>
   dc9a6:	686d      	ldr	r5, [r5, #4]
   dc9a8:	4621      	mov	r1, r4
   dc9aa:	4640      	mov	r0, r8
   dc9ac:	f7fb f88d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc9b0:	b104      	cbz	r4, dc9b4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x1b0>
   dc9b2:	6864      	ldr	r4, [r4, #4]
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
TFLITE_COMPARISON_OP(Less);
TFLITE_COMPARISON_OP(LessEqual);
   dc9b4:	9402      	str	r4, [sp, #8]
   dc9b6:	e88d 0120 	stmia.w	sp, {r5, r8}
   dc9ba:	ab18      	add	r3, sp, #96	; 0x60
   dc9bc:	4632      	mov	r2, r6
   dc9be:	a913      	add	r1, sp, #76	; 0x4c
   dc9c0:	a822      	add	r0, sp, #136	; 0x88
   dc9c2:	f7fd fb57 	bl	da074 <_ZN6tflite13reference_ops29BroadcastComparison4DSlowImplIxXadL_ZNS0_11LessEqualFnIxEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dc9c6:	e106      	b.n	dcbd6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dc9c8:	a818      	add	r0, sp, #96	; 0x60
   dc9ca:	f7fb f87e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc9ce:	4629      	mov	r1, r5
   dc9d0:	4640      	mov	r0, r8
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dc9d2:	6876      	ldr	r6, [r6, #4]
   dc9d4:	f7fb f879 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dc9d8:	b105      	cbz	r5, dc9dc <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x1d8>
   dc9da:	686d      	ldr	r5, [r5, #4]
   dc9dc:	4621      	mov	r1, r4
   dc9de:	a822      	add	r0, sp, #136	; 0x88
   dc9e0:	f7fb f873 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dc9e4:	b104      	cbz	r4, dc9e8 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x1e4>
   dc9e6:	6864      	ldr	r4, [r4, #4]
inline void ComparisonImpl(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dc9e8:	aa22      	add	r2, sp, #136	; 0x88
   dc9ea:	4641      	mov	r1, r8
   dc9ec:	a818      	add	r0, sp, #96	; 0x60
   dc9ee:	f7fa fe4e 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dc9f2:	3d08      	subs	r5, #8
   dc9f4:	17c1      	asrs	r1, r0, #31
   dc9f6:	f1a6 0e08 	sub.w	lr, r6, #8
   dc9fa:	3c01      	subs	r4, #1
  for (int64_t i = 0; i < flatsize; ++i) {
   dc9fc:	2200      	movs	r2, #0
   dc9fe:	2300      	movs	r3, #0
   dca00:	4282      	cmp	r2, r0
   dca02:	eb73 0601 	sbcs.w	r6, r3, r1
   dca06:	f280 814a 	bge.w	dcc9e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x49a>
    output_data[i] = F(input1_data[i], input2_data[i]);
   dca0a:	e9fe 6702 	ldrd	r6, r7, [lr, #8]!
   dca0e:	e9f5 ab02 	ldrd	sl, fp, [r5, #8]!
   dca12:	45b2      	cmp	sl, r6
   dca14:	eb7b 0607 	sbcs.w	r6, fp, r7
   dca18:	bfac      	ite	ge
   dca1a:	2601      	movge	r6, #1
   dca1c:	2600      	movlt	r6, #0
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dca1e:	3201      	adds	r2, #1
    output_data[i] = F(input1_data[i], input2_data[i]);
   dca20:	f804 6f01 	strb.w	r6, [r4, #1]!
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dca24:	f143 0300 	adc.w	r3, r3, #0
   dca28:	e7ea      	b.n	dca00 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x1fc>
TF_LITE_QUANTIZE_COMPARISON(Equal);
TF_LITE_QUANTIZE_COMPARISON(NotEqual);
TF_LITE_QUANTIZE_COMPARISON(Greater);
TF_LITE_QUANTIZE_COMPARISON(GreaterEqual);
TF_LITE_QUANTIZE_COMPARISON(Less);
TF_LITE_QUANTIZE_COMPARISON(LessEqual);
   dca2a:	6933      	ldr	r3, [r6, #16]
   dca2c:	68f0      	ldr	r0, [r6, #12]
   dca2e:	f1c3 0900 	rsb	r9, r3, #0
   dca32:	692b      	ldr	r3, [r5, #16]
   dca34:	f1c3 0800 	rsb	r8, r3, #0
   dca38:	f00b fca0 	bl	e837c <__aeabi_f2d>
   dca3c:	ec41 0b10 	vmov	d0, r0, r1
   dca40:	a910      	add	r1, sp, #64	; 0x40
   dca42:	a80f      	add	r0, sp, #60	; 0x3c
   dca44:	f008 fa9c 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dca48:	68e8      	ldr	r0, [r5, #12]
   dca4a:	f00b fc97 	bl	e837c <__aeabi_f2d>
   dca4e:	ec41 0b10 	vmov	d0, r0, r1
   dca52:	a912      	add	r1, sp, #72	; 0x48
   dca54:	a811      	add	r0, sp, #68	; 0x44
   dca56:	f008 fa93 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dca5a:	2308      	movs	r3, #8
   dca5c:	9322      	str	r3, [sp, #136]	; 0x88
   dca5e:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   dca60:	9324      	str	r3, [sp, #144]	; 0x90
   dca62:	9b10      	ldr	r3, [sp, #64]	; 0x40
   dca64:	9325      	str	r3, [sp, #148]	; 0x94
   dca66:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dca68:	9327      	str	r3, [sp, #156]	; 0x9c
   dca6a:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dca6c:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   dca70:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   dca74:	9328      	str	r3, [sp, #160]	; 0xa0
   dca76:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   dca7a:	4631      	mov	r1, r6
   dca7c:	a813      	add	r0, sp, #76	; 0x4c
   dca7e:	b1bf      	cbz	r7, dcab0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x2ac>
   dca80:	f7fb f823 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dca84:	4629      	mov	r1, r5
   dca86:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dca88:	6876      	ldr	r6, [r6, #4]
   dca8a:	f7fb f81e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dca8e:	4621      	mov	r1, r4
   dca90:	4640      	mov	r0, r8
   dca92:	686d      	ldr	r5, [r5, #4]
   dca94:	f7fb f819 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dca98:	b104      	cbz	r4, dca9c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x298>
   dca9a:	6864      	ldr	r4, [r4, #4]
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
TFLITE_COMPARISON_OP(Less);
TFLITE_COMPARISON_OP(LessEqual);
   dca9c:	9402      	str	r4, [sp, #8]
   dca9e:	e88d 0120 	stmia.w	sp, {r5, r8}
   dcaa2:	ab18      	add	r3, sp, #96	; 0x60
   dcaa4:	4632      	mov	r2, r6
   dcaa6:	a913      	add	r1, sp, #76	; 0x4c
   dcaa8:	a822      	add	r0, sp, #136	; 0x88
   dcaaa:	f7ff fd81 	bl	dc5b0 <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIhXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dcaae:	e092      	b.n	dcbd6 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x3d2>
   dcab0:	f7fb f80b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dcab4:	6873      	ldr	r3, [r6, #4]
   dcab6:	9305      	str	r3, [sp, #20]
   dcab8:	4629      	mov	r1, r5
   dcaba:	a818      	add	r0, sp, #96	; 0x60
   dcabc:	f7fb f805 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dcac0:	4621      	mov	r1, r4
   dcac2:	4640      	mov	r0, r8
   dcac4:	f8d5 b004 	ldr.w	fp, [r5, #4]
   dcac8:	f7fa ffff 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dcacc:	b104      	cbz	r4, dcad0 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x2cc>
   dcace:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dcad0:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   dcad2:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   dcad4:	9b24      	ldr	r3, [sp, #144]	; 0x90
   dcad6:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   dcad8:	9b25      	ldr	r3, [sp, #148]	; 0x94
   dcada:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   dcadc:	9b26      	ldr	r3, [sp, #152]	; 0x98
   dcade:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   dcae0:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   dcae2:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dcae4:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dcae6:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   dcae8:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dcaea:	a918      	add	r1, sp, #96	; 0x60
   dcaec:	a813      	add	r0, sp, #76	; 0x4c
   dcaee:	f7fa fdce 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dcaf2:	4602      	mov	r2, r0
   dcaf4:	17c3      	asrs	r3, r0, #31
   dcaf6:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   dcafa:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dcafc:	f04f 0800 	mov.w	r8, #0
   dcb00:	f04f 0900 	mov.w	r9, #0
   dcb04:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   dcb08:	4590      	cmp	r8, r2
   dcb0a:	eb79 0303 	sbcs.w	r3, r9, r3
   dcb0e:	f280 80b4 	bge.w	dcc7a <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x476>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dcb12:	f81b 5008 	ldrb.w	r5, [fp, r8]
   dcb16:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dcb18:	9a08      	ldr	r2, [sp, #32]
   dcb1a:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dcb1c:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dcb1e:	9b05      	ldr	r3, [sp, #20]
   dcb20:	f813 0008 	ldrb.w	r0, [r3, r8]
   dcb24:	9b06      	ldr	r3, [sp, #24]
   dcb26:	4418      	add	r0, r3
   dcb28:	40b8      	lsls	r0, r7
   dcb2a:	f7fa fded 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dcb2e:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dcb30:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   dcb32:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dcb34:	990a      	ldr	r1, [sp, #40]	; 0x28
   dcb36:	4628      	mov	r0, r5
   dcb38:	f7fa fde6 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   dcb3c:	4582      	cmp	sl, r0
   dcb3e:	bfcc      	ite	gt
   dcb40:	2000      	movgt	r0, #0
   dcb42:	2001      	movle	r0, #1
   dcb44:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dcb48:	f118 0801 	adds.w	r8, r8, #1
   dcb4c:	f149 0900 	adc.w	r9, r9, #0
   dcb50:	e7d8      	b.n	dcb04 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x300>
   dcb52:	6933      	ldr	r3, [r6, #16]
   dcb54:	68f0      	ldr	r0, [r6, #12]
   dcb56:	f1c3 0900 	rsb	r9, r3, #0
   dcb5a:	692b      	ldr	r3, [r5, #16]
   dcb5c:	f1c3 0800 	rsb	r8, r3, #0
   dcb60:	f00b fc0c 	bl	e837c <__aeabi_f2d>
   dcb64:	ec41 0b10 	vmov	d0, r0, r1
   dcb68:	a910      	add	r1, sp, #64	; 0x40
   dcb6a:	a80f      	add	r0, sp, #60	; 0x3c
   dcb6c:	f008 fa08 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dcb70:	68e8      	ldr	r0, [r5, #12]
   dcb72:	f00b fc03 	bl	e837c <__aeabi_f2d>
   dcb76:	ec41 0b10 	vmov	d0, r0, r1
   dcb7a:	a912      	add	r1, sp, #72	; 0x48
   dcb7c:	a811      	add	r0, sp, #68	; 0x44
   dcb7e:	f008 f9ff 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
   dcb82:	2308      	movs	r3, #8
   dcb84:	9322      	str	r3, [sp, #136]	; 0x88
   dcb86:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   dcb88:	9324      	str	r3, [sp, #144]	; 0x90
   dcb8a:	9b10      	ldr	r3, [sp, #64]	; 0x40
   dcb8c:	9325      	str	r3, [sp, #148]	; 0x94
   dcb8e:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dcb90:	9327      	str	r3, [sp, #156]	; 0x9c
   dcb92:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dcb94:	f8cd 8098 	str.w	r8, [sp, #152]	; 0x98
   dcb98:	f8cd 908c 	str.w	r9, [sp, #140]	; 0x8c
   dcb9c:	9328      	str	r3, [sp, #160]	; 0xa0
   dcb9e:	f10d 0874 	add.w	r8, sp, #116	; 0x74
   dcba2:	4631      	mov	r1, r6
   dcba4:	a813      	add	r0, sp, #76	; 0x4c
   dcba6:	b1c7      	cbz	r7, dcbda <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x3d6>
   dcba8:	f7fa ff8f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dcbac:	4629      	mov	r1, r5
   dcbae:	a818      	add	r0, sp, #96	; 0x60
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dcbb0:	6876      	ldr	r6, [r6, #4]
   dcbb2:	f7fa ff8a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dcbb6:	4621      	mov	r1, r4
   dcbb8:	4640      	mov	r0, r8
   dcbba:	686d      	ldr	r5, [r5, #4]
   dcbbc:	f7fa ff85 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dcbc0:	b104      	cbz	r4, dcbc4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x3c0>
   dcbc2:	6864      	ldr	r4, [r4, #4]
TFLITE_COMPARISON_OP(Equal);
TFLITE_COMPARISON_OP(NotEqual);
TFLITE_COMPARISON_OP(Greater);
TFLITE_COMPARISON_OP(GreaterEqual);
TFLITE_COMPARISON_OP(Less);
TFLITE_COMPARISON_OP(LessEqual);
   dcbc4:	9402      	str	r4, [sp, #8]
   dcbc6:	e88d 0120 	stmia.w	sp, {r5, r8}
   dcbca:	ab18      	add	r3, sp, #96	; 0x60
   dcbcc:	4632      	mov	r2, r6
   dcbce:	a913      	add	r1, sp, #76	; 0x4c
   dcbd0:	a822      	add	r0, sp, #136	; 0x88
   dcbd2:	f7ff fd82 	bl	dc6da <_ZN6tflite13reference_ops36BroadcastComparison4DSlowWithScalingIaXadL_ZNS0_11LessEqualFnIlEEbT_S3_EEEEvRKNS_16ComparisonParamsERKNS_12RuntimeShapeEPKS3_S9_SB_S9_Pb>
   dcbd6:	4640      	mov	r0, r8
   dcbd8:	e050      	b.n	dcc7c <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x478>
   dcbda:	f7fa ff76 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dcbde:	6873      	ldr	r3, [r6, #4]
   dcbe0:	9305      	str	r3, [sp, #20]
   dcbe2:	4629      	mov	r1, r5
   dcbe4:	a818      	add	r0, sp, #96	; 0x60
   dcbe6:	f7fa ff70 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dcbea:	4621      	mov	r1, r4
   dcbec:	4640      	mov	r0, r8
   dcbee:	f8d5 b004 	ldr.w	fp, [r5, #4]
   dcbf2:	f7fa ff6a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dcbf6:	b104      	cbz	r4, dcbfa <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x3f6>
   dcbf8:	6864      	ldr	r4, [r4, #4]
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
  int32 input1_offset = op_params.input1_offset;
   dcbfa:	9b23      	ldr	r3, [sp, #140]	; 0x8c
   dcbfc:	9306      	str	r3, [sp, #24]
  int32 input1_multiplier = op_params.input1_multiplier;
   dcbfe:	9b24      	ldr	r3, [sp, #144]	; 0x90
   dcc00:	9307      	str	r3, [sp, #28]
  int input1_shift = op_params.input1_shift;
   dcc02:	9b25      	ldr	r3, [sp, #148]	; 0x94
   dcc04:	9308      	str	r3, [sp, #32]
  int32 input2_offset = op_params.input2_offset;
   dcc06:	9b26      	ldr	r3, [sp, #152]	; 0x98
   dcc08:	9309      	str	r3, [sp, #36]	; 0x24
  int32 input2_multiplier = op_params.input2_multiplier;
   dcc0a:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   dcc0c:	930a      	str	r3, [sp, #40]	; 0x28
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dcc0e:	aa1d      	add	r2, sp, #116	; 0x74
  int32 input1_offset = op_params.input1_offset;
  int32 input1_multiplier = op_params.input1_multiplier;
  int input1_shift = op_params.input1_shift;
  int32 input2_offset = op_params.input2_offset;
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;
   dcc10:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   dcc12:	930b      	str	r3, [sp, #44]	; 0x2c

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
   dcc14:	a918      	add	r1, sp, #96	; 0x60
   dcc16:	a813      	add	r0, sp, #76	; 0x4c
   dcc18:	f7fa fd39 	bl	d768e <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_S2_>
   dcc1c:	4602      	mov	r2, r0
   dcc1e:	17c3      	asrs	r3, r0, #31
   dcc20:	e9cd 230c 	strd	r2, r3, [sp, #48]	; 0x30
template <typename T, ComparisonFn<int32> F>
inline void ComparisonWithScaling(
    const ComparisonParams& op_params, const RuntimeShape& input1_shape,
    const T* input1_data, const RuntimeShape& input2_shape,
    const T* input2_data, const RuntimeShape& output_shape, bool* output_data) {
  int left_shift = op_params.left_shift;
   dcc24:	9f22      	ldr	r7, [sp, #136]	; 0x88
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dcc26:	f04f 0800 	mov.w	r8, #0
   dcc2a:	f04f 0900 	mov.w	r9, #0
   dcc2e:	e9dd 230c 	ldrd	r2, r3, [sp, #48]	; 0x30
   dcc32:	4590      	cmp	r8, r2
   dcc34:	eb79 0303 	sbcs.w	r3, r9, r3
   dcc38:	da1f      	bge.n	dcc7a <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x476>
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dcc3a:	f91b 5008 	ldrsb.w	r5, [fp, r8]
   dcc3e:	9b09      	ldr	r3, [sp, #36]	; 0x24
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dcc40:	9a08      	ldr	r2, [sp, #32]
   dcc42:	9907      	ldr	r1, [sp, #28]
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dcc44:	441d      	add	r5, r3
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dcc46:	9b05      	ldr	r3, [sp, #20]
   dcc48:	f913 0008 	ldrsb.w	r0, [r3, r8]
   dcc4c:	9b06      	ldr	r3, [sp, #24]
   dcc4e:	4418      	add	r0, r3
   dcc50:	40b8      	lsls	r0, r7
   dcc52:	f7fa fd59 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
    const int32 input1_val = input1_offset + input1_data[i];
    const int32 input2_val = input2_offset + input2_data[i];
    const int32 shifted_input1_val = input1_val * (1 << left_shift);
    const int32 shifted_input2_val = input2_val * (1 << left_shift);
   dcc56:	40bd      	lsls	r5, r7
    const int32 scaled_input1_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input1_val, input1_multiplier, input1_shift);
   dcc58:	4682      	mov	sl, r0
    const int32 scaled_input2_val =
        MultiplyByQuantizedMultiplierSmallerThanOneExp(
            shifted_input2_val, input2_multiplier, input2_shift);
   dcc5a:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dcc5c:	990a      	ldr	r1, [sp, #40]	; 0x28
   dcc5e:	4628      	mov	r0, r5
   dcc60:	f7fa fd52 	bl	d7708 <_ZN6tflite46MultiplyByQuantizedMultiplierSmallerThanOneExpElli>
    output_data[i] = F(scaled_input1_val, scaled_input2_val);
   dcc64:	4582      	cmp	sl, r0
   dcc66:	bfcc      	ite	gt
   dcc68:	2000      	movgt	r0, #0
   dcc6a:	2001      	movle	r0, #1
   dcc6c:	f804 0008 	strb.w	r0, [r4, r8]
  int32 input2_multiplier = op_params.input2_multiplier;
  int input2_shift = op_params.input2_shift;

  const int64_t flatsize =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int64_t i = 0; i < flatsize; ++i) {
   dcc70:	f118 0801 	adds.w	r8, r8, #1
   dcc74:	f149 0900 	adc.w	r9, r9, #0
   dcc78:	e7d9      	b.n	dcc2e <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x42a>
   dcc7a:	a81d      	add	r0, sp, #116	; 0x74
   dcc7c:	f7fa fc75 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dcc80:	a818      	add	r0, sp, #96	; 0x60
   dcc82:	f7fa fc72 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dcc86:	a813      	add	r0, sp, #76	; 0x4c
   dcc88:	f7fa fc6f 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      context->ReportError(context,
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
   dcc8c:	2000      	movs	r0, #0
   dcc8e:	e00e      	b.n	dccae <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x4aa>
                                     requires_broadcast);
      break;
    default:
      context->ReportError(context,
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
   dcc90:	4650      	mov	r0, sl
   dcc92:	f8da 3014 	ldr.w	r3, [sl, #20]
   dcc96:	4907      	ldr	r1, [pc, #28]	; (dccb4 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x4b0>)
   dcc98:	4798      	blx	r3
      return kTfLiteError;
   dcc9a:	2001      	movs	r0, #1
   dcc9c:	e007      	b.n	dccae <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x4aa>
      break;
    case kTfLiteInt32:
      TF_LITE_COMPARISON(int32_t, LessEqual, requires_broadcast);
      break;
    case kTfLiteInt64:
      TF_LITE_COMPARISON(int64_t, LessEqual, requires_broadcast);
   dcc9e:	a822      	add	r0, sp, #136	; 0x88
   dcca0:	f7fa fc63 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dcca4:	4640      	mov	r0, r8
   dcca6:	f7fa fc60 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   dccaa:	a818      	add	r0, sp, #96	; 0x60
   dccac:	e7ec      	b.n	dcc88 <_ZN6tflite3ops5micro11comparisons12_GLOBAL__N_113LessEqualEvalEP13TfLiteContextP10TfLiteNode+0x484>
                           "Does not support type %d, requires float|int|uint8",
                           input1->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   dccae:	b02b      	add	sp, #172	; 0xac
   dccb0:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   dccb4:	000eb4b0 	.word	0x000eb4b0

000dccb8 <_ZN6tflite3ops5micro4conv4InitEP13TfLiteContextPKcj>:
  return kTfLiteOk;
}

void* Init(TfLiteContext* context, const char* buffer, size_t length) {
  return nullptr;
}
   dccb8:	2000      	movs	r0, #0
   dccba:	4770      	bx	lr

000dccbc <_ZN6tflite3ops5micro4conv4FreeEP13TfLiteContextPv>:

void Free(TfLiteContext* context, void* buffer) {}
   dccbc:	4770      	bx	lr

000dccbe <_ZN6tflite3ops5micro4conv7PrepareEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   dccbe:	2000      	movs	r0, #0
   dccc0:	4770      	bx	lr

000dccc2 <_ZNK6tflite12RuntimeShape8FlatSizeEv>:
    BuildFrom<const std::initializer_list<int>>(init_list);
  }

  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
   dccc2:	b510      	push	{r4, lr}

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   dccc4:	6801      	ldr	r1, [r0, #0]
   dccc6:	2904      	cmp	r1, #4
   dccc8:	bfcc      	ite	gt
   dccca:	6843      	ldrgt	r3, [r0, #4]
   dcccc:	1d03      	addle	r3, r0, #4
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   dccce:	2200      	movs	r2, #0
  }

  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
   dccd0:	2001      	movs	r0, #1
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   dccd2:	428a      	cmp	r2, r1
   dccd4:	da04      	bge.n	dcce0 <_ZNK6tflite12RuntimeShape8FlatSizeEv+0x1e>
      buffer_size *= dims_data[i];
   dccd6:	f853 4022 	ldr.w	r4, [r3, r2, lsl #2]
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   dccda:	3201      	adds	r2, #1
      buffer_size *= dims_data[i];
   dccdc:	4360      	muls	r0, r4
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   dccde:	e7f8      	b.n	dccd2 <_ZNK6tflite12RuntimeShape8FlatSizeEv+0x10>
      buffer_size *= dims_data[i];
    }
    return buffer_size;
  }
   dcce0:	bd10      	pop	{r4, pc}

000dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>:
  return MatchingArraySize(array1, index1, args...);
}

// Get common shape dim, DCHECKing that they all agree.
inline int MatchingDim(const RuntimeShape& shape1, int index1,
                       const RuntimeShape& shape2, int index2) {
   dcce2:	b570      	push	{r4, r5, r6, lr}
   dcce4:	4615      	mov	r5, r2
   dcce6:	461e      	mov	r6, r3
  TFLITE_DCHECK_EQ(shape1.Dims(index1), shape2.Dims(index2));
   dcce8:	f7fa fc4a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dccec:	4631      	mov	r1, r6
   dccee:	4604      	mov	r4, r0
   dccf0:	4628      	mov	r0, r5
   dccf2:	f7fa fc45 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dccf6:	4284      	cmp	r4, r0
   dccf8:	d001      	beq.n	dccfe <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i+0x1c>
   dccfa:	f008 fbfb 	bl	e54f4 <abort>
  return shape1.Dims(index1);
}
   dccfe:	bd70      	pop	{r4, r5, r6, pc}

000dcd00 <_ZN6tflite29MultiplyByQuantizedMultiplierElli>:
  return SaturatingRoundingDoublingHighMul(x * (1 << left_shift),
                                           quantized_multiplier);
}

inline int32 MultiplyByQuantizedMultiplier(int32 x, int32 quantized_multiplier,
                                           int shift) {
   dcd00:	b570      	push	{r4, r5, r6, lr}
  using gemmlowp::RoundingDivideByPOT;
  using gemmlowp::SaturatingRoundingDoublingHighMul;
  int left_shift = shift > 0 ? shift : 0;
   dcd02:	ea22 74e2 	bic.w	r4, r2, r2, asr #31
  int right_shift = shift > 0 ? 0 : -shift;
   dcd06:	2a00      	cmp	r2, #0
  return RoundingDivideByPOT(SaturatingRoundingDoublingHighMul(
   dcd08:	fa00 f004 	lsl.w	r0, r0, r4
inline int32 MultiplyByQuantizedMultiplier(int32 x, int32 quantized_multiplier,
                                           int shift) {
  using gemmlowp::RoundingDivideByPOT;
  using gemmlowp::SaturatingRoundingDoublingHighMul;
  int left_shift = shift > 0 ? shift : 0;
  int right_shift = shift > 0 ? 0 : -shift;
   dcd0c:	bfd4      	ite	le
   dcd0e:	4256      	negle	r6, r2
   dcd10:	2600      	movgt	r6, #0
// This function implements the same computation as the ARMv7 NEON VQRDMULH
// instruction.
template <>
inline std::int32_t SaturatingRoundingDoublingHighMul(std::int32_t a,
                                                      std::int32_t b) {
  bool overflow = a == b && a == std::numeric_limits<std::int32_t>::min();
   dcd12:	4288      	cmp	r0, r1
   dcd14:	d104      	bne.n	dcd20 <_ZN6tflite29MultiplyByQuantizedMultiplierElli+0x20>
   dcd16:	f101 4300 	add.w	r3, r1, #2147483648	; 0x80000000
   dcd1a:	425a      	negs	r2, r3
   dcd1c:	415a      	adcs	r2, r3
   dcd1e:	e000      	b.n	dcd22 <_ZN6tflite29MultiplyByQuantizedMultiplierElli+0x22>
   dcd20:	2200      	movs	r2, #0
  std::int64_t a_64(a);
  std::int64_t b_64(b);
  std::int64_t ab_64 = a_64 * b_64;
   dcd22:	fb80 4501 	smull	r4, r5, r0, r1
  std::int32_t nudge = ab_64 >= 0 ? (1 << 30) : (1 - (1 << 30));
   dcd26:	2c00      	cmp	r4, #0
   dcd28:	f175 0300 	sbcs.w	r3, r5, #0
   dcd2c:	4b18      	ldr	r3, [pc, #96]	; (dcd90 <_ZN6tflite29MultiplyByQuantizedMultiplierElli+0x90>)
   dcd2e:	bfa8      	it	ge
   dcd30:	f04f 4380 	movge.w	r3, #1073741824	; 0x40000000
  std::int32_t ab_x2_high32 =
      static_cast<std::int32_t>((ab_64 + nudge) / (1ll << 31));
  return overflow ? std::numeric_limits<std::int32_t>::max() : ab_x2_high32;
   dcd34:	b97a      	cbnz	r2, dcd56 <_ZN6tflite29MultiplyByQuantizedMultiplierElli+0x56>
  std::int64_t a_64(a);
  std::int64_t b_64(b);
  std::int64_t ab_64 = a_64 * b_64;
  std::int32_t nudge = ab_64 >= 0 ? (1 << 30) : (1 - (1 << 30));
  std::int32_t ab_x2_high32 =
      static_cast<std::int32_t>((ab_64 + nudge) / (1ll << 31));
   dcd36:	18e4      	adds	r4, r4, r3
   dcd38:	eb45 75e3 	adc.w	r5, r5, r3, asr #31
   dcd3c:	2c00      	cmp	r4, #0
   dcd3e:	f175 0300 	sbcs.w	r3, r5, #0
   dcd42:	da04      	bge.n	dcd4e <_ZN6tflite29MultiplyByQuantizedMultiplierElli+0x4e>
   dcd44:	f06f 4200 	mvn.w	r2, #2147483648	; 0x80000000
   dcd48:	2300      	movs	r3, #0
   dcd4a:	18a4      	adds	r4, r4, r2
   dcd4c:	415d      	adcs	r5, r3
   dcd4e:	0fe0      	lsrs	r0, r4, #31
   dcd50:	ea40 0445 	orr.w	r4, r0, r5, lsl #1
   dcd54:	e001      	b.n	dcd5a <_ZN6tflite29MultiplyByQuantizedMultiplierElli+0x5a>
  return overflow ? std::numeric_limits<std::int32_t>::max() : ab_x2_high32;
   dcd56:	f06f 4400 	mvn.w	r4, #2147483648	; 0x80000000
// Correctly-rounded-to-nearest division by a power-of-two.
// Also known as a rounding arithmetic right shift.
template <typename IntegerType>
inline IntegerType RoundingDivideByPOT(IntegerType x, int exponent) {
  assert(exponent >= 0);
  assert(exponent <= 31);
   dcd5a:	2e1f      	cmp	r6, #31
   dcd5c:	dd06      	ble.n	dcd6c <_ZN6tflite29MultiplyByQuantizedMultiplierElli+0x6c>
   dcd5e:	4b0d      	ldr	r3, [pc, #52]	; (dcd94 <_ZN6tflite29MultiplyByQuantizedMultiplierElli+0x94>)
   dcd60:	4a0d      	ldr	r2, [pc, #52]	; (dcd98 <_ZN6tflite29MultiplyByQuantizedMultiplierElli+0x98>)
   dcd62:	480e      	ldr	r0, [pc, #56]	; (dcd9c <_ZN6tflite29MultiplyByQuantizedMultiplierElli+0x9c>)
   dcd64:	f240 1167 	movw	r1, #359	; 0x167
   dcd68:	f008 fbd4 	bl	e5514 <__assert_func>
  const IntegerType mask = Dup<IntegerType>((1ll << exponent) - 1);
   dcd6c:	4632      	mov	r2, r6
   dcd6e:	2001      	movs	r0, #1
   dcd70:	2100      	movs	r1, #0
   dcd72:	f00b f993 	bl	e809c <__aeabi_llsl>
   dcd76:	3801      	subs	r0, #1
  return RoundingDivideByPOT(SaturatingRoundingDoublingHighMul(
                                 x * (1 << left_shift), quantized_multiplier),
                             right_shift);
   dcd78:	ea00 0304 	and.w	r3, r0, r4
   dcd7c:	1040      	asrs	r0, r0, #1
   dcd7e:	eb00 70d4 	add.w	r0, r0, r4, lsr #31
   dcd82:	4134      	asrs	r4, r6
}
   dcd84:	4283      	cmp	r3, r0
   dcd86:	bfd4      	ite	le
   dcd88:	4620      	movle	r0, r4
   dcd8a:	1c60      	addgt	r0, r4, #1
   dcd8c:	bd70      	pop	{r4, r5, r6, pc}
   dcd8e:	bf00      	nop
   dcd90:	c0000001 	.word	0xc0000001
   dcd94:	000eb1ee 	.word	0x000eb1ee
   dcd98:	000eb65c 	.word	0x000eb65c
   dcd9c:	000eb14a 	.word	0x000eb14a

000dcda0 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_>:
inline void Conv(const ConvParams& params, const RuntimeShape& input_shape,
                 const float* input_data, const RuntimeShape& filter_shape,
                 const float* filter_data, const RuntimeShape& bias_shape,
                 const float* bias_data, const RuntimeShape& output_shape,
                 float* output_data, const RuntimeShape& im2col_shape,
                 float* im2col_data) {
   dcda0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dcda4:	ed2d 8b04 	vpush	{d8-d9}
   dcda8:	b09b      	sub	sp, #108	; 0x6c
   dcdaa:	4699      	mov	r9, r3
  const int stride_width = params.stride_width;
   dcdac:	f9b0 300a 	ldrsh.w	r3, [r0, #10]
   dcdb0:	930a      	str	r3, [sp, #40]	; 0x28
  const int stride_height = params.stride_height;
   dcdb2:	f9b0 300c 	ldrsh.w	r3, [r0, #12]
   dcdb6:	930b      	str	r3, [sp, #44]	; 0x2c
  const int dilation_width_factor = params.dilation_width_factor;
   dcdb8:	f9b0 300e 	ldrsh.w	r3, [r0, #14]
   dcdbc:	930c      	str	r3, [sp, #48]	; 0x30
  const int dilation_height_factor = params.dilation_height_factor;
   dcdbe:	f9b0 3010 	ldrsh.w	r3, [r0, #16]
   dcdc2:	930d      	str	r3, [sp, #52]	; 0x34
  const int pad_width = params.padding_values.width;
   dcdc4:	f9b0 3002 	ldrsh.w	r3, [r0, #2]
   dcdc8:	930e      	str	r3, [sp, #56]	; 0x38
  const int pad_height = params.padding_values.height;
   dcdca:	f9b0 3004 	ldrsh.w	r3, [r0, #4]
   dcdce:	930f      	str	r3, [sp, #60]	; 0x3c
  const float output_activation_min = params.float_activation_min;
  const float output_activation_max = params.float_activation_max;
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dcdd0:	680b      	ldr	r3, [r1, #0]
inline void Conv(const ConvParams& params, const RuntimeShape& input_shape,
                 const float* input_data, const RuntimeShape& filter_shape,
                 const float* filter_data, const RuntimeShape& bias_shape,
                 const float* bias_data, const RuntimeShape& output_shape,
                 float* output_data, const RuntimeShape& im2col_shape,
                 float* im2col_data) {
   dcdd2:	9219      	str	r2, [sp, #100]	; 0x64
  const int dilation_height_factor = params.dilation_height_factor;
  const int pad_width = params.padding_values.width;
  const int pad_height = params.padding_values.height;
  const float output_activation_min = params.float_activation_min;
  const float output_activation_max = params.float_activation_max;
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dcdd4:	2b04      	cmp	r3, #4
inline void Conv(const ConvParams& params, const RuntimeShape& input_shape,
                 const float* input_data, const RuntimeShape& filter_shape,
                 const float* filter_data, const RuntimeShape& bias_shape,
                 const float* bias_data, const RuntimeShape& output_shape,
                 float* output_data, const RuntimeShape& im2col_shape,
                 float* im2col_data) {
   dcdd6:	468b      	mov	fp, r1
   dcdd8:	f8dd a0ac 	ldr.w	sl, [sp, #172]	; 0xac
  const int stride_height = params.stride_height;
  const int dilation_width_factor = params.dilation_width_factor;
  const int dilation_height_factor = params.dilation_height_factor;
  const int pad_width = params.padding_values.width;
  const int pad_height = params.padding_values.height;
  const float output_activation_min = params.float_activation_min;
   dcddc:	edd0 8a0c 	vldr	s17, [r0, #48]	; 0x30
  const float output_activation_max = params.float_activation_max;
   dcde0:	ed90 9a0d 	vldr	s18, [r0, #52]	; 0x34
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dcde4:	d001      	beq.n	dcdea <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x4a>
   dcde6:	f008 fb85 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
   dcdea:	f8d9 3000 	ldr.w	r3, [r9]
   dcdee:	2b04      	cmp	r3, #4
   dcdf0:	d1f9      	bne.n	dcde6 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x46>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   dcdf2:	f8da 3000 	ldr.w	r3, [sl]
   dcdf6:	2b04      	cmp	r3, #4
   dcdf8:	d1f5      	bne.n	dcde6 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x46>

  (void)im2col_data;   // only used in optimized code.
  (void)im2col_shape;  // only used in optimized code.
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dcdfa:	2300      	movs	r3, #0
   dcdfc:	4619      	mov	r1, r3
   dcdfe:	4652      	mov	r2, sl
   dce00:	4658      	mov	r0, fp
   dce02:	f7ff ff6e 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
   dce06:	2303      	movs	r3, #3
   dce08:	4619      	mov	r1, r3
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  (void)im2col_data;   // only used in optimized code.
  (void)im2col_shape;  // only used in optimized code.
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dce0a:	9010      	str	r0, [sp, #64]	; 0x40
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
   dce0c:	464a      	mov	r2, r9
   dce0e:	4658      	mov	r0, fp
   dce10:	f7ff ff67 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
   dce14:	2303      	movs	r3, #3
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  (void)im2col_data;   // only used in optimized code.
  (void)im2col_shape;  // only used in optimized code.
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
   dce16:	9011      	str	r0, [sp, #68]	; 0x44
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
   dce18:	4652      	mov	r2, sl
   dce1a:	2100      	movs	r1, #0
   dce1c:	4648      	mov	r0, r9
   dce1e:	f7ff ff60 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  if (bias_data) {
   dce22:	9b2a      	ldr	r3, [sp, #168]	; 0xa8

  (void)im2col_data;   // only used in optimized code.
  (void)im2col_shape;  // only used in optimized code.
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
   dce24:	9009      	str	r0, [sp, #36]	; 0x24
  if (bias_data) {
   dce26:	b12b      	cbz	r3, dce34 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x94>
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
   dce28:	9829      	ldr	r0, [sp, #164]	; 0xa4
   dce2a:	f7ff ff4a 	bl	dccc2 <_ZNK6tflite12RuntimeShape8FlatSizeEv>
   dce2e:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dce30:	4283      	cmp	r3, r0
   dce32:	d1d8      	bne.n	dcde6 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x46>
  }
  const int input_height = input_shape.Dims(1);
   dce34:	2101      	movs	r1, #1
   dce36:	4658      	mov	r0, fp
   dce38:	f7fa fba2 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   dce3c:	2102      	movs	r1, #2
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
  if (bias_data) {
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
  }
  const int input_height = input_shape.Dims(1);
   dce3e:	9012      	str	r0, [sp, #72]	; 0x48
  const int input_width = input_shape.Dims(2);
   dce40:	4658      	mov	r0, fp
   dce42:	f7fa fb9d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_height = filter_shape.Dims(1);
   dce46:	2101      	movs	r1, #1
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
  if (bias_data) {
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
  }
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   dce48:	9013      	str	r0, [sp, #76]	; 0x4c
  const int filter_height = filter_shape.Dims(1);
   dce4a:	4648      	mov	r0, r9
   dce4c:	f7fa fb98 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_width = filter_shape.Dims(2);
   dce50:	2102      	movs	r1, #2
  if (bias_data) {
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
  }
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
   dce52:	9014      	str	r0, [sp, #80]	; 0x50
  const int filter_width = filter_shape.Dims(2);
   dce54:	4648      	mov	r0, r9
   dce56:	f7fa fb93 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   dce5a:	2101      	movs	r1, #1
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
  }
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
   dce5c:	9015      	str	r0, [sp, #84]	; 0x54
  const int output_height = output_shape.Dims(1);
   dce5e:	4650      	mov	r0, sl
   dce60:	f7fa fb8e 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   dce64:	2102      	movs	r1, #2
  }
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   dce66:	9016      	str	r0, [sp, #88]	; 0x58
  const int output_width = output_shape.Dims(2);
   dce68:	4650      	mov	r0, sl
   dce6a:	f7fa fb89 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  for (int batch = 0; batch < batches; ++batch) {
   dce6e:	2500      	movs	r5, #0
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   dce70:	9017      	str	r0, [sp, #92]	; 0x5c
  for (int batch = 0; batch < batches; ++batch) {
   dce72:	9b10      	ldr	r3, [sp, #64]	; 0x40
   dce74:	429d      	cmp	r5, r3
   dce76:	f280 809c 	bge.w	dcfb2 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x212>
   dce7a:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   dce7c:	425b      	negs	r3, r3
   dce7e:	9308      	str	r3, [sp, #32]
   dce80:	2300      	movs	r3, #0
   dce82:	9303      	str	r3, [sp, #12]
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dce84:	9b03      	ldr	r3, [sp, #12]
   dce86:	9a16      	ldr	r2, [sp, #88]	; 0x58
   dce88:	4293      	cmp	r3, r2
   dce8a:	f280 8090 	bge.w	dcfae <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x20e>
   dce8e:	9b0e      	ldr	r3, [sp, #56]	; 0x38
   dce90:	425b      	negs	r3, r3
   dce92:	9307      	str	r3, [sp, #28]
   dce94:	2300      	movs	r3, #0
   dce96:	9304      	str	r3, [sp, #16]
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dce98:	9b04      	ldr	r3, [sp, #16]
   dce9a:	9a17      	ldr	r2, [sp, #92]	; 0x5c
   dce9c:	4293      	cmp	r3, r2
   dce9e:	da7e      	bge.n	dcf9e <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x1fe>
   dcea0:	2400      	movs	r4, #0
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
   dcea2:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dcea4:	429c      	cmp	r4, r3
   dcea6:	da72      	bge.n	dcf8e <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x1ee>
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          float total = 0.f;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   dcea8:	2300      	movs	r3, #0
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
   dceaa:	9e08      	ldr	r6, [sp, #32]
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          float total = 0.f;
   dceac:	ed9f 8a43 	vldr	s16, [pc, #268]	; dcfbc <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x21c>
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   dceb0:	9305      	str	r3, [sp, #20]
   dceb2:	9b05      	ldr	r3, [sp, #20]
   dceb4:	9a14      	ldr	r2, [sp, #80]	; 0x50
   dceb6:	4293      	cmp	r3, r2
   dceb8:	da42      	bge.n	dcf40 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x1a0>
   dceba:	2300      	movs	r3, #0
   dcebc:	9f07      	ldr	r7, [sp, #28]
   dcebe:	9306      	str	r3, [sp, #24]
            for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   dcec0:	9b06      	ldr	r3, [sp, #24]
   dcec2:	9a15      	ldr	r2, [sp, #84]	; 0x54
   dcec4:	4293      	cmp	r3, r2
   dcec6:	da35      	bge.n	dcf34 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x194>
   dcec8:	f04f 0800 	mov.w	r8, #0
              for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
   dcecc:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dcece:	4598      	cmp	r8, r3
   dced0:	da2a      	bge.n	dcf28 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x188>
                const int in_x = in_x_origin + dilation_width_factor * filter_x;
                const int in_y =
                    in_y_origin + dilation_height_factor * filter_y;
                // If the location is outside the bounds of the input image,
                // use zero as a default value.
                if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
   dced2:	2f00      	cmp	r7, #0
   dced4:	db25      	blt.n	dcf22 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x182>
   dced6:	9b13      	ldr	r3, [sp, #76]	; 0x4c
   dced8:	42bb      	cmp	r3, r7
   dceda:	dd22      	ble.n	dcf22 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x182>
   dcedc:	2e00      	cmp	r6, #0
   dcede:	db20      	blt.n	dcf22 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x182>
   dcee0:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dcee2:	42b3      	cmp	r3, r6
   dcee4:	dd1d      	ble.n	dcf22 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x182>
                    (in_y < input_height)) {
                  float input_value = input_data[Offset(
   dcee6:	463b      	mov	r3, r7
   dcee8:	4632      	mov	r2, r6
   dceea:	4629      	mov	r1, r5
   dceec:	f8cd 8000 	str.w	r8, [sp]
   dcef0:	4658      	mov	r0, fp
   dcef2:	f7fa fbaa 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                      input_shape, batch, in_y, in_x, in_channel)];
                  float filter_value =
                      filter_data[Offset(filter_shape, out_channel, filter_y,
   dcef6:	9b06      	ldr	r3, [sp, #24]
                    in_y_origin + dilation_height_factor * filter_y;
                // If the location is outside the bounds of the input image,
                // use zero as a default value.
                if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                    (in_y < input_height)) {
                  float input_value = input_data[Offset(
   dcef8:	9018      	str	r0, [sp, #96]	; 0x60
                      input_shape, batch, in_y, in_x, in_channel)];
                  float filter_value =
                      filter_data[Offset(filter_shape, out_channel, filter_y,
   dcefa:	9a05      	ldr	r2, [sp, #20]
   dcefc:	f8cd 8000 	str.w	r8, [sp]
   dcf00:	4621      	mov	r1, r4
   dcf02:	4648      	mov	r0, r9
   dcf04:	f7fa fba1 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                // If the location is outside the bounds of the input image,
                // use zero as a default value.
                if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                    (in_y < input_height)) {
                  float input_value = input_data[Offset(
                      input_shape, batch, in_y, in_x, in_channel)];
   dcf08:	9a18      	ldr	r2, [sp, #96]	; 0x60
   dcf0a:	9b19      	ldr	r3, [sp, #100]	; 0x64
   dcf0c:	eb03 0382 	add.w	r3, r3, r2, lsl #2
                  float filter_value =
                      filter_data[Offset(filter_shape, out_channel, filter_y,
                                         filter_x, in_channel)];
   dcf10:	9a28      	ldr	r2, [sp, #160]	; 0xa0
                  total += (input_value * filter_value);
   dcf12:	ed93 7a00 	vldr	s14, [r3]
                    (in_y < input_height)) {
                  float input_value = input_data[Offset(
                      input_shape, batch, in_y, in_x, in_channel)];
                  float filter_value =
                      filter_data[Offset(filter_shape, out_channel, filter_y,
                                         filter_x, in_channel)];
   dcf16:	eb02 0080 	add.w	r0, r2, r0, lsl #2
                  total += (input_value * filter_value);
   dcf1a:	edd0 7a00 	vldr	s15, [r0]
   dcf1e:	eea7 8a27 	vfma.f32	s16, s14, s15
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          float total = 0.f;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
            for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
              for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
   dcf22:	f108 0801 	add.w	r8, r8, #1
   dcf26:	e7d1      	b.n	dcecc <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x12c>
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          float total = 0.f;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
            for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   dcf28:	9b06      	ldr	r3, [sp, #24]
   dcf2a:	3301      	adds	r3, #1
   dcf2c:	9306      	str	r3, [sp, #24]
   dcf2e:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   dcf30:	441f      	add	r7, r3
   dcf32:	e7c5      	b.n	dcec0 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x120>
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          float total = 0.f;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   dcf34:	9b05      	ldr	r3, [sp, #20]
   dcf36:	3301      	adds	r3, #1
   dcf38:	9305      	str	r3, [sp, #20]
   dcf3a:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   dcf3c:	441e      	add	r6, r3
   dcf3e:	e7b8      	b.n	dceb2 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x112>
                }
              }
            }
          }
          float bias_value = 0.0f;
          if (bias_data) {
   dcf40:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
   dcf42:	b123      	cbz	r3, dcf4e <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x1ae>
            bias_value = bias_data[out_channel];
   dcf44:	eb03 0384 	add.w	r3, r3, r4, lsl #2
   dcf48:	edd3 9a00 	vldr	s19, [r3]
   dcf4c:	e001      	b.n	dcf52 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x1b2>
                  total += (input_value * filter_value);
                }
              }
            }
          }
          float bias_value = 0.0f;
   dcf4e:	eddf 9a1b 	vldr	s19, [pc, #108]	; dcfbc <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x21c>
          if (bias_data) {
            bias_value = bias_data[out_channel];
          }
          output_data[Offset(output_shape, batch, out_y, out_x, out_channel)] =
   dcf52:	9400      	str	r4, [sp, #0]
   dcf54:	9b04      	ldr	r3, [sp, #16]
   dcf56:	9a03      	ldr	r2, [sp, #12]
   dcf58:	4629      	mov	r1, r5
   dcf5a:	4650      	mov	r0, sl
   dcf5c:	f7fa fb75 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              ActivationFunctionWithMinMax(total + bias_value,
   dcf60:	ee78 7a29 	vadd.f32	s15, s16, s19
          }
          float bias_value = 0.0f;
          if (bias_data) {
            bias_value = bias_data[out_channel];
          }
          output_data[Offset(output_shape, batch, out_y, out_x, out_channel)] =
   dcf64:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
	return __b;
      return __a;
   dcf66:	eef4 8ae7 	vcmpe.f32	s17, s15
   dcf6a:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   dcf6e:	bfc8      	it	gt
   dcf70:	eef0 7a68 	vmovgt.f32	s15, s17
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
   dcf74:	eeb4 9a67 	vcmp.f32	s18, s15
   dcf78:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   dcf7c:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   dcf80:	bf48      	it	mi
   dcf82:	eef0 7a49 	vmovmi.f32	s15, s18
              ActivationFunctionWithMinMax(total + bias_value,
                                           output_activation_min,
                                           output_activation_max);
   dcf86:	edc0 7a00 	vstr	s15, [r0]
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
   dcf8a:	3401      	adds	r4, #1
   dcf8c:	e789      	b.n	dcea2 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0x102>
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dcf8e:	9b04      	ldr	r3, [sp, #16]
   dcf90:	9a0a      	ldr	r2, [sp, #40]	; 0x28
   dcf92:	3301      	adds	r3, #1
   dcf94:	9304      	str	r3, [sp, #16]
   dcf96:	9b07      	ldr	r3, [sp, #28]
   dcf98:	4413      	add	r3, r2
   dcf9a:	9307      	str	r3, [sp, #28]
   dcf9c:	e77c      	b.n	dce98 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0xf8>
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dcf9e:	9b03      	ldr	r3, [sp, #12]
   dcfa0:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dcfa2:	3301      	adds	r3, #1
   dcfa4:	9303      	str	r3, [sp, #12]
   dcfa6:	9b08      	ldr	r3, [sp, #32]
   dcfa8:	4413      	add	r3, r2
   dcfaa:	9308      	str	r3, [sp, #32]
   dcfac:	e76a      	b.n	dce84 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0xe4>
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
   dcfae:	3501      	adds	r5, #1
   dcfb0:	e75f      	b.n	dce72 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_+0xd2>
                                           output_activation_max);
        }
      }
    }
  }
}
   dcfb2:	b01b      	add	sp, #108	; 0x6c
   dcfb4:	ecbd 8b04 	vpop	{d8-d9}
   dcfb8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   dcfbc:	00000000 	.word	0x00000000

000dcfc0 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv>:
inline void Conv(const ConvParams& params, const RuntimeShape& input_shape,
                 const uint8* input_data, const RuntimeShape& filter_shape,
                 const uint8* filter_data, const RuntimeShape& bias_shape,
                 const int32* bias_data, const RuntimeShape& output_shape,
                 uint8* output_data, const RuntimeShape& im2col_shape,
                 uint8* im2col_data, void* cpu_backend_context) {
   dcfc0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dcfc4:	b0a3      	sub	sp, #140	; 0x8c
   dcfc6:	469a      	mov	sl, r3
  (void)cpu_backend_context;  // only used in optimized code.
  (void)im2col_data;   // only used in optimized code.
  (void)im2col_shape;  // only used in optimized code.
  const int stride_width = params.stride_width;
   dcfc8:	f9b0 300a 	ldrsh.w	r3, [r0, #10]
   dcfcc:	930d      	str	r3, [sp, #52]	; 0x34
  const int stride_height = params.stride_height;
   dcfce:	f9b0 300c 	ldrsh.w	r3, [r0, #12]
   dcfd2:	930e      	str	r3, [sp, #56]	; 0x38
  const int dilation_width_factor = params.dilation_width_factor;
   dcfd4:	f9b0 300e 	ldrsh.w	r3, [r0, #14]
   dcfd8:	930f      	str	r3, [sp, #60]	; 0x3c
  const int dilation_height_factor = params.dilation_height_factor;
   dcfda:	f9b0 3010 	ldrsh.w	r3, [r0, #16]
   dcfde:	9310      	str	r3, [sp, #64]	; 0x40
  const int pad_width = params.padding_values.width;
   dcfe0:	f9b0 3002 	ldrsh.w	r3, [r0, #2]
   dcfe4:	9311      	str	r3, [sp, #68]	; 0x44
  const int pad_height = params.padding_values.height;
   dcfe6:	f9b0 3004 	ldrsh.w	r3, [r0, #4]
   dcfea:	9312      	str	r3, [sp, #72]	; 0x48
  const int32 input_offset = params.input_offset;
   dcfec:	6943      	ldr	r3, [r0, #20]
   dcfee:	9313      	str	r3, [sp, #76]	; 0x4c
  const int32 filter_offset = params.weights_offset;
   dcff0:	6983      	ldr	r3, [r0, #24]
   dcff2:	9314      	str	r3, [sp, #80]	; 0x50
  const int32 output_offset = params.output_offset;
   dcff4:	69c3      	ldr	r3, [r0, #28]
   dcff6:	9315      	str	r3, [sp, #84]	; 0x54
  const int32 output_multiplier = params.output_multiplier;
   dcff8:	6a03      	ldr	r3, [r0, #32]
   dcffa:	9316      	str	r3, [sp, #88]	; 0x58
  const int output_shift = params.output_shift;
   dcffc:	6a43      	ldr	r3, [r0, #36]	; 0x24
   dcffe:	9317      	str	r3, [sp, #92]	; 0x5c
  const int32 output_activation_min = params.quantized_activation_min;
   dd000:	6a83      	ldr	r3, [r0, #40]	; 0x28
   dd002:	930a      	str	r3, [sp, #40]	; 0x28
  const int32 output_activation_max = params.quantized_activation_max;
   dd004:	6ac3      	ldr	r3, [r0, #44]	; 0x2c
   dd006:	930b      	str	r3, [sp, #44]	; 0x2c
inline void Conv(const ConvParams& params, const RuntimeShape& input_shape,
                 const uint8* input_data, const RuntimeShape& filter_shape,
                 const uint8* filter_data, const RuntimeShape& bias_shape,
                 const int32* bias_data, const RuntimeShape& output_shape,
                 uint8* output_data, const RuntimeShape& im2col_shape,
                 uint8* im2col_data, void* cpu_backend_context) {
   dd008:	9221      	str	r2, [sp, #132]	; 0x84
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
   dd00a:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   dd00c:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
inline void Conv(const ConvParams& params, const RuntimeShape& input_shape,
                 const uint8* input_data, const RuntimeShape& filter_shape,
                 const uint8* filter_data, const RuntimeShape& bias_shape,
                 const int32* bias_data, const RuntimeShape& output_shape,
                 uint8* output_data, const RuntimeShape& im2col_shape,
                 uint8* im2col_data, void* cpu_backend_context) {
   dd00e:	f8dd 80bc 	ldr.w	r8, [sp, #188]	; 0xbc
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
   dd012:	4293      	cmp	r3, r2
inline void Conv(const ConvParams& params, const RuntimeShape& input_shape,
                 const uint8* input_data, const RuntimeShape& filter_shape,
                 const uint8* filter_data, const RuntimeShape& bias_shape,
                 const int32* bias_data, const RuntimeShape& output_shape,
                 uint8* output_data, const RuntimeShape& im2col_shape,
                 uint8* im2col_data, void* cpu_backend_context) {
   dd014:	4689      	mov	r9, r1
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
   dd016:	dd01      	ble.n	dd01c <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x5c>
   dd018:	f008 fa6c 	bl	e54f4 <abort>

  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dd01c:	680b      	ldr	r3, [r1, #0]
   dd01e:	2b04      	cmp	r3, #4
   dd020:	d1fa      	bne.n	dd018 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x58>
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
   dd022:	f8da 3000 	ldr.w	r3, [sl]
   dd026:	2b04      	cmp	r3, #4
   dd028:	d1f6      	bne.n	dd018 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x58>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   dd02a:	f8d8 3000 	ldr.w	r3, [r8]
   dd02e:	2b04      	cmp	r3, #4
   dd030:	d1f2      	bne.n	dd018 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x58>
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dd032:	2300      	movs	r3, #0
   dd034:	4619      	mov	r1, r3
   dd036:	4642      	mov	r2, r8
   dd038:	4648      	mov	r0, r9
   dd03a:	f7ff fe52 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
   dd03e:	2303      	movs	r3, #3
   dd040:	4619      	mov	r1, r3
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);

  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dd042:	9018      	str	r0, [sp, #96]	; 0x60
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
   dd044:	4652      	mov	r2, sl
   dd046:	4648      	mov	r0, r9
   dd048:	f7ff fe4b 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
   dd04c:	2303      	movs	r3, #3

  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
   dd04e:	9019      	str	r0, [sp, #100]	; 0x64
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
   dd050:	4642      	mov	r2, r8
   dd052:	2100      	movs	r1, #0
   dd054:	4650      	mov	r0, sl
   dd056:	f7ff fe44 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  if (bias_data) {
   dd05a:	9b2e      	ldr	r3, [sp, #184]	; 0xb8
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
   dd05c:	900c      	str	r0, [sp, #48]	; 0x30
  if (bias_data) {
   dd05e:	b12b      	cbz	r3, dd06c <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0xac>
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
   dd060:	982d      	ldr	r0, [sp, #180]	; 0xb4
   dd062:	f7ff fe2e 	bl	dccc2 <_ZNK6tflite12RuntimeShape8FlatSizeEv>
   dd066:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   dd068:	4283      	cmp	r3, r0
   dd06a:	d1d5      	bne.n	dd018 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x58>
  }
  const int input_height = input_shape.Dims(1);
   dd06c:	2101      	movs	r1, #1
   dd06e:	4648      	mov	r0, r9
   dd070:	f7fa fa86 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   dd074:	2102      	movs	r1, #2
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
  if (bias_data) {
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
  }
  const int input_height = input_shape.Dims(1);
   dd076:	901a      	str	r0, [sp, #104]	; 0x68
  const int input_width = input_shape.Dims(2);
   dd078:	4648      	mov	r0, r9
   dd07a:	f7fa fa81 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_height = filter_shape.Dims(1);
   dd07e:	2101      	movs	r1, #1
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
  if (bias_data) {
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
  }
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   dd080:	901b      	str	r0, [sp, #108]	; 0x6c
  const int filter_height = filter_shape.Dims(1);
   dd082:	4650      	mov	r0, sl
   dd084:	f7fa fa7c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_width = filter_shape.Dims(2);
   dd088:	2102      	movs	r1, #2
  if (bias_data) {
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
  }
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
   dd08a:	901c      	str	r0, [sp, #112]	; 0x70
  const int filter_width = filter_shape.Dims(2);
   dd08c:	4650      	mov	r0, sl
   dd08e:	f7fa fa77 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   dd092:	2101      	movs	r1, #1
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
  }
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
   dd094:	901d      	str	r0, [sp, #116]	; 0x74
  const int output_height = output_shape.Dims(1);
   dd096:	4640      	mov	r0, r8
   dd098:	f7fa fa72 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   dd09c:	2102      	movs	r1, #2
  }
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   dd09e:	901e      	str	r0, [sp, #120]	; 0x78
  const int output_width = output_shape.Dims(2);
   dd0a0:	4640      	mov	r0, r8
   dd0a2:	f7fa fa6d 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  for (int batch = 0; batch < batches; ++batch) {
   dd0a6:	f04f 0b00 	mov.w	fp, #0
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   dd0aa:	901f      	str	r0, [sp, #124]	; 0x7c
  for (int batch = 0; batch < batches; ++batch) {
   dd0ac:	9b18      	ldr	r3, [sp, #96]	; 0x60
   dd0ae:	459b      	cmp	fp, r3
   dd0b0:	f280 8093 	bge.w	dd1da <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x21a>
   dd0b4:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dd0b6:	425b      	negs	r3, r3
   dd0b8:	9309      	str	r3, [sp, #36]	; 0x24
   dd0ba:	2300      	movs	r3, #0
   dd0bc:	9304      	str	r3, [sp, #16]
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dd0be:	9b04      	ldr	r3, [sp, #16]
   dd0c0:	9a1e      	ldr	r2, [sp, #120]	; 0x78
   dd0c2:	4293      	cmp	r3, r2
   dd0c4:	f280 8086 	bge.w	dd1d4 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x214>
   dd0c8:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dd0ca:	425b      	negs	r3, r3
   dd0cc:	9308      	str	r3, [sp, #32]
   dd0ce:	2300      	movs	r3, #0
   dd0d0:	9305      	str	r3, [sp, #20]
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dd0d2:	9b05      	ldr	r3, [sp, #20]
   dd0d4:	9a1f      	ldr	r2, [sp, #124]	; 0x7c
   dd0d6:	4293      	cmp	r3, r2
   dd0d8:	da74      	bge.n	dd1c4 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x204>
   dd0da:	2400      	movs	r4, #0
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
   dd0dc:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   dd0de:	429c      	cmp	r4, r3
   dd0e0:	da68      	bge.n	dd1b4 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x1f4>
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          int32 acc = 0;
   dd0e2:	2500      	movs	r5, #0
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
   dd0e4:	9e09      	ldr	r6, [sp, #36]	; 0x24
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          int32 acc = 0;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   dd0e6:	9506      	str	r5, [sp, #24]
   dd0e8:	9b06      	ldr	r3, [sp, #24]
   dd0ea:	9a1c      	ldr	r2, [sp, #112]	; 0x70
   dd0ec:	4293      	cmp	r3, r2
   dd0ee:	da41      	bge.n	dd174 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x1b4>
   dd0f0:	2300      	movs	r3, #0
   dd0f2:	9f08      	ldr	r7, [sp, #32]
   dd0f4:	9307      	str	r3, [sp, #28]
            for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   dd0f6:	9b07      	ldr	r3, [sp, #28]
   dd0f8:	9a1d      	ldr	r2, [sp, #116]	; 0x74
   dd0fa:	4293      	cmp	r3, r2
   dd0fc:	da34      	bge.n	dd168 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x1a8>
   dd0fe:	2300      	movs	r3, #0
   dd100:	9303      	str	r3, [sp, #12]
              for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
   dd102:	9b03      	ldr	r3, [sp, #12]
   dd104:	9a19      	ldr	r2, [sp, #100]	; 0x64
   dd106:	4293      	cmp	r3, r2
   dd108:	da28      	bge.n	dd15c <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x19c>
                const int in_x = in_x_origin + dilation_width_factor * filter_x;
                const int in_y =
                    in_y_origin + dilation_height_factor * filter_y;
                // If the location is outside the bounds of the input image,
                // use zero as a default value.
                if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
   dd10a:	2f00      	cmp	r7, #0
   dd10c:	db23      	blt.n	dd156 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x196>
   dd10e:	9b1b      	ldr	r3, [sp, #108]	; 0x6c
   dd110:	42bb      	cmp	r3, r7
   dd112:	dd20      	ble.n	dd156 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x196>
   dd114:	2e00      	cmp	r6, #0
   dd116:	db1e      	blt.n	dd156 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x196>
   dd118:	9b1a      	ldr	r3, [sp, #104]	; 0x68
   dd11a:	42b3      	cmp	r3, r6
   dd11c:	dd1b      	ble.n	dd156 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x196>
                    (in_y < input_height)) {
                  int32 input_val = input_data[Offset(input_shape, batch, in_y,
   dd11e:	9b03      	ldr	r3, [sp, #12]
   dd120:	9300      	str	r3, [sp, #0]
   dd122:	4632      	mov	r2, r6
   dd124:	463b      	mov	r3, r7
   dd126:	4659      	mov	r1, fp
   dd128:	4648      	mov	r0, r9
   dd12a:	f7fa fa8e 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                                                      in_x, in_channel)];
                  int32 filter_val =
                      filter_data[Offset(filter_shape, out_channel, filter_y,
   dd12e:	9b03      	ldr	r3, [sp, #12]
                    in_y_origin + dilation_height_factor * filter_y;
                // If the location is outside the bounds of the input image,
                // use zero as a default value.
                if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                    (in_y < input_height)) {
                  int32 input_val = input_data[Offset(input_shape, batch, in_y,
   dd130:	9020      	str	r0, [sp, #128]	; 0x80
                                                      in_x, in_channel)];
                  int32 filter_val =
                      filter_data[Offset(filter_shape, out_channel, filter_y,
   dd132:	9300      	str	r3, [sp, #0]
   dd134:	9a06      	ldr	r2, [sp, #24]
   dd136:	9b07      	ldr	r3, [sp, #28]
   dd138:	4621      	mov	r1, r4
   dd13a:	4650      	mov	r0, sl
   dd13c:	f7fa fa85 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                                         filter_x, in_channel)];
                  acc +=
                      (filter_val + filter_offset) * (input_val + input_offset);
   dd140:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   dd142:	9a14      	ldr	r2, [sp, #80]	; 0x50
   dd144:	5c1b      	ldrb	r3, [r3, r0]
   dd146:	9920      	ldr	r1, [sp, #128]	; 0x80
   dd148:	4413      	add	r3, r2
   dd14a:	9a21      	ldr	r2, [sp, #132]	; 0x84
   dd14c:	5c52      	ldrb	r2, [r2, r1]
   dd14e:	9913      	ldr	r1, [sp, #76]	; 0x4c
   dd150:	440a      	add	r2, r1
   dd152:	fb02 5503 	mla	r5, r2, r3, r5
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          int32 acc = 0;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
            for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
              for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
   dd156:	9b03      	ldr	r3, [sp, #12]
   dd158:	3301      	adds	r3, #1
   dd15a:	e7d1      	b.n	dd100 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x140>
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          int32 acc = 0;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
            for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   dd15c:	9b07      	ldr	r3, [sp, #28]
   dd15e:	3301      	adds	r3, #1
   dd160:	9307      	str	r3, [sp, #28]
   dd162:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   dd164:	441f      	add	r7, r3
   dd166:	e7c6      	b.n	dd0f6 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x136>
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          int32 acc = 0;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   dd168:	9b06      	ldr	r3, [sp, #24]
   dd16a:	3301      	adds	r3, #1
   dd16c:	9306      	str	r3, [sp, #24]
   dd16e:	9b10      	ldr	r3, [sp, #64]	; 0x40
   dd170:	441e      	add	r6, r3
   dd172:	e7b9      	b.n	dd0e8 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x128>
                      (filter_val + filter_offset) * (input_val + input_offset);
                }
              }
            }
          }
          if (bias_data) {
   dd174:	9b2e      	ldr	r3, [sp, #184]	; 0xb8
   dd176:	b113      	cbz	r3, dd17e <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x1be>
            acc += bias_data[out_channel];
   dd178:	f853 3024 	ldr.w	r3, [r3, r4, lsl #2]
   dd17c:	441d      	add	r5, r3
          }
          acc = MultiplyByQuantizedMultiplier(acc, output_multiplier,
   dd17e:	9a17      	ldr	r2, [sp, #92]	; 0x5c
   dd180:	9916      	ldr	r1, [sp, #88]	; 0x58
   dd182:	4628      	mov	r0, r5
   dd184:	f7ff fdbc 	bl	dcd00 <_ZN6tflite29MultiplyByQuantizedMultiplierElli>
                                              output_shift);
          acc += output_offset;
   dd188:	9b15      	ldr	r3, [sp, #84]	; 0x54
          acc = std::max(acc, output_activation_min);
          acc = std::min(acc, output_activation_max);
          output_data[Offset(output_shape, batch, out_y, out_x, out_channel)] =
   dd18a:	9400      	str	r4, [sp, #0]
          if (bias_data) {
            acc += bias_data[out_channel];
          }
          acc = MultiplyByQuantizedMultiplier(acc, output_multiplier,
                                              output_shift);
          acc += output_offset;
   dd18c:	4418      	add	r0, r3
   dd18e:	9b0a      	ldr	r3, [sp, #40]	; 0x28
          acc = std::max(acc, output_activation_min);
          acc = std::min(acc, output_activation_max);
          output_data[Offset(output_shape, batch, out_y, out_x, out_channel)] =
   dd190:	9a04      	ldr	r2, [sp, #16]
   dd192:	4283      	cmp	r3, r0
   dd194:	bfb8      	it	lt
   dd196:	4603      	movlt	r3, r0
   dd198:	461d      	mov	r5, r3
   dd19a:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   dd19c:	429d      	cmp	r5, r3
   dd19e:	bfa8      	it	ge
   dd1a0:	461d      	movge	r5, r3
   dd1a2:	4659      	mov	r1, fp
   dd1a4:	9b05      	ldr	r3, [sp, #20]
   dd1a6:	4640      	mov	r0, r8
   dd1a8:	f7fa fa4f 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              static_cast<uint8>(acc);
   dd1ac:	9b30      	ldr	r3, [sp, #192]	; 0xc0
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
   dd1ae:	3401      	adds	r4, #1
                                              output_shift);
          acc += output_offset;
          acc = std::max(acc, output_activation_min);
          acc = std::min(acc, output_activation_max);
          output_data[Offset(output_shape, batch, out_y, out_x, out_channel)] =
              static_cast<uint8>(acc);
   dd1b0:	541d      	strb	r5, [r3, r0]
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
   dd1b2:	e793      	b.n	dd0dc <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x11c>
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dd1b4:	9b05      	ldr	r3, [sp, #20]
   dd1b6:	9a0d      	ldr	r2, [sp, #52]	; 0x34
   dd1b8:	3301      	adds	r3, #1
   dd1ba:	9305      	str	r3, [sp, #20]
   dd1bc:	9b08      	ldr	r3, [sp, #32]
   dd1be:	4413      	add	r3, r2
   dd1c0:	9308      	str	r3, [sp, #32]
   dd1c2:	e786      	b.n	dd0d2 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0x112>
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dd1c4:	9b04      	ldr	r3, [sp, #16]
   dd1c6:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   dd1c8:	3301      	adds	r3, #1
   dd1ca:	9304      	str	r3, [sp, #16]
   dd1cc:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dd1ce:	4413      	add	r3, r2
   dd1d0:	9309      	str	r3, [sp, #36]	; 0x24
   dd1d2:	e774      	b.n	dd0be <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0xfe>
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
   dd1d4:	f10b 0b01 	add.w	fp, fp, #1
   dd1d8:	e768      	b.n	dd0ac <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv+0xec>
              static_cast<uint8>(acc);
        }
      }
    }
  }
}
   dd1da:	b023      	add	sp, #140	; 0x8c
   dd1dc:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dd1e0 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa>:
    const ConvParams& params, const int32* output_multiplier,
    const int32* output_shift, const RuntimeShape& input_shape,
    const int8* input_data, const RuntimeShape& filter_shape,
    const int8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int8* output_data) {
   dd1e0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dd1e4:	b09d      	sub	sp, #116	; 0x74
   dd1e6:	4699      	mov	r9, r3
  // Get parameters.
  const int32 input_offset = params.input_offset;  // r = s(q - Z)
   dd1e8:	6943      	ldr	r3, [r0, #20]
   dd1ea:	9309      	str	r3, [sp, #36]	; 0x24
  const int stride_width = params.stride_width;
   dd1ec:	f9b0 300a 	ldrsh.w	r3, [r0, #10]
   dd1f0:	930a      	str	r3, [sp, #40]	; 0x28
  const int stride_height = params.stride_height;
   dd1f2:	f9b0 300c 	ldrsh.w	r3, [r0, #12]
   dd1f6:	930b      	str	r3, [sp, #44]	; 0x2c
  const int dilation_width_factor = params.dilation_width_factor;
   dd1f8:	f9b0 300e 	ldrsh.w	r3, [r0, #14]
   dd1fc:	930c      	str	r3, [sp, #48]	; 0x30
  const int dilation_height_factor = params.dilation_height_factor;
   dd1fe:	f9b0 3010 	ldrsh.w	r3, [r0, #16]
   dd202:	930d      	str	r3, [sp, #52]	; 0x34
  const int pad_width = params.padding_values.width;
   dd204:	f9b0 3002 	ldrsh.w	r3, [r0, #2]
   dd208:	930e      	str	r3, [sp, #56]	; 0x38
  const int pad_height = params.padding_values.height;
   dd20a:	f9b0 3004 	ldrsh.w	r3, [r0, #4]
   dd20e:	930f      	str	r3, [sp, #60]	; 0x3c
  const int32 output_offset = params.output_offset;
   dd210:	69c3      	ldr	r3, [r0, #28]
   dd212:	9310      	str	r3, [sp, #64]	; 0x40
  const int32 output_activation_min = std::numeric_limits<int8_t>::min();
  const int32 output_activation_max = std::numeric_limits<int8_t>::max();

  // Sanity check.
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dd214:	f8d9 3000 	ldr.w	r3, [r9]
    const ConvParams& params, const int32* output_multiplier,
    const int32* output_shift, const RuntimeShape& input_shape,
    const int8* input_data, const RuntimeShape& filter_shape,
    const int8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int8* output_data) {
   dd218:	911a      	str	r1, [sp, #104]	; 0x68
  const int32 output_activation_min = std::numeric_limits<int8_t>::min();
  const int32 output_activation_max = std::numeric_limits<int8_t>::max();

  // Sanity check.
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dd21a:	2b04      	cmp	r3, #4
    const ConvParams& params, const int32* output_multiplier,
    const int32* output_shift, const RuntimeShape& input_shape,
    const int8* input_data, const RuntimeShape& filter_shape,
    const int8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int8* output_data) {
   dd21c:	921b      	str	r2, [sp, #108]	; 0x6c
   dd21e:	f8dd b09c 	ldr.w	fp, [sp, #156]	; 0x9c
  const int32 output_activation_min = std::numeric_limits<int8_t>::min();
  const int32 output_activation_max = std::numeric_limits<int8_t>::max();

  // Sanity check.
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dd222:	d001      	beq.n	dd228 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x48>
   dd224:	f008 f966 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
   dd228:	f8db 3000 	ldr.w	r3, [fp]
   dd22c:	2b04      	cmp	r3, #4
   dd22e:	d1f9      	bne.n	dd224 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x44>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   dd230:	9b2b      	ldr	r3, [sp, #172]	; 0xac
   dd232:	681b      	ldr	r3, [r3, #0]
   dd234:	2b04      	cmp	r3, #4
   dd236:	d1f5      	bne.n	dd224 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x44>
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dd238:	2300      	movs	r3, #0
   dd23a:	4619      	mov	r1, r3
   dd23c:	9a2b      	ldr	r2, [sp, #172]	; 0xac
   dd23e:	4648      	mov	r0, r9
   dd240:	f7ff fd4f 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
   dd244:	2303      	movs	r3, #3
   dd246:	4619      	mov	r1, r3
  // Sanity check.
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dd248:	9011      	str	r0, [sp, #68]	; 0x44
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
   dd24a:	465a      	mov	r2, fp
   dd24c:	4648      	mov	r0, r9
   dd24e:	f7ff fd48 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
   dd252:	2303      	movs	r3, #3
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
   dd254:	9012      	str	r0, [sp, #72]	; 0x48
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
   dd256:	9a2b      	ldr	r2, [sp, #172]	; 0xac
   dd258:	2100      	movs	r1, #0
   dd25a:	4658      	mov	r0, fp
   dd25c:	f7ff fd41 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  if (bias_data) {
   dd260:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int input_depth = MatchingDim(input_shape, 3, filter_shape, 3);
  const int output_depth = MatchingDim(filter_shape, 0, output_shape, 3);
   dd262:	9008      	str	r0, [sp, #32]
  if (bias_data) {
   dd264:	b12b      	cbz	r3, dd272 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x92>
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
   dd266:	9829      	ldr	r0, [sp, #164]	; 0xa4
   dd268:	f7ff fd2b 	bl	dccc2 <_ZNK6tflite12RuntimeShape8FlatSizeEv>
   dd26c:	9b08      	ldr	r3, [sp, #32]
   dd26e:	4283      	cmp	r3, r0
   dd270:	d1d8      	bne.n	dd224 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x44>
  }

  // Check dimensions of the tensors.
  const int input_height = input_shape.Dims(1);
   dd272:	2101      	movs	r1, #1
   dd274:	4648      	mov	r0, r9
   dd276:	f7fa f983 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   dd27a:	2102      	movs	r1, #2
  if (bias_data) {
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
  }

  // Check dimensions of the tensors.
  const int input_height = input_shape.Dims(1);
   dd27c:	9013      	str	r0, [sp, #76]	; 0x4c
  const int input_width = input_shape.Dims(2);
   dd27e:	4648      	mov	r0, r9
   dd280:	f7fa f97e 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_height = filter_shape.Dims(1);
   dd284:	2101      	movs	r1, #1
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
  }

  // Check dimensions of the tensors.
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   dd286:	9014      	str	r0, [sp, #80]	; 0x50
  const int filter_height = filter_shape.Dims(1);
   dd288:	4658      	mov	r0, fp
   dd28a:	f7fa f979 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_width = filter_shape.Dims(2);
   dd28e:	2102      	movs	r1, #2
  }

  // Check dimensions of the tensors.
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
   dd290:	9015      	str	r0, [sp, #84]	; 0x54
  const int filter_width = filter_shape.Dims(2);
   dd292:	4658      	mov	r0, fp
   dd294:	f7fa f974 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   dd298:	2101      	movs	r1, #1

  // Check dimensions of the tensors.
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
   dd29a:	9016      	str	r0, [sp, #88]	; 0x58
  const int output_height = output_shape.Dims(1);
   dd29c:	982b      	ldr	r0, [sp, #172]	; 0xac
   dd29e:	f7fa f96f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   dd2a2:	2102      	movs	r1, #2
  // Check dimensions of the tensors.
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   dd2a4:	9017      	str	r0, [sp, #92]	; 0x5c
  const int output_width = output_shape.Dims(2);
   dd2a6:	982b      	ldr	r0, [sp, #172]	; 0xac
   dd2a8:	f7fa f96a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  for (int batch = 0; batch < batches; ++batch) {
   dd2ac:	f04f 0a00 	mov.w	sl, #0
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   dd2b0:	9018      	str	r0, [sp, #96]	; 0x60
  for (int batch = 0; batch < batches; ++batch) {
   dd2b2:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dd2b4:	459a      	cmp	sl, r3
   dd2b6:	f280 8091 	bge.w	dd3dc <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x1fc>
   dd2ba:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   dd2bc:	425b      	negs	r3, r3
   dd2be:	9307      	str	r3, [sp, #28]
   dd2c0:	2300      	movs	r3, #0
   dd2c2:	9302      	str	r3, [sp, #8]
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dd2c4:	9b02      	ldr	r3, [sp, #8]
   dd2c6:	9a17      	ldr	r2, [sp, #92]	; 0x5c
   dd2c8:	4293      	cmp	r3, r2
   dd2ca:	da6b      	bge.n	dd3a4 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x1c4>
   dd2cc:	9b0e      	ldr	r3, [sp, #56]	; 0x38
   dd2ce:	425b      	negs	r3, r3
   dd2d0:	9306      	str	r3, [sp, #24]
   dd2d2:	2300      	movs	r3, #0
   dd2d4:	9303      	str	r3, [sp, #12]
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dd2d6:	9b03      	ldr	r3, [sp, #12]
   dd2d8:	9a18      	ldr	r2, [sp, #96]	; 0x60
   dd2da:	4293      	cmp	r3, r2
   dd2dc:	da5a      	bge.n	dd394 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x1b4>
   dd2de:	2400      	movs	r4, #0
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
   dd2e0:	9b08      	ldr	r3, [sp, #32]
   dd2e2:	429c      	cmp	r4, r3
   dd2e4:	da4e      	bge.n	dd384 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x1a4>
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          int32 acc = 0;
   dd2e6:	2500      	movs	r5, #0
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
   dd2e8:	9f07      	ldr	r7, [sp, #28]
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          int32 acc = 0;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   dd2ea:	9504      	str	r5, [sp, #16]
   dd2ec:	9b04      	ldr	r3, [sp, #16]
   dd2ee:	9a15      	ldr	r2, [sp, #84]	; 0x54
   dd2f0:	4293      	cmp	r3, r2
   dd2f2:	da24      	bge.n	dd33e <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x15e>
   dd2f4:	2300      	movs	r3, #0
   dd2f6:	f8dd 8018 	ldr.w	r8, [sp, #24]
   dd2fa:	9305      	str	r3, [sp, #20]
            for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   dd2fc:	9b05      	ldr	r3, [sp, #20]
   dd2fe:	9a16      	ldr	r2, [sp, #88]	; 0x58
   dd300:	4293      	cmp	r3, r2
   dd302:	da16      	bge.n	dd332 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x152>
   dd304:	2600      	movs	r6, #0
              for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
   dd306:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dd308:	429e      	cmp	r6, r3
   dd30a:	da0c      	bge.n	dd326 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x146>
                const int in_x = in_x_origin + dilation_width_factor * filter_x;
                const int in_y =
                    in_y_origin + dilation_height_factor * filter_y;
                // Zero padding by omitting the areas outside the image.
                const bool is_point_inside_image =
                    (in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
   dd30c:	f1b8 0f00 	cmp.w	r8, #0
   dd310:	db07      	blt.n	dd322 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x142>
   dd312:	9b14      	ldr	r3, [sp, #80]	; 0x50
   dd314:	4543      	cmp	r3, r8
   dd316:	dd04      	ble.n	dd322 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x142>
   dd318:	2f00      	cmp	r7, #0
   dd31a:	db02      	blt.n	dd322 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x142>
   dd31c:	9b13      	ldr	r3, [sp, #76]	; 0x4c
   dd31e:	42bb      	cmp	r3, r7
   dd320:	dc43      	bgt.n	dd3aa <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x1ca>
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          int32 acc = 0;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
            for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
              for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
   dd322:	3601      	adds	r6, #1
   dd324:	e7ef      	b.n	dd306 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x126>
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          int32 acc = 0;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
            for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   dd326:	9b05      	ldr	r3, [sp, #20]
   dd328:	3301      	adds	r3, #1
   dd32a:	9305      	str	r3, [sp, #20]
   dd32c:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   dd32e:	4498      	add	r8, r3
   dd330:	e7e4      	b.n	dd2fc <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x11c>
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
          const int in_x_origin = (out_x * stride_width) - pad_width;
          const int in_y_origin = (out_y * stride_height) - pad_height;
          int32 acc = 0;
          for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   dd332:	9b04      	ldr	r3, [sp, #16]
   dd334:	3301      	adds	r3, #1
   dd336:	9304      	str	r3, [sp, #16]
   dd338:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   dd33a:	441f      	add	r7, r3
   dd33c:	e7d6      	b.n	dd2ec <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x10c>
                }
              }
            }
          }

          if (bias_data) {
   dd33e:	9b2a      	ldr	r3, [sp, #168]	; 0xa8
   dd340:	b113      	cbz	r3, dd348 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x168>
            acc += bias_data[out_channel];
   dd342:	f853 3024 	ldr.w	r3, [r3, r4, lsl #2]
   dd346:	441d      	add	r5, r3
          }
          acc = MultiplyByQuantizedMultiplier(
   dd348:	9b1b      	ldr	r3, [sp, #108]	; 0x6c
   dd34a:	f853 2024 	ldr.w	r2, [r3, r4, lsl #2]
   dd34e:	9b1a      	ldr	r3, [sp, #104]	; 0x68
   dd350:	4628      	mov	r0, r5
   dd352:	f853 1024 	ldr.w	r1, [r3, r4, lsl #2]
   dd356:	f7ff fcd3 	bl	dcd00 <_ZN6tflite29MultiplyByQuantizedMultiplierElli>
              acc, output_multiplier[out_channel], output_shift[out_channel]);
          acc += output_offset;
   dd35a:	9b10      	ldr	r3, [sp, #64]	; 0x40
          acc = std::max(acc, output_activation_min);
          acc = std::min(acc, output_activation_max);
          output_data[Offset(output_shape, batch, out_y, out_x, out_channel)] =
   dd35c:	9400      	str	r4, [sp, #0]
   dd35e:	f06f 057f 	mvn.w	r5, #127	; 0x7f
          if (bias_data) {
            acc += bias_data[out_channel];
          }
          acc = MultiplyByQuantizedMultiplier(
              acc, output_multiplier[out_channel], output_shift[out_channel]);
          acc += output_offset;
   dd362:	4418      	add	r0, r3
   dd364:	4285      	cmp	r5, r0
   dd366:	bfb8      	it	lt
   dd368:	4605      	movlt	r5, r0
          acc = std::max(acc, output_activation_min);
          acc = std::min(acc, output_activation_max);
          output_data[Offset(output_shape, batch, out_y, out_x, out_channel)] =
   dd36a:	9b03      	ldr	r3, [sp, #12]
   dd36c:	9a02      	ldr	r2, [sp, #8]
   dd36e:	982b      	ldr	r0, [sp, #172]	; 0xac
   dd370:	4651      	mov	r1, sl
   dd372:	f7fa f96a 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              static_cast<int8_t>(acc);
   dd376:	2d7f      	cmp	r5, #127	; 0x7f
   dd378:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   dd37a:	bfa8      	it	ge
   dd37c:	257f      	movge	r5, #127	; 0x7f
   dd37e:	541d      	strb	r5, [r3, r0]
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int out_channel = 0; out_channel < output_depth; ++out_channel) {
   dd380:	3401      	adds	r4, #1
   dd382:	e7ad      	b.n	dd2e0 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x100>
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dd384:	9b03      	ldr	r3, [sp, #12]
   dd386:	9a0a      	ldr	r2, [sp, #40]	; 0x28
   dd388:	3301      	adds	r3, #1
   dd38a:	9303      	str	r3, [sp, #12]
   dd38c:	9b06      	ldr	r3, [sp, #24]
   dd38e:	4413      	add	r3, r2
   dd390:	9306      	str	r3, [sp, #24]
   dd392:	e7a0      	b.n	dd2d6 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0xf6>
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dd394:	9b02      	ldr	r3, [sp, #8]
   dd396:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dd398:	3301      	adds	r3, #1
   dd39a:	9302      	str	r3, [sp, #8]
   dd39c:	9b07      	ldr	r3, [sp, #28]
   dd39e:	4413      	add	r3, r2
   dd3a0:	9307      	str	r3, [sp, #28]
   dd3a2:	e78f      	b.n	dd2c4 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0xe4>
  const int input_width = input_shape.Dims(2);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  for (int batch = 0; batch < batches; ++batch) {
   dd3a4:	f10a 0a01 	add.w	sl, sl, #1
   dd3a8:	e783      	b.n	dd2b2 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0xd2>
                // Zero padding by omitting the areas outside the image.
                const bool is_point_inside_image =
                    (in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                    (in_y < input_height);
                if (is_point_inside_image) {
                  int32 input_val = input_data[Offset(input_shape, batch, in_y,
   dd3aa:	4643      	mov	r3, r8
   dd3ac:	463a      	mov	r2, r7
   dd3ae:	4651      	mov	r1, sl
   dd3b0:	9600      	str	r6, [sp, #0]
   dd3b2:	4648      	mov	r0, r9
   dd3b4:	f7fa f949 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                                                      in_x, in_channel)];
                  int32 filter_val =
                      filter_data[Offset(filter_shape, out_channel, filter_y,
   dd3b8:	9b05      	ldr	r3, [sp, #20]
                // Zero padding by omitting the areas outside the image.
                const bool is_point_inside_image =
                    (in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                    (in_y < input_height);
                if (is_point_inside_image) {
                  int32 input_val = input_data[Offset(input_shape, batch, in_y,
   dd3ba:	9019      	str	r0, [sp, #100]	; 0x64
                                                      in_x, in_channel)];
                  int32 filter_val =
                      filter_data[Offset(filter_shape, out_channel, filter_y,
   dd3bc:	9a04      	ldr	r2, [sp, #16]
   dd3be:	9600      	str	r6, [sp, #0]
   dd3c0:	4621      	mov	r1, r4
   dd3c2:	4658      	mov	r0, fp
   dd3c4:	f7fa f941 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                  // long as the filter size (filter_y * filter_x * in_channel)
                  // does not exceed 2^16, which is the case in all the models
                  // we have seen so far.
                  // TODO(jianlijianli): Add a check to make sure the
                  // accumulator depth is smaller than 2^16.
                  acc += filter_val * (input_val + input_offset);
   dd3c8:	9a19      	ldr	r2, [sp, #100]	; 0x64
   dd3ca:	9b26      	ldr	r3, [sp, #152]	; 0x98
   dd3cc:	569b      	ldrsb	r3, [r3, r2]
   dd3ce:	9a09      	ldr	r2, [sp, #36]	; 0x24
   dd3d0:	4413      	add	r3, r2
   dd3d2:	9a28      	ldr	r2, [sp, #160]	; 0xa0
   dd3d4:	5612      	ldrsb	r2, [r2, r0]
   dd3d6:	fb02 5503 	mla	r5, r2, r3, r5
   dd3da:	e7a2      	b.n	dd322 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x142>
              static_cast<int8_t>(acc);
        }
      }
    }
  }
}
   dd3dc:	b01d      	add	sp, #116	; 0x74
   dd3de:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dd3e2 <_ZN6tflite14ComputeOutSizeE13TfLitePaddingiiii>:

// Matching GetWindowedOutputSize in TensorFlow.
inline int ComputeOutSize(TfLitePadding padding, int image_size,
                          int filter_size, int stride, int dilation_rate = 1) {
  int effective_filter_size = (filter_size - 1) * dilation_rate + 1;
  switch (padding) {
   dd3e2:	2801      	cmp	r0, #1
   dd3e4:	d008      	beq.n	dd3f8 <_ZN6tflite14ComputeOutSizeE13TfLitePaddingiiii+0x16>
   dd3e6:	2802      	cmp	r0, #2
   dd3e8:	d10b      	bne.n	dd402 <_ZN6tflite14ComputeOutSizeE13TfLitePaddingiiii+0x20>
    case kTfLitePaddingSame:
      return (image_size + stride - 1) / stride;
    case kTfLitePaddingValid:
      return (image_size + stride - effective_filter_size) / stride;
   dd3ea:	9800      	ldr	r0, [sp, #0]
   dd3ec:	3a01      	subs	r2, #1
   dd3ee:	4350      	muls	r0, r2
   dd3f0:	4419      	add	r1, r3
   dd3f2:	3001      	adds	r0, #1
   dd3f4:	1a09      	subs	r1, r1, r0
   dd3f6:	e001      	b.n	dd3fc <_ZN6tflite14ComputeOutSizeE13TfLitePaddingiiii+0x1a>
inline int ComputeOutSize(TfLitePadding padding, int image_size,
                          int filter_size, int stride, int dilation_rate = 1) {
  int effective_filter_size = (filter_size - 1) * dilation_rate + 1;
  switch (padding) {
    case kTfLitePaddingSame:
      return (image_size + stride - 1) / stride;
   dd3f8:	4419      	add	r1, r3
   dd3fa:	3901      	subs	r1, #1
    case kTfLitePaddingValid:
      return (image_size + stride - effective_filter_size) / stride;
   dd3fc:	fb91 f0f3 	sdiv	r0, r1, r3
   dd400:	4770      	bx	lr
    default:
      return 0;
   dd402:	2000      	movs	r0, #0
  }
}
   dd404:	4770      	bx	lr
	...

000dd408 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE>:

TfLiteStatus CalculateOpData(TfLiteContext* context, TfLiteNode* node,
                             TfLiteConvParams* params, int width, int height,
                             int filter_width, int filter_height, int out_width,
                             int out_height, const TfLiteType data_type,
                             OpData* data) {
   dd408:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dd40c:	469a      	mov	sl, r3
  bool has_bias = node->inputs->size == 3;
   dd40e:	680b      	ldr	r3, [r1, #0]
  // Check number of inputs/outputs
  TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);
   dd410:	681b      	ldr	r3, [r3, #0]

TfLiteStatus CalculateOpData(TfLiteContext* context, TfLiteNode* node,
                             TfLiteConvParams* params, int width, int height,
                             int filter_width, int filter_height, int out_width,
                             int out_height, const TfLiteType data_type,
                             OpData* data) {
   dd412:	b08d      	sub	sp, #52	; 0x34
  bool has_bias = node->inputs->size == 3;
  // Check number of inputs/outputs
  TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);
   dd414:	3b02      	subs	r3, #2
   dd416:	2b01      	cmp	r3, #1

TfLiteStatus CalculateOpData(TfLiteContext* context, TfLiteNode* node,
                             TfLiteConvParams* params, int width, int height,
                             int filter_width, int filter_height, int out_width,
                             int out_height, const TfLiteType data_type,
                             OpData* data) {
   dd418:	4680      	mov	r8, r0
   dd41a:	4689      	mov	r9, r1
   dd41c:	4616      	mov	r6, r2
   dd41e:	9c1c      	ldr	r4, [sp, #112]	; 0x70
  bool has_bias = node->inputs->size == 3;
  // Check number of inputs/outputs
  TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);
   dd420:	d908      	bls.n	dd434 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x2c>
   dd422:	4b49      	ldr	r3, [pc, #292]	; (dd548 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x140>)
   dd424:	9300      	str	r3, [sp, #0]
   dd426:	6944      	ldr	r4, [r0, #20]
   dd428:	4a48      	ldr	r2, [pc, #288]	; (dd54c <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x144>)
   dd42a:	4949      	ldr	r1, [pc, #292]	; (dd550 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x148>)
   dd42c:	234f      	movs	r3, #79	; 0x4f
   dd42e:	47a0      	blx	r4
   dd430:	2001      	movs	r0, #1
   dd432:	e085      	b.n	dd540 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x138>
  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);
   dd434:	684b      	ldr	r3, [r1, #4]
   dd436:	681b      	ldr	r3, [r3, #0]
   dd438:	2b01      	cmp	r3, #1
   dd43a:	d00c      	beq.n	dd456 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x4e>
   dd43c:	9302      	str	r3, [sp, #8]
   dd43e:	4b45      	ldr	r3, [pc, #276]	; (dd554 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x14c>)
   dd440:	9301      	str	r3, [sp, #4]
   dd442:	2401      	movs	r4, #1
   dd444:	4b44      	ldr	r3, [pc, #272]	; (dd558 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x150>)
   dd446:	9300      	str	r3, [sp, #0]
   dd448:	9403      	str	r4, [sp, #12]
   dd44a:	6945      	ldr	r5, [r0, #20]
   dd44c:	4a3f      	ldr	r2, [pc, #252]	; (dd54c <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x144>)
   dd44e:	4943      	ldr	r1, [pc, #268]	; (dd55c <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x154>)
   dd450:	2350      	movs	r3, #80	; 0x50
   dd452:	47a8      	blx	r5
   dd454:	e7ec      	b.n	dd430 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x28>

  // Matching GetWindowedOutputSize in TensorFlow.
  auto padding = params->padding;
   dd456:	f892 b000 	ldrb.w	fp, [r2]
  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
      params->dilation_height_factor, params->dilation_width_factor, height,
      width, filter_height, filter_width, padding, &out_height, &out_width);
   dd45a:	6893      	ldr	r3, [r2, #8]
   dd45c:	68d5      	ldr	r5, [r2, #12]
   dd45e:	6917      	ldr	r7, [r2, #16]
   dd460:	9309      	str	r3, [sp, #36]	; 0x24

inline TfLitePaddingValues ComputePaddingHeightWidth(
    int stride_height, int stride_width, int dilation_rate_height,
    int dilation_rate_width, int in_height, int in_width, int filter_height,
    int filter_width, TfLitePadding padding, int* out_height, int* out_width) {
  *out_width = ComputeOutSize(padding, in_width, filter_width, stride_width,
   dd462:	4651      	mov	r1, sl
   dd464:	6853      	ldr	r3, [r2, #4]
   dd466:	9500      	str	r5, [sp, #0]
   dd468:	9a17      	ldr	r2, [sp, #92]	; 0x5c
   dd46a:	930a      	str	r3, [sp, #40]	; 0x28
   dd46c:	4658      	mov	r0, fp
   dd46e:	f7ff ffb8 	bl	dd3e2 <_ZN6tflite14ComputeOutSizeE13TfLitePaddingiiii>
                              dilation_rate_width);
  *out_height = ComputeOutSize(padding, in_height, filter_height, stride_height,
   dd472:	9700      	str	r7, [sp, #0]

inline TfLitePaddingValues ComputePaddingHeightWidth(
    int stride_height, int stride_width, int dilation_rate_height,
    int dilation_rate_width, int in_height, int in_width, int filter_height,
    int filter_width, TfLitePadding padding, int* out_height, int* out_width) {
  *out_width = ComputeOutSize(padding, in_width, filter_width, stride_width,
   dd474:	900b      	str	r0, [sp, #44]	; 0x2c
                              dilation_rate_width);
  *out_height = ComputeOutSize(padding, in_height, filter_height, stride_height,
   dd476:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dd478:	9a18      	ldr	r2, [sp, #96]	; 0x60
   dd47a:	9916      	ldr	r1, [sp, #88]	; 0x58
   dd47c:	4658      	mov	r0, fp
   dd47e:	f7ff ffb0 	bl	dd3e2 <_ZN6tflite14ComputeOutSizeE13TfLitePaddingiiii>
inline int ComputePaddingWithOffset(int stride, int dilation_rate, int in_size,
                                    int filter_size, int out_size,
                                    int* offset) {
  int effective_filter_size = (filter_size - 1) * dilation_rate + 1;
  int total_padding =
      ((out_size - 1) * stride + effective_filter_size - in_size);
   dd482:	9b18      	ldr	r3, [sp, #96]	; 0x60
   dd484:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dd486:	3b01      	subs	r3, #1
   dd488:	435f      	muls	r7, r3
   dd48a:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dd48c:	3701      	adds	r7, #1
   dd48e:	3801      	subs	r0, #1
   dd490:	fb03 7000 	mla	r0, r3, r0, r7
   dd494:	9b16      	ldr	r3, [sp, #88]	; 0x58
   dd496:	1ac0      	subs	r0, r0, r3
   dd498:	9b17      	ldr	r3, [sp, #92]	; 0x5c
   dd49a:	3b01      	subs	r3, #1
   dd49c:	436b      	muls	r3, r5
   dd49e:	1e55      	subs	r5, r2, #1
   dd4a0:	9a0a      	ldr	r2, [sp, #40]	; 0x28
   dd4a2:	3301      	adds	r3, #1
   dd4a4:	fb02 3505 	mla	r5, r2, r5, r3
   dd4a8:	ebca 0a05 	rsb	sl, sl, r5
  total_padding = total_padding > 0 ? total_padding : 0;
   dd4ac:	ea2a 7aea 	bic.w	sl, sl, sl, asr #31
   dd4b0:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
   dd4b4:	ea4f 036a 	mov.w	r3, sl, asr #1
   dd4b8:	6023      	str	r3, [r4, #0]
   dd4ba:	1043      	asrs	r3, r0, #1
   dd4bc:	6063      	str	r3, [r4, #4]

  // Note that quantized inference requires that all tensors have their
  // parameters set. This is usually done during quantized training.
  if (data_type != kTfLiteFloat32) {
   dd4be:	f89d 306c 	ldrb.w	r3, [sp, #108]	; 0x6c
  // Matching GetWindowedOutputSize in TensorFlow.
  auto padding = params->padding;
  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
      params->dilation_height_factor, params->dilation_width_factor, height,
      width, filter_height, filter_width, padding, &out_height, &out_width);
   dd4c2:	f00a 0501 	and.w	r5, sl, #1
   dd4c6:	f000 0001 	and.w	r0, r0, #1

  // Note that quantized inference requires that all tensors have their
  // parameters set. This is usually done during quantized training.
  if (data_type != kTfLiteFloat32) {
   dd4ca:	2b01      	cmp	r3, #1
  // Matching GetWindowedOutputSize in TensorFlow.
  auto padding = params->padding;
  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
      params->dilation_height_factor, params->dilation_width_factor, height,
      width, filter_height, filter_width, padding, &out_height, &out_width);
   dd4cc:	60a5      	str	r5, [r4, #8]
   dd4ce:	60e0      	str	r0, [r4, #12]

  // Note that quantized inference requires that all tensors have their
  // parameters set. This is usually done during quantized training.
  if (data_type != kTfLiteFloat32) {
   dd4d0:	d035      	beq.n	dd53e <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x136>
   dd4d2:	f8d9 5000 	ldr.w	r5, [r9]
   dd4d6:	f8d8 0008 	ldr.w	r0, [r8, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dd4da:	6869      	ldr	r1, [r5, #4]
   dd4dc:	68aa      	ldr	r2, [r5, #8]
}

inline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
   dd4de:	68ed      	ldr	r5, [r5, #12]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dd4e0:	2338      	movs	r3, #56	; 0x38

inline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
   dd4e2:	1c6f      	adds	r7, r5, #1
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dd4e4:	fb03 0101 	mla	r1, r3, r1, r0
   dd4e8:	fb03 0202 	mla	r2, r3, r2, r0
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
    return &context
                ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dd4ec:	bf18      	it	ne
   dd4ee:	fb03 0305 	mlane	r3, r3, r5, r0
    const TfLiteTensor* filter = GetInput(context, node, kFilterTensor);
    const TfLiteTensor* bias =
        GetOptionalInputTensor(context, node, kBiasTensor);
    TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

    TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams(
   dd4f2:	f504 758c 	add.w	r5, r4, #280	; 0x118
   dd4f6:	9507      	str	r5, [sp, #28]
   dd4f8:	f104 0518 	add.w	r5, r4, #24
   dd4fc:	9506      	str	r5, [sp, #24]
   dd4fe:	f504 7507 	add.w	r5, r4, #540	; 0x21c
   dd502:	9505      	str	r5, [sp, #20]
   dd504:	f504 7506 	add.w	r5, r4, #536	; 0x218
   dd508:	9504      	str	r5, [sp, #16]
   dd50a:	f104 0514 	add.w	r5, r4, #20
   dd50e:	f104 0410 	add.w	r4, r4, #16
   dd512:	9402      	str	r4, [sp, #8]
   dd514:	f106 0614 	add.w	r6, r6, #20
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dd518:	f8d9 4004 	ldr.w	r4, [r9, #4]
   dd51c:	9503      	str	r5, [sp, #12]
   dd51e:	9601      	str	r6, [sp, #4]
   dd520:	6864      	ldr	r4, [r4, #4]
   dd522:	f04f 0538 	mov.w	r5, #56	; 0x38
   dd526:	fb05 0004 	mla	r0, r5, r4, r0
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
    return &context
                ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
  }
  return nullptr;
   dd52a:	bf08      	it	eq
   dd52c:	2300      	moveq	r3, #0
   dd52e:	9000      	str	r0, [sp, #0]
   dd530:	4640      	mov	r0, r8
   dd532:	f007 fbb7 	bl	e4ca4 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_>
                             int filter_width, int filter_height, int out_width,
                             int out_height, const TfLiteType data_type,
                             OpData* data) {
  bool has_bias = node->inputs->size == 3;
  // Check number of inputs/outputs
  TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);
   dd536:	3000      	adds	r0, #0
   dd538:	bf18      	it	ne
   dd53a:	2001      	movne	r0, #1
   dd53c:	e000      	b.n	dd540 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE+0x138>
        &data->output_multiplier, &data->output_shift,
        &data->output_activation_min, &data->output_activation_max,
        data->per_channel_output_multiplier,
        reinterpret_cast<int*>(data->per_channel_output_shift)));
  }
  return kTfLiteOk;
   dd53e:	2000      	movs	r0, #0
}
   dd540:	b00d      	add	sp, #52	; 0x34
   dd542:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   dd546:	bf00      	nop
   dd548:	000eb5a5 	.word	0x000eb5a5
   dd54c:	000eb4e3 	.word	0x000eb4e3
   dd550:	000eb58e 	.word	0x000eb58e
   dd554:	000ecdd6 	.word	0x000ecdd6
   dd558:	000eb5c9 	.word	0x000eb5c9
   dd55c:	000eb3b9 	.word	0x000eb3b9

000dd560 <_ZN6tflite3ops5micro4conv13EvalQuantizedEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_>:

void EvalQuantized(TfLiteContext* context, TfLiteNode* node,
                   TfLiteConvParams* params, OpData* data,
                   const TfLiteTensor* input, const TfLiteTensor* filter,
                   const TfLiteTensor* bias, TfLiteTensor* im2col,
                   TfLiteTensor* hwcn_weights, TfLiteTensor* output) {
   dd560:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dd564:	b0b1      	sub	sp, #196	; 0xc4
  int32_t output_activation_min;
  int32_t output_activation_max;
};

inline PaddingType RuntimePaddingType(TfLitePadding padding) {
  switch (padding) {
   dd566:	7810      	ldrb	r0, [r2, #0]

void EvalQuantized(TfLiteContext* context, TfLiteNode* node,
                   TfLiteConvParams* params, OpData* data,
                   const TfLiteTensor* input, const TfLiteTensor* filter,
                   const TfLiteTensor* bias, TfLiteTensor* im2col,
                   TfLiteTensor* hwcn_weights, TfLiteTensor* output) {
   dd568:	f8dd 80e8 	ldr.w	r8, [sp, #232]	; 0xe8
   dd56c:	9f3b      	ldr	r7, [sp, #236]	; 0xec
  const int32_t input_offset = -input->params.zero_point;
   dd56e:	f8d8 1010 	ldr.w	r1, [r8, #16]

void EvalQuantized(TfLiteContext* context, TfLiteNode* node,
                   TfLiteConvParams* params, OpData* data,
                   const TfLiteTensor* input, const TfLiteTensor* filter,
                   const TfLiteTensor* bias, TfLiteTensor* im2col,
                   TfLiteTensor* hwcn_weights, TfLiteTensor* output) {
   dd572:	9e3f      	ldr	r6, [sp, #252]	; 0xfc
   dd574:	9c3c      	ldr	r4, [sp, #240]	; 0xf0
   dd576:	9d3d      	ldr	r5, [sp, #244]	; 0xf4
  const int32_t input_offset = -input->params.zero_point;
  const int32_t filter_offset = -filter->params.zero_point;
  const int32_t output_offset = output->params.zero_point;
   dd578:	f8d6 c010 	ldr.w	ip, [r6, #16]
void EvalQuantized(TfLiteContext* context, TfLiteNode* node,
                   TfLiteConvParams* params, OpData* data,
                   const TfLiteTensor* input, const TfLiteTensor* filter,
                   const TfLiteTensor* bias, TfLiteTensor* im2col,
                   TfLiteTensor* hwcn_weights, TfLiteTensor* output) {
  const int32_t input_offset = -input->params.zero_point;
   dd57c:	f1c1 0e00 	rsb	lr, r1, #0
  const int32_t filter_offset = -filter->params.zero_point;
   dd580:	6939      	ldr	r1, [r7, #16]
  int32_t output_activation_min;
  int32_t output_activation_max;
};

inline PaddingType RuntimePaddingType(TfLitePadding padding) {
  switch (padding) {
   dd582:	2801      	cmp	r0, #1
                   TfLiteConvParams* params, OpData* data,
                   const TfLiteTensor* input, const TfLiteTensor* filter,
                   const TfLiteTensor* bias, TfLiteTensor* im2col,
                   TfLiteTensor* hwcn_weights, TfLiteTensor* output) {
  const int32_t input_offset = -input->params.zero_point;
  const int32_t filter_offset = -filter->params.zero_point;
   dd584:	f1c1 0100 	rsb	r1, r1, #0
  int32_t output_activation_min;
  int32_t output_activation_max;
};

inline PaddingType RuntimePaddingType(TfLitePadding padding) {
  switch (padding) {
   dd588:	d003      	beq.n	dd592 <_ZN6tflite3ops5micro4conv13EvalQuantizedEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x32>
      return PaddingType::kSame;
    case TfLitePadding::kTfLitePaddingValid:
      return PaddingType::kValid;
    case TfLitePadding::kTfLitePaddingUnknown:
    default:
      return PaddingType::kNone;
   dd58a:	2802      	cmp	r0, #2
   dd58c:	bf0c      	ite	eq
   dd58e:	2002      	moveq	r0, #2
   dd590:	2000      	movne	r0, #0
  const int32_t input_offset = -input->params.zero_point;
  const int32_t filter_offset = -filter->params.zero_point;
  const int32_t output_offset = output->params.zero_point;

  ConvParams op_params;
  op_params.padding_type = RuntimePaddingType(params->padding);
   dd592:	f88d 0088 	strb.w	r0, [sp, #136]	; 0x88
  op_params.padding_values.width = data->padding.width;
   dd596:	6818      	ldr	r0, [r3, #0]
   dd598:	f8ad 008a 	strh.w	r0, [sp, #138]	; 0x8a
  op_params.padding_values.height = data->padding.height;
   dd59c:	6858      	ldr	r0, [r3, #4]
   dd59e:	f8ad 008c 	strh.w	r0, [sp, #140]	; 0x8c
  op_params.stride_width = params->stride_width;
   dd5a2:	6850      	ldr	r0, [r2, #4]
   dd5a4:	f8ad 0092 	strh.w	r0, [sp, #146]	; 0x92
  op_params.stride_height = params->stride_height;
   dd5a8:	6890      	ldr	r0, [r2, #8]
   dd5aa:	f8ad 0094 	strh.w	r0, [sp, #148]	; 0x94
  op_params.dilation_width_factor = params->dilation_width_factor;
   dd5ae:	68d0      	ldr	r0, [r2, #12]
  op_params.dilation_height_factor = params->dilation_height_factor;
   dd5b0:	6912      	ldr	r2, [r2, #16]
   dd5b2:	f8ad 2098 	strh.w	r2, [sp, #152]	; 0x98
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
   dd5b6:	691a      	ldr	r2, [r3, #16]
   dd5b8:	922a      	str	r2, [sp, #168]	; 0xa8
  op_params.output_shift = -data->output_shift;
   dd5ba:	695a      	ldr	r2, [r3, #20]
  op_params.padding_type = RuntimePaddingType(params->padding);
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
   dd5bc:	f8ad 0096 	strh.w	r0, [sp, #150]	; 0x96
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  op_params.output_shift = -data->output_shift;
   dd5c0:	4252      	negs	r2, r2
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
   dd5c2:	9128      	str	r1, [sp, #160]	; 0xa0
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  op_params.output_shift = -data->output_shift;
   dd5c4:	922b      	str	r2, [sp, #172]	; 0xac
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  reference_ops::Conv(op_params, GetTensorShape(input),
   dd5c6:	4641      	mov	r1, r8
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  op_params.output_shift = -data->output_shift;
  op_params.quantized_activation_min = data->output_activation_min;
   dd5c8:	f8d3 2218 	ldr.w	r2, [r3, #536]	; 0x218
  op_params.quantized_activation_max = data->output_activation_max;
   dd5cc:	f8d3 321c 	ldr.w	r3, [r3, #540]	; 0x21c
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.input_offset = input_offset;
   dd5d0:	f8cd e09c 	str.w	lr, [sp, #156]	; 0x9c
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  op_params.output_shift = -data->output_shift;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  reference_ops::Conv(op_params, GetTensorShape(input),
   dd5d4:	a809      	add	r0, sp, #36	; 0x24
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
   dd5d6:	f8cd c0a4 	str.w	ip, [sp, #164]	; 0xa4
  op_params.output_multiplier = data->output_multiplier;
  op_params.output_shift = -data->output_shift;
  op_params.quantized_activation_min = data->output_activation_min;
   dd5da:	922c      	str	r2, [sp, #176]	; 0xb0
  op_params.quantized_activation_max = data->output_activation_max;
   dd5dc:	932d      	str	r3, [sp, #180]	; 0xb4
  reference_ops::Conv(op_params, GetTensorShape(input),
   dd5de:	f7fa fa74 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
                      GetTensorData<uint8_t>(input), GetTensorShape(filter),
   dd5e2:	4639      	mov	r1, r7
   dd5e4:	a80e      	add	r0, sp, #56	; 0x38
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dd5e6:	f8d8 8004 	ldr.w	r8, [r8, #4]
   dd5ea:	f7fa fa6e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dd5ee:	f8d7 9004 	ldr.w	r9, [r7, #4]
                      GetTensorData<uint8_t>(filter), GetTensorShape(bias),
   dd5f2:	af13      	add	r7, sp, #76	; 0x4c
   dd5f4:	4621      	mov	r1, r4
   dd5f6:	4638      	mov	r0, r7
   dd5f8:	f7fa fa67 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dd5fc:	b114      	cbz	r4, dd604 <_ZN6tflite3ops5micro4conv13EvalQuantizedEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0xa4>
   dd5fe:	f8d4 a004 	ldr.w	sl, [r4, #4]
   dd602:	e000      	b.n	dd606 <_ZN6tflite3ops5micro4conv13EvalQuantizedEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0xa6>
   dd604:	46a2      	mov	sl, r4
                      GetTensorData<int32_t>(bias), GetTensorShape(output),
   dd606:	ac18      	add	r4, sp, #96	; 0x60
   dd608:	4631      	mov	r1, r6
   dd60a:	4620      	mov	r0, r4
   dd60c:	f7fa fa5d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dd610:	f8d6 b004 	ldr.w	fp, [r6, #4]
                      GetTensorData<uint8_t>(output), GetTensorShape(im2col),
   dd614:	ae1d      	add	r6, sp, #116	; 0x74
   dd616:	4629      	mov	r1, r5
   dd618:	4630      	mov	r0, r6
   dd61a:	f7fa fa56 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dd61e:	b105      	cbz	r5, dd622 <_ZN6tflite3ops5micro4conv13EvalQuantizedEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0xc2>
   dd620:	686d      	ldr	r5, [r5, #4]
                      GetTensorData<uint8_t>(im2col), nullptr);
   dd622:	9506      	str	r5, [sp, #24]
   dd624:	2300      	movs	r3, #0
   dd626:	4642      	mov	r2, r8
   dd628:	a909      	add	r1, sp, #36	; 0x24
   dd62a:	9307      	str	r3, [sp, #28]
   dd62c:	a822      	add	r0, sp, #136	; 0x88
   dd62e:	ab0e      	add	r3, sp, #56	; 0x38
   dd630:	9605      	str	r6, [sp, #20]
   dd632:	f8cd b010 	str.w	fp, [sp, #16]
   dd636:	9403      	str	r4, [sp, #12]
   dd638:	f8cd a008 	str.w	sl, [sp, #8]
   dd63c:	9701      	str	r7, [sp, #4]
   dd63e:	f8cd 9000 	str.w	r9, [sp]
   dd642:	f7ff fcbd 	bl	dcfc0 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_PhS6_SB_Pv>
  op_params.quantized_activation_max = data->output_activation_max;
  reference_ops::Conv(op_params, GetTensorShape(input),
                      GetTensorData<uint8_t>(input), GetTensorShape(filter),
                      GetTensorData<uint8_t>(filter), GetTensorShape(bias),
                      GetTensorData<int32_t>(bias), GetTensorShape(output),
                      GetTensorData<uint8_t>(output), GetTensorShape(im2col),
   dd646:	4630      	mov	r0, r6
   dd648:	f7f9 ff8f 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  reference_ops::Conv(op_params, GetTensorShape(input),
                      GetTensorData<uint8_t>(input), GetTensorShape(filter),
                      GetTensorData<uint8_t>(filter), GetTensorShape(bias),
                      GetTensorData<int32_t>(bias), GetTensorShape(output),
   dd64c:	4620      	mov	r0, r4
   dd64e:	f7f9 ff8c 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.output_shift = -data->output_shift;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  reference_ops::Conv(op_params, GetTensorShape(input),
                      GetTensorData<uint8_t>(input), GetTensorShape(filter),
                      GetTensorData<uint8_t>(filter), GetTensorShape(bias),
   dd652:	4638      	mov	r0, r7
   dd654:	f7f9 ff89 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.output_multiplier = data->output_multiplier;
  op_params.output_shift = -data->output_shift;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  reference_ops::Conv(op_params, GetTensorShape(input),
                      GetTensorData<uint8_t>(input), GetTensorShape(filter),
   dd658:	a80e      	add	r0, sp, #56	; 0x38
   dd65a:	f7f9 ff86 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  op_params.output_shift = -data->output_shift;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  reference_ops::Conv(op_params, GetTensorShape(input),
   dd65e:	a809      	add	r0, sp, #36	; 0x24
   dd660:	f7f9 ff83 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                      GetTensorData<uint8_t>(input), GetTensorShape(filter),
                      GetTensorData<uint8_t>(filter), GetTensorShape(bias),
                      GetTensorData<int32_t>(bias), GetTensorShape(output),
                      GetTensorData<uint8_t>(output), GetTensorShape(im2col),
                      GetTensorData<uint8_t>(im2col), nullptr);
}
   dd664:	b031      	add	sp, #196	; 0xc4
   dd666:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dd66a <_ZN6tflite3ops5micro4conv23EvalQuantizedPerChannelEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_>:
void EvalQuantizedPerChannel(TfLiteContext* context, TfLiteNode* node,
                             TfLiteConvParams* params, OpData* data,
                             const TfLiteTensor* input,
                             const TfLiteTensor* filter,
                             const TfLiteTensor* bias, TfLiteTensor* output,
                             TfLiteTensor* im2col) {
   dd66a:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dd66e:	b0ad      	sub	sp, #180	; 0xb4
   dd670:	ac37      	add	r4, sp, #220	; 0xdc
   dd672:	9f36      	ldr	r7, [sp, #216]	; 0xd8
   dd674:	e894 0430 	ldmia.w	r4, {r4, r5, sl}
  ConvParams op_params;
  op_params.input_offset = -input->params.zero_point;
   dd678:	6939      	ldr	r1, [r7, #16]
   dd67a:	4249      	negs	r1, r1
   dd67c:	9123      	str	r1, [sp, #140]	; 0x8c
  op_params.output_offset = output->params.zero_point;
   dd67e:	f8da 1010 	ldr.w	r1, [sl, #16]
   dd682:	9125      	str	r1, [sp, #148]	; 0x94
  op_params.stride_height = params->stride_height;
   dd684:	6891      	ldr	r1, [r2, #8]
   dd686:	f8ad 1084 	strh.w	r1, [sp, #132]	; 0x84
  op_params.stride_width = params->stride_width;
   dd68a:	6851      	ldr	r1, [r2, #4]
   dd68c:	f8ad 1082 	strh.w	r1, [sp, #130]	; 0x82
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
   dd690:	4699      	mov	r9, r3
  ConvParams op_params;
  op_params.input_offset = -input->params.zero_point;
  op_params.output_offset = output->params.zero_point;
  op_params.stride_height = params->stride_height;
  op_params.stride_width = params->stride_width;
  op_params.dilation_height_factor = params->dilation_height_factor;
   dd692:	6911      	ldr	r1, [r2, #16]
  op_params.dilation_width_factor = params->dilation_width_factor;
   dd694:	68d2      	ldr	r2, [r2, #12]
   dd696:	f8ad 2086 	strh.w	r2, [sp, #134]	; 0x86
  op_params.padding_values.height = data->padding.height;
   dd69a:	685a      	ldr	r2, [r3, #4]
  ConvParams op_params;
  op_params.input_offset = -input->params.zero_point;
  op_params.output_offset = output->params.zero_point;
  op_params.stride_height = params->stride_height;
  op_params.stride_width = params->stride_width;
  op_params.dilation_height_factor = params->dilation_height_factor;
   dd69c:	f8ad 1088 	strh.w	r1, [sp, #136]	; 0x88
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.padding_values.height = data->padding.height;
   dd6a0:	f8ad 207c 	strh.w	r2, [sp, #124]	; 0x7c
  op_params.padding_values.width = data->padding.width;

  reference_integer_ops::ConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
   dd6a4:	4639      	mov	r1, r7
  op_params.stride_height = params->stride_height;
  op_params.stride_width = params->stride_width;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
   dd6a6:	f859 2b18 	ldr.w	r2, [r9], #24
   dd6aa:	f8ad 207a 	strh.w	r2, [sp, #122]	; 0x7a

  reference_integer_ops::ConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
   dd6ae:	a80a      	add	r0, sp, #40	; 0x28
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;

  reference_integer_ops::ConvPerChannel(
   dd6b0:	f503 768c 	add.w	r6, r3, #280	; 0x118
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
   dd6b4:	f7fa fa09 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dd6b8:	f8d7 b004 	ldr.w	fp, [r7, #4]
      GetTensorData<int8>(input), GetTensorShape(filter),
   dd6bc:	af0f      	add	r7, sp, #60	; 0x3c
   dd6be:	4621      	mov	r1, r4
   dd6c0:	4638      	mov	r0, r7
   dd6c2:	f7fa fa02 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dd6c6:	b104      	cbz	r4, dd6ca <_ZN6tflite3ops5micro4conv23EvalQuantizedPerChannelEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_+0x60>
   dd6c8:	6864      	ldr	r4, [r4, #4]
      GetTensorData<int8>(filter), GetTensorShape(bias),
   dd6ca:	f10d 0850 	add.w	r8, sp, #80	; 0x50
   dd6ce:	4629      	mov	r1, r5
   dd6d0:	4640      	mov	r0, r8
   dd6d2:	f7fa f9fa 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dd6d6:	b10d      	cbz	r5, dd6dc <_ZN6tflite3ops5micro4conv23EvalQuantizedPerChannelEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_+0x72>
   dd6d8:	686b      	ldr	r3, [r5, #4]
   dd6da:	e000      	b.n	dd6de <_ZN6tflite3ops5micro4conv23EvalQuantizedPerChannelEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_+0x74>
   dd6dc:	462b      	mov	r3, r5
      GetTensorData<int32>(bias), GetTensorShape(output),
   dd6de:	ad19      	add	r5, sp, #100	; 0x64
   dd6e0:	4651      	mov	r1, sl
   dd6e2:	4628      	mov	r0, r5
   dd6e4:	9309      	str	r3, [sp, #36]	; 0x24
   dd6e6:	f7fa f9f0 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorData<int8>(output));
   dd6ea:	f8da 2004 	ldr.w	r2, [sl, #4]
   dd6ee:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dd6f0:	9206      	str	r2, [sp, #24]
   dd6f2:	4649      	mov	r1, r9
   dd6f4:	4632      	mov	r2, r6
   dd6f6:	9304      	str	r3, [sp, #16]
   dd6f8:	a81e      	add	r0, sp, #120	; 0x78
   dd6fa:	ab0a      	add	r3, sp, #40	; 0x28
   dd6fc:	9505      	str	r5, [sp, #20]
   dd6fe:	f8cd 800c 	str.w	r8, [sp, #12]
   dd702:	9402      	str	r4, [sp, #8]
   dd704:	9701      	str	r7, [sp, #4]
   dd706:	f8cd b000 	str.w	fp, [sp]
   dd70a:	f7ff fd69 	bl	dd1e0 <_ZN6tflite21reference_integer_ops14ConvPerChannelERKNS_10ConvParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa>
  reference_integer_ops::ConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
      GetTensorData<int8>(input), GetTensorShape(filter),
      GetTensorData<int8>(filter), GetTensorShape(bias),
      GetTensorData<int32>(bias), GetTensorShape(output),
   dd70e:	4628      	mov	r0, r5
   dd710:	f7f9 ff2b 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>

  reference_integer_ops::ConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
      GetTensorData<int8>(input), GetTensorShape(filter),
      GetTensorData<int8>(filter), GetTensorShape(bias),
   dd714:	4640      	mov	r0, r8
   dd716:	f7f9 ff28 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.padding_values.width = data->padding.width;

  reference_integer_ops::ConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
      GetTensorData<int8>(input), GetTensorShape(filter),
   dd71a:	4638      	mov	r0, r7
   dd71c:	f7f9 ff25 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;

  reference_integer_ops::ConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
   dd720:	a80a      	add	r0, sp, #40	; 0x28
   dd722:	f7f9 ff22 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      GetTensorData<int8>(input), GetTensorShape(filter),
      GetTensorData<int8>(filter), GetTensorShape(bias),
      GetTensorData<int32>(bias), GetTensorShape(output),
      GetTensorData<int8>(output));
}
   dd726:	b02d      	add	sp, #180	; 0xb4
   dd728:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dd72c <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_>:

void EvalFloat(TfLiteContext* context, TfLiteNode* node,
               TfLiteConvParams* params, OpData* data,
               const TfLiteTensor* input, const TfLiteTensor* filter,
               const TfLiteTensor* bias, TfLiteTensor* im2col,
               TfLiteTensor* hwcn_weights, TfLiteTensor* output) {
   dd72c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  float output_activation_min, output_activation_max;
  CalculateActivationRange(params->activation, &output_activation_min,
   dd730:	7d11      	ldrb	r1, [r2, #20]

void EvalFloat(TfLiteContext* context, TfLiteNode* node,
               TfLiteConvParams* params, OpData* data,
               const TfLiteTensor* input, const TfLiteTensor* filter,
               const TfLiteTensor* bias, TfLiteTensor* im2col,
               TfLiteTensor* hwcn_weights, TfLiteTensor* output) {
   dd732:	b0b1      	sub	sp, #196	; 0xc4
   dd734:	ac3a      	add	r4, sp, #232	; 0xe8
// Calculates the useful range of an activation layer given its activation
// tensor.a
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
   dd736:	2901      	cmp	r1, #1
   dd738:	e894 0170 	ldmia.w	r4, {r4, r5, r6, r8}
   dd73c:	9f3f      	ldr	r7, [sp, #252]	; 0xfc
   dd73e:	d011      	beq.n	dd764 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x38>
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
   dd740:	2903      	cmp	r1, #3
   dd742:	d012      	beq.n	dd76a <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x3e>
  } else if (activation == kTfLiteActRelu1) {
    *activation_min = -1;
    *activation_max = 1;
  } else {
    *activation_min = std::numeric_limits<T>::lowest();
    *activation_max = std::numeric_limits<T>::max();
   dd744:	ed9f 7a3f 	vldr	s14, [pc, #252]	; dd844 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x118>
   dd748:	eddf 6a3f 	vldr	s13, [pc, #252]	; dd848 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x11c>
   dd74c:	2902      	cmp	r1, #2
   dd74e:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   dd752:	bf18      	it	ne
   dd754:	eef0 7a47 	vmovne.f32	s15, s14
   dd758:	eebf 7a00 	vmov.f32	s14, #240	; 0xbf800000 -1.0
   dd75c:	bf18      	it	ne
   dd75e:	eeb0 7a66 	vmovne.f32	s14, s13
   dd762:	e006      	b.n	dd772 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x46>
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
   dd764:	eddf 7a37 	vldr	s15, [pc, #220]	; dd844 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x118>
   dd768:	e001      	b.n	dd76e <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x42>
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
    *activation_max = 6;
   dd76a:	eef1 7a08 	vmov.f32	s15, #24	; 0x40c00000  6.0
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
   dd76e:	ed9f 7a37 	vldr	s14, [pc, #220]	; dd84c <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x120>
  int32_t output_activation_min;
  int32_t output_activation_max;
};

inline PaddingType RuntimePaddingType(TfLitePadding padding) {
  switch (padding) {
   dd772:	7811      	ldrb	r1, [r2, #0]
   dd774:	2901      	cmp	r1, #1
   dd776:	d003      	beq.n	dd780 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x54>
      return PaddingType::kSame;
    case TfLitePadding::kTfLitePaddingValid:
      return PaddingType::kValid;
    case TfLitePadding::kTfLitePaddingUnknown:
    default:
      return PaddingType::kNone;
   dd778:	2902      	cmp	r1, #2
   dd77a:	bf0c      	ite	eq
   dd77c:	2102      	moveq	r1, #2
   dd77e:	2100      	movne	r1, #0
  float output_activation_min, output_activation_max;
  CalculateActivationRange(params->activation, &output_activation_min,
                           &output_activation_max);

  ConvParams op_params;
  op_params.padding_type = RuntimePaddingType(params->padding);
   dd780:	f88d 1088 	strb.w	r1, [sp, #136]	; 0x88
  op_params.padding_values.width = data->padding.width;
   dd784:	6819      	ldr	r1, [r3, #0]
  op_params.padding_values.height = data->padding.height;
   dd786:	685b      	ldr	r3, [r3, #4]
   dd788:	f8ad 308c 	strh.w	r3, [sp, #140]	; 0x8c
  op_params.stride_width = params->stride_width;
   dd78c:	6853      	ldr	r3, [r2, #4]
   dd78e:	f8ad 3092 	strh.w	r3, [sp, #146]	; 0x92
  op_params.stride_height = params->stride_height;
   dd792:	6893      	ldr	r3, [r2, #8]
   dd794:	f8ad 3094 	strh.w	r3, [sp, #148]	; 0x94
  op_params.dilation_width_factor = params->dilation_width_factor;
   dd798:	68d3      	ldr	r3, [r2, #12]
  CalculateActivationRange(params->activation, &output_activation_min,
                           &output_activation_max);

  ConvParams op_params;
  op_params.padding_type = RuntimePaddingType(params->padding);
  op_params.padding_values.width = data->padding.width;
   dd79a:	f8ad 108a 	strh.w	r1, [sp, #138]	; 0x8a
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
   dd79e:	f8ad 3096 	strh.w	r3, [sp, #150]	; 0x96
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;

  reference_ops::Conv(op_params, GetTensorShape(input),
   dd7a2:	4621      	mov	r1, r4
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
   dd7a4:	6913      	ldr	r3, [r2, #16]
   dd7a6:	f8ad 3098 	strh.w	r3, [sp, #152]	; 0x98
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;

  reference_ops::Conv(op_params, GetTensorShape(input),
   dd7aa:	a809      	add	r0, sp, #36	; 0x24
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.float_activation_min = output_activation_min;
   dd7ac:	ed8d 7a2e 	vstr	s14, [sp, #184]	; 0xb8
  op_params.float_activation_max = output_activation_max;
   dd7b0:	edcd 7a2f 	vstr	s15, [sp, #188]	; 0xbc

  reference_ops::Conv(op_params, GetTensorShape(input),
   dd7b4:	f7fa f989 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dd7b8:	b104      	cbz	r4, dd7bc <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x90>
   dd7ba:	6864      	ldr	r4, [r4, #4]
                      GetTensorData<float>(input), GetTensorShape(filter),
   dd7bc:	4629      	mov	r1, r5
   dd7be:	a80e      	add	r0, sp, #56	; 0x38
   dd7c0:	f7fa f983 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dd7c4:	b105      	cbz	r5, dd7c8 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0x9c>
   dd7c6:	686d      	ldr	r5, [r5, #4]
                      GetTensorData<float>(filter), GetTensorShape(bias),
   dd7c8:	f10d 094c 	add.w	r9, sp, #76	; 0x4c
   dd7cc:	4631      	mov	r1, r6
   dd7ce:	4648      	mov	r0, r9
   dd7d0:	f7fa f97b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dd7d4:	b106      	cbz	r6, dd7d8 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0xac>
   dd7d6:	6876      	ldr	r6, [r6, #4]
                      GetTensorData<float>(bias), GetTensorShape(output),
   dd7d8:	f10d 0a60 	add.w	sl, sp, #96	; 0x60
   dd7dc:	4639      	mov	r1, r7
   dd7de:	4650      	mov	r0, sl
   dd7e0:	f7fa f973 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dd7e4:	b107      	cbz	r7, dd7e8 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0xbc>
   dd7e6:	687f      	ldr	r7, [r7, #4]
                      GetTensorData<float>(output), GetTensorShape(im2col),
   dd7e8:	f10d 0b74 	add.w	fp, sp, #116	; 0x74
   dd7ec:	4641      	mov	r1, r8
   dd7ee:	4658      	mov	r0, fp
   dd7f0:	f7fa f96b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   dd7f4:	f1b8 0f00 	cmp.w	r8, #0
   dd7f8:	d002      	beq.n	dd800 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0xd4>
   dd7fa:	f8d8 3004 	ldr.w	r3, [r8, #4]
   dd7fe:	e000      	b.n	dd802 <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_+0xd6>
   dd800:	4643      	mov	r3, r8
                      GetTensorData<float>(im2col));
   dd802:	4622      	mov	r2, r4
   dd804:	a909      	add	r1, sp, #36	; 0x24
   dd806:	9306      	str	r3, [sp, #24]
   dd808:	a822      	add	r0, sp, #136	; 0x88
   dd80a:	ab0e      	add	r3, sp, #56	; 0x38
   dd80c:	f8cd b014 	str.w	fp, [sp, #20]
   dd810:	9704      	str	r7, [sp, #16]
   dd812:	f8cd a00c 	str.w	sl, [sp, #12]
   dd816:	9602      	str	r6, [sp, #8]
   dd818:	e88d 0220 	stmia.w	sp, {r5, r9}
   dd81c:	f7ff fac0 	bl	dcda0 <_ZN6tflite13reference_ops4ConvERKNS_10ConvParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfS6_S9_>

  reference_ops::Conv(op_params, GetTensorShape(input),
                      GetTensorData<float>(input), GetTensorShape(filter),
                      GetTensorData<float>(filter), GetTensorShape(bias),
                      GetTensorData<float>(bias), GetTensorShape(output),
                      GetTensorData<float>(output), GetTensorShape(im2col),
   dd820:	4658      	mov	r0, fp
   dd822:	f7f9 fea2 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.float_activation_max = output_activation_max;

  reference_ops::Conv(op_params, GetTensorShape(input),
                      GetTensorData<float>(input), GetTensorShape(filter),
                      GetTensorData<float>(filter), GetTensorShape(bias),
                      GetTensorData<float>(bias), GetTensorShape(output),
   dd826:	4650      	mov	r0, sl
   dd828:	f7f9 fe9f 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;

  reference_ops::Conv(op_params, GetTensorShape(input),
                      GetTensorData<float>(input), GetTensorShape(filter),
                      GetTensorData<float>(filter), GetTensorShape(bias),
   dd82c:	4648      	mov	r0, r9
   dd82e:	f7f9 fe9c 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;

  reference_ops::Conv(op_params, GetTensorShape(input),
                      GetTensorData<float>(input), GetTensorShape(filter),
   dd832:	a80e      	add	r0, sp, #56	; 0x38
   dd834:	f7f9 fe99 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;

  reference_ops::Conv(op_params, GetTensorShape(input),
   dd838:	a809      	add	r0, sp, #36	; 0x24
   dd83a:	f7f9 fe96 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                      GetTensorData<float>(input), GetTensorShape(filter),
                      GetTensorData<float>(filter), GetTensorShape(bias),
                      GetTensorData<float>(bias), GetTensorShape(output),
                      GetTensorData<float>(output), GetTensorShape(im2col),
                      GetTensorData<float>(im2col));
}
   dd83e:	b031      	add	sp, #196	; 0xc4
   dd840:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   dd844:	7f7fffff 	.word	0x7f7fffff
   dd848:	ff7fffff 	.word	0xff7fffff
   dd84c:	00000000 	.word	0x00000000

000dd850 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   dd850:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dd854:	680a      	ldr	r2, [r1, #0]
   dd856:	6887      	ldr	r7, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dd858:	6896      	ldr	r6, [r2, #8]
   dd85a:	4688      	mov	r8, r1
   dd85c:	6851      	ldr	r1, [r2, #4]
}

inline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
   dd85e:	68d2      	ldr	r2, [r2, #12]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dd860:	2338      	movs	r3, #56	; 0x38
   dd862:	fb03 fa01 	mul.w	sl, r3, r1
   dd866:	f5ad 7d15 	sub.w	sp, sp, #596	; 0x254
   dd86a:	eb07 010a 	add.w	r1, r7, sl
   dd86e:	4605      	mov	r5, r0
  int filter_height = filter->dims->data[1];
  int output_width = output->dims->data[2];
  int output_height = output->dims->data[1];

  OpData data;
  if (input->type != kTfLiteFloat32) {
   dd870:	f817 000a 	ldrb.w	r0, [r7, sl]
   dd874:	910b      	str	r1, [sp, #44]	; 0x2c

inline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
   dd876:	1c51      	adds	r1, r2, #1
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dd878:	fb03 7606 	mla	r6, r3, r6, r7
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
    return &context
                ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dd87c:	bf14      	ite	ne
   dd87e:	fb03 7302 	mlane	r3, r3, r2, r7
  }
  return nullptr;
   dd882:	2300      	moveq	r3, #0
   dd884:	2801      	cmp	r0, #1
   dd886:	930a      	str	r3, [sp, #40]	; 0x28
   dd888:	d024      	beq.n	dd8d4 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x84>
    TF_LITE_ENSURE_EQ(context, filter->quantization.type,
   dd88a:	f896 4030 	ldrb.w	r4, [r6, #48]	; 0x30
   dd88e:	2c01      	cmp	r4, #1
   dd890:	d00e      	beq.n	dd8b0 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x60>
   dd892:	4b47      	ldr	r3, [pc, #284]	; (dd9b0 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x160>)
   dd894:	9301      	str	r3, [sp, #4]
   dd896:	2601      	movs	r6, #1
   dd898:	4b46      	ldr	r3, [pc, #280]	; (dd9b4 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x164>)
   dd89a:	9402      	str	r4, [sp, #8]
   dd89c:	9300      	str	r3, [sp, #0]
   dd89e:	696c      	ldr	r4, [r5, #20]
   dd8a0:	9603      	str	r6, [sp, #12]
   dd8a2:	23dd      	movs	r3, #221	; 0xdd
   dd8a4:	4a44      	ldr	r2, [pc, #272]	; (dd9b8 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x168>)
   dd8a6:	4945      	ldr	r1, [pc, #276]	; (dd9bc <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x16c>)
   dd8a8:	4628      	mov	r0, r5
   dd8aa:	47a0      	blx	r4
   dd8ac:	4634      	mov	r4, r6
   dd8ae:	e079      	b.n	dd9a4 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x154>
                      kTfLiteAffineQuantization);

    const auto* affine_quantization =
        reinterpret_cast<TfLiteAffineQuantization*>(
            filter->quantization.params);
   dd8b0:	6b73      	ldr	r3, [r6, #52]	; 0x34
    TF_LITE_ENSURE(context, affine_quantization);
   dd8b2:	b923      	cbnz	r3, dd8be <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x6e>
   dd8b4:	4b42      	ldr	r3, [pc, #264]	; (dd9c0 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x170>)
   dd8b6:	9300      	str	r3, [sp, #0]
   dd8b8:	696e      	ldr	r6, [r5, #20]
   dd8ba:	23e2      	movs	r3, #226	; 0xe2
   dd8bc:	e005      	b.n	dd8ca <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x7a>
    TF_LITE_ENSURE(context, affine_quantization->scale);
   dd8be:	681b      	ldr	r3, [r3, #0]
   dd8c0:	b943      	cbnz	r3, dd8d4 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x84>
   dd8c2:	4b40      	ldr	r3, [pc, #256]	; (dd9c4 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x174>)
   dd8c4:	696e      	ldr	r6, [r5, #20]
   dd8c6:	9300      	str	r3, [sp, #0]
   dd8c8:	23e3      	movs	r3, #227	; 0xe3
   dd8ca:	4a3b      	ldr	r2, [pc, #236]	; (dd9b8 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x168>)
   dd8cc:	493e      	ldr	r1, [pc, #248]	; (dd9c8 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x178>)
   dd8ce:	4628      	mov	r0, r5
   dd8d0:	47b0      	blx	r6
   dd8d2:	e067      	b.n	dd9a4 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x154>
                      GetTensorData<float>(output), GetTensorShape(im2col),
                      GetTensorData<float>(im2col));
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  auto* params = reinterpret_cast<TfLiteConvParams*>(node->builtin_data);
   dd8d4:	f8d8 3014 	ldr.w	r3, [r8, #20]
   dd8d8:	9309      	str	r3, [sp, #36]	; 0x24
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dd8da:	f8d8 3004 	ldr.w	r3, [r8, #4]
  const TfLiteTensor* filter = GetInput(context, node, kFilterTensor);
  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);

  int input_width = input->dims->data[2];
  int input_height = input->dims->data[1];
  int filter_width = filter->dims->data[2];
   dd8de:	68b2      	ldr	r2, [r6, #8]
   dd8e0:	685b      	ldr	r3, [r3, #4]
   dd8e2:	f04f 0938 	mov.w	r9, #56	; 0x38
   dd8e6:	fb09 7903 	mla	r9, r9, r3, r7
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  const TfLiteTensor* filter = GetInput(context, node, kFilterTensor);
  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);

  int input_width = input->dims->data[2];
   dd8ea:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
  int input_height = input->dims->data[1];
  int filter_width = filter->dims->data[2];
  int filter_height = filter->dims->data[1];
  int output_width = output->dims->data[2];
   dd8ec:	f8d9 1008 	ldr.w	r1, [r9, #8]
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  const TfLiteTensor* filter = GetInput(context, node, kFilterTensor);
  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);

  int input_width = input->dims->data[2];
   dd8f0:	689b      	ldr	r3, [r3, #8]
            filter->quantization.params);
    TF_LITE_ENSURE(context, affine_quantization);
    TF_LITE_ENSURE(context, affine_quantization->scale);
  }

  TF_LITE_ENSURE_STATUS(CalculateOpData(
   dd8f2:	9005      	str	r0, [sp, #20]
   dd8f4:	f10d 0b30 	add.w	fp, sp, #48	; 0x30
   dd8f8:	f8cd b018 	str.w	fp, [sp, #24]
   dd8fc:	6888      	ldr	r0, [r1, #8]
   dd8fe:	9004      	str	r0, [sp, #16]
   dd900:	68c9      	ldr	r1, [r1, #12]
   dd902:	9103      	str	r1, [sp, #12]
   dd904:	6891      	ldr	r1, [r2, #8]
   dd906:	9102      	str	r1, [sp, #8]
   dd908:	68d2      	ldr	r2, [r2, #12]
   dd90a:	9201      	str	r2, [sp, #4]
   dd90c:	689a      	ldr	r2, [r3, #8]
   dd90e:	9200      	str	r2, [sp, #0]
   dd910:	68db      	ldr	r3, [r3, #12]
   dd912:	9a09      	ldr	r2, [sp, #36]	; 0x24
   dd914:	4641      	mov	r1, r8
   dd916:	4628      	mov	r0, r5
   dd918:	f7ff fd76 	bl	dd408 <_ZN6tflite3ops5micro4conv15CalculateOpDataEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsiiiiii10TfLiteTypePNS2_6OpDataE>
   dd91c:	4604      	mov	r4, r0
   dd91e:	2800      	cmp	r0, #0
   dd920:	d13f      	bne.n	dd9a2 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x152>
      context, node, params, input_width, input_height, filter_width,
      filter_height, output_width, output_height, input->type, &data));

  switch (input->type) {  // Already know in/out types are same.
   dd922:	f817 000a 	ldrb.w	r0, [r7, sl]
   dd926:	2803      	cmp	r0, #3
   dd928:	d022      	beq.n	dd970 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x120>
   dd92a:	2809      	cmp	r0, #9
   dd92c:	d011      	beq.n	dd952 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x102>
   dd92e:	2801      	cmp	r0, #1
   dd930:	d12e      	bne.n	dd990 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x140>
    case kTfLiteFloat32:
      EvalFloat(context, node, params, &data, input, filter, bias, nullptr,
                nullptr, output);
   dd932:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   dd934:	9302      	str	r3, [sp, #8]
   dd936:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   dd938:	9300      	str	r3, [sp, #0]
   dd93a:	f8cd 9014 	str.w	r9, [sp, #20]
   dd93e:	9404      	str	r4, [sp, #16]
   dd940:	9403      	str	r4, [sp, #12]
   dd942:	9601      	str	r6, [sp, #4]
   dd944:	465b      	mov	r3, fp
   dd946:	9a09      	ldr	r2, [sp, #36]	; 0x24
   dd948:	4641      	mov	r1, r8
   dd94a:	4628      	mov	r0, r5
   dd94c:	f7ff feee 	bl	dd72c <_ZN6tflite3ops5micro4conv9EvalFloatEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_>
      break;
   dd950:	e028      	b.n	dd9a4 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x154>
    case kTfLiteInt8:
      EvalQuantizedPerChannel(context, node, params, &data, input, filter, bias,
                              output, nullptr);
   dd952:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   dd954:	9302      	str	r3, [sp, #8]
   dd956:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   dd958:	9300      	str	r3, [sp, #0]
   dd95a:	9404      	str	r4, [sp, #16]
   dd95c:	f8cd 900c 	str.w	r9, [sp, #12]
   dd960:	9601      	str	r6, [sp, #4]
   dd962:	465b      	mov	r3, fp
   dd964:	9a09      	ldr	r2, [sp, #36]	; 0x24
   dd966:	4641      	mov	r1, r8
   dd968:	4628      	mov	r0, r5
   dd96a:	f7ff fe7e 	bl	dd66a <_ZN6tflite3ops5micro4conv23EvalQuantizedPerChannelEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_>
      break;
   dd96e:	e019      	b.n	dd9a4 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x154>
    case kTfLiteUInt8:
      EvalQuantized(context, node, params, &data, input, filter, bias, nullptr,
                    nullptr, output);
   dd970:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   dd972:	9302      	str	r3, [sp, #8]
   dd974:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   dd976:	9300      	str	r3, [sp, #0]
   dd978:	f8cd 9014 	str.w	r9, [sp, #20]
   dd97c:	9404      	str	r4, [sp, #16]
   dd97e:	9403      	str	r4, [sp, #12]
   dd980:	9601      	str	r6, [sp, #4]
   dd982:	465b      	mov	r3, fp
   dd984:	9a09      	ldr	r2, [sp, #36]	; 0x24
   dd986:	4641      	mov	r1, r8
   dd988:	4628      	mov	r0, r5
   dd98a:	f7ff fde9 	bl	dd560 <_ZN6tflite3ops5micro4conv13EvalQuantizedEP13TfLiteContextP10TfLiteNodeP16TfLiteConvParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_>
      break;
   dd98e:	e009      	b.n	dd9a4 <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x154>
    default:
      context->ReportError(context, "Type %s (%d) not supported.",
   dd990:	696c      	ldr	r4, [r5, #20]
   dd992:	f7f6 fbcb 	bl	d412c <TfLiteTypeGetName>
                           TfLiteTypeGetName(input->type), input->type);
   dd996:	f817 300a 	ldrb.w	r3, [r7, sl]
   dd99a:	490c      	ldr	r1, [pc, #48]	; (dd9cc <_ZN6tflite3ops5micro4conv4EvalEP13TfLiteContextP10TfLiteNode+0x17c>)
   dd99c:	4602      	mov	r2, r0
   dd99e:	4628      	mov	r0, r5
   dd9a0:	47a0      	blx	r4
            filter->quantization.params);
    TF_LITE_ENSURE(context, affine_quantization);
    TF_LITE_ENSURE(context, affine_quantization->scale);
  }

  TF_LITE_ENSURE_STATUS(CalculateOpData(
   dd9a2:	2401      	movs	r4, #1
      context->ReportError(context, "Type %s (%d) not supported.",
                           TfLiteTypeGetName(input->type), input->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   dd9a4:	4620      	mov	r0, r4
   dd9a6:	f50d 7d15 	add.w	sp, sp, #596	; 0x254
   dd9aa:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   dd9ae:	bf00      	nop
   dd9b0:	000eb5dd 	.word	0x000eb5dd
   dd9b4:	000eb5f7 	.word	0x000eb5f7
   dd9b8:	000eb4e3 	.word	0x000eb4e3
   dd9bc:	000eb3b9 	.word	0x000eb3b9
   dd9c0:	000eb611 	.word	0x000eb611
   dd9c4:	000eb625 	.word	0x000eb625
   dd9c8:	000eb58e 	.word	0x000eb58e
   dd9cc:	000eb640 	.word	0x000eb640

000dd9d0 <_ZN6tflite3ops5micro16Register_CONV_2DEv>:

TfLiteRegistration* Register_CONV_2D() {
  static TfLiteRegistration r = {conv::Init, conv::Free, conv::Prepare,
                                 conv::Eval};
  return &r;
}
   dd9d0:	4800      	ldr	r0, [pc, #0]	; (dd9d4 <_ZN6tflite3ops5micro16Register_CONV_2DEv+0x4>)
   dd9d2:	4770      	bx	lr
   dd9d4:	2003be50 	.word	0x2003be50

000dd9d8 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode>:
namespace tflite {
namespace ops {
namespace micro {
namespace dequantize {

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   dd9d8:	b5f0      	push	{r4, r5, r6, r7, lr}
   dd9da:	680b      	ldr	r3, [r1, #0]
}
inline const TfLiteTensor* GetIntermediates(TfLiteContext* context,
                                            TfLiteNode* node, int index) {
  return &context->tensors[node->intermediates->data[index]];
}
inline int NumInputs(const TfLiteNode* node) { return node->inputs->size; }
   dd9dc:	681e      	ldr	r6, [r3, #0]
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
   dd9de:	2e01      	cmp	r6, #1
namespace tflite {
namespace ops {
namespace micro {
namespace dequantize {

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   dd9e0:	b085      	sub	sp, #20
   dd9e2:	4605      	mov	r5, r0
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
   dd9e4:	d00c      	beq.n	dda00 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x28>
   dd9e6:	4b20      	ldr	r3, [pc, #128]	; (dda68 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x90>)
   dd9e8:	9301      	str	r3, [sp, #4]
   dd9ea:	2401      	movs	r4, #1
   dd9ec:	4b1f      	ldr	r3, [pc, #124]	; (dda6c <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x94>)
   dd9ee:	9300      	str	r3, [sp, #0]
   dd9f0:	9403      	str	r4, [sp, #12]
   dd9f2:	9602      	str	r6, [sp, #8]
   dd9f4:	6945      	ldr	r5, [r0, #20]
   dd9f6:	4a1e      	ldr	r2, [pc, #120]	; (dda70 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x98>)
   dd9f8:	491e      	ldr	r1, [pc, #120]	; (dda74 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x9c>)
   dd9fa:	231d      	movs	r3, #29
   dd9fc:	47a8      	blx	r5
   dd9fe:	e02d      	b.n	dda5c <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x84>
   dda00:	684f      	ldr	r7, [r1, #4]
inline int NumOutputs(const TfLiteNode* node) { return node->outputs->size; }
   dda02:	683c      	ldr	r4, [r7, #0]
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
   dda04:	2c01      	cmp	r4, #1
   dda06:	d00b      	beq.n	dda20 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x48>
   dda08:	4b17      	ldr	r3, [pc, #92]	; (dda68 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x90>)
   dda0a:	9301      	str	r3, [sp, #4]
   dda0c:	4b1a      	ldr	r3, [pc, #104]	; (dda78 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0xa0>)
   dda0e:	9300      	str	r3, [sp, #0]
   dda10:	9603      	str	r6, [sp, #12]
   dda12:	9402      	str	r4, [sp, #8]
   dda14:	6944      	ldr	r4, [r0, #20]
   dda16:	4a16      	ldr	r2, [pc, #88]	; (dda70 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x98>)
   dda18:	4916      	ldr	r1, [pc, #88]	; (dda74 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x9c>)
   dda1a:	231e      	movs	r3, #30
   dda1c:	47a0      	blx	r4
   dda1e:	e01d      	b.n	dda5c <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x84>

  // TODO(b/140515557): Add cached dequant to improve hybrid model performance.
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];

  TF_LITE_ENSURE(context,
   dda20:	685a      	ldr	r2, [r3, #4]
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);

  // TODO(b/140515557): Add cached dequant to improve hybrid model performance.
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
   dda22:	6881      	ldr	r1, [r0, #8]
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];

  TF_LITE_ENSURE(context,
   dda24:	2338      	movs	r3, #56	; 0x38
   dda26:	435a      	muls	r2, r3
   dda28:	5c8a      	ldrb	r2, [r1, r2]
   dda2a:	2a03      	cmp	r2, #3
   dda2c:	d009      	beq.n	dda42 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x6a>
   dda2e:	2a09      	cmp	r2, #9
   dda30:	d007      	beq.n	dda42 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x6a>
   dda32:	4b12      	ldr	r3, [pc, #72]	; (dda7c <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0xa4>)
   dda34:	9300      	str	r3, [sp, #0]
   dda36:	6945      	ldr	r5, [r0, #20]
   dda38:	4a0d      	ldr	r2, [pc, #52]	; (dda70 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x98>)
   dda3a:	4911      	ldr	r1, [pc, #68]	; (dda80 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0xa8>)
   dda3c:	2325      	movs	r3, #37	; 0x25
   dda3e:	47a8      	blx	r5
   dda40:	e00c      	b.n	dda5c <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x84>
                 input->type == kTfLiteUInt8 || input->type == kTfLiteInt8);
  TF_LITE_ENSURE(context, output->type == kTfLiteFloat32);
   dda42:	687a      	ldr	r2, [r7, #4]
   dda44:	4353      	muls	r3, r2
   dda46:	5ccb      	ldrb	r3, [r1, r3]
   dda48:	2b01      	cmp	r3, #1
   dda4a:	d009      	beq.n	dda60 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x88>
   dda4c:	4b0d      	ldr	r3, [pc, #52]	; (dda84 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0xac>)
   dda4e:	9300      	str	r3, [sp, #0]
   dda50:	696c      	ldr	r4, [r5, #20]
   dda52:	4a07      	ldr	r2, [pc, #28]	; (dda70 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x98>)
   dda54:	490a      	ldr	r1, [pc, #40]	; (dda80 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0xa8>)
   dda56:	2326      	movs	r3, #38	; 0x26
   dda58:	4628      	mov	r0, r5
   dda5a:	47a0      	blx	r4
   dda5c:	2001      	movs	r0, #1
   dda5e:	e000      	b.n	dda62 <_ZN6tflite3ops5micro10dequantize7PrepareEP13TfLiteContextP10TfLiteNode+0x8a>

  return kTfLiteOk;
   dda60:	2000      	movs	r0, #0
}
   dda62:	b005      	add	sp, #20
   dda64:	bdf0      	pop	{r4, r5, r6, r7, pc}
   dda66:	bf00      	nop
   dda68:	000ecdd6 	.word	0x000ecdd6
   dda6c:	000eb3d3 	.word	0x000eb3d3
   dda70:	000eb6b6 	.word	0x000eb6b6
   dda74:	000eb3b9 	.word	0x000eb3b9
   dda78:	000eb3e3 	.word	0x000eb3e3
   dda7c:	000eb767 	.word	0x000eb767
   dda80:	000eb58e 	.word	0x000eb58e
   dda84:	000eb7a1 	.word	0x000eb7a1

000dda88 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_>:
}

// Flat size calculation, checking that dimensions match with one or more other
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
   dda88:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   dda8c:	6806      	ldr	r6, [r0, #0]
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   dda8e:	680b      	ldr	r3, [r1, #0]
   dda90:	429e      	cmp	r6, r3
}

// Flat size calculation, checking that dimensions match with one or more other
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
   dda92:	4604      	mov	r4, r0
   dda94:	460f      	mov	r7, r1
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   dda96:	d101      	bne.n	dda9c <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_+0x14>
   dda98:	2500      	movs	r5, #0
   dda9a:	e00d      	b.n	ddab8 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_+0x30>
   dda9c:	f007 fd2a 	bl	e54f4 <abort>
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   ddaa0:	4629      	mov	r1, r5
   ddaa2:	4620      	mov	r0, r4
   ddaa4:	f7f9 fd6c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   ddaa8:	4629      	mov	r1, r5
   ddaaa:	4680      	mov	r8, r0
   ddaac:	4638      	mov	r0, r7
   ddaae:	f7f9 fd67 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   ddab2:	4580      	cmp	r8, r0
   ddab4:	d1f2      	bne.n	dda9c <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_+0x14>
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   ddab6:	3501      	adds	r5, #1
   ddab8:	42b5      	cmp	r5, r6
   ddaba:	dbf1      	blt.n	ddaa0 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_+0x18>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   ddabc:	2e04      	cmp	r6, #4
   ddabe:	bfcc      	ite	gt
   ddac0:	6864      	ldrgt	r4, [r4, #4]
   ddac2:	3404      	addle	r4, #4
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   ddac4:	2300      	movs	r3, #0
  }

  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
   ddac6:	2001      	movs	r0, #1
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   ddac8:	429e      	cmp	r6, r3
   ddaca:	dd04      	ble.n	ddad6 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_+0x4e>
      buffer_size *= dims_data[i];
   ddacc:	f854 2023 	ldr.w	r2, [r4, r3, lsl #2]
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   ddad0:	3301      	adds	r3, #1
      buffer_size *= dims_data[i];
   ddad2:	4350      	muls	r0, r2
   ddad4:	e7f8      	b.n	ddac8 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_+0x40>
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
  }
  return shape.FlatSize();
}
   ddad6:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	...

000ddadc <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   ddadc:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
   ddae0:	680b      	ldr	r3, [r1, #0]
   ddae2:	f8d0 b008 	ldr.w	fp, [r0, #8]
   ddae6:	685a      	ldr	r2, [r3, #4]
   ddae8:	2338      	movs	r3, #56	; 0x38
   ddaea:	fb03 f802 	mul.w	r8, r3, r2
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];
   ddaee:	684a      	ldr	r2, [r1, #4]

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
   ddaf0:	eb0b 0508 	add.w	r5, fp, r8
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];
   ddaf4:	6854      	ldr	r4, [r2, #4]

  tflite::DequantizationParams op_params;
  op_params.zero_point = input->params.zero_point;
   ddaf6:	f8d5 9010 	ldr.w	r9, [r5, #16]
  TF_LITE_ENSURE(context, output->type == kTfLiteFloat32);

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   ddafa:	b08b      	sub	sp, #44	; 0x2c
   ddafc:	4682      	mov	sl, r0
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];

  tflite::DequantizationParams op_params;
  op_params.zero_point = input->params.zero_point;
  op_params.scale = input->params.scale;
   ddafe:	68e8      	ldr	r0, [r5, #12]
  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];
   ddb00:	fb03 b404 	mla	r4, r3, r4, fp

  tflite::DequantizationParams op_params;
  op_params.zero_point = input->params.zero_point;
  op_params.scale = input->params.scale;
   ddb04:	f00a fc3a 	bl	e837c <__aeabi_f2d>
   ddb08:	4606      	mov	r6, r0
  switch (input->type) {
   ddb0a:	f81b 0008 	ldrb.w	r0, [fp, r8]
   ddb0e:	2803      	cmp	r0, #3
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];

  tflite::DequantizationParams op_params;
  op_params.zero_point = input->params.zero_point;
  op_params.scale = input->params.scale;
   ddb10:	460f      	mov	r7, r1
  switch (input->type) {
   ddb12:	d002      	beq.n	ddb1a <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0x3e>
   ddb14:	2809      	cmp	r0, #9
   ddb16:	d025      	beq.n	ddb64 <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0x88>
   ddb18:	e051      	b.n	ddbbe <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0xe2>
    case kTfLiteUInt8:
      reference_ops::Dequantize(
          op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   ddb1a:	4629      	mov	r1, r5
   ddb1c:	4668      	mov	r0, sp
   ddb1e:	f7f9 ffd4 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
          GetTensorShape(output), GetTensorData<float>(output));
   ddb22:	4621      	mov	r1, r4
   ddb24:	a805      	add	r0, sp, #20
   ddb26:	f8d5 8004 	ldr.w	r8, [r5, #4]
   ddb2a:	f7f9 ffce 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   ddb2e:	b104      	cbz	r4, ddb32 <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0x56>
   ddb30:	6864      	ldr	r4, [r4, #4]
inline void Dequantize(const tflite::DequantizationParams& op_params,
                       const RuntimeShape& input_shape, const T* input_data,
                       const RuntimeShape& output_shape, float* output_data) {
  int32 zero_point = op_params.zero_point;
  const double scale = op_params.scale;
  const int flat_size = MatchingFlatSize(input_shape, output_shape);
   ddb32:	a905      	add	r1, sp, #20
   ddb34:	4668      	mov	r0, sp
   ddb36:	f7ff ffa7 	bl	dda88 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_>
   ddb3a:	4645      	mov	r5, r8
   ddb3c:	4682      	mov	sl, r0

  for (int i = 0; i < flat_size; i++) {
   ddb3e:	ebc8 0305 	rsb	r3, r8, r5
   ddb42:	4553      	cmp	r3, sl
   ddb44:	da33      	bge.n	ddbae <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0xd2>
    const int32 val = input_data[i];
   ddb46:	f815 0b01 	ldrb.w	r0, [r5], #1
    const float result = static_cast<float>(scale * (val - zero_point));
    output_data[i] = result;
   ddb4a:	ebc9 0000 	rsb	r0, r9, r0
   ddb4e:	f00a fc03 	bl	e8358 <__aeabi_i2d>
   ddb52:	4632      	mov	r2, r6
   ddb54:	463b      	mov	r3, r7
   ddb56:	f00a fc65 	bl	e8424 <__aeabi_dmul>
   ddb5a:	f00a ff45 	bl	e89e8 <__aeabi_d2f>
   ddb5e:	f844 0b04 	str.w	r0, [r4], #4
   ddb62:	e7ec      	b.n	ddb3e <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0x62>
      break;
    case kTfLiteInt8:
      reference_ops::Dequantize(
          op_params, GetTensorShape(input), GetTensorData<int8_t>(input),
   ddb64:	4629      	mov	r1, r5
   ddb66:	4668      	mov	r0, sp
   ddb68:	f7f9 ffaf 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
          GetTensorShape(output), GetTensorData<float>(output));
   ddb6c:	4621      	mov	r1, r4
   ddb6e:	a805      	add	r0, sp, #20
   ddb70:	f8d5 8004 	ldr.w	r8, [r5, #4]
   ddb74:	f7f9 ffa9 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   ddb78:	b104      	cbz	r4, ddb7c <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0xa0>
   ddb7a:	6864      	ldr	r4, [r4, #4]
inline void Dequantize(const tflite::DequantizationParams& op_params,
                       const RuntimeShape& input_shape, const T* input_data,
                       const RuntimeShape& output_shape, float* output_data) {
  int32 zero_point = op_params.zero_point;
  const double scale = op_params.scale;
  const int flat_size = MatchingFlatSize(input_shape, output_shape);
   ddb7c:	a905      	add	r1, sp, #20
   ddb7e:	4668      	mov	r0, sp
   ddb80:	f7ff ff82 	bl	dda88 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_>
   ddb84:	4645      	mov	r5, r8
   ddb86:	4682      	mov	sl, r0

  for (int i = 0; i < flat_size; i++) {
   ddb88:	ebc8 0305 	rsb	r3, r8, r5
   ddb8c:	4553      	cmp	r3, sl
   ddb8e:	da0e      	bge.n	ddbae <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0xd2>
    const int32 val = input_data[i];
   ddb90:	f915 0b01 	ldrsb.w	r0, [r5], #1
    const float result = static_cast<float>(scale * (val - zero_point));
    output_data[i] = result;
   ddb94:	ebc9 0000 	rsb	r0, r9, r0
   ddb98:	f00a fbde 	bl	e8358 <__aeabi_i2d>
   ddb9c:	4632      	mov	r2, r6
   ddb9e:	463b      	mov	r3, r7
   ddba0:	f00a fc40 	bl	e8424 <__aeabi_dmul>
   ddba4:	f00a ff20 	bl	e89e8 <__aeabi_d2f>
   ddba8:	f844 0b04 	str.w	r0, [r4], #4
   ddbac:	e7ec      	b.n	ddb88 <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0xac>
   ddbae:	a805      	add	r0, sp, #20
   ddbb0:	f7f9 fcdb 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
          GetTensorShape(output), GetTensorData<float>(output));
      break;
    case kTfLiteInt8:
      reference_ops::Dequantize(
          op_params, GetTensorShape(input), GetTensorData<int8_t>(input),
   ddbb4:	4668      	mov	r0, sp
   ddbb6:	f7f9 fcd8 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      context->ReportError(context, "Type %s (%d) not supported.",
                           TfLiteTypeGetName(input->type), input->type);
      return kTfLiteError;
  }

  return kTfLiteOk;
   ddbba:	2000      	movs	r0, #0
      break;
    case kTfLiteInt8:
      reference_ops::Dequantize(
          op_params, GetTensorShape(input), GetTensorData<int8_t>(input),
          GetTensorShape(output), GetTensorData<float>(output));
      break;
   ddbbc:	e00a      	b.n	ddbd4 <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0xf8>
    default:
      context->ReportError(context, "Type %s (%d) not supported.",
   ddbbe:	f8da 4014 	ldr.w	r4, [sl, #20]
   ddbc2:	f7f6 fab3 	bl	d412c <TfLiteTypeGetName>
                           TfLiteTypeGetName(input->type), input->type);
   ddbc6:	f81b 3008 	ldrb.w	r3, [fp, r8]
   ddbca:	4904      	ldr	r1, [pc, #16]	; (ddbdc <_ZN6tflite3ops5micro10dequantize4EvalEP13TfLiteContextP10TfLiteNode+0x100>)
   ddbcc:	4602      	mov	r2, r0
   ddbce:	4650      	mov	r0, sl
   ddbd0:	47a0      	blx	r4
      return kTfLiteError;
   ddbd2:	2001      	movs	r0, #1
  }

  return kTfLiteOk;
}
   ddbd4:	b00b      	add	sp, #44	; 0x2c
   ddbd6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   ddbda:	bf00      	nop
   ddbdc:	000eb640 	.word	0x000eb640

000ddbe0 <_ZN6tflite3ops5micro19Register_DEQUANTIZEEv>:

TfLiteRegistration* Register_DEQUANTIZE() {
  static TfLiteRegistration r = {nullptr, nullptr, dequantize::Prepare,
                                 dequantize::Eval};
  return &r;
}
   ddbe0:	4800      	ldr	r0, [pc, #0]	; (ddbe4 <_ZN6tflite3ops5micro19Register_DEQUANTIZEEv+0x4>)
   ddbe2:	4770      	bx	lr
   ddbe4:	2003be70 	.word	0x2003be70

000ddbe8 <_ZSt3absf>:
#endif

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  abs(float __x)
  { return __builtin_fabsf(__x); }
   ddbe8:	eeb0 0ac0 	vabs.f32	s0, s0
   ddbec:	4770      	bx	lr

000ddbee <_ZZN6tflite3ops5micro11elementwise12_GLOBAL__N_110SquareEvalEP13TfLiteContextP10TfLiteNodeENUlfE_4_FUNEf>:
TfLiteStatus RsqrtEval(TfLiteContext* context, TfLiteNode* node) {
  return EvalNumeric(context, node, [](float f) { return 1.f / std::sqrt(f); });
}

TfLiteStatus SquareEval(TfLiteContext* context, TfLiteNode* node) {
  return EvalNumeric(context, node, [](float f) { return f * f; });
   ddbee:	ee20 0a00 	vmul.f32	s0, s0, s0
   ddbf2:	4770      	bx	lr

000ddbf4 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode>:
  return type == kTfLiteBool;
}

typedef bool (*IsSupportedType)(TfLiteType);
template <IsSupportedType>
TfLiteStatus GenericPrepare(TfLiteContext* context, TfLiteNode* node) {
   ddbf4:	e92d 41ff 	stmdb	sp!, {r0, r1, r2, r3, r4, r5, r6, r7, r8, lr}
   ddbf8:	680b      	ldr	r3, [r1, #0]
}
inline const TfLiteTensor* GetIntermediates(TfLiteContext* context,
                                            TfLiteNode* node, int index) {
  return &context->tensors[node->intermediates->data[index]];
}
inline int NumInputs(const TfLiteNode* node) { return node->inputs->size; }
   ddbfa:	681e      	ldr	r6, [r3, #0]
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
   ddbfc:	2e01      	cmp	r6, #1
  return type == kTfLiteBool;
}

typedef bool (*IsSupportedType)(TfLiteType);
template <IsSupportedType>
TfLiteStatus GenericPrepare(TfLiteContext* context, TfLiteNode* node) {
   ddbfe:	4605      	mov	r5, r0
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
   ddc00:	d009      	beq.n	ddc16 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x22>
   ddc02:	4b21      	ldr	r3, [pc, #132]	; (ddc88 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x94>)
   ddc04:	9301      	str	r3, [sp, #4]
   ddc06:	2401      	movs	r4, #1
   ddc08:	4b20      	ldr	r3, [pc, #128]	; (ddc8c <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x98>)
   ddc0a:	9300      	str	r3, [sp, #0]
   ddc0c:	9403      	str	r4, [sp, #12]
   ddc0e:	9602      	str	r6, [sp, #8]
   ddc10:	6945      	ldr	r5, [r0, #20]
   ddc12:	2327      	movs	r3, #39	; 0x27
   ddc14:	e022      	b.n	ddc5c <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x68>
   ddc16:	6849      	ldr	r1, [r1, #4]
inline int NumOutputs(const TfLiteNode* node) { return node->outputs->size; }
   ddc18:	680c      	ldr	r4, [r1, #0]
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
   ddc1a:	2c01      	cmp	r4, #1
   ddc1c:	d00c      	beq.n	ddc38 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x44>
   ddc1e:	4b1a      	ldr	r3, [pc, #104]	; (ddc88 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x94>)
   ddc20:	9301      	str	r3, [sp, #4]
   ddc22:	4b1b      	ldr	r3, [pc, #108]	; (ddc90 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x9c>)
   ddc24:	9300      	str	r3, [sp, #0]
   ddc26:	9603      	str	r6, [sp, #12]
   ddc28:	9402      	str	r4, [sp, #8]
   ddc2a:	6944      	ldr	r4, [r0, #20]
   ddc2c:	4a19      	ldr	r2, [pc, #100]	; (ddc94 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xa0>)
   ddc2e:	491a      	ldr	r1, [pc, #104]	; (ddc98 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xa4>)
   ddc30:	2328      	movs	r3, #40	; 0x28
   ddc32:	47a0      	blx	r4
   ddc34:	4630      	mov	r0, r6
   ddc36:	e023      	b.n	ddc80 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x8c>
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   ddc38:	685e      	ldr	r6, [r3, #4]
  const TfLiteTensor* input = GetInput(context, node, 0);
  TfLiteTensor* output = GetOutput(context, node, 0);
  TF_LITE_ENSURE_EQ(context, input->type, output->type);
   ddc3a:	6849      	ldr	r1, [r1, #4]
   ddc3c:	6887      	ldr	r7, [r0, #8]
   ddc3e:	2238      	movs	r2, #56	; 0x38
   ddc40:	4356      	muls	r6, r2
   ddc42:	434a      	muls	r2, r1
   ddc44:	5dbb      	ldrb	r3, [r7, r6]
   ddc46:	5cba      	ldrb	r2, [r7, r2]
   ddc48:	4293      	cmp	r3, r2
   ddc4a:	d00b      	beq.n	ddc64 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x70>
   ddc4c:	9302      	str	r3, [sp, #8]
   ddc4e:	4b13      	ldr	r3, [pc, #76]	; (ddc9c <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xa8>)
   ddc50:	9301      	str	r3, [sp, #4]
   ddc52:	4b13      	ldr	r3, [pc, #76]	; (ddca0 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xac>)
   ddc54:	9300      	str	r3, [sp, #0]
   ddc56:	9203      	str	r2, [sp, #12]
   ddc58:	6945      	ldr	r5, [r0, #20]
   ddc5a:	232b      	movs	r3, #43	; 0x2b
   ddc5c:	4a0d      	ldr	r2, [pc, #52]	; (ddc94 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xa0>)
   ddc5e:	490e      	ldr	r1, [pc, #56]	; (ddc98 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xa4>)
   ddc60:	47a8      	blx	r5
   ddc62:	e00a      	b.n	ddc7a <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x86>
  if (!IsSupportedType(input->type)) {
   ddc64:	b95b      	cbnz	r3, ddc7e <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x8a>
    context->ReportError(context, "Input data type %s (%d) is not supported.",
   ddc66:	f8d0 8014 	ldr.w	r8, [r0, #20]
   ddc6a:	4618      	mov	r0, r3
   ddc6c:	f7f6 fa5e 	bl	d412c <TfLiteTypeGetName>
   ddc70:	5dbb      	ldrb	r3, [r7, r6]
   ddc72:	490c      	ldr	r1, [pc, #48]	; (ddca4 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xb0>)
   ddc74:	4602      	mov	r2, r0
   ddc76:	4628      	mov	r0, r5
   ddc78:	47c0      	blx	r8
                         TfLiteTypeGetName(input->type), input->type);
    return kTfLiteError;
   ddc7a:	4620      	mov	r0, r4
   ddc7c:	e000      	b.n	ddc80 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x8c>
  }
  return kTfLiteOk;
   ddc7e:	2000      	movs	r0, #0
}
   ddc80:	b004      	add	sp, #16
   ddc82:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   ddc86:	bf00      	nop
   ddc88:	000ecdd6 	.word	0x000ecdd6
   ddc8c:	000eb3d3 	.word	0x000eb3d3
   ddc90:	000eb3e3 	.word	0x000eb3e3
   ddc94:	000eb7c0 	.word	0x000eb7c0
   ddc98:	000eb3b9 	.word	0x000eb3b9
   ddc9c:	000eb400 	.word	0x000eb400
   ddca0:	000eb3f4 	.word	0x000eb3f4
   ddca4:	000eb872 	.word	0x000eb872

000ddca8 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsNumericSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode>:
   ddca8:	f7ff bfa4 	b.w	ddbf4 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114GenericPrepareIXadL_ZNS3_22IsLogicalSupportedTypeE10TfLiteTypeEEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode>

000ddcac <_ZSt3sinf>:
  using ::sin;

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  sin(float __x)
  { return __builtin_sinf(__x); }
   ddcac:	f008 be48 	b.w	e6940 <sinf>

000ddcb0 <_ZSt3cosf>:
  using ::cos;

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  cos(float __x)
  { return __builtin_cosf(__x); }
   ddcb0:	f008 bd2e 	b.w	e6710 <cosf>

000ddcb4 <_ZSt3logf>:
  using ::log;

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  log(float __x)
  { return __builtin_logf(__x); }
   ddcb4:	f008 bf96 	b.w	e6be4 <logf>

000ddcb8 <_ZSt4sqrtf>:
  using ::sqrt;

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  sqrt(float __x)
  { return __builtin_sqrtf(__x); }
   ddcb8:	f009 b810 	b.w	e6cdc <sqrtf>

000ddcbc <_ZZN6tflite3ops5micro11elementwise12_GLOBAL__N_19RsqrtEvalEP13TfLiteContextP10TfLiteNodeENUlfE_4_FUNEf>:
TfLiteStatus SqrtEval(TfLiteContext* context, TfLiteNode* node) {
  return EvalNumeric(context, node, std::sqrt);
}

TfLiteStatus RsqrtEval(TfLiteContext* context, TfLiteNode* node) {
  return EvalNumeric(context, node, [](float f) { return 1.f / std::sqrt(f); });
   ddcbc:	b508      	push	{r3, lr}
   ddcbe:	f009 f80d 	bl	e6cdc <sqrtf>
   ddcc2:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   ddcc6:	ee87 0a80 	vdiv.f32	s0, s15, s0
   ddcca:	bd08      	pop	{r3, pc}

000ddccc <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13>:
  }
  return kTfLiteOk;
}

template <typename T>
inline TfLiteStatus EvalImpl(TfLiteContext* context, TfLiteNode* node,
   ddccc:	e92d 4dff 	stmdb	sp!, {r0, r1, r2, r3, r4, r5, r6, r7, r8, sl, fp, lr}
   ddcd0:	4690      	mov	r8, r2
   ddcd2:	680a      	ldr	r2, [r1, #0]
   ddcd4:	6883      	ldr	r3, [r0, #8]
   ddcd6:	6854      	ldr	r4, [r2, #4]
   ddcd8:	2238      	movs	r2, #56	; 0x38
   ddcda:	4362      	muls	r2, r4
   ddcdc:	189c      	adds	r4, r3, r2
                             T func(T), TfLiteType expected_type) {
  const TfLiteTensor* input = GetInput(context, node, 0);
  TfLiteTensor* output = GetOutput(context, node, 0);
  TF_LITE_ENSURE_EQ(context, input->type, expected_type);
   ddcde:	5c9a      	ldrb	r2, [r3, r2]
   ddce0:	2a01      	cmp	r2, #1
   ddce2:	d00d      	beq.n	ddd00 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0x34>
   ddce4:	4b20      	ldr	r3, [pc, #128]	; (ddd68 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0x9c>)
   ddce6:	9301      	str	r3, [sp, #4]
   ddce8:	2401      	movs	r4, #1
   ddcea:	4b20      	ldr	r3, [pc, #128]	; (ddd6c <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0xa0>)
   ddcec:	9202      	str	r2, [sp, #8]
   ddcee:	9300      	str	r3, [sp, #0]
   ddcf0:	9403      	str	r4, [sp, #12]
   ddcf2:	6945      	ldr	r5, [r0, #20]
   ddcf4:	4a1e      	ldr	r2, [pc, #120]	; (ddd70 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0xa4>)
   ddcf6:	491f      	ldr	r1, [pc, #124]	; (ddd74 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0xa8>)
   ddcf8:	2339      	movs	r3, #57	; 0x39
   ddcfa:	47a8      	blx	r5
   ddcfc:	4620      	mov	r0, r4
   ddcfe:	e030      	b.n	ddd62 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0x96>
   ddd00:	68a0      	ldr	r0, [r4, #8]
  return node->intermediates->size;
}

inline int64_t NumElements(const TfLiteIntArray* dims) {
  int64_t count = 1;
  for (int i = 0; i < dims->size; ++i) {
   ddd02:	f8d0 e000 	ldr.w	lr, [r0]
   ddd06:	2200      	movs	r2, #0
inline int NumIntermediates(const TfLiteNode* node) {
  return node->intermediates->size;
}

inline int64_t NumElements(const TfLiteIntArray* dims) {
  int64_t count = 1;
   ddd08:	2601      	movs	r6, #1
   ddd0a:	2700      	movs	r7, #0
  for (int i = 0; i < dims->size; ++i) {
   ddd0c:	4596      	cmp	lr, r2
   ddd0e:	dd0c      	ble.n	ddd2a <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0x5e>
    count *= dims->data[i];
   ddd10:	f850 cf04 	ldr.w	ip, [r0, #4]!
   ddd14:	ea4f 7bec 	mov.w	fp, ip, asr #31
   ddd18:	fb06 f50b 	mul.w	r5, r6, fp
   ddd1c:	fb0c 5507 	mla	r5, ip, r7, r5
   ddd20:	fba6 670c 	umull	r6, r7, r6, ip
   ddd24:	442f      	add	r7, r5
  return node->intermediates->size;
}

inline int64_t NumElements(const TfLiteIntArray* dims) {
  int64_t count = 1;
  for (int i = 0; i < dims->size; ++i) {
   ddd26:	3201      	adds	r2, #1
   ddd28:	e7f0      	b.n	ddd0c <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0x40>
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   ddd2a:	684a      	ldr	r2, [r1, #4]
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   ddd2c:	6865      	ldr	r5, [r4, #4]
   ddd2e:	6851      	ldr	r1, [r2, #4]
   ddd30:	2238      	movs	r2, #56	; 0x38
   ddd32:	fb02 3301 	mla	r3, r2, r1, r3

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   ddd36:	b103      	cbz	r3, ddd3a <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0x6e>
   ddd38:	685b      	ldr	r3, [r3, #4]
   ddd3a:	461c      	mov	r4, r3
  const int64_t num_elements = NumElements(input);
  const T* in_data = GetTensorData<T>(input);
  T* out_data = GetTensorData<T>(output);
  for (int64_t i = 0; i < num_elements; ++i) {
   ddd3c:	f04f 0a00 	mov.w	sl, #0
   ddd40:	f04f 0b00 	mov.w	fp, #0
   ddd44:	45b2      	cmp	sl, r6
   ddd46:	eb7b 0307 	sbcs.w	r3, fp, r7
   ddd4a:	da09      	bge.n	ddd60 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0x94>
    out_data[i] = func(in_data[i]);
   ddd4c:	ecb5 0a01 	vldmia	r5!, {s0}
   ddd50:	47c0      	blx	r8
  TfLiteTensor* output = GetOutput(context, node, 0);
  TF_LITE_ENSURE_EQ(context, input->type, expected_type);
  const int64_t num_elements = NumElements(input);
  const T* in_data = GetTensorData<T>(input);
  T* out_data = GetTensorData<T>(output);
  for (int64_t i = 0; i < num_elements; ++i) {
   ddd52:	f11a 0a01 	adds.w	sl, sl, #1
    out_data[i] = func(in_data[i]);
   ddd56:	eca4 0a01 	vstmia	r4!, {s0}
  TfLiteTensor* output = GetOutput(context, node, 0);
  TF_LITE_ENSURE_EQ(context, input->type, expected_type);
  const int64_t num_elements = NumElements(input);
  const T* in_data = GetTensorData<T>(input);
  T* out_data = GetTensorData<T>(output);
  for (int64_t i = 0; i < num_elements; ++i) {
   ddd5a:	f14b 0b00 	adc.w	fp, fp, #0
   ddd5e:	e7f1      	b.n	ddd44 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13+0x78>
    out_data[i] = func(in_data[i]);
  }
  return kTfLiteOk;
   ddd60:	2000      	movs	r0, #0
}
   ddd62:	b004      	add	sp, #16
   ddd64:	e8bd 8df0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, sl, fp, pc}
   ddd68:	000eb89c 	.word	0x000eb89c
   ddd6c:	000eb3f4 	.word	0x000eb3f4
   ddd70:	000eb7c0 	.word	0x000eb7c0
   ddd74:	000eb3b9 	.word	0x000eb3b9

000ddd78 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_110SquareEvalEP13TfLiteContextP10TfLiteNode>:

inline TfLiteStatus EvalNumeric(TfLiteContext* context, TfLiteNode* node,
                                float float_func(float)) {
  return EvalImpl<float>(context, node, float_func, kTfLiteFloat32);
   ddd78:	4a01      	ldr	r2, [pc, #4]	; (ddd80 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_110SquareEvalEP13TfLiteContextP10TfLiteNode+0x8>)
   ddd7a:	f7ff bfa7 	b.w	ddccc <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13>
   ddd7e:	bf00      	nop
   ddd80:	000ddbef 	.word	0x000ddbef

000ddd84 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_17AbsEvalEP13TfLiteContextP10TfLiteNode>:
   ddd84:	4a01      	ldr	r2, [pc, #4]	; (ddd8c <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_17AbsEvalEP13TfLiteContextP10TfLiteNode+0x8>)
   ddd86:	f7ff bfa1 	b.w	ddccc <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13>
   ddd8a:	bf00      	nop
   ddd8c:	000ddbe9 	.word	0x000ddbe9

000ddd90 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_17SinEvalEP13TfLiteContextP10TfLiteNode>:
   ddd90:	4a01      	ldr	r2, [pc, #4]	; (ddd98 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_17SinEvalEP13TfLiteContextP10TfLiteNode+0x8>)
   ddd92:	f7ff bf9b 	b.w	ddccc <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13>
   ddd96:	bf00      	nop
   ddd98:	000ddcad 	.word	0x000ddcad

000ddd9c <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_17CosEvalEP13TfLiteContextP10TfLiteNode>:
   ddd9c:	4a01      	ldr	r2, [pc, #4]	; (ddda4 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_17CosEvalEP13TfLiteContextP10TfLiteNode+0x8>)
   ddd9e:	f7ff bf95 	b.w	ddccc <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13>
   ddda2:	bf00      	nop
   ddda4:	000ddcb1 	.word	0x000ddcb1

000ddda8 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_19RsqrtEvalEP13TfLiteContextP10TfLiteNode>:
   ddda8:	4a01      	ldr	r2, [pc, #4]	; (dddb0 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_19RsqrtEvalEP13TfLiteContextP10TfLiteNode+0x8>)
   dddaa:	f7ff bf8f 	b.w	ddccc <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13>
   dddae:	bf00      	nop
   dddb0:	000ddcbd 	.word	0x000ddcbd

000dddb4 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_17LogEvalEP13TfLiteContextP10TfLiteNode>:
   dddb4:	4a01      	ldr	r2, [pc, #4]	; (dddbc <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_17LogEvalEP13TfLiteContextP10TfLiteNode+0x8>)
   dddb6:	f7ff bf89 	b.w	ddccc <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13>
   dddba:	bf00      	nop
   dddbc:	000ddcb5 	.word	0x000ddcb5

000dddc0 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18SqrtEvalEP13TfLiteContextP10TfLiteNode>:
   dddc0:	4a01      	ldr	r2, [pc, #4]	; (dddc8 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18SqrtEvalEP13TfLiteContextP10TfLiteNode+0x8>)
   dddc2:	f7ff bf83 	b.w	ddccc <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_18EvalImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePFT_SA_E10TfLiteType.constprop.13>
   dddc6:	bf00      	nop
   dddc8:	000ddcb9 	.word	0x000ddcb9

000dddcc <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus SquareEval(TfLiteContext* context, TfLiteNode* node) {
  return EvalNumeric(context, node, [](float f) { return f * f; });
}

TfLiteStatus LogicalNotEval(TfLiteContext* context, TfLiteNode* node) {
   dddcc:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   dddd0:	680a      	ldr	r2, [r1, #0]
   dddd2:	6883      	ldr	r3, [r0, #8]
   dddd4:	460f      	mov	r7, r1
   dddd6:	6851      	ldr	r1, [r2, #4]
   dddd8:	2238      	movs	r2, #56	; 0x38
   dddda:	434a      	muls	r2, r1
   ddddc:	189e      	adds	r6, r3, r2
template <typename T>
inline TfLiteStatus EvalImpl(TfLiteContext* context, TfLiteNode* node,
                             T func(T), TfLiteType expected_type) {
  const TfLiteTensor* input = GetInput(context, node, 0);
  TfLiteTensor* output = GetOutput(context, node, 0);
  TF_LITE_ENSURE_EQ(context, input->type, expected_type);
   dddde:	5c9a      	ldrb	r2, [r3, r2]
   ddde0:	2a06      	cmp	r2, #6

TfLiteStatus SquareEval(TfLiteContext* context, TfLiteNode* node) {
  return EvalNumeric(context, node, [](float f) { return f * f; });
}

TfLiteStatus LogicalNotEval(TfLiteContext* context, TfLiteNode* node) {
   ddde2:	b085      	sub	sp, #20
template <typename T>
inline TfLiteStatus EvalImpl(TfLiteContext* context, TfLiteNode* node,
                             T func(T), TfLiteType expected_type) {
  const TfLiteTensor* input = GetInput(context, node, 0);
  TfLiteTensor* output = GetOutput(context, node, 0);
  TF_LITE_ENSURE_EQ(context, input->type, expected_type);
   ddde4:	d00d      	beq.n	dde02 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0x36>
   ddde6:	2306      	movs	r3, #6
   ddde8:	9303      	str	r3, [sp, #12]
   dddea:	4b1f      	ldr	r3, [pc, #124]	; (dde68 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0x9c>)
   dddec:	9301      	str	r3, [sp, #4]
   dddee:	4b1f      	ldr	r3, [pc, #124]	; (dde6c <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0xa0>)
   dddf0:	9202      	str	r2, [sp, #8]
   dddf2:	9300      	str	r3, [sp, #0]
   dddf4:	6944      	ldr	r4, [r0, #20]
   dddf6:	4a1e      	ldr	r2, [pc, #120]	; (dde70 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0xa4>)
   dddf8:	491e      	ldr	r1, [pc, #120]	; (dde74 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0xa8>)
   dddfa:	2339      	movs	r3, #57	; 0x39
   dddfc:	47a0      	blx	r4
   dddfe:	2001      	movs	r0, #1
   dde00:	e02f      	b.n	dde62 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0x96>
   dde02:	68b2      	ldr	r2, [r6, #8]
  return node->intermediates->size;
}

inline int64_t NumElements(const TfLiteIntArray* dims) {
  int64_t count = 1;
  for (int i = 0; i < dims->size; ++i) {
   dde04:	f8d2 c000 	ldr.w	ip, [r2]
   dde08:	2400      	movs	r4, #0
inline int NumIntermediates(const TfLiteNode* node) {
  return node->intermediates->size;
}

inline int64_t NumElements(const TfLiteIntArray* dims) {
  int64_t count = 1;
   dde0a:	2001      	movs	r0, #1
   dde0c:	2100      	movs	r1, #0
  for (int i = 0; i < dims->size; ++i) {
   dde0e:	45a4      	cmp	ip, r4
   dde10:	dd0c      	ble.n	dde2c <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0x60>
    count *= dims->data[i];
   dde12:	f852 ef04 	ldr.w	lr, [r2, #4]!
   dde16:	ea4f 79ee 	mov.w	r9, lr, asr #31
   dde1a:	fb00 f509 	mul.w	r5, r0, r9
   dde1e:	fb0e 5501 	mla	r5, lr, r1, r5
   dde22:	fba0 010e 	umull	r0, r1, r0, lr
   dde26:	4429      	add	r1, r5
  return node->intermediates->size;
}

inline int64_t NumElements(const TfLiteIntArray* dims) {
  int64_t count = 1;
  for (int i = 0; i < dims->size; ++i) {
   dde28:	3401      	adds	r4, #1
   dde2a:	e7f0      	b.n	dde0e <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0x42>
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dde2c:	687a      	ldr	r2, [r7, #4]
   dde2e:	6852      	ldr	r2, [r2, #4]
   dde30:	2438      	movs	r4, #56	; 0x38
   dde32:	fb04 3302 	mla	r3, r4, r2, r3
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dde36:	6872      	ldr	r2, [r6, #4]

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dde38:	b103      	cbz	r3, dde3c <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0x70>
   dde3a:	685b      	ldr	r3, [r3, #4]
   dde3c:	3a01      	subs	r2, #1
   dde3e:	3b01      	subs	r3, #1
  const int64_t num_elements = NumElements(input);
  const T* in_data = GetTensorData<T>(input);
  T* out_data = GetTensorData<T>(output);
  for (int64_t i = 0; i < num_elements; ++i) {
   dde40:	2400      	movs	r4, #0
   dde42:	2500      	movs	r5, #0
   dde44:	4284      	cmp	r4, r0
   dde46:	eb75 0601 	sbcs.w	r6, r5, r1
   dde4a:	da09      	bge.n	dde60 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0x94>
    out_data[i] = func(in_data[i]);
   dde4c:	f812 6f01 	ldrb.w	r6, [r2, #1]!
  TfLiteTensor* output = GetOutput(context, node, 0);
  TF_LITE_ENSURE_EQ(context, input->type, expected_type);
  const int64_t num_elements = NumElements(input);
  const T* in_data = GetTensorData<T>(input);
  T* out_data = GetTensorData<T>(output);
  for (int64_t i = 0; i < num_elements; ++i) {
   dde50:	3401      	adds	r4, #1
    out_data[i] = func(in_data[i]);
   dde52:	f086 0601 	eor.w	r6, r6, #1
   dde56:	f803 6f01 	strb.w	r6, [r3, #1]!
  TfLiteTensor* output = GetOutput(context, node, 0);
  TF_LITE_ENSURE_EQ(context, input->type, expected_type);
  const int64_t num_elements = NumElements(input);
  const T* in_data = GetTensorData<T>(input);
  T* out_data = GetTensorData<T>(output);
  for (int64_t i = 0; i < num_elements; ++i) {
   dde5a:	f145 0500 	adc.w	r5, r5, #0
   dde5e:	e7f1      	b.n	dde44 <_ZN6tflite3ops5micro11elementwise12_GLOBAL__N_114LogicalNotEvalEP13TfLiteContextP10TfLiteNode+0x78>
    out_data[i] = func(in_data[i]);
  }
  return kTfLiteOk;
   dde60:	2000      	movs	r0, #0
  return EvalNumeric(context, node, [](float f) { return f * f; });
}

TfLiteStatus LogicalNotEval(TfLiteContext* context, TfLiteNode* node) {
  return EvalLogical(context, node, [](bool v) { return !v; });
}
   dde62:	b005      	add	sp, #20
   dde64:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
   dde68:	000eb89c 	.word	0x000eb89c
   dde6c:	000eb3f4 	.word	0x000eb3f4
   dde70:	000eb7c0 	.word	0x000eb7c0
   dde74:	000eb3b9 	.word	0x000eb3b9

000dde78 <_ZN6tflite3ops5micro12Register_ABSEv>:
  static TfLiteRegistration r = {
      /* init */ nullptr, /* free */ nullptr,
      elementwise::GenericPrepare<elementwise::IsNumericSupportedType>,
      elementwise::AbsEval};
  return &r;
}
   dde78:	4800      	ldr	r0, [pc, #0]	; (dde7c <_ZN6tflite3ops5micro12Register_ABSEv+0x4>)
   dde7a:	4770      	bx	lr
   dde7c:	2003bf70 	.word	0x2003bf70

000dde80 <_ZN6tflite3ops5micro12Register_SINEv>:
  static TfLiteRegistration r = {
      /* init */ nullptr, /* free */ nullptr,
      elementwise::GenericPrepare<elementwise::IsNumericSupportedType>,
      elementwise::SinEval};
  return &r;
}
   dde80:	4800      	ldr	r0, [pc, #0]	; (dde84 <_ZN6tflite3ops5micro12Register_SINEv+0x4>)
   dde82:	4770      	bx	lr
   dde84:	2003bf50 	.word	0x2003bf50

000dde88 <_ZN6tflite3ops5micro12Register_COSEv>:
  static TfLiteRegistration r = {
      /* init */ nullptr, /* free */ nullptr,
      elementwise::GenericPrepare<elementwise::IsNumericSupportedType>,
      elementwise::CosEval};
  return &r;
}
   dde88:	4800      	ldr	r0, [pc, #0]	; (dde8c <_ZN6tflite3ops5micro12Register_COSEv+0x4>)
   dde8a:	4770      	bx	lr
   dde8c:	2003bed0 	.word	0x2003bed0

000dde90 <_ZN6tflite3ops5micro12Register_LOGEv>:
  static TfLiteRegistration r = {
      /* init */ nullptr, /* free */ nullptr,
      elementwise::GenericPrepare<elementwise::IsNumericSupportedType>,
      elementwise::LogEval};
  return &r;
}
   dde90:	4800      	ldr	r0, [pc, #0]	; (dde94 <_ZN6tflite3ops5micro12Register_LOGEv+0x4>)
   dde92:	4770      	bx	lr
   dde94:	2003be90 	.word	0x2003be90

000dde98 <_ZN6tflite3ops5micro13Register_SQRTEv>:
  static TfLiteRegistration r = {
      /* init */ nullptr, /* free */ nullptr,
      elementwise::GenericPrepare<elementwise::IsNumericSupportedType>,
      elementwise::SqrtEval};
  return &r;
}
   dde98:	4800      	ldr	r0, [pc, #0]	; (dde9c <_ZN6tflite3ops5micro13Register_SQRTEv+0x4>)
   dde9a:	4770      	bx	lr
   dde9c:	2003bf30 	.word	0x2003bf30

000ddea0 <_ZN6tflite3ops5micro14Register_RSQRTEv>:
  static TfLiteRegistration r = {
      /* init */ nullptr, /* free */ nullptr,
      elementwise::GenericPrepare<elementwise::IsNumericSupportedType>,
      elementwise::RsqrtEval};
  return &r;
}
   ddea0:	4800      	ldr	r0, [pc, #0]	; (ddea4 <_ZN6tflite3ops5micro14Register_RSQRTEv+0x4>)
   ddea2:	4770      	bx	lr
   ddea4:	2003bf10 	.word	0x2003bf10

000ddea8 <_ZN6tflite3ops5micro15Register_SQUAREEv>:
  static TfLiteRegistration r = {
      /* init */ nullptr, /* free */ nullptr,
      elementwise::GenericPrepare<elementwise::IsNumericSupportedType>,
      elementwise::SquareEval};
  return &r;
}
   ddea8:	4800      	ldr	r0, [pc, #0]	; (ddeac <_ZN6tflite3ops5micro15Register_SQUAREEv+0x4>)
   ddeaa:	4770      	bx	lr
   ddeac:	2003beb0 	.word	0x2003beb0

000ddeb0 <_ZN6tflite3ops5micro20Register_LOGICAL_NOTEv>:
  static TfLiteRegistration r = {
      /*init=*/nullptr, /*free=*/nullptr,
      elementwise::GenericPrepare<elementwise::IsLogicalSupportedType>,
      elementwise::LogicalNotEval};
  return &r;
}
   ddeb0:	4800      	ldr	r0, [pc, #0]	; (ddeb4 <_ZN6tflite3ops5micro20Register_LOGICAL_NOTEv+0x4>)
   ddeb2:	4770      	bx	lr
   ddeb4:	2003bef0 	.word	0x2003bef0

000ddeb8 <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode>:
namespace floor {

constexpr int kInputTensor = 0;
constexpr int kOutputTensor = 0;

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   ddeb8:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   ddebc:	680b      	ldr	r3, [r1, #0]
   ddebe:	6882      	ldr	r2, [r0, #8]
   ddec0:	685b      	ldr	r3, [r3, #4]
   ddec2:	2438      	movs	r4, #56	; 0x38
   ddec4:	4363      	muls	r3, r4
   ddec6:	18d5      	adds	r5, r2, r3
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);
   ddec8:	5cd3      	ldrb	r3, [r2, r3]
   ddeca:	2b01      	cmp	r3, #1
namespace floor {

constexpr int kInputTensor = 0;
constexpr int kOutputTensor = 0;

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   ddecc:	b08e      	sub	sp, #56	; 0x38
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);
   ddece:	d00d      	beq.n	ddeec <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0x34>
   dded0:	9302      	str	r3, [sp, #8]
   dded2:	4b2b      	ldr	r3, [pc, #172]	; (ddf80 <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0xc8>)
   dded4:	9301      	str	r3, [sp, #4]
   dded6:	2401      	movs	r4, #1
   dded8:	4b2a      	ldr	r3, [pc, #168]	; (ddf84 <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0xcc>)
   ddeda:	9300      	str	r3, [sp, #0]
   ddedc:	9403      	str	r4, [sp, #12]
   ddede:	6945      	ldr	r5, [r0, #20]
   ddee0:	4a29      	ldr	r2, [pc, #164]	; (ddf88 <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0xd0>)
   ddee2:	492a      	ldr	r1, [pc, #168]	; (ddf8c <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0xd4>)
   ddee4:	231f      	movs	r3, #31
   ddee6:	47a8      	blx	r5
   ddee8:	4620      	mov	r0, r4
   ddeea:	e046      	b.n	ddf7a <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0xc2>
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   ddeec:	684b      	ldr	r3, [r1, #4]
   ddeee:	685b      	ldr	r3, [r3, #4]
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  reference_ops::Floor(GetTensorShape(input), GetTensorData<float>(input),
   ddef0:	4629      	mov	r1, r5
   ddef2:	fb04 2403 	mla	r4, r4, r3, r2
   ddef6:	a804      	add	r0, sp, #16
   ddef8:	f7f9 fde7 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
                       GetTensorShape(output), GetTensorData<float>(output));
   ddefc:	4621      	mov	r1, r4
   ddefe:	a809      	add	r0, sp, #36	; 0x24
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   ddf00:	686e      	ldr	r6, [r5, #4]
   ddf02:	f7f9 fde2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   ddf06:	b104      	cbz	r4, ddf0a <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0x52>
   ddf08:	6864      	ldr	r4, [r4, #4]
   ddf0a:	9f04      	ldr	r7, [sp, #16]

// Flat size calculation, checking that dimensions match with one or more other
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   ddf0c:	9b09      	ldr	r3, [sp, #36]	; 0x24
   ddf0e:	429f      	cmp	r7, r3
   ddf10:	d101      	bne.n	ddf16 <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0x5e>
   ddf12:	2500      	movs	r5, #0
   ddf14:	e00d      	b.n	ddf32 <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0x7a>
   ddf16:	f007 faed 	bl	e54f4 <abort>
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   ddf1a:	4629      	mov	r1, r5
   ddf1c:	a804      	add	r0, sp, #16
   ddf1e:	f7f9 fb2f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   ddf22:	4629      	mov	r1, r5
   ddf24:	4680      	mov	r8, r0
   ddf26:	a809      	add	r0, sp, #36	; 0x24
   ddf28:	f7f9 fb2a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   ddf2c:	4580      	cmp	r8, r0
   ddf2e:	d1f2      	bne.n	ddf16 <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0x5e>
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   ddf30:	3501      	adds	r5, #1
   ddf32:	42af      	cmp	r7, r5
   ddf34:	dcf1      	bgt.n	ddf1a <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0x62>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   ddf36:	2f04      	cmp	r7, #4
   ddf38:	bfcc      	ite	gt
   ddf3a:	9a05      	ldrgt	r2, [sp, #20]
   ddf3c:	aa05      	addle	r2, sp, #20
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   ddf3e:	2300      	movs	r3, #0
  }

  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
   ddf40:	f04f 0801 	mov.w	r8, #1
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   ddf44:	429f      	cmp	r7, r3
   ddf46:	dd05      	ble.n	ddf54 <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0x9c>
      buffer_size *= dims_data[i];
   ddf48:	f852 1023 	ldr.w	r1, [r2, r3, lsl #2]
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   ddf4c:	3301      	adds	r3, #1
      buffer_size *= dims_data[i];
   ddf4e:	fb01 f808 	mul.w	r8, r1, r8
   ddf52:	e7f7      	b.n	ddf44 <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0x8c>
   ddf54:	4635      	mov	r5, r6
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   ddf56:	2600      	movs	r6, #0

inline void Floor(const RuntimeShape& input_shape, const float* input_data,
                  const RuntimeShape& output_shape, float* output_data) {
  const int flat_size = MatchingFlatSize(input_shape, output_shape);

  for (int i = 0; i < flat_size; i++) {
   ddf58:	4546      	cmp	r6, r8
   ddf5a:	da07      	bge.n	ddf6c <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0xb4>
  using ::floor;

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  floor(float __x)
  { return __builtin_floorf(__x); }
   ddf5c:	ecb5 0a01 	vldmia	r5!, {s0}
   ddf60:	f008 fc1e 	bl	e67a0 <floorf>
   ddf64:	3601      	adds	r6, #1
    int offset = i;
    output_data[offset] = std::floor(input_data[offset]);
   ddf66:	eca4 0a01 	vstmia	r4!, {s0}
   ddf6a:	e7f5      	b.n	ddf58 <_ZN6tflite3ops5micro5floor4EvalEP13TfLiteContextP10TfLiteNode+0xa0>
   ddf6c:	a809      	add	r0, sp, #36	; 0x24
   ddf6e:	f7f9 fafc 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  reference_ops::Floor(GetTensorShape(input), GetTensorData<float>(input),
   ddf72:	a804      	add	r0, sp, #16
   ddf74:	f7f9 faf9 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                       GetTensorShape(output), GetTensorData<float>(output));
  return kTfLiteOk;
   ddf78:	2000      	movs	r0, #0
}
   ddf7a:	b00e      	add	sp, #56	; 0x38
   ddf7c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   ddf80:	000ebc41 	.word	0x000ebc41
   ddf84:	000eb3f4 	.word	0x000eb3f4
   ddf88:	000eb8aa 	.word	0x000eb8aa
   ddf8c:	000eb3b9 	.word	0x000eb3b9

000ddf90 <_ZN6tflite3ops5micro14Register_FLOOREv>:
TfLiteRegistration* Register_FLOOR() {
  static TfLiteRegistration r = {/*init=*/nullptr,
                                 /*free=*/nullptr, /*prepare=*/nullptr,
                                 floor::Eval};
  return &r;
}
   ddf90:	4800      	ldr	r0, [pc, #0]	; (ddf94 <_ZN6tflite3ops5micro14Register_FLOOREv+0x4>)
   ddf92:	4770      	bx	lr
   ddf94:	2003bf90 	.word	0x2003bf90

000ddf98 <_ZN6tflite3ops5micro15fully_connected4InitEP13TfLiteContextPKcj>:

}  // namespace

void* Init(TfLiteContext* context, const char* buffer, size_t length) {
  return nullptr;
}
   ddf98:	2000      	movs	r0, #0
   ddf9a:	4770      	bx	lr

000ddf9c <_ZN6tflite3ops5micro15fully_connected4FreeEP13TfLiteContextPv>:

void Free(TfLiteContext* context, void* buffer) {}
   ddf9c:	4770      	bx	lr

000ddf9e <_ZN6tflite3ops5micro15fully_connected7PrepareEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   ddf9e:	2000      	movs	r0, #0
   ddfa0:	4770      	bx	lr

000ddfa2 <_ZN6tflite15FlatSizeSkipDimERKNS_12RuntimeShapeEi>:
}

// Data is required to be contiguous, and so many operators can use either the
// full array flat size or the flat size with one dimension skipped (commonly
// the depth).
inline int FlatSizeSkipDim(const RuntimeShape& shape, int skip_dim) {
   ddfa2:	b538      	push	{r3, r4, r5, lr}
  const int dims_count = shape.DimensionsCount();
  TFLITE_DCHECK(skip_dim >= 0 && skip_dim < dims_count);
   ddfa4:	2900      	cmp	r1, #0
   ddfa6:	6804      	ldr	r4, [r0, #0]
   ddfa8:	db01      	blt.n	ddfae <_ZN6tflite15FlatSizeSkipDimERKNS_12RuntimeShapeEi+0xc>
   ddfaa:	42a1      	cmp	r1, r4
   ddfac:	db01      	blt.n	ddfb2 <_ZN6tflite15FlatSizeSkipDimERKNS_12RuntimeShapeEi+0x10>
   ddfae:	f007 faa1 	bl	e54f4 <abort>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   ddfb2:	2c04      	cmp	r4, #4
   ddfb4:	bfcc      	ite	gt
   ddfb6:	6843      	ldrgt	r3, [r0, #4]
   ddfb8:	1d03      	addle	r3, r0, #4
inline int FlatSizeSkipDim(const RuntimeShape& shape, int skip_dim) {
  const int dims_count = shape.DimensionsCount();
  TFLITE_DCHECK(skip_dim >= 0 && skip_dim < dims_count);
  const auto* dims_data = shape.DimsData();
  int flat_size = 1;
  for (int i = 0; i < dims_count; ++i) {
   ddfba:	2200      	movs	r2, #0
// the depth).
inline int FlatSizeSkipDim(const RuntimeShape& shape, int skip_dim) {
  const int dims_count = shape.DimensionsCount();
  TFLITE_DCHECK(skip_dim >= 0 && skip_dim < dims_count);
  const auto* dims_data = shape.DimsData();
  int flat_size = 1;
   ddfbc:	2001      	movs	r0, #1
  for (int i = 0; i < dims_count; ++i) {
   ddfbe:	42a2      	cmp	r2, r4
   ddfc0:	da07      	bge.n	ddfd2 <_ZN6tflite15FlatSizeSkipDimERKNS_12RuntimeShapeEi+0x30>
    flat_size *= (i == skip_dim) ? 1 : dims_data[i];
   ddfc2:	428a      	cmp	r2, r1
   ddfc4:	bf14      	ite	ne
   ddfc6:	f853 5022 	ldrne.w	r5, [r3, r2, lsl #2]
   ddfca:	2501      	moveq	r5, #1
   ddfcc:	4368      	muls	r0, r5
inline int FlatSizeSkipDim(const RuntimeShape& shape, int skip_dim) {
  const int dims_count = shape.DimensionsCount();
  TFLITE_DCHECK(skip_dim >= 0 && skip_dim < dims_count);
  const auto* dims_data = shape.DimsData();
  int flat_size = 1;
  for (int i = 0; i < dims_count; ++i) {
   ddfce:	3201      	adds	r2, #1
   ddfd0:	e7f5      	b.n	ddfbe <_ZN6tflite15FlatSizeSkipDimERKNS_12RuntimeShapeEi+0x1c>
    flat_size *= (i == skip_dim) ? 1 : dims_data[i];
  }
  return flat_size;
}
   ddfd2:	bd38      	pop	{r3, r4, r5, pc}

000ddfd4 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph>:
inline void FullyConnected(
    const FullyConnectedParams& params, const RuntimeShape& input_shape,
    const uint8* input_data, const RuntimeShape& filter_shape,
    const uint8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    uint8* output_data) {
   ddfd4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   ddfd8:	b08b      	sub	sp, #44	; 0x2c
   ddfda:	461d      	mov	r5, r3
  const int32 input_offset = params.input_offset;
   ddfdc:	6803      	ldr	r3, [r0, #0]
   ddfde:	9302      	str	r3, [sp, #8]
  const int32 filter_offset = params.weights_offset;
   ddfe0:	6843      	ldr	r3, [r0, #4]
   ddfe2:	9303      	str	r3, [sp, #12]
  const int32 output_offset = params.output_offset;
   ddfe4:	6883      	ldr	r3, [r0, #8]
   ddfe6:	9304      	str	r3, [sp, #16]
   ddfe8:	682e      	ldr	r6, [r5, #0]
  const int32 output_multiplier = params.output_multiplier;
   ddfea:	68c3      	ldr	r3, [r0, #12]
   ddfec:	9305      	str	r3, [sp, #20]
  const int output_shift = params.output_shift;
   ddfee:	6903      	ldr	r3, [r0, #16]
   ddff0:	9306      	str	r3, [sp, #24]
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;
  TFLITE_DCHECK_GE(filter_shape.DimensionsCount(), 2);
   ddff2:	2e01      	cmp	r6, #1
  const int32 input_offset = params.input_offset;
  const int32 filter_offset = params.weights_offset;
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
   ddff4:	6943      	ldr	r3, [r0, #20]
inline void FullyConnected(
    const FullyConnectedParams& params, const RuntimeShape& input_shape,
    const uint8* input_data, const RuntimeShape& filter_shape,
    const uint8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    uint8* output_data) {
   ddff6:	9f17      	ldr	r7, [sp, #92]	; 0x5c
  const int32 input_offset = params.input_offset;
  const int32 filter_offset = params.weights_offset;
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
   ddff8:	9301      	str	r3, [sp, #4]
inline void FullyConnected(
    const FullyConnectedParams& params, const RuntimeShape& input_shape,
    const uint8* input_data, const RuntimeShape& filter_shape,
    const uint8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    uint8* output_data) {
   ddffa:	4614      	mov	r4, r2
  const int32 filter_offset = params.weights_offset;
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;
   ddffc:	f8d0 b018 	ldr.w	fp, [r0, #24]
  TFLITE_DCHECK_GE(filter_shape.DimensionsCount(), 2);
   de000:	dc01      	bgt.n	de006 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph+0x32>
   de002:	f007 fa77 	bl	e54f4 <abort>
   de006:	683b      	ldr	r3, [r7, #0]
  TFLITE_DCHECK_GE(output_shape.DimensionsCount(), 1);
   de008:	2b00      	cmp	r3, #0
   de00a:	ddfa      	ble.n	de002 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph+0x2e>

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
   de00c:	9a01      	ldr	r2, [sp, #4]
   de00e:	455a      	cmp	r2, fp
   de010:	dcf7      	bgt.n	de002 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph+0x2e>
  // but the current --variable_batch hack consists in overwriting the 3rd
  // dimension with the runtime batch size, as we don't keep track for each
  // array of which dimension is the batch dimension in it.
  const int output_dim_count = output_shape.DimensionsCount();
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dim_count - 1);
   de012:	f103 38ff 	add.w	r8, r3, #4294967295	; 0xffffffff
   de016:	4641      	mov	r1, r8
   de018:	4638      	mov	r0, r7
   de01a:	f7ff ffc2 	bl	ddfa2 <_ZN6tflite15FlatSizeSkipDimERKNS_12RuntimeShapeEi>
  const int output_depth = MatchingDim(filter_shape, filter_dim_count - 2,
                                       output_shape, output_dim_count - 1);
   de01e:	4643      	mov	r3, r8
   de020:	463a      	mov	r2, r7
   de022:	1eb1      	subs	r1, r6, #2
  // but the current --variable_batch hack consists in overwriting the 3rd
  // dimension with the runtime batch size, as we don't keep track for each
  // array of which dimension is the batch dimension in it.
  const int output_dim_count = output_shape.DimensionsCount();
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dim_count - 1);
   de024:	9007      	str	r0, [sp, #28]
  const int output_depth = MatchingDim(filter_shape, filter_dim_count - 2,
                                       output_shape, output_dim_count - 1);
   de026:	4628      	mov	r0, r5
   de028:	f7fe fe5b 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
   de02c:	1e71      	subs	r1, r6, #1
  // array of which dimension is the batch dimension in it.
  const int output_dim_count = output_shape.DimensionsCount();
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dim_count - 1);
  const int output_depth = MatchingDim(filter_shape, filter_dim_count - 2,
                                       output_shape, output_dim_count - 1);
   de02e:	4682      	mov	sl, r0
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
   de030:	4628      	mov	r0, r5
   de032:	f7f9 faa5 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de036:	f8dd 8060 	ldr.w	r8, [sp, #96]	; 0x60
   de03a:	4606      	mov	r6, r0
   de03c:	4267      	negs	r7, r4
  for (int b = 0; b < batches; ++b) {
   de03e:	f04f 0900 	mov.w	r9, #0
   de042:	9b07      	ldr	r3, [sp, #28]
   de044:	4599      	cmp	r9, r3
   de046:	da39      	bge.n	de0bc <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph+0xe8>
   de048:	9b14      	ldr	r3, [sp, #80]	; 0x50
   de04a:	2500      	movs	r5, #0
    for (int out_c = 0; out_c < output_depth; ++out_c) {
   de04c:	4555      	cmp	r5, sl
   de04e:	da2f      	bge.n	de0b0 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph+0xdc>
   de050:	469c      	mov	ip, r3
   de052:	46a6      	mov	lr, r4
      int32 acc = 0;
   de054:	2000      	movs	r0, #0
      for (int d = 0; d < accum_depth; ++d) {
   de056:	eb0e 0207 	add.w	r2, lr, r7
   de05a:	4296      	cmp	r6, r2
   de05c:	dd0f      	ble.n	de07e <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph+0xaa>
        int32 input_val = input_data[b * accum_depth + d];
   de05e:	f81e 2b01 	ldrb.w	r2, [lr], #1
   de062:	9208      	str	r2, [sp, #32]
        int32 filter_val = filter_data[out_c * accum_depth + d];
        acc += (filter_val + filter_offset) * (input_val + input_offset);
   de064:	9903      	ldr	r1, [sp, #12]
  for (int b = 0; b < batches; ++b) {
    for (int out_c = 0; out_c < output_depth; ++out_c) {
      int32 acc = 0;
      for (int d = 0; d < accum_depth; ++d) {
        int32 input_val = input_data[b * accum_depth + d];
        int32 filter_val = filter_data[out_c * accum_depth + d];
   de066:	f81c 2b01 	ldrb.w	r2, [ip], #1
        acc += (filter_val + filter_offset) * (input_val + input_offset);
   de06a:	440a      	add	r2, r1
   de06c:	9209      	str	r2, [sp, #36]	; 0x24
   de06e:	9902      	ldr	r1, [sp, #8]
   de070:	9a08      	ldr	r2, [sp, #32]
   de072:	440a      	add	r2, r1
   de074:	4611      	mov	r1, r2
   de076:	9a09      	ldr	r2, [sp, #36]	; 0x24
   de078:	fb01 0002 	mla	r0, r1, r2, r0
                                       output_shape, output_dim_count - 1);
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
  for (int b = 0; b < batches; ++b) {
    for (int out_c = 0; out_c < output_depth; ++out_c) {
      int32 acc = 0;
      for (int d = 0; d < accum_depth; ++d) {
   de07c:	e7eb      	b.n	de056 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph+0x82>
        int32 input_val = input_data[b * accum_depth + d];
        int32 filter_val = filter_data[out_c * accum_depth + d];
        acc += (filter_val + filter_offset) * (input_val + input_offset);
      }
      if (bias_data) {
   de07e:	9a16      	ldr	r2, [sp, #88]	; 0x58
   de080:	b112      	cbz	r2, de088 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph+0xb4>
        acc += bias_data[out_c];
   de082:	f852 2025 	ldr.w	r2, [r2, r5, lsl #2]
   de086:	4410      	add	r0, r2
      }
      acc = MultiplyByQuantizedMultiplier(acc, output_multiplier, output_shift);
   de088:	9a06      	ldr	r2, [sp, #24]
   de08a:	9905      	ldr	r1, [sp, #20]
   de08c:	9308      	str	r3, [sp, #32]
   de08e:	f7fe fe37 	bl	dcd00 <_ZN6tflite29MultiplyByQuantizedMultiplierElli>
      acc += output_offset;
   de092:	9b04      	ldr	r3, [sp, #16]
   de094:	4418      	add	r0, r3
   de096:	9b01      	ldr	r3, [sp, #4]
   de098:	4298      	cmp	r0, r3
   de09a:	bfb8      	it	lt
   de09c:	4618      	movlt	r0, r3
      acc = std::max(acc, output_activation_min);
      acc = std::min(acc, output_activation_max);
      output_data[out_c + output_depth * b] = static_cast<uint8>(acc);
   de09e:	4558      	cmp	r0, fp
   de0a0:	9b08      	ldr	r3, [sp, #32]
   de0a2:	bfa8      	it	ge
   de0a4:	4658      	movge	r0, fp
   de0a6:	f808 0005 	strb.w	r0, [r8, r5]
   de0aa:	4433      	add	r3, r6
  const int batches = FlatSizeSkipDim(output_shape, output_dim_count - 1);
  const int output_depth = MatchingDim(filter_shape, filter_dim_count - 2,
                                       output_shape, output_dim_count - 1);
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
  for (int b = 0; b < batches; ++b) {
    for (int out_c = 0; out_c < output_depth; ++out_c) {
   de0ac:	3501      	adds	r5, #1
   de0ae:	e7cd      	b.n	de04c <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph+0x78>
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dim_count - 1);
  const int output_depth = MatchingDim(filter_shape, filter_dim_count - 2,
                                       output_shape, output_dim_count - 1);
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
  for (int b = 0; b < batches; ++b) {
   de0b0:	f109 0901 	add.w	r9, r9, #1
   de0b4:	44d0      	add	r8, sl
   de0b6:	4434      	add	r4, r6
   de0b8:	1bbf      	subs	r7, r7, r6
   de0ba:	e7c2      	b.n	de042 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph+0x6e>
      acc = std::max(acc, output_activation_min);
      acc = std::min(acc, output_activation_max);
      output_data[out_c + output_depth * b] = static_cast<uint8>(acc);
    }
  }
}
   de0bc:	b00b      	add	sp, #44	; 0x2c
   de0be:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000de0c2 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ps>:
inline void FullyConnected(
    const FullyConnectedParams& params, const RuntimeShape& input_shape,
    const uint8* input_data, const RuntimeShape& filter_shape,
    const uint8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int16* output_data) {
   de0c2:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   de0c6:	b089      	sub	sp, #36	; 0x24
   de0c8:	461e      	mov	r6, r3
  const int32 input_offset = params.input_offset;
   de0ca:	6803      	ldr	r3, [r0, #0]
   de0cc:	9301      	str	r3, [sp, #4]
  const int32 filter_offset = params.weights_offset;
   de0ce:	6843      	ldr	r3, [r0, #4]
   de0d0:	9302      	str	r3, [sp, #8]
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
   de0d2:	68c3      	ldr	r3, [r0, #12]
   de0d4:	9303      	str	r3, [sp, #12]
  const int output_shift = params.output_shift;
   de0d6:	6903      	ldr	r3, [r0, #16]
   de0d8:	9304      	str	r3, [sp, #16]
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;
   de0da:	f8d0 a018 	ldr.w	sl, [r0, #24]
  const int32 input_offset = params.input_offset;
  const int32 filter_offset = params.weights_offset;
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
   de0de:	6943      	ldr	r3, [r0, #20]
inline void FullyConnected(
    const FullyConnectedParams& params, const RuntimeShape& input_shape,
    const uint8* input_data, const RuntimeShape& filter_shape,
    const uint8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int16* output_data) {
   de0e0:	f8dd 8054 	ldr.w	r8, [sp, #84]	; 0x54
  const int32 input_offset = params.input_offset;
  const int32 filter_offset = params.weights_offset;
  const int32 output_offset = params.output_offset;
   de0e4:	6885      	ldr	r5, [r0, #8]
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
   de0e6:	9300      	str	r3, [sp, #0]
  const int32 output_activation_max = params.quantized_activation_max;

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
   de0e8:	4553      	cmp	r3, sl
inline void FullyConnected(
    const FullyConnectedParams& params, const RuntimeShape& input_shape,
    const uint8* input_data, const RuntimeShape& filter_shape,
    const uint8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int16* output_data) {
   de0ea:	4614      	mov	r4, r2
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
   de0ec:	dd01      	ble.n	de0f2 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ps+0x30>
   de0ee:	f007 fa01 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(output_offset, 0);
   de0f2:	2d00      	cmp	r5, #0
   de0f4:	d1fb      	bne.n	de0ee <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ps+0x2c>
  // but the current --variable_batch hack consists in overwriting the 3rd
  // dimension with the runtime batch size, as we don't keep track for each
  // array of which dimension is the batch dimension in it.
  const int output_dim_count = output_shape.DimensionsCount();
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dim_count - 1);
   de0f6:	f8d8 3000 	ldr.w	r3, [r8]
   de0fa:	6837      	ldr	r7, [r6, #0]
   de0fc:	f103 39ff 	add.w	r9, r3, #4294967295	; 0xffffffff
   de100:	4649      	mov	r1, r9
   de102:	4640      	mov	r0, r8
   de104:	f7ff ff4d 	bl	ddfa2 <_ZN6tflite15FlatSizeSkipDimERKNS_12RuntimeShapeEi>
  const int output_depth = MatchingDim(filter_shape, filter_dim_count - 2,
                                       output_shape, output_dim_count - 1);
   de108:	464b      	mov	r3, r9
   de10a:	4642      	mov	r2, r8
   de10c:	1eb9      	subs	r1, r7, #2
  // but the current --variable_batch hack consists in overwriting the 3rd
  // dimension with the runtime batch size, as we don't keep track for each
  // array of which dimension is the batch dimension in it.
  const int output_dim_count = output_shape.DimensionsCount();
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dim_count - 1);
   de10e:	9005      	str	r0, [sp, #20]
  const int output_depth = MatchingDim(filter_shape, filter_dim_count - 2,
                                       output_shape, output_dim_count - 1);
   de110:	4630      	mov	r0, r6
   de112:	f7fe fde6 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
   de116:	1e79      	subs	r1, r7, #1
  // array of which dimension is the batch dimension in it.
  const int output_dim_count = output_shape.DimensionsCount();
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dim_count - 1);
  const int output_depth = MatchingDim(filter_shape, filter_dim_count - 2,
                                       output_shape, output_dim_count - 1);
   de118:	4683      	mov	fp, r0
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
   de11a:	4630      	mov	r0, r6
   de11c:	f7f9 fa30 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de120:	ea4f 034b 	mov.w	r3, fp, lsl #1
   de124:	f8dd 9058 	ldr.w	r9, [sp, #88]	; 0x58
   de128:	9306      	str	r3, [sp, #24]
   de12a:	4607      	mov	r7, r0
   de12c:	f1c4 0800 	rsb	r8, r4, #0
  for (int b = 0; b < batches; ++b) {
   de130:	9b05      	ldr	r3, [sp, #20]
   de132:	429d      	cmp	r5, r3
   de134:	da33      	bge.n	de19e <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ps+0xdc>
   de136:	9b12      	ldr	r3, [sp, #72]	; 0x48
   de138:	2600      	movs	r6, #0
    for (int out_c = 0; out_c < output_depth; ++out_c) {
   de13a:	455e      	cmp	r6, fp
   de13c:	da28      	bge.n	de190 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ps+0xce>
      // Internal accumulation.
      // Initialize accumulator with the bias-value.
      int32 accum = bias_data[out_c];
   de13e:	9a14      	ldr	r2, [sp, #80]	; 0x50
   de140:	f852 0026 	ldr.w	r0, [r2, r6, lsl #2]
   de144:	469c      	mov	ip, r3
   de146:	46a6      	mov	lr, r4
      // Accumulation loop.
      for (int d = 0; d < accum_depth; ++d) {
   de148:	eb08 020e 	add.w	r2, r8, lr
   de14c:	4297      	cmp	r7, r2
   de14e:	dd0d      	ble.n	de16c <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ps+0xaa>
        int16 input_val = input_data[b * accum_depth + d] + input_offset;
   de150:	9901      	ldr	r1, [sp, #4]
   de152:	f81e 2b01 	ldrb.w	r2, [lr], #1
   de156:	440a      	add	r2, r1
   de158:	9207      	str	r2, [sp, #28]
        int16 filter_val = filter_data[out_c * accum_depth + d] + filter_offset;
   de15a:	f81c 1b01 	ldrb.w	r1, [ip], #1
   de15e:	9a02      	ldr	r2, [sp, #8]
   de160:	4411      	add	r1, r2
        accum += filter_val * input_val;
   de162:	f8bd 201c 	ldrh.w	r2, [sp, #28]
   de166:	fb11 0002 	smlabb	r0, r1, r2, r0
    for (int out_c = 0; out_c < output_depth; ++out_c) {
      // Internal accumulation.
      // Initialize accumulator with the bias-value.
      int32 accum = bias_data[out_c];
      // Accumulation loop.
      for (int d = 0; d < accum_depth; ++d) {
   de16a:	e7ed      	b.n	de148 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ps+0x86>
      // Down-scale the final int32 accumulator to the scale used by our
      // (16-bit, typically 3 integer bits) fixed-point format. The quantized
      // multiplier and shift here have been pre-computed offline
      // (e.g. by toco).
      accum =
          MultiplyByQuantizedMultiplier(accum, output_multiplier, output_shift);
   de16c:	9a04      	ldr	r2, [sp, #16]
   de16e:	9903      	ldr	r1, [sp, #12]
   de170:	9307      	str	r3, [sp, #28]
   de172:	f7fe fdc5 	bl	dcd00 <_ZN6tflite29MultiplyByQuantizedMultiplierElli>
   de176:	9b00      	ldr	r3, [sp, #0]
   de178:	4298      	cmp	r0, r3
   de17a:	bfb8      	it	lt
   de17c:	4618      	movlt	r0, r3
      // Saturate, cast to int16, and store to output array.
      accum = std::max(accum, output_activation_min - output_offset);
      accum = std::min(accum, output_activation_max - output_offset);
      accum += output_offset;
      output_data[out_c + output_depth * b] = accum;
   de17e:	4550      	cmp	r0, sl
   de180:	9b07      	ldr	r3, [sp, #28]
   de182:	bfa8      	it	ge
   de184:	4650      	movge	r0, sl
   de186:	f829 0016 	strh.w	r0, [r9, r6, lsl #1]
   de18a:	443b      	add	r3, r7
  const int batches = FlatSizeSkipDim(output_shape, output_dim_count - 1);
  const int output_depth = MatchingDim(filter_shape, filter_dim_count - 2,
                                       output_shape, output_dim_count - 1);
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
  for (int b = 0; b < batches; ++b) {
    for (int out_c = 0; out_c < output_depth; ++out_c) {
   de18c:	3601      	adds	r6, #1
   de18e:	e7d4      	b.n	de13a <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ps+0x78>
   de190:	9b06      	ldr	r3, [sp, #24]
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dim_count - 1);
  const int output_depth = MatchingDim(filter_shape, filter_dim_count - 2,
                                       output_shape, output_dim_count - 1);
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
  for (int b = 0; b < batches; ++b) {
   de192:	3501      	adds	r5, #1
   de194:	4499      	add	r9, r3
   de196:	443c      	add	r4, r7
   de198:	ebc7 0808 	rsb	r8, r7, r8
   de19c:	e7c8      	b.n	de130 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ps+0x6e>
      accum = std::min(accum, output_activation_max - output_offset);
      accum += output_offset;
      output_data[out_c + output_depth * b] = accum;
    }
  }
}
   de19e:	b009      	add	sp, #36	; 0x24
   de1a0:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000de1a4 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa>:
inline void FullyConnected(
    const FullyConnectedParams& params, const RuntimeShape& input_shape,
    const int8_t* input_data, const RuntimeShape& filter_shape,
    const int8_t* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int8_t* output_data) {
   de1a4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   de1a8:	b08b      	sub	sp, #44	; 0x2c
   de1aa:	461d      	mov	r5, r3
  const int32 input_offset = params.input_offset;
   de1ac:	6803      	ldr	r3, [r0, #0]
   de1ae:	9302      	str	r3, [sp, #8]
  const int32 filter_offset = params.weights_offset;
   de1b0:	6843      	ldr	r3, [r0, #4]
   de1b2:	9303      	str	r3, [sp, #12]
  const int32 output_offset = params.output_offset;
   de1b4:	6883      	ldr	r3, [r0, #8]
   de1b6:	9304      	str	r3, [sp, #16]
   de1b8:	682e      	ldr	r6, [r5, #0]
  const int32 output_multiplier = params.output_multiplier;
   de1ba:	68c3      	ldr	r3, [r0, #12]
   de1bc:	9305      	str	r3, [sp, #20]
  const int output_shift = params.output_shift;
   de1be:	6903      	ldr	r3, [r0, #16]
   de1c0:	9306      	str	r3, [sp, #24]
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;
  TFLITE_DCHECK_GE(filter_shape.DimensionsCount(), 2);
   de1c2:	2e01      	cmp	r6, #1
  const int32 input_offset = params.input_offset;
  const int32 filter_offset = params.weights_offset;
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
   de1c4:	6943      	ldr	r3, [r0, #20]
inline void FullyConnected(
    const FullyConnectedParams& params, const RuntimeShape& input_shape,
    const int8_t* input_data, const RuntimeShape& filter_shape,
    const int8_t* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int8_t* output_data) {
   de1c6:	9f17      	ldr	r7, [sp, #92]	; 0x5c
  const int32 input_offset = params.input_offset;
  const int32 filter_offset = params.weights_offset;
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
   de1c8:	9301      	str	r3, [sp, #4]
inline void FullyConnected(
    const FullyConnectedParams& params, const RuntimeShape& input_shape,
    const int8_t* input_data, const RuntimeShape& filter_shape,
    const int8_t* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int8_t* output_data) {
   de1ca:	4614      	mov	r4, r2
  const int32 filter_offset = params.weights_offset;
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;
   de1cc:	f8d0 b018 	ldr.w	fp, [r0, #24]
  TFLITE_DCHECK_GE(filter_shape.DimensionsCount(), 2);
   de1d0:	dc01      	bgt.n	de1d6 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0x32>
   de1d2:	f007 f98f 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 2);
   de1d6:	683b      	ldr	r3, [r7, #0]
   de1d8:	2b02      	cmp	r3, #2
   de1da:	d1fa      	bne.n	de1d2 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0x2e>

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
   de1dc:	9b01      	ldr	r3, [sp, #4]
   de1de:	455b      	cmp	r3, fp
   de1e0:	dcf7      	bgt.n	de1d2 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0x2e>
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = output_shape.Dims(0);
   de1e2:	2100      	movs	r1, #0
   de1e4:	4638      	mov	r0, r7
   de1e6:	f7f9 f9cb 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_depth = output_shape.Dims(1);
   de1ea:	2101      	movs	r1, #1
  TFLITE_DCHECK_GE(filter_shape.DimensionsCount(), 2);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 2);

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = output_shape.Dims(0);
   de1ec:	9007      	str	r0, [sp, #28]
  const int output_depth = output_shape.Dims(1);
   de1ee:	4638      	mov	r0, r7
   de1f0:	f7f9 f9c6 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  TFLITE_DCHECK_LE(output_depth, filter_shape.Dims(filter_dim_count - 2));
   de1f4:	1eb1      	subs	r1, r6, #2
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 2);

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = output_shape.Dims(0);
  const int output_depth = output_shape.Dims(1);
   de1f6:	4681      	mov	r9, r0
  TFLITE_DCHECK_LE(output_depth, filter_shape.Dims(filter_dim_count - 2));
   de1f8:	4628      	mov	r0, r5
   de1fa:	f7f9 f9c1 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de1fe:	4581      	cmp	r9, r0
   de200:	dce7      	bgt.n	de1d2 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0x2e>
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
   de202:	1e71      	subs	r1, r6, #1
   de204:	4628      	mov	r0, r5
   de206:	f7f9 f9bb 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de20a:	f8dd 8060 	ldr.w	r8, [sp, #96]	; 0x60
   de20e:	4606      	mov	r6, r0
   de210:	4267      	negs	r7, r4
  for (int b = 0; b < batches; ++b) {
   de212:	f04f 0a00 	mov.w	sl, #0
   de216:	9b07      	ldr	r3, [sp, #28]
   de218:	459a      	cmp	sl, r3
   de21a:	da39      	bge.n	de290 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0xec>
   de21c:	9b14      	ldr	r3, [sp, #80]	; 0x50
   de21e:	2500      	movs	r5, #0
    for (int out_c = 0; out_c < output_depth; ++out_c) {
   de220:	454d      	cmp	r5, r9
   de222:	da2f      	bge.n	de284 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0xe0>
   de224:	469c      	mov	ip, r3
   de226:	46a6      	mov	lr, r4
      int32 acc = 0;
   de228:	2000      	movs	r0, #0
      for (int d = 0; d < accum_depth; ++d) {
   de22a:	eb07 020e 	add.w	r2, r7, lr
   de22e:	4296      	cmp	r6, r2
   de230:	dd0f      	ble.n	de252 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0xae>
        int32 input_val = input_data[b * accum_depth + d];
   de232:	f91e 2b01 	ldrsb.w	r2, [lr], #1
   de236:	9208      	str	r2, [sp, #32]
        int32 filter_val = filter_data[out_c * accum_depth + d];
        acc += (filter_val + filter_offset) * (input_val + input_offset);
   de238:	9903      	ldr	r1, [sp, #12]
  for (int b = 0; b < batches; ++b) {
    for (int out_c = 0; out_c < output_depth; ++out_c) {
      int32 acc = 0;
      for (int d = 0; d < accum_depth; ++d) {
        int32 input_val = input_data[b * accum_depth + d];
        int32 filter_val = filter_data[out_c * accum_depth + d];
   de23a:	f91c 2b01 	ldrsb.w	r2, [ip], #1
        acc += (filter_val + filter_offset) * (input_val + input_offset);
   de23e:	440a      	add	r2, r1
   de240:	9209      	str	r2, [sp, #36]	; 0x24
   de242:	9902      	ldr	r1, [sp, #8]
   de244:	9a08      	ldr	r2, [sp, #32]
   de246:	440a      	add	r2, r1
   de248:	4611      	mov	r1, r2
   de24a:	9a09      	ldr	r2, [sp, #36]	; 0x24
   de24c:	fb01 0002 	mla	r0, r1, r2, r0
  TFLITE_DCHECK_LE(output_depth, filter_shape.Dims(filter_dim_count - 2));
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
  for (int b = 0; b < batches; ++b) {
    for (int out_c = 0; out_c < output_depth; ++out_c) {
      int32 acc = 0;
      for (int d = 0; d < accum_depth; ++d) {
   de250:	e7eb      	b.n	de22a <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0x86>
        int32 input_val = input_data[b * accum_depth + d];
        int32 filter_val = filter_data[out_c * accum_depth + d];
        acc += (filter_val + filter_offset) * (input_val + input_offset);
      }
      if (bias_data) {
   de252:	9a16      	ldr	r2, [sp, #88]	; 0x58
   de254:	b112      	cbz	r2, de25c <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0xb8>
        acc += bias_data[out_c];
   de256:	f852 2025 	ldr.w	r2, [r2, r5, lsl #2]
   de25a:	4410      	add	r0, r2
      }
      acc = MultiplyByQuantizedMultiplier(acc, output_multiplier, output_shift);
   de25c:	9a06      	ldr	r2, [sp, #24]
   de25e:	9905      	ldr	r1, [sp, #20]
   de260:	9308      	str	r3, [sp, #32]
   de262:	f7fe fd4d 	bl	dcd00 <_ZN6tflite29MultiplyByQuantizedMultiplierElli>
      acc += output_offset;
   de266:	9b04      	ldr	r3, [sp, #16]
   de268:	4418      	add	r0, r3
   de26a:	9b01      	ldr	r3, [sp, #4]
   de26c:	4298      	cmp	r0, r3
   de26e:	bfb8      	it	lt
   de270:	4618      	movlt	r0, r3
      acc = std::max(acc, output_activation_min);
      acc = std::min(acc, output_activation_max);
      output_data[out_c + output_depth * b] = static_cast<int8_t>(acc);
   de272:	4558      	cmp	r0, fp
   de274:	9b08      	ldr	r3, [sp, #32]
   de276:	bfa8      	it	ge
   de278:	4658      	movge	r0, fp
   de27a:	f808 0005 	strb.w	r0, [r8, r5]
   de27e:	4433      	add	r3, r6
  const int batches = output_shape.Dims(0);
  const int output_depth = output_shape.Dims(1);
  TFLITE_DCHECK_LE(output_depth, filter_shape.Dims(filter_dim_count - 2));
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
  for (int b = 0; b < batches; ++b) {
    for (int out_c = 0; out_c < output_depth; ++out_c) {
   de280:	3501      	adds	r5, #1
   de282:	e7cd      	b.n	de220 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0x7c>
  const int filter_dim_count = filter_shape.DimensionsCount();
  const int batches = output_shape.Dims(0);
  const int output_depth = output_shape.Dims(1);
  TFLITE_DCHECK_LE(output_depth, filter_shape.Dims(filter_dim_count - 2));
  const int accum_depth = filter_shape.Dims(filter_dim_count - 1);
  for (int b = 0; b < batches; ++b) {
   de284:	f10a 0a01 	add.w	sl, sl, #1
   de288:	44c8      	add	r8, r9
   de28a:	4434      	add	r4, r6
   de28c:	1bbf      	subs	r7, r7, r6
   de28e:	e7c2      	b.n	de216 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa+0x72>
      acc = std::max(acc, output_activation_min);
      acc = std::min(acc, output_activation_max);
      output_data[out_c + output_depth * b] = static_cast<int8_t>(acc);
    }
  }
}
   de290:	b00b      	add	sp, #44	; 0x2c
   de292:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	...

000de298 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode>:
      GetTensorShape(bias), GetTensorData<float>(bias), GetTensorShape(output),
      GetTensorData<float>(output));
  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   de298:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   de29c:	ed2d 8b02 	vpush	{d8}
   de2a0:	680c      	ldr	r4, [r1, #0]
  auto* params =
      reinterpret_cast<TfLiteFullyConnectedParams*>(node->builtin_data);
   de2a2:	694b      	ldr	r3, [r1, #20]
   de2a4:	f8d0 9008 	ldr.w	r9, [r0, #8]
      GetTensorShape(bias), GetTensorData<float>(bias), GetTensorShape(output),
      GetTensorData<float>(output));
  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   de2a8:	b0af      	sub	sp, #188	; 0xbc
   de2aa:	4680      	mov	r8, r0
  auto* params =
      reinterpret_cast<TfLiteFullyConnectedParams*>(node->builtin_data);
   de2ac:	9307      	str	r3, [sp, #28]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   de2ae:	68a0      	ldr	r0, [r4, #8]
   de2b0:	6863      	ldr	r3, [r4, #4]
}

inline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
   de2b2:	68e4      	ldr	r4, [r4, #12]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   de2b4:	2238      	movs	r2, #56	; 0x38
   de2b6:	fb02 fa00 	mul.w	sl, r2, r0

inline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
   de2ba:	1c60      	adds	r0, r4, #1
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   de2bc:	fb02 f303 	mul.w	r3, r2, r3
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
    return &context
                ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   de2c0:	bf18      	it	ne
   de2c2:	fb02 9404 	mlane	r4, r2, r4, r9
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   de2c6:	684a      	ldr	r2, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   de2c8:	eb09 0703 	add.w	r7, r9, r3
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   de2cc:	6852      	ldr	r2, [r2, #4]
                             TfLiteType data_type, const TfLiteTensor* input,
                             const TfLiteTensor* filter,
                             const TfLiteTensor* bias, TfLiteTensor* output,
                             OpData* data) {
  TfLiteStatus status = kTfLiteOk;
  if (data_type != kTfLiteFloat32) {
   de2ce:	f819 3003 	ldrb.w	r3, [r9, r3]
   de2d2:	f04f 0b38 	mov.w	fp, #56	; 0x38
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
    return &context
                ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
  }
  return nullptr;
   de2d6:	bf08      	it	eq
   de2d8:	2400      	moveq	r4, #0
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   de2da:	fb0b fb02 	mul.w	fp, fp, r2
   de2de:	2b01      	cmp	r3, #1
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   de2e0:	eb09 060a 	add.w	r6, r9, sl
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   de2e4:	eb09 050b 	add.w	r5, r9, fp
   de2e8:	d021      	beq.n	de32e <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x96>
    double real_multiplier = 0.0;
   de2ea:	ab2e      	add	r3, sp, #184	; 0xb8
   de2ec:	2000      	movs	r0, #0
   de2ee:	2100      	movs	r1, #0
   de2f0:	e963 010a 	strd	r0, r1, [r3, #-40]!	; 0x28
    TF_LITE_ENSURE_STATUS(GetQuantizedConvolutionMultipler(
   de2f4:	4632      	mov	r2, r6
   de2f6:	9301      	str	r3, [sp, #4]
   de2f8:	9500      	str	r5, [sp, #0]
   de2fa:	4623      	mov	r3, r4
   de2fc:	4639      	mov	r1, r7
   de2fe:	4640      	mov	r0, r8
   de300:	f006 fc36 	bl	e4b70 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd>
   de304:	2800      	cmp	r0, #0
   de306:	d132      	bne.n	de36e <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0xd6>
        context, input, filter, bias, output, &real_multiplier));
    int exponent;
    QuantizeMultiplier(real_multiplier, &data->output_multiplier, &exponent);
   de308:	a91f      	add	r1, sp, #124	; 0x7c
   de30a:	a80b      	add	r0, sp, #44	; 0x2c
   de30c:	ed9d 0b24 	vldr	d0, [sp, #144]	; 0x90
   de310:	f006 fdcc 	bl	e4eac <_ZN6tflite18QuantizeMultiplierEdPlPi>
    data->output_shift = -exponent;
   de314:	9b1f      	ldr	r3, [sp, #124]	; 0x7c
   de316:	425b      	negs	r3, r3
   de318:	930c      	str	r3, [sp, #48]	; 0x30
    TF_LITE_ENSURE_STATUS(CalculateActivationRangeQuantized(
   de31a:	9b07      	ldr	r3, [sp, #28]
   de31c:	7819      	ldrb	r1, [r3, #0]
   de31e:	ab0e      	add	r3, sp, #56	; 0x38
   de320:	9300      	str	r3, [sp, #0]
   de322:	462a      	mov	r2, r5
   de324:	ab0d      	add	r3, sp, #52	; 0x34
   de326:	4640      	mov	r0, r8
   de328:	f006 fc80 	bl	e4c2c <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_>
   de32c:	b9f8      	cbnz	r0, de36e <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0xd6>
  OpData local_data_object;
  OpData* data = &local_data_object;
  TF_LITE_ENSURE_STATUS(CalculateOpData(context, params, data_type, input,
                                        filter, bias, output, data));

  switch (filter->type) {  // Already know in/out types are same.
   de32e:	f819 200a 	ldrb.w	r2, [r9, sl]
   de332:	2a03      	cmp	r2, #3
   de334:	d176      	bne.n	de424 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x18c>
                           TfLiteFullyConnectedParams* params, OpData* data,
                           const TfLiteTensor* input,
                           const TfLiteTensor* filter, const TfLiteTensor* bias,
                           TfLiteTensor* output) {
  const int32_t input_offset = -input->params.zero_point;
  const int32_t filter_offset = -filter->params.zero_point;
   de336:	6933      	ldr	r3, [r6, #16]
  const int32_t output_offset = output->params.zero_point;

  tflite::FullyConnectedParams op_params;
  op_params.input_offset = input_offset;
   de338:	693a      	ldr	r2, [r7, #16]
                           const TfLiteTensor* input,
                           const TfLiteTensor* filter, const TfLiteTensor* bias,
                           TfLiteTensor* output) {
  const int32_t input_offset = -input->params.zero_point;
  const int32_t filter_offset = -filter->params.zero_point;
  const int32_t output_offset = output->params.zero_point;
   de33a:	6929      	ldr	r1, [r5, #16]

  tflite::FullyConnectedParams op_params;
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
   de33c:	9126      	str	r1, [sp, #152]	; 0x98
                           TfLiteFullyConnectedParams* params, OpData* data,
                           const TfLiteTensor* input,
                           const TfLiteTensor* filter, const TfLiteTensor* bias,
                           TfLiteTensor* output) {
  const int32_t input_offset = -input->params.zero_point;
  const int32_t filter_offset = -filter->params.zero_point;
   de33e:	425b      	negs	r3, r3
  const int32_t output_offset = output->params.zero_point;

  tflite::FullyConnectedParams op_params;
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
   de340:	9325      	str	r3, [sp, #148]	; 0x94
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
   de342:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   de344:	9327      	str	r3, [sp, #156]	; 0x9c
  // Legacy ops used mixed left and right shifts. Now all are +ve-means-left.
  op_params.output_shift = -data->output_shift;
   de346:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   de348:	425b      	negs	r3, r3
   de34a:	9328      	str	r3, [sp, #160]	; 0xa0
  op_params.quantized_activation_min = data->output_activation_min;
   de34c:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   de34e:	9329      	str	r3, [sp, #164]	; 0xa4
  const int32_t input_offset = -input->params.zero_point;
  const int32_t filter_offset = -filter->params.zero_point;
  const int32_t output_offset = output->params.zero_point;

  tflite::FullyConnectedParams op_params;
  op_params.input_offset = input_offset;
   de350:	4252      	negs	r2, r2
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  // Legacy ops used mixed left and right shifts. Now all are +ve-means-left.
  op_params.output_shift = -data->output_shift;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
   de352:	9b0e      	ldr	r3, [sp, #56]	; 0x38
  const int32_t input_offset = -input->params.zero_point;
  const int32_t filter_offset = -filter->params.zero_point;
  const int32_t output_offset = output->params.zero_point;

  tflite::FullyConnectedParams op_params;
  op_params.input_offset = input_offset;
   de354:	9224      	str	r2, [sp, #144]	; 0x90
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  // Legacy ops used mixed left and right shifts. Now all are +ve-means-left.
  op_params.output_shift = -data->output_shift;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
   de356:	932a      	str	r3, [sp, #168]	; 0xa8
  reference_ops::FullyConnected(                                       \
      op_params, GetTensorShape(input), GetTensorData<uint8_t>(input), \
      GetTensorShape(filter), GetTensorData<uint8_t>(filter),          \
      GetTensorShape(bias), GetTensorData<int32_t>(bias),              \
      GetTensorShape(output), GetTensorData<output_data_type>(output))
  switch (output->type) {
   de358:	f819 300b 	ldrb.w	r3, [r9, fp]
   de35c:	2b03      	cmp	r3, #3
   de35e:	d008      	beq.n	de372 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0xda>
   de360:	2b07      	cmp	r3, #7
   de362:	d02c      	beq.n	de3be <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x126>
      TF_LITE_FULLY_CONNECTED(int16_t);
      break;
    default:
      context->ReportError(
          context,
          "Quantized FullyConnected expects output data type uint8 or int16");
   de364:	f8d8 3014 	ldr.w	r3, [r8, #20]
   de368:	499d      	ldr	r1, [pc, #628]	; (de5e0 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x348>)
   de36a:	4640      	mov	r0, r8
   de36c:	4798      	blx	r3
                           output);

    default:
      context->ReportError(context, "Type %d not currently supported.",
                           filter->type);
      return kTfLiteError;
   de36e:	2001      	movs	r0, #1
   de370:	e131      	b.n	de5d6 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x33e>
      GetTensorShape(filter), GetTensorData<uint8_t>(filter),          \
      GetTensorShape(bias), GetTensorData<int32_t>(bias),              \
      GetTensorShape(output), GetTensorData<output_data_type>(output))
  switch (output->type) {
    case kTfLiteUInt8:
      TF_LITE_FULLY_CONNECTED(uint8_t);
   de372:	4639      	mov	r1, r7
   de374:	a810      	add	r0, sp, #64	; 0x40
   de376:	f7f9 fba8 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de37a:	4631      	mov	r1, r6
   de37c:	a815      	add	r0, sp, #84	; 0x54
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   de37e:	f8d7 8004 	ldr.w	r8, [r7, #4]
   de382:	f7f9 fba2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de386:	f8d6 9004 	ldr.w	r9, [r6, #4]
   de38a:	ae1a      	add	r6, sp, #104	; 0x68
   de38c:	4621      	mov	r1, r4
   de38e:	4630      	mov	r0, r6
   de390:	f7f9 fb9b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de394:	b104      	cbz	r4, de398 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x100>
   de396:	6864      	ldr	r4, [r4, #4]
   de398:	af1f      	add	r7, sp, #124	; 0x7c
   de39a:	4629      	mov	r1, r5
   de39c:	4638      	mov	r0, r7
   de39e:	f7f9 fb94 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de3a2:	686b      	ldr	r3, [r5, #4]
   de3a4:	9304      	str	r3, [sp, #16]
   de3a6:	9703      	str	r7, [sp, #12]
   de3a8:	9402      	str	r4, [sp, #8]
   de3aa:	9601      	str	r6, [sp, #4]
   de3ac:	f8cd 9000 	str.w	r9, [sp]
   de3b0:	ab15      	add	r3, sp, #84	; 0x54
   de3b2:	4642      	mov	r2, r8
   de3b4:	a910      	add	r1, sp, #64	; 0x40
   de3b6:	a824      	add	r0, sp, #144	; 0x90
   de3b8:	f7ff fe0c 	bl	ddfd4 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ph>
   de3bc:	e024      	b.n	de408 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x170>
      break;
    case kTfLiteInt16:
      TF_LITE_FULLY_CONNECTED(int16_t);
   de3be:	4639      	mov	r1, r7
   de3c0:	a810      	add	r0, sp, #64	; 0x40
   de3c2:	f7f9 fb82 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de3c6:	4631      	mov	r1, r6
   de3c8:	a815      	add	r0, sp, #84	; 0x54
   de3ca:	f8d7 8004 	ldr.w	r8, [r7, #4]
   de3ce:	f7f9 fb7c 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de3d2:	f8d6 9004 	ldr.w	r9, [r6, #4]
   de3d6:	ae1a      	add	r6, sp, #104	; 0x68
   de3d8:	4621      	mov	r1, r4
   de3da:	4630      	mov	r0, r6
   de3dc:	f7f9 fb75 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de3e0:	b104      	cbz	r4, de3e4 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x14c>
   de3e2:	6864      	ldr	r4, [r4, #4]
   de3e4:	af1f      	add	r7, sp, #124	; 0x7c
   de3e6:	4629      	mov	r1, r5
   de3e8:	4638      	mov	r0, r7
   de3ea:	f7f9 fb6e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de3ee:	686b      	ldr	r3, [r5, #4]
   de3f0:	9304      	str	r3, [sp, #16]
   de3f2:	9703      	str	r7, [sp, #12]
   de3f4:	9402      	str	r4, [sp, #8]
   de3f6:	9601      	str	r6, [sp, #4]
   de3f8:	f8cd 9000 	str.w	r9, [sp]
   de3fc:	ab15      	add	r3, sp, #84	; 0x54
   de3fe:	4642      	mov	r2, r8
   de400:	a910      	add	r1, sp, #64	; 0x40
   de402:	a824      	add	r0, sp, #144	; 0x90
   de404:	f7ff fe5d 	bl	de0c2 <_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKlS6_Ps>
   de408:	4638      	mov	r0, r7
   de40a:	f7f9 f8ae 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   de40e:	4630      	mov	r0, r6
   de410:	f7f9 f8ab 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   de414:	a815      	add	r0, sp, #84	; 0x54
   de416:	f7f9 f8a8 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   de41a:	a810      	add	r0, sp, #64	; 0x40
   de41c:	f7f9 f8a5 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          context,
          "Quantized FullyConnected expects output data type uint8 or int16");
      return kTfLiteError;
  }

  return kTfLiteOk;
   de420:	2000      	movs	r0, #0
   de422:	e0d8      	b.n	de5d6 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x33e>
  OpData local_data_object;
  OpData* data = &local_data_object;
  TF_LITE_ENSURE_STATUS(CalculateOpData(context, params, data_type, input,
                                        filter, bias, output, data));

  switch (filter->type) {  // Already know in/out types are same.
   de424:	2a09      	cmp	r2, #9
   de426:	d136      	bne.n	de496 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x1fe>
                               TfLiteFullyConnectedParams* params, OpData* data,
                               const TfLiteTensor* input,
                               const TfLiteTensor* filter,
                               const TfLiteTensor* bias, TfLiteTensor* output) {
  FullyConnectedParams op_params;
  op_params.input_offset = -input->params.zero_point;
   de428:	693b      	ldr	r3, [r7, #16]
   de42a:	425b      	negs	r3, r3
   de42c:	9324      	str	r3, [sp, #144]	; 0x90
  op_params.weights_offset = -filter->params.zero_point;
   de42e:	6933      	ldr	r3, [r6, #16]
   de430:	425b      	negs	r3, r3
   de432:	9325      	str	r3, [sp, #148]	; 0x94
  op_params.output_offset = output->params.zero_point;
   de434:	692b      	ldr	r3, [r5, #16]
   de436:	9326      	str	r3, [sp, #152]	; 0x98
  op_params.output_multiplier = data->output_multiplier;
   de438:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   de43a:	9327      	str	r3, [sp, #156]	; 0x9c
  // TODO(b/138810107): Figure out whether output shift should be inverted
  op_params.output_shift = -data->output_shift;
   de43c:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   de43e:	425b      	negs	r3, r3
   de440:	9328      	str	r3, [sp, #160]	; 0xa0
  op_params.quantized_activation_min = data->output_activation_min;
   de442:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   de444:	9329      	str	r3, [sp, #164]	; 0xa4
  op_params.quantized_activation_max = data->output_activation_max;

  reference_integer_ops::FullyConnected(
      op_params, GetTensorShape(input), GetTensorData<int8_t>(input),
   de446:	4639      	mov	r1, r7
  op_params.output_offset = output->params.zero_point;
  op_params.output_multiplier = data->output_multiplier;
  // TODO(b/138810107): Figure out whether output shift should be inverted
  op_params.output_shift = -data->output_shift;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
   de448:	9b0e      	ldr	r3, [sp, #56]	; 0x38
   de44a:	932a      	str	r3, [sp, #168]	; 0xa8

  reference_integer_ops::FullyConnected(
      op_params, GetTensorShape(input), GetTensorData<int8_t>(input),
   de44c:	a810      	add	r0, sp, #64	; 0x40
   de44e:	f7f9 fb3c 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorShape(filter), GetTensorData<int8_t>(filter),
   de452:	4631      	mov	r1, r6
   de454:	a815      	add	r0, sp, #84	; 0x54
   de456:	f8d7 8004 	ldr.w	r8, [r7, #4]
   de45a:	f7f9 fb36 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de45e:	f8d6 9004 	ldr.w	r9, [r6, #4]
      GetTensorShape(bias), GetTensorData<int32_t>(bias),
   de462:	ae1a      	add	r6, sp, #104	; 0x68
   de464:	4621      	mov	r1, r4
   de466:	4630      	mov	r0, r6
   de468:	f7f9 fb2f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de46c:	b104      	cbz	r4, de470 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x1d8>
   de46e:	6864      	ldr	r4, [r4, #4]
      GetTensorShape(output), GetTensorData<int8_t>(output));
   de470:	af1f      	add	r7, sp, #124	; 0x7c
   de472:	4629      	mov	r1, r5
   de474:	4638      	mov	r0, r7
   de476:	f7f9 fb28 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de47a:	686b      	ldr	r3, [r5, #4]
   de47c:	9304      	str	r3, [sp, #16]
   de47e:	9703      	str	r7, [sp, #12]
   de480:	9402      	str	r4, [sp, #8]
   de482:	9601      	str	r6, [sp, #4]
   de484:	f8cd 9000 	str.w	r9, [sp]
   de488:	ab15      	add	r3, sp, #84	; 0x54
   de48a:	4642      	mov	r2, r8
   de48c:	a910      	add	r1, sp, #64	; 0x40
   de48e:	a824      	add	r0, sp, #144	; 0x90
   de490:	f7ff fe88 	bl	de1a4 <_ZN6tflite21reference_integer_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKaS6_S8_S6_PKlS6_Pa>
   de494:	e7b8      	b.n	de408 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x170>
  OpData local_data_object;
  OpData* data = &local_data_object;
  TF_LITE_ENSURE_STATUS(CalculateOpData(context, params, data_type, input,
                                        filter, bias, output, data));

  switch (filter->type) {  // Already know in/out types are same.
   de496:	2a01      	cmp	r2, #1
   de498:	f040 8097 	bne.w	de5ca <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x332>
   de49c:	9b07      	ldr	r3, [sp, #28]
   de49e:	781b      	ldrb	r3, [r3, #0]
// Calculates the useful range of an activation layer given its activation
// tensor.a
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
   de4a0:	2b01      	cmp	r3, #1
   de4a2:	d011      	beq.n	de4c8 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x230>
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
   de4a4:	2b03      	cmp	r3, #3
   de4a6:	d012      	beq.n	de4ce <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x236>
  } else if (activation == kTfLiteActRelu1) {
    *activation_min = -1;
    *activation_max = 1;
  } else {
    *activation_min = std::numeric_limits<T>::lowest();
    *activation_max = std::numeric_limits<T>::max();
   de4a8:	ed9f 8a4e 	vldr	s16, [pc, #312]	; de5e4 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x34c>
   de4ac:	eddf 8a4e 	vldr	s17, [pc, #312]	; de5e8 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x350>
   de4b0:	2b02      	cmp	r3, #2
   de4b2:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   de4b6:	bf08      	it	eq
   de4b8:	eeb0 8a67 	vmoveq.f32	s16, s15
   de4bc:	eeff 7a00 	vmov.f32	s15, #240	; 0xbf800000 -1.0
   de4c0:	bf08      	it	eq
   de4c2:	eef0 8a67 	vmoveq.f32	s17, s15
   de4c6:	e006      	b.n	de4d6 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x23e>
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
   de4c8:	ed9f 8a46 	vldr	s16, [pc, #280]	; de5e4 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x34c>
   de4cc:	e001      	b.n	de4d2 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x23a>
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
    *activation_max = 6;
   de4ce:	eeb1 8a08 	vmov.f32	s16, #24	; 0x40c00000  6.0
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
   de4d2:	eddf 8a46 	vldr	s17, [pc, #280]	; de5ec <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x354>
                           &output_activation_max);
  tflite::FullyConnectedParams op_params;
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;
  tflite::reference_ops::FullyConnected(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
   de4d6:	4639      	mov	r1, r7
   de4d8:	a815      	add	r0, sp, #84	; 0x54
   de4da:	f7f9 faf6 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorShape(filter), GetTensorData<float>(filter),
   de4de:	4631      	mov	r1, r6
   de4e0:	a81a      	add	r0, sp, #104	; 0x68
   de4e2:	687f      	ldr	r7, [r7, #4]
   de4e4:	f7f9 faf1 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de4e8:	6873      	ldr	r3, [r6, #4]
   de4ea:	9308      	str	r3, [sp, #32]
      GetTensorShape(bias), GetTensorData<float>(bias), GetTensorShape(output),
   de4ec:	4621      	mov	r1, r4
   de4ee:	a81f      	add	r0, sp, #124	; 0x7c
   de4f0:	f7f9 faeb 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de4f4:	b104      	cbz	r4, de4f8 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x260>
   de4f6:	6864      	ldr	r4, [r4, #4]
   de4f8:	4629      	mov	r1, r5
   de4fa:	a824      	add	r0, sp, #144	; 0x90
   de4fc:	f7f9 fae5 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   de500:	b105      	cbz	r5, de504 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x26c>
   de502:	686d      	ldr	r5, [r5, #4]
  // but the current --variable_batch hack consists in overwriting the 3rd
  // dimension with the runtime batch size, as we don't keep track for each
  // array of which dimension is the batch dimension in it.
  const int output_dims_count = output_shape.DimensionsCount();
  const int weights_dims_count = weights_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dims_count - 1);
   de504:	9e24      	ldr	r6, [sp, #144]	; 0x90
   de506:	f8dd 9068 	ldr.w	r9, [sp, #104]	; 0x68
   de50a:	3e01      	subs	r6, #1
   de50c:	4631      	mov	r1, r6
   de50e:	a824      	add	r0, sp, #144	; 0x90
   de510:	f7ff fd47 	bl	ddfa2 <_ZN6tflite15FlatSizeSkipDimERKNS_12RuntimeShapeEi>
  const int output_depth = MatchingDim(weights_shape, weights_dims_count - 2,
                                       output_shape, output_dims_count - 1);
   de514:	4633      	mov	r3, r6
   de516:	aa24      	add	r2, sp, #144	; 0x90
  // but the current --variable_batch hack consists in overwriting the 3rd
  // dimension with the runtime batch size, as we don't keep track for each
  // array of which dimension is the batch dimension in it.
  const int output_dims_count = output_shape.DimensionsCount();
  const int weights_dims_count = weights_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dims_count - 1);
   de518:	9009      	str	r0, [sp, #36]	; 0x24
  const int output_depth = MatchingDim(weights_shape, weights_dims_count - 2,
                                       output_shape, output_dims_count - 1);
   de51a:	f1a9 0102 	sub.w	r1, r9, #2
   de51e:	a81a      	add	r0, sp, #104	; 0x68
   de520:	f7fe fbdf 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int accum_depth = weights_shape.Dims(weights_dims_count - 1);
   de524:	f109 31ff 	add.w	r1, r9, #4294967295	; 0xffffffff
  // array of which dimension is the batch dimension in it.
  const int output_dims_count = output_shape.DimensionsCount();
  const int weights_dims_count = weights_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dims_count - 1);
  const int output_depth = MatchingDim(weights_shape, weights_dims_count - 2,
                                       output_shape, output_dims_count - 1);
   de528:	4680      	mov	r8, r0
  const int accum_depth = weights_shape.Dims(weights_dims_count - 1);
   de52a:	a81a      	add	r0, sp, #104	; 0x68
   de52c:	f7f9 f828 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de530:	ea4f 0388 	mov.w	r3, r8, lsl #2
   de534:	9307      	str	r3, [sp, #28]
   de536:	ea4f 0c80 	mov.w	ip, r0, lsl #2
   de53a:	463b      	mov	r3, r7
  for (int b = 0; b < batches; ++b) {
   de53c:	2200      	movs	r2, #0
   de53e:	9909      	ldr	r1, [sp, #36]	; 0x24
   de540:	4291      	cmp	r1, r2
   de542:	dd37      	ble.n	de5b4 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x31c>
   de544:	9908      	ldr	r1, [sp, #32]
   de546:	4626      	mov	r6, r4
   de548:	46a9      	mov	r9, r5
   de54a:	2700      	movs	r7, #0
    for (int out_c = 0; out_c < output_depth; ++out_c) {
   de54c:	45b8      	cmp	r8, r7
   de54e:	dd2c      	ble.n	de5aa <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x312>
   de550:	eddf 7a26 	vldr	s15, [pc, #152]	; de5ec <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x354>
   de554:	468a      	mov	sl, r1
   de556:	469b      	mov	fp, r3
   de558:	f04f 0e00 	mov.w	lr, #0
      float total = 0.f;
      for (int d = 0; d < accum_depth; ++d) {
   de55c:	4570      	cmp	r0, lr
   de55e:	dd08      	ble.n	de572 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x2da>
        total += input_data[b * accum_depth + d] *
   de560:	ecfb 6a01 	vldmia	fp!, {s13}
   de564:	ecba 7a01 	vldmia	sl!, {s14}
                                       output_shape, output_dims_count - 1);
  const int accum_depth = weights_shape.Dims(weights_dims_count - 1);
  for (int b = 0; b < batches; ++b) {
    for (int out_c = 0; out_c < output_depth; ++out_c) {
      float total = 0.f;
      for (int d = 0; d < accum_depth; ++d) {
   de568:	f10e 0e01 	add.w	lr, lr, #1
        total += input_data[b * accum_depth + d] *
                 weights_data[out_c * accum_depth + d];
   de56c:	eee6 7a87 	vfma.f32	s15, s13, s14
   de570:	e7f4      	b.n	de55c <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x2c4>
      }
      float bias_value = 0.0f;
      if (bias_data) {
   de572:	b114      	cbz	r4, de57a <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x2e2>
        bias_value = bias_data[out_c];
   de574:	ed96 7a00 	vldr	s14, [r6]
   de578:	e001      	b.n	de57e <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x2e6>
      float total = 0.f;
      for (int d = 0; d < accum_depth; ++d) {
        total += input_data[b * accum_depth + d] *
                 weights_data[out_c * accum_depth + d];
      }
      float bias_value = 0.0f;
   de57a:	ed9f 7a1c 	vldr	s14, [pc, #112]	; de5ec <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x354>
      if (bias_data) {
        bias_value = bias_data[out_c];
      }
      output_data[out_c + output_depth * b] = ActivationFunctionWithMinMax(
   de57e:	ee77 7a87 	vadd.f32	s15, s15, s14
  const int batches = FlatSizeSkipDim(output_shape, output_dims_count - 1);
  const int output_depth = MatchingDim(weights_shape, weights_dims_count - 2,
                                       output_shape, output_dims_count - 1);
  const int accum_depth = weights_shape.Dims(weights_dims_count - 1);
  for (int b = 0; b < batches; ++b) {
    for (int out_c = 0; out_c < output_depth; ++out_c) {
   de582:	3701      	adds	r7, #1
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
	return __b;
      return __a;
   de584:	eef4 7ae8 	vcmpe.f32	s15, s17
   de588:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   de58c:	bf48      	it	mi
   de58e:	eef0 7a68 	vmovmi.f32	s15, s17
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
   de592:	eef4 7a48 	vcmp.f32	s15, s16
   de596:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   de59a:	bfc8      	it	gt
   de59c:	eef0 7a48 	vmovgt.f32	s15, s16
      float bias_value = 0.0f;
      if (bias_data) {
        bias_value = bias_data[out_c];
      }
      output_data[out_c + output_depth * b] = ActivationFunctionWithMinMax(
          total + bias_value, output_activation_min, output_activation_max);
   de5a0:	ece9 7a01 	vstmia	r9!, {s15}
   de5a4:	3604      	adds	r6, #4
   de5a6:	4461      	add	r1, ip
   de5a8:	e7d0      	b.n	de54c <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x2b4>
   de5aa:	9907      	ldr	r1, [sp, #28]
  const int weights_dims_count = weights_shape.DimensionsCount();
  const int batches = FlatSizeSkipDim(output_shape, output_dims_count - 1);
  const int output_depth = MatchingDim(weights_shape, weights_dims_count - 2,
                                       output_shape, output_dims_count - 1);
  const int accum_depth = weights_shape.Dims(weights_dims_count - 1);
  for (int b = 0; b < batches; ++b) {
   de5ac:	3201      	adds	r2, #1
   de5ae:	440d      	add	r5, r1
   de5b0:	4463      	add	r3, ip
   de5b2:	e7c4      	b.n	de53e <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x2a6>
   de5b4:	a824      	add	r0, sp, #144	; 0x90
   de5b6:	f7f8 ffd8 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   de5ba:	a81f      	add	r0, sp, #124	; 0x7c
   de5bc:	f7f8 ffd5 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  tflite::FullyConnectedParams op_params;
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;
  tflite::reference_ops::FullyConnected(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
      GetTensorShape(filter), GetTensorData<float>(filter),
   de5c0:	a81a      	add	r0, sp, #104	; 0x68
   de5c2:	f7f8 ffd2 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                           &output_activation_max);
  tflite::FullyConnectedParams op_params;
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;
  tflite::reference_ops::FullyConnected(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
   de5c6:	a815      	add	r0, sp, #84	; 0x54
   de5c8:	e728      	b.n	de41c <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x184>
      return EvalQuantized(context, node, params, data, input, filter, bias,
                           output);

    default:
      context->ReportError(context, "Type %d not currently supported.",
                           filter->type);
   de5ca:	f8d8 3014 	ldr.w	r3, [r8, #20]
   de5ce:	4908      	ldr	r1, [pc, #32]	; (de5f0 <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0x358>)
   de5d0:	4640      	mov	r0, r8
   de5d2:	4798      	blx	r3
   de5d4:	e6cb      	b.n	de36e <_ZN6tflite3ops5micro15fully_connected4EvalEP13TfLiteContextP10TfLiteNode+0xd6>
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   de5d6:	b02f      	add	sp, #188	; 0xbc
   de5d8:	ecbd 8b02 	vpop	{d8}
   de5dc:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   de5e0:	000eb956 	.word	0x000eb956
   de5e4:	7f7fffff 	.word	0x7f7fffff
   de5e8:	ff7fffff 	.word	0xff7fffff
   de5ec:	00000000 	.word	0x00000000
   de5f0:	000eb997 	.word	0x000eb997

000de5f4 <_ZN6tflite3ops5micro24Register_FULLY_CONNECTEDEv>:
TfLiteRegistration* Register_FULLY_CONNECTED() {
  static TfLiteRegistration r = {fully_connected::Init, fully_connected::Free,
                                 fully_connected::Prepare,
                                 fully_connected::Eval};
  return &r;
}
   de5f4:	4800      	ldr	r0, [pc, #0]	; (de5f8 <_ZN6tflite3ops5micro24Register_FULLY_CONNECTEDEv+0x4>)
   de5f6:	4770      	bx	lr
   de5f8:	2003bfb0 	.word	0x2003bfb0

000de5fc <_ZN6tflite3ops5micro7logical12_GLOBAL__N_19LogicalOrEbb>:
  }

  return kTfLiteOk;
}

bool LogicalOr(bool x, bool y) { return x || y; }
   de5fc:	2800      	cmp	r0, #0
   de5fe:	bf0c      	ite	eq
   de600:	4608      	moveq	r0, r1
   de602:	2001      	movne	r0, #1
   de604:	4770      	bx	lr

000de606 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_110LogicalAndEbb>:

TfLiteStatus LogicalOrEval(TfLiteContext* context, TfLiteNode* node) {
  return LogicalImpl(context, node, LogicalOr);
}

bool LogicalAnd(bool x, bool y) { return x && y; }
   de606:	2800      	cmp	r0, #0
   de608:	bf14      	ite	ne
   de60a:	4608      	movne	r0, r1
   de60c:	2000      	moveq	r0, #0
   de60e:	4770      	bx	lr

000de610 <_ZN6tflite3ops5micro19Register_LOGICAL_OREv>:
  // Init, Free, Prepare, Eval are satisfying the Interface required by
  // TfLiteRegistration.
  static TfLiteRegistration r = {/* init */ nullptr, /* free */ nullptr,
                                 /* prepare */ nullptr, logical::LogicalOrEval};
  return &r;
}
   de610:	4800      	ldr	r0, [pc, #0]	; (de614 <_ZN6tflite3ops5micro19Register_LOGICAL_OREv+0x4>)
   de612:	4770      	bx	lr
   de614:	2003bfd0 	.word	0x2003bfd0

000de618 <_ZN6tflite3ops5micro20Register_LOGICAL_ANDEv>:
  // TfLiteRegistration.
  static TfLiteRegistration r = {/* init */ nullptr, /* free */ nullptr,
                                 /* prepare */ nullptr,
                                 logical::LogicalAndEval};
  return &r;
}
   de618:	4800      	ldr	r0, [pc, #0]	; (de61c <_ZN6tflite3ops5micro20Register_LOGICAL_ANDEv+0x4>)
   de61a:	4770      	bx	lr
   de61c:	2003bff0 	.word	0x2003bff0

000de620 <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E>:
}

// R: Result type. T1: Input 1 type. T2: Input 2 type.
// TODO(renjieliu): Refactor other binary functions to use this one.
template <typename R, typename T1, typename T2>
inline void BinaryFunction(const RuntimeShape& input1_shape,
   de620:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
   de624:	4699      	mov	r9, r3
   de626:	6807      	ldr	r7, [r0, #0]
}

inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0,
                            const RuntimeShape& check_shape_1) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   de628:	6813      	ldr	r3, [r2, #0]
   de62a:	9d0a      	ldr	r5, [sp, #40]	; 0x28
   de62c:	429f      	cmp	r7, r3
   de62e:	4604      	mov	r4, r0
   de630:	4688      	mov	r8, r1
   de632:	4616      	mov	r6, r2
   de634:	d102      	bne.n	de63c <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x1c>
   de636:	f04f 0a00 	mov.w	sl, #0
   de63a:	e00e      	b.n	de65a <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x3a>
   de63c:	f006 ff5a 	bl	e54f4 <abort>
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   de640:	4651      	mov	r1, sl
   de642:	4620      	mov	r0, r4
   de644:	f7f8 ff9c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de648:	4651      	mov	r1, sl
   de64a:	4683      	mov	fp, r0
   de64c:	4630      	mov	r0, r6
   de64e:	f7f8 ff97 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de652:	4583      	cmp	fp, r0
   de654:	d1f2      	bne.n	de63c <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x1c>
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0,
                            const RuntimeShape& check_shape_1) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   de656:	f10a 0a01 	add.w	sl, sl, #1
   de65a:	4557      	cmp	r7, sl
   de65c:	dcf0      	bgt.n	de640 <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x20>

// Flat size calculation, checking that dimensions match with one or more other
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   de65e:	682b      	ldr	r3, [r5, #0]
   de660:	429f      	cmp	r7, r3
   de662:	d1eb      	bne.n	de63c <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x1c>
   de664:	f04f 0a00 	mov.w	sl, #0
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   de668:	4557      	cmp	r7, sl
   de66a:	dd0d      	ble.n	de688 <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x68>
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   de66c:	4651      	mov	r1, sl
   de66e:	4620      	mov	r0, r4
   de670:	f7f8 ff86 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de674:	4651      	mov	r1, sl
   de676:	4606      	mov	r6, r0
   de678:	4628      	mov	r0, r5
   de67a:	f7f8 ff81 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de67e:	4286      	cmp	r6, r0
   de680:	d1dc      	bne.n	de63c <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x1c>
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   de682:	f10a 0a01 	add.w	sl, sl, #1
   de686:	e7ef      	b.n	de668 <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x48>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   de688:	2f04      	cmp	r7, #4
   de68a:	bfcc      	ite	gt
   de68c:	6864      	ldrgt	r4, [r4, #4]
   de68e:	3404      	addle	r4, #4
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   de690:	2300      	movs	r3, #0
  }

  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
   de692:	f04f 0a01 	mov.w	sl, #1
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   de696:	429f      	cmp	r7, r3
   de698:	dc01      	bgt.n	de69e <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x7e>
   de69a:	2400      	movs	r4, #0
   de69c:	e005      	b.n	de6aa <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x8a>
      buffer_size *= dims_data[i];
   de69e:	f854 2023 	ldr.w	r2, [r4, r3, lsl #2]
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   de6a2:	3301      	adds	r3, #1
      buffer_size *= dims_data[i];
   de6a4:	fb02 fa0a 	mul.w	sl, r2, sl
   de6a8:	e7f5      	b.n	de696 <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x76>
                           const T2* input2_data,
                           const RuntimeShape& output_shape, R* output_data,
                           R (*func)(T1, T2)) {
  const int flat_size =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int i = 0; i < flat_size; ++i) {
   de6aa:	4554      	cmp	r4, sl
   de6ac:	da09      	bge.n	de6c2 <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0xa2>
    output_data[i] = func(input1_data[i], input2_data[i]);
   de6ae:	f819 1004 	ldrb.w	r1, [r9, r4]
   de6b2:	f818 0004 	ldrb.w	r0, [r8, r4]
   de6b6:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   de6b8:	4798      	blx	r3
   de6ba:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   de6bc:	5518      	strb	r0, [r3, r4]
                           const T2* input2_data,
                           const RuntimeShape& output_shape, R* output_data,
                           R (*func)(T1, T2)) {
  const int flat_size =
      MatchingFlatSize(input1_shape, input2_shape, output_shape);
  for (int i = 0; i < flat_size; ++i) {
   de6be:	3401      	adds	r4, #1
   de6c0:	e7f3      	b.n	de6aa <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x8a>
   de6c2:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}

000de6c6 <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E>:
//
// Also appears to duplicte MinimumMaximum.
//
// R: Result type. T1: Input 1 type. T2: Input 2 type.
template <typename R, typename T1, typename T2>
inline void BroadcastBinaryFunction4DSlow(
   de6c6:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   de6ca:	469a      	mov	sl, r3
    const RuntimeShape& unextended_input1_shape, const T1* input1_data,
    const RuntimeShape& unextended_input2_shape, const T2* input2_data,
    const RuntimeShape& unextended_output_shape, R* output_data,
    R (*func)(T1, T2)) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   de6cc:	6803      	ldr	r3, [r0, #0]
//
// Also appears to duplicte MinimumMaximum.
//
// R: Result type. T1: Input 1 type. T2: Input 2 type.
template <typename R, typename T1, typename T2>
inline void BroadcastBinaryFunction4DSlow(
   de6ce:	b0a5      	sub	sp, #148	; 0x94
    const RuntimeShape& unextended_input1_shape, const T1* input1_data,
    const RuntimeShape& unextended_input2_shape, const T2* input2_data,
    const RuntimeShape& unextended_output_shape, R* output_data,
    R (*func)(T1, T2)) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   de6d0:	2b04      	cmp	r3, #4
//
// Also appears to duplicte MinimumMaximum.
//
// R: Result type. T1: Input 1 type. T2: Input 2 type.
template <typename R, typename T1, typename T2>
inline void BroadcastBinaryFunction4DSlow(
   de6d2:	4614      	mov	r4, r2
   de6d4:	4605      	mov	r5, r0
   de6d6:	9103      	str	r1, [sp, #12]
   de6d8:	9a2e      	ldr	r2, [sp, #184]	; 0xb8
    const RuntimeShape& unextended_input1_shape, const T1* input1_data,
    const RuntimeShape& unextended_input2_shape, const T2* input2_data,
    const RuntimeShape& unextended_output_shape, R* output_data,
    R (*func)(T1, T2)) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   de6da:	dd01      	ble.n	de6e0 <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x1a>
   de6dc:	f006 ff0a 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   de6e0:	6823      	ldr	r3, [r4, #0]
   de6e2:	2b04      	cmp	r3, #4
   de6e4:	dcfa      	bgt.n	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   de6e6:	6813      	ldr	r3, [r2, #0]
   de6e8:	2b04      	cmp	r3, #4
   de6ea:	dcf7      	bgt.n	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
  // (a) as Dims<4>-dependent code is eliminated, the reliance on this should be
  // reduced, and (b) some kernels are stricly 4-D, but then the shapes of their
  // inputs should already be 4-D, so this function should not be needed.
  inline static RuntimeShape ExtendedShape(int new_shape_size,
                                           const RuntimeShape& shape) {
    return RuntimeShape(new_shape_size, shape, 1);
   de6ec:	2301      	movs	r3, #1
   de6ee:	2104      	movs	r1, #4
   de6f0:	a805      	add	r0, sp, #20
   de6f2:	f7f8 ff7e 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   de6f6:	462a      	mov	r2, r5
   de6f8:	2301      	movs	r3, #1
   de6fa:	2104      	movs	r1, #4
   de6fc:	a80a      	add	r0, sp, #40	; 0x28
   de6fe:	f7f8 ff78 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   de702:	4622      	mov	r2, r4
   de704:	2301      	movs	r3, #1
   de706:	2104      	movs	r1, #4
   de708:	a80f      	add	r0, sp, #60	; 0x3c
   de70a:	f7f8 ff72 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   de70e:	f10d 0970 	add.w	r9, sp, #112	; 0x70
  auto extended_input0_shape = RuntimeShape::ExtendedShape(N, input0_shape);
  auto extended_input1_shape = RuntimeShape::ExtendedShape(N, input1_shape);

  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
  int desc1_stride = 1;
   de712:	f04f 0b01 	mov.w	fp, #1
   de716:	f10d 0890 	add.w	r8, sp, #144	; 0x90

  auto extended_input0_shape = RuntimeShape::ExtendedShape(N, input0_shape);
  auto extended_input1_shape = RuntimeShape::ExtendedShape(N, input1_shape);

  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
   de71a:	465e      	mov	r6, fp
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
   de71c:	2403      	movs	r4, #3
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
   de71e:	ad14      	add	r5, sp, #80	; 0x50
   de720:	464f      	mov	r7, r9
   de722:	4621      	mov	r1, r4
   de724:	a80a      	add	r0, sp, #40	; 0x28
   de726:	f7f8 ff2b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    desc0_out->strides[i] = desc0_stride;
    desc0_stride *= extended_input0_shape.Dims(i);
   de72a:	4621      	mov	r1, r4

  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
   de72c:	f845 0024 	str.w	r0, [r5, r4, lsl #2]
    desc0_out->strides[i] = desc0_stride;
    desc0_stride *= extended_input0_shape.Dims(i);
   de730:	a80a      	add	r0, sp, #40	; 0x28
  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
    desc0_out->strides[i] = desc0_stride;
   de732:	f849 6d04 	str.w	r6, [r9, #-4]!
    desc0_stride *= extended_input0_shape.Dims(i);
   de736:	f7f8 ff23 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    desc1_out->extents[i] = extended_input1_shape.Dims(i);
   de73a:	4621      	mov	r1, r4
  int desc0_stride = 1;
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
    desc0_out->strides[i] = desc0_stride;
    desc0_stride *= extended_input0_shape.Dims(i);
   de73c:	4346      	muls	r6, r0
    desc1_out->extents[i] = extended_input1_shape.Dims(i);
   de73e:	a80f      	add	r0, sp, #60	; 0x3c
   de740:	f7f8 ff1e 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de744:	ab1c      	add	r3, sp, #112	; 0x70
    desc1_out->strides[i] = desc1_stride;
    desc1_stride *= extended_input1_shape.Dims(i);
   de746:	4621      	mov	r1, r4
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
    desc0_out->strides[i] = desc0_stride;
    desc0_stride *= extended_input0_shape.Dims(i);
    desc1_out->extents[i] = extended_input1_shape.Dims(i);
   de748:	f843 0024 	str.w	r0, [r3, r4, lsl #2]
    desc1_out->strides[i] = desc1_stride;
   de74c:	f848 bd04 	str.w	fp, [r8, #-4]!
    desc1_stride *= extended_input1_shape.Dims(i);
   de750:	a80f      	add	r0, sp, #60	; 0x3c
   de752:	f7f8 ff15 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  auto extended_input1_shape = RuntimeShape::ExtendedShape(N, input1_shape);

  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
   de756:	f114 34ff 	adds.w	r4, r4, #4294967295	; 0xffffffff
    desc0_out->extents[i] = extended_input0_shape.Dims(i);
    desc0_out->strides[i] = desc0_stride;
    desc0_stride *= extended_input0_shape.Dims(i);
    desc1_out->extents[i] = extended_input1_shape.Dims(i);
    desc1_out->strides[i] = desc1_stride;
    desc1_stride *= extended_input1_shape.Dims(i);
   de75a:	fb00 fb0b 	mul.w	fp, r0, fp
  auto extended_input1_shape = RuntimeShape::ExtendedShape(N, input1_shape);

  // Copy dims to desc, calculating strides.
  int desc0_stride = 1;
  int desc1_stride = 1;
  for (int i = N - 1; i >= 0; --i) {
   de75e:	d2e0      	bcs.n	de722 <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x5c>
   de760:	2400      	movs	r4, #0
      if (extent0 == 1) {
        desc0_out->strides[i] = 0;
        desc0_out->extents[i] = extent1;
      } else {
        TFLITE_DCHECK_EQ(extent1, 1);
        desc1_out->strides[i] = 0;
   de762:	46a0      	mov	r8, r4

  // Walk over each dimension. If the extents are equal do nothing.
  // Otherwise, set the desc with extent 1 to have extent equal to the other and
  // stride 0.
  for (int i = 0; i < N; ++i) {
    const int extent0 = extended_input0_shape.Dims(i);
   de764:	4621      	mov	r1, r4
   de766:	a80a      	add	r0, sp, #40	; 0x28
   de768:	f7f8 ff0a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    const int extent1 = extended_input1_shape.Dims(i);
   de76c:	4621      	mov	r1, r4

  // Walk over each dimension. If the extents are equal do nothing.
  // Otherwise, set the desc with extent 1 to have extent equal to the other and
  // stride 0.
  for (int i = 0; i < N; ++i) {
    const int extent0 = extended_input0_shape.Dims(i);
   de76e:	4606      	mov	r6, r0
    const int extent1 = extended_input1_shape.Dims(i);
   de770:	a80f      	add	r0, sp, #60	; 0x3c
   de772:	f7f8 ff05 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    if (extent0 != extent1) {
   de776:	4286      	cmp	r6, r0
   de778:	d010      	beq.n	de79c <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0xd6>
      if (extent0 == 1) {
   de77a:	2e01      	cmp	r6, #1
   de77c:	ea4f 0384 	mov.w	r3, r4, lsl #2
   de780:	d105      	bne.n	de78e <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0xc8>
        desc0_out->strides[i] = 0;
   de782:	442b      	add	r3, r5
   de784:	f8c3 8010 	str.w	r8, [r3, #16]
        desc0_out->extents[i] = extent1;
   de788:	f845 0024 	str.w	r0, [r5, r4, lsl #2]
   de78c:	e006      	b.n	de79c <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0xd6>
      } else {
        TFLITE_DCHECK_EQ(extent1, 1);
   de78e:	2801      	cmp	r0, #1
   de790:	d1a4      	bne.n	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
        desc1_out->strides[i] = 0;
   de792:	443b      	add	r3, r7
   de794:	f8c3 8010 	str.w	r8, [r3, #16]
        desc1_out->extents[i] = extent0;
   de798:	f847 6024 	str.w	r6, [r7, r4, lsl #2]
  }

  // Walk over each dimension. If the extents are equal do nothing.
  // Otherwise, set the desc with extent 1 to have extent equal to the other and
  // stride 0.
  for (int i = 0; i < N; ++i) {
   de79c:	3401      	adds	r4, #1
   de79e:	2c04      	cmp	r4, #4
   de7a0:	d1e0      	bne.n	de764 <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x9e>
    NdArrayDesc<N>* desc0_out, NdArrayDesc<N>* desc1_out) {
  TFLITE_DCHECK(desc0_out != nullptr);
  TFLITE_DCHECK(desc1_out != nullptr);

  auto extended_input0_shape = RuntimeShape::ExtendedShape(N, input0_shape);
  auto extended_input1_shape = RuntimeShape::ExtendedShape(N, input1_shape);
   de7a2:	a80f      	add	r0, sp, #60	; 0x3c
   de7a4:	f7f8 fee1 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
    const RuntimeShape& input0_shape, const RuntimeShape& input1_shape,
    NdArrayDesc<N>* desc0_out, NdArrayDesc<N>* desc1_out) {
  TFLITE_DCHECK(desc0_out != nullptr);
  TFLITE_DCHECK(desc1_out != nullptr);

  auto extended_input0_shape = RuntimeShape::ExtendedShape(N, input0_shape);
   de7a8:	a80a      	add	r0, sp, #40	; 0x28
   de7aa:	f7f8 fede 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   de7ae:	2400      	movs	r4, #0
   de7b0:	2100      	movs	r1, #0
   de7b2:	a805      	add	r0, sp, #20
   de7b4:	f7f8 fee4 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de7b8:	4284      	cmp	r4, r0
   de7ba:	da5d      	bge.n	de878 <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x1b2>
   de7bc:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   de7be:	f10d 0914 	add.w	r9, sp, #20
   de7c2:	2101      	movs	r1, #1
   de7c4:	4648      	mov	r0, r9
   de7c6:	f7f8 fedb 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de7ca:	4285      	cmp	r5, r0
   de7cc:	da52      	bge.n	de874 <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x1ae>
   de7ce:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   de7d0:	2102      	movs	r1, #2
   de7d2:	4648      	mov	r0, r9
   de7d4:	f7f8 fed4 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de7d8:	4286      	cmp	r6, r0
   de7da:	da49      	bge.n	de870 <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x1aa>
   de7dc:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   de7de:	2103      	movs	r1, #3
   de7e0:	4648      	mov	r0, r9
   de7e2:	f7f8 fecd 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de7e6:	4287      	cmp	r7, r0
   de7e8:	da40      	bge.n	de86c <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x1a6>
  }
  return offset;
}

inline int Offset(const RuntimeShape& shape, int i0, int i1, int i2, int i3) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), 4);
   de7ea:	9b05      	ldr	r3, [sp, #20]
   de7ec:	2b04      	cmp	r3, #4
   de7ee:	f47f af75 	bne.w	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
  const int* dims_data = reinterpret_cast<const int*>(shape.DimsDataUpTo4D());
  TFLITE_DCHECK(i0 >= 0 && i0 < dims_data[0]);
   de7f2:	2c00      	cmp	r4, #0
   de7f4:	f6ff af72 	blt.w	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
   de7f8:	9b06      	ldr	r3, [sp, #24]
   de7fa:	429c      	cmp	r4, r3
   de7fc:	f6bf af6e 	bge.w	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
  TFLITE_DCHECK(i1 >= 0 && i1 < dims_data[1]);
   de800:	2d00      	cmp	r5, #0
   de802:	f6ff af6b 	blt.w	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
   de806:	9b07      	ldr	r3, [sp, #28]
   de808:	429d      	cmp	r5, r3
   de80a:	f6bf af67 	bge.w	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
  TFLITE_DCHECK(i2 >= 0 && i2 < dims_data[2]);
   de80e:	2e00      	cmp	r6, #0
   de810:	f6ff af64 	blt.w	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
   de814:	9908      	ldr	r1, [sp, #32]
   de816:	428e      	cmp	r6, r1
   de818:	f6bf af60 	bge.w	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
  TFLITE_DCHECK(i3 >= 0 && i3 < dims_data[3]);
   de81c:	2f00      	cmp	r7, #0
   de81e:	f6ff af5d 	blt.w	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
   de822:	9a09      	ldr	r2, [sp, #36]	; 0x24
   de824:	4297      	cmp	r7, r2
   de826:	f6bf af59 	bge.w	de6dc <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x16>
  return ((i0 * dims_data[1] + i1) * dims_data[2] + i2) * dims_data[3] + i3;
   de82a:	fb03 5304 	mla	r3, r3, r4, r5
   de82e:	fb01 6303 	mla	r3, r1, r3, r6
   de832:	fb02 7803 	mla	r8, r2, r3, r7
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   de836:	9700      	str	r7, [sp, #0]
   de838:	4633      	mov	r3, r6
   de83a:	462a      	mov	r2, r5
   de83c:	4621      	mov	r1, r4
   de83e:	a814      	add	r0, sp, #80	; 0x50
   de840:	f7f8 ffb4 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   de844:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   de846:	4683      	mov	fp, r0
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   de848:	4633      	mov	r3, r6
   de84a:	462a      	mov	r2, r5
   de84c:	4621      	mov	r1, r4
   de84e:	a81c      	add	r0, sp, #112	; 0x70
   de850:	f7f8 ffac 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = func(in1_val, in2_val);
   de854:	9b03      	ldr	r3, [sp, #12]
   de856:	f81a 1000 	ldrb.w	r1, [sl, r0]
   de85a:	f813 000b 	ldrb.w	r0, [r3, fp]
   de85e:	9b30      	ldr	r3, [sp, #192]	; 0xc0
   de860:	4798      	blx	r3
   de862:	9b2f      	ldr	r3, [sp, #188]	; 0xbc
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   de864:	3701      	adds	r7, #1
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = func(in1_val, in2_val);
   de866:	f803 0008 	strb.w	r0, [r3, r8]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   de86a:	e7b8      	b.n	de7de <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x118>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   de86c:	3601      	adds	r6, #1
   de86e:	e7af      	b.n	de7d0 <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0x10a>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   de870:	3501      	adds	r5, #1
   de872:	e7a4      	b.n	de7be <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0xf8>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   de874:	3401      	adds	r4, #1
   de876:	e79b      	b.n	de7b0 <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E+0xea>
    R (*func)(T1, T2)) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   de878:	a805      	add	r0, sp, #20
   de87a:	f7f8 fe76 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          output_data[out_idx] = func(in1_val, in2_val);
        }
      }
    }
  }
}
   de87e:	b025      	add	sp, #148	; 0x94
   de880:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000de884 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE>:
constexpr int kInputTensor1 = 0;
constexpr int kInputTensor2 = 1;
constexpr int kOutputTensor = 0;

TfLiteStatus LogicalImpl(TfLiteContext* context, TfLiteNode* node,
                         bool (*func)(bool, bool)) {
   de884:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   de888:	680b      	ldr	r3, [r1, #0]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   de88a:	685c      	ldr	r4, [r3, #4]
   de88c:	689d      	ldr	r5, [r3, #8]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   de88e:	684b      	ldr	r3, [r1, #4]
   de890:	4617      	mov	r7, r2
   de892:	6882      	ldr	r2, [r0, #8]
   de894:	6859      	ldr	r1, [r3, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   de896:	2038      	movs	r0, #56	; 0x38
   de898:	fb00 2404 	mla	r4, r0, r4, r2
   de89c:	fb00 2505 	mla	r5, r0, r5, r2
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   de8a0:	fb00 2801 	mla	r8, r0, r1, r2
   de8a4:	b094      	sub	sp, #80	; 0x50
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  if (HaveSameShapes(input1, input2)) {
   de8a6:	4629      	mov	r1, r5
   de8a8:	4620      	mov	r0, r4
   de8aa:	f006 faf5 	bl	e4e98 <_ZN6tflite14HaveSameShapesEPK12TfLiteTensorS2_>
   de8ae:	ae0f      	add	r6, sp, #60	; 0x3c
    reference_ops::BinaryFunction<bool, bool, bool>(
        GetTensorShape(input1), GetTensorData<bool>(input1),
   de8b0:	4621      	mov	r1, r4
                         bool (*func)(bool, bool)) {
  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);
  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  if (HaveSameShapes(input1, input2)) {
   de8b2:	b1f8      	cbz	r0, de8f4 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE+0x70>
    reference_ops::BinaryFunction<bool, bool, bool>(
        GetTensorShape(input1), GetTensorData<bool>(input1),
   de8b4:	a805      	add	r0, sp, #20
   de8b6:	f7f9 f908 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   de8ba:	b104      	cbz	r4, de8be <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE+0x3a>
   de8bc:	6864      	ldr	r4, [r4, #4]
        GetTensorShape(input2), GetTensorData<bool>(input2),
   de8be:	4629      	mov	r1, r5
   de8c0:	a80a      	add	r0, sp, #40	; 0x28
   de8c2:	f7f9 f902 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de8c6:	b105      	cbz	r5, de8ca <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE+0x46>
   de8c8:	686d      	ldr	r5, [r5, #4]
        GetTensorShape(output), GetTensorData<bool>(output), func);
   de8ca:	4641      	mov	r1, r8
   de8cc:	4630      	mov	r0, r6
   de8ce:	f7f9 f8fc 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   de8d2:	f1b8 0f00 	cmp.w	r8, #0
   de8d6:	d002      	beq.n	de8de <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE+0x5a>
   de8d8:	f8d8 2004 	ldr.w	r2, [r8, #4]
   de8dc:	e000      	b.n	de8e0 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE+0x5c>
   de8de:	4642      	mov	r2, r8
   de8e0:	9201      	str	r2, [sp, #4]
   de8e2:	9702      	str	r7, [sp, #8]
   de8e4:	9600      	str	r6, [sp, #0]
   de8e6:	462b      	mov	r3, r5
   de8e8:	aa0a      	add	r2, sp, #40	; 0x28
   de8ea:	4621      	mov	r1, r4
   de8ec:	a805      	add	r0, sp, #20
   de8ee:	f7ff fe97 	bl	de620 <_ZN6tflite13reference_ops14BinaryFunctionIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E>
   de8f2:	e01e      	b.n	de932 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE+0xae>
  } else {
    reference_ops::BroadcastBinaryFunction4DSlow<bool, bool, bool>(
        GetTensorShape(input1), GetTensorData<bool>(input1),
   de8f4:	a805      	add	r0, sp, #20
   de8f6:	f7f9 f8e8 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   de8fa:	b104      	cbz	r4, de8fe <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE+0x7a>
   de8fc:	6864      	ldr	r4, [r4, #4]
        GetTensorShape(input2), GetTensorData<bool>(input2),
   de8fe:	4629      	mov	r1, r5
   de900:	a80a      	add	r0, sp, #40	; 0x28
   de902:	f7f9 f8e2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   de906:	b105      	cbz	r5, de90a <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE+0x86>
   de908:	686d      	ldr	r5, [r5, #4]
        GetTensorShape(output), GetTensorData<bool>(output), func);
   de90a:	4641      	mov	r1, r8
   de90c:	4630      	mov	r0, r6
   de90e:	f7f9 f8dc 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   de912:	f1b8 0f00 	cmp.w	r8, #0
   de916:	d002      	beq.n	de91e <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE+0x9a>
   de918:	f8d8 1004 	ldr.w	r1, [r8, #4]
   de91c:	e000      	b.n	de920 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE+0x9c>
   de91e:	4641      	mov	r1, r8
   de920:	9101      	str	r1, [sp, #4]
   de922:	9702      	str	r7, [sp, #8]
   de924:	9600      	str	r6, [sp, #0]
   de926:	462b      	mov	r3, r5
   de928:	aa0a      	add	r2, sp, #40	; 0x28
   de92a:	4621      	mov	r1, r4
   de92c:	a805      	add	r0, sp, #20
   de92e:	f7ff feca 	bl	de6c6 <_ZN6tflite13reference_ops29BroadcastBinaryFunction4DSlowIbbbEEvRKNS_12RuntimeShapeEPKT0_S4_PKT1_S4_PT_PFSB_S5_S8_E>
   de932:	4630      	mov	r0, r6
   de934:	f7f8 fe19 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
        GetTensorShape(input2), GetTensorData<bool>(input2),
        GetTensorShape(output), GetTensorData<bool>(output), func);
  } else {
    reference_ops::BroadcastBinaryFunction4DSlow<bool, bool, bool>(
        GetTensorShape(input1), GetTensorData<bool>(input1),
        GetTensorShape(input2), GetTensorData<bool>(input2),
   de938:	a80a      	add	r0, sp, #40	; 0x28
   de93a:	f7f8 fe16 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
        GetTensorShape(input1), GetTensorData<bool>(input1),
        GetTensorShape(input2), GetTensorData<bool>(input2),
        GetTensorShape(output), GetTensorData<bool>(output), func);
  } else {
    reference_ops::BroadcastBinaryFunction4DSlow<bool, bool, bool>(
        GetTensorShape(input1), GetTensorData<bool>(input1),
   de93e:	a805      	add	r0, sp, #20
   de940:	f7f8 fe13 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
        GetTensorShape(input2), GetTensorData<bool>(input2),
        GetTensorShape(output), GetTensorData<bool>(output), func);
  }

  return kTfLiteOk;
}
   de944:	2000      	movs	r0, #0
   de946:	b014      	add	sp, #80	; 0x50
   de948:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

000de94c <_ZN6tflite3ops5micro7logical12_GLOBAL__N_113LogicalOrEvalEP13TfLiteContextP10TfLiteNode>:

bool LogicalOr(bool x, bool y) { return x || y; }

TfLiteStatus LogicalOrEval(TfLiteContext* context, TfLiteNode* node) {
  return LogicalImpl(context, node, LogicalOr);
   de94c:	4a01      	ldr	r2, [pc, #4]	; (de954 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_113LogicalOrEvalEP13TfLiteContextP10TfLiteNode+0x8>)
   de94e:	f7ff bf99 	b.w	de884 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE>
   de952:	bf00      	nop
   de954:	000de5fd 	.word	0x000de5fd

000de958 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_114LogicalAndEvalEP13TfLiteContextP10TfLiteNode>:
}

bool LogicalAnd(bool x, bool y) { return x && y; }

TfLiteStatus LogicalAndEval(TfLiteContext* context, TfLiteNode* node) {
  return LogicalImpl(context, node, LogicalAnd);
   de958:	4a01      	ldr	r2, [pc, #4]	; (de960 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_114LogicalAndEvalEP13TfLiteContextP10TfLiteNode+0x8>)
   de95a:	f7ff bf93 	b.w	de884 <_ZN6tflite3ops5micro7logical12_GLOBAL__N_111LogicalImplEP13TfLiteContextP10TfLiteNodePFbbbE>
   de95e:	bf00      	nop
   de960:	000de607 	.word	0x000de607

000de964 <_ZN6tflite3ops5micro11activations7PrepareEP13TfLiteContextP10TfLiteNode>:
constexpr int kInputTensor = 0;
constexpr int kOutputTensor = 0;

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   de964:	2000      	movs	r0, #0
   de966:	4770      	bx	lr

000de968 <_ZN6tflite13reference_ops8LogisticERKNS_12RuntimeShapeEPKfS3_Pf>:

namespace tflite {
namespace reference_ops {

inline void Logistic(const RuntimeShape& input_shape, const float* input_data,
                     const RuntimeShape& output_shape, float* output_data) {
   de968:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   de96c:	ed2d 8b02 	vpush	{d8}
   de970:	461e      	mov	r6, r3
   de972:	f8d0 8000 	ldr.w	r8, [r0]

// Flat size calculation, checking that dimensions match with one or more other
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   de976:	6813      	ldr	r3, [r2, #0]
   de978:	4598      	cmp	r8, r3
   de97a:	4604      	mov	r4, r0
   de97c:	460f      	mov	r7, r1
   de97e:	4691      	mov	r9, r2
   de980:	d101      	bne.n	de986 <_ZN6tflite13reference_ops8LogisticERKNS_12RuntimeShapeEPKfS3_Pf+0x1e>
   de982:	2500      	movs	r5, #0
   de984:	e00d      	b.n	de9a2 <_ZN6tflite13reference_ops8LogisticERKNS_12RuntimeShapeEPKfS3_Pf+0x3a>
   de986:	f006 fdb5 	bl	e54f4 <abort>
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   de98a:	4629      	mov	r1, r5
   de98c:	4620      	mov	r0, r4
   de98e:	f7f8 fdf7 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de992:	4629      	mov	r1, r5
   de994:	4682      	mov	sl, r0
   de996:	4648      	mov	r0, r9
   de998:	f7f8 fdf2 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   de99c:	4582      	cmp	sl, r0
   de99e:	d1f2      	bne.n	de986 <_ZN6tflite13reference_ops8LogisticERKNS_12RuntimeShapeEPKfS3_Pf+0x1e>
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   de9a0:	3501      	adds	r5, #1
   de9a2:	45a8      	cmp	r8, r5
   de9a4:	dcf1      	bgt.n	de98a <_ZN6tflite13reference_ops8LogisticERKNS_12RuntimeShapeEPKfS3_Pf+0x22>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   de9a6:	f1b8 0f04 	cmp.w	r8, #4
   de9aa:	bfcc      	ite	gt
   de9ac:	6864      	ldrgt	r4, [r4, #4]
   de9ae:	3404      	addle	r4, #4
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   de9b0:	2300      	movs	r3, #0
  }

  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
   de9b2:	f04f 0901 	mov.w	r9, #1
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   de9b6:	4598      	cmp	r8, r3
   de9b8:	dd05      	ble.n	de9c6 <_ZN6tflite13reference_ops8LogisticERKNS_12RuntimeShapeEPKfS3_Pf+0x5e>
      buffer_size *= dims_data[i];
   de9ba:	f854 2023 	ldr.w	r2, [r4, r3, lsl #2]
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   de9be:	3301      	adds	r3, #1
      buffer_size *= dims_data[i];
   de9c0:	fb02 f909 	mul.w	r9, r2, r9
   de9c4:	e7f7      	b.n	de9b6 <_ZN6tflite13reference_ops8LogisticERKNS_12RuntimeShapeEPKfS3_Pf+0x4e>
   de9c6:	4634      	mov	r4, r6
   de9c8:	463d      	mov	r5, r7
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   de9ca:	2600      	movs	r6, #0
  const int flat_size = MatchingFlatSize(input_shape, output_shape);

  for (int i = 0; i < flat_size; i++) {
    float val = input_data[i];
    float result = 1.f / (1.f + std::exp(-val));
    output_data[i] = result;
   de9cc:	eeb7 8a00 	vmov.f32	s16, #112	; 0x3f800000  1.0

inline void Logistic(const RuntimeShape& input_shape, const float* input_data,
                     const RuntimeShape& output_shape, float* output_data) {
  const int flat_size = MatchingFlatSize(input_shape, output_shape);

  for (int i = 0; i < flat_size; i++) {
   de9d0:	454e      	cmp	r6, r9
   de9d2:	da0d      	bge.n	de9f0 <_ZN6tflite13reference_ops8LogisticERKNS_12RuntimeShapeEPKfS3_Pf+0x88>
    float val = input_data[i];
   de9d4:	ecb5 0a01 	vldmia	r5!, {s0}
  using ::exp;

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  exp(float __x)
  { return __builtin_expf(__x); }
   de9d8:	eeb1 0a40 	vneg.f32	s0, s0
   de9dc:	f008 f880 	bl	e6ae0 <expf>
    float result = 1.f / (1.f + std::exp(-val));
    output_data[i] = result;
   de9e0:	ee30 0a08 	vadd.f32	s0, s0, s16

inline void Logistic(const RuntimeShape& input_shape, const float* input_data,
                     const RuntimeShape& output_shape, float* output_data) {
  const int flat_size = MatchingFlatSize(input_shape, output_shape);

  for (int i = 0; i < flat_size; i++) {
   de9e4:	3601      	adds	r6, #1
    float val = input_data[i];
    float result = 1.f / (1.f + std::exp(-val));
    output_data[i] = result;
   de9e6:	eec8 7a00 	vdiv.f32	s15, s16, s0
   de9ea:	ece4 7a01 	vstmia	r4!, {s15}

inline void Logistic(const RuntimeShape& input_shape, const float* input_data,
                     const RuntimeShape& output_shape, float* output_data) {
  const int flat_size = MatchingFlatSize(input_shape, output_shape);

  for (int i = 0; i < flat_size; i++) {
   de9ee:	e7ef      	b.n	de9d0 <_ZN6tflite13reference_ops8LogisticERKNS_12RuntimeShapeEPKfS3_Pf+0x68>
    float val = input_data[i];
    float result = 1.f / (1.f + std::exp(-val));
    output_data[i] = result;
  }
}
   de9f0:	ecbd 8b02 	vpop	{d8}
   de9f4:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}

000de9f8 <_ZN6tflite3ops5micro11activations4EvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   de9f8:	b570      	push	{r4, r5, r6, lr}
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   de9fa:	680a      	ldr	r2, [r1, #0]
   de9fc:	6883      	ldr	r3, [r0, #8]
   de9fe:	6852      	ldr	r2, [r2, #4]
   dea00:	2438      	movs	r4, #56	; 0x38
   dea02:	4362      	muls	r2, r4
   dea04:	4605      	mov	r5, r0
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  switch (input->type) {
   dea06:	5c98      	ldrb	r0, [r3, r2]
   dea08:	2801      	cmp	r0, #1

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   dea0a:	b08a      	sub	sp, #40	; 0x28
   dea0c:	eb03 0602 	add.w	r6, r3, r2
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  switch (input->type) {
   dea10:	d11d      	bne.n	dea4e <_ZN6tflite3ops5micro11activations4EvalEP13TfLiteContextP10TfLiteNode+0x56>
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   dea12:	684a      	ldr	r2, [r1, #4]
   dea14:	6852      	ldr	r2, [r2, #4]
    case kTfLiteFloat32: {
      reference_ops::Logistic(
          GetTensorShape(input), GetTensorData<float>(input),
   dea16:	4631      	mov	r1, r6
   dea18:	fb04 3402 	mla	r4, r4, r2, r3
   dea1c:	4668      	mov	r0, sp
   dea1e:	f7f9 f854 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
          GetTensorShape(output), GetTensorData<float>(output));
   dea22:	4621      	mov	r1, r4
   dea24:	a805      	add	r0, sp, #20
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   dea26:	6875      	ldr	r5, [r6, #4]
   dea28:	f7f9 f84f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   dea2c:	b10c      	cbz	r4, dea32 <_ZN6tflite3ops5micro11activations4EvalEP13TfLiteContextP10TfLiteNode+0x3a>
   dea2e:	6863      	ldr	r3, [r4, #4]
   dea30:	e000      	b.n	dea34 <_ZN6tflite3ops5micro11activations4EvalEP13TfLiteContextP10TfLiteNode+0x3c>
   dea32:	4623      	mov	r3, r4
   dea34:	aa05      	add	r2, sp, #20
   dea36:	4629      	mov	r1, r5
   dea38:	4668      	mov	r0, sp
   dea3a:	f7ff ff95 	bl	de968 <_ZN6tflite13reference_ops8LogisticERKNS_12RuntimeShapeEPKfS3_Pf>
   dea3e:	a805      	add	r0, sp, #20
   dea40:	f7f8 fd93 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  switch (input->type) {
    case kTfLiteFloat32: {
      reference_ops::Logistic(
          GetTensorShape(input), GetTensorData<float>(input),
   dea44:	4668      	mov	r0, sp
   dea46:	f7f8 fd90 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          GetTensorShape(output), GetTensorData<float>(output));
      return kTfLiteOk;
   dea4a:	2000      	movs	r0, #0
   dea4c:	e007      	b.n	dea5e <_ZN6tflite3ops5micro11activations4EvalEP13TfLiteContextP10TfLiteNode+0x66>
    }
    default: {
      // TODO(b/141211002): Also support other data types once we have supported
      // temporary tensors in TFLM.
      context->ReportError(context,
   dea4e:	696c      	ldr	r4, [r5, #20]
   dea50:	f7f5 fb6c 	bl	d412c <TfLiteTypeGetName>
                           "Only float32 is supported currently, got %s",
                           TfLiteTypeGetName(input->type));
   dea54:	4903      	ldr	r1, [pc, #12]	; (dea64 <_ZN6tflite3ops5micro11activations4EvalEP13TfLiteContextP10TfLiteNode+0x6c>)
   dea56:	4602      	mov	r2, r0
   dea58:	4628      	mov	r0, r5
   dea5a:	47a0      	blx	r4
      return kTfLiteError;
   dea5c:	2001      	movs	r0, #1
    }
  }
}
   dea5e:	b00a      	add	sp, #40	; 0x28
   dea60:	bd70      	pop	{r4, r5, r6, pc}
   dea62:	bf00      	nop
   dea64:	000eb9b8 	.word	0x000eb9b8

000dea68 <_ZN6tflite3ops5micro17Register_LOGISTICEv>:
TfLiteRegistration* Register_LOGISTIC() {
  static TfLiteRegistration r = {/*init=*/nullptr,
                                 /*free=*/nullptr, activations::Prepare,
                                 activations::Eval};
  return &r;
}
   dea68:	4800      	ldr	r0, [pc, #0]	; (dea6c <_ZN6tflite3ops5micro17Register_LOGISTICEv+0x4>)
   dea6a:	4770      	bx	lr
   dea6c:	2003c010 	.word	0x2003c010

000dea70 <_ZN6tflite3ops5micro15maximum_minimum12_GLOBAL__N_19MaximumOp2opIfEET_S6_S6_>:
};

struct MaximumOp {
  template <typename data_type>
  static data_type op(data_type el1, data_type el2) {
    return el1 > el2 ? el1 : el2;
   dea70:	eeb4 0ae0 	vcmpe.f32	s0, s1
   dea74:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
  }
   dea78:	bfd8      	it	le
   dea7a:	eeb0 0a60 	vmovle.f32	s0, s1
   dea7e:	4770      	bx	lr

000dea80 <_ZN6tflite3ops5micro15maximum_minimum12_GLOBAL__N_19MaximumOp2opIhEET_S6_S6_>:
   dea80:	4288      	cmp	r0, r1
   dea82:	bf38      	it	cc
   dea84:	4608      	movcc	r0, r1
   dea86:	4770      	bx	lr

000dea88 <_ZN6tflite3ops5micro15maximum_minimum12_GLOBAL__N_19MaximumOp2opIaEET_S6_S6_>:
   dea88:	4288      	cmp	r0, r1
   dea8a:	bfb8      	it	lt
   dea8c:	4608      	movlt	r0, r1
   dea8e:	4770      	bx	lr

000dea90 <_ZN6tflite3ops5micro15maximum_minimum12_GLOBAL__N_19MaximumOp2opIlEET_S6_S6_>:
   dea90:	4288      	cmp	r0, r1
   dea92:	bfb8      	it	lt
   dea94:	4608      	movlt	r0, r1
   dea96:	4770      	bx	lr

000dea98 <_ZN6tflite3ops5micro15maximum_minimum12_GLOBAL__N_19MaximumOp2opIxEET_S6_S6_>:
  TfLiteTensor* output;
};

struct MaximumOp {
  template <typename data_type>
  static data_type op(data_type el1, data_type el2) {
   dea98:	b500      	push	{lr}
    return el1 > el2 ? el1 : el2;
   dea9a:	4290      	cmp	r0, r2
   dea9c:	eb71 0e03 	sbcs.w	lr, r1, r3
   deaa0:	bfbc      	itt	lt
   deaa2:	4610      	movlt	r0, r2
   deaa4:	4619      	movlt	r1, r3
  }
   deaa6:	f85d fb04 	ldr.w	pc, [sp], #4

000deaaa <_ZN6tflite3ops5micro15maximum_minimum12_GLOBAL__N_19MinimumOp2opIfEET_S6_S6_>:
};

struct MinimumOp {
  template <typename data_type>
  static data_type op(data_type el1, data_type el2) {
    return el1 < el2 ? el1 : el2;
   deaaa:	eeb4 0ae0 	vcmpe.f32	s0, s1
   deaae:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
  }
   deab2:	bf58      	it	pl
   deab4:	eeb0 0a60 	vmovpl.f32	s0, s1
   deab8:	4770      	bx	lr

000deaba <_ZN6tflite3ops5micro15maximum_minimum12_GLOBAL__N_19MinimumOp2opIhEET_S6_S6_>:
   deaba:	4288      	cmp	r0, r1
   deabc:	bf28      	it	cs
   deabe:	4608      	movcs	r0, r1
   deac0:	4770      	bx	lr

000deac2 <_ZN6tflite3ops5micro15maximum_minimum12_GLOBAL__N_19MinimumOp2opIaEET_S6_S6_>:
   deac2:	4288      	cmp	r0, r1
   deac4:	bfa8      	it	ge
   deac6:	4608      	movge	r0, r1
   deac8:	4770      	bx	lr

000deaca <_ZN6tflite3ops5micro15maximum_minimum12_GLOBAL__N_19MinimumOp2opIlEET_S6_S6_>:
   deaca:	4288      	cmp	r0, r1
   deacc:	bfa8      	it	ge
   deace:	4608      	movge	r0, r1
   dead0:	4770      	bx	lr

000dead2 <_ZN6tflite3ops5micro15maximum_minimum12_GLOBAL__N_19MinimumOp2opIxEET_S6_S6_>:
  }
};

struct MinimumOp {
  template <typename data_type>
  static data_type op(data_type el1, data_type el2) {
   dead2:	b500      	push	{lr}
    return el1 < el2 ? el1 : el2;
   dead4:	4282      	cmp	r2, r0
   dead6:	eb73 0e01 	sbcs.w	lr, r3, r1
   deada:	bfbc      	itt	lt
   deadc:	4610      	movlt	r0, r2
   deade:	4619      	movlt	r1, r3
  }
   deae0:	f85d fb04 	ldr.w	pc, [sp], #4

000deae4 <_ZN6tflite3ops5micro16Register_MAXIMUMEv>:
      /* free */ nullptr,
      /* prepare */ nullptr,
      maximum_minimum::Eval<maximum_minimum::kReference,
                            maximum_minimum::MaximumOp>};
  return &r;
}
   deae4:	4800      	ldr	r0, [pc, #0]	; (deae8 <_ZN6tflite3ops5micro16Register_MAXIMUMEv+0x4>)
   deae6:	4770      	bx	lr
   deae8:	2003c050 	.word	0x2003c050

000deaec <_ZN6tflite3ops5micro16Register_MINIMUMEv>:
      /* free */ nullptr,
      /* prepare */ nullptr,
      maximum_minimum::Eval<maximum_minimum::kReference,
                            maximum_minimum::MinimumOp>};
  return &r;
}
   deaec:	4800      	ldr	r0, [pc, #0]	; (deaf0 <_ZN6tflite3ops5micro16Register_MINIMUMEv+0x4>)
   deaee:	4770      	bx	lr
   deaf0:	2003c030 	.word	0x2003c030

000deaf4 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>:

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   deaf4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   deaf8:	469b      	mov	fp, r3
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   deafa:	6803      	ldr	r3, [r0, #0]

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   deafc:	b09b      	sub	sp, #108	; 0x6c
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   deafe:	2b04      	cmp	r3, #4

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   deb00:	4616      	mov	r6, r2
   deb02:	4604      	mov	r4, r0
   deb04:	9102      	str	r1, [sp, #8]
   deb06:	9a24      	ldr	r2, [sp, #144]	; 0x90
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   deb08:	dd01      	ble.n	deb0e <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x1a>
   deb0a:	f006 fcf3 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   deb0e:	6833      	ldr	r3, [r6, #0]
   deb10:	2b04      	cmp	r3, #4
   deb12:	dcfa      	bgt.n	deb0a <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   deb14:	6813      	ldr	r3, [r2, #0]
   deb16:	2b04      	cmp	r3, #4
   deb18:	dcf7      	bgt.n	deb0a <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x16>
  // (a) as Dims<4>-dependent code is eliminated, the reliance on this should be
  // reduced, and (b) some kernels are stricly 4-D, but then the shapes of their
  // inputs should already be 4-D, so this function should not be needed.
  inline static RuntimeShape ExtendedShape(int new_shape_size,
                                           const RuntimeShape& shape) {
    return RuntimeShape(new_shape_size, shape, 1);
   deb1a:	2301      	movs	r3, #1
   deb1c:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   deb1e:	ad0a      	add	r5, sp, #40	; 0x28
   deb20:	a805      	add	r0, sp, #20
   deb22:	f7f8 fd66 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   deb26:	4620      	mov	r0, r4
   deb28:	ab12      	add	r3, sp, #72	; 0x48
   deb2a:	462a      	mov	r2, r5
   deb2c:	4631      	mov	r1, r6
   deb2e:	f7f9 f875 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   deb32:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   deb34:	9503      	str	r5, [sp, #12]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   deb36:	2100      	movs	r1, #0
   deb38:	a805      	add	r0, sp, #20
   deb3a:	f7f8 fd21 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   deb3e:	4284      	cmp	r4, r0
   deb40:	da49      	bge.n	debd6 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xe2>
   deb42:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   deb44:	af05      	add	r7, sp, #20
   deb46:	2101      	movs	r1, #1
   deb48:	4638      	mov	r0, r7
   deb4a:	f7f8 fd19 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   deb4e:	4285      	cmp	r5, r0
   deb50:	da3f      	bge.n	debd2 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xde>
   deb52:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   deb54:	2102      	movs	r1, #2
   deb56:	4638      	mov	r0, r7
   deb58:	f7f8 fd12 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   deb5c:	4286      	cmp	r6, r0
   deb5e:	da36      	bge.n	debce <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xda>
   deb60:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   deb64:	2103      	movs	r1, #3
   deb66:	4638      	mov	r0, r7
   deb68:	f7f8 fd0a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   deb6c:	4580      	cmp	r8, r0
   deb6e:	da2c      	bge.n	debca <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xd6>
          auto out_idx = Offset(output_shape, b, y, x, c);
   deb70:	f8cd 8000 	str.w	r8, [sp]
   deb74:	4633      	mov	r3, r6
   deb76:	462a      	mov	r2, r5
   deb78:	4621      	mov	r1, r4
   deb7a:	4638      	mov	r0, r7
   deb7c:	f7f8 fd65 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   deb80:	f8cd 8000 	str.w	r8, [sp]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
   deb84:	4681      	mov	r9, r0
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   deb86:	4633      	mov	r3, r6
   deb88:	462a      	mov	r2, r5
   deb8a:	4621      	mov	r1, r4
   deb8c:	9803      	ldr	r0, [sp, #12]
   deb8e:	f7f8 fe0d 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   deb92:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   deb96:	4682      	mov	sl, r0
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   deb98:	4633      	mov	r3, r6
   deb9a:	462a      	mov	r2, r5
   deb9c:	4621      	mov	r1, r4
   deb9e:	a812      	add	r0, sp, #72	; 0x48
   deba0:	f7f8 fe04 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   deba4:	9b25      	ldr	r3, [sp, #148]	; 0x94
   deba6:	eb03 0989 	add.w	r9, r3, r9, lsl #2
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
   debaa:	9b02      	ldr	r3, [sp, #8]
          auto in2_val = input2_data[in2_idx];
   debac:	eb0b 0080 	add.w	r0, fp, r0, lsl #2
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
   debb0:	eb03 0a8a 	add.w	sl, r3, sl, lsl #2
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   debb4:	edd0 0a00 	vldr	s1, [r0]
   debb8:	ed9a 0a00 	vldr	s0, [sl]
   debbc:	9b26      	ldr	r3, [sp, #152]	; 0x98
   debbe:	4798      	blx	r3
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   debc0:	f108 0801 	add.w	r8, r8, #1
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   debc4:	ed89 0a00 	vstr	s0, [r9]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   debc8:	e7cc      	b.n	deb64 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x70>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   debca:	3601      	adds	r6, #1
   debcc:	e7c2      	b.n	deb54 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x60>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   debce:	3501      	adds	r5, #1
   debd0:	e7b8      	b.n	deb44 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x50>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   debd2:	3401      	adds	r4, #1
   debd4:	e7af      	b.n	deb36 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x42>
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   debd6:	a805      	add	r0, sp, #20
   debd8:	f7f8 fcc7 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          output_data[out_idx] = op(in1_val, in2_val);
        }
      }
    }
  }
}
   debdc:	b01b      	add	sp, #108	; 0x6c
   debde:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000debe2 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>:

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   debe2:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   debe6:	4699      	mov	r9, r3
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   debe8:	6803      	ldr	r3, [r0, #0]

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   debea:	b09b      	sub	sp, #108	; 0x6c
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   debec:	2b04      	cmp	r3, #4

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   debee:	4616      	mov	r6, r2
   debf0:	4604      	mov	r4, r0
   debf2:	9102      	str	r1, [sp, #8]
   debf4:	9a24      	ldr	r2, [sp, #144]	; 0x90
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   debf6:	dd01      	ble.n	debfc <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x1a>
   debf8:	f006 fc7c 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   debfc:	6833      	ldr	r3, [r6, #0]
   debfe:	2b04      	cmp	r3, #4
   dec00:	dcfa      	bgt.n	debf8 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   dec02:	6813      	ldr	r3, [r2, #0]
   dec04:	2b04      	cmp	r3, #4
   dec06:	dcf7      	bgt.n	debf8 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x16>
   dec08:	2301      	movs	r3, #1
   dec0a:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   dec0c:	ad0a      	add	r5, sp, #40	; 0x28
   dec0e:	a805      	add	r0, sp, #20
   dec10:	f7f8 fcef 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   dec14:	4620      	mov	r0, r4
   dec16:	ab12      	add	r3, sp, #72	; 0x48
   dec18:	462a      	mov	r2, r5
   dec1a:	4631      	mov	r1, r6
   dec1c:	f7f8 fffe 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dec20:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   dec22:	9503      	str	r5, [sp, #12]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dec24:	2100      	movs	r1, #0
   dec26:	a805      	add	r0, sp, #20
   dec28:	f7f8 fcaa 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dec2c:	4284      	cmp	r4, r0
   dec2e:	da43      	bge.n	decb8 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xd6>
   dec30:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dec32:	af05      	add	r7, sp, #20
   dec34:	2101      	movs	r1, #1
   dec36:	4638      	mov	r0, r7
   dec38:	f7f8 fca2 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dec3c:	4285      	cmp	r5, r0
   dec3e:	da39      	bge.n	decb4 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xd2>
   dec40:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dec42:	2102      	movs	r1, #2
   dec44:	4638      	mov	r0, r7
   dec46:	f7f8 fc9b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dec4a:	4286      	cmp	r6, r0
   dec4c:	da30      	bge.n	decb0 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xce>
   dec4e:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dec52:	2103      	movs	r1, #3
   dec54:	4638      	mov	r0, r7
   dec56:	f7f8 fc93 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dec5a:	4580      	cmp	r8, r0
   dec5c:	da26      	bge.n	decac <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xca>
          auto out_idx = Offset(output_shape, b, y, x, c);
   dec5e:	f8cd 8000 	str.w	r8, [sp]
   dec62:	4633      	mov	r3, r6
   dec64:	462a      	mov	r2, r5
   dec66:	4621      	mov	r1, r4
   dec68:	4638      	mov	r0, r7
   dec6a:	f7f8 fcee 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   dec6e:	f8cd 8000 	str.w	r8, [sp]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
   dec72:	4682      	mov	sl, r0
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   dec74:	4633      	mov	r3, r6
   dec76:	462a      	mov	r2, r5
   dec78:	4621      	mov	r1, r4
   dec7a:	9803      	ldr	r0, [sp, #12]
   dec7c:	f7f8 fd96 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   dec80:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   dec84:	4683      	mov	fp, r0
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   dec86:	4633      	mov	r3, r6
   dec88:	462a      	mov	r2, r5
   dec8a:	4621      	mov	r1, r4
   dec8c:	a812      	add	r0, sp, #72	; 0x48
   dec8e:	f7f8 fd8d 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   dec92:	9b02      	ldr	r3, [sp, #8]
   dec94:	f819 1000 	ldrb.w	r1, [r9, r0]
   dec98:	f813 000b 	ldrb.w	r0, [r3, fp]
   dec9c:	9b26      	ldr	r3, [sp, #152]	; 0x98
   dec9e:	4798      	blx	r3
   deca0:	9b25      	ldr	r3, [sp, #148]	; 0x94
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   deca2:	f108 0801 	add.w	r8, r8, #1
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   deca6:	f803 000a 	strb.w	r0, [r3, sl]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   decaa:	e7d2      	b.n	dec52 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x70>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   decac:	3601      	adds	r6, #1
   decae:	e7c8      	b.n	dec42 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x60>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   decb0:	3501      	adds	r5, #1
   decb2:	e7be      	b.n	dec32 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x50>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   decb4:	3401      	adds	r4, #1
   decb6:	e7b5      	b.n	dec24 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x42>
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   decb8:	a805      	add	r0, sp, #20
   decba:	f7f8 fc56 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          output_data[out_idx] = op(in1_val, in2_val);
        }
      }
    }
  }
}
   decbe:	b01b      	add	sp, #108	; 0x6c
   decc0:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000decc4 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>:

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   decc4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   decc8:	4699      	mov	r9, r3
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   decca:	6803      	ldr	r3, [r0, #0]

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   deccc:	b09b      	sub	sp, #108	; 0x6c
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   decce:	2b04      	cmp	r3, #4

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   decd0:	4616      	mov	r6, r2
   decd2:	4604      	mov	r4, r0
   decd4:	9102      	str	r1, [sp, #8]
   decd6:	9a24      	ldr	r2, [sp, #144]	; 0x90
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   decd8:	dd01      	ble.n	decde <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x1a>
   decda:	f006 fc0b 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   decde:	6833      	ldr	r3, [r6, #0]
   dece0:	2b04      	cmp	r3, #4
   dece2:	dcfa      	bgt.n	decda <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   dece4:	6813      	ldr	r3, [r2, #0]
   dece6:	2b04      	cmp	r3, #4
   dece8:	dcf7      	bgt.n	decda <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x16>
   decea:	2301      	movs	r3, #1
   decec:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   decee:	ad0a      	add	r5, sp, #40	; 0x28
   decf0:	a805      	add	r0, sp, #20
   decf2:	f7f8 fc7e 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   decf6:	4620      	mov	r0, r4
   decf8:	ab12      	add	r3, sp, #72	; 0x48
   decfa:	462a      	mov	r2, r5
   decfc:	4631      	mov	r1, r6
   decfe:	f7f8 ff8d 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   ded02:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   ded04:	9503      	str	r5, [sp, #12]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   ded06:	2100      	movs	r1, #0
   ded08:	a805      	add	r0, sp, #20
   ded0a:	f7f8 fc39 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   ded0e:	4284      	cmp	r4, r0
   ded10:	da43      	bge.n	ded9a <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xd6>
   ded12:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   ded14:	af05      	add	r7, sp, #20
   ded16:	2101      	movs	r1, #1
   ded18:	4638      	mov	r0, r7
   ded1a:	f7f8 fc31 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   ded1e:	4285      	cmp	r5, r0
   ded20:	da39      	bge.n	ded96 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xd2>
   ded22:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   ded24:	2102      	movs	r1, #2
   ded26:	4638      	mov	r0, r7
   ded28:	f7f8 fc2a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   ded2c:	4286      	cmp	r6, r0
   ded2e:	da30      	bge.n	ded92 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xce>
   ded30:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   ded34:	2103      	movs	r1, #3
   ded36:	4638      	mov	r0, r7
   ded38:	f7f8 fc22 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   ded3c:	4580      	cmp	r8, r0
   ded3e:	da26      	bge.n	ded8e <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xca>
          auto out_idx = Offset(output_shape, b, y, x, c);
   ded40:	f8cd 8000 	str.w	r8, [sp]
   ded44:	4633      	mov	r3, r6
   ded46:	462a      	mov	r2, r5
   ded48:	4621      	mov	r1, r4
   ded4a:	4638      	mov	r0, r7
   ded4c:	f7f8 fc7d 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   ded50:	f8cd 8000 	str.w	r8, [sp]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
   ded54:	4682      	mov	sl, r0
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   ded56:	4633      	mov	r3, r6
   ded58:	462a      	mov	r2, r5
   ded5a:	4621      	mov	r1, r4
   ded5c:	9803      	ldr	r0, [sp, #12]
   ded5e:	f7f8 fd25 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   ded62:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   ded66:	4683      	mov	fp, r0
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   ded68:	4633      	mov	r3, r6
   ded6a:	462a      	mov	r2, r5
   ded6c:	4621      	mov	r1, r4
   ded6e:	a812      	add	r0, sp, #72	; 0x48
   ded70:	f7f8 fd1c 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   ded74:	9b02      	ldr	r3, [sp, #8]
   ded76:	f919 1000 	ldrsb.w	r1, [r9, r0]
   ded7a:	f913 000b 	ldrsb.w	r0, [r3, fp]
   ded7e:	9b26      	ldr	r3, [sp, #152]	; 0x98
   ded80:	4798      	blx	r3
   ded82:	9b25      	ldr	r3, [sp, #148]	; 0x94
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   ded84:	f108 0801 	add.w	r8, r8, #1
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   ded88:	f803 000a 	strb.w	r0, [r3, sl]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   ded8c:	e7d2      	b.n	ded34 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x70>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   ded8e:	3601      	adds	r6, #1
   ded90:	e7c8      	b.n	ded24 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x60>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   ded92:	3501      	adds	r5, #1
   ded94:	e7be      	b.n	ded14 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x50>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   ded96:	3401      	adds	r4, #1
   ded98:	e7b5      	b.n	ded06 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x42>
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   ded9a:	a805      	add	r0, sp, #20
   ded9c:	f7f8 fbe5 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          output_data[out_idx] = op(in1_val, in2_val);
        }
      }
    }
  }
}
   deda0:	b01b      	add	sp, #108	; 0x6c
   deda2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000deda6 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>:

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   deda6:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dedaa:	4699      	mov	r9, r3
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dedac:	6803      	ldr	r3, [r0, #0]

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   dedae:	b09b      	sub	sp, #108	; 0x6c
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dedb0:	2b04      	cmp	r3, #4

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   dedb2:	4616      	mov	r6, r2
   dedb4:	4604      	mov	r4, r0
   dedb6:	9102      	str	r1, [sp, #8]
   dedb8:	9a24      	ldr	r2, [sp, #144]	; 0x90
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dedba:	dd01      	ble.n	dedc0 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x1a>
   dedbc:	f006 fb9a 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   dedc0:	6833      	ldr	r3, [r6, #0]
   dedc2:	2b04      	cmp	r3, #4
   dedc4:	dcfa      	bgt.n	dedbc <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   dedc6:	6813      	ldr	r3, [r2, #0]
   dedc8:	2b04      	cmp	r3, #4
   dedca:	dcf7      	bgt.n	dedbc <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x16>
   dedcc:	2301      	movs	r3, #1
   dedce:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   dedd0:	ad0a      	add	r5, sp, #40	; 0x28
   dedd2:	a805      	add	r0, sp, #20
   dedd4:	f7f8 fc0d 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   dedd8:	4620      	mov	r0, r4
   dedda:	ab12      	add	r3, sp, #72	; 0x48
   deddc:	462a      	mov	r2, r5
   dedde:	4631      	mov	r1, r6
   dede0:	f7f8 ff1c 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dede4:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   dede6:	9503      	str	r5, [sp, #12]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dede8:	2100      	movs	r1, #0
   dedea:	a805      	add	r0, sp, #20
   dedec:	f7f8 fbc8 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dedf0:	4284      	cmp	r4, r0
   dedf2:	da43      	bge.n	dee7c <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xd6>
   dedf4:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dedf6:	af05      	add	r7, sp, #20
   dedf8:	2101      	movs	r1, #1
   dedfa:	4638      	mov	r0, r7
   dedfc:	f7f8 fbc0 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dee00:	4285      	cmp	r5, r0
   dee02:	da39      	bge.n	dee78 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xd2>
   dee04:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dee06:	2102      	movs	r1, #2
   dee08:	4638      	mov	r0, r7
   dee0a:	f7f8 fbb9 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dee0e:	4286      	cmp	r6, r0
   dee10:	da30      	bge.n	dee74 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xce>
   dee12:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dee16:	2103      	movs	r1, #3
   dee18:	4638      	mov	r0, r7
   dee1a:	f7f8 fbb1 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   dee1e:	4580      	cmp	r8, r0
   dee20:	da26      	bge.n	dee70 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xca>
          auto out_idx = Offset(output_shape, b, y, x, c);
   dee22:	f8cd 8000 	str.w	r8, [sp]
   dee26:	4633      	mov	r3, r6
   dee28:	462a      	mov	r2, r5
   dee2a:	4621      	mov	r1, r4
   dee2c:	4638      	mov	r0, r7
   dee2e:	f7f8 fc0c 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   dee32:	f8cd 8000 	str.w	r8, [sp]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
   dee36:	4682      	mov	sl, r0
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   dee38:	4633      	mov	r3, r6
   dee3a:	462a      	mov	r2, r5
   dee3c:	4621      	mov	r1, r4
   dee3e:	9803      	ldr	r0, [sp, #12]
   dee40:	f7f8 fcb4 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   dee44:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   dee48:	4683      	mov	fp, r0
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   dee4a:	4633      	mov	r3, r6
   dee4c:	462a      	mov	r2, r5
   dee4e:	4621      	mov	r1, r4
   dee50:	a812      	add	r0, sp, #72	; 0x48
   dee52:	f7f8 fcab 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   dee56:	9b02      	ldr	r3, [sp, #8]
   dee58:	f859 1020 	ldr.w	r1, [r9, r0, lsl #2]
   dee5c:	f853 002b 	ldr.w	r0, [r3, fp, lsl #2]
   dee60:	9b26      	ldr	r3, [sp, #152]	; 0x98
   dee62:	4798      	blx	r3
   dee64:	9b25      	ldr	r3, [sp, #148]	; 0x94
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dee66:	f108 0801 	add.w	r8, r8, #1
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   dee6a:	f843 002a 	str.w	r0, [r3, sl, lsl #2]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   dee6e:	e7d2      	b.n	dee16 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x70>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   dee70:	3601      	adds	r6, #1
   dee72:	e7c8      	b.n	dee06 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x60>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   dee74:	3501      	adds	r5, #1
   dee76:	e7be      	b.n	dedf6 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x50>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   dee78:	3401      	adds	r4, #1
   dee7a:	e7b5      	b.n	dede8 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x42>
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   dee7c:	a805      	add	r0, sp, #20
   dee7e:	f7f8 fb74 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          output_data[out_idx] = op(in1_val, in2_val);
        }
      }
    }
  }
}
   dee82:	b01b      	add	sp, #108	; 0x6c
   dee84:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dee88 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>:

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   dee88:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dee8c:	469b      	mov	fp, r3
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dee8e:	6803      	ldr	r3, [r0, #0]

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   dee90:	b09d      	sub	sp, #116	; 0x74
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dee92:	2b04      	cmp	r3, #4

namespace tflite {
namespace reference_ops {

template <typename T, typename Op>
void MaximumMinimumBroadcast4DSlow(const RuntimeShape& unextended_input1_shape,
   dee94:	4616      	mov	r6, r2
   dee96:	4604      	mov	r4, r0
   dee98:	9104      	str	r1, [sp, #16]
   dee9a:	9a26      	ldr	r2, [sp, #152]	; 0x98
                                   const T* input1_data,
                                   const RuntimeShape& unextended_input2_shape,
                                   const T* input2_data,
                                   const RuntimeShape& unextended_output_shape,
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   dee9c:	dd01      	ble.n	deea2 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x1a>
   dee9e:	f006 fb29 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   deea2:	6833      	ldr	r3, [r6, #0]
   deea4:	2b04      	cmp	r3, #4
   deea6:	dcfa      	bgt.n	dee9e <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   deea8:	6813      	ldr	r3, [r2, #0]
   deeaa:	2b04      	cmp	r3, #4
   deeac:	dcf7      	bgt.n	dee9e <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x16>
   deeae:	2301      	movs	r3, #1
   deeb0:	2104      	movs	r1, #4
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
   deeb2:	ad0c      	add	r5, sp, #48	; 0x30
   deeb4:	a807      	add	r0, sp, #28
   deeb6:	f7f8 fb9c 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   deeba:	4620      	mov	r0, r4
   deebc:	ab14      	add	r3, sp, #80	; 0x50
   deebe:	462a      	mov	r2, r5
   deec0:	4631      	mov	r1, r6
   deec2:	f7f8 feab 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   deec6:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   deec8:	9505      	str	r5, [sp, #20]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   deeca:	2100      	movs	r1, #0
   deecc:	a807      	add	r0, sp, #28
   deece:	f7f8 fb57 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   deed2:	4284      	cmp	r4, r0
   deed4:	da4a      	bge.n	def6c <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xe4>
   deed6:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   deed8:	af07      	add	r7, sp, #28
   deeda:	2101      	movs	r1, #1
   deedc:	4638      	mov	r0, r7
   deede:	f7f8 fb4f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   deee2:	4285      	cmp	r5, r0
   deee4:	da40      	bge.n	def68 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xe0>
   deee6:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   deee8:	9703      	str	r7, [sp, #12]
   deeea:	2102      	movs	r1, #2
   deeec:	9803      	ldr	r0, [sp, #12]
   deeee:	f7f8 fb47 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   deef2:	4286      	cmp	r6, r0
   deef4:	da36      	bge.n	def64 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xdc>
   deef6:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   deefa:	2103      	movs	r1, #3
   deefc:	9803      	ldr	r0, [sp, #12]
   deefe:	f7f8 fb3f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   def02:	4580      	cmp	r8, r0
   def04:	da2c      	bge.n	def60 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0xd8>
          auto out_idx = Offset(output_shape, b, y, x, c);
   def06:	f8cd 8000 	str.w	r8, [sp]
   def0a:	4633      	mov	r3, r6
   def0c:	462a      	mov	r2, r5
   def0e:	4621      	mov	r1, r4
   def10:	9803      	ldr	r0, [sp, #12]
   def12:	f7f8 fb9a 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   def16:	f8cd 8000 	str.w	r8, [sp]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
   def1a:	4681      	mov	r9, r0
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   def1c:	4633      	mov	r3, r6
   def1e:	462a      	mov	r2, r5
   def20:	4621      	mov	r1, r4
   def22:	9805      	ldr	r0, [sp, #20]
   def24:	f7f8 fc42 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   def28:	f8cd 8000 	str.w	r8, [sp]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   def2c:	4682      	mov	sl, r0
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   def2e:	4633      	mov	r3, r6
   def30:	462a      	mov	r2, r5
   def32:	4621      	mov	r1, r4
   def34:	a814      	add	r0, sp, #80	; 0x50
   def36:	f7f8 fc39 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   def3a:	9b27      	ldr	r3, [sp, #156]	; 0x9c
   def3c:	9f28      	ldr	r7, [sp, #160]	; 0xa0
   def3e:	eb03 09c9 	add.w	r9, r3, r9, lsl #3
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
   def42:	9b04      	ldr	r3, [sp, #16]
          auto in2_val = input2_data[in2_idx];
   def44:	eb0b 00c0 	add.w	r0, fp, r0, lsl #3
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
   def48:	eb03 0aca 	add.w	sl, r3, sl, lsl #3
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   def4c:	e9d0 2300 	ldrd	r2, r3, [r0]
   def50:	e9da 0100 	ldrd	r0, r1, [sl]
   def54:	47b8      	blx	r7
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   def56:	f108 0801 	add.w	r8, r8, #1
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = op(in1_val, in2_val);
   def5a:	e9c9 0100 	strd	r0, r1, [r9]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   def5e:	e7cc      	b.n	deefa <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x72>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   def60:	3601      	adds	r6, #1
   def62:	e7c2      	b.n	deeea <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x62>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   def64:	3501      	adds	r5, #1
   def66:	e7b7      	b.n	deed8 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x50>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   def68:	3401      	adds	r4, #1
   def6a:	e7ae      	b.n	deeca <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_+0x42>
                                   T* output_data, Op op) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   def6c:	a807      	add	r0, sp, #28
   def6e:	f7f8 fafc 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          output_data[out_idx] = op(in1_val, in2_val);
        }
      }
    }
  }
}
   def72:	b01d      	add	sp, #116	; 0x74
   def74:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000def78 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode>:
      GetTensorData<data_type>(op_context.output),
      op_type::template op<data_type>);
}

template <KernelType kernel_type, typename OpType>
TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   def78:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
   def7c:	680b      	ldr	r3, [r1, #0]
   def7e:	f8d0 8008 	ldr.w	r8, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   def82:	685c      	ldr	r4, [r3, #4]
   def84:	689d      	ldr	r5, [r3, #8]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   def86:	684b      	ldr	r3, [r1, #4]
   def88:	685f      	ldr	r7, [r3, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   def8a:	2238      	movs	r2, #56	; 0x38
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   def8c:	4357      	muls	r7, r2
   def8e:	4681      	mov	r9, r0
  OpContext op_context(context, node);

  if (kernel_type == kReference) {
    switch (op_context.output->type) {
   def90:	f818 0007 	ldrb.w	r0, [r8, r7]
   def94:	1e43      	subs	r3, r0, #1
      GetTensorData<data_type>(op_context.output),
      op_type::template op<data_type>);
}

template <KernelType kernel_type, typename OpType>
TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   def96:	b095      	sub	sp, #84	; 0x54
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   def98:	fb02 8404 	mla	r4, r2, r4, r8
   def9c:	fb02 8505 	mla	r5, r2, r5, r8
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   defa0:	eb08 0607 	add.w	r6, r8, r7
  OpContext op_context(context, node);

  if (kernel_type == kReference) {
    switch (op_context.output->type) {
   defa4:	2b08      	cmp	r3, #8
   defa6:	f200 80a2 	bhi.w	df0ee <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x176>
   defaa:	e8df f003 	tbb	[pc, r3]
   defae:	5c05      	.short	0x5c05
   defb0:	a0a07922 	.word	0xa0a07922
   defb4:	a0a0      	.short	0xa0a0
   defb6:	3f          	.byte	0x3f
   defb7:	00          	.byte	0x00
}  // namespace

template <typename data_type, typename op_type>
void TFLiteOperation(TfLiteContext* context, TfLiteNode* node,
                     const OpContext& op_context) {
  reference_ops::MaximumMinimumBroadcast4DSlow(
   defb8:	4621      	mov	r1, r4
   defba:	a80f      	add	r0, sp, #60	; 0x3c
   defbc:	f7f8 fd85 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   defc0:	b104      	cbz	r4, defc4 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x4c>
   defc2:	6864      	ldr	r4, [r4, #4]
   defc4:	4629      	mov	r1, r5
   defc6:	a80a      	add	r0, sp, #40	; 0x28
   defc8:	f7f8 fd7f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   defcc:	b105      	cbz	r5, defd0 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x58>
   defce:	686d      	ldr	r5, [r5, #4]
   defd0:	af05      	add	r7, sp, #20
   defd2:	4631      	mov	r1, r6
   defd4:	4638      	mov	r0, r7
   defd6:	f7f8 fd78 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   defda:	4b4c      	ldr	r3, [pc, #304]	; (df10c <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x194>)
   defdc:	9302      	str	r3, [sp, #8]
   defde:	6873      	ldr	r3, [r6, #4]
   defe0:	9301      	str	r3, [sp, #4]
   defe2:	9700      	str	r7, [sp, #0]
   defe4:	462b      	mov	r3, r5
   defe6:	aa0a      	add	r2, sp, #40	; 0x28
   defe8:	4621      	mov	r1, r4
   defea:	a80f      	add	r0, sp, #60	; 0x3c
   defec:	f7ff fd82 	bl	deaf4 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>
   deff0:	e072      	b.n	df0d8 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x160>
   deff2:	4621      	mov	r1, r4
   deff4:	a80f      	add	r0, sp, #60	; 0x3c
   deff6:	f7f8 fd68 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   deffa:	b104      	cbz	r4, deffe <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x86>
   deffc:	6864      	ldr	r4, [r4, #4]
   deffe:	4629      	mov	r1, r5
   df000:	a80a      	add	r0, sp, #40	; 0x28
   df002:	f7f8 fd62 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df006:	b105      	cbz	r5, df00a <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x92>
   df008:	686d      	ldr	r5, [r5, #4]
   df00a:	af05      	add	r7, sp, #20
   df00c:	4631      	mov	r1, r6
   df00e:	4638      	mov	r0, r7
   df010:	f7f8 fd5b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df014:	4b3e      	ldr	r3, [pc, #248]	; (df110 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x198>)
   df016:	9302      	str	r3, [sp, #8]
   df018:	6873      	ldr	r3, [r6, #4]
   df01a:	9301      	str	r3, [sp, #4]
   df01c:	9700      	str	r7, [sp, #0]
   df01e:	462b      	mov	r3, r5
   df020:	aa0a      	add	r2, sp, #40	; 0x28
   df022:	4621      	mov	r1, r4
   df024:	a80f      	add	r0, sp, #60	; 0x3c
   df026:	f7ff fddc 	bl	debe2 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>
   df02a:	e055      	b.n	df0d8 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x160>
   df02c:	4621      	mov	r1, r4
   df02e:	a80f      	add	r0, sp, #60	; 0x3c
   df030:	f7f8 fd4b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df034:	b104      	cbz	r4, df038 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xc0>
   df036:	6864      	ldr	r4, [r4, #4]
   df038:	4629      	mov	r1, r5
   df03a:	a80a      	add	r0, sp, #40	; 0x28
   df03c:	f7f8 fd45 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df040:	b105      	cbz	r5, df044 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xcc>
   df042:	686d      	ldr	r5, [r5, #4]
   df044:	af05      	add	r7, sp, #20
   df046:	4631      	mov	r1, r6
   df048:	4638      	mov	r0, r7
   df04a:	f7f8 fd3e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df04e:	4b31      	ldr	r3, [pc, #196]	; (df114 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x19c>)
   df050:	9302      	str	r3, [sp, #8]
   df052:	6873      	ldr	r3, [r6, #4]
   df054:	9301      	str	r3, [sp, #4]
   df056:	9700      	str	r7, [sp, #0]
   df058:	462b      	mov	r3, r5
   df05a:	aa0a      	add	r2, sp, #40	; 0x28
   df05c:	4621      	mov	r1, r4
   df05e:	a80f      	add	r0, sp, #60	; 0x3c
   df060:	f7ff fe30 	bl	decc4 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>
   df064:	e038      	b.n	df0d8 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x160>
   df066:	4621      	mov	r1, r4
   df068:	a80f      	add	r0, sp, #60	; 0x3c
   df06a:	f7f8 fd2e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df06e:	b104      	cbz	r4, df072 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xfa>
   df070:	6864      	ldr	r4, [r4, #4]
   df072:	4629      	mov	r1, r5
   df074:	a80a      	add	r0, sp, #40	; 0x28
   df076:	f7f8 fd28 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df07a:	b105      	cbz	r5, df07e <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x106>
   df07c:	686d      	ldr	r5, [r5, #4]
   df07e:	af05      	add	r7, sp, #20
   df080:	4631      	mov	r1, r6
   df082:	4638      	mov	r0, r7
   df084:	f7f8 fd21 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df088:	4b23      	ldr	r3, [pc, #140]	; (df118 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x1a0>)
   df08a:	9302      	str	r3, [sp, #8]
   df08c:	6873      	ldr	r3, [r6, #4]
   df08e:	9301      	str	r3, [sp, #4]
   df090:	9700      	str	r7, [sp, #0]
   df092:	462b      	mov	r3, r5
   df094:	aa0a      	add	r2, sp, #40	; 0x28
   df096:	4621      	mov	r1, r4
   df098:	a80f      	add	r0, sp, #60	; 0x3c
   df09a:	f7ff fe84 	bl	deda6 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>
   df09e:	e01b      	b.n	df0d8 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x160>
   df0a0:	4621      	mov	r1, r4
   df0a2:	a80f      	add	r0, sp, #60	; 0x3c
   df0a4:	f7f8 fd11 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df0a8:	b104      	cbz	r4, df0ac <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x134>
   df0aa:	6864      	ldr	r4, [r4, #4]
   df0ac:	4629      	mov	r1, r5
   df0ae:	a80a      	add	r0, sp, #40	; 0x28
   df0b0:	f7f8 fd0b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df0b4:	b105      	cbz	r5, df0b8 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x140>
   df0b6:	686d      	ldr	r5, [r5, #4]
   df0b8:	af05      	add	r7, sp, #20
   df0ba:	4631      	mov	r1, r6
   df0bc:	4638      	mov	r0, r7
   df0be:	f7f8 fd04 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df0c2:	4b16      	ldr	r3, [pc, #88]	; (df11c <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x1a4>)
   df0c4:	9302      	str	r3, [sp, #8]
   df0c6:	6873      	ldr	r3, [r6, #4]
   df0c8:	9301      	str	r3, [sp, #4]
   df0ca:	9700      	str	r7, [sp, #0]
   df0cc:	462b      	mov	r3, r5
   df0ce:	aa0a      	add	r2, sp, #40	; 0x28
   df0d0:	4621      	mov	r1, r4
   df0d2:	a80f      	add	r0, sp, #60	; 0x3c
   df0d4:	f7ff fed8 	bl	dee88 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>
   df0d8:	4638      	mov	r0, r7
   df0da:	f7f8 fa46 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   df0de:	a80a      	add	r0, sp, #40	; 0x28
   df0e0:	f7f8 fa43 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   df0e4:	a80f      	add	r0, sp, #60	; 0x3c
   df0e6:	f7f8 fa40 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  } else {
    context->ReportError(context,
                         "Kernel type not supported by Maximum/Minimum.");
    return kTfLiteError;
  }
  return kTfLiteOk;
   df0ea:	2000      	movs	r0, #0
   df0ec:	e00a      	b.n	df104 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x18c>
        break;
      case kTfLiteInt64:
        TFLiteOperation<int64_t, OpType>(context, node, op_context);
        break;
      default:
        context->ReportError(
   df0ee:	f8d9 4014 	ldr.w	r4, [r9, #20]
   df0f2:	f7f5 f81b 	bl	d412c <TfLiteTypeGetName>
   df0f6:	f818 3007 	ldrb.w	r3, [r8, r7]
   df0fa:	4909      	ldr	r1, [pc, #36]	; (df120 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MinimumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x1a8>)
   df0fc:	4602      	mov	r2, r0
   df0fe:	4648      	mov	r0, r9
   df100:	47a0      	blx	r4
            context, "Type %s (%d) is not supported by Maximum/Minimum.",
            TfLiteTypeGetName(op_context.output->type),
            op_context.output->type);
        return kTfLiteError;
   df102:	2001      	movs	r0, #1
    context->ReportError(context,
                         "Kernel type not supported by Maximum/Minimum.");
    return kTfLiteError;
  }
  return kTfLiteOk;
}
   df104:	b015      	add	sp, #84	; 0x54
   df106:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
   df10a:	bf00      	nop
   df10c:	000deaab 	.word	0x000deaab
   df110:	000deabb 	.word	0x000deabb
   df114:	000deac3 	.word	0x000deac3
   df118:	000deacb 	.word	0x000deacb
   df11c:	000dead3 	.word	0x000dead3
   df120:	000eb9e4 	.word	0x000eb9e4

000df124 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode>:
      GetTensorData<data_type>(op_context.output),
      op_type::template op<data_type>);
}

template <KernelType kernel_type, typename OpType>
TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   df124:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
   df128:	680b      	ldr	r3, [r1, #0]
   df12a:	f8d0 8008 	ldr.w	r8, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   df12e:	685c      	ldr	r4, [r3, #4]
   df130:	689d      	ldr	r5, [r3, #8]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   df132:	684b      	ldr	r3, [r1, #4]
   df134:	685f      	ldr	r7, [r3, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   df136:	2238      	movs	r2, #56	; 0x38
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   df138:	4357      	muls	r7, r2
   df13a:	4681      	mov	r9, r0
  OpContext op_context(context, node);

  if (kernel_type == kReference) {
    switch (op_context.output->type) {
   df13c:	f818 0007 	ldrb.w	r0, [r8, r7]
   df140:	1e43      	subs	r3, r0, #1
      GetTensorData<data_type>(op_context.output),
      op_type::template op<data_type>);
}

template <KernelType kernel_type, typename OpType>
TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   df142:	b095      	sub	sp, #84	; 0x54
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   df144:	fb02 8404 	mla	r4, r2, r4, r8
   df148:	fb02 8505 	mla	r5, r2, r5, r8
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   df14c:	eb08 0607 	add.w	r6, r8, r7
  OpContext op_context(context, node);

  if (kernel_type == kReference) {
    switch (op_context.output->type) {
   df150:	2b08      	cmp	r3, #8
   df152:	f200 80a2 	bhi.w	df29a <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x176>
   df156:	e8df f003 	tbb	[pc, r3]
   df15a:	5c05      	.short	0x5c05
   df15c:	a0a07922 	.word	0xa0a07922
   df160:	a0a0      	.short	0xa0a0
   df162:	3f          	.byte	0x3f
   df163:	00          	.byte	0x00
}  // namespace

template <typename data_type, typename op_type>
void TFLiteOperation(TfLiteContext* context, TfLiteNode* node,
                     const OpContext& op_context) {
  reference_ops::MaximumMinimumBroadcast4DSlow(
   df164:	4621      	mov	r1, r4
   df166:	a80f      	add	r0, sp, #60	; 0x3c
   df168:	f7f8 fcaf 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df16c:	b104      	cbz	r4, df170 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x4c>
   df16e:	6864      	ldr	r4, [r4, #4]
   df170:	4629      	mov	r1, r5
   df172:	a80a      	add	r0, sp, #40	; 0x28
   df174:	f7f8 fca9 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df178:	b105      	cbz	r5, df17c <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x58>
   df17a:	686d      	ldr	r5, [r5, #4]
   df17c:	af05      	add	r7, sp, #20
   df17e:	4631      	mov	r1, r6
   df180:	4638      	mov	r0, r7
   df182:	f7f8 fca2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df186:	4b4c      	ldr	r3, [pc, #304]	; (df2b8 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x194>)
   df188:	9302      	str	r3, [sp, #8]
   df18a:	6873      	ldr	r3, [r6, #4]
   df18c:	9301      	str	r3, [sp, #4]
   df18e:	9700      	str	r7, [sp, #0]
   df190:	462b      	mov	r3, r5
   df192:	aa0a      	add	r2, sp, #40	; 0x28
   df194:	4621      	mov	r1, r4
   df196:	a80f      	add	r0, sp, #60	; 0x3c
   df198:	f7ff fcac 	bl	deaf4 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIfPFfffEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>
   df19c:	e072      	b.n	df284 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x160>
   df19e:	4621      	mov	r1, r4
   df1a0:	a80f      	add	r0, sp, #60	; 0x3c
   df1a2:	f7f8 fc92 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df1a6:	b104      	cbz	r4, df1aa <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x86>
   df1a8:	6864      	ldr	r4, [r4, #4]
   df1aa:	4629      	mov	r1, r5
   df1ac:	a80a      	add	r0, sp, #40	; 0x28
   df1ae:	f7f8 fc8c 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df1b2:	b105      	cbz	r5, df1b6 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x92>
   df1b4:	686d      	ldr	r5, [r5, #4]
   df1b6:	af05      	add	r7, sp, #20
   df1b8:	4631      	mov	r1, r6
   df1ba:	4638      	mov	r0, r7
   df1bc:	f7f8 fc85 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df1c0:	4b3e      	ldr	r3, [pc, #248]	; (df2bc <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x198>)
   df1c2:	9302      	str	r3, [sp, #8]
   df1c4:	6873      	ldr	r3, [r6, #4]
   df1c6:	9301      	str	r3, [sp, #4]
   df1c8:	9700      	str	r7, [sp, #0]
   df1ca:	462b      	mov	r3, r5
   df1cc:	aa0a      	add	r2, sp, #40	; 0x28
   df1ce:	4621      	mov	r1, r4
   df1d0:	a80f      	add	r0, sp, #60	; 0x3c
   df1d2:	f7ff fd06 	bl	debe2 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIhPFhhhEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>
   df1d6:	e055      	b.n	df284 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x160>
   df1d8:	4621      	mov	r1, r4
   df1da:	a80f      	add	r0, sp, #60	; 0x3c
   df1dc:	f7f8 fc75 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df1e0:	b104      	cbz	r4, df1e4 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xc0>
   df1e2:	6864      	ldr	r4, [r4, #4]
   df1e4:	4629      	mov	r1, r5
   df1e6:	a80a      	add	r0, sp, #40	; 0x28
   df1e8:	f7f8 fc6f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df1ec:	b105      	cbz	r5, df1f0 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xcc>
   df1ee:	686d      	ldr	r5, [r5, #4]
   df1f0:	af05      	add	r7, sp, #20
   df1f2:	4631      	mov	r1, r6
   df1f4:	4638      	mov	r0, r7
   df1f6:	f7f8 fc68 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df1fa:	4b31      	ldr	r3, [pc, #196]	; (df2c0 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x19c>)
   df1fc:	9302      	str	r3, [sp, #8]
   df1fe:	6873      	ldr	r3, [r6, #4]
   df200:	9301      	str	r3, [sp, #4]
   df202:	9700      	str	r7, [sp, #0]
   df204:	462b      	mov	r3, r5
   df206:	aa0a      	add	r2, sp, #40	; 0x28
   df208:	4621      	mov	r1, r4
   df20a:	a80f      	add	r0, sp, #60	; 0x3c
   df20c:	f7ff fd5a 	bl	decc4 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIaPFaaaEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>
   df210:	e038      	b.n	df284 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x160>
   df212:	4621      	mov	r1, r4
   df214:	a80f      	add	r0, sp, #60	; 0x3c
   df216:	f7f8 fc58 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df21a:	b104      	cbz	r4, df21e <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xfa>
   df21c:	6864      	ldr	r4, [r4, #4]
   df21e:	4629      	mov	r1, r5
   df220:	a80a      	add	r0, sp, #40	; 0x28
   df222:	f7f8 fc52 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df226:	b105      	cbz	r5, df22a <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x106>
   df228:	686d      	ldr	r5, [r5, #4]
   df22a:	af05      	add	r7, sp, #20
   df22c:	4631      	mov	r1, r6
   df22e:	4638      	mov	r0, r7
   df230:	f7f8 fc4b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df234:	4b23      	ldr	r3, [pc, #140]	; (df2c4 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x1a0>)
   df236:	9302      	str	r3, [sp, #8]
   df238:	6873      	ldr	r3, [r6, #4]
   df23a:	9301      	str	r3, [sp, #4]
   df23c:	9700      	str	r7, [sp, #0]
   df23e:	462b      	mov	r3, r5
   df240:	aa0a      	add	r2, sp, #40	; 0x28
   df242:	4621      	mov	r1, r4
   df244:	a80f      	add	r0, sp, #60	; 0x3c
   df246:	f7ff fdae 	bl	deda6 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIlPFlllEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>
   df24a:	e01b      	b.n	df284 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x160>
   df24c:	4621      	mov	r1, r4
   df24e:	a80f      	add	r0, sp, #60	; 0x3c
   df250:	f7f8 fc3b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df254:	b104      	cbz	r4, df258 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x134>
   df256:	6864      	ldr	r4, [r4, #4]
   df258:	4629      	mov	r1, r5
   df25a:	a80a      	add	r0, sp, #40	; 0x28
   df25c:	f7f8 fc35 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df260:	b105      	cbz	r5, df264 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x140>
   df262:	686d      	ldr	r5, [r5, #4]
   df264:	af05      	add	r7, sp, #20
   df266:	4631      	mov	r1, r6
   df268:	4638      	mov	r0, r7
   df26a:	f7f8 fc2e 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   df26e:	4b16      	ldr	r3, [pc, #88]	; (df2c8 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x1a4>)
   df270:	9302      	str	r3, [sp, #8]
   df272:	6873      	ldr	r3, [r6, #4]
   df274:	9301      	str	r3, [sp, #4]
   df276:	9700      	str	r7, [sp, #0]
   df278:	462b      	mov	r3, r5
   df27a:	aa0a      	add	r2, sp, #40	; 0x28
   df27c:	4621      	mov	r1, r4
   df27e:	a80f      	add	r0, sp, #60	; 0x3c
   df280:	f7ff fe02 	bl	dee88 <_ZN6tflite13reference_ops29MaximumMinimumBroadcast4DSlowIxPFxxxEEEvRKNS_12RuntimeShapeEPKT_S6_S9_S6_PS7_T0_>
   df284:	4638      	mov	r0, r7
   df286:	f7f8 f970 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   df28a:	a80a      	add	r0, sp, #40	; 0x28
   df28c:	f7f8 f96d 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   df290:	a80f      	add	r0, sp, #60	; 0x3c
   df292:	f7f8 f96a 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  } else {
    context->ReportError(context,
                         "Kernel type not supported by Maximum/Minimum.");
    return kTfLiteError;
  }
  return kTfLiteOk;
   df296:	2000      	movs	r0, #0
   df298:	e00a      	b.n	df2b0 <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x18c>
        break;
      case kTfLiteInt64:
        TFLiteOperation<int64_t, OpType>(context, node, op_context);
        break;
      default:
        context->ReportError(
   df29a:	f8d9 4014 	ldr.w	r4, [r9, #20]
   df29e:	f7f4 ff45 	bl	d412c <TfLiteTypeGetName>
   df2a2:	f818 3007 	ldrb.w	r3, [r8, r7]
   df2a6:	4909      	ldr	r1, [pc, #36]	; (df2cc <_ZN6tflite3ops5micro15maximum_minimum4EvalILNS2_12_GLOBAL__N_110KernelTypeE0ENS4_9MaximumOpEEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x1a8>)
   df2a8:	4602      	mov	r2, r0
   df2aa:	4648      	mov	r0, r9
   df2ac:	47a0      	blx	r4
            context, "Type %s (%d) is not supported by Maximum/Minimum.",
            TfLiteTypeGetName(op_context.output->type),
            op_context.output->type);
        return kTfLiteError;
   df2ae:	2001      	movs	r0, #1
    context->ReportError(context,
                         "Kernel type not supported by Maximum/Minimum.");
    return kTfLiteError;
  }
  return kTfLiteOk;
}
   df2b0:	b015      	add	sp, #84	; 0x54
   df2b2:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
   df2b6:	bf00      	nop
   df2b8:	000dea71 	.word	0x000dea71
   df2bc:	000dea81 	.word	0x000dea81
   df2c0:	000dea89 	.word	0x000dea89
   df2c4:	000dea91 	.word	0x000dea91
   df2c8:	000dea99 	.word	0x000dea99
   df2cc:	000eb9e4 	.word	0x000eb9e4

000df2d0 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode>:
namespace neg {

constexpr int kInputTensor = 0;
constexpr int kOutputTensor = 0;

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   df2d0:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   df2d4:	680b      	ldr	r3, [r1, #0]
   df2d6:	6884      	ldr	r4, [r0, #8]
   df2d8:	685b      	ldr	r3, [r3, #4]
   df2da:	2738      	movs	r7, #56	; 0x38
   df2dc:	437b      	muls	r3, r7
   df2de:	b08a      	sub	sp, #40	; 0x28
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  switch (input->type) {
   df2e0:	5ce2      	ldrb	r2, [r4, r3]
   df2e2:	2a01      	cmp	r2, #1
   df2e4:	eb04 0603 	add.w	r6, r4, r3
   df2e8:	d145      	bne.n	df376 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0xa6>
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   df2ea:	684b      	ldr	r3, [r1, #4]
   df2ec:	685b      	ldr	r3, [r3, #4]
    // TODO(wangtz): handle for kTfLiteInt8
    case kTfLiteFloat32:
      reference_ops::Negate(GetTensorShape(input), GetTensorData<float>(input),
   df2ee:	4631      	mov	r1, r6
   df2f0:	fb07 4403 	mla	r4, r7, r3, r4
   df2f4:	4668      	mov	r0, sp
   df2f6:	f7f8 fbe8 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
                            GetTensorShape(output),
   df2fa:	4621      	mov	r1, r4
   df2fc:	a805      	add	r0, sp, #20
   df2fe:	6876      	ldr	r6, [r6, #4]
   df300:	f7f8 fbe3 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   df304:	b104      	cbz	r4, df308 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0x38>
   df306:	6864      	ldr	r4, [r4, #4]
   df308:	9f00      	ldr	r7, [sp, #0]

// Flat size calculation, checking that dimensions match with one or more other
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   df30a:	9b05      	ldr	r3, [sp, #20]
   df30c:	429f      	cmp	r7, r3
   df30e:	d101      	bne.n	df314 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0x44>
   df310:	2500      	movs	r5, #0
   df312:	e00d      	b.n	df330 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0x60>
   df314:	f006 f8ee 	bl	e54f4 <abort>
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   df318:	4629      	mov	r1, r5
   df31a:	4668      	mov	r0, sp
   df31c:	f7f8 f930 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   df320:	4629      	mov	r1, r5
   df322:	4680      	mov	r8, r0
   df324:	a805      	add	r0, sp, #20
   df326:	f7f8 f92b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   df32a:	4580      	cmp	r8, r0
   df32c:	d1f2      	bne.n	df314 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0x44>
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   df32e:	3501      	adds	r5, #1
   df330:	42af      	cmp	r7, r5
   df332:	dcf1      	bgt.n	df318 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0x48>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   df334:	2f04      	cmp	r7, #4
   df336:	bfcc      	ite	gt
   df338:	9a01      	ldrgt	r2, [sp, #4]
   df33a:	aa01      	addle	r2, sp, #4
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   df33c:	2300      	movs	r3, #0
  }

  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
   df33e:	2101      	movs	r1, #1
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   df340:	429f      	cmp	r7, r3
   df342:	dd04      	ble.n	df34e <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0x7e>
      buffer_size *= dims_data[i];
   df344:	f852 0023 	ldr.w	r0, [r2, r3, lsl #2]
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   df348:	3301      	adds	r3, #1
      buffer_size *= dims_data[i];
   df34a:	4341      	muls	r1, r0
   df34c:	e7f8      	b.n	df340 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0x70>
   df34e:	4633      	mov	r3, r6
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   df350:	2200      	movs	r2, #0
template <typename T>
inline void Negate(const RuntimeShape& input_shape, const T* input_data,
                   const RuntimeShape& output_shape, T* output_data) {
  const int flat_size = MatchingFlatSize(input_shape, output_shape);

  for (int i = 0; i < flat_size; ++i) {
   df352:	428a      	cmp	r2, r1
   df354:	da07      	bge.n	df366 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0x96>
    output_data[i] = -input_data[i];
   df356:	ecf3 7a01 	vldmia	r3!, {s15}
   df35a:	eef1 7a67 	vneg.f32	s15, s15
   df35e:	ece4 7a01 	vstmia	r4!, {s15}
template <typename T>
inline void Negate(const RuntimeShape& input_shape, const T* input_data,
                   const RuntimeShape& output_shape, T* output_data) {
  const int flat_size = MatchingFlatSize(input_shape, output_shape);

  for (int i = 0; i < flat_size; ++i) {
   df362:	3201      	adds	r2, #1
   df364:	e7f5      	b.n	df352 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0x82>
   df366:	a805      	add	r0, sp, #20
   df368:	f7f8 f8ff 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  switch (input->type) {
    // TODO(wangtz): handle for kTfLiteInt8
    case kTfLiteFloat32:
      reference_ops::Negate(GetTensorShape(input), GetTensorData<float>(input),
   df36c:	4668      	mov	r0, sp
   df36e:	f7f8 f8fc 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
    default:
      context->ReportError(
          context, "Neg only currently supports float32, got %d.", input->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
   df372:	2000      	movs	r0, #0
   df374:	e003      	b.n	df37e <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0xae>
                            GetTensorShape(output),
                            GetTensorData<float>(output));
      break;
    default:
      context->ReportError(
          context, "Neg only currently supports float32, got %d.", input->type);
   df376:	6943      	ldr	r3, [r0, #20]
   df378:	4902      	ldr	r1, [pc, #8]	; (df384 <_ZN6tflite3ops5micro3neg4EvalEP13TfLiteContextP10TfLiteNode+0xb4>)
   df37a:	4798      	blx	r3
      return kTfLiteError;
   df37c:	2001      	movs	r0, #1
  }
  return kTfLiteOk;
}
   df37e:	b00a      	add	sp, #40	; 0x28
   df380:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   df384:	000eba16 	.word	0x000eba16

000df388 <_ZN6tflite3ops5micro12Register_NEGEv>:

TfLiteRegistration* Register_NEG() {
  static TfLiteRegistration r = {/*init=*/nullptr, /*free=*/nullptr,
                                 /*prepare=*/nullptr, neg::Eval};
  return &r;
}
   df388:	4800      	ldr	r0, [pc, #0]	; (df38c <_ZN6tflite3ops5micro12Register_NEGEv+0x4>)
   df38a:	4770      	bx	lr
   df38c:	2003c070 	.word	0x2003c070

000df390 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_17PrepareEP13TfLiteContextP10TfLiteNode>:

constexpr int kOutputTensor = 0;

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   df390:	2000      	movs	r0, #0
   df392:	4770      	bx	lr

000df394 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode>:
  }

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   df394:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   df398:	684b      	ldr	r3, [r1, #4]
   df39a:	6885      	ldr	r5, [r0, #8]
  const TfLitePackParams* data =
      reinterpret_cast<TfLitePackParams*>(node->builtin_data);
   df39c:	694a      	ldr	r2, [r1, #20]
  }

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   df39e:	b085      	sub	sp, #20
   df3a0:	9000      	str	r0, [sp, #0]
   df3a2:	6858      	ldr	r0, [r3, #4]
   df3a4:	2338      	movs	r3, #56	; 0x38
   df3a6:	4358      	muls	r0, r3
   df3a8:	182b      	adds	r3, r5, r0
  const TfLitePackParams* data =
      reinterpret_cast<TfLitePackParams*>(node->builtin_data);

  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  switch (output->type) {
   df3aa:	5c28      	ldrb	r0, [r5, r0]
   df3ac:	1e46      	subs	r6, r0, #1
   df3ae:	2e08      	cmp	r6, #8
   df3b0:	f200 821a 	bhi.w	df7e8 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x454>
   df3b4:	e8df f016 	tbh	[pc, r6, lsl #1]
   df3b8:	013f0009 	.word	0x013f0009
   df3bc:	01aa0077 	.word	0x01aa0077
   df3c0:	02180218 	.word	0x02180218
   df3c4:	02180218 	.word	0x02180218
   df3c8:	00da      	.short	0x00da

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
   df3ca:	6808      	ldr	r0, [r1, #0]
}

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
   df3cc:	689f      	ldr	r7, [r3, #8]
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df3ce:	6840      	ldr	r0, [r0, #4]

  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  switch (output->type) {
    case kTfLiteFloat32: {
      return PackImpl<float>(context, node, output, data->values_count,
   df3d0:	f8d2 8000 	ldr.w	r8, [r2]
                             data->axis);
   df3d4:	6852      	ldr	r2, [r2, #4]
}

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
   df3d6:	f8d7 e000 	ldr.w	lr, [r7]
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df3da:	2638      	movs	r6, #56	; 0x38
   df3dc:	fb06 5500 	mla	r5, r6, r0, r5
  const TfLiteIntArray* output_dims = output->dims;

  if (axis < 0) {
   df3e0:	2a00      	cmp	r2, #0
template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df3e2:	68ad      	ldr	r5, [r5, #8]
  const TfLiteIntArray* output_dims = output->dims;

  if (axis < 0) {
    axis += dimensions;
   df3e4:	bfb8      	it	lt
   df3e6:	4472      	addlt	r2, lr
   df3e8:	46bc      	mov	ip, r7
  }

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   df3ea:	2000      	movs	r0, #0

  if (axis < 0) {
    axis += dimensions;
  }

  int outer_size = 1;
   df3ec:	2601      	movs	r6, #1
  for (int i = 0; i < axis; ++i) {
   df3ee:	4282      	cmp	r2, r0
   df3f0:	dd05      	ble.n	df3fe <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x6a>
    outer_size *= output_dims->data[i];
   df3f2:	f85c 9f04 	ldr.w	r9, [ip, #4]!
  if (axis < 0) {
    axis += dimensions;
  }

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   df3f6:	3001      	adds	r0, #1
    outer_size *= output_dims->data[i];
   df3f8:	fb09 f606 	mul.w	r6, r9, r6
   df3fc:	e7f7      	b.n	df3ee <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x5a>
   df3fe:	1c50      	adds	r0, r2, #1
  }
  int copy_size = 1;
   df400:	2201      	movs	r2, #1
  for (int i = axis + 1; i < dimensions; ++i) {
   df402:	4586      	cmp	lr, r0
   df404:	f100 0c01 	add.w	ip, r0, #1
   df408:	dd04      	ble.n	df414 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x80>
    copy_size *= output_dims->data[i];
   df40a:	f857 002c 	ldr.w	r0, [r7, ip, lsl #2]
   df40e:	4342      	muls	r2, r0
   df410:	4660      	mov	r0, ip
   df412:	e7f6      	b.n	df402 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x6e>
  }
  int input_size = 1;
  for (int i = 0; i < input_dims->size; ++i) {
   df414:	f8d5 c000 	ldr.w	ip, [r5]
   df418:	4628      	mov	r0, r5
   df41a:	2700      	movs	r7, #0
   df41c:	2501      	movs	r5, #1
   df41e:	45bc      	cmp	ip, r7
   df420:	dd05      	ble.n	df42e <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x9a>
    input_size *= input_dims->data[i];
   df422:	f850 ef04 	ldr.w	lr, [r0, #4]!
  int copy_size = 1;
  for (int i = axis + 1; i < dimensions; ++i) {
    copy_size *= output_dims->data[i];
  }
  int input_size = 1;
  for (int i = 0; i < input_dims->size; ++i) {
   df426:	3701      	adds	r7, #1
    input_size *= input_dims->data[i];
   df428:	fb0e f505 	mul.w	r5, lr, r5
   df42c:	e7f7      	b.n	df41e <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x8a>
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);
   df42e:	fb02 f006 	mul.w	r0, r2, r6
   df432:	4285      	cmp	r5, r0
   df434:	d001      	beq.n	df43a <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xa6>
   df436:	f006 f85d 	bl	e54f4 <abort>
   df43a:	685b      	ldr	r3, [r3, #4]
   df43c:	9301      	str	r3, [sp, #4]
   df43e:	fb02 f308 	mul.w	r3, r2, r8
   df442:	009b      	lsls	r3, r3, #2
   df444:	2000      	movs	r0, #0
   df446:	ea4f 0982 	mov.w	r9, r2, lsl #2
   df44a:	9302      	str	r3, [sp, #8]

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df44c:	4605      	mov	r5, r0
   df44e:	45a8      	cmp	r8, r5
   df450:	dc01      	bgt.n	df456 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xc2>
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  switch (output->type) {
    case kTfLiteFloat32: {
      return PackImpl<float>(context, node, output, data->values_count,
                             data->axis);
   df452:	2000      	movs	r0, #0
   df454:	e1d1      	b.n	df7fa <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x466>
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
   df456:	680b      	ldr	r3, [r1, #0]
   df458:	eb03 0385 	add.w	r3, r3, r5, lsl #2
   df45c:	2438      	movs	r4, #56	; 0x38
   df45e:	685f      	ldr	r7, [r3, #4]
   df460:	9b00      	ldr	r3, [sp, #0]
   df462:	689b      	ldr	r3, [r3, #8]
   df464:	fb04 3307 	mla	r3, r4, r7, r3
   df468:	b103      	cbz	r3, df46c <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xd8>
   df46a:	685b      	ldr	r3, [r3, #4]
   df46c:	2700      	movs	r7, #0
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df46e:	46bc      	mov	ip, r7
   df470:	4566      	cmp	r6, ip
   df472:	dd15      	ble.n	df4a0 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x10c>
   df474:	9c01      	ldr	r4, [sp, #4]
   df476:	eb00 0e07 	add.w	lr, r0, r7
   df47a:	44a6      	add	lr, r4
   df47c:	469b      	mov	fp, r3
      const T* input_ptr = input_data + copy_size * k;
      int loc = k * values_count * copy_size + i * copy_size;
      T* output_ptr = output_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   df47e:	f04f 0a00 	mov.w	sl, #0
   df482:	4552      	cmp	r2, sl
   df484:	dd06      	ble.n	df494 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x100>
   df486:	ecfb 7a01 	vldmia	fp!, {s15}
   df48a:	f10a 0a01 	add.w	sl, sl, #1
   df48e:	ecee 7a01 	vstmia	lr!, {s15}
   df492:	e7f6      	b.n	df482 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xee>
   df494:	9c02      	ldr	r4, [sp, #8]
  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df496:	f10c 0c01 	add.w	ip, ip, #1
   df49a:	444b      	add	r3, r9
   df49c:	4427      	add	r7, r4
   df49e:	e7e7      	b.n	df470 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xdc>
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df4a0:	3501      	adds	r5, #1
   df4a2:	4448      	add	r0, r9
   df4a4:	e7d3      	b.n	df44e <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xba>

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
   df4a6:	6808      	ldr	r0, [r1, #0]
}

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
   df4a8:	689f      	ldr	r7, [r3, #8]
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df4aa:	6840      	ldr	r0, [r0, #4]
    case kTfLiteFloat32: {
      return PackImpl<float>(context, node, output, data->values_count,
                             data->axis);
    }
    case kTfLiteUInt8: {
      return PackImpl<uint8_t>(context, node, output, data->values_count,
   df4ac:	f8d2 9000 	ldr.w	r9, [r2]
                               data->axis);
   df4b0:	6852      	ldr	r2, [r2, #4]
}

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
   df4b2:	f8d7 e000 	ldr.w	lr, [r7]
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df4b6:	2638      	movs	r6, #56	; 0x38
   df4b8:	fb06 5500 	mla	r5, r6, r0, r5
  const TfLiteIntArray* output_dims = output->dims;

  if (axis < 0) {
   df4bc:	2a00      	cmp	r2, #0
template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df4be:	68ae      	ldr	r6, [r5, #8]
  const TfLiteIntArray* output_dims = output->dims;

  if (axis < 0) {
    axis += dimensions;
   df4c0:	bfb8      	it	lt
   df4c2:	4472      	addlt	r2, lr
   df4c4:	46bc      	mov	ip, r7
  }

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   df4c6:	2000      	movs	r0, #0

  if (axis < 0) {
    axis += dimensions;
  }

  int outer_size = 1;
   df4c8:	2501      	movs	r5, #1
  for (int i = 0; i < axis; ++i) {
   df4ca:	4282      	cmp	r2, r0
   df4cc:	dd05      	ble.n	df4da <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x146>
    outer_size *= output_dims->data[i];
   df4ce:	f85c 8f04 	ldr.w	r8, [ip, #4]!
  if (axis < 0) {
    axis += dimensions;
  }

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   df4d2:	3001      	adds	r0, #1
    outer_size *= output_dims->data[i];
   df4d4:	fb08 f505 	mul.w	r5, r8, r5
   df4d8:	e7f7      	b.n	df4ca <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x136>
   df4da:	1c50      	adds	r0, r2, #1
  }
  int copy_size = 1;
   df4dc:	2201      	movs	r2, #1
  for (int i = axis + 1; i < dimensions; ++i) {
   df4de:	4586      	cmp	lr, r0
   df4e0:	f100 0c01 	add.w	ip, r0, #1
   df4e4:	dd04      	ble.n	df4f0 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x15c>
    copy_size *= output_dims->data[i];
   df4e6:	f857 002c 	ldr.w	r0, [r7, ip, lsl #2]
   df4ea:	4342      	muls	r2, r0
   df4ec:	4660      	mov	r0, ip
   df4ee:	e7f6      	b.n	df4de <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x14a>
  }
  int input_size = 1;
  for (int i = 0; i < input_dims->size; ++i) {
   df4f0:	f8d6 c000 	ldr.w	ip, [r6]
   df4f4:	4630      	mov	r0, r6
   df4f6:	2700      	movs	r7, #0
   df4f8:	2601      	movs	r6, #1
   df4fa:	45bc      	cmp	ip, r7
   df4fc:	dd05      	ble.n	df50a <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x176>
    input_size *= input_dims->data[i];
   df4fe:	f850 ef04 	ldr.w	lr, [r0, #4]!
  int copy_size = 1;
  for (int i = axis + 1; i < dimensions; ++i) {
    copy_size *= output_dims->data[i];
  }
  int input_size = 1;
  for (int i = 0; i < input_dims->size; ++i) {
   df502:	3701      	adds	r7, #1
    input_size *= input_dims->data[i];
   df504:	fb0e f606 	mul.w	r6, lr, r6
   df508:	e7f7      	b.n	df4fa <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x166>
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);
   df50a:	fb02 f005 	mul.w	r0, r2, r5
   df50e:	4286      	cmp	r6, r0
   df510:	d191      	bne.n	df436 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xa2>
   df512:	685e      	ldr	r6, [r3, #4]
   df514:	fb02 f309 	mul.w	r3, r2, r9
   df518:	9301      	str	r3, [sp, #4]

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df51a:	2000      	movs	r0, #0
   df51c:	4581      	cmp	r9, r0
   df51e:	dd98      	ble.n	df452 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xbe>
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
   df520:	680b      	ldr	r3, [r1, #0]
   df522:	eb03 0380 	add.w	r3, r3, r0, lsl #2
   df526:	2438      	movs	r4, #56	; 0x38
   df528:	685f      	ldr	r7, [r3, #4]
   df52a:	9b00      	ldr	r3, [sp, #0]
   df52c:	689b      	ldr	r3, [r3, #8]
   df52e:	fb04 3307 	mla	r3, r4, r7, r3
   df532:	b103      	cbz	r3, df536 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1a2>
   df534:	685b      	ldr	r3, [r3, #4]
   df536:	425f      	negs	r7, r3
   df538:	46b6      	mov	lr, r6
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df53a:	f04f 0c00 	mov.w	ip, #0
   df53e:	4565      	cmp	r5, ip
   df540:	dd11      	ble.n	df566 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1d2>
   df542:	46f2      	mov	sl, lr
   df544:	4698      	mov	r8, r3
      const T* input_ptr = input_data + copy_size * k;
      int loc = k * values_count * copy_size + i * copy_size;
      T* output_ptr = output_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   df546:	eb07 0b08 	add.w	fp, r7, r8
   df54a:	455a      	cmp	r2, fp
   df54c:	dd04      	ble.n	df558 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1c4>
   df54e:	f818 bb01 	ldrb.w	fp, [r8], #1
   df552:	f80a bb01 	strb.w	fp, [sl], #1
   df556:	e7f6      	b.n	df546 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1b2>
   df558:	9c01      	ldr	r4, [sp, #4]
  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df55a:	f10c 0c01 	add.w	ip, ip, #1
   df55e:	4413      	add	r3, r2
   df560:	44a6      	add	lr, r4
   df562:	1abf      	subs	r7, r7, r2
   df564:	e7eb      	b.n	df53e <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1aa>
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df566:	3001      	adds	r0, #1
   df568:	4416      	add	r6, r2
   df56a:	e7d7      	b.n	df51c <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x188>

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
   df56c:	6808      	ldr	r0, [r1, #0]
}

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
   df56e:	689f      	ldr	r7, [r3, #8]
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df570:	6840      	ldr	r0, [r0, #4]
    case kTfLiteUInt8: {
      return PackImpl<uint8_t>(context, node, output, data->values_count,
                               data->axis);
    }
    case kTfLiteInt8: {
      return PackImpl<int8_t>(context, node, output, data->values_count,
   df572:	f8d2 9000 	ldr.w	r9, [r2]
                              data->axis);
   df576:	6852      	ldr	r2, [r2, #4]
}

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
   df578:	f8d7 e000 	ldr.w	lr, [r7]
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df57c:	2638      	movs	r6, #56	; 0x38
   df57e:	fb06 5500 	mla	r5, r6, r0, r5
  const TfLiteIntArray* output_dims = output->dims;

  if (axis < 0) {
   df582:	2a00      	cmp	r2, #0
template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df584:	68ae      	ldr	r6, [r5, #8]
  const TfLiteIntArray* output_dims = output->dims;

  if (axis < 0) {
    axis += dimensions;
   df586:	bfb8      	it	lt
   df588:	4472      	addlt	r2, lr
   df58a:	46bc      	mov	ip, r7
  }

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   df58c:	2000      	movs	r0, #0

  if (axis < 0) {
    axis += dimensions;
  }

  int outer_size = 1;
   df58e:	2501      	movs	r5, #1
  for (int i = 0; i < axis; ++i) {
   df590:	4282      	cmp	r2, r0
   df592:	dd05      	ble.n	df5a0 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x20c>
    outer_size *= output_dims->data[i];
   df594:	f85c 8f04 	ldr.w	r8, [ip, #4]!
  if (axis < 0) {
    axis += dimensions;
  }

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   df598:	3001      	adds	r0, #1
    outer_size *= output_dims->data[i];
   df59a:	fb08 f505 	mul.w	r5, r8, r5
   df59e:	e7f7      	b.n	df590 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1fc>
   df5a0:	1c50      	adds	r0, r2, #1
  }
  int copy_size = 1;
   df5a2:	2201      	movs	r2, #1
  for (int i = axis + 1; i < dimensions; ++i) {
   df5a4:	4586      	cmp	lr, r0
   df5a6:	f100 0c01 	add.w	ip, r0, #1
   df5aa:	dd04      	ble.n	df5b6 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x222>
    copy_size *= output_dims->data[i];
   df5ac:	f857 002c 	ldr.w	r0, [r7, ip, lsl #2]
   df5b0:	4342      	muls	r2, r0
   df5b2:	4660      	mov	r0, ip
   df5b4:	e7f6      	b.n	df5a4 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x210>
  }
  int input_size = 1;
  for (int i = 0; i < input_dims->size; ++i) {
   df5b6:	f8d6 c000 	ldr.w	ip, [r6]
   df5ba:	4630      	mov	r0, r6
   df5bc:	2700      	movs	r7, #0
   df5be:	2601      	movs	r6, #1
   df5c0:	45bc      	cmp	ip, r7
   df5c2:	dd05      	ble.n	df5d0 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x23c>
    input_size *= input_dims->data[i];
   df5c4:	f850 ef04 	ldr.w	lr, [r0, #4]!
  int copy_size = 1;
  for (int i = axis + 1; i < dimensions; ++i) {
    copy_size *= output_dims->data[i];
  }
  int input_size = 1;
  for (int i = 0; i < input_dims->size; ++i) {
   df5c8:	3701      	adds	r7, #1
    input_size *= input_dims->data[i];
   df5ca:	fb0e f606 	mul.w	r6, lr, r6
   df5ce:	e7f7      	b.n	df5c0 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x22c>
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);
   df5d0:	fb02 f005 	mul.w	r0, r2, r5
   df5d4:	4286      	cmp	r6, r0
   df5d6:	f47f af2e 	bne.w	df436 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xa2>
   df5da:	685e      	ldr	r6, [r3, #4]
   df5dc:	fb02 f309 	mul.w	r3, r2, r9
   df5e0:	9301      	str	r3, [sp, #4]

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df5e2:	2000      	movs	r0, #0
   df5e4:	4581      	cmp	r9, r0
   df5e6:	f77f af34 	ble.w	df452 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xbe>
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
   df5ea:	680b      	ldr	r3, [r1, #0]
   df5ec:	eb03 0380 	add.w	r3, r3, r0, lsl #2
   df5f0:	2438      	movs	r4, #56	; 0x38
   df5f2:	685f      	ldr	r7, [r3, #4]
   df5f4:	9b00      	ldr	r3, [sp, #0]
   df5f6:	689b      	ldr	r3, [r3, #8]
   df5f8:	fb04 3307 	mla	r3, r4, r7, r3
   df5fc:	b103      	cbz	r3, df600 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x26c>
   df5fe:	685b      	ldr	r3, [r3, #4]
   df600:	425f      	negs	r7, r3
   df602:	46b6      	mov	lr, r6
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df604:	f04f 0c00 	mov.w	ip, #0
   df608:	4565      	cmp	r5, ip
   df60a:	dd11      	ble.n	df630 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x29c>
   df60c:	46f2      	mov	sl, lr
   df60e:	4698      	mov	r8, r3
      const T* input_ptr = input_data + copy_size * k;
      int loc = k * values_count * copy_size + i * copy_size;
      T* output_ptr = output_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   df610:	eb08 0b07 	add.w	fp, r8, r7
   df614:	455a      	cmp	r2, fp
   df616:	dd04      	ble.n	df622 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x28e>
   df618:	f918 bb01 	ldrsb.w	fp, [r8], #1
   df61c:	f80a bb01 	strb.w	fp, [sl], #1
   df620:	e7f6      	b.n	df610 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x27c>
   df622:	9c01      	ldr	r4, [sp, #4]
  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df624:	f10c 0c01 	add.w	ip, ip, #1
   df628:	4413      	add	r3, r2
   df62a:	44a6      	add	lr, r4
   df62c:	1abf      	subs	r7, r7, r2
   df62e:	e7eb      	b.n	df608 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x274>
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df630:	3001      	adds	r0, #1
   df632:	4416      	add	r6, r2
   df634:	e7d6      	b.n	df5e4 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x250>

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
   df636:	6808      	ldr	r0, [r1, #0]
}

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
   df638:	689e      	ldr	r6, [r3, #8]
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df63a:	6840      	ldr	r0, [r0, #4]
    case kTfLiteInt8: {
      return PackImpl<int8_t>(context, node, output, data->values_count,
                              data->axis);
    }
    case kTfLiteInt32: {
      return PackImpl<int32_t>(context, node, output, data->values_count,
   df63c:	f8d2 8000 	ldr.w	r8, [r2]
                               data->axis);
   df640:	6852      	ldr	r2, [r2, #4]
}

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
   df642:	f8d6 e000 	ldr.w	lr, [r6]
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df646:	2738      	movs	r7, #56	; 0x38
   df648:	fb07 5500 	mla	r5, r7, r0, r5
  const TfLiteIntArray* output_dims = output->dims;

  if (axis < 0) {
   df64c:	2a00      	cmp	r2, #0
template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df64e:	68ad      	ldr	r5, [r5, #8]
  const TfLiteIntArray* output_dims = output->dims;

  if (axis < 0) {
    axis += dimensions;
   df650:	bfb8      	it	lt
   df652:	4472      	addlt	r2, lr
   df654:	46b4      	mov	ip, r6
  }

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   df656:	2000      	movs	r0, #0

  if (axis < 0) {
    axis += dimensions;
  }

  int outer_size = 1;
   df658:	2701      	movs	r7, #1
  for (int i = 0; i < axis; ++i) {
   df65a:	4282      	cmp	r2, r0
   df65c:	dd05      	ble.n	df66a <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x2d6>
    outer_size *= output_dims->data[i];
   df65e:	f85c 9f04 	ldr.w	r9, [ip, #4]!
  if (axis < 0) {
    axis += dimensions;
  }

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   df662:	3001      	adds	r0, #1
    outer_size *= output_dims->data[i];
   df664:	fb09 f707 	mul.w	r7, r9, r7
   df668:	e7f7      	b.n	df65a <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x2c6>
   df66a:	1c50      	adds	r0, r2, #1
  }
  int copy_size = 1;
   df66c:	2201      	movs	r2, #1
  for (int i = axis + 1; i < dimensions; ++i) {
   df66e:	4586      	cmp	lr, r0
   df670:	f100 0c01 	add.w	ip, r0, #1
   df674:	dd04      	ble.n	df680 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x2ec>
    copy_size *= output_dims->data[i];
   df676:	f856 002c 	ldr.w	r0, [r6, ip, lsl #2]
   df67a:	4342      	muls	r2, r0
   df67c:	4660      	mov	r0, ip
   df67e:	e7f6      	b.n	df66e <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x2da>
  }
  int input_size = 1;
  for (int i = 0; i < input_dims->size; ++i) {
   df680:	f8d5 c000 	ldr.w	ip, [r5]
   df684:	4628      	mov	r0, r5
   df686:	2600      	movs	r6, #0
   df688:	2501      	movs	r5, #1
   df68a:	45b4      	cmp	ip, r6
   df68c:	dd05      	ble.n	df69a <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x306>
    input_size *= input_dims->data[i];
   df68e:	f850 ef04 	ldr.w	lr, [r0, #4]!
  int copy_size = 1;
  for (int i = axis + 1; i < dimensions; ++i) {
    copy_size *= output_dims->data[i];
  }
  int input_size = 1;
  for (int i = 0; i < input_dims->size; ++i) {
   df692:	3601      	adds	r6, #1
    input_size *= input_dims->data[i];
   df694:	fb0e f505 	mul.w	r5, lr, r5
   df698:	e7f7      	b.n	df68a <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x2f6>
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);
   df69a:	fb02 f007 	mul.w	r0, r2, r7
   df69e:	4285      	cmp	r5, r0
   df6a0:	f47f aec9 	bne.w	df436 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xa2>
   df6a4:	685b      	ldr	r3, [r3, #4]
   df6a6:	9301      	str	r3, [sp, #4]
   df6a8:	fb02 f308 	mul.w	r3, r2, r8
   df6ac:	009b      	lsls	r3, r3, #2
   df6ae:	2500      	movs	r5, #0
   df6b0:	ea4f 0c82 	mov.w	ip, r2, lsl #2
   df6b4:	9302      	str	r3, [sp, #8]

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df6b6:	462e      	mov	r6, r5
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
   df6b8:	f04f 0938 	mov.w	r9, #56	; 0x38
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df6bc:	45b0      	cmp	r8, r6
   df6be:	f77f aec8 	ble.w	df452 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xbe>
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
   df6c2:	680b      	ldr	r3, [r1, #0]
   df6c4:	eb03 0386 	add.w	r3, r3, r6, lsl #2
   df6c8:	6858      	ldr	r0, [r3, #4]
   df6ca:	9b00      	ldr	r3, [sp, #0]
   df6cc:	689b      	ldr	r3, [r3, #8]
   df6ce:	fb09 3300 	mla	r3, r9, r0, r3
   df6d2:	b103      	cbz	r3, df6d6 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x342>
   df6d4:	685b      	ldr	r3, [r3, #4]
   df6d6:	f04f 0e00 	mov.w	lr, #0
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df6da:	46f2      	mov	sl, lr
   df6dc:	4557      	cmp	r7, sl
   df6de:	dd12      	ble.n	df706 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x372>
      const T* input_ptr = input_data + copy_size * k;
      int loc = k * values_count * copy_size + i * copy_size;
      T* output_ptr = output_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   df6e0:	9c01      	ldr	r4, [sp, #4]
   df6e2:	eb05 0b0e 	add.w	fp, r5, lr
  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df6e6:	2000      	movs	r0, #0
      const T* input_ptr = input_data + copy_size * k;
      int loc = k * values_count * copy_size + i * copy_size;
      T* output_ptr = output_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   df6e8:	44a3      	add	fp, r4
   df6ea:	4282      	cmp	r2, r0
   df6ec:	dd05      	ble.n	df6fa <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x366>
   df6ee:	f853 4020 	ldr.w	r4, [r3, r0, lsl #2]
   df6f2:	f84b 4020 	str.w	r4, [fp, r0, lsl #2]
   df6f6:	3001      	adds	r0, #1
   df6f8:	e7f7      	b.n	df6ea <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x356>
   df6fa:	9802      	ldr	r0, [sp, #8]
  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df6fc:	f10a 0a01 	add.w	sl, sl, #1
   df700:	4463      	add	r3, ip
   df702:	4486      	add	lr, r0
   df704:	e7ea      	b.n	df6dc <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x348>
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df706:	3601      	adds	r6, #1
   df708:	4465      	add	r5, ip
   df70a:	e7d7      	b.n	df6bc <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x328>
    case kTfLiteInt32: {
      return PackImpl<int32_t>(context, node, output, data->values_count,
                               data->axis);
    }
    case kTfLiteInt64: {
      return PackImpl<int64_t>(context, node, output, data->values_count,
   df70c:	6810      	ldr	r0, [r2, #0]
   df70e:	9001      	str	r0, [sp, #4]

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
   df710:	6808      	ldr	r0, [r1, #0]
}

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
   df712:	689e      	ldr	r6, [r3, #8]
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df714:	6840      	ldr	r0, [r0, #4]
      return PackImpl<int32_t>(context, node, output, data->values_count,
                               data->axis);
    }
    case kTfLiteInt64: {
      return PackImpl<int64_t>(context, node, output, data->values_count,
                               data->axis);
   df716:	6852      	ldr	r2, [r2, #4]
}

template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
   df718:	6837      	ldr	r7, [r6, #0]
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df71a:	f04f 0e38 	mov.w	lr, #56	; 0x38
   df71e:	fb0e 5500 	mla	r5, lr, r0, r5
  const TfLiteIntArray* output_dims = output->dims;

  if (axis < 0) {
   df722:	2a00      	cmp	r2, #0
template <typename T>
TfLiteStatus PackImpl(TfLiteContext* context, TfLiteNode* node,
                      TfLiteTensor* output, int values_count, int axis) {
  const int dimensions = output->dims->size;
  const TfLiteTensor* input0 = &context->tensors[node->inputs->data[0]];
  const TfLiteIntArray* input_dims = input0->dims;
   df724:	68ad      	ldr	r5, [r5, #8]
  const TfLiteIntArray* output_dims = output->dims;

  if (axis < 0) {
    axis += dimensions;
   df726:	bfb8      	it	lt
   df728:	19d2      	addlt	r2, r2, r7
   df72a:	46b4      	mov	ip, r6
  }

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   df72c:	2000      	movs	r0, #0

  if (axis < 0) {
    axis += dimensions;
  }

  int outer_size = 1;
   df72e:	f04f 0e01 	mov.w	lr, #1
  for (int i = 0; i < axis; ++i) {
   df732:	4282      	cmp	r2, r0
   df734:	dd05      	ble.n	df742 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x3ae>
    outer_size *= output_dims->data[i];
   df736:	f85c 8f04 	ldr.w	r8, [ip, #4]!
  if (axis < 0) {
    axis += dimensions;
  }

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   df73a:	3001      	adds	r0, #1
    outer_size *= output_dims->data[i];
   df73c:	fb08 fe0e 	mul.w	lr, r8, lr
   df740:	e7f7      	b.n	df732 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x39e>
   df742:	1c50      	adds	r0, r2, #1
  }
  int copy_size = 1;
   df744:	2201      	movs	r2, #1
  for (int i = axis + 1; i < dimensions; ++i) {
   df746:	4287      	cmp	r7, r0
   df748:	f100 0c01 	add.w	ip, r0, #1
   df74c:	dd04      	ble.n	df758 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x3c4>
    copy_size *= output_dims->data[i];
   df74e:	f856 002c 	ldr.w	r0, [r6, ip, lsl #2]
   df752:	4342      	muls	r2, r0
   df754:	4660      	mov	r0, ip
   df756:	e7f6      	b.n	df746 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x3b2>
  }
  int input_size = 1;
  for (int i = 0; i < input_dims->size; ++i) {
   df758:	f8d5 c000 	ldr.w	ip, [r5]
   df75c:	4628      	mov	r0, r5
   df75e:	2600      	movs	r6, #0
   df760:	2501      	movs	r5, #1
   df762:	45b4      	cmp	ip, r6
   df764:	dd04      	ble.n	df770 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x3dc>
    input_size *= input_dims->data[i];
   df766:	f850 7f04 	ldr.w	r7, [r0, #4]!
  int copy_size = 1;
  for (int i = axis + 1; i < dimensions; ++i) {
    copy_size *= output_dims->data[i];
  }
  int input_size = 1;
  for (int i = 0; i < input_dims->size; ++i) {
   df76a:	3601      	adds	r6, #1
    input_size *= input_dims->data[i];
   df76c:	437d      	muls	r5, r7
   df76e:	e7f8      	b.n	df762 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x3ce>
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);
   df770:	fb02 f00e 	mul.w	r0, r2, lr
   df774:	4285      	cmp	r5, r0
   df776:	f47f ae5e 	bne.w	df436 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xa2>
   df77a:	685b      	ldr	r3, [r3, #4]
   df77c:	9302      	str	r3, [sp, #8]
   df77e:	9b01      	ldr	r3, [sp, #4]
   df780:	4353      	muls	r3, r2
   df782:	00db      	lsls	r3, r3, #3
   df784:	2000      	movs	r0, #0
   df786:	00d7      	lsls	r7, r2, #3
   df788:	9303      	str	r3, [sp, #12]

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df78a:	4605      	mov	r5, r0
   df78c:	9b01      	ldr	r3, [sp, #4]
   df78e:	42ab      	cmp	r3, r5
   df790:	f77f ae5f 	ble.w	df452 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xbe>
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
   df794:	680b      	ldr	r3, [r1, #0]
   df796:	eb03 0385 	add.w	r3, r3, r5, lsl #2
   df79a:	2438      	movs	r4, #56	; 0x38
   df79c:	685e      	ldr	r6, [r3, #4]
   df79e:	9b00      	ldr	r3, [sp, #0]
   df7a0:	689b      	ldr	r3, [r3, #8]
   df7a2:	fb04 3306 	mla	r3, r4, r6, r3
   df7a6:	b103      	cbz	r3, df7aa <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x416>
   df7a8:	685b      	ldr	r3, [r3, #4]
   df7aa:	f04f 0c00 	mov.w	ip, #0
   df7ae:	461e      	mov	r6, r3
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df7b0:	46e1      	mov	r9, ip
   df7b2:	45ce      	cmp	lr, r9
   df7b4:	dd15      	ble.n	df7e2 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x44e>
   df7b6:	9c02      	ldr	r4, [sp, #8]
   df7b8:	eb00 080c 	add.w	r8, r0, ip
   df7bc:	44a0      	add	r8, r4
   df7be:	46b3      	mov	fp, r6
      const T* input_ptr = input_data + copy_size * k;
      int loc = k * values_count * copy_size + i * copy_size;
      T* output_ptr = output_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   df7c0:	f04f 0a00 	mov.w	sl, #0
   df7c4:	4552      	cmp	r2, sl
   df7c6:	dd06      	ble.n	df7d6 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x442>
   df7c8:	e8fb 3402 	ldrd	r3, r4, [fp], #8
   df7cc:	f10a 0a01 	add.w	sl, sl, #1
   df7d0:	e8e8 3402 	strd	r3, r4, [r8], #8
   df7d4:	e7f6      	b.n	df7c4 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x430>
   df7d6:	9c03      	ldr	r4, [sp, #12]
  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->inputs->data[i]];
    const T* input_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   df7d8:	f109 0901 	add.w	r9, r9, #1
   df7dc:	443e      	add	r6, r7
   df7de:	44a4      	add	ip, r4
   df7e0:	e7e7      	b.n	df7b2 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x41e>
  }
  TFLITE_DCHECK_EQ(input_size, copy_size * outer_size);

  T* output_data = GetTensorData<T>(output);

  for (int i = 0; i < values_count; ++i) {
   df7e2:	3501      	adds	r5, #1
   df7e4:	4438      	add	r0, r7
   df7e6:	e7d1      	b.n	df78c <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x3f8>
    case kTfLiteInt64: {
      return PackImpl<int64_t>(context, node, output, data->values_count,
                               data->axis);
    }
    default: {
      context->ReportError(context, "Type '%s' is not supported by pack.",
   df7e8:	9b00      	ldr	r3, [sp, #0]
   df7ea:	695d      	ldr	r5, [r3, #20]
   df7ec:	f7f4 fc9e 	bl	d412c <TfLiteTypeGetName>
                           TfLiteTypeGetName(output->type));
   df7f0:	4903      	ldr	r1, [pc, #12]	; (df800 <_ZN6tflite3ops5micro4pack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x46c>)
   df7f2:	4602      	mov	r2, r0
   df7f4:	9800      	ldr	r0, [sp, #0]
   df7f6:	47a8      	blx	r5
      return kTfLiteError;
   df7f8:	2001      	movs	r0, #1
    }
  }

  return kTfLiteOk;
}
   df7fa:	b005      	add	sp, #20
   df7fc:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   df800:	000eba43 	.word	0x000eba43

000df804 <_ZN6tflite3ops5micro13Register_PACKEv>:
}  // namespace pack

TfLiteRegistration* Register_PACK() {
  static TfLiteRegistration r = {nullptr, nullptr, pack::Prepare, pack::Eval};
  return &r;
}
   df804:	4800      	ldr	r0, [pc, #0]	; (df808 <_ZN6tflite3ops5micro13Register_PACKEv+0x4>)
   df806:	4770      	bx	lr
   df808:	2003c090 	.word	0x2003c090

000df80c <_ZN6tflite3ops5micro7pooling4InitEP13TfLiteContextPKcj>:

}  // namespace

void* Init(TfLiteContext* context, const char* buffer, size_t length) {
  return nullptr;
}
   df80c:	2000      	movs	r0, #0
   df80e:	4770      	bx	lr

000df810 <_ZN6tflite3ops5micro7pooling4FreeEP13TfLiteContextPv>:

void Free(TfLiteContext* context, void* buffer) {}
   df810:	4770      	bx	lr

000df812 <_ZN6tflite3ops5micro7pooling7PrepareEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   df812:	2000      	movs	r0, #0
   df814:	4770      	bx	lr
	...

000df818 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf>:
namespace reference_ops {

inline void AveragePool(const PoolParams& params,
                        const RuntimeShape& input_shape,
                        const float* input_data,
                        const RuntimeShape& output_shape, float* output_data) {
   df818:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   df81c:	ed2d 8b04 	vpush	{d8-d9}
   df820:	461d      	mov	r5, r3
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   df822:	680b      	ldr	r3, [r1, #0]
namespace reference_ops {

inline void AveragePool(const PoolParams& params,
                        const RuntimeShape& input_shape,
                        const float* input_data,
                        const RuntimeShape& output_shape, float* output_data) {
   df824:	b095      	sub	sp, #84	; 0x54
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   df826:	2b04      	cmp	r3, #4
namespace reference_ops {

inline void AveragePool(const PoolParams& params,
                        const RuntimeShape& input_shape,
                        const float* input_data,
                        const RuntimeShape& output_shape, float* output_data) {
   df828:	4604      	mov	r4, r0
   df82a:	468a      	mov	sl, r1
   df82c:	9212      	str	r2, [sp, #72]	; 0x48
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   df82e:	d001      	beq.n	df834 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x1c>
   df830:	f005 fe60 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   df834:	682b      	ldr	r3, [r5, #0]
   df836:	2b04      	cmp	r3, #4
   df838:	d1fa      	bne.n	df830 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x18>
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   df83a:	2300      	movs	r3, #0
   df83c:	4619      	mov	r1, r3
   df83e:	462a      	mov	r2, r5
   df840:	4650      	mov	r0, sl
   df842:	f7fd fa4e 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   df846:	2303      	movs	r3, #3
   df848:	4619      	mov	r1, r3
   df84a:	462a      	mov	r2, r5
                        const RuntimeShape& input_shape,
                        const float* input_data,
                        const RuntimeShape& output_shape, float* output_data) {
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   df84c:	9008      	str	r0, [sp, #32]
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   df84e:	4650      	mov	r0, sl
   df850:	f7fd fa47 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_height = input_shape.Dims(1);
   df854:	2101      	movs	r1, #1
                        const float* input_data,
                        const RuntimeShape& output_shape, float* output_data) {
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   df856:	9009      	str	r0, [sp, #36]	; 0x24
  const int input_height = input_shape.Dims(1);
   df858:	4650      	mov	r0, sl
   df85a:	f7f7 fe91 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   df85e:	2102      	movs	r1, #2
                        const RuntimeShape& output_shape, float* output_data) {
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
   df860:	900a      	str	r0, [sp, #40]	; 0x28
  const int input_width = input_shape.Dims(2);
   df862:	4650      	mov	r0, sl
   df864:	f7f7 fe8c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   df868:	2101      	movs	r1, #1
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   df86a:	900b      	str	r0, [sp, #44]	; 0x2c
  const int output_height = output_shape.Dims(1);
   df86c:	4628      	mov	r0, r5
   df86e:	f7f7 fe87 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   df872:	2102      	movs	r1, #2
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   df874:	900c      	str	r0, [sp, #48]	; 0x30
  const int output_width = output_shape.Dims(2);
   df876:	4628      	mov	r0, r5
   df878:	f7f7 fe82 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int stride_height = params.stride_height;
   df87c:	68e3      	ldr	r3, [r4, #12]
   df87e:	930f      	str	r3, [sp, #60]	; 0x3c
  const int stride_width = params.stride_width;
   df880:	6923      	ldr	r3, [r4, #16]
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   df882:	900e      	str	r0, [sp, #56]	; 0x38
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
   df884:	9310      	str	r3, [sp, #64]	; 0x40
  for (int batch = 0; batch < batches; ++batch) {
   df886:	f04f 0b00 	mov.w	fp, #0
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              total +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
              filter_count++;
   df88a:	eef7 9a00 	vmov.f32	s19, #112	; 0x3f800000  1.0
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
   df88e:	9b08      	ldr	r3, [sp, #32]
   df890:	459b      	cmp	fp, r3
   df892:	f280 8092 	bge.w	df9ba <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x1a2>
   df896:	2300      	movs	r3, #0
   df898:	9304      	str	r3, [sp, #16]
   df89a:	9302      	str	r3, [sp, #8]
    for (int out_y = 0; out_y < output_height; ++out_y) {
   df89c:	9b02      	ldr	r3, [sp, #8]
   df89e:	9a0c      	ldr	r2, [sp, #48]	; 0x30
   df8a0:	4293      	cmp	r3, r2
   df8a2:	f280 8087 	bge.w	df9b4 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x19c>
   df8a6:	2300      	movs	r3, #0
   df8a8:	9305      	str	r3, [sp, #20]
   df8aa:	9303      	str	r3, [sp, #12]
      for (int out_x = 0; out_x < output_width; ++out_x) {
   df8ac:	9b03      	ldr	r3, [sp, #12]
   df8ae:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   df8b0:	4293      	cmp	r3, r2
   df8b2:	da77      	bge.n	df9a4 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x18c>
   df8b4:	f04f 0900 	mov.w	r9, #0
        for (int channel = 0; channel < depth; ++channel) {
   df8b8:	9b09      	ldr	r3, [sp, #36]	; 0x24
   df8ba:	4599      	cmp	r9, r3
   df8bc:	da6a      	bge.n	df994 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x17c>
          const int in_x_origin =
              (out_x * stride_width) - params.padding_values.width;
   df8be:	f9b4 7002 	ldrsh.w	r7, [r4, #2]
   df8c2:	9b05      	ldr	r3, [sp, #20]
          const int in_y_origin =
              (out_y * stride_height) - params.padding_values.height;
   df8c4:	f9b4 8004 	ldrsh.w	r8, [r4, #4]
              std::min(params.filter_width, input_width - in_x_origin);
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          float total = 0.f;
          float filter_count = 0;
   df8c8:	ed9f 8a3e 	vldr	s16, [pc, #248]	; df9c4 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x1ac>
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int channel = 0; channel < depth; ++channel) {
          const int in_x_origin =
              (out_x * stride_width) - params.padding_values.width;
   df8cc:	1bdb      	subs	r3, r3, r7
   df8ce:	9306      	str	r3, [sp, #24]
          const int in_y_origin =
              (out_y * stride_height) - params.padding_values.height;
   df8d0:	9b04      	ldr	r3, [sp, #16]
   df8d2:	9a06      	ldr	r2, [sp, #24]
   df8d4:	ebc8 0803 	rsb	r8, r8, r3
   df8d8:	9b06      	ldr	r3, [sp, #24]
   df8da:	425b      	negs	r3, r3
   df8dc:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
   df8e0:	9307      	str	r3, [sp, #28]
   df8e2:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   df8e4:	1a9a      	subs	r2, r3, r2
   df8e6:	69a3      	ldr	r3, [r4, #24]
   df8e8:	429a      	cmp	r2, r3
   df8ea:	bfa8      	it	ge
   df8ec:	461a      	movge	r2, r3
   df8ee:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   df8f0:	920d      	str	r2, [sp, #52]	; 0x34
   df8f2:	6962      	ldr	r2, [r4, #20]
   df8f4:	ebc8 0303 	rsb	r3, r8, r3
   df8f8:	4293      	cmp	r3, r2
   df8fa:	f1c8 0600 	rsb	r6, r8, #0
   df8fe:	bfa8      	it	ge
   df900:	4613      	movge	r3, r2
   df902:	ea26 76e6 	bic.w	r6, r6, r6, asr #31
   df906:	9311      	str	r3, [sp, #68]	; 0x44
          const int filter_x_end =
              std::min(params.filter_width, input_width - in_x_origin);
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          float total = 0.f;
   df908:	eef0 8a48 	vmov.f32	s17, s16
          float filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
   df90c:	9b11      	ldr	r3, [sp, #68]	; 0x44
   df90e:	429e      	cmp	r6, r3
   df910:	da1c      	bge.n	df94c <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x134>
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              total +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
   df912:	eb08 0306 	add.w	r3, r8, r6
   df916:	9f07      	ldr	r7, [sp, #28]
   df918:	9313      	str	r3, [sp, #76]	; 0x4c
              std::min(params.filter_height, input_height - in_y_origin);
          float total = 0.f;
          float filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   df91a:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   df91c:	429f      	cmp	r7, r3
   df91e:	da13      	bge.n	df948 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x130>
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              total +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
   df920:	9b06      	ldr	r3, [sp, #24]
   df922:	f8cd 9000 	str.w	r9, [sp]
   df926:	18fb      	adds	r3, r7, r3
   df928:	9a13      	ldr	r2, [sp, #76]	; 0x4c
   df92a:	4659      	mov	r1, fp
   df92c:	4650      	mov	r0, sl
   df92e:	f7f7 fe8c 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   df932:	9b12      	ldr	r3, [sp, #72]	; 0x48
   df934:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   df938:	edd0 7a00 	vldr	s15, [r0]
              filter_count++;
   df93c:	ee38 8a29 	vadd.f32	s16, s16, s19
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              total +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
   df940:	ee78 8aa7 	vadd.f32	s17, s17, s15
              std::min(params.filter_height, input_height - in_y_origin);
          float total = 0.f;
          float filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   df944:	3701      	adds	r7, #1
   df946:	e7e8      	b.n	df91a <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x102>
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          float total = 0.f;
          float filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
   df948:	3601      	adds	r6, #1
   df94a:	e7df      	b.n	df90c <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0xf4>
              total +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
              filter_count++;
            }
          }
          const float average = total / filter_count;
   df94c:	ee88 9a88 	vdiv.f32	s18, s17, s16
          output_data[Offset(output_shape, batch, out_y, out_x, channel)] =
   df950:	f8cd 9000 	str.w	r9, [sp]
   df954:	9b03      	ldr	r3, [sp, #12]
   df956:	9a02      	ldr	r2, [sp, #8]
   df958:	4659      	mov	r1, fp
   df95a:	4628      	mov	r0, r5
   df95c:	f7f7 fe75 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   df960:	9b22      	ldr	r3, [sp, #136]	; 0x88
   df962:	eb03 0080 	add.w	r0, r3, r0, lsl #2
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int channel = 0; channel < depth; ++channel) {
   df966:	f109 0901 	add.w	r9, r9, #1
              filter_count++;
            }
          }
          const float average = total / filter_count;
          output_data[Offset(output_shape, batch, out_y, out_x, channel)] =
              ActivationFunctionWithMinMax(average, params.float_activation_min,
   df96a:	edd4 7a09 	vldr	s15, [r4, #36]	; 0x24
                                           params.float_activation_max);
   df96e:	ed94 7a0a 	vldr	s14, [r4, #40]	; 0x28
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
	return __b;
      return __a;
   df972:	eeb4 9ae7 	vcmpe.f32	s18, s15
   df976:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   df97a:	bf58      	it	pl
   df97c:	eef0 7a49 	vmovpl.f32	s15, s18
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
   df980:	eeb4 7a67 	vcmp.f32	s14, s15
   df984:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   df988:	bf48      	it	mi
   df98a:	eef0 7a47 	vmovmi.f32	s15, s14
   df98e:	edc0 7a00 	vstr	s15, [r0]
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int channel = 0; channel < depth; ++channel) {
   df992:	e791      	b.n	df8b8 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0xa0>
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   df994:	9b03      	ldr	r3, [sp, #12]
   df996:	9a10      	ldr	r2, [sp, #64]	; 0x40
   df998:	3301      	adds	r3, #1
   df99a:	9303      	str	r3, [sp, #12]
   df99c:	9b05      	ldr	r3, [sp, #20]
   df99e:	4413      	add	r3, r2
   df9a0:	9305      	str	r3, [sp, #20]
   df9a2:	e783      	b.n	df8ac <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x94>
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   df9a4:	9b02      	ldr	r3, [sp, #8]
   df9a6:	9a0f      	ldr	r2, [sp, #60]	; 0x3c
   df9a8:	3301      	adds	r3, #1
   df9aa:	9302      	str	r3, [sp, #8]
   df9ac:	9b04      	ldr	r3, [sp, #16]
   df9ae:	4413      	add	r3, r2
   df9b0:	9304      	str	r3, [sp, #16]
   df9b2:	e773      	b.n	df89c <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x84>
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
   df9b4:	f10b 0b01 	add.w	fp, fp, #1
   df9b8:	e769      	b.n	df88e <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x76>
                                           params.float_activation_max);
        }
      }
    }
  }
}
   df9ba:	b015      	add	sp, #84	; 0x54
   df9bc:	ecbd 8b04 	vpop	{d8-d9}
   df9c0:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   df9c4:	00000000 	.word	0x00000000

000df9c8 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph>:

inline void AveragePool(const PoolParams& params,
                        const RuntimeShape& input_shape,
                        const uint8* input_data,
                        const RuntimeShape& output_shape, uint8* output_data) {
   df9c8:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   df9cc:	b097      	sub	sp, #92	; 0x5c
   df9ce:	461f      	mov	r7, r3
   df9d0:	9214      	str	r2, [sp, #80]	; 0x50
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
   df9d2:	6a03      	ldr	r3, [r0, #32]
   df9d4:	69c2      	ldr	r2, [r0, #28]
   df9d6:	429a      	cmp	r2, r3
}

inline void AveragePool(const PoolParams& params,
                        const RuntimeShape& input_shape,
                        const uint8* input_data,
                        const RuntimeShape& output_shape, uint8* output_data) {
   df9d8:	4604      	mov	r4, r0
   df9da:	460e      	mov	r6, r1
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
   df9dc:	dd01      	ble.n	df9e2 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x1a>

inline void AveragePool(const PoolParams& params,
                        const RuntimeShape& input_shape,
                        const uint8* input_data,
                        const RuntimeShape& output_shape, uint8* output_data) {
  TFLITE_DCHECK_LE(params.quantized_activation_min,
   df9de:	f005 fd89 	bl	e54f4 <abort>
                   params.quantized_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   df9e2:	680b      	ldr	r3, [r1, #0]
   df9e4:	2b04      	cmp	r3, #4
   df9e6:	d1fa      	bne.n	df9de <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x16>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   df9e8:	683b      	ldr	r3, [r7, #0]
   df9ea:	2b04      	cmp	r3, #4
   df9ec:	d1f7      	bne.n	df9de <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x16>
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   df9ee:	2300      	movs	r3, #0
   df9f0:	4619      	mov	r1, r3
   df9f2:	463a      	mov	r2, r7
   df9f4:	4630      	mov	r0, r6
   df9f6:	f7fd f974 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   df9fa:	2303      	movs	r3, #3
   df9fc:	4619      	mov	r1, r3
   df9fe:	463a      	mov	r2, r7
                        const RuntimeShape& output_shape, uint8* output_data) {
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dfa00:	900a      	str	r0, [sp, #40]	; 0x28
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dfa02:	4630      	mov	r0, r6
   dfa04:	f7fd f96d 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_height = input_shape.Dims(1);
   dfa08:	2101      	movs	r1, #1
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dfa0a:	900b      	str	r0, [sp, #44]	; 0x2c
  const int input_height = input_shape.Dims(1);
   dfa0c:	4630      	mov	r0, r6
   dfa0e:	f7f7 fdb7 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   dfa12:	2102      	movs	r1, #2
                   params.quantized_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
   dfa14:	900c      	str	r0, [sp, #48]	; 0x30
  const int input_width = input_shape.Dims(2);
   dfa16:	4630      	mov	r0, r6
   dfa18:	f7f7 fdb2 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   dfa1c:	2101      	movs	r1, #1
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   dfa1e:	900d      	str	r0, [sp, #52]	; 0x34
  const int output_height = output_shape.Dims(1);
   dfa20:	4638      	mov	r0, r7
   dfa22:	f7f7 fdad 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   dfa26:	2102      	movs	r1, #2
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   dfa28:	900e      	str	r0, [sp, #56]	; 0x38
  const int output_width = output_shape.Dims(2);
   dfa2a:	4638      	mov	r0, r7
   dfa2c:	f7f7 fda8 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int stride_height = params.stride_height;
   dfa30:	68e3      	ldr	r3, [r4, #12]
   dfa32:	9310      	str	r3, [sp, #64]	; 0x40
  const int stride_width = params.stride_width;
   dfa34:	6923      	ldr	r3, [r4, #16]
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   dfa36:	900f      	str	r0, [sp, #60]	; 0x3c
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
   dfa38:	9311      	str	r3, [sp, #68]	; 0x44
  for (int batch = 0; batch < batches; ++batch) {
   dfa3a:	f04f 0a00 	mov.w	sl, #0
   dfa3e:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   dfa40:	459a      	cmp	sl, r3
   dfa42:	f280 8088 	bge.w	dfb56 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x18e>
   dfa46:	2300      	movs	r3, #0
   dfa48:	9305      	str	r3, [sp, #20]
   dfa4a:	9303      	str	r3, [sp, #12]
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dfa4c:	9b03      	ldr	r3, [sp, #12]
   dfa4e:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   dfa50:	4293      	cmp	r3, r2
   dfa52:	da7d      	bge.n	dfb50 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x188>
   dfa54:	2300      	movs	r3, #0
   dfa56:	9306      	str	r3, [sp, #24]
   dfa58:	9304      	str	r3, [sp, #16]
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dfa5a:	9b04      	ldr	r3, [sp, #16]
   dfa5c:	9a0f      	ldr	r2, [sp, #60]	; 0x3c
   dfa5e:	4293      	cmp	r3, r2
   dfa60:	da6e      	bge.n	dfb40 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x178>
   dfa62:	2300      	movs	r3, #0
   dfa64:	9302      	str	r3, [sp, #8]
        for (int channel = 0; channel < depth; ++channel) {
   dfa66:	9b02      	ldr	r3, [sp, #8]
   dfa68:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dfa6a:	4293      	cmp	r3, r2
   dfa6c:	da60      	bge.n	dfb30 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x168>
          const int in_x_origin =
              (out_x * stride_width) - params.padding_values.width;
   dfa6e:	9a06      	ldr	r2, [sp, #24]
   dfa70:	f9b4 3002 	ldrsh.w	r3, [r4, #2]
   dfa74:	1ad3      	subs	r3, r2, r3
   dfa76:	9308      	str	r3, [sp, #32]
          const int in_y_origin =
              (out_y * stride_height) - params.padding_values.height;
   dfa78:	9a05      	ldr	r2, [sp, #20]
   dfa7a:	f9b4 3004 	ldrsh.w	r3, [r4, #4]
   dfa7e:	1ad3      	subs	r3, r2, r3
   dfa80:	9309      	str	r3, [sp, #36]	; 0x24
   dfa82:	9b08      	ldr	r3, [sp, #32]
   dfa84:	9a08      	ldr	r2, [sp, #32]
   dfa86:	425b      	negs	r3, r3
   dfa88:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
   dfa8c:	9307      	str	r3, [sp, #28]
   dfa8e:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   dfa90:	1a9a      	subs	r2, r3, r2
   dfa92:	69a3      	ldr	r3, [r4, #24]
   dfa94:	429a      	cmp	r2, r3
   dfa96:	bfa8      	it	ge
   dfa98:	461a      	movge	r2, r3
   dfa9a:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dfa9c:	9213      	str	r2, [sp, #76]	; 0x4c
   dfa9e:	f1c3 0800 	rsb	r8, r3, #0
   dfaa2:	9a09      	ldr	r2, [sp, #36]	; 0x24
   dfaa4:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   dfaa6:	1a9a      	subs	r2, r3, r2
   dfaa8:	6963      	ldr	r3, [r4, #20]
   dfaaa:	429a      	cmp	r2, r3
   dfaac:	bfa8      	it	ge
   dfaae:	461a      	movge	r2, r3
          const int filter_x_end =
              std::min(params.filter_width, input_width - in_x_origin);
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          int32 acc = 0;
   dfab0:	2500      	movs	r5, #0
   dfab2:	ea28 78e8 	bic.w	r8, r8, r8, asr #31
   dfab6:	9212      	str	r2, [sp, #72]	; 0x48
          int filter_count = 0;
   dfab8:	46ab      	mov	fp, r5
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
   dfaba:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dfabc:	4598      	cmp	r8, r3
   dfabe:	da1e      	bge.n	dfafe <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x136>
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              acc +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
   dfac0:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dfac2:	f8dd 901c 	ldr.w	r9, [sp, #28]
   dfac6:	4443      	add	r3, r8
   dfac8:	ebc9 0b0b 	rsb	fp, r9, fp
   dfacc:	9315      	str	r3, [sp, #84]	; 0x54
              std::min(params.filter_height, input_height - in_y_origin);
          int32 acc = 0;
          int filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dface:	9a13      	ldr	r2, [sp, #76]	; 0x4c
   dfad0:	4591      	cmp	r9, r2
   dfad2:	eb0b 0309 	add.w	r3, fp, r9
   dfad6:	da0e      	bge.n	dfaf6 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x12e>
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              acc +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
   dfad8:	9b02      	ldr	r3, [sp, #8]
   dfada:	9300      	str	r3, [sp, #0]
   dfadc:	9b08      	ldr	r3, [sp, #32]
   dfade:	9a15      	ldr	r2, [sp, #84]	; 0x54
   dfae0:	444b      	add	r3, r9
   dfae2:	4651      	mov	r1, sl
   dfae4:	4630      	mov	r0, r6
   dfae6:	f7f7 fdb0 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   dfaea:	9b14      	ldr	r3, [sp, #80]	; 0x50
   dfaec:	5c1b      	ldrb	r3, [r3, r0]
              std::min(params.filter_height, input_height - in_y_origin);
          int32 acc = 0;
          int filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dfaee:	f109 0901 	add.w	r9, r9, #1
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              acc +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
   dfaf2:	441d      	add	r5, r3
              std::min(params.filter_height, input_height - in_y_origin);
          int32 acc = 0;
          int filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dfaf4:	e7eb      	b.n	dface <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x106>
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          int32 acc = 0;
          int filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
   dfaf6:	f108 0801 	add.w	r8, r8, #1
   dfafa:	469b      	mov	fp, r3
   dfafc:	e7dd      	b.n	dfaba <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0xf2>
              acc +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
              filter_count++;
            }
          }
          acc = (acc + filter_count / 2) / filter_count;
   dfafe:	eb05 056b 	add.w	r5, r5, fp, asr #1
   dfb02:	fb95 fbfb 	sdiv	fp, r5, fp
   dfb06:	69e5      	ldr	r5, [r4, #28]
   dfb08:	6a23      	ldr	r3, [r4, #32]
          acc = std::max(acc, params.quantized_activation_min);
          acc = std::min(acc, params.quantized_activation_max);
          output_data[Offset(output_shape, batch, out_y, out_x, channel)] =
   dfb0a:	9a03      	ldr	r2, [sp, #12]
   dfb0c:	455d      	cmp	r5, fp
   dfb0e:	bfb8      	it	lt
   dfb10:	465d      	movlt	r5, fp
   dfb12:	429d      	cmp	r5, r3
   dfb14:	bfa8      	it	ge
   dfb16:	461d      	movge	r5, r3
   dfb18:	9b02      	ldr	r3, [sp, #8]
   dfb1a:	9300      	str	r3, [sp, #0]
   dfb1c:	4651      	mov	r1, sl
   dfb1e:	9b04      	ldr	r3, [sp, #16]
   dfb20:	4638      	mov	r0, r7
   dfb22:	f7f7 fd92 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              static_cast<uint8>(acc);
   dfb26:	9b20      	ldr	r3, [sp, #128]	; 0x80
   dfb28:	541d      	strb	r5, [r3, r0]
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int channel = 0; channel < depth; ++channel) {
   dfb2a:	9b02      	ldr	r3, [sp, #8]
   dfb2c:	3301      	adds	r3, #1
   dfb2e:	e799      	b.n	dfa64 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x9c>
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dfb30:	9b04      	ldr	r3, [sp, #16]
   dfb32:	9a11      	ldr	r2, [sp, #68]	; 0x44
   dfb34:	3301      	adds	r3, #1
   dfb36:	9304      	str	r3, [sp, #16]
   dfb38:	9b06      	ldr	r3, [sp, #24]
   dfb3a:	4413      	add	r3, r2
   dfb3c:	9306      	str	r3, [sp, #24]
   dfb3e:	e78c      	b.n	dfa5a <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x92>
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dfb40:	9b03      	ldr	r3, [sp, #12]
   dfb42:	9a10      	ldr	r2, [sp, #64]	; 0x40
   dfb44:	3301      	adds	r3, #1
   dfb46:	9303      	str	r3, [sp, #12]
   dfb48:	9b05      	ldr	r3, [sp, #20]
   dfb4a:	4413      	add	r3, r2
   dfb4c:	9305      	str	r3, [sp, #20]
   dfb4e:	e77d      	b.n	dfa4c <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x84>
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
   dfb50:	f10a 0a01 	add.w	sl, sl, #1
   dfb54:	e773      	b.n	dfa3e <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x76>
              static_cast<uint8>(acc);
        }
      }
    }
  }
}
   dfb56:	b017      	add	sp, #92	; 0x5c
   dfb58:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dfb5c <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf>:
  }
}

inline void MaxPool(const PoolParams& params, const RuntimeShape& input_shape,
                    const float* input_data, const RuntimeShape& output_shape,
                    float* output_data) {
   dfb5c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dfb60:	ed2d 8b02 	vpush	{d8}
   dfb64:	461e      	mov	r6, r3
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dfb66:	680b      	ldr	r3, [r1, #0]
  }
}

inline void MaxPool(const PoolParams& params, const RuntimeShape& input_shape,
                    const float* input_data, const RuntimeShape& output_shape,
                    float* output_data) {
   dfb68:	b097      	sub	sp, #92	; 0x5c
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dfb6a:	2b04      	cmp	r3, #4
  }
}

inline void MaxPool(const PoolParams& params, const RuntimeShape& input_shape,
                    const float* input_data, const RuntimeShape& output_shape,
                    float* output_data) {
   dfb6c:	4604      	mov	r4, r0
   dfb6e:	460d      	mov	r5, r1
   dfb70:	9212      	str	r2, [sp, #72]	; 0x48
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dfb72:	d001      	beq.n	dfb78 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x1c>
   dfb74:	f005 fcbe 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   dfb78:	6833      	ldr	r3, [r6, #0]
   dfb7a:	2b04      	cmp	r3, #4
   dfb7c:	d1fa      	bne.n	dfb74 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x18>
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dfb7e:	2300      	movs	r3, #0
   dfb80:	4619      	mov	r1, r3
   dfb82:	4632      	mov	r2, r6
   dfb84:	4628      	mov	r0, r5
   dfb86:	f7fd f8ac 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dfb8a:	2303      	movs	r3, #3
   dfb8c:	4619      	mov	r1, r3
   dfb8e:	4632      	mov	r2, r6
inline void MaxPool(const PoolParams& params, const RuntimeShape& input_shape,
                    const float* input_data, const RuntimeShape& output_shape,
                    float* output_data) {
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dfb90:	9008      	str	r0, [sp, #32]
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dfb92:	4628      	mov	r0, r5
   dfb94:	f7fd f8a5 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_height = input_shape.Dims(1);
   dfb98:	2101      	movs	r1, #1
                    const float* input_data, const RuntimeShape& output_shape,
                    float* output_data) {
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dfb9a:	9009      	str	r0, [sp, #36]	; 0x24
  const int input_height = input_shape.Dims(1);
   dfb9c:	4628      	mov	r0, r5
   dfb9e:	f7f7 fcef 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   dfba2:	2102      	movs	r1, #2
                    float* output_data) {
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
   dfba4:	900a      	str	r0, [sp, #40]	; 0x28
  const int input_width = input_shape.Dims(2);
   dfba6:	4628      	mov	r0, r5
   dfba8:	f7f7 fcea 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   dfbac:	2101      	movs	r1, #1
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   dfbae:	900b      	str	r0, [sp, #44]	; 0x2c
  const int output_height = output_shape.Dims(1);
   dfbb0:	4630      	mov	r0, r6
   dfbb2:	f7f7 fce5 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   dfbb6:	2102      	movs	r1, #2
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   dfbb8:	900c      	str	r0, [sp, #48]	; 0x30
  const int output_width = output_shape.Dims(2);
   dfbba:	4630      	mov	r0, r6
   dfbbc:	f7f7 fce0 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int stride_height = params.stride_height;
   dfbc0:	68e3      	ldr	r3, [r4, #12]
   dfbc2:	930e      	str	r3, [sp, #56]	; 0x38
          const int filter_x_end =
              std::min(params.filter_width, input_width - in_x_origin);
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          float max = std::numeric_limits<float>::lowest();
   dfbc4:	ed9f 8a54 	vldr	s16, [pc, #336]	; dfd18 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x1bc>
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
   dfbc8:	6923      	ldr	r3, [r4, #16]
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   dfbca:	900d      	str	r0, [sp, #52]	; 0x34
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
   dfbcc:	930f      	str	r3, [sp, #60]	; 0x3c
  for (int batch = 0; batch < batches; ++batch) {
   dfbce:	f04f 0b00 	mov.w	fp, #0
   dfbd2:	9b08      	ldr	r3, [sp, #32]
   dfbd4:	459b      	cmp	fp, r3
   dfbd6:	f280 8099 	bge.w	dfd0c <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x1b0>
   dfbda:	2300      	movs	r3, #0
   dfbdc:	9304      	str	r3, [sp, #16]
   dfbde:	9302      	str	r3, [sp, #8]
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dfbe0:	9b02      	ldr	r3, [sp, #8]
   dfbe2:	9a0c      	ldr	r2, [sp, #48]	; 0x30
   dfbe4:	4293      	cmp	r3, r2
   dfbe6:	f280 808e 	bge.w	dfd06 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x1aa>
   dfbea:	2300      	movs	r3, #0
   dfbec:	9305      	str	r3, [sp, #20]
   dfbee:	9303      	str	r3, [sp, #12]
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dfbf0:	9b03      	ldr	r3, [sp, #12]
   dfbf2:	9a0d      	ldr	r2, [sp, #52]	; 0x34
   dfbf4:	4293      	cmp	r3, r2
   dfbf6:	da7e      	bge.n	dfcf6 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x19a>
   dfbf8:	f04f 0800 	mov.w	r8, #0
        for (int channel = 0; channel < depth; ++channel) {
   dfbfc:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dfbfe:	4598      	cmp	r8, r3
   dfc00:	da71      	bge.n	dfce6 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x18a>
          const int in_x_origin =
              (out_x * stride_width) - params.padding_values.width;
   dfc02:	f9b4 9002 	ldrsh.w	r9, [r4, #2]
   dfc06:	9b05      	ldr	r3, [sp, #20]
          const int in_y_origin =
              (out_y * stride_height) - params.padding_values.height;
   dfc08:	f9b4 a004 	ldrsh.w	sl, [r4, #4]
          const int filter_x_end =
              std::min(params.filter_width, input_width - in_x_origin);
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          float max = std::numeric_limits<float>::lowest();
   dfc0c:	ed8d 8a15 	vstr	s16, [sp, #84]	; 0x54
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int channel = 0; channel < depth; ++channel) {
          const int in_x_origin =
              (out_x * stride_width) - params.padding_values.width;
   dfc10:	ebc9 0303 	rsb	r3, r9, r3
   dfc14:	9307      	str	r3, [sp, #28]
          const int in_y_origin =
              (out_y * stride_height) - params.padding_values.height;
   dfc16:	9b04      	ldr	r3, [sp, #16]
   dfc18:	9a07      	ldr	r2, [sp, #28]
   dfc1a:	ebca 0a03 	rsb	sl, sl, r3
   dfc1e:	9b07      	ldr	r3, [sp, #28]
   dfc20:	425b      	negs	r3, r3
   dfc22:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
   dfc26:	9306      	str	r3, [sp, #24]
   dfc28:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   dfc2a:	1a9a      	subs	r2, r3, r2
   dfc2c:	69a3      	ldr	r3, [r4, #24]
   dfc2e:	429a      	cmp	r2, r3
   dfc30:	bfa8      	it	ge
   dfc32:	461a      	movge	r2, r3
   dfc34:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   dfc36:	9210      	str	r2, [sp, #64]	; 0x40
   dfc38:	ebca 0203 	rsb	r2, sl, r3
   dfc3c:	6963      	ldr	r3, [r4, #20]
   dfc3e:	429a      	cmp	r2, r3
   dfc40:	f1ca 0700 	rsb	r7, sl, #0
   dfc44:	bfa8      	it	ge
   dfc46:	461a      	movge	r2, r3
   dfc48:	ea27 77e7 	bic.w	r7, r7, r7, asr #31
   dfc4c:	9211      	str	r2, [sp, #68]	; 0x44
              std::min(params.filter_width, input_width - in_x_origin);
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          float max = std::numeric_limits<float>::lowest();
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
   dfc4e:	9b11      	ldr	r3, [sp, #68]	; 0x44
   dfc50:	429f      	cmp	r7, r3
   dfc52:	da24      	bge.n	dfc9e <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x142>
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              max = std::max(
                  max,
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)]);
   dfc54:	eb07 030a 	add.w	r3, r7, sl
   dfc58:	f8dd 9018 	ldr.w	r9, [sp, #24]
   dfc5c:	9313      	str	r3, [sp, #76]	; 0x4c
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          float max = std::numeric_limits<float>::lowest();
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dfc5e:	9b10      	ldr	r3, [sp, #64]	; 0x40
   dfc60:	4599      	cmp	r9, r3
   dfc62:	da1a      	bge.n	dfc9a <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x13e>
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              max = std::max(
                  max,
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)]);
   dfc64:	9b07      	ldr	r3, [sp, #28]
   dfc66:	f8cd 8000 	str.w	r8, [sp]
   dfc6a:	444b      	add	r3, r9
   dfc6c:	9a13      	ldr	r2, [sp, #76]	; 0x4c
   dfc6e:	4659      	mov	r1, fp
   dfc70:	4628      	mov	r0, r5
   dfc72:	f7f7 fcea 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   dfc76:	9b12      	ldr	r3, [sp, #72]	; 0x48
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
   dfc78:	eddd 7a15 	vldr	s15, [sp, #84]	; 0x54
   dfc7c:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   dfc80:	ed90 7a00 	vldr	s14, [r0]
   dfc84:	eeb4 7ae7 	vcmpe.f32	s14, s15
   dfc88:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
	return __b;
      return __a;
   dfc8c:	bfd8      	it	le
   dfc8e:	a815      	addle	r0, sp, #84	; 0x54
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          float max = std::numeric_limits<float>::lowest();
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dfc90:	f109 0901 	add.w	r9, r9, #1
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              max = std::max(
                  max,
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)]);
   dfc94:	6803      	ldr	r3, [r0, #0]
   dfc96:	9315      	str	r3, [sp, #84]	; 0x54
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          float max = std::numeric_limits<float>::lowest();
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dfc98:	e7e1      	b.n	dfc5e <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x102>
              std::min(params.filter_width, input_width - in_x_origin);
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          float max = std::numeric_limits<float>::lowest();
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
   dfc9a:	3701      	adds	r7, #1
   dfc9c:	e7d7      	b.n	dfc4e <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0xf2>
              max = std::max(
                  max,
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)]);
            }
          }
          output_data[Offset(output_shape, batch, out_y, out_x, channel)] =
   dfc9e:	f8cd 8000 	str.w	r8, [sp]
   dfca2:	9b03      	ldr	r3, [sp, #12]
   dfca4:	9a02      	ldr	r2, [sp, #8]
   dfca6:	4659      	mov	r1, fp
   dfca8:	4630      	mov	r0, r6
   dfcaa:	f7f7 fcce 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              ActivationFunctionWithMinMax(max, params.float_activation_min,
   dfcae:	edd4 7a09 	vldr	s15, [r4, #36]	; 0x24
   dfcb2:	eddd 6a15 	vldr	s13, [sp, #84]	; 0x54
                                           params.float_activation_max);
   dfcb6:	ed94 7a0a 	vldr	s14, [r4, #40]	; 0x28
              max = std::max(
                  max,
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)]);
            }
          }
          output_data[Offset(output_shape, batch, out_y, out_x, channel)] =
   dfcba:	9b22      	ldr	r3, [sp, #136]	; 0x88
   dfcbc:	eef4 6ae7 	vcmpe.f32	s13, s15
   dfcc0:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   dfcc4:	bf58      	it	pl
   dfcc6:	eef0 7a66 	vmovpl.f32	s15, s13
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
   dfcca:	eeb4 7a67 	vcmp.f32	s14, s15
   dfcce:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   dfcd2:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   dfcd6:	bf48      	it	mi
   dfcd8:	eef0 7a47 	vmovmi.f32	s15, s14
              ActivationFunctionWithMinMax(max, params.float_activation_min,
                                           params.float_activation_max);
   dfcdc:	edc0 7a00 	vstr	s15, [r0]
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int channel = 0; channel < depth; ++channel) {
   dfce0:	f108 0801 	add.w	r8, r8, #1
   dfce4:	e78a      	b.n	dfbfc <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0xa0>
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dfce6:	9b03      	ldr	r3, [sp, #12]
   dfce8:	9a0f      	ldr	r2, [sp, #60]	; 0x3c
   dfcea:	3301      	adds	r3, #1
   dfcec:	9303      	str	r3, [sp, #12]
   dfcee:	9b05      	ldr	r3, [sp, #20]
   dfcf0:	4413      	add	r3, r2
   dfcf2:	9305      	str	r3, [sp, #20]
   dfcf4:	e77c      	b.n	dfbf0 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x94>
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dfcf6:	9b02      	ldr	r3, [sp, #8]
   dfcf8:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   dfcfa:	3301      	adds	r3, #1
   dfcfc:	9302      	str	r3, [sp, #8]
   dfcfe:	9b04      	ldr	r3, [sp, #16]
   dfd00:	4413      	add	r3, r2
   dfd02:	9304      	str	r3, [sp, #16]
   dfd04:	e76c      	b.n	dfbe0 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x84>
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
   dfd06:	f10b 0b01 	add.w	fp, fp, #1
   dfd0a:	e762      	b.n	dfbd2 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x76>
                                           params.float_activation_max);
        }
      }
    }
  }
}
   dfd0c:	b017      	add	sp, #92	; 0x5c
   dfd0e:	ecbd 8b02 	vpop	{d8}
   dfd12:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   dfd16:	bf00      	nop
   dfd18:	ff7fffff 	.word	0xff7fffff

000dfd1c <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph>:

inline void MaxPool(const PoolParams& params, const RuntimeShape& input_shape,
                    const uint8* input_data, const RuntimeShape& output_shape,
                    uint8* output_data) {
   dfd1c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dfd20:	b097      	sub	sp, #92	; 0x5c
   dfd22:	461e      	mov	r6, r3
   dfd24:	9208      	str	r2, [sp, #32]
  TFLITE_DCHECK_LE(params.quantized_activation_min,
   dfd26:	6a03      	ldr	r3, [r0, #32]
   dfd28:	69c2      	ldr	r2, [r0, #28]
                   params.quantized_activation_max);
   dfd2a:	429a      	cmp	r2, r3
  }
}

inline void MaxPool(const PoolParams& params, const RuntimeShape& input_shape,
                    const uint8* input_data, const RuntimeShape& output_shape,
                    uint8* output_data) {
   dfd2c:	4604      	mov	r4, r0
   dfd2e:	460d      	mov	r5, r1
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
   dfd30:	dd01      	ble.n	dfd36 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x1a>
}

inline void MaxPool(const PoolParams& params, const RuntimeShape& input_shape,
                    const uint8* input_data, const RuntimeShape& output_shape,
                    uint8* output_data) {
  TFLITE_DCHECK_LE(params.quantized_activation_min,
   dfd32:	f005 fbdf 	bl	e54f4 <abort>
                   params.quantized_activation_max);
  TFLITE_DCHECK_GE(params.quantized_activation_min, 0);
   dfd36:	2a00      	cmp	r2, #0
   dfd38:	dbfb      	blt.n	dfd32 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x16>
  TFLITE_DCHECK_LE(params.quantized_activation_max, 255);
   dfd3a:	2bff      	cmp	r3, #255	; 0xff
   dfd3c:	dcf9      	bgt.n	dfd32 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x16>
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dfd3e:	680b      	ldr	r3, [r1, #0]
   dfd40:	2b04      	cmp	r3, #4
   dfd42:	d1f6      	bne.n	dfd32 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x16>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   dfd44:	6833      	ldr	r3, [r6, #0]
   dfd46:	2b04      	cmp	r3, #4
   dfd48:	d1f3      	bne.n	dfd32 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x16>
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dfd4a:	2300      	movs	r3, #0
   dfd4c:	4619      	mov	r1, r3
   dfd4e:	4632      	mov	r2, r6
   dfd50:	4628      	mov	r0, r5
   dfd52:	f7fc ffc6 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dfd56:	2303      	movs	r3, #3
   dfd58:	4619      	mov	r1, r3
   dfd5a:	4632      	mov	r2, r6
                   params.quantized_activation_max);
  TFLITE_DCHECK_GE(params.quantized_activation_min, 0);
  TFLITE_DCHECK_LE(params.quantized_activation_max, 255);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dfd5c:	9009      	str	r0, [sp, #36]	; 0x24
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dfd5e:	4628      	mov	r0, r5
   dfd60:	f7fc ffbf 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_height = input_shape.Dims(1);
   dfd64:	2101      	movs	r1, #1
  TFLITE_DCHECK_GE(params.quantized_activation_min, 0);
  TFLITE_DCHECK_LE(params.quantized_activation_max, 255);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dfd66:	900b      	str	r0, [sp, #44]	; 0x2c
  const int input_height = input_shape.Dims(1);
   dfd68:	4628      	mov	r0, r5
   dfd6a:	f7f7 fc09 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   dfd6e:	2102      	movs	r1, #2
  TFLITE_DCHECK_LE(params.quantized_activation_max, 255);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
   dfd70:	900c      	str	r0, [sp, #48]	; 0x30
  const int input_width = input_shape.Dims(2);
   dfd72:	4628      	mov	r0, r5
   dfd74:	f7f7 fc04 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   dfd78:	2101      	movs	r1, #1
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   dfd7a:	900d      	str	r0, [sp, #52]	; 0x34
  const int output_height = output_shape.Dims(1);
   dfd7c:	4630      	mov	r0, r6
   dfd7e:	f7f7 fbff 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   dfd82:	2102      	movs	r1, #2
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   dfd84:	900e      	str	r0, [sp, #56]	; 0x38
  const int output_width = output_shape.Dims(2);
   dfd86:	4630      	mov	r0, r6
   dfd88:	f7f7 fbfa 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int stride_height = params.stride_height;
   dfd8c:	68e3      	ldr	r3, [r4, #12]
   dfd8e:	9310      	str	r3, [sp, #64]	; 0x40
  const int stride_width = params.stride_width;
   dfd90:	6923      	ldr	r3, [r4, #16]
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   dfd92:	900f      	str	r0, [sp, #60]	; 0x3c
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
   dfd94:	9311      	str	r3, [sp, #68]	; 0x44
  for (int batch = 0; batch < batches; ++batch) {
   dfd96:	f04f 0b00 	mov.w	fp, #0
   dfd9a:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dfd9c:	459b      	cmp	fp, r3
   dfd9e:	f280 808d 	bge.w	dfebc <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x1a0>
   dfda2:	2300      	movs	r3, #0
   dfda4:	9305      	str	r3, [sp, #20]
   dfda6:	9302      	str	r3, [sp, #8]
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dfda8:	9b02      	ldr	r3, [sp, #8]
   dfdaa:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   dfdac:	4293      	cmp	r3, r2
   dfdae:	f280 8082 	bge.w	dfeb6 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x19a>
   dfdb2:	2300      	movs	r3, #0
   dfdb4:	9304      	str	r3, [sp, #16]
   dfdb6:	9303      	str	r3, [sp, #12]
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dfdb8:	9b03      	ldr	r3, [sp, #12]
   dfdba:	9a0f      	ldr	r2, [sp, #60]	; 0x3c
   dfdbc:	4293      	cmp	r3, r2
   dfdbe:	da72      	bge.n	dfea6 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x18a>
   dfdc0:	f04f 0800 	mov.w	r8, #0
        for (int channel = 0; channel < depth; ++channel) {
   dfdc4:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   dfdc6:	4598      	cmp	r8, r3
   dfdc8:	da65      	bge.n	dfe96 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x17a>
          const int in_x_origin =
              (out_x * stride_width) - params.padding_values.width;
   dfdca:	f9b4 9002 	ldrsh.w	r9, [r4, #2]
   dfdce:	9b04      	ldr	r3, [sp, #16]
          const int in_y_origin =
              (out_y * stride_height) - params.padding_values.height;
   dfdd0:	f9b4 a004 	ldrsh.w	sl, [r4, #4]
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int channel = 0; channel < depth; ++channel) {
          const int in_x_origin =
              (out_x * stride_width) - params.padding_values.width;
   dfdd4:	ebc9 0303 	rsb	r3, r9, r3
   dfdd8:	9307      	str	r3, [sp, #28]
          const int in_y_origin =
              (out_y * stride_height) - params.padding_values.height;
   dfdda:	9b05      	ldr	r3, [sp, #20]
   dfddc:	9a07      	ldr	r2, [sp, #28]
   dfdde:	ebca 0a03 	rsb	sl, sl, r3
   dfde2:	9b07      	ldr	r3, [sp, #28]
   dfde4:	425b      	negs	r3, r3
   dfde6:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
   dfdea:	9306      	str	r3, [sp, #24]
   dfdec:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   dfdee:	1a9a      	subs	r2, r3, r2
   dfdf0:	69a3      	ldr	r3, [r4, #24]
   dfdf2:	429a      	cmp	r2, r3
   dfdf4:	bfa8      	it	ge
   dfdf6:	461a      	movge	r2, r3
   dfdf8:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   dfdfa:	920a      	str	r2, [sp, #40]	; 0x28
   dfdfc:	ebca 0203 	rsb	r2, sl, r3
   dfe00:	6963      	ldr	r3, [r4, #20]
   dfe02:	429a      	cmp	r2, r3
   dfe04:	bfa8      	it	ge
   dfe06:	461a      	movge	r2, r3
   dfe08:	f1ca 0700 	rsb	r7, sl, #0
          const int filter_x_end =
              std::min(params.filter_width, input_width - in_x_origin);
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          uint8 max = 0;
   dfe0c:	f04f 0300 	mov.w	r3, #0
   dfe10:	ea27 77e7 	bic.w	r7, r7, r7, asr #31
   dfe14:	9212      	str	r2, [sp, #72]	; 0x48
   dfe16:	f88d 3057 	strb.w	r3, [sp, #87]	; 0x57
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
   dfe1a:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dfe1c:	429f      	cmp	r7, r3
   dfe1e:	da22      	bge.n	dfe66 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x14a>
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              max = std::max(
                  max,
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)]);
   dfe20:	eb0a 0307 	add.w	r3, sl, r7
   dfe24:	f8dd 9018 	ldr.w	r9, [sp, #24]
   dfe28:	9313      	str	r3, [sp, #76]	; 0x4c
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          uint8 max = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dfe2a:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   dfe2c:	4599      	cmp	r9, r3
   dfe2e:	da18      	bge.n	dfe62 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x146>
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              max = std::max(
                  max,
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)]);
   dfe30:	9b07      	ldr	r3, [sp, #28]
   dfe32:	9a13      	ldr	r2, [sp, #76]	; 0x4c
   dfe34:	f8cd 8000 	str.w	r8, [sp]
   dfe38:	444b      	add	r3, r9
   dfe3a:	4659      	mov	r1, fp
   dfe3c:	4628      	mov	r0, r5
   dfe3e:	f7f7 fc04 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
   dfe42:	9a08      	ldr	r2, [sp, #32]
   dfe44:	9b08      	ldr	r3, [sp, #32]
   dfe46:	5c11      	ldrb	r1, [r2, r0]
   dfe48:	f89d 2057 	ldrb.w	r2, [sp, #87]	; 0x57
   dfe4c:	4291      	cmp	r1, r2
   dfe4e:	4403      	add	r3, r0
	return __b;
      return __a;
   dfe50:	bf98      	it	ls
   dfe52:	f10d 0357 	addls.w	r3, sp, #87	; 0x57
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          uint8 max = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dfe56:	f109 0901 	add.w	r9, r9, #1
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              max = std::max(
                  max,
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)]);
   dfe5a:	781b      	ldrb	r3, [r3, #0]
   dfe5c:	f88d 3057 	strb.w	r3, [sp, #87]	; 0x57
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          uint8 max = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dfe60:	e7e3      	b.n	dfe2a <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x10e>
              std::min(params.filter_width, input_width - in_x_origin);
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          uint8 max = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
   dfe62:	3701      	adds	r7, #1
   dfe64:	e7d9      	b.n	dfe1a <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0xfe>
   dfe66:	7f27      	ldrb	r7, [r4, #28]
   dfe68:	f89d 3057 	ldrb.w	r3, [sp, #87]	; 0x57
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)]);
            }
          }
          max = std::max<uint8>(max, params.quantized_activation_min);
          max = std::min<uint8>(max, params.quantized_activation_max);
          output_data[Offset(output_shape, batch, out_y, out_x, channel)] =
   dfe6c:	f8cd 8000 	str.w	r8, [sp]
   dfe70:	429f      	cmp	r7, r3
   dfe72:	bf38      	it	cc
   dfe74:	461f      	movcc	r7, r3
   dfe76:	f894 3020 	ldrb.w	r3, [r4, #32]
   dfe7a:	9a02      	ldr	r2, [sp, #8]
   dfe7c:	429f      	cmp	r7, r3
   dfe7e:	bf28      	it	cs
   dfe80:	461f      	movcs	r7, r3
   dfe82:	4659      	mov	r1, fp
   dfe84:	9b03      	ldr	r3, [sp, #12]
   dfe86:	4630      	mov	r0, r6
   dfe88:	f7f7 fbdf 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              static_cast<uint8>(max);
   dfe8c:	9b20      	ldr	r3, [sp, #128]	; 0x80
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int channel = 0; channel < depth; ++channel) {
   dfe8e:	f108 0801 	add.w	r8, r8, #1
            }
          }
          max = std::max<uint8>(max, params.quantized_activation_min);
          max = std::min<uint8>(max, params.quantized_activation_max);
          output_data[Offset(output_shape, batch, out_y, out_x, channel)] =
              static_cast<uint8>(max);
   dfe92:	541f      	strb	r7, [r3, r0]
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int channel = 0; channel < depth; ++channel) {
   dfe94:	e796      	b.n	dfdc4 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0xa8>
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dfe96:	9b03      	ldr	r3, [sp, #12]
   dfe98:	9a11      	ldr	r2, [sp, #68]	; 0x44
   dfe9a:	3301      	adds	r3, #1
   dfe9c:	9303      	str	r3, [sp, #12]
   dfe9e:	9b04      	ldr	r3, [sp, #16]
   dfea0:	4413      	add	r3, r2
   dfea2:	9304      	str	r3, [sp, #16]
   dfea4:	e788      	b.n	dfdb8 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x9c>
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dfea6:	9b02      	ldr	r3, [sp, #8]
   dfea8:	9a10      	ldr	r2, [sp, #64]	; 0x40
   dfeaa:	3301      	adds	r3, #1
   dfeac:	9302      	str	r3, [sp, #8]
   dfeae:	9b05      	ldr	r3, [sp, #20]
   dfeb0:	4413      	add	r3, r2
   dfeb2:	9305      	str	r3, [sp, #20]
   dfeb4:	e778      	b.n	dfda8 <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x8c>
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
   dfeb6:	f10b 0b01 	add.w	fp, fp, #1
   dfeba:	e76e      	b.n	dfd9a <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x7e>
              static_cast<uint8>(max);
        }
      }
    }
  }
}
   dfebc:	b017      	add	sp, #92	; 0x5c
   dfebe:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000dfec2 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa>:
namespace tflite {
namespace reference_integer_ops {

inline void AveragePool(const PoolParams& params,
                        const RuntimeShape& input_shape, const int8* input_data,
                        const RuntimeShape& output_shape, int8* output_data) {
   dfec2:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   dfec6:	b097      	sub	sp, #92	; 0x5c
   dfec8:	461f      	mov	r7, r3
   dfeca:	9214      	str	r2, [sp, #80]	; 0x50
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
   dfecc:	6a03      	ldr	r3, [r0, #32]
   dfece:	69c2      	ldr	r2, [r0, #28]
   dfed0:	429a      	cmp	r2, r3
namespace tflite {
namespace reference_integer_ops {

inline void AveragePool(const PoolParams& params,
                        const RuntimeShape& input_shape, const int8* input_data,
                        const RuntimeShape& output_shape, int8* output_data) {
   dfed2:	4604      	mov	r4, r0
   dfed4:	4689      	mov	r9, r1
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
   dfed6:	dd01      	ble.n	dfedc <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x1a>
namespace reference_integer_ops {

inline void AveragePool(const PoolParams& params,
                        const RuntimeShape& input_shape, const int8* input_data,
                        const RuntimeShape& output_shape, int8* output_data) {
  TFLITE_DCHECK_LE(params.quantized_activation_min,
   dfed8:	f005 fb0c 	bl	e54f4 <abort>
                   params.quantized_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   dfedc:	680b      	ldr	r3, [r1, #0]
   dfede:	2b04      	cmp	r3, #4
   dfee0:	d1fa      	bne.n	dfed8 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x16>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   dfee2:	683b      	ldr	r3, [r7, #0]
   dfee4:	2b04      	cmp	r3, #4
   dfee6:	d1f7      	bne.n	dfed8 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x16>
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dfee8:	2300      	movs	r3, #0
   dfeea:	4619      	mov	r1, r3
   dfeec:	463a      	mov	r2, r7
   dfeee:	4648      	mov	r0, r9
   dfef0:	f7fc fef7 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dfef4:	2303      	movs	r3, #3
   dfef6:	4619      	mov	r1, r3
   dfef8:	463a      	mov	r2, r7
                        const RuntimeShape& output_shape, int8* output_data) {
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   dfefa:	900a      	str	r0, [sp, #40]	; 0x28
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dfefc:	4648      	mov	r0, r9
   dfefe:	f7fc fef0 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_height = input_shape.Dims(1);
   dff02:	2101      	movs	r1, #1
  TFLITE_DCHECK_LE(params.quantized_activation_min,
                   params.quantized_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
   dff04:	900b      	str	r0, [sp, #44]	; 0x2c
  const int input_height = input_shape.Dims(1);
   dff06:	4648      	mov	r0, r9
   dff08:	f7f7 fb3a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   dff0c:	2102      	movs	r1, #2
                   params.quantized_activation_max);
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
   dff0e:	900c      	str	r0, [sp, #48]	; 0x30
  const int input_width = input_shape.Dims(2);
   dff10:	4648      	mov	r0, r9
   dff12:	f7f7 fb35 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   dff16:	2101      	movs	r1, #1
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   dff18:	900d      	str	r0, [sp, #52]	; 0x34
  const int output_height = output_shape.Dims(1);
   dff1a:	4638      	mov	r0, r7
   dff1c:	f7f7 fb30 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   dff20:	2102      	movs	r1, #2
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   dff22:	900e      	str	r0, [sp, #56]	; 0x38
  const int output_width = output_shape.Dims(2);
   dff24:	4638      	mov	r0, r7
   dff26:	f7f7 fb2b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int stride_height = params.stride_height;
   dff2a:	68e3      	ldr	r3, [r4, #12]
   dff2c:	9310      	str	r3, [sp, #64]	; 0x40
  const int stride_width = params.stride_width;
   dff2e:	6923      	ldr	r3, [r4, #16]
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int depth = MatchingDim(input_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   dff30:	900f      	str	r0, [sp, #60]	; 0x3c
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
   dff32:	9311      	str	r3, [sp, #68]	; 0x44
  for (int batch = 0; batch < batches; ++batch) {
   dff34:	f04f 0a00 	mov.w	sl, #0
   dff38:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   dff3a:	459a      	cmp	sl, r3
   dff3c:	f280 808d 	bge.w	e005a <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x198>
   dff40:	2300      	movs	r3, #0
   dff42:	9305      	str	r3, [sp, #20]
   dff44:	9303      	str	r3, [sp, #12]
    for (int out_y = 0; out_y < output_height; ++out_y) {
   dff46:	9b03      	ldr	r3, [sp, #12]
   dff48:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   dff4a:	4293      	cmp	r3, r2
   dff4c:	f280 8082 	bge.w	e0054 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x192>
   dff50:	2300      	movs	r3, #0
   dff52:	9306      	str	r3, [sp, #24]
   dff54:	9304      	str	r3, [sp, #16]
      for (int out_x = 0; out_x < output_width; ++out_x) {
   dff56:	9b04      	ldr	r3, [sp, #16]
   dff58:	9a0f      	ldr	r2, [sp, #60]	; 0x3c
   dff5a:	4293      	cmp	r3, r2
   dff5c:	da72      	bge.n	e0044 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x182>
   dff5e:	2300      	movs	r3, #0
   dff60:	9302      	str	r3, [sp, #8]
        for (int channel = 0; channel < depth; ++channel) {
   dff62:	9b02      	ldr	r3, [sp, #8]
   dff64:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   dff66:	4293      	cmp	r3, r2
   dff68:	da64      	bge.n	e0034 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x172>
          const int in_x_origin =
              (out_x * stride_width) - params.padding_values.width;
   dff6a:	9a06      	ldr	r2, [sp, #24]
   dff6c:	f9b4 3002 	ldrsh.w	r3, [r4, #2]
   dff70:	1ad3      	subs	r3, r2, r3
   dff72:	9308      	str	r3, [sp, #32]
          const int in_y_origin =
              (out_y * stride_height) - params.padding_values.height;
   dff74:	9a05      	ldr	r2, [sp, #20]
   dff76:	f9b4 3004 	ldrsh.w	r3, [r4, #4]
   dff7a:	1ad3      	subs	r3, r2, r3
   dff7c:	9309      	str	r3, [sp, #36]	; 0x24
   dff7e:	9b08      	ldr	r3, [sp, #32]
   dff80:	9a08      	ldr	r2, [sp, #32]
   dff82:	425b      	negs	r3, r3
   dff84:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
   dff88:	9307      	str	r3, [sp, #28]
   dff8a:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   dff8c:	1a9a      	subs	r2, r3, r2
   dff8e:	69a3      	ldr	r3, [r4, #24]
   dff90:	429a      	cmp	r2, r3
   dff92:	bfa8      	it	ge
   dff94:	461a      	movge	r2, r3
   dff96:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dff98:	9213      	str	r2, [sp, #76]	; 0x4c
   dff9a:	425e      	negs	r6, r3
   dff9c:	9a09      	ldr	r2, [sp, #36]	; 0x24
   dff9e:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   dffa0:	1a9a      	subs	r2, r3, r2
   dffa2:	6963      	ldr	r3, [r4, #20]
   dffa4:	429a      	cmp	r2, r3
   dffa6:	bfa8      	it	ge
   dffa8:	461a      	movge	r2, r3
          const int filter_x_end =
              std::min(params.filter_width, input_width - in_x_origin);
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          int32 acc = 0;
   dffaa:	2500      	movs	r5, #0
   dffac:	ea26 76e6 	bic.w	r6, r6, r6, asr #31
   dffb0:	9212      	str	r2, [sp, #72]	; 0x48
          int filter_count = 0;
   dffb2:	46ab      	mov	fp, r5
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
   dffb4:	9b12      	ldr	r3, [sp, #72]	; 0x48
   dffb6:	429e      	cmp	r6, r3
   dffb8:	da1d      	bge.n	dfff6 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x134>
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              acc +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
   dffba:	9b09      	ldr	r3, [sp, #36]	; 0x24
   dffbc:	f8dd 801c 	ldr.w	r8, [sp, #28]
   dffc0:	4433      	add	r3, r6
   dffc2:	ebc8 0b0b 	rsb	fp, r8, fp
   dffc6:	9315      	str	r3, [sp, #84]	; 0x54
              std::min(params.filter_height, input_height - in_y_origin);
          int32 acc = 0;
          int filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dffc8:	9a13      	ldr	r2, [sp, #76]	; 0x4c
   dffca:	4590      	cmp	r8, r2
   dffcc:	eb0b 0308 	add.w	r3, fp, r8
   dffd0:	da0e      	bge.n	dfff0 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x12e>
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              acc +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
   dffd2:	9b02      	ldr	r3, [sp, #8]
   dffd4:	9300      	str	r3, [sp, #0]
   dffd6:	9b08      	ldr	r3, [sp, #32]
   dffd8:	9a15      	ldr	r2, [sp, #84]	; 0x54
   dffda:	4443      	add	r3, r8
   dffdc:	4651      	mov	r1, sl
   dffde:	4648      	mov	r0, r9
   dffe0:	f7f7 fb33 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   dffe4:	9b14      	ldr	r3, [sp, #80]	; 0x50
   dffe6:	561b      	ldrsb	r3, [r3, r0]
              std::min(params.filter_height, input_height - in_y_origin);
          int32 acc = 0;
          int filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dffe8:	f108 0801 	add.w	r8, r8, #1
                 ++filter_x) {
              const int in_x = in_x_origin + filter_x;
              const int in_y = in_y_origin + filter_y;
              acc +=
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
   dffec:	441d      	add	r5, r3
              std::min(params.filter_height, input_height - in_y_origin);
          int32 acc = 0;
          int filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
               ++filter_y) {
            for (int filter_x = filter_x_start; filter_x < filter_x_end;
   dffee:	e7eb      	b.n	dffc8 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x106>
          const int filter_y_start = std::max(0, -in_y_origin);
          const int filter_y_end =
              std::min(params.filter_height, input_height - in_y_origin);
          int32 acc = 0;
          int filter_count = 0;
          for (int filter_y = filter_y_start; filter_y < filter_y_end;
   dfff0:	3601      	adds	r6, #1
   dfff2:	469b      	mov	fp, r3
   dfff4:	e7de      	b.n	dffb4 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0xf2>
              filter_count++;
            }
          }
          // Round to the closest integer value.
          acc = acc > 0 ? (acc + filter_count / 2) / filter_count
                        : (acc - filter_count / 2) / filter_count;
   dfff6:	2d00      	cmp	r5, #0
   dfff8:	bfd7      	itett	le
   dfffa:	2302      	movle	r3, #2
                  input_data[Offset(input_shape, batch, in_y, in_x, channel)];
              filter_count++;
            }
          }
          // Round to the closest integer value.
          acc = acc > 0 ? (acc + filter_count / 2) / filter_count
   dfffc:	eb05 056b 	addgt.w	r5, r5, fp, asr #1
                        : (acc - filter_count / 2) / filter_count;
   e0000:	fb9b f3f3 	sdivle	r3, fp, r3
   e0004:	1aed      	suble	r5, r5, r3
   e0006:	fb95 fbfb 	sdiv	fp, r5, fp
   e000a:	69e5      	ldr	r5, [r4, #28]
          acc = std::max(acc, params.quantized_activation_min);
          acc = std::min(acc, params.quantized_activation_max);
          output_data[Offset(output_shape, batch, out_y, out_x, channel)] =
   e000c:	9b02      	ldr	r3, [sp, #8]
   e000e:	9300      	str	r3, [sp, #0]
   e0010:	45ab      	cmp	fp, r5
   e0012:	bfb8      	it	lt
   e0014:	46ab      	movlt	fp, r5
   e0016:	6a25      	ldr	r5, [r4, #32]
   e0018:	9b04      	ldr	r3, [sp, #16]
   e001a:	9a03      	ldr	r2, [sp, #12]
   e001c:	455d      	cmp	r5, fp
   e001e:	4651      	mov	r1, sl
   e0020:	4638      	mov	r0, r7
   e0022:	bfa8      	it	ge
   e0024:	465d      	movge	r5, fp
   e0026:	f7f7 fb10 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
              static_cast<int8>(acc);
   e002a:	9b20      	ldr	r3, [sp, #128]	; 0x80
   e002c:	541d      	strb	r5, [r3, r0]
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int channel = 0; channel < depth; ++channel) {
   e002e:	9b02      	ldr	r3, [sp, #8]
   e0030:	3301      	adds	r3, #1
   e0032:	e795      	b.n	dff60 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x9e>
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   e0034:	9b04      	ldr	r3, [sp, #16]
   e0036:	9a11      	ldr	r2, [sp, #68]	; 0x44
   e0038:	3301      	adds	r3, #1
   e003a:	9304      	str	r3, [sp, #16]
   e003c:	9b06      	ldr	r3, [sp, #24]
   e003e:	4413      	add	r3, r2
   e0040:	9306      	str	r3, [sp, #24]
   e0042:	e788      	b.n	dff56 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x94>
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   e0044:	9b03      	ldr	r3, [sp, #12]
   e0046:	9a10      	ldr	r2, [sp, #64]	; 0x40
   e0048:	3301      	adds	r3, #1
   e004a:	9303      	str	r3, [sp, #12]
   e004c:	9b05      	ldr	r3, [sp, #20]
   e004e:	4413      	add	r3, r2
   e0050:	9305      	str	r3, [sp, #20]
   e0052:	e778      	b.n	dff46 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x84>
  const int input_width = input_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  const int stride_height = params.stride_height;
  const int stride_width = params.stride_width;
  for (int batch = 0; batch < batches; ++batch) {
   e0054:	f10a 0a01 	add.w	sl, sl, #1
   e0058:	e76e      	b.n	dff38 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa+0x76>
              static_cast<int8>(acc);
        }
      }
    }
  }
}
   e005a:	b017      	add	sp, #92	; 0x5c
   e005c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000e0060 <_ZN6tflite3ops5micro7pooling12_GLOBAL__N_115CalculateOpDataEPK13TfLiteContextPK16TfLitePoolParamsPK12TfLiteTensorSC_PNS3_6OpDataE.isra.2>:

struct OpData {
  TfLitePaddingValues padding;
};

TfLiteStatus CalculateOpData(const TfLiteContext* context,
   e0060:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e0064:	688b      	ldr	r3, [r1, #8]
  int width = SizeOfDimension(input, 2);

  int out_height, out_width;

  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
   e0066:	6846      	ldr	r6, [r0, #4]

namespace tflite {

inline int NumDimensions(const TfLiteTensor* t) { return t->dims->size; }
inline int SizeOfDimension(const TfLiteTensor* t, int dim) {
  return t->dims->data[dim];
   e0068:	689f      	ldr	r7, [r3, #8]
   e006a:	f8d3 b00c 	ldr.w	fp, [r3, #12]
      /*dilation_rate_height=*/1,
      /*dilation_rate_width=*/1, height, width, params->filter_height,
      params->filter_width, params->padding, &out_height, &out_width);
   e006e:	f890 a000 	ldrb.w	sl, [r0]
   e0072:	68c3      	ldr	r3, [r0, #12]
  int width = SizeOfDimension(input, 2);

  int out_height, out_width;

  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
   e0074:	f8d0 9008 	ldr.w	r9, [r0, #8]
      /*dilation_rate_height=*/1,
      /*dilation_rate_width=*/1, height, width, params->filter_height,
   e0078:	f8d0 8010 	ldr.w	r8, [r0, #16]

struct OpData {
  TfLitePaddingValues padding;
};

TfLiteStatus CalculateOpData(const TfLiteContext* context,
   e007c:	b085      	sub	sp, #20

inline TfLitePaddingValues ComputePaddingHeightWidth(
    int stride_height, int stride_width, int dilation_rate_height,
    int dilation_rate_width, int in_height, int in_width, int filter_height,
    int filter_width, TfLitePadding padding, int* out_height, int* out_width) {
  *out_width = ComputeOutSize(padding, in_width, filter_width, stride_width,
   e007e:	2401      	movs	r4, #1

  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
      /*dilation_rate_height=*/1,
      /*dilation_rate_width=*/1, height, width, params->filter_height,
      params->filter_width, params->padding, &out_height, &out_width);
   e0080:	9302      	str	r3, [sp, #8]

struct OpData {
  TfLitePaddingValues padding;
};

TfLiteStatus CalculateOpData(const TfLiteContext* context,
   e0082:	4615      	mov	r5, r2
   e0084:	9400      	str	r4, [sp, #0]
   e0086:	4633      	mov	r3, r6
   e0088:	9a02      	ldr	r2, [sp, #8]
   e008a:	4659      	mov	r1, fp
   e008c:	4650      	mov	r0, sl
   e008e:	f7fd f9a8 	bl	dd3e2 <_ZN6tflite14ComputeOutSizeE13TfLitePaddingiiii>
                              dilation_rate_width);
  *out_height = ComputeOutSize(padding, in_height, filter_height, stride_height,
   e0092:	9400      	str	r4, [sp, #0]

inline TfLitePaddingValues ComputePaddingHeightWidth(
    int stride_height, int stride_width, int dilation_rate_height,
    int dilation_rate_width, int in_height, int in_width, int filter_height,
    int filter_width, TfLitePadding padding, int* out_height, int* out_width) {
  *out_width = ComputeOutSize(padding, in_width, filter_width, stride_width,
   e0094:	9003      	str	r0, [sp, #12]
                              dilation_rate_width);
  *out_height = ComputeOutSize(padding, in_height, filter_height, stride_height,
   e0096:	464b      	mov	r3, r9
   e0098:	4642      	mov	r2, r8
   e009a:	4639      	mov	r1, r7
   e009c:	4650      	mov	r0, sl
   e009e:	f7fd f9a0 	bl	dd3e2 <_ZN6tflite14ComputeOutSizeE13TfLitePaddingiiii>
inline int ComputePaddingWithOffset(int stride, int dilation_rate, int in_size,
                                    int filter_size, int out_size,
                                    int* offset) {
  int effective_filter_size = (filter_size - 1) * dilation_rate + 1;
  int total_padding =
      ((out_size - 1) * stride + effective_filter_size - in_size);
   e00a2:	9b03      	ldr	r3, [sp, #12]
   e00a4:	1e5c      	subs	r4, r3, #1
   e00a6:	9b02      	ldr	r3, [sp, #8]
   e00a8:	3801      	subs	r0, #1
   e00aa:	fb06 3604 	mla	r6, r6, r4, r3
   e00ae:	fb09 8800 	mla	r8, r9, r0, r8
   e00b2:	ebcb 0606 	rsb	r6, fp, r6
   e00b6:	ebc7 0708 	rsb	r7, r7, r8
  total_padding = total_padding > 0 ? total_padding : 0;
   e00ba:	ea26 76e6 	bic.w	r6, r6, r6, asr #31

  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
      /*dilation_rate_height=*/1,
      /*dilation_rate_width=*/1, height, width, params->filter_height,
      params->filter_width, params->padding, &out_height, &out_width);
   e00be:	1073      	asrs	r3, r6, #1
   e00c0:	ea27 77e7 	bic.w	r7, r7, r7, asr #31
   e00c4:	602b      	str	r3, [r5, #0]
   e00c6:	f006 0601 	and.w	r6, r6, #1
   e00ca:	107b      	asrs	r3, r7, #1

  return kTfLiteOk;
}
   e00cc:	2000      	movs	r0, #0

  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
      /*dilation_rate_height=*/1,
      /*dilation_rate_width=*/1, height, width, params->filter_height,
      params->filter_width, params->padding, &out_height, &out_width);
   e00ce:	f007 0701 	and.w	r7, r7, #1
   e00d2:	606b      	str	r3, [r5, #4]
   e00d4:	60ae      	str	r6, [r5, #8]
   e00d6:	60ef      	str	r7, [r5, #12]

  return kTfLiteOk;
}
   e00d8:	b005      	add	sp, #20
   e00da:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	...

000e00e0 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode>:
      return kTfLiteError;
  }
  return kTfLiteOk;
}

TfLiteStatus MaxEval(TfLiteContext* context, TfLiteNode* node) {
   e00e0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e00e4:	680b      	ldr	r3, [r1, #0]
   e00e6:	f8d0 a008 	ldr.w	sl, [r0, #8]
   e00ea:	685b      	ldr	r3, [r3, #4]
  auto* params = reinterpret_cast<TfLitePoolParams*>(node->builtin_data);
   e00ec:	694d      	ldr	r5, [r1, #20]
   e00ee:	2438      	movs	r4, #56	; 0x38
   e00f0:	fb04 f803 	mul.w	r8, r4, r3
      return kTfLiteError;
  }
  return kTfLiteOk;
}

TfLiteStatus MaxEval(TfLiteContext* context, TfLiteNode* node) {
   e00f4:	b09f      	sub	sp, #124	; 0x7c
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e00f6:	684b      	ldr	r3, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e00f8:	eb0a 0708 	add.w	r7, sl, r8
   e00fc:	4681      	mov	r9, r0
  OpData data;

  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  TF_LITE_ENSURE_STATUS(CalculateOpData(context, params, input, output, &data));
   e00fe:	aa05      	add	r2, sp, #20
   e0100:	4639      	mov	r1, r7
   e0102:	4628      	mov	r0, r5
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0104:	f8d3 b004 	ldr.w	fp, [r3, #4]
   e0108:	f7ff ffaa 	bl	e0060 <_ZN6tflite3ops5micro7pooling12_GLOBAL__N_115CalculateOpDataEPK13TfLiteContextPK16TfLitePoolParamsPK12TfLiteTensorSC_PNS3_6OpDataE.isra.2>
   e010c:	4606      	mov	r6, r0
   e010e:	2800      	cmp	r0, #0
   e0110:	f040 8085 	bne.w	e021e <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x13e>

  switch (input->type) {
   e0114:	f81a 0008 	ldrb.w	r0, [sl, r8]
   e0118:	2801      	cmp	r0, #1
   e011a:	fb04 a40b 	mla	r4, r4, fp, sl
   e011e:	d002      	beq.n	e0126 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x46>
   e0120:	2803      	cmp	r0, #3
   e0122:	d041      	beq.n	e01a8 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0xc8>
   e0124:	e073      	b.n	e020e <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x12e>

void MaxEvalFloat(TfLiteContext* context, TfLiteNode* node,
                  TfLitePoolParams* params, OpData* data,
                  const TfLiteTensor* input, TfLiteTensor* output) {
  float activation_min, activation_max;
  CalculateActivationRange(params->activation, &activation_min,
   e0126:	7d2b      	ldrb	r3, [r5, #20]
// Calculates the useful range of an activation layer given its activation
// tensor.a
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
   e0128:	2b01      	cmp	r3, #1
   e012a:	d011      	beq.n	e0150 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x70>
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
   e012c:	2b03      	cmp	r3, #3
   e012e:	d012      	beq.n	e0156 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x76>
  } else if (activation == kTfLiteActRelu1) {
    *activation_min = -1;
    *activation_max = 1;
  } else {
    *activation_min = std::numeric_limits<T>::lowest();
    *activation_max = std::numeric_limits<T>::max();
   e0130:	ed9f 7a3d 	vldr	s14, [pc, #244]	; e0228 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x148>
   e0134:	eddf 6a3d 	vldr	s13, [pc, #244]	; e022c <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x14c>
   e0138:	2b02      	cmp	r3, #2
   e013a:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   e013e:	bf18      	it	ne
   e0140:	eef0 7a47 	vmovne.f32	s15, s14
   e0144:	eebf 7a00 	vmov.f32	s14, #240	; 0xbf800000 -1.0
   e0148:	bf18      	it	ne
   e014a:	eeb0 7a66 	vmovne.f32	s14, s13
   e014e:	e006      	b.n	e015e <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x7e>
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
   e0150:	eddf 7a35 	vldr	s15, [pc, #212]	; e0228 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x148>
   e0154:	e001      	b.n	e015a <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x7a>
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
    *activation_max = 6;
   e0156:	eef1 7a08 	vmov.f32	s15, #24	; 0x40c00000  6.0
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
   e015a:	ed9f 7a35 	vldr	s14, [pc, #212]	; e0230 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x150>
                           &activation_max);

  tflite::PoolParams op_params;
  op_params.stride_height = params->stride_height;
   e015e:	68ab      	ldr	r3, [r5, #8]
   e0160:	9316      	str	r3, [sp, #88]	; 0x58
  op_params.stride_width = params->stride_width;
   e0162:	686b      	ldr	r3, [r5, #4]
   e0164:	9317      	str	r3, [sp, #92]	; 0x5c
  op_params.filter_height = params->filter_height;
   e0166:	692b      	ldr	r3, [r5, #16]
   e0168:	9318      	str	r3, [sp, #96]	; 0x60
  op_params.filter_width = params->filter_width;
   e016a:	68eb      	ldr	r3, [r5, #12]
   e016c:	9319      	str	r3, [sp, #100]	; 0x64
  op_params.padding_values.height = data->padding.height;
   e016e:	9b06      	ldr	r3, [sp, #24]
   e0170:	f8ad 3050 	strh.w	r3, [sp, #80]	; 0x50
  op_params.padding_values.width = data->padding.width;
  op_params.float_activation_min = activation_min;
  op_params.float_activation_max = activation_max;
  reference_ops::MaxPool(op_params, GetTensorShape(input),
   e0174:	4639      	mov	r1, r7
  op_params.stride_height = params->stride_height;
  op_params.stride_width = params->stride_width;
  op_params.filter_height = params->filter_height;
  op_params.filter_width = params->filter_width;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
   e0176:	9b05      	ldr	r3, [sp, #20]
   e0178:	f8ad 304e 	strh.w	r3, [sp, #78]	; 0x4e
  op_params.float_activation_min = activation_min;
  op_params.float_activation_max = activation_max;
  reference_ops::MaxPool(op_params, GetTensorShape(input),
   e017c:	a809      	add	r0, sp, #36	; 0x24
  op_params.stride_width = params->stride_width;
  op_params.filter_height = params->filter_height;
  op_params.filter_width = params->filter_width;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
  op_params.float_activation_min = activation_min;
   e017e:	ed8d 7a1c 	vstr	s14, [sp, #112]	; 0x70
  op_params.float_activation_max = activation_max;
   e0182:	edcd 7a1d 	vstr	s15, [sp, #116]	; 0x74
  reference_ops::MaxPool(op_params, GetTensorShape(input),
   e0186:	f7f7 fca0 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
                         GetTensorData<float>(input), GetTensorShape(output),
   e018a:	4621      	mov	r1, r4
   e018c:	a80e      	add	r0, sp, #56	; 0x38
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e018e:	687d      	ldr	r5, [r7, #4]
   e0190:	f7f7 fc9b 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e0194:	b104      	cbz	r4, e0198 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0xb8>
   e0196:	6864      	ldr	r4, [r4, #4]
                         GetTensorData<float>(output));
   e0198:	9400      	str	r4, [sp, #0]
   e019a:	ab0e      	add	r3, sp, #56	; 0x38
   e019c:	462a      	mov	r2, r5
   e019e:	a909      	add	r1, sp, #36	; 0x24
   e01a0:	a813      	add	r0, sp, #76	; 0x4c
   e01a2:	f7ff fcdb 	bl	dfb5c <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf>
   e01a6:	e02b      	b.n	e0200 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x120>
void MaxEvalQuantizedUInt8(TfLiteContext* context, TfLiteNode* node,
                           TfLitePoolParams* params, OpData* data,
                           const TfLiteTensor* input, TfLiteTensor* output) {
  int32_t activation_min, activation_max;
  CalculateActivationRangeUint8(params->activation, output, &activation_min,
                                &activation_max);
   e01a8:	7d28      	ldrb	r0, [r5, #20]
   e01aa:	ab04      	add	r3, sp, #16
   e01ac:	aa03      	add	r2, sp, #12
   e01ae:	4621      	mov	r1, r4
   e01b0:	f004 fd6c 	bl	e4c8c <_ZN6tflite29CalculateActivationRangeUint8E21TfLiteFusedActivationP12TfLiteTensorPlS3_>

  tflite::PoolParams op_params;
  op_params.stride_height = params->stride_height;
   e01b4:	68ab      	ldr	r3, [r5, #8]
   e01b6:	9316      	str	r3, [sp, #88]	; 0x58
  op_params.stride_width = params->stride_width;
   e01b8:	686b      	ldr	r3, [r5, #4]
   e01ba:	9317      	str	r3, [sp, #92]	; 0x5c
  op_params.filter_height = params->filter_height;
   e01bc:	692b      	ldr	r3, [r5, #16]
   e01be:	9318      	str	r3, [sp, #96]	; 0x60
  op_params.filter_width = params->filter_width;
   e01c0:	68eb      	ldr	r3, [r5, #12]
   e01c2:	9319      	str	r3, [sp, #100]	; 0x64
  op_params.padding_values.height = data->padding.height;
   e01c4:	9b06      	ldr	r3, [sp, #24]
   e01c6:	f8ad 3050 	strh.w	r3, [sp, #80]	; 0x50
  op_params.padding_values.width = data->padding.width;
   e01ca:	9b05      	ldr	r3, [sp, #20]
   e01cc:	f8ad 304e 	strh.w	r3, [sp, #78]	; 0x4e
  op_params.quantized_activation_min = activation_min;
   e01d0:	9b03      	ldr	r3, [sp, #12]
   e01d2:	931a      	str	r3, [sp, #104]	; 0x68
  op_params.quantized_activation_max = activation_max;
  reference_ops::MaxPool(op_params, GetTensorShape(input),
   e01d4:	4639      	mov	r1, r7
  op_params.filter_height = params->filter_height;
  op_params.filter_width = params->filter_width;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
  op_params.quantized_activation_min = activation_min;
  op_params.quantized_activation_max = activation_max;
   e01d6:	9b04      	ldr	r3, [sp, #16]
   e01d8:	931b      	str	r3, [sp, #108]	; 0x6c
  reference_ops::MaxPool(op_params, GetTensorShape(input),
   e01da:	a809      	add	r0, sp, #36	; 0x24
   e01dc:	f7f7 fc75 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
                         GetTensorData<uint8_t>(input), GetTensorShape(output),
   e01e0:	4621      	mov	r1, r4
   e01e2:	a80e      	add	r0, sp, #56	; 0x38
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e01e4:	687d      	ldr	r5, [r7, #4]
   e01e6:	f7f7 fc70 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e01ea:	b10c      	cbz	r4, e01f0 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x110>
   e01ec:	6863      	ldr	r3, [r4, #4]
   e01ee:	e000      	b.n	e01f2 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x112>
   e01f0:	4633      	mov	r3, r6
                         GetTensorData<uint8_t>(output));
   e01f2:	9300      	str	r3, [sp, #0]
   e01f4:	462a      	mov	r2, r5
   e01f6:	ab0e      	add	r3, sp, #56	; 0x38
   e01f8:	a909      	add	r1, sp, #36	; 0x24
   e01fa:	a813      	add	r0, sp, #76	; 0x4c
   e01fc:	f7ff fd8e 	bl	dfd1c <_ZN6tflite13reference_ops7MaxPoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph>
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
  op_params.quantized_activation_min = activation_min;
  op_params.quantized_activation_max = activation_max;
  reference_ops::MaxPool(op_params, GetTensorShape(input),
                         GetTensorData<uint8_t>(input), GetTensorShape(output),
   e0200:	a80e      	add	r0, sp, #56	; 0x38
   e0202:	f7f7 f9b2 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.filter_width = params->filter_width;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
  op_params.quantized_activation_min = activation_min;
  op_params.quantized_activation_max = activation_max;
  reference_ops::MaxPool(op_params, GetTensorShape(input),
   e0206:	a809      	add	r0, sp, #36	; 0x24
   e0208:	f7f7 f9af 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   e020c:	e008      	b.n	e0220 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x140>
      break;
    case kTfLiteUInt8:
      MaxEvalQuantizedUInt8(context, node, params, &data, input, output);
      break;
    default:
      context->ReportError(context, "Type %s not currently supported.",
   e020e:	f8d9 4014 	ldr.w	r4, [r9, #20]
   e0212:	f7f3 ff8b 	bl	d412c <TfLiteTypeGetName>
                           TfLiteTypeGetName(input->type));
   e0216:	4907      	ldr	r1, [pc, #28]	; (e0234 <_ZN6tflite3ops5micro7pooling7MaxEvalEP13TfLiteContextP10TfLiteNode+0x154>)
   e0218:	4602      	mov	r2, r0
   e021a:	4648      	mov	r0, r9
   e021c:	47a0      	blx	r4
  OpData data;

  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  TF_LITE_ENSURE_STATUS(CalculateOpData(context, params, input, output, &data));
   e021e:	2601      	movs	r6, #1
      context->ReportError(context, "Type %s not currently supported.",
                           TfLiteTypeGetName(input->type));
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   e0220:	4630      	mov	r0, r6
   e0222:	b01f      	add	sp, #124	; 0x7c
   e0224:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e0228:	7f7fffff 	.word	0x7f7fffff
   e022c:	ff7fffff 	.word	0xff7fffff
   e0230:	00000000 	.word	0x00000000
   e0234:	000eba67 	.word	0x000eba67

000e0238 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

TfLiteStatus AverageEval(TfLiteContext* context, TfLiteNode* node) {
   e0238:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e023c:	680b      	ldr	r3, [r1, #0]
   e023e:	f8d0 a008 	ldr.w	sl, [r0, #8]
   e0242:	685b      	ldr	r3, [r3, #4]
  auto* params = reinterpret_cast<TfLitePoolParams*>(node->builtin_data);
   e0244:	694d      	ldr	r5, [r1, #20]
   e0246:	2438      	movs	r4, #56	; 0x38
   e0248:	fb04 f803 	mul.w	r8, r4, r3

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

TfLiteStatus AverageEval(TfLiteContext* context, TfLiteNode* node) {
   e024c:	b09f      	sub	sp, #124	; 0x7c
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e024e:	684b      	ldr	r3, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e0250:	eb0a 0608 	add.w	r6, sl, r8
   e0254:	4681      	mov	r9, r0
  OpData data;

  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  TF_LITE_ENSURE_STATUS(CalculateOpData(context, params, input, output, &data));
   e0256:	aa05      	add	r2, sp, #20
   e0258:	4631      	mov	r1, r6
   e025a:	4628      	mov	r0, r5
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e025c:	f8d3 b004 	ldr.w	fp, [r3, #4]
   e0260:	f7ff fefe 	bl	e0060 <_ZN6tflite3ops5micro7pooling12_GLOBAL__N_115CalculateOpDataEPK13TfLiteContextPK16TfLitePoolParamsPK12TfLiteTensorSC_PNS3_6OpDataE.isra.2>
   e0264:	4607      	mov	r7, r0
   e0266:	2800      	cmp	r0, #0
   e0268:	f040 80b4 	bne.w	e03d4 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x19c>

  // Inputs and outputs share the same type, guarenteed by the converter.
  switch (input->type) {
   e026c:	f81a 0008 	ldrb.w	r0, [sl, r8]
   e0270:	2803      	cmp	r0, #3
   e0272:	fb04 a40b 	mla	r4, r4, fp, sl
   e0276:	d045      	beq.n	e0304 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0xcc>
   e0278:	2809      	cmp	r0, #9
   e027a:	d070      	beq.n	e035e <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x126>
   e027c:	2801      	cmp	r0, #1
   e027e:	f040 80a1 	bne.w	e03c4 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x18c>

void AverageEvalFloat(const TfLiteContext* context, const TfLiteNode* node,
                      const TfLitePoolParams* params, const OpData* data,
                      const TfLiteTensor* input, TfLiteTensor* output) {
  float activation_min, activation_max;
  CalculateActivationRange(params->activation, &activation_min,
   e0282:	7d2b      	ldrb	r3, [r5, #20]
// Calculates the useful range of an activation layer given its activation
// tensor.a
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
   e0284:	2b01      	cmp	r3, #1
   e0286:	d011      	beq.n	e02ac <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x74>
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
   e0288:	2b03      	cmp	r3, #3
   e028a:	d012      	beq.n	e02b2 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x7a>
  } else if (activation == kTfLiteActRelu1) {
    *activation_min = -1;
    *activation_max = 1;
  } else {
    *activation_min = std::numeric_limits<T>::lowest();
    *activation_max = std::numeric_limits<T>::max();
   e028c:	ed9f 7a54 	vldr	s14, [pc, #336]	; e03e0 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x1a8>
   e0290:	eddf 6a54 	vldr	s13, [pc, #336]	; e03e4 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x1ac>
   e0294:	2b02      	cmp	r3, #2
   e0296:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   e029a:	bf18      	it	ne
   e029c:	eef0 7a47 	vmovne.f32	s15, s14
   e02a0:	eebf 7a00 	vmov.f32	s14, #240	; 0xbf800000 -1.0
   e02a4:	bf18      	it	ne
   e02a6:	eeb0 7a66 	vmovne.f32	s14, s13
   e02aa:	e006      	b.n	e02ba <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x82>
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
   e02ac:	eddf 7a4c 	vldr	s15, [pc, #304]	; e03e0 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x1a8>
   e02b0:	e001      	b.n	e02b6 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x7e>
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
    *activation_max = 6;
   e02b2:	eef1 7a08 	vmov.f32	s15, #24	; 0x40c00000  6.0
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
   e02b6:	ed9f 7a4c 	vldr	s14, [pc, #304]	; e03e8 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x1b0>
                           &activation_max);

  PoolParams op_params;
  op_params.stride_height = params->stride_height;
   e02ba:	68ab      	ldr	r3, [r5, #8]
   e02bc:	9316      	str	r3, [sp, #88]	; 0x58
  op_params.stride_width = params->stride_width;
   e02be:	686b      	ldr	r3, [r5, #4]
   e02c0:	9317      	str	r3, [sp, #92]	; 0x5c
  op_params.filter_height = params->filter_height;
   e02c2:	692b      	ldr	r3, [r5, #16]
   e02c4:	9318      	str	r3, [sp, #96]	; 0x60
  op_params.filter_width = params->filter_width;
   e02c6:	68eb      	ldr	r3, [r5, #12]
   e02c8:	9319      	str	r3, [sp, #100]	; 0x64
  op_params.padding_values.height = data->padding.height;
   e02ca:	9b06      	ldr	r3, [sp, #24]
   e02cc:	f8ad 3050 	strh.w	r3, [sp, #80]	; 0x50
  op_params.padding_values.width = data->padding.width;
  op_params.float_activation_min = activation_min;
  op_params.float_activation_max = activation_max;
  reference_ops::AveragePool(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
   e02d0:	4631      	mov	r1, r6
  op_params.stride_height = params->stride_height;
  op_params.stride_width = params->stride_width;
  op_params.filter_height = params->filter_height;
  op_params.filter_width = params->filter_width;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
   e02d2:	9b05      	ldr	r3, [sp, #20]
   e02d4:	f8ad 304e 	strh.w	r3, [sp, #78]	; 0x4e
  op_params.float_activation_min = activation_min;
  op_params.float_activation_max = activation_max;
  reference_ops::AveragePool(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
   e02d8:	a809      	add	r0, sp, #36	; 0x24
  op_params.stride_width = params->stride_width;
  op_params.filter_height = params->filter_height;
  op_params.filter_width = params->filter_width;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
  op_params.float_activation_min = activation_min;
   e02da:	ed8d 7a1c 	vstr	s14, [sp, #112]	; 0x70
  op_params.float_activation_max = activation_max;
   e02de:	edcd 7a1d 	vstr	s15, [sp, #116]	; 0x74
  reference_ops::AveragePool(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
   e02e2:	f7f7 fbf2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorShape(output), GetTensorData<float>(output));
   e02e6:	4621      	mov	r1, r4
   e02e8:	a80e      	add	r0, sp, #56	; 0x38
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e02ea:	6875      	ldr	r5, [r6, #4]
   e02ec:	f7f7 fbed 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e02f0:	b104      	cbz	r4, e02f4 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0xbc>
   e02f2:	6864      	ldr	r4, [r4, #4]
   e02f4:	9400      	str	r4, [sp, #0]
   e02f6:	ab0e      	add	r3, sp, #56	; 0x38
   e02f8:	462a      	mov	r2, r5
   e02fa:	a909      	add	r1, sp, #36	; 0x24
   e02fc:	a813      	add	r0, sp, #76	; 0x4c
   e02fe:	f7ff fa8b 	bl	df818 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKfS6_Pf>
   e0302:	e058      	b.n	e03b6 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x17e>
void AverageEvalUint8(const TfLiteContext* context, const TfLiteNode* node,
                      const TfLitePoolParams* params, const OpData* data,
                      const TfLiteTensor* input, TfLiteTensor* output) {
  int32_t activation_min, activation_max;
  CalculateActivationRangeUint8(params->activation, output, &activation_min,
                                &activation_max);
   e0304:	7d28      	ldrb	r0, [r5, #20]
   e0306:	ab04      	add	r3, sp, #16
   e0308:	aa03      	add	r2, sp, #12
   e030a:	4621      	mov	r1, r4
   e030c:	f004 fcbe 	bl	e4c8c <_ZN6tflite29CalculateActivationRangeUint8E21TfLiteFusedActivationP12TfLiteTensorPlS3_>

  PoolParams op_params;
  op_params.stride_height = params->stride_height;
   e0310:	68ab      	ldr	r3, [r5, #8]
   e0312:	9316      	str	r3, [sp, #88]	; 0x58
  op_params.stride_width = params->stride_width;
   e0314:	686b      	ldr	r3, [r5, #4]
   e0316:	9317      	str	r3, [sp, #92]	; 0x5c
  op_params.filter_height = params->filter_height;
   e0318:	692b      	ldr	r3, [r5, #16]
   e031a:	9318      	str	r3, [sp, #96]	; 0x60
  op_params.filter_width = params->filter_width;
   e031c:	68eb      	ldr	r3, [r5, #12]
   e031e:	9319      	str	r3, [sp, #100]	; 0x64
  op_params.padding_values.height = data->padding.height;
   e0320:	9b06      	ldr	r3, [sp, #24]
   e0322:	f8ad 3050 	strh.w	r3, [sp, #80]	; 0x50
  op_params.padding_values.width = data->padding.width;
   e0326:	9b05      	ldr	r3, [sp, #20]
   e0328:	f8ad 304e 	strh.w	r3, [sp, #78]	; 0x4e
  op_params.quantized_activation_min = activation_min;
   e032c:	9b03      	ldr	r3, [sp, #12]
   e032e:	931a      	str	r3, [sp, #104]	; 0x68
  op_params.quantized_activation_max = activation_max;
  reference_ops::AveragePool(
      op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e0330:	4631      	mov	r1, r6
  op_params.filter_height = params->filter_height;
  op_params.filter_width = params->filter_width;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
  op_params.quantized_activation_min = activation_min;
  op_params.quantized_activation_max = activation_max;
   e0332:	9b04      	ldr	r3, [sp, #16]
   e0334:	931b      	str	r3, [sp, #108]	; 0x6c
  reference_ops::AveragePool(
      op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e0336:	a809      	add	r0, sp, #36	; 0x24
   e0338:	f7f7 fbc7 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorShape(output), GetTensorData<uint8_t>(output));
   e033c:	4621      	mov	r1, r4
   e033e:	a80e      	add	r0, sp, #56	; 0x38
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e0340:	6875      	ldr	r5, [r6, #4]
   e0342:	f7f7 fbc2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e0346:	b10c      	cbz	r4, e034c <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x114>
   e0348:	6863      	ldr	r3, [r4, #4]
   e034a:	e000      	b.n	e034e <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x116>
   e034c:	463b      	mov	r3, r7
   e034e:	9300      	str	r3, [sp, #0]
   e0350:	462a      	mov	r2, r5
   e0352:	ab0e      	add	r3, sp, #56	; 0x38
   e0354:	a909      	add	r1, sp, #36	; 0x24
   e0356:	a813      	add	r0, sp, #76	; 0x4c
   e0358:	f7ff fb36 	bl	df9c8 <_ZN6tflite13reference_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKhS6_Ph>
   e035c:	e02b      	b.n	e03b6 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x17e>
void AverageEvalInt8(const TfLiteContext* context, const TfLiteNode* node,
                     const TfLitePoolParams* params, const OpData* data,
                     const TfLiteTensor* input, TfLiteTensor* output) {
  int32_t activation_min, activation_max;
  CalculateActivationRangeInt8(params->activation, output, &activation_min,
                               &activation_max);
   e035e:	7d28      	ldrb	r0, [r5, #20]
   e0360:	ab04      	add	r3, sp, #16
   e0362:	aa03      	add	r2, sp, #12
   e0364:	4621      	mov	r1, r4
   e0366:	f004 fd8b 	bl	e4e80 <_ZN6tflite28CalculateActivationRangeInt8E21TfLiteFusedActivationP12TfLiteTensorPlS3_>

  PoolParams op_params;
  op_params.stride_height = params->stride_height;
   e036a:	68ab      	ldr	r3, [r5, #8]
   e036c:	9316      	str	r3, [sp, #88]	; 0x58
  op_params.stride_width = params->stride_width;
   e036e:	686b      	ldr	r3, [r5, #4]
   e0370:	9317      	str	r3, [sp, #92]	; 0x5c
  op_params.filter_height = params->filter_height;
   e0372:	692b      	ldr	r3, [r5, #16]
   e0374:	9318      	str	r3, [sp, #96]	; 0x60
  op_params.filter_width = params->filter_width;
   e0376:	68eb      	ldr	r3, [r5, #12]
   e0378:	9319      	str	r3, [sp, #100]	; 0x64
  op_params.padding_values.height = data->padding.height;
   e037a:	9b06      	ldr	r3, [sp, #24]
   e037c:	f8ad 3050 	strh.w	r3, [sp, #80]	; 0x50
  op_params.padding_values.width = data->padding.width;
   e0380:	9b05      	ldr	r3, [sp, #20]
   e0382:	f8ad 304e 	strh.w	r3, [sp, #78]	; 0x4e
  op_params.quantized_activation_min = activation_min;
   e0386:	9b03      	ldr	r3, [sp, #12]
   e0388:	931a      	str	r3, [sp, #104]	; 0x68
  op_params.quantized_activation_max = activation_max;
  reference_integer_ops::AveragePool(
      op_params, GetTensorShape(input), GetTensorData<int8_t>(input),
   e038a:	4631      	mov	r1, r6
  op_params.filter_height = params->filter_height;
  op_params.filter_width = params->filter_width;
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
  op_params.quantized_activation_min = activation_min;
  op_params.quantized_activation_max = activation_max;
   e038c:	9b04      	ldr	r3, [sp, #16]
   e038e:	931b      	str	r3, [sp, #108]	; 0x6c
  reference_integer_ops::AveragePool(
      op_params, GetTensorShape(input), GetTensorData<int8_t>(input),
   e0390:	a809      	add	r0, sp, #36	; 0x24
   e0392:	f7f7 fb9a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorShape(output), GetTensorData<int8_t>(output));
   e0396:	4621      	mov	r1, r4
   e0398:	a80e      	add	r0, sp, #56	; 0x38
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e039a:	6875      	ldr	r5, [r6, #4]
   e039c:	f7f7 fb95 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e03a0:	b10c      	cbz	r4, e03a6 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x16e>
   e03a2:	6863      	ldr	r3, [r4, #4]
   e03a4:	e000      	b.n	e03a8 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x170>
   e03a6:	463b      	mov	r3, r7
   e03a8:	9300      	str	r3, [sp, #0]
   e03aa:	462a      	mov	r2, r5
   e03ac:	ab0e      	add	r3, sp, #56	; 0x38
   e03ae:	a909      	add	r1, sp, #36	; 0x24
   e03b0:	a813      	add	r0, sp, #76	; 0x4c
   e03b2:	f7ff fd86 	bl	dfec2 <_ZN6tflite21reference_integer_ops11AveragePoolERKNS_10PoolParamsERKNS_12RuntimeShapeEPKaS6_Pa>
   e03b6:	a80e      	add	r0, sp, #56	; 0x38
   e03b8:	f7f7 f8d7 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.padding_values.height = data->padding.height;
  op_params.padding_values.width = data->padding.width;
  op_params.quantized_activation_min = activation_min;
  op_params.quantized_activation_max = activation_max;
  reference_integer_ops::AveragePool(
      op_params, GetTensorShape(input), GetTensorData<int8_t>(input),
   e03bc:	a809      	add	r0, sp, #36	; 0x24
   e03be:	f7f7 f8d4 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   e03c2:	e008      	b.n	e03d6 <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x19e>
      break;
    case kTfLiteInt8:
      AverageEvalInt8(context, node, params, &data, input, output);
      break;
    default:
      context->ReportError(context, "Input type %s is not currently supported",
   e03c4:	f8d9 4014 	ldr.w	r4, [r9, #20]
   e03c8:	f7f3 feb0 	bl	d412c <TfLiteTypeGetName>
                           TfLiteTypeGetName(input->type));
   e03cc:	4907      	ldr	r1, [pc, #28]	; (e03ec <_ZN6tflite3ops5micro7pooling11AverageEvalEP13TfLiteContextP10TfLiteNode+0x1b4>)
   e03ce:	4602      	mov	r2, r0
   e03d0:	4648      	mov	r0, r9
   e03d2:	47a0      	blx	r4
  OpData data;

  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  TF_LITE_ENSURE_STATUS(CalculateOpData(context, params, input, output, &data));
   e03d4:	2701      	movs	r7, #1
      context->ReportError(context, "Input type %s is not currently supported",
                           TfLiteTypeGetName(input->type));
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   e03d6:	4638      	mov	r0, r7
   e03d8:	b01f      	add	sp, #124	; 0x7c
   e03da:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e03de:	bf00      	nop
   e03e0:	7f7fffff 	.word	0x7f7fffff
   e03e4:	ff7fffff 	.word	0xff7fffff
   e03e8:	00000000 	.word	0x00000000
   e03ec:	000eba88 	.word	0x000eba88

000e03f0 <_ZN6tflite3ops5micro24Register_AVERAGE_POOL_2DEv>:
      pooling::Free,
      pooling::Prepare,
      pooling::AverageEval,
  };
  return &r;
}
   e03f0:	4800      	ldr	r0, [pc, #0]	; (e03f4 <_ZN6tflite3ops5micro24Register_AVERAGE_POOL_2DEv+0x4>)
   e03f2:	4770      	bx	lr
   e03f4:	2003c0b0 	.word	0x2003c0b0

000e03f8 <_ZN6tflite3ops5micro20Register_MAX_POOL_2DEv>:

TfLiteRegistration* Register_MAX_POOL_2D() {
  static TfLiteRegistration r = {pooling::Init, pooling::Free, pooling::Prepare,
                                 pooling::MaxEval};
  return &r;
}
   e03f8:	4800      	ldr	r0, [pc, #0]	; (e03fc <_ZN6tflite3ops5micro20Register_MAX_POOL_2DEv+0x4>)
   e03fa:	4770      	bx	lr
   e03fc:	2003c0d0 	.word	0x2003c0d0

000e0400 <_ZN6tflite3ops5micro11activations12PreluPrepareEP13TfLiteContextP10TfLiteNode>:
namespace micro {
namespace activations {

TfLiteStatus PreluPrepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   e0400:	2000      	movs	r0, #0
   e0402:	4770      	bx	lr

000e0404 <_ZN6tflite3ops5micro14Register_PRELUEv>:

TfLiteRegistration* Register_PRELU() {
  static TfLiteRegistration r = {nullptr, nullptr, activations::PreluPrepare,
                                 activations::PreluEval};
  return &r;
}
   e0404:	4800      	ldr	r0, [pc, #0]	; (e0408 <_ZN6tflite3ops5micro14Register_PRELUEv+0x4>)
   e0406:	4770      	bx	lr
   e0408:	2003c0f0 	.word	0x2003c0f0

000e040c <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf>:
}

inline void BroadcastPrelu4DSlowFloat(
    const RuntimeShape& unextended_input1_shape, const float* input1_data,
    const RuntimeShape& unextended_input2_shape, const float* input2_data,
    const RuntimeShape& unextended_output_shape, float* output_data) {
   e040c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e0410:	469b      	mov	fp, r3
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   e0412:	6803      	ldr	r3, [r0, #0]
}

inline void BroadcastPrelu4DSlowFloat(
    const RuntimeShape& unextended_input1_shape, const float* input1_data,
    const RuntimeShape& unextended_input2_shape, const float* input2_data,
    const RuntimeShape& unextended_output_shape, float* output_data) {
   e0414:	b09b      	sub	sp, #108	; 0x6c
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   e0416:	2b04      	cmp	r3, #4
}

inline void BroadcastPrelu4DSlowFloat(
    const RuntimeShape& unextended_input1_shape, const float* input1_data,
    const RuntimeShape& unextended_input2_shape, const float* input2_data,
    const RuntimeShape& unextended_output_shape, float* output_data) {
   e0418:	4616      	mov	r6, r2
   e041a:	4604      	mov	r4, r0
   e041c:	468a      	mov	sl, r1
   e041e:	9a24      	ldr	r2, [sp, #144]	; 0x90
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
   e0420:	dd01      	ble.n	e0426 <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0x1a>
   e0422:	f005 f867 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
   e0426:	6833      	ldr	r3, [r6, #0]
   e0428:	2b04      	cmp	r3, #4
   e042a:	dcfa      	bgt.n	e0422 <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0x16>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   e042c:	6813      	ldr	r3, [r2, #0]
   e042e:	2b04      	cmp	r3, #4
   e0430:	dcf7      	bgt.n	e0422 <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0x16>
  // (a) as Dims<4>-dependent code is eliminated, the reliance on this should be
  // reduced, and (b) some kernels are stricly 4-D, but then the shapes of their
  // inputs should already be 4-D, so this function should not be needed.
  inline static RuntimeShape ExtendedShape(int new_shape_size,
                                           const RuntimeShape& shape) {
    return RuntimeShape(new_shape_size, shape, 1);
   e0432:	2301      	movs	r3, #1
   e0434:	2104      	movs	r1, #4
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);
   e0436:	ad0a      	add	r5, sp, #40	; 0x28
   e0438:	a805      	add	r0, sp, #20
   e043a:	f7f7 f8da 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   e043e:	4620      	mov	r0, r4
   e0440:	ab12      	add	r3, sp, #72	; 0x48
   e0442:	462a      	mov	r2, r5
   e0444:	4631      	mov	r1, r6
   e0446:	f7f7 fbe9 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   e044a:	2400      	movs	r4, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   e044c:	9503      	str	r5, [sp, #12]
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   e044e:	2100      	movs	r1, #0
   e0450:	a805      	add	r0, sp, #20
   e0452:	f7f7 f895 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0456:	4284      	cmp	r4, r0
   e0458:	da47      	bge.n	e04ea <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0xde>
   e045a:	2500      	movs	r5, #0
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   e045c:	2101      	movs	r1, #1
   e045e:	a805      	add	r0, sp, #20
   e0460:	f7f7 f88e 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0464:	4285      	cmp	r5, r0
   e0466:	da3e      	bge.n	e04e6 <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0xda>
   e0468:	2600      	movs	r6, #0
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   e046a:	2102      	movs	r1, #2
   e046c:	a805      	add	r0, sp, #20
   e046e:	f7f7 f887 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0472:	4286      	cmp	r6, r0
   e0474:	da35      	bge.n	e04e2 <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0xd6>
   e0476:	2700      	movs	r7, #0
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   e0478:	2103      	movs	r1, #3
   e047a:	a805      	add	r0, sp, #20
   e047c:	f7f7 f880 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0480:	4287      	cmp	r7, r0
   e0482:	da2c      	bge.n	e04de <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0xd2>
          auto out_idx = Offset(output_shape, b, y, x, c);
   e0484:	9700      	str	r7, [sp, #0]
   e0486:	4633      	mov	r3, r6
   e0488:	462a      	mov	r2, r5
   e048a:	4621      	mov	r1, r4
   e048c:	a805      	add	r0, sp, #20
   e048e:	f7f7 f8dc 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   e0492:	9700      	str	r7, [sp, #0]

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
   e0494:	4680      	mov	r8, r0
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   e0496:	4633      	mov	r3, r6
   e0498:	462a      	mov	r2, r5
   e049a:	4621      	mov	r1, r4
   e049c:	9803      	ldr	r0, [sp, #12]
   e049e:	f7f7 f985 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   e04a2:	9700      	str	r7, [sp, #0]
  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
   e04a4:	4681      	mov	r9, r0
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
   e04a6:	4633      	mov	r3, r6
   e04a8:	462a      	mov	r2, r5
   e04aa:	4621      	mov	r1, r4
   e04ac:	a812      	add	r0, sp, #72	; 0x48
   e04ae:	f7f7 f97d 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          auto in1_val = input1_data[in1_idx];
   e04b2:	eb0a 0989 	add.w	r9, sl, r9, lsl #2
   e04b6:	edd9 7a00 	vldr	s15, [r9]
          auto in2_val = input2_data[in2_idx];
          output_data[out_idx] = in1_val >= 0.0 ? in1_val : in1_val * in2_val;
   e04ba:	9b25      	ldr	r3, [sp, #148]	; 0x94
        for (int c = 0; c < output_shape.Dims(3); ++c) {
          auto out_idx = Offset(output_shape, b, y, x, c);
          auto in1_idx = SubscriptToIndex(desc1, b, y, x, c);
          auto in2_idx = SubscriptToIndex(desc2, b, y, x, c);
          auto in1_val = input1_data[in1_idx];
          auto in2_val = input2_data[in2_idx];
   e04bc:	eb0b 0080 	add.w	r0, fp, r0, lsl #2
   e04c0:	ed90 7a00 	vldr	s14, [r0]
          output_data[out_idx] = in1_val >= 0.0 ? in1_val : in1_val * in2_val;
   e04c4:	eef5 7ac0 	vcmpe.f32	s15, #0.0
   e04c8:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e04cc:	bfb8      	it	lt
   e04ce:	ee67 7a87 	vmullt.f32	s15, s15, s14
   e04d2:	eb03 0888 	add.w	r8, r3, r8, lsl #2
   e04d6:	edc8 7a00 	vstr	s15, [r8]
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
        for (int c = 0; c < output_shape.Dims(3); ++c) {
   e04da:	3701      	adds	r7, #1
   e04dc:	e7cc      	b.n	e0478 <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0x6c>
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
      for (int x = 0; x < output_shape.Dims(2); ++x) {
   e04de:	3601      	adds	r6, #1
   e04e0:	e7c3      	b.n	e046a <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0x5e>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
    for (int y = 0; y < output_shape.Dims(1); ++y) {
   e04e2:	3501      	adds	r5, #1
   e04e4:	e7ba      	b.n	e045c <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0x50>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(unextended_input1_shape,
                                      unextended_input2_shape, &desc1, &desc2);

  for (int b = 0; b < output_shape.Dims(0); ++b) {
   e04e6:	3401      	adds	r4, #1
   e04e8:	e7b1      	b.n	e044e <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf+0x42>
    const RuntimeShape& unextended_output_shape, float* output_data) {
  TFLITE_DCHECK_LE(unextended_input1_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_input2_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   e04ea:	a805      	add	r0, sp, #20
   e04ec:	f7f7 f83d 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          output_data[out_idx] = in1_val >= 0.0 ? in1_val : in1_val * in2_val;
        }
      }
    }
  }
}
   e04f0:	b01b      	add	sp, #108	; 0x6c
   e04f2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	...

000e04f8 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph>:
                                 const RuntimeShape& input_shape,
                                 const uint8* input_data,
                                 const RuntimeShape& alpha_shape,
                                 const uint8* alpha_data,
                                 const RuntimeShape& output_shape,
                                 uint8* output_data) {
   e04f8:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e04fc:	461d      	mov	r5, r3
  TFLITE_DCHECK_LE(input_shape.DimensionsCount(), 4);
   e04fe:	680b      	ldr	r3, [r1, #0]
                                 const RuntimeShape& input_shape,
                                 const uint8* input_data,
                                 const RuntimeShape& alpha_shape,
                                 const uint8* alpha_data,
                                 const RuntimeShape& output_shape,
                                 uint8* output_data) {
   e0500:	b09d      	sub	sp, #116	; 0x74
  TFLITE_DCHECK_LE(input_shape.DimensionsCount(), 4);
   e0502:	2b04      	cmp	r3, #4
                                 const RuntimeShape& input_shape,
                                 const uint8* input_data,
                                 const RuntimeShape& alpha_shape,
                                 const uint8* alpha_data,
                                 const RuntimeShape& output_shape,
                                 uint8* output_data) {
   e0504:	9204      	str	r2, [sp, #16]
   e0506:	4681      	mov	r9, r0
   e0508:	460c      	mov	r4, r1
   e050a:	9a27      	ldr	r2, [sp, #156]	; 0x9c
  TFLITE_DCHECK_LE(input_shape.DimensionsCount(), 4);
   e050c:	dd01      	ble.n	e0512 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x1a>
   e050e:	f004 fff1 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(alpha_shape.DimensionsCount(), 4);
   e0512:	682b      	ldr	r3, [r5, #0]
   e0514:	2b04      	cmp	r3, #4
   e0516:	dcfa      	bgt.n	e050e <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x16>
  TFLITE_DCHECK_LE(output_shape.DimensionsCount(), 4);
   e0518:	6813      	ldr	r3, [r2, #0]
   e051a:	2b04      	cmp	r3, #4
   e051c:	dcf7      	bgt.n	e050e <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x16>
   e051e:	2301      	movs	r3, #1
   e0520:	2104      	movs	r1, #4
   e0522:	a807      	add	r0, sp, #28
   e0524:	f7f7 f865 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
  const RuntimeShape extended_output_shape =
      RuntimeShape::ExtendedShape(4, output_shape);
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input_shape, alpha_shape, &desc1, &desc2);
   e0528:	4629      	mov	r1, r5
   e052a:	ab14      	add	r3, sp, #80	; 0x50
   e052c:	aa0c      	add	r2, sp, #48	; 0x30
   e052e:	4620      	mov	r0, r4
   e0530:	f7f7 fb74 	bl	d7c1c <_ZN6tflite35NdArrayDescsForElementwiseBroadcastILi4EEEvRKNS_12RuntimeShapeES3_PNS_11NdArrayDescIXT_EEES6_>

  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   e0534:	2500      	movs	r5, #0
   e0536:	2100      	movs	r1, #0
   e0538:	a807      	add	r0, sp, #28
   e053a:	f7f7 f821 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e053e:	4285      	cmp	r5, r0
   e0540:	f280 80ac 	bge.w	e069c <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x1a4>
   e0544:	2600      	movs	r6, #0
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
   e0546:	2101      	movs	r1, #1
   e0548:	a807      	add	r0, sp, #28
   e054a:	f7f7 f819 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e054e:	4286      	cmp	r6, r0
   e0550:	f280 80a2 	bge.w	e0698 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x1a0>
   e0554:	2700      	movs	r7, #0
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
   e0556:	f10d 0a1c 	add.w	sl, sp, #28
   e055a:	2102      	movs	r1, #2
   e055c:	4650      	mov	r0, sl
   e055e:	f7f7 f80f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0562:	4287      	cmp	r7, r0
   e0564:	f280 8096 	bge.w	e0694 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x19c>
   e0568:	f04f 0800 	mov.w	r8, #0
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
   e056c:	2103      	movs	r1, #3
   e056e:	4650      	mov	r0, sl
   e0570:	f7f7 f806 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0574:	4580      	cmp	r8, r0
   e0576:	f280 808b 	bge.w	e0690 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x198>
          int output_index = Offset(extended_output_shape, b, y, x, c);
   e057a:	463b      	mov	r3, r7
   e057c:	4632      	mov	r2, r6
   e057e:	4629      	mov	r1, r5
   e0580:	f8cd 8000 	str.w	r8, [sp]
   e0584:	4650      	mov	r0, sl
   e0586:	f7f7 f860 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
          int input_index = SubscriptToIndex(desc1, b, y, x, c);
   e058a:	463b      	mov	r3, r7

  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
          int output_index = Offset(extended_output_shape, b, y, x, c);
   e058c:	4683      	mov	fp, r0
          int input_index = SubscriptToIndex(desc1, b, y, x, c);
   e058e:	f8cd 8000 	str.w	r8, [sp]
   e0592:	4632      	mov	r2, r6
   e0594:	4629      	mov	r1, r5
   e0596:	a80c      	add	r0, sp, #48	; 0x30
   e0598:	f7f7 f908 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
          const int32 input_value =
              params.input_offset + input_data[input_index];
   e059c:	9b04      	ldr	r3, [sp, #16]
   e059e:	f8d9 4000 	ldr.w	r4, [r9]
   e05a2:	5c1b      	ldrb	r3, [r3, r0]
          if (input_value >= 0) {
   e05a4:	191c      	adds	r4, r3, r4
   e05a6:	d403      	bmi.n	e05b0 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0xb8>
            output_data[output_index] = input_data[input_index];
   e05a8:	9a28      	ldr	r2, [sp, #160]	; 0xa0
   e05aa:	f802 300b 	strb.w	r3, [r2, fp]
   e05ae:	e06c      	b.n	e068a <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x192>
          } else {
            auto alpha_index = SubscriptToIndex(desc2, b, y, x, c);
   e05b0:	463b      	mov	r3, r7
   e05b2:	4632      	mov	r2, r6
   e05b4:	f8cd 8000 	str.w	r8, [sp]
   e05b8:	4629      	mov	r1, r5
   e05ba:	a814      	add	r0, sp, #80	; 0x50
   e05bc:	f7f7 f8f6 	bl	d77ac <_ZN6tflite16SubscriptToIndexERKNS_11NdArrayDescILi4EEEiiii>
            const int32 alpha_value =
                params.alpha_offset + alpha_data[alpha_index];
            const int32 unclamped_output =
                params.output_offset +
   e05c0:	f8d9 3008 	ldr.w	r3, [r9, #8]
   e05c4:	9303      	str	r3, [sp, #12]
                MultiplyByQuantizedMultiplierSmallerThanOneExp(
   e05c6:	9b26      	ldr	r3, [sp, #152]	; 0x98
                    input_value * alpha_value, params.output_multiplier,
                    params.output_shift);
   e05c8:	f8d9 e010 	ldr.w	lr, [r9, #16]
            auto alpha_index = SubscriptToIndex(desc2, b, y, x, c);
            const int32 alpha_value =
                params.alpha_offset + alpha_data[alpha_index];
            const int32 unclamped_output =
                params.output_offset +
                MultiplyByQuantizedMultiplierSmallerThanOneExp(
   e05cc:	5c1a      	ldrb	r2, [r3, r0]
   e05ce:	f8d9 3004 	ldr.w	r3, [r9, #4]
   e05d2:	441a      	add	r2, r3
                    input_value * alpha_value, params.output_multiplier,
   e05d4:	f8d9 300c 	ldr.w	r3, [r9, #12]
            auto alpha_index = SubscriptToIndex(desc2, b, y, x, c);
            const int32 alpha_value =
                params.alpha_offset + alpha_data[alpha_index];
            const int32 unclamped_output =
                params.output_offset +
                MultiplyByQuantizedMultiplierSmallerThanOneExp(
   e05d8:	4362      	muls	r2, r4
// This function implements the same computation as the ARMv7 NEON VQRDMULH
// instruction.
template <>
inline std::int32_t SaturatingRoundingDoublingHighMul(std::int32_t a,
                                                      std::int32_t b) {
  bool overflow = a == b && a == std::numeric_limits<std::int32_t>::min();
   e05da:	429a      	cmp	r2, r3
   e05dc:	d104      	bne.n	e05e8 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0xf0>
   e05de:	f102 4100 	add.w	r1, r2, #2147483648	; 0x80000000
   e05e2:	424c      	negs	r4, r1
   e05e4:	414c      	adcs	r4, r1
   e05e6:	e000      	b.n	e05ea <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0xf2>
   e05e8:	2400      	movs	r4, #0
  std::int64_t a_64(a);
  std::int64_t b_64(b);
  std::int64_t ab_64 = a_64 * b_64;
   e05ea:	fb82 2303 	smull	r2, r3, r2, r3
  std::int32_t nudge = ab_64 >= 0 ? (1 << 30) : (1 - (1 << 30));
   e05ee:	2a00      	cmp	r2, #0
   e05f0:	f173 0100 	sbcs.w	r1, r3, #0
   e05f4:	482c      	ldr	r0, [pc, #176]	; (e06a8 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x1b0>)
   e05f6:	bfa8      	it	ge
   e05f8:	f04f 4080 	movge.w	r0, #1073741824	; 0x40000000
  std::int32_t ab_x2_high32 =
      static_cast<std::int32_t>((ab_64 + nudge) / (1ll << 31));
  return overflow ? std::numeric_limits<std::int32_t>::max() : ab_x2_high32;
   e05fc:	b994      	cbnz	r4, e0624 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x12c>
  std::int64_t a_64(a);
  std::int64_t b_64(b);
  std::int64_t ab_64 = a_64 * b_64;
  std::int32_t nudge = ab_64 >= 0 ? (1 << 30) : (1 - (1 << 30));
  std::int32_t ab_x2_high32 =
      static_cast<std::int32_t>((ab_64 + nudge) / (1ll << 31));
   e05fe:	1812      	adds	r2, r2, r0
   e0600:	eb43 73e0 	adc.w	r3, r3, r0, asr #31
   e0604:	2a00      	cmp	r2, #0
   e0606:	f173 0100 	sbcs.w	r1, r3, #0
   e060a:	da07      	bge.n	e061c <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x124>
   e060c:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
   e0610:	1880      	adds	r0, r0, r2
   e0612:	f04f 0100 	mov.w	r1, #0
   e0616:	4159      	adcs	r1, r3
   e0618:	4602      	mov	r2, r0
   e061a:	460b      	mov	r3, r1
   e061c:	0fd4      	lsrs	r4, r2, #31
   e061e:	ea44 0443 	orr.w	r4, r4, r3, lsl #1
   e0622:	e001      	b.n	e0628 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x130>
  return overflow ? std::numeric_limits<std::int32_t>::max() : ab_x2_high32;
   e0624:	f06f 4400 	mvn.w	r4, #2147483648	; 0x80000000

inline int32 MultiplyByQuantizedMultiplierSmallerThanOneExp(
    int32 x, int32 quantized_multiplier, int left_shift) {
  using gemmlowp::RoundingDivideByPOT;
  using gemmlowp::SaturatingRoundingDoublingHighMul;
  return RoundingDivideByPOT(
   e0628:	f1ce 0300 	rsb	r3, lr, #0

// Correctly-rounded-to-nearest division by a power-of-two.
// Also known as a rounding arithmetic right shift.
template <typename IntegerType>
inline IntegerType RoundingDivideByPOT(IntegerType x, int exponent) {
  assert(exponent >= 0);
   e062c:	2b00      	cmp	r3, #0
   e062e:	da04      	bge.n	e063a <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x142>
   e0630:	4b1e      	ldr	r3, [pc, #120]	; (e06ac <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x1b4>)
   e0632:	4a1f      	ldr	r2, [pc, #124]	; (e06b0 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x1b8>)
   e0634:	f44f 71b3 	mov.w	r1, #358	; 0x166
   e0638:	e005      	b.n	e0646 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x14e>
  assert(exponent <= 31);
   e063a:	2b1f      	cmp	r3, #31
   e063c:	dd06      	ble.n	e064c <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x154>
   e063e:	4b1d      	ldr	r3, [pc, #116]	; (e06b4 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x1bc>)
   e0640:	4a1b      	ldr	r2, [pc, #108]	; (e06b0 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x1b8>)
   e0642:	f240 1167 	movw	r1, #359	; 0x167
   e0646:	481c      	ldr	r0, [pc, #112]	; (e06b8 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x1c0>)
   e0648:	f004 ff64 	bl	e5514 <__assert_func>
  const IntegerType mask = Dup<IntegerType>((1ll << exponent) - 1);
   e064c:	461a      	mov	r2, r3
   e064e:	2001      	movs	r0, #1
   e0650:	2100      	movs	r1, #0
   e0652:	9305      	str	r3, [sp, #20]
   e0654:	f007 fd22 	bl	e809c <__aeabi_llsl>
          } else {
            auto alpha_index = SubscriptToIndex(desc2, b, y, x, c);
            const int32 alpha_value =
                params.alpha_offset + alpha_data[alpha_index];
            const int32 unclamped_output =
                params.output_offset +
   e0658:	9b05      	ldr	r3, [sp, #20]
   e065a:	3801      	subs	r0, #1
   e065c:	ea00 0204 	and.w	r2, r0, r4
   e0660:	1040      	asrs	r0, r0, #1
   e0662:	fa44 f303 	asr.w	r3, r4, r3
   e0666:	eb00 70d4 	add.w	r0, r0, r4, lsr #31
   e066a:	4282      	cmp	r2, r0
   e066c:	bfd4      	ite	le
   e066e:	461c      	movle	r4, r3
   e0670:	1c5c      	addgt	r4, r3, #1
   e0672:	9b03      	ldr	r3, [sp, #12]
   e0674:	441c      	add	r4, r3
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
   e0676:	2c00      	cmp	r4, #0
   e0678:	dd03      	ble.n	e0682 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x18a>
    min(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
   e067a:	2cfe      	cmp	r4, #254	; 0xfe
   e067c:	dd02      	ble.n	e0684 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x18c>
	return __b;
      return __a;
   e067e:	24ff      	movs	r4, #255	; 0xff
   e0680:	e000      	b.n	e0684 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x18c>
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
	return __b;
      return __a;
   e0682:	2400      	movs	r4, #0
                    params.output_shift);
            const int32 quantized_min = std::numeric_limits<uint8_t>::min();
            const int32 quantized_max = std::numeric_limits<uint8_t>::max();
            const int32 clamped_output = std::min(
                quantized_max, std::max(quantized_min, unclamped_output));
            output_data[output_index] = static_cast<uint8>(clamped_output);
   e0684:	9b28      	ldr	r3, [sp, #160]	; 0xa0
   e0686:	f803 400b 	strb.w	r4, [r3, fp]
  NdArrayDescsForElementwiseBroadcast(input_shape, alpha_shape, &desc1, &desc2);

  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
        for (int c = 0; c < extended_output_shape.Dims(3); ++c) {
   e068a:	f108 0801 	add.w	r8, r8, #1
   e068e:	e76d      	b.n	e056c <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x74>
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input_shape, alpha_shape, &desc1, &desc2);

  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
      for (int x = 0; x < extended_output_shape.Dims(2); ++x) {
   e0690:	3701      	adds	r7, #1
   e0692:	e760      	b.n	e0556 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x5e>
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input_shape, alpha_shape, &desc1, &desc2);

  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
    for (int y = 0; y < extended_output_shape.Dims(1); ++y) {
   e0694:	3601      	adds	r6, #1
   e0696:	e756      	b.n	e0546 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x4e>
      RuntimeShape::ExtendedShape(4, output_shape);
  NdArrayDesc<4> desc1;
  NdArrayDesc<4> desc2;
  NdArrayDescsForElementwiseBroadcast(input_shape, alpha_shape, &desc1, &desc2);

  for (int b = 0; b < extended_output_shape.Dims(0); ++b) {
   e0698:	3501      	adds	r5, #1
   e069a:	e74c      	b.n	e0536 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph+0x3e>
                                 uint8* output_data) {
  TFLITE_DCHECK_LE(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(alpha_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(output_shape.DimensionsCount(), 4);
  const RuntimeShape extended_output_shape =
      RuntimeShape::ExtendedShape(4, output_shape);
   e069c:	a807      	add	r0, sp, #28
   e069e:	f7f6 ff64 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          }
        }
      }
    }
  }
}
   e06a2:	b01d      	add	sp, #116	; 0x74
   e06a4:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e06a8:	c0000001 	.word	0xc0000001
   e06ac:	000eb13c 	.word	0x000eb13c
   e06b0:	000ebae9 	.word	0x000ebae9
   e06b4:	000eb1ee 	.word	0x000eb1ee
   e06b8:	000eb14a 	.word	0x000eb14a

000e06bc <_ZN6tflite3ops5micro11activations9PreluEvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus PreluEval(TfLiteContext* context, TfLiteNode* node) {
   e06bc:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
   e06c0:	680b      	ldr	r3, [r1, #0]
   e06c2:	6887      	ldr	r7, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e06c4:	689c      	ldr	r4, [r3, #8]
   e06c6:	4681      	mov	r9, r0
   e06c8:	6858      	ldr	r0, [r3, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e06ca:	684b      	ldr	r3, [r1, #4]
   e06cc:	685b      	ldr	r3, [r3, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e06ce:	2238      	movs	r2, #56	; 0x38
   e06d0:	b09b      	sub	sp, #108	; 0x6c
   e06d2:	fb02 f800 	mul.w	r8, r2, r0
   e06d6:	fb02 7404 	mla	r4, r2, r4, r7
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e06da:	435a      	muls	r2, r3
  const TfLiteTensor* input = GetInput(context, node, 0);
  const TfLiteTensor* alpha = GetInput(context, node, 1);
  TfLiteTensor* output = GetOutput(context, node, 0);
  int32_t output_multiplier = 0;
   e06dc:	2300      	movs	r3, #0
   e06de:	9304      	str	r3, [sp, #16]
  int output_shift = 0;
   e06e0:	9305      	str	r3, [sp, #20]
  if (output->type == kTfLiteUInt8 || output->type == kTfLiteInt16) {
   e06e2:	5cbb      	ldrb	r3, [r7, r2]
   e06e4:	f003 03fb 	and.w	r3, r3, #251	; 0xfb
   e06e8:	2b03      	cmp	r3, #3
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e06ea:	eb07 0608 	add.w	r6, r7, r8
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e06ee:	eb07 0502 	add.w	r5, r7, r2
   e06f2:	d113      	bne.n	e071c <_ZN6tflite3ops5micro11activations9PreluEvalEP13TfLiteContextP10TfLiteNode+0x60>
    double real_multiplier =
        input->params.scale * alpha->params.scale / output->params.scale;
    QuantizeMultiplierSmallerThanOneExp(real_multiplier, &output_multiplier,
                                        &output_shift);
   e06f4:	ed94 7a03 	vldr	s14, [r4, #12]
   e06f8:	edd6 7a03 	vldr	s15, [r6, #12]
   e06fc:	ee67 7a87 	vmul.f32	s15, s15, s14
   e0700:	ed95 7a03 	vldr	s14, [r5, #12]
   e0704:	eec7 6a87 	vdiv.f32	s13, s15, s14
   e0708:	ee16 0a90 	vmov	r0, s13
   e070c:	f007 fe36 	bl	e837c <__aeabi_f2d>
   e0710:	ec41 0b10 	vmov	d0, r0, r1
   e0714:	a905      	add	r1, sp, #20
   e0716:	a804      	add	r0, sp, #16
   e0718:	f004 fc32 	bl	e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>
  }
  switch (input->type) {
   e071c:	f817 0008 	ldrb.w	r0, [r7, r8]
   e0720:	2801      	cmp	r0, #1
   e0722:	d028      	beq.n	e0776 <_ZN6tflite3ops5micro11activations9PreluEvalEP13TfLiteContextP10TfLiteNode+0xba>
   e0724:	2803      	cmp	r0, #3
   e0726:	d14a      	bne.n	e07be <_ZN6tflite3ops5micro11activations9PreluEvalEP13TfLiteContextP10TfLiteNode+0x102>
          GetTensorShape(output), GetTensorData<float>(output));
      return kTfLiteOk;
    } break;
    case kTfLiteUInt8: {
      PreluParams op_params;
      op_params.input_offset = -input->params.zero_point;
   e0728:	6933      	ldr	r3, [r6, #16]
   e072a:	425b      	negs	r3, r3
   e072c:	9306      	str	r3, [sp, #24]
      op_params.alpha_offset = -alpha->params.zero_point;
   e072e:	6923      	ldr	r3, [r4, #16]
   e0730:	425b      	negs	r3, r3
   e0732:	9307      	str	r3, [sp, #28]
      op_params.output_offset = output->params.zero_point;
   e0734:	692b      	ldr	r3, [r5, #16]
   e0736:	9308      	str	r3, [sp, #32]
      op_params.output_multiplier = output_multiplier;
   e0738:	9b04      	ldr	r3, [sp, #16]
   e073a:	9309      	str	r3, [sp, #36]	; 0x24
      op_params.output_shift = output_shift;
      reference_ops::BroadcastPrelu4DSlow(
          op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e073c:	4631      	mov	r1, r6
      PreluParams op_params;
      op_params.input_offset = -input->params.zero_point;
      op_params.alpha_offset = -alpha->params.zero_point;
      op_params.output_offset = output->params.zero_point;
      op_params.output_multiplier = output_multiplier;
      op_params.output_shift = output_shift;
   e073e:	9b05      	ldr	r3, [sp, #20]
   e0740:	930a      	str	r3, [sp, #40]	; 0x28
      reference_ops::BroadcastPrelu4DSlow(
          op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e0742:	a80b      	add	r0, sp, #44	; 0x2c
   e0744:	f7f7 f9c1 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
          GetTensorShape(alpha), GetTensorData<uint8_t>(alpha),
   e0748:	4621      	mov	r1, r4
   e074a:	a810      	add	r0, sp, #64	; 0x40
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e074c:	6876      	ldr	r6, [r6, #4]
   e074e:	f7f7 f9bc 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e0752:	6867      	ldr	r7, [r4, #4]
          GetTensorShape(output), GetTensorData<uint8_t>(output));
   e0754:	ac15      	add	r4, sp, #84	; 0x54
   e0756:	4629      	mov	r1, r5
   e0758:	4620      	mov	r0, r4
   e075a:	f7f7 f9b6 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e075e:	686b      	ldr	r3, [r5, #4]
   e0760:	9302      	str	r3, [sp, #8]
   e0762:	a806      	add	r0, sp, #24
   e0764:	9401      	str	r4, [sp, #4]
   e0766:	9700      	str	r7, [sp, #0]
   e0768:	ab10      	add	r3, sp, #64	; 0x40
   e076a:	4632      	mov	r2, r6
   e076c:	a90b      	add	r1, sp, #44	; 0x2c
   e076e:	f7ff fec3 	bl	e04f8 <_ZN6tflite13reference_ops20BroadcastPrelu4DSlowERKNS_11PreluParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_Ph>
   e0772:	4620      	mov	r0, r4
   e0774:	e019      	b.n	e07aa <_ZN6tflite3ops5micro11activations9PreluEvalEP13TfLiteContextP10TfLiteNode+0xee>
                                        &output_shift);
  }
  switch (input->type) {
    case kTfLiteFloat32: {
      BroadcastPrelu4DSlowFloat(
          GetTensorShape(input), GetTensorData<float>(input),
   e0776:	4631      	mov	r1, r6
   e0778:	a80b      	add	r0, sp, #44	; 0x2c
   e077a:	f7f7 f9a6 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
          GetTensorShape(alpha), GetTensorData<float>(alpha),
   e077e:	4621      	mov	r1, r4
   e0780:	a810      	add	r0, sp, #64	; 0x40
   e0782:	6877      	ldr	r7, [r6, #4]
   e0784:	f7f7 f9a1 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e0788:	b104      	cbz	r4, e078c <_ZN6tflite3ops5micro11activations9PreluEvalEP13TfLiteContextP10TfLiteNode+0xd0>
   e078a:	6864      	ldr	r4, [r4, #4]
          GetTensorShape(output), GetTensorData<float>(output));
   e078c:	ae15      	add	r6, sp, #84	; 0x54
   e078e:	4629      	mov	r1, r5
   e0790:	4630      	mov	r0, r6
   e0792:	f7f7 f99a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e0796:	686b      	ldr	r3, [r5, #4]
   e0798:	9301      	str	r3, [sp, #4]
   e079a:	a80b      	add	r0, sp, #44	; 0x2c
   e079c:	9600      	str	r6, [sp, #0]
   e079e:	4623      	mov	r3, r4
   e07a0:	aa10      	add	r2, sp, #64	; 0x40
   e07a2:	4639      	mov	r1, r7
   e07a4:	f7ff fe32 	bl	e040c <_ZN6tflite3ops5micro11activations25BroadcastPrelu4DSlowFloatERKNS_12RuntimeShapeEPKfS5_S7_S5_Pf>
   e07a8:	4630      	mov	r0, r6
      op_params.output_multiplier = output_multiplier;
      op_params.output_shift = output_shift;
      reference_ops::BroadcastPrelu4DSlow(
          op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
          GetTensorShape(alpha), GetTensorData<uint8_t>(alpha),
          GetTensorShape(output), GetTensorData<uint8_t>(output));
   e07aa:	f7f6 fede 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      op_params.output_offset = output->params.zero_point;
      op_params.output_multiplier = output_multiplier;
      op_params.output_shift = output_shift;
      reference_ops::BroadcastPrelu4DSlow(
          op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
          GetTensorShape(alpha), GetTensorData<uint8_t>(alpha),
   e07ae:	a810      	add	r0, sp, #64	; 0x40
   e07b0:	f7f6 fedb 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      op_params.alpha_offset = -alpha->params.zero_point;
      op_params.output_offset = output->params.zero_point;
      op_params.output_multiplier = output_multiplier;
      op_params.output_shift = output_shift;
      reference_ops::BroadcastPrelu4DSlow(
          op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e07b4:	a80b      	add	r0, sp, #44	; 0x2c
   e07b6:	f7f6 fed8 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          GetTensorShape(alpha), GetTensorData<uint8_t>(alpha),
          GetTensorShape(output), GetTensorData<uint8_t>(output));
      return kTfLiteOk;
   e07ba:	2000      	movs	r0, #0
   e07bc:	e008      	b.n	e07d0 <_ZN6tflite3ops5micro11activations9PreluEvalEP13TfLiteContextP10TfLiteNode+0x114>
    } break;
    default:
      context->ReportError(
   e07be:	f8d9 4014 	ldr.w	r4, [r9, #20]
   e07c2:	f7f3 fcb3 	bl	d412c <TfLiteTypeGetName>
          context, "Only float32 and uint8 are supported currently, got %d.",
          TfLiteTypeGetName(input->type));
   e07c6:	4904      	ldr	r1, [pc, #16]	; (e07d8 <_ZN6tflite3ops5micro11activations9PreluEvalEP13TfLiteContextP10TfLiteNode+0x11c>)
   e07c8:	4602      	mov	r2, r0
   e07ca:	4648      	mov	r0, r9
   e07cc:	47a0      	blx	r4
      return kTfLiteError;
   e07ce:	2001      	movs	r0, #1
  }
}
   e07d0:	b01b      	add	sp, #108	; 0x6c
   e07d2:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
   e07d6:	bf00      	nop
   e07d8:	000ebab1 	.word	0x000ebab1

000e07dc <_ZN6tflite3ops5micro8quantize4InitEP13TfLiteContextPKcj>:
namespace micro {
namespace quantize {

void* Init(TfLiteContext* context, const char* buffer, size_t length) {
  return nullptr;
}
   e07dc:	2000      	movs	r0, #0
   e07de:	4770      	bx	lr

000e07e0 <_ZN6tflite3ops5micro8quantize4FreeEP13TfLiteContextPv>:

void Free(TfLiteContext* context, void* buffer) {}
   e07e0:	4770      	bx	lr
	...

000e07e4 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   e07e4:	b5f0      	push	{r4, r5, r6, r7, lr}
   e07e6:	680f      	ldr	r7, [r1, #0]
}
inline const TfLiteTensor* GetIntermediates(TfLiteContext* context,
                                            TfLiteNode* node, int index) {
  return &context->tensors[node->intermediates->data[index]];
}
inline int NumInputs(const TfLiteNode* node) { return node->inputs->size; }
   e07e8:	683c      	ldr	r4, [r7, #0]
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
   e07ea:	2c01      	cmp	r4, #1
  return nullptr;
}

void Free(TfLiteContext* context, void* buffer) {}

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   e07ec:	b085      	sub	sp, #20
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
   e07ee:	d009      	beq.n	e0804 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x20>
   e07f0:	4a32      	ldr	r2, [pc, #200]	; (e08bc <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xd8>)
   e07f2:	9201      	str	r2, [sp, #4]
   e07f4:	2501      	movs	r5, #1
   e07f6:	4a32      	ldr	r2, [pc, #200]	; (e08c0 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xdc>)
   e07f8:	9503      	str	r5, [sp, #12]
   e07fa:	9402      	str	r4, [sp, #8]
   e07fc:	9200      	str	r2, [sp, #0]
   e07fe:	6944      	ldr	r4, [r0, #20]
   e0800:	2322      	movs	r3, #34	; 0x22
   e0802:	e021      	b.n	e0848 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x64>
   e0804:	684a      	ldr	r2, [r1, #4]
inline int NumOutputs(const TfLiteNode* node) { return node->outputs->size; }
   e0806:	6815      	ldr	r5, [r2, #0]
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
   e0808:	2d01      	cmp	r5, #1
   e080a:	d00b      	beq.n	e0824 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x40>
   e080c:	4a2b      	ldr	r2, [pc, #172]	; (e08bc <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xd8>)
   e080e:	9201      	str	r2, [sp, #4]
   e0810:	4a2c      	ldr	r2, [pc, #176]	; (e08c4 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xe0>)
   e0812:	9200      	str	r2, [sp, #0]
   e0814:	9403      	str	r4, [sp, #12]
   e0816:	9502      	str	r5, [sp, #8]
   e0818:	6945      	ldr	r5, [r0, #20]
   e081a:	4a2b      	ldr	r2, [pc, #172]	; (e08c8 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xe4>)
   e081c:	492b      	ldr	r1, [pc, #172]	; (e08cc <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xe8>)
   e081e:	2323      	movs	r3, #35	; 0x23
   e0820:	47a8      	blx	r5
   e0822:	e046      	b.n	e08b2 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xce>

  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];
   e0824:	6852      	ldr	r2, [r2, #4]

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);

  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
   e0826:	6886      	ldr	r6, [r0, #8]
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];
   e0828:	2138      	movs	r1, #56	; 0x38
   e082a:	434a      	muls	r2, r1
   e082c:	eb06 0e02 	add.w	lr, r6, r2

  // TODO(b/128934713): Add support for fixed-point per-channel quantization.
  // Currently this only support affine per-layer quantization.
  TF_LITE_ENSURE_EQ(context, output->quantization.type,
   e0830:	f89e 4030 	ldrb.w	r4, [lr, #48]	; 0x30
   e0834:	2c01      	cmp	r4, #1
   e0836:	d00c      	beq.n	e0852 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x6e>
   e0838:	4a25      	ldr	r2, [pc, #148]	; (e08d0 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xec>)
   e083a:	9201      	str	r2, [sp, #4]
   e083c:	4a25      	ldr	r2, [pc, #148]	; (e08d4 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xf0>)
   e083e:	9503      	str	r5, [sp, #12]
   e0840:	9402      	str	r4, [sp, #8]
   e0842:	9200      	str	r2, [sp, #0]
   e0844:	6944      	ldr	r4, [r0, #20]
   e0846:	232b      	movs	r3, #43	; 0x2b
   e0848:	4a1f      	ldr	r2, [pc, #124]	; (e08c8 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xe4>)
   e084a:	4920      	ldr	r1, [pc, #128]	; (e08cc <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xe8>)
   e084c:	47a0      	blx	r4
   e084e:	4628      	mov	r0, r5
   e0850:	e032      	b.n	e08b8 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xd4>
                    kTfLiteAffineQuantization);
  const auto* affine_quantization =
      reinterpret_cast<TfLiteAffineQuantization*>(output->quantization.params);
   e0852:	f8de 5034 	ldr.w	r5, [lr, #52]	; 0x34
  TF_LITE_ENSURE(context, affine_quantization);
   e0856:	b925      	cbnz	r5, e0862 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x7e>
   e0858:	4a1f      	ldr	r2, [pc, #124]	; (e08d8 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xf4>)
   e085a:	9200      	str	r2, [sp, #0]
   e085c:	6945      	ldr	r5, [r0, #20]
   e085e:	232e      	movs	r3, #46	; 0x2e
   e0860:	e024      	b.n	e08ac <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xc8>
  TF_LITE_ENSURE(context, affine_quantization->scale);
   e0862:	682d      	ldr	r5, [r5, #0]
   e0864:	b925      	cbnz	r5, e0870 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x8c>
   e0866:	4a1d      	ldr	r2, [pc, #116]	; (e08dc <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xf8>)
   e0868:	9200      	str	r2, [sp, #0]
   e086a:	6945      	ldr	r5, [r0, #20]
   e086c:	232f      	movs	r3, #47	; 0x2f
   e086e:	e01d      	b.n	e08ac <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xc8>
  TF_LITE_ENSURE(context, affine_quantization->scale->size == 1);
   e0870:	682d      	ldr	r5, [r5, #0]
   e0872:	2d01      	cmp	r5, #1
   e0874:	d004      	beq.n	e0880 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x9c>
   e0876:	4a1a      	ldr	r2, [pc, #104]	; (e08e0 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xfc>)
   e0878:	9200      	str	r2, [sp, #0]
   e087a:	6945      	ldr	r5, [r0, #20]
   e087c:	2330      	movs	r3, #48	; 0x30
   e087e:	e015      	b.n	e08ac <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xc8>

  TF_LITE_ENSURE(context, input->type == kTfLiteFloat32);
   e0880:	687c      	ldr	r4, [r7, #4]
   e0882:	4361      	muls	r1, r4
   e0884:	5c74      	ldrb	r4, [r6, r1]
   e0886:	2c01      	cmp	r4, #1
   e0888:	d007      	beq.n	e089a <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xb6>
   e088a:	4a16      	ldr	r2, [pc, #88]	; (e08e4 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x100>)
   e088c:	9200      	str	r2, [sp, #0]
   e088e:	6944      	ldr	r4, [r0, #20]
   e0890:	4a0d      	ldr	r2, [pc, #52]	; (e08c8 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xe4>)
   e0892:	4915      	ldr	r1, [pc, #84]	; (e08e8 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x104>)
   e0894:	2332      	movs	r3, #50	; 0x32
   e0896:	47a0      	blx	r4
   e0898:	e7d9      	b.n	e084e <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x6a>
  TF_LITE_ENSURE(context,
   e089a:	5cb2      	ldrb	r2, [r6, r2]
   e089c:	2a03      	cmp	r2, #3
   e089e:	d00a      	beq.n	e08b6 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xd2>
   e08a0:	2a09      	cmp	r2, #9
   e08a2:	d008      	beq.n	e08b6 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xd2>
   e08a4:	4a11      	ldr	r2, [pc, #68]	; (e08ec <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x108>)
   e08a6:	9200      	str	r2, [sp, #0]
   e08a8:	6945      	ldr	r5, [r0, #20]
   e08aa:	2334      	movs	r3, #52	; 0x34
   e08ac:	4a06      	ldr	r2, [pc, #24]	; (e08c8 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xe4>)
   e08ae:	490e      	ldr	r1, [pc, #56]	; (e08e8 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0x104>)
   e08b0:	47a8      	blx	r5
   e08b2:	4620      	mov	r0, r4
   e08b4:	e000      	b.n	e08b8 <_ZN6tflite3ops5micro8quantize7PrepareEP13TfLiteContextP10TfLiteNode+0xd4>
                 output->type == kTfLiteUInt8 || output->type == kTfLiteInt8);

  return kTfLiteOk;
   e08b6:	2000      	movs	r0, #0
}
   e08b8:	b005      	add	sp, #20
   e08ba:	bdf0      	pop	{r4, r5, r6, r7, pc}
   e08bc:	000ecdd6 	.word	0x000ecdd6
   e08c0:	000eb3d3 	.word	0x000eb3d3
   e08c4:	000eb3e3 	.word	0x000eb3e3
   e08c8:	000ebb43 	.word	0x000ebb43
   e08cc:	000eb3b9 	.word	0x000eb3b9
   e08d0:	000eb5dd 	.word	0x000eb5dd
   e08d4:	000ebbf2 	.word	0x000ebbf2
   e08d8:	000eb611 	.word	0x000eb611
   e08dc:	000eb625 	.word	0x000eb625
   e08e0:	000ebc0c 	.word	0x000ebc0c
   e08e4:	000ebc32 	.word	0x000ebc32
   e08e8:	000eb58e 	.word	0x000eb58e
   e08ec:	000ebc50 	.word	0x000ebc50

000e08f0 <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e08f0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
   e08f4:	680b      	ldr	r3, [r1, #0]
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];
   e08f6:	6849      	ldr	r1, [r1, #4]

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
   e08f8:	f8d0 8008 	ldr.w	r8, [r0, #8]
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];
   e08fc:	684d      	ldr	r5, [r1, #4]

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
   e08fe:	685b      	ldr	r3, [r3, #4]
   e0900:	2238      	movs	r2, #56	; 0x38
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];
   e0902:	4355      	muls	r5, r2
   e0904:	eb08 0a05 	add.w	sl, r8, r5
                 output->type == kTfLiteUInt8 || output->type == kTfLiteInt8);

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e0908:	b08d      	sub	sp, #52	; 0x34
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
   e090a:	4353      	muls	r3, r2
                 output->type == kTfLiteUInt8 || output->type == kTfLiteInt8);

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e090c:	4683      	mov	fp, r0
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];

  tflite::QuantizationParams op_params;
  op_params.zero_point = output->params.zero_point;
  op_params.scale = output->params.scale;
   e090e:	f8da 000c 	ldr.w	r0, [sl, #12]

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
   e0912:	9301      	str	r3, [sp, #4]
   e0914:	eb08 0403 	add.w	r4, r8, r3
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];

  tflite::QuantizationParams op_params;
  op_params.zero_point = output->params.zero_point;
  op_params.scale = output->params.scale;
   e0918:	f007 fd30 	bl	e837c <__aeabi_f2d>
  switch (output->type) {
   e091c:	f818 2005 	ldrb.w	r2, [r8, r5]
TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];

  tflite::QuantizationParams op_params;
  op_params.zero_point = output->params.zero_point;
   e0920:	f8da 9010 	ldr.w	r9, [sl, #16]
  op_params.scale = output->params.scale;
  switch (output->type) {
   e0924:	2a03      	cmp	r2, #3
  TfLiteTensor* input = &context->tensors[node->inputs->data[0]];
  TfLiteTensor* output = &context->tensors[node->outputs->data[0]];

  tflite::QuantizationParams op_params;
  op_params.zero_point = output->params.zero_point;
  op_params.scale = output->params.scale;
   e0926:	4606      	mov	r6, r0
   e0928:	460f      	mov	r7, r1
  switch (output->type) {
   e092a:	d035      	beq.n	e0998 <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0xa8>
   e092c:	2a09      	cmp	r2, #9
   e092e:	9b01      	ldr	r3, [sp, #4]
   e0930:	d16b      	bne.n	e0a0a <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0x11a>
    case kTfLiteInt8:
      reference_ops::AffineQuantize(
          op_params, GetTensorShape(input), GetTensorData<float>(input),
   e0932:	4621      	mov	r1, r4
   e0934:	a802      	add	r0, sp, #8
   e0936:	f7f7 f8c8 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e093a:	b104      	cbz	r4, e093e <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0x4e>
   e093c:	6864      	ldr	r4, [r4, #4]
          GetTensorShape(output), GetTensorData<int8_t>(output));
   e093e:	4651      	mov	r1, sl
   e0940:	a807      	add	r0, sp, #28
   e0942:	f7f7 f8c2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
                           const RuntimeShape& input_shape,
                           const float* input_data,
                           const RuntimeShape& output_shape, T* output_data) {
  const int32 zero_point = op_params.zero_point;
  const double scale = static_cast<double>(op_params.scale);
  const int flat_size = MatchingFlatSize(input_shape, output_shape);
   e0946:	a907      	add	r1, sp, #28
   e0948:	a802      	add	r0, sp, #8
   e094a:	f7fd f89d 	bl	dda88 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_>
   e094e:	f8da a004 	ldr.w	sl, [sl, #4]
   e0952:	4680      	mov	r8, r0
   e0954:	4655      	mov	r5, sl
  static constexpr int32 min_val = std::numeric_limits<T>::min();
  static constexpr int32 max_val = std::numeric_limits<T>::max();

  for (int i = 0; i < flat_size; i++) {
   e0956:	ebca 0305 	rsb	r3, sl, r5
   e095a:	4598      	cmp	r8, r3
   e095c:	dd4d      	ble.n	e09fa <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0x10a>
}
inline double TfLiteRound(const double x) { return ::round(x); }
#else
template <class T>
inline T TfLiteRound(const T x) {
  return std::round(x);
   e095e:	f854 0b04 	ldr.w	r0, [r4], #4
   e0962:	f007 fd0b 	bl	e837c <__aeabi_f2d>
   e0966:	4632      	mov	r2, r6
   e0968:	463b      	mov	r3, r7
   e096a:	f007 fe85 	bl	e8678 <__aeabi_ddiv>
   e096e:	ec41 0b10 	vmov	d0, r0, r1
   e0972:	f005 fe2f 	bl	e65d4 <round>
    const float val = input_data[i];
    int32 unclamped = static_cast<int32>(TfLiteRound(val / scale)) + zero_point;
   e0976:	ec51 0b10 	vmov	r0, r1, d0
   e097a:	f007 ffed 	bl	e8958 <__aeabi_d2iz>
   e097e:	4448      	add	r0, r9
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
   e0980:	f110 0f80 	cmn.w	r0, #128	; 0x80
   e0984:	db03      	blt.n	e098e <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0x9e>
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
   e0986:	287f      	cmp	r0, #127	; 0x7f
   e0988:	bfa8      	it	ge
   e098a:	207f      	movge	r0, #127	; 0x7f
   e098c:	e001      	b.n	e0992 <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0xa2>
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
	return __b;
   e098e:	f06f 007f 	mvn.w	r0, #127	; 0x7f
    int32 clamped = std::min(std::max(unclamped, min_val), max_val);
    output_data[i] = clamped;
   e0992:	f805 0b01 	strb.w	r0, [r5], #1
   e0996:	e7de      	b.n	e0956 <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0x66>
      break;
    case kTfLiteUInt8:
      reference_ops::AffineQuantize(
          op_params, GetTensorShape(input), GetTensorData<float>(input),
   e0998:	4621      	mov	r1, r4
   e099a:	a802      	add	r0, sp, #8
   e099c:	f7f7 f895 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e09a0:	b104      	cbz	r4, e09a4 <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0xb4>
   e09a2:	6864      	ldr	r4, [r4, #4]
          GetTensorShape(output), GetTensorData<uint8_t>(output));
   e09a4:	4651      	mov	r1, sl
   e09a6:	a807      	add	r0, sp, #28
   e09a8:	f7f7 f88f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
                           const RuntimeShape& input_shape,
                           const float* input_data,
                           const RuntimeShape& output_shape, T* output_data) {
  const int32 zero_point = op_params.zero_point;
  const double scale = static_cast<double>(op_params.scale);
  const int flat_size = MatchingFlatSize(input_shape, output_shape);
   e09ac:	a907      	add	r1, sp, #28
   e09ae:	a802      	add	r0, sp, #8
   e09b0:	f7fd f86a 	bl	dda88 <_ZN6tflite16MatchingFlatSizeERKNS_12RuntimeShapeES2_>
   e09b4:	f8da 8004 	ldr.w	r8, [sl, #4]
   e09b8:	4605      	mov	r5, r0
   e09ba:	46c2      	mov	sl, r8
  static constexpr int32 min_val = std::numeric_limits<T>::min();
  static constexpr int32 max_val = std::numeric_limits<T>::max();

  for (int i = 0; i < flat_size; i++) {
   e09bc:	ebc8 030a 	rsb	r3, r8, sl
   e09c0:	429d      	cmp	r5, r3
   e09c2:	dd1a      	ble.n	e09fa <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0x10a>
   e09c4:	f854 0b04 	ldr.w	r0, [r4], #4
   e09c8:	f007 fcd8 	bl	e837c <__aeabi_f2d>
   e09cc:	4632      	mov	r2, r6
   e09ce:	463b      	mov	r3, r7
   e09d0:	f007 fe52 	bl	e8678 <__aeabi_ddiv>
   e09d4:	ec41 0b10 	vmov	d0, r0, r1
   e09d8:	f005 fdfc 	bl	e65d4 <round>
    const float val = input_data[i];
    int32 unclamped = static_cast<int32>(TfLiteRound(val / scale)) + zero_point;
   e09dc:	ec51 0b10 	vmov	r0, r1, d0
   e09e0:	f007 ffba 	bl	e8958 <__aeabi_d2iz>
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
   e09e4:	eb10 0009 	adds.w	r0, r0, r9
   e09e8:	d403      	bmi.n	e09f2 <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0x102>
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
   e09ea:	28ff      	cmp	r0, #255	; 0xff
   e09ec:	bfa8      	it	ge
   e09ee:	20ff      	movge	r0, #255	; 0xff
   e09f0:	e000      	b.n	e09f4 <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0x104>
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
	return __b;
   e09f2:	2000      	movs	r0, #0
    int32 clamped = std::min(std::max(unclamped, min_val), max_val);
    output_data[i] = clamped;
   e09f4:	f80a 0b01 	strb.w	r0, [sl], #1
   e09f8:	e7e0      	b.n	e09bc <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0xcc>
   e09fa:	a807      	add	r0, sp, #28
   e09fc:	f7f6 fdb5 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          op_params, GetTensorShape(input), GetTensorData<float>(input),
          GetTensorShape(output), GetTensorData<int8_t>(output));
      break;
    case kTfLiteUInt8:
      reference_ops::AffineQuantize(
          op_params, GetTensorShape(input), GetTensorData<float>(input),
   e0a00:	a802      	add	r0, sp, #8
   e0a02:	f7f6 fdb2 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      context->ReportError(context, "Output type %s (%d) not supported",
                           TfLiteTypeGetName(input->type), output->type);
      return kTfLiteError;
  }

  return kTfLiteOk;
   e0a06:	2000      	movs	r0, #0
      break;
    case kTfLiteUInt8:
      reference_ops::AffineQuantize(
          op_params, GetTensorShape(input), GetTensorData<float>(input),
          GetTensorShape(output), GetTensorData<uint8_t>(output));
      break;
   e0a08:	e00c      	b.n	e0a24 <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0x134>
    default:
      context->ReportError(context, "Output type %s (%d) not supported",
   e0a0a:	f818 0003 	ldrb.w	r0, [r8, r3]
   e0a0e:	f8db 4014 	ldr.w	r4, [fp, #20]
   e0a12:	f7f3 fb8b 	bl	d412c <TfLiteTypeGetName>
                           TfLiteTypeGetName(input->type), output->type);
   e0a16:	f818 3005 	ldrb.w	r3, [r8, r5]
   e0a1a:	4904      	ldr	r1, [pc, #16]	; (e0a2c <_ZN6tflite3ops5micro8quantize4EvalEP13TfLiteContextP10TfLiteNode+0x13c>)
   e0a1c:	4602      	mov	r2, r0
   e0a1e:	4658      	mov	r0, fp
   e0a20:	47a0      	blx	r4
      return kTfLiteError;
   e0a22:	2001      	movs	r0, #1
  }

  return kTfLiteOk;
}
   e0a24:	b00d      	add	sp, #52	; 0x34
   e0a26:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e0a2a:	bf00      	nop
   e0a2c:	000ebc8c 	.word	0x000ebc8c

000e0a30 <_ZN6tflite3ops5micro17Register_QUANTIZEEv>:
// quantized output, in int8 or uint8 format.
TfLiteRegistration* Register_QUANTIZE() {
  static TfLiteRegistration r = {quantize::Init, quantize::Free,
                                 quantize::Prepare, quantize::Eval};
  return &r;
}
   e0a30:	4800      	ldr	r0, [pc, #0]	; (e0a34 <_ZN6tflite3ops5micro17Register_QUANTIZEEv+0x4>)
   e0a32:	4770      	bx	lr
   e0a34:	2003c110 	.word	0x2003c110

000e0a38 <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode>:
  TF_LITE_ENSURE_EQ(context, input->type, output->type);
  TF_LITE_ENSURE_EQ(context, num_input_elements, num_output_elements);
  return kTfLiteOk;
}

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   e0a38:	b530      	push	{r4, r5, lr}
}
inline const TfLiteTensor* GetIntermediates(TfLiteContext* context,
                                            TfLiteNode* node, int index) {
  return &context->tensors[node->intermediates->data[index]];
}
inline int NumInputs(const TfLiteNode* node) { return node->inputs->size; }
   e0a3a:	680b      	ldr	r3, [r1, #0]
  TF_LITE_ENSURE(context, NumInputs(node) == 1 || NumInputs(node) == 2);
   e0a3c:	681b      	ldr	r3, [r3, #0]
   e0a3e:	3b01      	subs	r3, #1
   e0a40:	2b01      	cmp	r3, #1
  TF_LITE_ENSURE_EQ(context, input->type, output->type);
  TF_LITE_ENSURE_EQ(context, num_input_elements, num_output_elements);
  return kTfLiteOk;
}

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   e0a42:	b085      	sub	sp, #20
   e0a44:	4602      	mov	r2, r0
  TF_LITE_ENSURE(context, NumInputs(node) == 1 || NumInputs(node) == 2);
   e0a46:	d813      	bhi.n	e0a70 <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x38>
inline int NumOutputs(const TfLiteNode* node) { return node->outputs->size; }
   e0a48:	684b      	ldr	r3, [r1, #4]
   e0a4a:	681b      	ldr	r3, [r3, #0]
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
   e0a4c:	2b01      	cmp	r3, #1
   e0a4e:	d00d      	beq.n	e0a6c <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x34>
   e0a50:	9302      	str	r3, [sp, #8]
   e0a52:	4b0c      	ldr	r3, [pc, #48]	; (e0a84 <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x4c>)
   e0a54:	9301      	str	r3, [sp, #4]
   e0a56:	2401      	movs	r4, #1
   e0a58:	4b0b      	ldr	r3, [pc, #44]	; (e0a88 <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x50>)
   e0a5a:	9300      	str	r3, [sp, #0]
   e0a5c:	9403      	str	r4, [sp, #12]
   e0a5e:	6955      	ldr	r5, [r2, #20]
   e0a60:	490a      	ldr	r1, [pc, #40]	; (e0a8c <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x54>)
   e0a62:	4a0b      	ldr	r2, [pc, #44]	; (e0a90 <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x58>)
   e0a64:	2348      	movs	r3, #72	; 0x48
   e0a66:	47a8      	blx	r5
   e0a68:	4620      	mov	r0, r4
   e0a6a:	e009      	b.n	e0a80 <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x48>
  return kTfLiteOk;
   e0a6c:	2000      	movs	r0, #0
   e0a6e:	e007      	b.n	e0a80 <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x48>
  TF_LITE_ENSURE_EQ(context, num_input_elements, num_output_elements);
  return kTfLiteOk;
}

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  TF_LITE_ENSURE(context, NumInputs(node) == 1 || NumInputs(node) == 2);
   e0a70:	4b08      	ldr	r3, [pc, #32]	; (e0a94 <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x5c>)
   e0a72:	9300      	str	r3, [sp, #0]
   e0a74:	6944      	ldr	r4, [r0, #20]
   e0a76:	4a06      	ldr	r2, [pc, #24]	; (e0a90 <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x58>)
   e0a78:	4907      	ldr	r1, [pc, #28]	; (e0a98 <_ZN6tflite3ops5micro7reshape7PrepareEP13TfLiteContextP10TfLiteNode+0x60>)
   e0a7a:	2347      	movs	r3, #71	; 0x47
   e0a7c:	47a0      	blx	r4
   e0a7e:	2001      	movs	r0, #1
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
  return kTfLiteOk;
}
   e0a80:	b005      	add	sp, #20
   e0a82:	bd30      	pop	{r4, r5, pc}
   e0a84:	000ecdd6 	.word	0x000ecdd6
   e0a88:	000eb3e3 	.word	0x000eb3e3
   e0a8c:	000eb3b9 	.word	0x000eb3b9
   e0a90:	000ebcae 	.word	0x000ebcae
   e0a94:	000ebd5c 	.word	0x000ebd5c
   e0a98:	000eb58e 	.word	0x000eb58e

000e0a9c <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode>:

constexpr int kInputTensor = 0;
constexpr int kShapeTensor = 1;
constexpr int kOutputTensor = 0;

TfLiteStatus ReshapeOutput(TfLiteContext* context, TfLiteNode* node) {
   e0a9c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e0aa0:	f8d1 c000 	ldr.w	ip, [r1]
   e0aa4:	6886      	ldr	r6, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e0aa6:	f8dc 7004 	ldr.w	r7, [ip, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0aaa:	6849      	ldr	r1, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e0aac:	2338      	movs	r3, #56	; 0x38
   e0aae:	435f      	muls	r7, r3
   e0ab0:	19f2      	adds	r2, r6, r7
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0ab2:	684d      	ldr	r5, [r1, #4]
   e0ab4:	6891      	ldr	r1, [r2, #8]
   e0ab6:	435d      	muls	r5, r3
  return node->intermediates->size;
}

inline int64_t NumElements(const TfLiteIntArray* dims) {
  int64_t count = 1;
  for (int i = 0; i < dims->size; ++i) {
   e0ab8:	f8d1 b000 	ldr.w	fp, [r1]
   e0abc:	b085      	sub	sp, #20
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0abe:	eb06 0a05 	add.w	sl, r6, r5
  return node->intermediates->size;
}

inline int64_t NumElements(const TfLiteIntArray* dims) {
  int64_t count = 1;
  for (int i = 0; i < dims->size; ++i) {
   e0ac2:	2400      	movs	r4, #0
inline int NumIntermediates(const TfLiteNode* node) {
  return node->intermediates->size;
}

inline int64_t NumElements(const TfLiteIntArray* dims) {
  int64_t count = 1;
   e0ac4:	2201      	movs	r2, #1
   e0ac6:	2300      	movs	r3, #0
  for (int i = 0; i < dims->size; ++i) {
   e0ac8:	45a3      	cmp	fp, r4
   e0aca:	dd0c      	ble.n	e0ae6 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x4a>
    count *= dims->data[i];
   e0acc:	f851 ef04 	ldr.w	lr, [r1, #4]!
   e0ad0:	ea4f 79ee 	mov.w	r9, lr, asr #31
   e0ad4:	fb02 f809 	mul.w	r8, r2, r9
   e0ad8:	fb0e 8803 	mla	r8, lr, r3, r8
   e0adc:	fba2 230e 	umull	r2, r3, r2, lr
   e0ae0:	4443      	add	r3, r8
  return node->intermediates->size;
}

inline int64_t NumElements(const TfLiteIntArray* dims) {
  int64_t count = 1;
  for (int i = 0; i < dims->size; ++i) {
   e0ae2:	3401      	adds	r4, #1
   e0ae4:	e7f0      	b.n	e0ac8 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x2c>
  // of output elements in the same as the number of input elements.
  int num_input_elements = NumElements(input);
  TfLiteIntArray* output_shape = output->dims;

  if (NumInputs(node) == 1 &&  // Legacy scalar supported with params.
      output_shape->size == 1 && output_shape->data[0] == 0) {
   e0ae6:	f8dc 3000 	ldr.w	r3, [ip]
  // Tensorflow's Reshape allows one of the shape components to have the
  // special -1 value, meaning it will be calculated automatically based on the
  // input. Here we calculate what that dimension should be so that the number
  // of output elements in the same as the number of input elements.
  int num_input_elements = NumElements(input);
  TfLiteIntArray* output_shape = output->dims;
   e0aea:	f8da 4008 	ldr.w	r4, [sl, #8]

  if (NumInputs(node) == 1 &&  // Legacy scalar supported with params.
      output_shape->size == 1 && output_shape->data[0] == 0) {
   e0aee:	2b01      	cmp	r3, #1
   e0af0:	d105      	bne.n	e0afe <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x62>
  // input. Here we calculate what that dimension should be so that the number
  // of output elements in the same as the number of input elements.
  int num_input_elements = NumElements(input);
  TfLiteIntArray* output_shape = output->dims;

  if (NumInputs(node) == 1 &&  // Legacy scalar supported with params.
   e0af2:	6823      	ldr	r3, [r4, #0]
   e0af4:	2b01      	cmp	r3, #1
   e0af6:	d102      	bne.n	e0afe <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x62>
      output_shape->size == 1 && output_shape->data[0] == 0) {
   e0af8:	6863      	ldr	r3, [r4, #4]
   e0afa:	2b00      	cmp	r3, #0
   e0afc:	d04c      	beq.n	e0b98 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0xfc>
    output_shape->size = 0;
  }

  int num_output_elements = 1;
  int stretch_dim = -1;
  for (int i = 0; i < output_shape->size; ++i) {
   e0afe:	f8d4 9000 	ldr.w	r9, [r4]
   e0b02:	46a0      	mov	r8, r4
   e0b04:	f04f 31ff 	mov.w	r1, #4294967295	; 0xffffffff
   e0b08:	2301      	movs	r3, #1
   e0b0a:	f04f 0e00 	mov.w	lr, #0
   e0b0e:	45ce      	cmp	lr, r9
   e0b10:	da18      	bge.n	e0b44 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0xa8>
    int value = output_shape->data[i];
   e0b12:	f858 cf04 	ldr.w	ip, [r8, #4]!
    if (value == -1) {
   e0b16:	f1bc 3fff 	cmp.w	ip, #4294967295	; 0xffffffff
   e0b1a:	d10c      	bne.n	e0b36 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x9a>
      TF_LITE_ENSURE_EQ(context, stretch_dim, -1);
   e0b1c:	f1b1 3fff 	cmp.w	r1, #4294967295	; 0xffffffff
   e0b20:	d00c      	beq.n	e0b3c <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0xa0>
   e0b22:	4b20      	ldr	r3, [pc, #128]	; (e0ba4 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x108>)
   e0b24:	9301      	str	r3, [sp, #4]
   e0b26:	4b20      	ldr	r3, [pc, #128]	; (e0ba8 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x10c>)
   e0b28:	9300      	str	r3, [sp, #0]
   e0b2a:	f8cd c00c 	str.w	ip, [sp, #12]
   e0b2e:	9102      	str	r1, [sp, #8]
   e0b30:	6944      	ldr	r4, [r0, #20]
   e0b32:	2336      	movs	r3, #54	; 0x36
   e0b34:	e029      	b.n	e0b8a <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0xee>
      stretch_dim = i;
    } else {
      num_output_elements *= value;
   e0b36:	fb0c f303 	mul.w	r3, ip, r3
   e0b3a:	e000      	b.n	e0b3e <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0xa2>
   e0b3c:	4671      	mov	r1, lr
    output_shape->size = 0;
  }

  int num_output_elements = 1;
  int stretch_dim = -1;
  for (int i = 0; i < output_shape->size; ++i) {
   e0b3e:	f10e 0e01 	add.w	lr, lr, #1
   e0b42:	e7e4      	b.n	e0b0e <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x72>
      stretch_dim = i;
    } else {
      num_output_elements *= value;
    }
  }
  if (stretch_dim != -1) {
   e0b44:	f1b1 3fff 	cmp.w	r1, #4294967295	; 0xffffffff
    output_shape->data[stretch_dim] = num_input_elements / num_output_elements;
   e0b48:	bf1e      	ittt	ne
   e0b4a:	eb04 0181 	addne.w	r1, r4, r1, lsl #2
   e0b4e:	fb92 fef3 	sdivne	lr, r2, r3
   e0b52:	f8c1 e004 	strne.w	lr, [r1, #4]
    num_output_elements *= output_shape->data[stretch_dim];
  }

  TF_LITE_ENSURE_EQ(context, input->type, output->type);
   e0b56:	5df1      	ldrb	r1, [r6, r7]
   e0b58:	5d74      	ldrb	r4, [r6, r5]
      num_output_elements *= value;
    }
  }
  if (stretch_dim != -1) {
    output_shape->data[stretch_dim] = num_input_elements / num_output_elements;
    num_output_elements *= output_shape->data[stretch_dim];
   e0b5a:	bf18      	it	ne
   e0b5c:	fb0e f303 	mulne.w	r3, lr, r3
  }

  TF_LITE_ENSURE_EQ(context, input->type, output->type);
   e0b60:	42a1      	cmp	r1, r4
   e0b62:	d008      	beq.n	e0b76 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0xda>
   e0b64:	4b11      	ldr	r3, [pc, #68]	; (e0bac <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x110>)
   e0b66:	9301      	str	r3, [sp, #4]
   e0b68:	4b11      	ldr	r3, [pc, #68]	; (e0bb0 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x114>)
   e0b6a:	9300      	str	r3, [sp, #0]
   e0b6c:	9403      	str	r4, [sp, #12]
   e0b6e:	9102      	str	r1, [sp, #8]
   e0b70:	6944      	ldr	r4, [r0, #20]
   e0b72:	2341      	movs	r3, #65	; 0x41
   e0b74:	e009      	b.n	e0b8a <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0xee>
  TF_LITE_ENSURE_EQ(context, num_input_elements, num_output_elements);
   e0b76:	429a      	cmp	r2, r3
   e0b78:	d00c      	beq.n	e0b94 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0xf8>
   e0b7a:	9303      	str	r3, [sp, #12]
   e0b7c:	4b0d      	ldr	r3, [pc, #52]	; (e0bb4 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x118>)
   e0b7e:	9301      	str	r3, [sp, #4]
   e0b80:	4b0d      	ldr	r3, [pc, #52]	; (e0bb8 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x11c>)
   e0b82:	9300      	str	r3, [sp, #0]
   e0b84:	9202      	str	r2, [sp, #8]
   e0b86:	6944      	ldr	r4, [r0, #20]
   e0b88:	2342      	movs	r3, #66	; 0x42
   e0b8a:	4a0c      	ldr	r2, [pc, #48]	; (e0bbc <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x120>)
   e0b8c:	490c      	ldr	r1, [pc, #48]	; (e0bc0 <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x124>)
   e0b8e:	47a0      	blx	r4
   e0b90:	2001      	movs	r0, #1
   e0b92:	e003      	b.n	e0b9c <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x100>
  return kTfLiteOk;
   e0b94:	2000      	movs	r0, #0
   e0b96:	e001      	b.n	e0b9c <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x100>
  if (NumInputs(node) == 1 &&  // Legacy scalar supported with params.
      output_shape->size == 1 && output_shape->data[0] == 0) {
    // Legacy tflite models use a shape parameter of [0] to indicate scalars,
    // so adjust accordingly. TODO(b/111614235): Allow zero-sized buffers during
    // toco conversion.
    output_shape->size = 0;
   e0b98:	6023      	str	r3, [r4, #0]
   e0b9a:	e7b0      	b.n	e0afe <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode+0x62>
  }

  TF_LITE_ENSURE_EQ(context, input->type, output->type);
  TF_LITE_ENSURE_EQ(context, num_input_elements, num_output_elements);
  return kTfLiteOk;
}
   e0b9c:	b005      	add	sp, #20
   e0b9e:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e0ba2:	bf00      	nop
   e0ba4:	000ebd89 	.word	0x000ebd89
   e0ba8:	000ebd8c 	.word	0x000ebd8c
   e0bac:	000eb400 	.word	0x000eb400
   e0bb0:	000eb3f4 	.word	0x000eb3f4
   e0bb4:	000ebd98 	.word	0x000ebd98
   e0bb8:	000ebdac 	.word	0x000ebdac
   e0bbc:	000ebcae 	.word	0x000ebcae
   e0bc0:	000eb3b9 	.word	0x000eb3b9

000e0bc4 <_ZN6tflite3ops5micro7reshape4EvalEP13TfLiteContextP10TfLiteNode>:
  TF_LITE_ENSURE(context, NumInputs(node) == 1 || NumInputs(node) == 2);
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e0bc4:	b570      	push	{r4, r5, r6, lr}
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e0bc6:	680a      	ldr	r2, [r1, #0]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0bc8:	684b      	ldr	r3, [r1, #4]
   e0bca:	6886      	ldr	r6, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e0bcc:	6854      	ldr	r4, [r2, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0bce:	685d      	ldr	r5, [r3, #4]
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  if (ReshapeOutput(context, node) != kTfLiteOk) {
   e0bd0:	f7ff ff64 	bl	e0a9c <_ZN6tflite3ops5micro7reshape13ReshapeOutputEP13TfLiteContextP10TfLiteNode>
   e0bd4:	b970      	cbnz	r0, e0bf4 <_ZN6tflite3ops5micro7reshape4EvalEP13TfLiteContextP10TfLiteNode+0x30>
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e0bd6:	2338      	movs	r3, #56	; 0x38
   e0bd8:	fb03 6204 	mla	r2, r3, r4, r6
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0bdc:	fb03 6505 	mla	r5, r3, r5, r6
   e0be0:	4603      	mov	r3, r0
    return kTfLiteError;
  }

  for (int i = 0; i < input->bytes; ++i) {
   e0be2:	6991      	ldr	r1, [r2, #24]
   e0be4:	4299      	cmp	r1, r3
   e0be6:	d906      	bls.n	e0bf6 <_ZN6tflite3ops5micro7reshape4EvalEP13TfLiteContextP10TfLiteNode+0x32>
    output->data.raw[i] = input->data.raw[i];
   e0be8:	6851      	ldr	r1, [r2, #4]
   e0bea:	5ccc      	ldrb	r4, [r1, r3]
   e0bec:	6869      	ldr	r1, [r5, #4]
   e0bee:	54cc      	strb	r4, [r1, r3]
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  if (ReshapeOutput(context, node) != kTfLiteOk) {
    return kTfLiteError;
  }

  for (int i = 0; i < input->bytes; ++i) {
   e0bf0:	3301      	adds	r3, #1
   e0bf2:	e7f6      	b.n	e0be2 <_ZN6tflite3ops5micro7reshape4EvalEP13TfLiteContextP10TfLiteNode+0x1e>

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  if (ReshapeOutput(context, node) != kTfLiteOk) {
    return kTfLiteError;
   e0bf4:	2001      	movs	r0, #1

  for (int i = 0; i < input->bytes; ++i) {
    output->data.raw[i] = input->data.raw[i];
  }
  return kTfLiteOk;
}
   e0bf6:	bd70      	pop	{r4, r5, r6, pc}

000e0bf8 <_ZN6tflite3ops5micro16Register_RESHAPEEv>:

TfLiteRegistration* Register_RESHAPE() {
  static TfLiteRegistration r = {nullptr, nullptr, reshape::Prepare,
                                 reshape::Eval};
  return &r;
}
   e0bf8:	4800      	ldr	r0, [pc, #0]	; (e0bfc <_ZN6tflite3ops5micro16Register_RESHAPEEv+0x4>)
   e0bfa:	4770      	bx	lr
   e0bfc:	2003c130 	.word	0x2003c130

000e0c00 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode>:
namespace round {

constexpr int kInputTensor = 0;
constexpr int kOutputTensor = 0;

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   e0c00:	b5f0      	push	{r4, r5, r6, r7, lr}
   e0c02:	680b      	ldr	r3, [r1, #0]
}
inline const TfLiteTensor* GetIntermediates(TfLiteContext* context,
                                            TfLiteNode* node, int index) {
  return &context->tensors[node->intermediates->data[index]];
}
inline int NumInputs(const TfLiteNode* node) { return node->inputs->size; }
   e0c04:	681e      	ldr	r6, [r3, #0]
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
   e0c06:	2e01      	cmp	r6, #1
namespace round {

constexpr int kInputTensor = 0;
constexpr int kOutputTensor = 0;

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   e0c08:	b085      	sub	sp, #20
   e0c0a:	4605      	mov	r5, r0
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
   e0c0c:	d009      	beq.n	e0c22 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x22>
   e0c0e:	4b3b      	ldr	r3, [pc, #236]	; (e0cfc <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0xfc>)
   e0c10:	9301      	str	r3, [sp, #4]
   e0c12:	2401      	movs	r4, #1
   e0c14:	4b3a      	ldr	r3, [pc, #232]	; (e0d00 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x100>)
   e0c16:	9300      	str	r3, [sp, #0]
   e0c18:	9403      	str	r4, [sp, #12]
   e0c1a:	9602      	str	r6, [sp, #8]
   e0c1c:	6945      	ldr	r5, [r0, #20]
   e0c1e:	2321      	movs	r3, #33	; 0x21
   e0c20:	e01e      	b.n	e0c60 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x60>
   e0c22:	f8d1 e004 	ldr.w	lr, [r1, #4]
inline int NumOutputs(const TfLiteNode* node) { return node->outputs->size; }
   e0c26:	f8de 4000 	ldr.w	r4, [lr]
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
   e0c2a:	2c01      	cmp	r4, #1
   e0c2c:	d008      	beq.n	e0c40 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x40>
   e0c2e:	4b33      	ldr	r3, [pc, #204]	; (e0cfc <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0xfc>)
   e0c30:	9301      	str	r3, [sp, #4]
   e0c32:	4b34      	ldr	r3, [pc, #208]	; (e0d04 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x104>)
   e0c34:	9300      	str	r3, [sp, #0]
   e0c36:	9603      	str	r6, [sp, #12]
   e0c38:	9402      	str	r4, [sp, #8]
   e0c3a:	6944      	ldr	r4, [r0, #20]
   e0c3c:	2322      	movs	r3, #34	; 0x22
   e0c3e:	e022      	b.n	e0c86 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x86>
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e0c40:	6859      	ldr	r1, [r3, #4]
   e0c42:	6882      	ldr	r2, [r0, #8]
   e0c44:	2338      	movs	r3, #56	; 0x38
   e0c46:	4359      	muls	r1, r3
   e0c48:	1857      	adds	r7, r2, r1
  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);
   e0c4a:	5c56      	ldrb	r6, [r2, r1]
   e0c4c:	2e01      	cmp	r6, #1
   e0c4e:	d00b      	beq.n	e0c68 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x68>
   e0c50:	4b2d      	ldr	r3, [pc, #180]	; (e0d08 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x108>)
   e0c52:	9301      	str	r3, [sp, #4]
   e0c54:	4b2d      	ldr	r3, [pc, #180]	; (e0d0c <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x10c>)
   e0c56:	9300      	str	r3, [sp, #0]
   e0c58:	9403      	str	r4, [sp, #12]
   e0c5a:	9602      	str	r6, [sp, #8]
   e0c5c:	6945      	ldr	r5, [r0, #20]
   e0c5e:	2323      	movs	r3, #35	; 0x23
   e0c60:	4a2b      	ldr	r2, [pc, #172]	; (e0d10 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x110>)
   e0c62:	492c      	ldr	r1, [pc, #176]	; (e0d14 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x114>)
   e0c64:	47a8      	blx	r5
   e0c66:	e042      	b.n	e0cee <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0xee>
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0c68:	f8de 1004 	ldr.w	r1, [lr, #4]
   e0c6c:	434b      	muls	r3, r1
   e0c6e:	18d1      	adds	r1, r2, r3
  TF_LITE_ENSURE_EQ(context, output->type, input->type);
   e0c70:	5cd4      	ldrb	r4, [r2, r3]
   e0c72:	2c01      	cmp	r4, #1
   e0c74:	d00a      	beq.n	e0c8c <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x8c>
   e0c76:	4b25      	ldr	r3, [pc, #148]	; (e0d0c <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x10c>)
   e0c78:	9301      	str	r3, [sp, #4]
   e0c7a:	4b27      	ldr	r3, [pc, #156]	; (e0d18 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x118>)
   e0c7c:	9300      	str	r3, [sp, #0]
   e0c7e:	9603      	str	r6, [sp, #12]
   e0c80:	9402      	str	r4, [sp, #8]
   e0c82:	6944      	ldr	r4, [r0, #20]
   e0c84:	2324      	movs	r3, #36	; 0x24
   e0c86:	4a22      	ldr	r2, [pc, #136]	; (e0d10 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x110>)
   e0c88:	4922      	ldr	r1, [pc, #136]	; (e0d14 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x114>)
   e0c8a:	e02f      	b.n	e0cec <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0xec>
  TF_LITE_ENSURE_EQ(context, output->bytes, input->bytes);
   e0c8c:	698b      	ldr	r3, [r1, #24]
   e0c8e:	69ba      	ldr	r2, [r7, #24]
   e0c90:	4293      	cmp	r3, r2
   e0c92:	d008      	beq.n	e0ca6 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0xa6>
   e0c94:	9302      	str	r3, [sp, #8]
   e0c96:	4b21      	ldr	r3, [pc, #132]	; (e0d1c <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x11c>)
   e0c98:	9301      	str	r3, [sp, #4]
   e0c9a:	4b21      	ldr	r3, [pc, #132]	; (e0d20 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x120>)
   e0c9c:	9300      	str	r3, [sp, #0]
   e0c9e:	9203      	str	r2, [sp, #12]
   e0ca0:	6945      	ldr	r5, [r0, #20]
   e0ca2:	2325      	movs	r3, #37	; 0x25
   e0ca4:	e7dc      	b.n	e0c60 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x60>
  TF_LITE_ENSURE_EQ(context, output->dims->size, input->dims->size);
   e0ca6:	688b      	ldr	r3, [r1, #8]
   e0ca8:	68ba      	ldr	r2, [r7, #8]
   e0caa:	681e      	ldr	r6, [r3, #0]
   e0cac:	6811      	ldr	r1, [r2, #0]
   e0cae:	428e      	cmp	r6, r1
   e0cb0:	d008      	beq.n	e0cc4 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0xc4>
   e0cb2:	4b1c      	ldr	r3, [pc, #112]	; (e0d24 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x124>)
   e0cb4:	9301      	str	r3, [sp, #4]
   e0cb6:	4b1c      	ldr	r3, [pc, #112]	; (e0d28 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x128>)
   e0cb8:	9300      	str	r3, [sp, #0]
   e0cba:	9103      	str	r1, [sp, #12]
   e0cbc:	9602      	str	r6, [sp, #8]
   e0cbe:	6945      	ldr	r5, [r0, #20]
   e0cc0:	2326      	movs	r3, #38	; 0x26
   e0cc2:	e7cd      	b.n	e0c60 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x60>
   e0cc4:	2100      	movs	r1, #0
  for (int i = 0; i < output->dims->size; ++i) {
   e0cc6:	42b1      	cmp	r1, r6
   e0cc8:	da15      	bge.n	e0cf6 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0xf6>
    TF_LITE_ENSURE_EQ(context, output->dims->data[i], input->dims->data[i]);
   e0cca:	f853 0f04 	ldr.w	r0, [r3, #4]!
   e0cce:	f852 4f04 	ldr.w	r4, [r2, #4]!
   e0cd2:	42a0      	cmp	r0, r4
   e0cd4:	d00d      	beq.n	e0cf2 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0xf2>
   e0cd6:	4b15      	ldr	r3, [pc, #84]	; (e0d2c <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x12c>)
   e0cd8:	9301      	str	r3, [sp, #4]
   e0cda:	4b15      	ldr	r3, [pc, #84]	; (e0d30 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x130>)
   e0cdc:	9002      	str	r0, [sp, #8]
   e0cde:	9300      	str	r3, [sp, #0]
   e0ce0:	9403      	str	r4, [sp, #12]
   e0ce2:	696c      	ldr	r4, [r5, #20]
   e0ce4:	4a0a      	ldr	r2, [pc, #40]	; (e0d10 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x110>)
   e0ce6:	490b      	ldr	r1, [pc, #44]	; (e0d14 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0x114>)
   e0ce8:	2328      	movs	r3, #40	; 0x28
   e0cea:	4628      	mov	r0, r5
   e0cec:	47a0      	blx	r4
   e0cee:	2001      	movs	r0, #1
   e0cf0:	e002      	b.n	e0cf8 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0xf8>
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);
  TF_LITE_ENSURE_EQ(context, output->type, input->type);
  TF_LITE_ENSURE_EQ(context, output->bytes, input->bytes);
  TF_LITE_ENSURE_EQ(context, output->dims->size, input->dims->size);
  for (int i = 0; i < output->dims->size; ++i) {
   e0cf2:	3101      	adds	r1, #1
   e0cf4:	e7e7      	b.n	e0cc6 <_ZN6tflite3ops5micro5round7PrepareEP13TfLiteContextP10TfLiteNode+0xc6>
    TF_LITE_ENSURE_EQ(context, output->dims->data[i], input->dims->data[i]);
  }
  return kTfLiteOk;
   e0cf6:	2000      	movs	r0, #0
}
   e0cf8:	b005      	add	sp, #20
   e0cfa:	bdf0      	pop	{r4, r5, r6, r7, pc}
   e0cfc:	000ecdd6 	.word	0x000ecdd6
   e0d00:	000eb3d3 	.word	0x000eb3d3
   e0d04:	000eb3e3 	.word	0x000eb3e3
   e0d08:	000ebc41 	.word	0x000ebc41
   e0d0c:	000eb3f4 	.word	0x000eb3f4
   e0d10:	000ebdbf 	.word	0x000ebdbf
   e0d14:	000eb3b9 	.word	0x000eb3b9
   e0d18:	000eb400 	.word	0x000eb400
   e0d1c:	000eb40d 	.word	0x000eb40d
   e0d20:	000eb41a 	.word	0x000eb41a
   e0d24:	000eb428 	.word	0x000eb428
   e0d28:	000eb43a 	.word	0x000eb43a
   e0d2c:	000eb44d 	.word	0x000eb44d
   e0d30:	000eb462 	.word	0x000eb462

000e0d34 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf>:
    return floor_val = floor_val + 1.0f;
  }
}

inline void Round(const RuntimeShape& input_shape, const float* input_data,
                  const RuntimeShape& output_shape, float* output_data) {
   e0d34:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   e0d38:	ed2d 8b04 	vpush	{d8-d9}
   e0d3c:	461e      	mov	r6, r3
   e0d3e:	f8d0 8000 	ldr.w	r8, [r0]

// Flat size calculation, checking that dimensions match with one or more other
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
   e0d42:	6813      	ldr	r3, [r2, #0]
   e0d44:	4598      	cmp	r8, r3
   e0d46:	4604      	mov	r4, r0
   e0d48:	460f      	mov	r7, r1
   e0d4a:	4691      	mov	r9, r2
   e0d4c:	d101      	bne.n	e0d52 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0x1e>
   e0d4e:	2500      	movs	r5, #0
   e0d50:	e00d      	b.n	e0d6e <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0x3a>
   e0d52:	f004 fbcf 	bl	e54f4 <abort>
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
    TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   e0d56:	4629      	mov	r1, r5
   e0d58:	4620      	mov	r0, r4
   e0d5a:	f7f6 fc11 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0d5e:	4629      	mov	r1, r5
   e0d60:	4682      	mov	sl, r0
   e0d62:	4648      	mov	r0, r9
   e0d64:	f7f6 fc0c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0d68:	4582      	cmp	sl, r0
   e0d6a:	d1f2      	bne.n	e0d52 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0x1e>
// arrays.
inline int MatchingFlatSize(const RuntimeShape& shape,
                            const RuntimeShape& check_shape_0) {
  TFLITE_DCHECK_EQ(shape.DimensionsCount(), check_shape_0.DimensionsCount());
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   e0d6c:	3501      	adds	r5, #1
   e0d6e:	45a8      	cmp	r8, r5
   e0d70:	dcf1      	bgt.n	e0d56 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0x22>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   e0d72:	f1b8 0f04 	cmp.w	r8, #4
   e0d76:	bfcc      	ite	gt
   e0d78:	6864      	ldrgt	r4, [r4, #4]
   e0d7a:	3404      	addle	r4, #4
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   e0d7c:	2300      	movs	r3, #0
  }

  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
   e0d7e:	f04f 0901 	mov.w	r9, #1
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   e0d82:	4598      	cmp	r8, r3
   e0d84:	dd05      	ble.n	e0d92 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0x5e>
      buffer_size *= dims_data[i];
   e0d86:	f854 2023 	ldr.w	r2, [r4, r3, lsl #2]
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   e0d8a:	3301      	adds	r3, #1
      buffer_size *= dims_data[i];
   e0d8c:	fb02 f909 	mul.w	r9, r2, r9
   e0d90:	e7f7      	b.n	e0d82 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0x4e>
   e0d92:	4634      	mov	r4, r6
   e0d94:	463d      	mov	r5, r7
  // Returns the total count of elements, that is the size when flattened into a
  // vector.
  inline int FlatSize() const {
    int buffer_size = 1;
    const int* dims_data = reinterpret_cast<const int*>(DimsData());
    for (int i = 0; i < size_; i++) {
   e0d96:	2600      	movs	r6, #0
namespace reference_ops {

inline float RoundToNearest(float value) {
  auto floor_val = std::floor(value);
  auto diff = value - floor_val;
  if ((diff < 0.5f) ||
   e0d98:	eef6 8a00 	vmov.f32	s17, #96	; 0x3f000000  0.5
      ((diff == 0.5f) && (static_cast<int>(floor_val) % 2 == 0))) {
    return floor_val;
  } else {
    return floor_val = floor_val + 1.0f;
   e0d9c:	eeb7 9a00 	vmov.f32	s18, #112	; 0x3f800000  1.0
}

inline void Round(const RuntimeShape& input_shape, const float* input_data,
                  const RuntimeShape& output_shape, float* output_data) {
  const int flat_size = MatchingFlatSize(input_shape, output_shape);
  for (int i = 0; i < flat_size; ++i) {
   e0da0:	454e      	cmp	r6, r9
   e0da2:	da1d      	bge.n	e0de0 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0xac>
    // Note that this implementation matches that of tensorFlow tf.round
    // and corresponds to the bankers rounding method.
    // cfenv (for fesetround) is not yet supported universally on Android, so
    // using a work around.
    output_data[i] = RoundToNearest(input_data[i]);
   e0da4:	ecb5 8a01 	vldmia	r5!, {s16}
  using ::floor;

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  floor(float __x)
  { return __builtin_floorf(__x); }
   e0da8:	eeb0 0a48 	vmov.f32	s0, s16
   e0dac:	f005 fcf8 	bl	e67a0 <floorf>

namespace reference_ops {

inline float RoundToNearest(float value) {
  auto floor_val = std::floor(value);
  auto diff = value - floor_val;
   e0db0:	ee38 8a40 	vsub.f32	s16, s16, s0
  if ((diff < 0.5f) ||
   e0db4:	eeb4 8ae8 	vcmpe.f32	s16, s17
   e0db8:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e0dbc:	d40c      	bmi.n	e0dd8 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0xa4>
   e0dbe:	eeb4 8a68 	vcmp.f32	s16, s17
   e0dc2:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e0dc6:	d105      	bne.n	e0dd4 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0xa0>
      ((diff == 0.5f) && (static_cast<int>(floor_val) % 2 == 0))) {
   e0dc8:	eefd 7ac0 	vcvt.s32.f32	s15, s0
   e0dcc:	ee17 3a90 	vmov	r3, s15
   e0dd0:	07db      	lsls	r3, r3, #31
   e0dd2:	d501      	bpl.n	e0dd8 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0xa4>
    return floor_val;
  } else {
    return floor_val = floor_val + 1.0f;
   e0dd4:	ee30 0a09 	vadd.f32	s0, s0, s18
  for (int i = 0; i < flat_size; ++i) {
    // Note that this implementation matches that of tensorFlow tf.round
    // and corresponds to the bankers rounding method.
    // cfenv (for fesetround) is not yet supported universally on Android, so
    // using a work around.
    output_data[i] = RoundToNearest(input_data[i]);
   e0dd8:	eca4 0a01 	vstmia	r4!, {s0}
}

inline void Round(const RuntimeShape& input_shape, const float* input_data,
                  const RuntimeShape& output_shape, float* output_data) {
  const int flat_size = MatchingFlatSize(input_shape, output_shape);
  for (int i = 0; i < flat_size; ++i) {
   e0ddc:	3601      	adds	r6, #1
   e0dde:	e7df      	b.n	e0da0 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf+0x6c>
    // and corresponds to the bankers rounding method.
    // cfenv (for fesetround) is not yet supported universally on Android, so
    // using a work around.
    output_data[i] = RoundToNearest(input_data[i]);
  }
}
   e0de0:	ecbd 8b04 	vpop	{d8-d9}
   e0de4:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}

000e0de8 <_ZN6tflite3ops5micro5round4EvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e0de8:	b530      	push	{r4, r5, lr}
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e0dea:	680a      	ldr	r2, [r1, #0]
   e0dec:	6883      	ldr	r3, [r0, #8]
   e0dee:	6854      	ldr	r4, [r2, #4]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0df0:	684a      	ldr	r2, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e0df2:	2538      	movs	r5, #56	; 0x38
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0df4:	6852      	ldr	r2, [r2, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e0df6:	fb05 3404 	mla	r4, r5, r4, r3
   e0dfa:	b08b      	sub	sp, #44	; 0x2c
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e0dfc:	fb05 3502 	mla	r5, r5, r2, r3
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
}

inline RuntimeShape GetTensorShape(const TfLiteTensor* tensor) {
  if (tensor == nullptr) {
   e0e00:	b90c      	cbnz	r4, e0e06 <_ZN6tflite3ops5micro5round4EvalEP13TfLiteContextP10TfLiteNode+0x1e>
  // larger shapes are separately allocated.
  static constexpr int kMaxSmallSize = 4;

  RuntimeShape& operator=(RuntimeShape const&) = delete;

  RuntimeShape() : size_(0) {}
   e0e02:	9400      	str	r4, [sp, #0]
   e0e04:	e008      	b.n	e0e18 <_ZN6tflite3ops5micro5round4EvalEP13TfLiteContextP10TfLiteNode+0x30>
    return RuntimeShape();
  }

  TfLiteIntArray* dims = tensor->dims;
  const int dims_size = dims->size;
   e0e06:	68a2      	ldr	r2, [r4, #8]
    for (int i = 0; i < shape_size; ++i) {
      SetDim(i, value);
    }
  }

  RuntimeShape(int dimensions_count, const int32* dims_data) : size_(0) {
   e0e08:	2300      	movs	r3, #0
   e0e0a:	f852 1b04 	ldr.w	r1, [r2], #4
   e0e0e:	9300      	str	r3, [sp, #0]
    ReplaceWith(dimensions_count, dims_data);
   e0e10:	4668      	mov	r0, sp
   e0e12:	f7f8 f849 	bl	d8ea8 <_ZN6tflite12RuntimeShape11ReplaceWithEiPKl>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e0e16:	6864      	ldr	r4, [r4, #4]
}

inline RuntimeShape GetTensorShape(const TfLiteTensor* tensor) {
  if (tensor == nullptr) {
   e0e18:	b915      	cbnz	r5, e0e20 <_ZN6tflite3ops5micro5round4EvalEP13TfLiteContextP10TfLiteNode+0x38>
  // larger shapes are separately allocated.
  static constexpr int kMaxSmallSize = 4;

  RuntimeShape& operator=(RuntimeShape const&) = delete;

  RuntimeShape() : size_(0) {}
   e0e1a:	9505      	str	r5, [sp, #20]

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e0e1c:	462b      	mov	r3, r5
   e0e1e:	e008      	b.n	e0e32 <_ZN6tflite3ops5micro5round4EvalEP13TfLiteContextP10TfLiteNode+0x4a>
  if (tensor == nullptr) {
    return RuntimeShape();
  }

  TfLiteIntArray* dims = tensor->dims;
  const int dims_size = dims->size;
   e0e20:	68aa      	ldr	r2, [r5, #8]
    for (int i = 0; i < shape_size; ++i) {
      SetDim(i, value);
    }
  }

  RuntimeShape(int dimensions_count, const int32* dims_data) : size_(0) {
   e0e22:	2300      	movs	r3, #0
   e0e24:	f852 1b04 	ldr.w	r1, [r2], #4
   e0e28:	9305      	str	r3, [sp, #20]
    ReplaceWith(dimensions_count, dims_data);
   e0e2a:	a805      	add	r0, sp, #20
   e0e2c:	f7f8 f83c 	bl	d8ea8 <_ZN6tflite12RuntimeShape11ReplaceWithEiPKl>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e0e30:	686b      	ldr	r3, [r5, #4]
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  reference_ops::Round(GetTensorShape(input), GetTensorData<float>(input),
                       GetTensorShape(output), GetTensorData<float>(output));
   e0e32:	aa05      	add	r2, sp, #20
   e0e34:	4621      	mov	r1, r4
   e0e36:	4668      	mov	r0, sp
   e0e38:	f7ff ff7c 	bl	e0d34 <_ZN6tflite13reference_ops5RoundERKNS_12RuntimeShapeEPKfS3_Pf>
   e0e3c:	a805      	add	r0, sp, #20
   e0e3e:	f7f6 fb94 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  reference_ops::Round(GetTensorShape(input), GetTensorData<float>(input),
   e0e42:	4668      	mov	r0, sp
   e0e44:	f7f6 fb91 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                       GetTensorShape(output), GetTensorData<float>(output));

  return kTfLiteOk;
}
   e0e48:	2000      	movs	r0, #0
   e0e4a:	b00b      	add	sp, #44	; 0x2c
   e0e4c:	bd30      	pop	{r4, r5, pc}
	...

000e0e50 <_ZN6tflite3ops5micro14Register_ROUNDEv>:

TfLiteRegistration* Register_ROUND() {
  static TfLiteRegistration r = {/*init=*/nullptr,
                                 /*free=*/nullptr, round::Prepare, round::Eval};
  return &r;
}
   e0e50:	4800      	ldr	r0, [pc, #0]	; (e0e54 <_ZN6tflite3ops5micro14Register_ROUNDEv+0x4>)
   e0e52:	4770      	bx	lr
   e0e54:	2003c150 	.word	0x2003c150

000e0e58 <_ZN6tflite3ops5micro11activations4InitEP13TfLiteContextPKcj>:

}  // namespace

void* Init(TfLiteContext* context, const char* buffer, size_t length) {
  return nullptr;
}
   e0e58:	2000      	movs	r0, #0
   e0e5a:	4770      	bx	lr

000e0e5c <_ZN6tflite3ops5micro11activations4FreeEP13TfLiteContextPv>:

void Free(TfLiteContext* context, void* buffer) {}
   e0e5c:	4770      	bx	lr

000e0e5e <_ZN6tflite3ops5micro11activations14SoftmaxPrepareEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus SoftmaxPrepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   e0e5e:	2000      	movs	r0, #0
   e0e60:	4770      	bx	lr
	...

000e0e64 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_>:
// This function implements the same computation as the ARMv7 NEON VQRDMULH
// instruction.
template <>
inline std::int32_t SaturatingRoundingDoublingHighMul(std::int32_t a,
                                                      std::int32_t b) {
  bool overflow = a == b && a == std::numeric_limits<std::int32_t>::min();
   e0e64:	4288      	cmp	r0, r1

// This function implements the same computation as the ARMv7 NEON VQRDMULH
// instruction.
template <>
inline std::int32_t SaturatingRoundingDoublingHighMul(std::int32_t a,
                                                      std::int32_t b) {
   e0e66:	b510      	push	{r4, lr}
  bool overflow = a == b && a == std::numeric_limits<std::int32_t>::min();
   e0e68:	d104      	bne.n	e0e74 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_+0x10>
   e0e6a:	f100 4300 	add.w	r3, r0, #2147483648	; 0x80000000
   e0e6e:	425c      	negs	r4, r3
   e0e70:	415c      	adcs	r4, r3
   e0e72:	e000      	b.n	e0e76 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_+0x12>
   e0e74:	2400      	movs	r4, #0
  std::int64_t a_64(a);
  std::int64_t b_64(b);
  std::int64_t ab_64 = a_64 * b_64;
   e0e76:	fb80 2301 	smull	r2, r3, r0, r1
  std::int32_t nudge = ab_64 >= 0 ? (1 << 30) : (1 - (1 << 30));
   e0e7a:	2a00      	cmp	r2, #0
   e0e7c:	f173 0100 	sbcs.w	r1, r3, #0
   e0e80:	490b      	ldr	r1, [pc, #44]	; (e0eb0 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_+0x4c>)
   e0e82:	bfa8      	it	ge
   e0e84:	f04f 4180 	movge.w	r1, #1073741824	; 0x40000000
  std::int32_t ab_x2_high32 =
      static_cast<std::int32_t>((ab_64 + nudge) / (1ll << 31));
  return overflow ? std::numeric_limits<std::int32_t>::max() : ab_x2_high32;
   e0e88:	b97c      	cbnz	r4, e0eaa <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_+0x46>
  std::int64_t a_64(a);
  std::int64_t b_64(b);
  std::int64_t ab_64 = a_64 * b_64;
  std::int32_t nudge = ab_64 >= 0 ? (1 << 30) : (1 - (1 << 30));
  std::int32_t ab_x2_high32 =
      static_cast<std::int32_t>((ab_64 + nudge) / (1ll << 31));
   e0e8a:	1852      	adds	r2, r2, r1
   e0e8c:	eb43 73e1 	adc.w	r3, r3, r1, asr #31
   e0e90:	2a00      	cmp	r2, #0
   e0e92:	f173 0100 	sbcs.w	r1, r3, #0
   e0e96:	da04      	bge.n	e0ea2 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_+0x3e>
   e0e98:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
   e0e9c:	2100      	movs	r1, #0
   e0e9e:	1812      	adds	r2, r2, r0
   e0ea0:	414b      	adcs	r3, r1
   e0ea2:	0fd0      	lsrs	r0, r2, #31
   e0ea4:	ea40 0043 	orr.w	r0, r0, r3, lsl #1
   e0ea8:	bd10      	pop	{r4, pc}
  return overflow ? std::numeric_limits<std::int32_t>::max() : ab_x2_high32;
   e0eaa:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
}
   e0eae:	bd10      	pop	{r4, pc}
   e0eb0:	c0000001 	.word	0xc0000001

000e0eb4 <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_>:
  return flat_size;
}

// A combination of MatchingFlatSize() and FlatSizeSkipDim().
inline int MatchingFlatSizeSkipDim(const RuntimeShape& shape, int skip_dim,
                                   const RuntimeShape& check_shape_0) {
   e0eb4:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
   e0eb8:	6806      	ldr	r6, [r0, #0]
   e0eba:	4604      	mov	r4, r0
   e0ebc:	460f      	mov	r7, r1
   e0ebe:	4690      	mov	r8, r2
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   e0ec0:	2500      	movs	r5, #0
   e0ec2:	42b5      	cmp	r5, r6
   e0ec4:	da10      	bge.n	e0ee8 <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_+0x34>
    if (i != skip_dim) {
   e0ec6:	42bd      	cmp	r5, r7
   e0ec8:	d00c      	beq.n	e0ee4 <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_+0x30>
      TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
   e0eca:	4629      	mov	r1, r5
   e0ecc:	4620      	mov	r0, r4
   e0ece:	f7f6 fb57 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0ed2:	4629      	mov	r1, r5
   e0ed4:	4681      	mov	r9, r0
   e0ed6:	4640      	mov	r0, r8
   e0ed8:	f7f6 fb52 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0edc:	4581      	cmp	r9, r0
   e0ede:	d001      	beq.n	e0ee4 <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_+0x30>
   e0ee0:	f004 fb08 	bl	e54f4 <abort>

// A combination of MatchingFlatSize() and FlatSizeSkipDim().
inline int MatchingFlatSizeSkipDim(const RuntimeShape& shape, int skip_dim,
                                   const RuntimeShape& check_shape_0) {
  const int dims_count = shape.DimensionsCount();
  for (int i = 0; i < dims_count; ++i) {
   e0ee4:	3501      	adds	r5, #1
   e0ee6:	e7ec      	b.n	e0ec2 <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_+0xe>
// Data is required to be contiguous, and so many operators can use either the
// full array flat size or the flat size with one dimension skipped (commonly
// the depth).
inline int FlatSizeSkipDim(const RuntimeShape& shape, int skip_dim) {
  const int dims_count = shape.DimensionsCount();
  TFLITE_DCHECK(skip_dim >= 0 && skip_dim < dims_count);
   e0ee8:	2f00      	cmp	r7, #0
   e0eea:	dbf9      	blt.n	e0ee0 <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_+0x2c>
   e0eec:	42b7      	cmp	r7, r6
   e0eee:	daf7      	bge.n	e0ee0 <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_+0x2c>

  inline int32* DimsData() {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
  }
  inline const int32* DimsData() const {
    return size_ > kMaxSmallSize ? dims_pointer_ : dims_;
   e0ef0:	2e04      	cmp	r6, #4
   e0ef2:	bfcc      	ite	gt
   e0ef4:	6864      	ldrgt	r4, [r4, #4]
   e0ef6:	3404      	addle	r4, #4
inline int FlatSizeSkipDim(const RuntimeShape& shape, int skip_dim) {
  const int dims_count = shape.DimensionsCount();
  TFLITE_DCHECK(skip_dim >= 0 && skip_dim < dims_count);
  const auto* dims_data = shape.DimsData();
  int flat_size = 1;
  for (int i = 0; i < dims_count; ++i) {
   e0ef8:	2300      	movs	r3, #0
// the depth).
inline int FlatSizeSkipDim(const RuntimeShape& shape, int skip_dim) {
  const int dims_count = shape.DimensionsCount();
  TFLITE_DCHECK(skip_dim >= 0 && skip_dim < dims_count);
  const auto* dims_data = shape.DimsData();
  int flat_size = 1;
   e0efa:	2001      	movs	r0, #1
  for (int i = 0; i < dims_count; ++i) {
   e0efc:	429e      	cmp	r6, r3
   e0efe:	dd07      	ble.n	e0f10 <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_+0x5c>
    flat_size *= (i == skip_dim) ? 1 : dims_data[i];
   e0f00:	429f      	cmp	r7, r3
   e0f02:	bf14      	ite	ne
   e0f04:	f854 2023 	ldrne.w	r2, [r4, r3, lsl #2]
   e0f08:	2201      	moveq	r2, #1
   e0f0a:	4350      	muls	r0, r2
inline int FlatSizeSkipDim(const RuntimeShape& shape, int skip_dim) {
  const int dims_count = shape.DimensionsCount();
  TFLITE_DCHECK(skip_dim >= 0 && skip_dim < dims_count);
  const auto* dims_data = shape.DimsData();
  int flat_size = 1;
  for (int i = 0; i < dims_count; ++i) {
   e0f0c:	3301      	adds	r3, #1
   e0f0e:	e7f5      	b.n	e0efc <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_+0x48>
    if (i != skip_dim) {
      TFLITE_DCHECK_EQ(shape.Dims(i), check_shape_0.Dims(i));
    }
  }
  return FlatSizeSkipDim(shape, skip_dim);
}
   e0f10:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}

000e0f14 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf>:
namespace tflite {
namespace reference_ops {

inline void Softmax(const SoftmaxParams& params,
                    const RuntimeShape& input_shape, const float* input_data,
                    const RuntimeShape& output_shape, float* output_data) {
   e0f14:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e0f18:	ed2d 8b02 	vpush	{d8}
  const int trailing_dim = input_shape.DimensionsCount() - 1;
   e0f1c:	680e      	ldr	r6, [r1, #0]
namespace tflite {
namespace reference_ops {

inline void Softmax(const SoftmaxParams& params,
                    const RuntimeShape& input_shape, const float* input_data,
                    const RuntimeShape& output_shape, float* output_data) {
   e0f1e:	b089      	sub	sp, #36	; 0x24
   e0f20:	460d      	mov	r5, r1
  const int trailing_dim = input_shape.DimensionsCount() - 1;
   e0f22:	3e01      	subs	r6, #1
namespace tflite {
namespace reference_ops {

inline void Softmax(const SoftmaxParams& params,
                    const RuntimeShape& input_shape, const float* input_data,
                    const RuntimeShape& output_shape, float* output_data) {
   e0f24:	9002      	str	r0, [sp, #8]
  const int trailing_dim = input_shape.DimensionsCount() - 1;
  const int outer_size =
      MatchingFlatSizeSkipDim(input_shape, trailing_dim, output_shape);
   e0f26:	4631      	mov	r1, r6
   e0f28:	4628      	mov	r0, r5
namespace tflite {
namespace reference_ops {

inline void Softmax(const SoftmaxParams& params,
                    const RuntimeShape& input_shape, const float* input_data,
                    const RuntimeShape& output_shape, float* output_data) {
   e0f2a:	4614      	mov	r4, r2
  const int trailing_dim = input_shape.DimensionsCount() - 1;
  const int outer_size =
      MatchingFlatSizeSkipDim(input_shape, trailing_dim, output_shape);
   e0f2c:	461a      	mov	r2, r3
namespace tflite {
namespace reference_ops {

inline void Softmax(const SoftmaxParams& params,
                    const RuntimeShape& input_shape, const float* input_data,
                    const RuntimeShape& output_shape, float* output_data) {
   e0f2e:	461f      	mov	r7, r3
  const int trailing_dim = input_shape.DimensionsCount() - 1;
  const int outer_size =
      MatchingFlatSizeSkipDim(input_shape, trailing_dim, output_shape);
   e0f30:	f7ff ffc0 	bl	e0eb4 <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_>
}

// Get common shape dim, DCHECKing that they all agree.
inline int MatchingDim(const RuntimeShape& shape1, int index1,
                       const RuntimeShape& shape2, int index2) {
  TFLITE_DCHECK_EQ(shape1.Dims(index1), shape2.Dims(index2));
   e0f34:	4631      	mov	r1, r6
   e0f36:	9003      	str	r0, [sp, #12]
   e0f38:	4628      	mov	r0, r5
   e0f3a:	f7f6 fb21 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0f3e:	4631      	mov	r1, r6
   e0f40:	4605      	mov	r5, r0
   e0f42:	4638      	mov	r0, r7
   e0f44:	f7f6 fb1c 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e0f48:	4285      	cmp	r5, r0
   e0f4a:	d001      	beq.n	e0f50 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x3c>
   e0f4c:	f004 fad2 	bl	e54f4 <abort>
   e0f50:	00ab      	lsls	r3, r5, #2
   e0f52:	9e14      	ldr	r6, [sp, #80]	; 0x50

  for (int i = 0; i < outer_size; ++i) {
    // Find max element value which we'll use to ensure numerical stability
    // taking advantage of the following equality:
    // exp(x[i])/sum(exp(x[i])) == exp(x[i]+C)/sum(exp(x[i]+C))
    float max = std::numeric_limits<float>::lowest();
   e0f54:	ed9f 8a3f 	vldr	s16, [pc, #252]	; e1054 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x140>
   e0f58:	9301      	str	r3, [sp, #4]
   e0f5a:	2700      	movs	r7, #0
  const int outer_size =
      MatchingFlatSizeSkipDim(input_shape, trailing_dim, output_shape);
  const int depth =
      MatchingDim(input_shape, trailing_dim, output_shape, trailing_dim);

  for (int i = 0; i < outer_size; ++i) {
   e0f5c:	9b03      	ldr	r3, [sp, #12]
   e0f5e:	429f      	cmp	r7, r3
   e0f60:	da72      	bge.n	e1048 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x134>
    // Find max element value which we'll use to ensure numerical stability
    // taking advantage of the following equality:
    // exp(x[i])/sum(exp(x[i])) == exp(x[i]+C)/sum(exp(x[i]+C))
    float max = std::numeric_limits<float>::lowest();
   e0f62:	ed8d 8a07 	vstr	s16, [sp, #28]
   e0f66:	4621      	mov	r1, r4
    for (int c = 0; c < depth; ++c) {
   e0f68:	2200      	movs	r2, #0
   e0f6a:	42aa      	cmp	r2, r5
   e0f6c:	da0f      	bge.n	e0f8e <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x7a>
      max = std::max(max, input_data[i * depth + c]);
   e0f6e:	460b      	mov	r3, r1
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
   e0f70:	ed93 7a00 	vldr	s14, [r3]
   e0f74:	eddd 7a07 	vldr	s15, [sp, #28]
   e0f78:	eeb4 7ae7 	vcmpe.f32	s14, s15
   e0f7c:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
	return __b;
      return __a;
   e0f80:	bfd8      	it	le
   e0f82:	ab07      	addle	r3, sp, #28
   e0f84:	3104      	adds	r1, #4
   e0f86:	681b      	ldr	r3, [r3, #0]
   e0f88:	9307      	str	r3, [sp, #28]
  for (int i = 0; i < outer_size; ++i) {
    // Find max element value which we'll use to ensure numerical stability
    // taking advantage of the following equality:
    // exp(x[i])/sum(exp(x[i])) == exp(x[i]+C)/sum(exp(x[i]+C))
    float max = std::numeric_limits<float>::lowest();
    for (int c = 0; c < depth; ++c) {
   e0f8a:	3201      	adds	r2, #1
   e0f8c:	e7ed      	b.n	e0f6a <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x56>
   e0f8e:	46a2      	mov	sl, r4
   e0f90:	f04f 0800 	mov.w	r8, #0
   e0f94:	f04f 0900 	mov.w	r9, #0
      max = std::max(max, input_data[i * depth + c]);
    }

    // Compute sum.
    float sum = 0.f;
    for (int c = 0; c < depth; ++c) {
   e0f98:	45a8      	cmp	r8, r5
   e0f9a:	da23      	bge.n	e0fe4 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf+0xd0>
      sum += std::exp((input_data[i * depth + c] - max) * params.beta);
   e0f9c:	ecba 7a01 	vldmia	sl!, {s14}
   e0fa0:	eddd 7a07 	vldr	s15, [sp, #28]
   e0fa4:	ee77 7a67 	vsub.f32	s15, s14, s15
      max = std::max(max, input_data[i * depth + c]);
    }

    // Compute sum.
    float sum = 0.f;
    for (int c = 0; c < depth; ++c) {
   e0fa8:	f108 0801 	add.w	r8, r8, #1
      sum += std::exp((input_data[i * depth + c] - max) * params.beta);
   e0fac:	ee17 0a90 	vmov	r0, s15
   e0fb0:	f007 f9e4 	bl	e837c <__aeabi_f2d>
   e0fb4:	9b02      	ldr	r3, [sp, #8]
   e0fb6:	e9d3 2300 	ldrd	r2, r3, [r3]
   e0fba:	f007 fa33 	bl	e8424 <__aeabi_dmul>
   e0fbe:	ec41 0b10 	vmov	d0, r0, r1
   e0fc2:	f005 fd09 	bl	e69d8 <exp>
   e0fc6:	ec53 2b10 	vmov	r2, r3, d0
   e0fca:	4648      	mov	r0, r9
   e0fcc:	e9cd 2304 	strd	r2, r3, [sp, #16]
   e0fd0:	f007 f9d4 	bl	e837c <__aeabi_f2d>
   e0fd4:	e9dd 2304 	ldrd	r2, r3, [sp, #16]
   e0fd8:	f007 f872 	bl	e80c0 <__adddf3>
   e0fdc:	f007 fd04 	bl	e89e8 <__aeabi_d2f>
   e0fe0:	4681      	mov	r9, r0
      max = std::max(max, input_data[i * depth + c]);
    }

    // Compute sum.
    float sum = 0.f;
    for (int c = 0; c < depth; ++c) {
   e0fe2:	e7d9      	b.n	e0f98 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x84>
   e0fe4:	46b2      	mov	sl, r6
   e0fe6:	46a3      	mov	fp, r4
   e0fe8:	f04f 0800 	mov.w	r8, #0
      sum += std::exp((input_data[i * depth + c] - max) * params.beta);
    }

    // Compute result.
    for (int c = 0; c < depth; ++c) {
   e0fec:	45a8      	cmp	r8, r5
   e0fee:	da26      	bge.n	e103e <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x12a>
      output_data[i * depth + c] =
          std::exp((input_data[i * depth + c] - max) * params.beta) / sum;
   e0ff0:	ecbb 7a01 	vldmia	fp!, {s14}
   e0ff4:	eddd 7a07 	vldr	s15, [sp, #28]
   e0ff8:	ee77 7a67 	vsub.f32	s15, s14, s15
    for (int c = 0; c < depth; ++c) {
      sum += std::exp((input_data[i * depth + c] - max) * params.beta);
    }

    // Compute result.
    for (int c = 0; c < depth; ++c) {
   e0ffc:	f108 0801 	add.w	r8, r8, #1
      output_data[i * depth + c] =
          std::exp((input_data[i * depth + c] - max) * params.beta) / sum;
   e1000:	ee17 0a90 	vmov	r0, s15
   e1004:	f007 f9ba 	bl	e837c <__aeabi_f2d>
   e1008:	9b02      	ldr	r3, [sp, #8]
   e100a:	e9d3 2300 	ldrd	r2, r3, [r3]
   e100e:	f007 fa09 	bl	e8424 <__aeabi_dmul>
   e1012:	ec41 0b10 	vmov	d0, r0, r1
   e1016:	f005 fcdf 	bl	e69d8 <exp>
   e101a:	4648      	mov	r0, r9
   e101c:	ed8d 0b04 	vstr	d0, [sp, #16]
   e1020:	f007 f9ac 	bl	e837c <__aeabi_f2d>
   e1024:	ed9d 0b04 	vldr	d0, [sp, #16]
   e1028:	4602      	mov	r2, r0
   e102a:	460b      	mov	r3, r1
   e102c:	ec51 0b10 	vmov	r0, r1, d0
   e1030:	f007 fb22 	bl	e8678 <__aeabi_ddiv>
   e1034:	f007 fcd8 	bl	e89e8 <__aeabi_d2f>
   e1038:	f84a 0b04 	str.w	r0, [sl], #4
    for (int c = 0; c < depth; ++c) {
      sum += std::exp((input_data[i * depth + c] - max) * params.beta);
    }

    // Compute result.
    for (int c = 0; c < depth; ++c) {
   e103c:	e7d6      	b.n	e0fec <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf+0xd8>
   e103e:	9b01      	ldr	r3, [sp, #4]
  const int outer_size =
      MatchingFlatSizeSkipDim(input_shape, trailing_dim, output_shape);
  const int depth =
      MatchingDim(input_shape, trailing_dim, output_shape, trailing_dim);

  for (int i = 0; i < outer_size; ++i) {
   e1040:	3701      	adds	r7, #1
   e1042:	441c      	add	r4, r3
   e1044:	441e      	add	r6, r3
   e1046:	e789      	b.n	e0f5c <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf+0x48>
    for (int c = 0; c < depth; ++c) {
      output_data[i * depth + c] =
          std::exp((input_data[i * depth + c] - max) * params.beta) / sum;
    }
  }
}
   e1048:	b009      	add	sp, #36	; 0x24
   e104a:	ecbd 8b02 	vpop	{d8}
   e104e:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e1052:	bf00      	nop
   e1054:	ff7fffff 	.word	0xff7fffff

000e1058 <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf>:
  }
}

// Performs softmax along the input of size (input_size * batch_size).
inline void Softmax(const float* in, const int input_size, const int batch_size,
                    const float beta, float* out) {
   e1058:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e105c:	ed2d 8b04 	vpush	{d8-d9}
   e1060:	4605      	mov	r5, r0
   e1062:	b085      	sub	sp, #20
   e1064:	460e      	mov	r6, r1
   e1066:	4693      	mov	fp, r2
   e1068:	eeb0 9a40 	vmov.f32	s18, s0
   e106c:	461c      	mov	r4, r3
    for (int i = 0; i < input_size; i++) {
      out[i] *= reciprocal_sum_exp;
    }

    // Advance in and out pointers for the next batch.
    in += input_size;
   e106e:	ea4f 0a81 	mov.w	sl, r1, lsl #2
inline void Softmax(const float* in, const int input_size, const int batch_size,
                    const float beta, float* out) {
  //  TF_LITE_ASSERT(input_size > 0);

  // For each batch
  for (int b = 0; b < batch_size; b++) {
   e1072:	2700      	movs	r7, #0
      out[i] = std::exp((in[i] - max_coeff) * beta);
      exp_sum += out[i];
    }

    // Divide by the sum of exps.
    float reciprocal_sum_exp = 1.f / exp_sum;
   e1074:	eef7 9a00 	vmov.f32	s19, #112	; 0x3f800000  1.0
inline void Softmax(const float* in, const int input_size, const int batch_size,
                    const float beta, float* out) {
  //  TF_LITE_ASSERT(input_size > 0);

  // For each batch
  for (int b = 0; b < batch_size; b++) {
   e1078:	455f      	cmp	r7, fp
   e107a:	da3e      	bge.n	e10fa <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf+0xa2>
    // Find the max coeff.
    float max_coeff = in[0];
   e107c:	462b      	mov	r3, r5
   e107e:	ecb3 8a01 	vldmia	r3!, {s16}
    for (int i = 1; i < input_size; i++) {
   e1082:	2101      	movs	r1, #1
   e1084:	42b1      	cmp	r1, r6
   e1086:	da0a      	bge.n	e109e <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf+0x46>
      if (in[i] > max_coeff) max_coeff = in[i];
   e1088:	ecf3 7a01 	vldmia	r3!, {s15}
   e108c:	eeb4 8a67 	vcmp.f32	s16, s15
   e1090:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e1094:	bf48      	it	mi
   e1096:	eeb0 8a67 	vmovmi.f32	s16, s15

  // For each batch
  for (int b = 0; b < batch_size; b++) {
    // Find the max coeff.
    float max_coeff = in[0];
    for (int i = 1; i < input_size; i++) {
   e109a:	3101      	adds	r1, #1
   e109c:	e7f2      	b.n	e1084 <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf+0x2c>
   e109e:	eddf 8a19 	vldr	s17, [pc, #100]	; e1104 <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf+0xac>
   e10a2:	462a      	mov	r2, r5
   e10a4:	46a0      	mov	r8, r4
   e10a6:	4623      	mov	r3, r4
   e10a8:	f04f 0900 	mov.w	r9, #0
      if (in[i] > max_coeff) max_coeff = in[i];
    }

    // Compute the normalized sum of exps.
    float exp_sum = 0.0;
    for (int i = 0; i < input_size; i++) {
   e10ac:	45b1      	cmp	r9, r6
   e10ae:	9302      	str	r3, [sp, #8]
   e10b0:	da12      	bge.n	e10d8 <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf+0x80>
      out[i] = std::exp((in[i] - max_coeff) * beta);
   e10b2:	ecb2 0a01 	vldmia	r2!, {s0}
  using ::exp;

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  exp(float __x)
  { return __builtin_expf(__x); }
   e10b6:	ee30 0a48 	vsub.f32	s0, s0, s16
   e10ba:	9201      	str	r2, [sp, #4]
   e10bc:	ee20 0a09 	vmul.f32	s0, s0, s18
   e10c0:	9203      	str	r2, [sp, #12]
   e10c2:	f005 fd0d 	bl	e6ae0 <expf>
   e10c6:	9b02      	ldr	r3, [sp, #8]
      if (in[i] > max_coeff) max_coeff = in[i];
    }

    // Compute the normalized sum of exps.
    float exp_sum = 0.0;
    for (int i = 0; i < input_size; i++) {
   e10c8:	9a01      	ldr	r2, [sp, #4]
      out[i] = std::exp((in[i] - max_coeff) * beta);
   e10ca:	eca3 0a01 	vstmia	r3!, {s0}
      exp_sum += out[i];
   e10ce:	ee78 8a80 	vadd.f32	s17, s17, s0
      if (in[i] > max_coeff) max_coeff = in[i];
    }

    // Compute the normalized sum of exps.
    float exp_sum = 0.0;
    for (int i = 0; i < input_size; i++) {
   e10d2:	f109 0901 	add.w	r9, r9, #1
   e10d6:	e7e9      	b.n	e10ac <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf+0x54>
      out[i] = std::exp((in[i] - max_coeff) * beta);
      exp_sum += out[i];
    }

    // Divide by the sum of exps.
    float reciprocal_sum_exp = 1.f / exp_sum;
   e10d8:	ee89 7aa8 	vdiv.f32	s14, s19, s17
    for (int i = 0; i < input_size; i++) {
   e10dc:	2300      	movs	r3, #0
   e10de:	42b3      	cmp	r3, r6
   e10e0:	da07      	bge.n	e10f2 <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf+0x9a>
   e10e2:	3301      	adds	r3, #1
      out[i] *= reciprocal_sum_exp;
   e10e4:	edd8 7a00 	vldr	s15, [r8]
   e10e8:	ee67 7a87 	vmul.f32	s15, s15, s14
   e10ec:	ece8 7a01 	vstmia	r8!, {s15}
      exp_sum += out[i];
    }

    // Divide by the sum of exps.
    float reciprocal_sum_exp = 1.f / exp_sum;
    for (int i = 0; i < input_size; i++) {
   e10f0:	e7f5      	b.n	e10de <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf+0x86>
      out[i] *= reciprocal_sum_exp;
    }

    // Advance in and out pointers for the next batch.
    in += input_size;
   e10f2:	4455      	add	r5, sl
    out += input_size;
   e10f4:	4454      	add	r4, sl
inline void Softmax(const float* in, const int input_size, const int batch_size,
                    const float beta, float* out) {
  //  TF_LITE_ASSERT(input_size > 0);

  // For each batch
  for (int b = 0; b < batch_size; b++) {
   e10f6:	3701      	adds	r7, #1
   e10f8:	e7be      	b.n	e1078 <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf+0x20>

    // Advance in and out pointers for the next batch.
    in += input_size;
    out += input_size;
  }
}
   e10fa:	b005      	add	sp, #20
   e10fc:	ecbd 8b04 	vpop	{d8-d9}
   e1100:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e1104:	00000000 	.word	0x00000000

000e1108 <_ZN6tflite3ops5micro11activations14Softmax1DFloatEPK12TfLiteTensorPS3_P19TfLiteSoftmaxParams>:

// Takes a 1D tensor and performs softmax along it.
void Softmax1DFloat(const TfLiteTensor* input, TfLiteTensor* output,
                    TfLiteSoftmaxParams* params) {
   e1108:	b510      	push	{r4, lr}
  const int input_size = input->dims->data[0];
   e110a:	6884      	ldr	r4, [r0, #8]
  tflite::reference_ops::Softmax(input->data.f, input_size, 1, params->beta,
                                 output->data.f);
   e110c:	684b      	ldr	r3, [r1, #4]
   e110e:	ed92 0a00 	vldr	s0, [r2]
   e1112:	6861      	ldr	r1, [r4, #4]
   e1114:	6840      	ldr	r0, [r0, #4]
   e1116:	2201      	movs	r2, #1
   e1118:	f7ff ff9e 	bl	e1058 <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf>
   e111c:	bd10      	pop	{r4, pc}

000e111e <_ZN6tflite3ops5micro11activations14Softmax2DFloatEPK12TfLiteTensorPS3_P19TfLiteSoftmaxParams>:
}

// Takes a 2D tensor and perform softmax along the last dimension.
void Softmax2DFloat(const TfLiteTensor* input, TfLiteTensor* output,
                    TfLiteSoftmaxParams* params) {
   e111e:	b510      	push	{r4, lr}
  const int batch_size = input->dims->data[0];
   e1120:	6884      	ldr	r4, [r0, #8]
  const int input_size = input->dims->data[1];
  tflite::reference_ops::Softmax(input->data.f, input_size, batch_size,
                                 params->beta, output->data.f);
   e1122:	684b      	ldr	r3, [r1, #4]
   e1124:	ed92 0a00 	vldr	s0, [r2]
   e1128:	68a1      	ldr	r1, [r4, #8]
   e112a:	6862      	ldr	r2, [r4, #4]
   e112c:	6840      	ldr	r0, [r0, #4]
   e112e:	f7ff ff93 	bl	e1058 <_ZN6tflite13reference_ops7SoftmaxEPKfiifPf>
   e1132:	bd10      	pop	{r4, pc}

000e1134 <_ZN6tflite3ops5micro11activations14Softmax4DFloatEPK12TfLiteTensorPS3_P19TfLiteSoftmaxParams>:
                                 GetTensorData<uint8_t>(output));
}

// Takes a 4D tensor and perform softmax along the forth dimension.
void Softmax4DFloat(const TfLiteTensor* input, TfLiteTensor* output,
                    TfLiteSoftmaxParams* params) {
   e1134:	b530      	push	{r4, r5, lr}
   e1136:	4604      	mov	r4, r0
   e1138:	b097      	sub	sp, #92	; 0x5c
  SoftmaxParams op_params;
  op_params.beta = params->beta;
   e113a:	6810      	ldr	r0, [r2, #0]
                                 GetTensorData<uint8_t>(output));
}

// Takes a 4D tensor and perform softmax along the forth dimension.
void Softmax4DFloat(const TfLiteTensor* input, TfLiteTensor* output,
                    TfLiteSoftmaxParams* params) {
   e113c:	460d      	mov	r5, r1
  SoftmaxParams op_params;
  op_params.beta = params->beta;
   e113e:	f007 f91d 	bl	e837c <__aeabi_f2d>
   e1142:	e9cd 010c 	strd	r0, r1, [sp, #48]	; 0x30
  tflite::reference_ops::Softmax(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
   e1146:	4621      	mov	r1, r4
   e1148:	a802      	add	r0, sp, #8
   e114a:	f7f6 fcbe 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e114e:	b104      	cbz	r4, e1152 <_ZN6tflite3ops5micro11activations14Softmax4DFloatEPK12TfLiteTensorPS3_P19TfLiteSoftmaxParams+0x1e>
   e1150:	6864      	ldr	r4, [r4, #4]
      GetTensorShape(output), GetTensorData<float>(output));
   e1152:	4629      	mov	r1, r5
   e1154:	a807      	add	r0, sp, #28
   e1156:	f7f6 fcb8 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e115a:	b105      	cbz	r5, e115e <_ZN6tflite3ops5micro11activations14Softmax4DFloatEPK12TfLiteTensorPS3_P19TfLiteSoftmaxParams+0x2a>
   e115c:	686d      	ldr	r5, [r5, #4]
   e115e:	9500      	str	r5, [sp, #0]
   e1160:	ab07      	add	r3, sp, #28
   e1162:	4622      	mov	r2, r4
   e1164:	a902      	add	r1, sp, #8
   e1166:	a80c      	add	r0, sp, #48	; 0x30
   e1168:	f7ff fed4 	bl	e0f14 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKfS6_Pf>
   e116c:	a807      	add	r0, sp, #28
   e116e:	f7f6 f9fc 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
void Softmax4DFloat(const TfLiteTensor* input, TfLiteTensor* output,
                    TfLiteSoftmaxParams* params) {
  SoftmaxParams op_params;
  op_params.beta = params->beta;
  tflite::reference_ops::Softmax(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
   e1172:	a802      	add	r0, sp, #8
   e1174:	f7f6 f9f9 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      GetTensorShape(output), GetTensorData<float>(output));
}
   e1178:	b017      	add	sp, #92	; 0x5c
   e117a:	bd30      	pop	{r4, r5, pc}

000e117c <_ZN6tflite3ops5micro16Register_SOFTMAXEv>:
TfLiteRegistration* Register_SOFTMAX() {
  static TfLiteRegistration r = {activations::Init, activations::Free,
                                 activations::SoftmaxPrepare,
                                 activations::SoftmaxEval};
  return &r;
}
   e117c:	4800      	ldr	r0, [pc, #0]	; (e1180 <_ZN6tflite3ops5micro16Register_SOFTMAXEv+0x4>)
   e117e:	4770      	bx	lr
   e1180:	2003c170 	.word	0x2003c170

000e1184 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i>:
}

// Correctly-rounded-to-nearest division by a power-of-two.
// Also known as a rounding arithmetic right shift.
template <typename IntegerType>
inline IntegerType RoundingDivideByPOT(IntegerType x, int exponent) {
   e1184:	b538      	push	{r3, r4, r5, lr}
  assert(exponent >= 0);
   e1186:	1e0d      	subs	r5, r1, #0
}

// Correctly-rounded-to-nearest division by a power-of-two.
// Also known as a rounding arithmetic right shift.
template <typename IntegerType>
inline IntegerType RoundingDivideByPOT(IntegerType x, int exponent) {
   e1188:	4604      	mov	r4, r0
  assert(exponent >= 0);
   e118a:	da04      	bge.n	e1196 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i+0x12>
   e118c:	4b0f      	ldr	r3, [pc, #60]	; (e11cc <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i+0x48>)
   e118e:	4a10      	ldr	r2, [pc, #64]	; (e11d0 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i+0x4c>)
   e1190:	f44f 71b3 	mov.w	r1, #358	; 0x166
   e1194:	e005      	b.n	e11a2 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i+0x1e>
  assert(exponent <= 31);
   e1196:	2d1f      	cmp	r5, #31
   e1198:	dd06      	ble.n	e11a8 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i+0x24>
   e119a:	4b0e      	ldr	r3, [pc, #56]	; (e11d4 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i+0x50>)
   e119c:	4a0c      	ldr	r2, [pc, #48]	; (e11d0 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i+0x4c>)
   e119e:	f240 1167 	movw	r1, #359	; 0x167
   e11a2:	480d      	ldr	r0, [pc, #52]	; (e11d8 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i+0x54>)
   e11a4:	f004 f9b6 	bl	e5514 <__assert_func>
  const IntegerType mask = Dup<IntegerType>((1ll << exponent) - 1);
   e11a8:	462a      	mov	r2, r5
   e11aa:	2001      	movs	r0, #1
   e11ac:	2100      	movs	r1, #0
   e11ae:	f006 ff75 	bl	e809c <__aeabi_llsl>
   e11b2:	3801      	subs	r0, #1
  const IntegerType one = Dup<IntegerType>(1);
  const IntegerType remainder = BitAnd(x, mask);
  const IntegerType threshold =
      Add(ShiftRight(mask, 1), BitAnd(MaskIfLessThan(x, zero), one));
  return Add(ShiftRight(x, exponent),
             BitAnd(MaskIfGreaterThan(remainder, threshold), one));
   e11b4:	1043      	asrs	r3, r0, #1
   e11b6:	ea00 0204 	and.w	r2, r0, r4
   e11ba:	eb03 73d4 	add.w	r3, r3, r4, lsr #31
   e11be:	fa44 f005 	asr.w	r0, r4, r5
}
   e11c2:	429a      	cmp	r2, r3
   e11c4:	bfc8      	it	gt
   e11c6:	3001      	addgt	r0, #1
   e11c8:	bd38      	pop	{r3, r4, r5, pc}
   e11ca:	bf00      	nop
   e11cc:	000eb13c 	.word	0x000eb13c
   e11d0:	000ebff9 	.word	0x000ebff9
   e11d4:	000eb1ee 	.word	0x000eb1ee
   e11d8:	000eb14a 	.word	0x000eb14a

000e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>:
// A FixedPoint multiplication is just a
// SaturatingRoundingDoublingHighMul operation on the underlying
// raw integer values. The IntegerBits simply add up, as is obvious
// from the fact that the range is [-2^IntegerBits, 2^IntegerBits).
template <typename tRawType, int tIntegerBits_a, int tIntegerBits_b>
FixedPoint<tRawType, tIntegerBits_a + tIntegerBits_b> operator*(
   e11dc:	b508      	push	{r3, lr}
    FixedPoint<tRawType, tIntegerBits_a> a,
    FixedPoint<tRawType, tIntegerBits_b> b) {
  FixedPoint<tRawType, tIntegerBits_a + tIntegerBits_b> c;
  c.raw() = SaturatingRoundingDoublingHighMul(a.raw(), b.raw());
   e11de:	f7ff fe41 	bl	e0e64 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_>
  return c;
}
   e11e2:	bd08      	pop	{r3, pc}

000e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>:
// fixed-point value, regardless of the actual Scalar type. This allows
// writing generic code that applies just as well to the 32-bit and 16-bit
// cases. In the 16-bit case, the raw integer value is internally
// rounding-shifted by 16 bits to the right.
template <typename FixedPointType>
inline typename FixedPointType::ScalarRawType RescaleConstantInitializer(
   e11e4:	b508      	push	{r3, lr}
    std::int32_t int32_value) {
  typedef typename FixedPointType::ScalarRawType ScalarRawType;
  static constexpr int ScalarTypeBits = 8 * sizeof(ScalarRawType);
  return static_cast<ScalarRawType>(
      RoundingDivideByPOT<std::int32_t>(int32_value, 32 - ScalarTypeBits));
   e11e6:	2100      	movs	r1, #0
   e11e8:	f7ff ffcc 	bl	e1184 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i>
}
   e11ec:	bd08      	pop	{r3, pc}
	...

000e11f0 <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_>:

// Implementation of logistic function.

// Returns 1 / (1 + x) for x in (0, 1).
template <typename tRawType>
FixedPoint<tRawType, 0> one_over_one_plus_x_for_x_in_0_1(
   e11f0:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}

template <>
inline std::int32_t RoundingHalfSum(std::int32_t a, std::int32_t b) {
  std::int64_t a64 = a;
  std::int64_t b64 = b;
  std::int64_t sum = a64 + b64;
   e11f4:	f06f 4600 	mvn.w	r6, #2147483648	; 0x80000000
   e11f8:	1833      	adds	r3, r6, r0
   e11fa:	f04f 0700 	mov.w	r7, #0
   e11fe:	eb47 74e0 	adc.w	r4, r7, r0, asr #31
   e1202:	4618      	mov	r0, r3
  std::int64_t sign = sum >= 0 ? 1 : -1;
   e1204:	1c63      	adds	r3, r4, #1
   e1206:	bf05      	ittet	eq
   e1208:	f1b0 3fff 	cmpeq.w	r0, #4294967295	; 0xffffffff
   e120c:	4602      	moveq	r2, r0
   e120e:	2201      	movne	r2, #1
   e1210:	4623      	moveq	r3, r4
   e1212:	bf18      	it	ne
   e1214:	2300      	movne	r3, #0
  return static_cast<std::int32_t>((sum + sign) / 2);
   e1216:	1886      	adds	r6, r0, r2
   e1218:	eb44 0703 	adc.w	r7, r4, r3
   e121c:	0ffb      	lsrs	r3, r7, #31
   e121e:	18f6      	adds	r6, r6, r3
  F0 half_denominator = RoundingHalfSum(a, F0::One());
  // Newton-Raphson division
  // https://en.wikipedia.org/wiki/Division_algorithm#Newton.E2.80.93Raphson_division
  // Refer to that page for the logic behind the 48/17 and 32/17 constants.
  const F2 constant_48_over_17 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F2, 1515870810, 48.0 / 17.0);
   e1220:	f04f 305a 	mov.w	r0, #1515870810	; 0x5a5a5a5a
inline std::int32_t RoundingHalfSum(std::int32_t a, std::int32_t b) {
  std::int64_t a64 = a;
  std::int64_t b64 = b;
  std::int64_t sum = a64 + b64;
  std::int64_t sign = sum >= 0 ? 1 : -1;
  return static_cast<std::int32_t>((sum + sign) / 2);
   e1224:	f147 0700 	adc.w	r7, r7, #0
  F0 half_denominator = RoundingHalfSum(a, F0::One());
  // Newton-Raphson division
  // https://en.wikipedia.org/wiki/Division_algorithm#Newton.E2.80.93Raphson_division
  // Refer to that page for the logic behind the 48/17 and 32/17 constants.
  const F2 constant_48_over_17 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F2, 1515870810, 48.0 / 17.0);
   e1228:	f7ff ffdc 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
   e122c:	4604      	mov	r4, r0
  const F2 constant_neg_32_over_17 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F2, -1010580540, -32.0 / 17.0);
   e122e:	4840      	ldr	r0, [pc, #256]	; (e1330 <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0x140>)
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e1230:	f8df b100 	ldr.w	fp, [pc, #256]	; e1334 <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0x144>
  // https://en.wikipedia.org/wiki/Division_algorithm#Newton.E2.80.93Raphson_division
  // Refer to that page for the logic behind the 48/17 and 32/17 constants.
  const F2 constant_48_over_17 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F2, 1515870810, 48.0 / 17.0);
  const F2 constant_neg_32_over_17 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F2, -1010580540, -32.0 / 17.0);
   e1234:	f7ff ffd6 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
inline std::int32_t RoundingHalfSum(std::int32_t a, std::int32_t b) {
  std::int64_t a64 = a;
  std::int64_t b64 = b;
  std::int64_t sum = a64 + b64;
  std::int64_t sign = sum >= 0 ? 1 : -1;
  return static_cast<std::int32_t>((sum + sign) / 2);
   e1238:	107f      	asrs	r7, r7, #1
   e123a:	ea4f 0636 	mov.w	r6, r6, rrx
template <typename tRawType, int tIntegerBits_a, int tIntegerBits_b>
FixedPoint<tRawType, tIntegerBits_a + tIntegerBits_b> operator*(
    FixedPoint<tRawType, tIntegerBits_a> a,
    FixedPoint<tRawType, tIntegerBits_b> b) {
  FixedPoint<tRawType, tIntegerBits_a + tIntegerBits_b> c;
  c.raw() = SaturatingRoundingDoublingHighMul(a.raw(), b.raw());
   e123e:	4601      	mov	r1, r0
   e1240:	4630      	mov	r0, r6
   e1242:	f7ff fe0f 	bl	e0e64 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_>
inline std::int32_t RoundingHalfSum(std::int32_t a, std::int32_t b) {
  std::int64_t a64 = a;
  std::int64_t b64 = b;
  std::int64_t sum = a64 + b64;
  std::int64_t sign = sum >= 0 ? 1 : -1;
  return static_cast<std::int32_t>((sum + sign) / 2);
   e1246:	46b2      	mov	sl, r6
}

// Integer addition. Not saturating. Overflow is undefined behavior.
template <typename tIntegerType>
tIntegerType Add(tIntegerType a, tIntegerType b) {
  return a + b;
   e1248:	4404      	add	r4, r0
   e124a:	2503      	movs	r5, #3
  const auto min = std::numeric_limits<tIntegerType>::min();
  const auto max = std::numeric_limits<tIntegerType>::max();
  return wide_shifted < min
             ? min
             : wide_shifted > max ? max
                                  : static_cast<tIntegerType>(wide_shifted);
   e124c:	f06f 4600 	mvn.w	r6, #2147483648	; 0x80000000
   e1250:	2700      	movs	r7, #0
template <typename tRawType, int tIntegerBits_a, int tIntegerBits_b>
FixedPoint<tRawType, tIntegerBits_a + tIntegerBits_b> operator*(
    FixedPoint<tRawType, tIntegerBits_a> a,
    FixedPoint<tRawType, tIntegerBits_b> b) {
  FixedPoint<tRawType, tIntegerBits_a + tIntegerBits_b> c;
  c.raw() = SaturatingRoundingDoublingHighMul(a.raw(), b.raw());
   e1252:	4621      	mov	r1, r4
   e1254:	4650      	mov	r0, sl
   e1256:	f7ff fe05 	bl	e0e64 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_>
   e125a:	f1c0 5100 	rsb	r1, r0, #536870912	; 0x20000000
   e125e:	4620      	mov	r0, r4
   e1260:	f7ff fe00 	bl	e0e64 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_>
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e1264:	f1b0 5f00 	cmp.w	r0, #536870912	; 0x20000000
   e1268:	da07      	bge.n	e127a <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0x8a>
   e126a:	4558      	cmp	r0, fp
   e126c:	f04f 31ff 	mov.w	r1, #4294967295	; 0xffffffff
   e1270:	f04f 0e00 	mov.w	lr, #0
   e1274:	bfa8      	it	ge
   e1276:	2100      	movge	r1, #0
   e1278:	e002      	b.n	e1280 <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0x90>
   e127a:	f04f 3eff 	mov.w	lr, #4294967295	; 0xffffffff
   e127e:	2100      	movs	r1, #0
//
// tIntegerType may be int32 or any narrower signed type.
template <typename tIntegerType>
tIntegerType ShiftLeft(tIntegerType a, int offset) {
  const std::int64_t wide_a = static_cast<std::int64_t>(a);
  const std::int64_t wide_shifted = wide_a * (1 << offset);
   e1280:	17c3      	asrs	r3, r0, #31
   e1282:	ea4f 0983 	mov.w	r9, r3, lsl #2
   e1286:	ea4f 0880 	mov.w	r8, r0, lsl #2
   e128a:	ea49 7990 	orr.w	r9, r9, r0, lsr #30
  const auto min = std::numeric_limits<tIntegerType>::min();
  const auto max = std::numeric_limits<tIntegerType>::max();
  return wide_shifted < min
             ? min
             : wide_shifted > max ? max
                                  : static_cast<tIntegerType>(wide_shifted);
   e128e:	f1b8 4f00 	cmp.w	r8, #2147483648	; 0x80000000
   e1292:	f179 33ff 	sbcs.w	r3, r9, #4294967295	; 0xffffffff
   e1296:	db07      	blt.n	e12a8 <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0xb8>
   e1298:	4546      	cmp	r6, r8
   e129a:	eb77 0309 	sbcs.w	r3, r7, r9
   e129e:	bfac      	ite	ge
   e12a0:	4643      	movge	r3, r8
   e12a2:	f06f 4300 	mvnlt.w	r3, #2147483648	; 0x80000000
   e12a6:	e001      	b.n	e12ac <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0xbc>
   e12a8:	f04f 4300 	mov.w	r3, #2147483648	; 0x80000000
}

// Integer addition. Not saturating. Overflow is undefined behavior.
template <typename tIntegerType>
tIntegerType Add(tIntegerType a, tIntegerType b) {
  return a + b;
   e12ac:	ea6f 020e 	mvn.w	r2, lr
   e12b0:	4013      	ands	r3, r2
   e12b2:	f02e 4e00 	bic.w	lr, lr, #2147483648	; 0x80000000
   e12b6:	ea83 0e0e 	eor.w	lr, r3, lr
   e12ba:	43cb      	mvns	r3, r1
   e12bc:	ea0e 0e03 	and.w	lr, lr, r3
   e12c0:	f001 4100 	and.w	r1, r1, #2147483648	; 0x80000000
   e12c4:	ea8e 0101 	eor.w	r1, lr, r1
  const F2 constant_48_over_17 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F2, 1515870810, 48.0 / 17.0);
  const F2 constant_neg_32_over_17 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F2, -1010580540, -32.0 / 17.0);
  F2 x = constant_48_over_17 + half_denominator * constant_neg_32_over_17;
  for (int i = 0; i < 3; i++) {
   e12c8:	3d01      	subs	r5, #1
}

// Integer addition. Not saturating. Overflow is undefined behavior.
template <typename tIntegerType>
tIntegerType Add(tIntegerType a, tIntegerType b) {
  return a + b;
   e12ca:	440c      	add	r4, r1
  const F2 constant_48_over_17 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F2, 1515870810, 48.0 / 17.0);
  const F2 constant_neg_32_over_17 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F2, -1010580540, -32.0 / 17.0);
  F2 x = constant_48_over_17 + half_denominator * constant_neg_32_over_17;
  for (int i = 0; i < 3; i++) {
   e12cc:	d1c1      	bne.n	e1252 <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0x62>
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e12ce:	f1b4 4f80 	cmp.w	r4, #1073741824	; 0x40000000
   e12d2:	da07      	bge.n	e12e4 <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0xf4>
   e12d4:	f1b4 4f40 	cmp.w	r4, #3221225472	; 0xc0000000
   e12d8:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
   e12dc:	4629      	mov	r1, r5
   e12de:	bfc8      	it	gt
   e12e0:	2000      	movgt	r0, #0
   e12e2:	e002      	b.n	e12ea <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0xfa>
   e12e4:	f04f 31ff 	mov.w	r1, #4294967295	; 0xffffffff
   e12e8:	4628      	mov	r0, r5
//
// tIntegerType may be int32 or any narrower signed type.
template <typename tIntegerType>
tIntegerType ShiftLeft(tIntegerType a, int offset) {
  const std::int64_t wide_a = static_cast<std::int64_t>(a);
  const std::int64_t wide_shifted = wide_a * (1 << offset);
   e12ea:	1922      	adds	r2, r4, r4
   e12ec:	ea4f 73e4 	mov.w	r3, r4, asr #31
   e12f0:	415b      	adcs	r3, r3
  const auto min = std::numeric_limits<tIntegerType>::min();
  const auto max = std::numeric_limits<tIntegerType>::max();
  return wide_shifted < min
             ? min
             : wide_shifted > max ? max
                                  : static_cast<tIntegerType>(wide_shifted);
   e12f2:	f1b2 4f00 	cmp.w	r2, #2147483648	; 0x80000000
   e12f6:	f173 34ff 	sbcs.w	r4, r3, #4294967295	; 0xffffffff
   e12fa:	db0a      	blt.n	e1312 <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0x122>
   e12fc:	f06f 4400 	mvn.w	r4, #2147483648	; 0x80000000
   e1300:	4294      	cmp	r4, r2
   e1302:	f04f 0500 	mov.w	r5, #0
   e1306:	eb75 0403 	sbcs.w	r4, r5, r3
   e130a:	bfb8      	it	lt
   e130c:	f06f 4200 	mvnlt.w	r2, #2147483648	; 0x80000000
   e1310:	e001      	b.n	e1316 <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_+0x126>
   e1312:	f04f 4200 	mov.w	r2, #2147483648	; 0x80000000
   e1316:	ea22 0201 	bic.w	r2, r2, r1
   e131a:	f021 4100 	bic.w	r1, r1, #2147483648	; 0x80000000
   e131e:	404a      	eors	r2, r1
   e1320:	ea22 0200 	bic.w	r2, r2, r0
   e1324:	f000 4000 	and.w	r0, r0, #2147483648	; 0x80000000
    F2 one_minus_half_denominator_times_x =
        F2::One() - half_denominator_times_x;
    x = x + Rescale<2>(x * one_minus_half_denominator_times_x);
  }
  return Rescale<0>(ExactMulByPot<-1>(x));
}
   e1328:	4050      	eors	r0, r2
   e132a:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e132e:	bf00      	nop
   e1330:	c3c3c3c4 	.word	0xc3c3c3c4
   e1334:	e0000001 	.word	0xe0000001

000e1338 <_ZN8gemmlowp55exp_on_interval_between_negative_one_quarter_and_0_exclIlEENS_10FixedPointIT_Li0EEES3_>:

// Implementation of exponential function.

// Returns exp(x) for x in [-1/4, 0).
template <typename tRawType>
FixedPoint<tRawType, 0> exp_on_interval_between_negative_one_quarter_and_0_excl(
   e1338:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   e133c:	4604      	mov	r4, r0
    FixedPoint<tRawType, 0> a) {
  typedef FixedPoint<tRawType, 0> F;
  const F constant_term =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F, 1895147668, std::exp(-1.0 / 8.0));
   e133e:	4814      	ldr	r0, [pc, #80]	; (e1390 <_ZN8gemmlowp55exp_on_interval_between_negative_one_quarter_and_0_exclIlEENS_10FixedPointIT_Li0EEES3_+0x58>)
   e1340:	f7ff ff50 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
   e1344:	4606      	mov	r6, r0
  const F constant_1_over_3 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F, 715827883, 1.0 / 3.0);
   e1346:	4813      	ldr	r0, [pc, #76]	; (e1394 <_ZN8gemmlowp55exp_on_interval_between_negative_one_quarter_and_0_exclIlEENS_10FixedPointIT_Li0EEES3_+0x5c>)
   e1348:	f7ff ff4c 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
}

// Integer addition. Not saturating. Overflow is undefined behavior.
template <typename tIntegerType>
tIntegerType Add(tIntegerType a, tIntegerType b) {
  return a + b;
   e134c:	f104 5480 	add.w	r4, r4, #268435456	; 0x10000000
    FixedPoint<tRawType, 0> a) {
  typedef FixedPoint<tRawType, 0> F;
  const F constant_term =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F, 1895147668, std::exp(-1.0 / 8.0));
  const F constant_1_over_3 =
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F, 715827883, 1.0 / 3.0);
   e1350:	4680      	mov	r8, r0
  // We're evaluating a Taylor expansion around -1/8, so we do the change of
  // variable: x = a + 1/8.
  // In fixed-point with 0 integer bits, 1/8 is represented by 1 << 28.
  F x = a + F::template ConstantPOT<-3>();
  F x2 = x * x;
   e1352:	4621      	mov	r1, r4
   e1354:	4620      	mov	r0, r4
   e1356:	f7ff ff41 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
  F x3 = x2 * x;
   e135a:	4621      	mov	r1, r4
      GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F, 715827883, 1.0 / 3.0);
  // We're evaluating a Taylor expansion around -1/8, so we do the change of
  // variable: x = a + 1/8.
  // In fixed-point with 0 integer bits, 1/8 is represented by 1 << 28.
  F x = a + F::template ConstantPOT<-3>();
  F x2 = x * x;
   e135c:	4605      	mov	r5, r0
  F x3 = x2 * x;
   e135e:	f7ff ff3d 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
  F x4 = x2 * x2;
   e1362:	4629      	mov	r1, r5
  // We're evaluating a Taylor expansion around -1/8, so we do the change of
  // variable: x = a + 1/8.
  // In fixed-point with 0 integer bits, 1/8 is represented by 1 << 28.
  F x = a + F::template ConstantPOT<-3>();
  F x2 = x * x;
  F x3 = x2 * x;
   e1364:	4607      	mov	r7, r0
  F x4 = x2 * x2;
   e1366:	4628      	mov	r0, r5
   e1368:	f7ff ff38 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
};

template <int Exponent, typename IntegerType>
struct ImplSaturatingRoundingMultiplyByPOT<Exponent, IntegerType, -1> {
  static IntegerType eval(IntegerType x) {
    return RoundingDivideByPOT<IntegerType>(x, -Exponent);
   e136c:	2102      	movs	r1, #2
   e136e:	f7ff ff09 	bl	e1184 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i>
  F x2 = x * x;
  F x3 = x2 * x;
  F x4 = x2 * x2;
  F x4_over_4 = SaturatingRoundingMultiplyByPOT<-2>(x4);
  F x4_over_24_plus_x3_over_6_plus_x2_over_2 =
      SaturatingRoundingMultiplyByPOT<-1>(
   e1372:	4641      	mov	r1, r8
   e1374:	4438      	add	r0, r7
   e1376:	f7ff ff31 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
};

template <int Exponent, typename IntegerType>
struct ImplSaturatingRoundingMultiplyByPOT<Exponent, IntegerType, -1> {
  static IntegerType eval(IntegerType x) {
    return RoundingDivideByPOT<IntegerType>(x, -Exponent);
   e137a:	2101      	movs	r1, #1
   e137c:	4428      	add	r0, r5
   e137e:	f7ff ff01 	bl	e1184 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i>
  F x4 = x2 * x2;
  F x4_over_4 = SaturatingRoundingMultiplyByPOT<-2>(x4);
  F x4_over_24_plus_x3_over_6_plus_x2_over_2 =
      SaturatingRoundingMultiplyByPOT<-1>(
          ((x4_over_4 + x3) * constant_1_over_3) + x2);
  return AddSaturatingIf16Bit(
   e1382:	1821      	adds	r1, r4, r0
   e1384:	4630      	mov	r0, r6
   e1386:	f7ff ff29 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
      constant_term,
      constant_term * (x + x4_over_24_plus_x3_over_6_plus_x2_over_2));
}
   e138a:	4430      	add	r0, r6
   e138c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   e1390:	70f5a894 	.word	0x70f5a894
   e1394:	2aaaaaab 	.word	0x2aaaaaab

000e1398 <_ZN8gemmlowp22exp_on_negative_valuesIlLi5EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE>:

// Returns exp(x) for x < 0.
template <typename tRawType, int tIntegerBits>
FixedPoint<tRawType, 0> exp_on_negative_values(
   e1398:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
  return a * b;
}

template <typename tIntegerType>
tIntegerType Sub(tIntegerType a, tIntegerType b) {
  return a - b;
   e139a:	f040 467f 	orr.w	r6, r0, #4278190080	; 0xff000000
      constant_term * (x + x4_over_24_plus_x3_over_6_plus_x2_over_2));
}

// Returns exp(x) for x < 0.
template <typename tRawType, int tIntegerBits>
FixedPoint<tRawType, 0> exp_on_negative_values(
   e139e:	4607      	mov	r7, r0
  static constexpr int kIntegerBits = InputF::kIntegerBits;
  const InputF kOneQuarter = InputF::template ConstantPOT<-2>();
  InputF mask = kOneQuarter - InputF::FromScalarRaw(1);
  InputF a_mod_quarter_minus_one_quarter = (a & mask) - kOneQuarter;
  ResultF result = exp_on_interval_between_negative_one_quarter_and_0_excl(
      Rescale<0>(a_mod_quarter_minus_one_quarter));
   e13a0:	0170      	lsls	r0, r6, #5
   e13a2:	f7ff ffc9 	bl	e1338 <_ZN8gemmlowp55exp_on_interval_between_negative_one_quarter_and_0_exclIlEENS_10FixedPointIT_Li0EEES3_>
   e13a6:	4605      	mov	r5, r0
    result = SelectUsingMask(                                               \
        MaskIfNonZero(BitAnd(remainder, Dup<tRawType>(1 << kShiftAmount))), \
        result * kMultiplier, result);                                      \
  }

  GEMMLOWP_EXP_BARREL_SHIFTER(-2, 1672461947);
   e13a8:	4833      	ldr	r0, [pc, #204]	; (e1478 <_ZN8gemmlowp22exp_on_negative_valuesIlLi5EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE+0xe0>)
   e13aa:	f7ff ff1b 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
   e13ae:	4601      	mov	r1, r0
   e13b0:	4628      	mov	r0, r5
   e13b2:	f7ff ff13 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
  return a * b;
}

template <typename tIntegerType>
tIntegerType Sub(tIntegerType a, tIntegerType b) {
  return a - b;
   e13b6:	1bf6      	subs	r6, r6, r7
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e13b8:	f346 6400 	sbfx	r4, r6, #24, #1
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e13bc:	4020      	ands	r0, r4
   e13be:	ea25 0504 	bic.w	r5, r5, r4
   e13c2:	ea80 0405 	eor.w	r4, r0, r5
        MaskIfNonZero(BitAnd(remainder, Dup<tRawType>(1 << kShiftAmount))), \
        result * kMultiplier, result);                                      \
  }

  GEMMLOWP_EXP_BARREL_SHIFTER(-2, 1672461947);
  GEMMLOWP_EXP_BARREL_SHIFTER(-1, 1302514674);
   e13c6:	482d      	ldr	r0, [pc, #180]	; (e147c <_ZN8gemmlowp22exp_on_negative_valuesIlLi5EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE+0xe4>)
   e13c8:	f7ff ff0c 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
   e13cc:	4601      	mov	r1, r0
   e13ce:	4620      	mov	r0, r4
   e13d0:	f7ff ff04 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e13d4:	f346 6540 	sbfx	r5, r6, #25, #1
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e13d8:	4028      	ands	r0, r5
}

// Plain bit-wise AND
template <typename tIntegerType>
tIntegerType BitAnd(tIntegerType a, tIntegerType b) {
  return a & b;
   e13da:	ea24 0405 	bic.w	r4, r4, r5
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e13de:	4044      	eors	r4, r0
        result * kMultiplier, result);                                      \
  }

  GEMMLOWP_EXP_BARREL_SHIFTER(-2, 1672461947);
  GEMMLOWP_EXP_BARREL_SHIFTER(-1, 1302514674);
  GEMMLOWP_EXP_BARREL_SHIFTER(+0, 790015084);
   e13e0:	4827      	ldr	r0, [pc, #156]	; (e1480 <_ZN8gemmlowp22exp_on_negative_valuesIlLi5EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE+0xe8>)
   e13e2:	f7ff feff 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
   e13e6:	4601      	mov	r1, r0
   e13e8:	4620      	mov	r0, r4
   e13ea:	f7ff fef7 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e13ee:	f346 6580 	sbfx	r5, r6, #26, #1
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e13f2:	4028      	ands	r0, r5
}

// Plain bit-wise AND
template <typename tIntegerType>
tIntegerType BitAnd(tIntegerType a, tIntegerType b) {
  return a & b;
   e13f4:	ea24 0405 	bic.w	r4, r4, r5
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e13f8:	4044      	eors	r4, r0
  }

  GEMMLOWP_EXP_BARREL_SHIFTER(-2, 1672461947);
  GEMMLOWP_EXP_BARREL_SHIFTER(-1, 1302514674);
  GEMMLOWP_EXP_BARREL_SHIFTER(+0, 790015084);
  GEMMLOWP_EXP_BARREL_SHIFTER(+1, 290630308);
   e13fa:	4822      	ldr	r0, [pc, #136]	; (e1484 <_ZN8gemmlowp22exp_on_negative_valuesIlLi5EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE+0xec>)
   e13fc:	f7ff fef2 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
   e1400:	4601      	mov	r1, r0
   e1402:	4620      	mov	r0, r4
   e1404:	f7ff feea 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e1408:	f346 65c0 	sbfx	r5, r6, #27, #1
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e140c:	4028      	ands	r0, r5
}

// Plain bit-wise AND
template <typename tIntegerType>
tIntegerType BitAnd(tIntegerType a, tIntegerType b) {
  return a & b;
   e140e:	ea24 0405 	bic.w	r4, r4, r5
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e1412:	4044      	eors	r4, r0

  GEMMLOWP_EXP_BARREL_SHIFTER(-2, 1672461947);
  GEMMLOWP_EXP_BARREL_SHIFTER(-1, 1302514674);
  GEMMLOWP_EXP_BARREL_SHIFTER(+0, 790015084);
  GEMMLOWP_EXP_BARREL_SHIFTER(+1, 290630308);
  GEMMLOWP_EXP_BARREL_SHIFTER(+2, 39332535);
   e1414:	481c      	ldr	r0, [pc, #112]	; (e1488 <_ZN8gemmlowp22exp_on_negative_valuesIlLi5EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE+0xf0>)
   e1416:	f7ff fee5 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
   e141a:	4601      	mov	r1, r0
   e141c:	4620      	mov	r0, r4
   e141e:	f7ff fedd 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e1422:	f346 7500 	sbfx	r5, r6, #28, #1
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e1426:	4028      	ands	r0, r5
}

// Plain bit-wise AND
template <typename tIntegerType>
tIntegerType BitAnd(tIntegerType a, tIntegerType b) {
  return a & b;
   e1428:	ea24 0405 	bic.w	r4, r4, r5
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e142c:	4044      	eors	r4, r0
  GEMMLOWP_EXP_BARREL_SHIFTER(-2, 1672461947);
  GEMMLOWP_EXP_BARREL_SHIFTER(-1, 1302514674);
  GEMMLOWP_EXP_BARREL_SHIFTER(+0, 790015084);
  GEMMLOWP_EXP_BARREL_SHIFTER(+1, 290630308);
  GEMMLOWP_EXP_BARREL_SHIFTER(+2, 39332535);
  GEMMLOWP_EXP_BARREL_SHIFTER(+3, 720401);
   e142e:	4817      	ldr	r0, [pc, #92]	; (e148c <_ZN8gemmlowp22exp_on_negative_valuesIlLi5EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE+0xf4>)
   e1430:	f7ff fed8 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
   e1434:	4601      	mov	r1, r0
   e1436:	4620      	mov	r0, r4
   e1438:	f7ff fed0 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e143c:	f346 7540 	sbfx	r5, r6, #29, #1
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e1440:	4028      	ands	r0, r5
}

// Plain bit-wise AND
template <typename tIntegerType>
tIntegerType BitAnd(tIntegerType a, tIntegerType b) {
  return a & b;
   e1442:	ea24 0405 	bic.w	r4, r4, r5
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e1446:	4044      	eors	r4, r0
  GEMMLOWP_EXP_BARREL_SHIFTER(-1, 1302514674);
  GEMMLOWP_EXP_BARREL_SHIFTER(+0, 790015084);
  GEMMLOWP_EXP_BARREL_SHIFTER(+1, 290630308);
  GEMMLOWP_EXP_BARREL_SHIFTER(+2, 39332535);
  GEMMLOWP_EXP_BARREL_SHIFTER(+3, 720401);
  GEMMLOWP_EXP_BARREL_SHIFTER(+4, 242);
   e1448:	20f2      	movs	r0, #242	; 0xf2
   e144a:	f7ff fecb 	bl	e11e4 <_ZN8gemmlowp26RescaleConstantInitializerINS_10FixedPointIlLi2EEEEENT_13ScalarRawTypeEl>
   e144e:	4601      	mov	r1, r0
   e1450:	4620      	mov	r0, r4
   e1452:	f7ff fec3 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e1456:	fab7 f787 	clz	r7, r7
   e145a:	f346 7680 	sbfx	r6, r6, #30, #1
   e145e:	097f      	lsrs	r7, r7, #5
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e1460:	4030      	ands	r0, r6
// For each input scalar, the corresponding bits of the result are set if the
// input scalar is non-zero.
template <typename tIntegerType>
tIntegerType MaskIfNonZero(tIntegerType a) {
  static constexpr tIntegerType zero = 0;
  return a ? BitNot(zero) : zero;
   e1462:	427f      	negs	r7, r7
}

// Plain bit-wise XOR
template <typename tIntegerType>
tIntegerType BitXor(tIntegerType a, tIntegerType b) {
  return a ^ b;
   e1464:	ea24 0406 	bic.w	r4, r4, r6
   e1468:	4044      	eors	r4, r0
        GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(InputF, -(1 << clampB), -32.0);
    result = SelectUsingMask(MaskIfLessThan(a, clamp), ResultF::Zero(), result);
  }

  result = SelectUsingMask(MaskIfZero(a), ResultF::One(), result);
  return result;
   e146a:	43f8      	mvns	r0, r7
   e146c:	4004      	ands	r4, r0
   e146e:	f027 4000 	bic.w	r0, r7, #2147483648	; 0x80000000
}
   e1472:	4060      	eors	r0, r4
   e1474:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
   e1476:	bf00      	nop
   e1478:	63afbe7b 	.word	0x63afbe7b
   e147c:	4da2cbf2 	.word	0x4da2cbf2
   e1480:	2f16ac6c 	.word	0x2f16ac6c
   e1484:	1152aaa4 	.word	0x1152aaa4
   e1488:	02582ab7 	.word	0x02582ab7
   e148c:	000afe11 	.word	0x000afe11

000e1490 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph>:
  }
}

inline void Softmax(const SoftmaxParams& params,
                    const RuntimeShape& input_shape, const uint8* input_data,
                    const RuntimeShape& output_shape, uint8* output_data) {
   e1490:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e1494:	b08d      	sub	sp, #52	; 0x34
  using FixedPointScaledDiff =
      gemmlowp::FixedPoint<int32, kScaledDiffIntegerBits>;
  using FixedPointAccum = gemmlowp::FixedPoint<int32, kAccumulationIntegerBits>;
  using FixedPoint0 = gemmlowp::FixedPoint<int32, 0>;

  const int trailing_dim = input_shape.DimensionsCount() - 1;
   e1496:	680d      	ldr	r5, [r1, #0]
  }
}

inline void Softmax(const SoftmaxParams& params,
                    const RuntimeShape& input_shape, const uint8* input_data,
                    const RuntimeShape& output_shape, uint8* output_data) {
   e1498:	461e      	mov	r6, r3
  const int32 input_beta_multiplier = params.input_multiplier;
   e149a:	6883      	ldr	r3, [r0, #8]
   e149c:	9301      	str	r3, [sp, #4]
  }
}

inline void Softmax(const SoftmaxParams& params,
                    const RuntimeShape& input_shape, const uint8* input_data,
                    const RuntimeShape& output_shape, uint8* output_data) {
   e149e:	460c      	mov	r4, r1
  const int32 input_beta_multiplier = params.input_multiplier;
  const int32 input_beta_left_shift = params.input_left_shift;
   e14a0:	68c3      	ldr	r3, [r0, #12]
   e14a2:	9302      	str	r3, [sp, #8]
  using FixedPointScaledDiff =
      gemmlowp::FixedPoint<int32, kScaledDiffIntegerBits>;
  using FixedPointAccum = gemmlowp::FixedPoint<int32, kAccumulationIntegerBits>;
  using FixedPoint0 = gemmlowp::FixedPoint<int32, 0>;

  const int trailing_dim = input_shape.DimensionsCount() - 1;
   e14a4:	3d01      	subs	r5, #1
inline void Softmax(const SoftmaxParams& params,
                    const RuntimeShape& input_shape, const uint8* input_data,
                    const RuntimeShape& output_shape, uint8* output_data) {
  const int32 input_beta_multiplier = params.input_multiplier;
  const int32 input_beta_left_shift = params.input_left_shift;
  const int diff_min = params.diff_min;
   e14a6:	6983      	ldr	r3, [r0, #24]
   e14a8:	9303      	str	r3, [sp, #12]
  using FixedPointAccum = gemmlowp::FixedPoint<int32, kAccumulationIntegerBits>;
  using FixedPoint0 = gemmlowp::FixedPoint<int32, 0>;

  const int trailing_dim = input_shape.DimensionsCount() - 1;
  const int outer_size =
      MatchingFlatSizeSkipDim(input_shape, trailing_dim, output_shape);
   e14aa:	4629      	mov	r1, r5
   e14ac:	4620      	mov	r0, r4
  }
}

inline void Softmax(const SoftmaxParams& params,
                    const RuntimeShape& input_shape, const uint8* input_data,
                    const RuntimeShape& output_shape, uint8* output_data) {
   e14ae:	4692      	mov	sl, r2
  using FixedPointAccum = gemmlowp::FixedPoint<int32, kAccumulationIntegerBits>;
  using FixedPoint0 = gemmlowp::FixedPoint<int32, 0>;

  const int trailing_dim = input_shape.DimensionsCount() - 1;
  const int outer_size =
      MatchingFlatSizeSkipDim(input_shape, trailing_dim, output_shape);
   e14b0:	4632      	mov	r2, r6
   e14b2:	f7ff fcff 	bl	e0eb4 <_ZN6tflite23MatchingFlatSizeSkipDimERKNS_12RuntimeShapeEiS2_>
   e14b6:	4629      	mov	r1, r5
   e14b8:	9004      	str	r0, [sp, #16]
   e14ba:	4620      	mov	r0, r4
   e14bc:	f7f6 f860 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e14c0:	4629      	mov	r1, r5
   e14c2:	4604      	mov	r4, r0
   e14c4:	4630      	mov	r0, r6
   e14c6:	f7f6 f85b 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e14ca:	4284      	cmp	r4, r0
   e14cc:	d001      	beq.n	e14d2 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x42>
   e14ce:	f004 f811 	bl	e54f4 <abort>
   e14d2:	f8dd 9058 	ldr.w	r9, [sp, #88]	; 0x58
   e14d6:	4656      	mov	r6, sl
   e14d8:	f1ca 0500 	rsb	r5, sl, #0
   e14dc:	2700      	movs	r7, #0
  const int depth =
      MatchingDim(input_shape, trailing_dim, output_shape, trailing_dim);

  for (int i = 0; i < outer_size; ++i) {
   e14de:	9b04      	ldr	r3, [sp, #16]
   e14e0:	429f      	cmp	r7, r3
   e14e2:	da7d      	bge.n	e15e0 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x150>
    uint8 max_in_row = 0;
   e14e4:	f04f 0300 	mov.w	r3, #0
   e14e8:	f88d 3023 	strb.w	r3, [sp, #35]	; 0x23
   e14ec:	4632      	mov	r2, r6
    for (int c = 0; c < depth; ++c) {
   e14ee:	1953      	adds	r3, r2, r5
   e14f0:	42a3      	cmp	r3, r4
   e14f2:	da0c      	bge.n	e150e <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x7e>
      max_in_row = std::max(max_in_row, input_data[i * depth + c]);
   e14f4:	4613      	mov	r3, r2
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
   e14f6:	f89d 1023 	ldrb.w	r1, [sp, #35]	; 0x23
   e14fa:	7818      	ldrb	r0, [r3, #0]
   e14fc:	4288      	cmp	r0, r1
	return __b;
      return __a;
   e14fe:	bf98      	it	ls
   e1500:	f10d 0323 	addls.w	r3, sp, #35	; 0x23
   e1504:	3201      	adds	r2, #1
   e1506:	781b      	ldrb	r3, [r3, #0]
   e1508:	f88d 3023 	strb.w	r3, [sp, #35]	; 0x23
  const int depth =
      MatchingDim(input_shape, trailing_dim, output_shape, trailing_dim);

  for (int i = 0; i < outer_size; ++i) {
    uint8 max_in_row = 0;
    for (int c = 0; c < depth; ++c) {
   e150c:	e7ef      	b.n	e14ee <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x5e>
   e150e:	46b0      	mov	r8, r6
   e1510:	f04f 0b00 	mov.w	fp, #0
      max_in_row = std::max(max_in_row, input_data[i * depth + c]);
    }

    FixedPointAccum sum_of_exps = FixedPointAccum::Zero();
    for (int c = 0; c < depth; ++c) {
   e1514:	eb08 0305 	add.w	r3, r8, r5
   e1518:	42a3      	cmp	r3, r4
   e151a:	da13      	bge.n	e1544 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0xb4>
      int32 input_diff =
          static_cast<int32>(input_data[i * depth + c]) - max_in_row;
   e151c:	f818 3b01 	ldrb.w	r3, [r8], #1
   e1520:	f89d 0023 	ldrb.w	r0, [sp, #35]	; 0x23
   e1524:	1a18      	subs	r0, r3, r0
      if (input_diff >= diff_min) {
   e1526:	9b03      	ldr	r3, [sp, #12]
   e1528:	4283      	cmp	r3, r0
   e152a:	dcf3      	bgt.n	e1514 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x84>

inline int32 MultiplyByQuantizedMultiplierGreaterThanOne(
    int32 x, int32 quantized_multiplier, int left_shift) {
  using gemmlowp::SaturatingRoundingDoublingHighMul;
  return SaturatingRoundingDoublingHighMul(x * (1 << left_shift),
                                           quantized_multiplier);
   e152c:	9b02      	ldr	r3, [sp, #8]
   e152e:	9901      	ldr	r1, [sp, #4]
   e1530:	4098      	lsls	r0, r3
   e1532:	f7ff fc97 	bl	e0e64 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_>
            MultiplyByQuantizedMultiplierGreaterThanOne(
                input_diff, input_beta_multiplier, input_beta_left_shift);
        const FixedPointScaledDiff scaled_diff_f8 =
            FixedPointScaledDiff::FromRaw(input_diff_rescaled);
        sum_of_exps = sum_of_exps + gemmlowp::Rescale<kAccumulationIntegerBits>(
                                        exp_on_negative_values(scaled_diff_f8));
   e1536:	f7ff ff2f 	bl	e1398 <_ZN8gemmlowp22exp_on_negative_valuesIlLi5EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE>
};

template <int Exponent, typename IntegerType>
struct ImplSaturatingRoundingMultiplyByPOT<Exponent, IntegerType, -1> {
  static IntegerType eval(IntegerType x) {
    return RoundingDivideByPOT<IntegerType>(x, -Exponent);
   e153a:	210c      	movs	r1, #12
   e153c:	f7ff fe22 	bl	e1184 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i>
}

// Integer addition. Not saturating. Overflow is undefined behavior.
template <typename tIntegerType>
tIntegerType Add(tIntegerType a, tIntegerType b) {
  return a + b;
   e1540:	4483      	add	fp, r0
    for (int c = 0; c < depth; ++c) {
      max_in_row = std::max(max_in_row, input_data[i * depth + c]);
    }

    FixedPointAccum sum_of_exps = FixedPointAccum::Zero();
    for (int c = 0; c < depth; ++c) {
   e1542:	e7e7      	b.n	e1514 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x84>
int CountLeadingZeros(T integer_input) {
  static_assert(std::is_unsigned<T>::value,
                "Only unsigned integer types handled.");
#if defined(__GNUC__)
  return integer_input ? __builtin_clz(integer_input)
                       : std::numeric_limits<T>::digits;
   e1544:	f1bb 0f00 	cmp.w	fp, #0
   e1548:	d002      	beq.n	e1550 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0xc0>
   e154a:	fabb f88b 	clz	r8, fp
   e154e:	e001      	b.n	e1554 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0xc4>
   e1550:	f04f 0820 	mov.w	r8, #32
   e1554:	fa0b f008 	lsl.w	r0, fp, r8
      static_cast<int32>((static_cast<uint32>(x) << headroom_plus_one) -
                         (static_cast<uint32>(1) << 31));

  gemmlowp::FixedPoint<int32, 0> shifted_scale =
      gemmlowp::one_over_one_plus_x_for_x_in_0_1(
          gemmlowp::FixedPoint<int32, 0>::FromRaw(shifted_sum_minus_one));
   e1558:	f100 4000 	add.w	r0, r0, #2147483648	; 0x80000000
   e155c:	f7ff fe48 	bl	e11f0 <_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IlEENS_10FixedPointIT_Li0EEES3_>

    int num_bits_over_unit;
    FixedPoint0 shifted_scale = FixedPoint0::FromRaw(GetReciprocal(
        sum_of_exps.raw(), kAccumulationIntegerBits, &num_bits_over_unit));

    for (int c = 0; c < depth; ++c) {
   e1560:	9916      	ldr	r1, [sp, #88]	; 0x58
   e1562:	1a69      	subs	r1, r5, r1
   e1564:	4451      	add	r1, sl
   e1566:	4683      	mov	fp, r0
      }
    }

    int num_bits_over_unit;
    FixedPoint0 shifted_scale = FixedPoint0::FromRaw(GetReciprocal(
        sum_of_exps.raw(), kAccumulationIntegerBits, &num_bits_over_unit));
   e1568:	4632      	mov	r2, r6
   e156a:	464b      	mov	r3, r9

    for (int c = 0; c < depth; ++c) {
   e156c:	9105      	str	r1, [sp, #20]
                input_diff, input_beta_multiplier, input_beta_left_shift);
        const FixedPointScaledDiff scaled_diff_f8 =
            FixedPointScaledDiff::FromRaw(input_diff_rescaled);

        FixedPoint0 exp_in_0 = exp_on_negative_values(scaled_diff_f8);
        int32 unsat_output = gemmlowp::RoundingDivideByPOT(
   e156e:	f1c8 0823 	rsb	r8, r8, #35	; 0x23

    int num_bits_over_unit;
    FixedPoint0 shifted_scale = FixedPoint0::FromRaw(GetReciprocal(
        sum_of_exps.raw(), kAccumulationIntegerBits, &num_bits_over_unit));

    for (int c = 0; c < depth; ++c) {
   e1572:	9905      	ldr	r1, [sp, #20]
   e1574:	4419      	add	r1, r3
   e1576:	428c      	cmp	r4, r1
   e1578:	dd2d      	ble.n	e15d6 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x146>
      int32 input_diff =
          static_cast<int32>(input_data[i * depth + c]) - max_in_row;
   e157a:	f812 1b01 	ldrb.w	r1, [r2], #1
   e157e:	f89d 0023 	ldrb.w	r0, [sp, #35]	; 0x23
   e1582:	1a08      	subs	r0, r1, r0
      if (input_diff >= diff_min) {
   e1584:	9903      	ldr	r1, [sp, #12]
   e1586:	4281      	cmp	r1, r0
   e1588:	dc20      	bgt.n	e15cc <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x13c>
   e158a:	9306      	str	r3, [sp, #24]

inline int32 MultiplyByQuantizedMultiplierGreaterThanOne(
    int32 x, int32 quantized_multiplier, int left_shift) {
  using gemmlowp::SaturatingRoundingDoublingHighMul;
  return SaturatingRoundingDoublingHighMul(x * (1 << left_shift),
                                           quantized_multiplier);
   e158c:	9b02      	ldr	r3, [sp, #8]
   e158e:	9901      	ldr	r1, [sp, #4]
   e1590:	9207      	str	r2, [sp, #28]
   e1592:	4098      	lsls	r0, r3
   e1594:	f7ff fc66 	bl	e0e64 <_ZN8gemmlowp33SaturatingRoundingDoublingHighMulIlEET_S1_S1_>
            MultiplyByQuantizedMultiplierGreaterThanOne(
                input_diff, input_beta_multiplier, input_beta_left_shift);
        const FixedPointScaledDiff scaled_diff_f8 =
            FixedPointScaledDiff::FromRaw(input_diff_rescaled);

        FixedPoint0 exp_in_0 = exp_on_negative_values(scaled_diff_f8);
   e1598:	f7ff fefe 	bl	e1398 <_ZN8gemmlowp22exp_on_negative_valuesIlLi5EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE>
        int32 unsat_output = gemmlowp::RoundingDivideByPOT(
            (shifted_scale * exp_in_0).raw(), num_bits_over_unit + 31 - 8);
   e159c:	4601      	mov	r1, r0
   e159e:	4658      	mov	r0, fp
   e15a0:	f7ff fe1c 	bl	e11dc <_ZN8gemmlowpmlIlLi0ELi0EEENS_10FixedPointIT_XplT0_T1_EEENS1_IS2_XT0_EEENS1_IS2_XT1_EEE>
                input_diff, input_beta_multiplier, input_beta_left_shift);
        const FixedPointScaledDiff scaled_diff_f8 =
            FixedPointScaledDiff::FromRaw(input_diff_rescaled);

        FixedPoint0 exp_in_0 = exp_on_negative_values(scaled_diff_f8);
        int32 unsat_output = gemmlowp::RoundingDivideByPOT(
   e15a4:	4641      	mov	r1, r8
   e15a6:	f7ff fded 	bl	e1184 <_ZN8gemmlowp19RoundingDivideByPOTIlEET_S1_i>
            (shifted_scale * exp_in_0).raw(), num_bits_over_unit + 31 - 8);

        output_data[i * depth + c] = static_cast<uint8>(
            std::max(std::min(unsat_output, static_cast<int32>(255)),
   e15aa:	21ff      	movs	r1, #255	; 0xff
    min(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
   e15ac:	4288      	cmp	r0, r1
   e15ae:	910a      	str	r1, [sp, #40]	; 0x28
	return __b;
      return __a;
   e15b0:	bfd4      	ite	le
   e15b2:	a909      	addle	r1, sp, #36	; 0x24
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
   e15b4:	a90a      	addgt	r1, sp, #40	; 0x28
        const FixedPointScaledDiff scaled_diff_f8 =
            FixedPointScaledDiff::FromRaw(input_diff_rescaled);

        FixedPoint0 exp_in_0 = exp_on_negative_values(scaled_diff_f8);
        int32 unsat_output = gemmlowp::RoundingDivideByPOT(
            (shifted_scale * exp_in_0).raw(), num_bits_over_unit + 31 - 8);
   e15b6:	9009      	str	r0, [sp, #36]	; 0x24

        output_data[i * depth + c] = static_cast<uint8>(
            std::max(std::min(unsat_output, static_cast<int32>(255)),
                     static_cast<int32>(0)));
   e15b8:	2000      	movs	r0, #0
   e15ba:	900b      	str	r0, [sp, #44]	; 0x2c
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
   e15bc:	6808      	ldr	r0, [r1, #0]
    min(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
   e15be:	9b06      	ldr	r3, [sp, #24]
   e15c0:	9a07      	ldr	r2, [sp, #28]
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
   e15c2:	2800      	cmp	r0, #0
	return __b;
   e15c4:	bfb8      	it	lt
   e15c6:	a90b      	addlt	r1, sp, #44	; 0x2c
   e15c8:	6809      	ldr	r1, [r1, #0]
   e15ca:	e001      	b.n	e15d0 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x140>

      } else {
        output_data[i * depth + c] = 0;
   e15cc:	f04f 0100 	mov.w	r1, #0
   e15d0:	7019      	strb	r1, [r3, #0]
   e15d2:	3301      	adds	r3, #1

    int num_bits_over_unit;
    FixedPoint0 shifted_scale = FixedPoint0::FromRaw(GetReciprocal(
        sum_of_exps.raw(), kAccumulationIntegerBits, &num_bits_over_unit));

    for (int c = 0; c < depth; ++c) {
   e15d4:	e7cd      	b.n	e1572 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0xe2>
  const int outer_size =
      MatchingFlatSizeSkipDim(input_shape, trailing_dim, output_shape);
  const int depth =
      MatchingDim(input_shape, trailing_dim, output_shape, trailing_dim);

  for (int i = 0; i < outer_size; ++i) {
   e15d6:	3701      	adds	r7, #1
   e15d8:	44a1      	add	r9, r4
   e15da:	4426      	add	r6, r4
   e15dc:	1b2d      	subs	r5, r5, r4
   e15de:	e77e      	b.n	e14de <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph+0x4e>
      } else {
        output_data[i * depth + c] = 0;
      }
    }
  }
}
   e15e0:	b00d      	add	sp, #52	; 0x34
   e15e2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	...

000e15e8 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode>:
  tflite::reference_ops::Softmax(
      op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
      GetTensorShape(output), GetTensorData<uint8_t>(output));
}

TfLiteStatus SoftmaxEval(TfLiteContext* context, TfLiteNode* node) {
   e15e8:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e15ec:	680b      	ldr	r3, [r1, #0]
   e15ee:	f8d0 8008 	ldr.w	r8, [r0, #8]
   e15f2:	685a      	ldr	r2, [r3, #4]
  auto* params = reinterpret_cast<TfLiteSoftmaxParams*>(node->builtin_data);
   e15f4:	694f      	ldr	r7, [r1, #20]
   e15f6:	2338      	movs	r3, #56	; 0x38
   e15f8:	fb03 f902 	mul.w	r9, r3, r2
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e15fc:	684a      	ldr	r2, [r1, #4]
  tflite::reference_ops::Softmax(
      op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
      GetTensorShape(output), GetTensorData<uint8_t>(output));
}

TfLiteStatus SoftmaxEval(TfLiteContext* context, TfLiteNode* node) {
   e15fe:	b09f      	sub	sp, #124	; 0x7c
   e1600:	6854      	ldr	r4, [r2, #4]
   e1602:	4605      	mov	r5, r0
  auto* params = reinterpret_cast<TfLiteSoftmaxParams*>(node->builtin_data);

  const TfLiteTensor* input = GetInput(context, node, 0);
  TfLiteTensor* output = GetOutput(context, node, 0);

  OpData local_data_object;
   e1604:	2210      	movs	r2, #16
   e1606:	2100      	movs	r1, #0
   e1608:	a806      	add	r0, sp, #24
   e160a:	fb03 8404 	mla	r4, r3, r4, r8
   e160e:	f007 fab3 	bl	e8b78 <memset>
TfLiteStatus CalculateSoftmaxOpData(TfLiteContext* context,
                                    const TfLiteTensor* input,
                                    TfLiteTensor* output,
                                    const TfLiteSoftmaxParams* params,
                                    OpData* data) {
  if (input->type == kTfLiteUInt8) {
   e1612:	f818 3009 	ldrb.w	r3, [r8, r9]
   e1616:	2b03      	cmp	r3, #3
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e1618:	eb08 0609 	add.w	r6, r8, r9
   e161c:	d13f      	bne.n	e169e <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0xb6>
    TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);
   e161e:	6923      	ldr	r3, [r4, #16]
   e1620:	b16b      	cbz	r3, e163e <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x56>
   e1622:	9302      	str	r3, [sp, #8]
   e1624:	4b67      	ldr	r3, [pc, #412]	; (e17c4 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1dc>)
   e1626:	9301      	str	r3, [sp, #4]
   e1628:	2200      	movs	r2, #0
   e162a:	4b67      	ldr	r3, [pc, #412]	; (e17c8 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1e0>)
   e162c:	9203      	str	r2, [sp, #12]
   e162e:	9300      	str	r3, [sp, #0]
   e1630:	696c      	ldr	r4, [r5, #20]
   e1632:	4a66      	ldr	r2, [pc, #408]	; (e17cc <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1e4>)
   e1634:	4966      	ldr	r1, [pc, #408]	; (e17d0 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1e8>)
   e1636:	232c      	movs	r3, #44	; 0x2c
   e1638:	4628      	mov	r0, r5
   e163a:	47a0      	blx	r4
   e163c:	e0bd      	b.n	e17ba <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1d2>
    TF_LITE_ENSURE(context, output->params.scale == 1.f / 256);
   e163e:	ed94 7a03 	vldr	s14, [r4, #12]
   e1642:	eddf 7a64 	vldr	s15, [pc, #400]	; e17d4 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1ec>
   e1646:	eeb4 7a67 	vcmp.f32	s14, s15
   e164a:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e164e:	d008      	beq.n	e1662 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x7a>
   e1650:	4b61      	ldr	r3, [pc, #388]	; (e17d8 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1f0>)
   e1652:	9300      	str	r3, [sp, #0]
   e1654:	696c      	ldr	r4, [r5, #20]
   e1656:	4a5d      	ldr	r2, [pc, #372]	; (e17cc <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1e4>)
   e1658:	4960      	ldr	r1, [pc, #384]	; (e17dc <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1f4>)
   e165a:	232d      	movs	r3, #45	; 0x2d
   e165c:	4628      	mov	r0, r5
   e165e:	47a0      	blx	r4
   e1660:	e0ab      	b.n	e17ba <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1d2>

    static const int kScaledDiffIntegerBits = 5;

    tflite::PreprocessSoftmaxScaling(
        params->beta, input->params.scale, kScaledDiffIntegerBits,
        &data->input_multiplier, &data->input_left_shift);
   e1662:	68f0      	ldr	r0, [r6, #12]
   e1664:	f006 fe8a 	bl	e837c <__aeabi_f2d>
   e1668:	e9cd 0104 	strd	r0, r1, [sp, #16]
   e166c:	6838      	ldr	r0, [r7, #0]
   e166e:	f006 fe85 	bl	e837c <__aeabi_f2d>
   e1672:	ed9d 1b04 	vldr	d1, [sp, #16]
   e1676:	ec41 0b10 	vmov	d0, r0, r1
   e167a:	aa07      	add	r2, sp, #28
   e167c:	a906      	add	r1, sp, #24
   e167e:	2005      	movs	r0, #5
   e1680:	f003 fcaa 	bl	e4fd8 <_ZN6tflite24PreprocessSoftmaxScalingEddiPlPi>
    data->diff_min = -1.0 * tflite::CalculateInputRadius(
   e1684:	221f      	movs	r2, #31
   e1686:	9907      	ldr	r1, [sp, #28]
   e1688:	2005      	movs	r0, #5
   e168a:	f003 fcdd 	bl	e5048 <_ZN6tflite20CalculateInputRadiusEiii>
                                kScaledDiffIntegerBits, data->input_left_shift);
   e168e:	f006 fe63 	bl	e8358 <__aeabi_i2d>
   e1692:	f101 4300 	add.w	r3, r1, #2147483648	; 0x80000000
   e1696:	4619      	mov	r1, r3
   e1698:	f007 f95e 	bl	e8958 <__aeabi_d2iz>
   e169c:	9009      	str	r0, [sp, #36]	; 0x24
  TF_LITE_ENSURE_STATUS(
      CalculateSoftmaxOpData(context, input, output, params, data));

  // TODO(ahentz): consider an implementation that works for many (all?)
  // dimensions.
  switch (input->type) {
   e169e:	f818 8009 	ldrb.w	r8, [r8, r9]
   e16a2:	f1b8 0f01 	cmp.w	r8, #1
   e16a6:	d11f      	bne.n	e16e8 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x100>
#include "tensorflow/lite/c/builtin_op_data.h"
#include "tensorflow/lite/c/c_api_internal.h"

namespace tflite {

inline int NumDimensions(const TfLiteTensor* t) { return t->dims->size; }
   e16a8:	68b3      	ldr	r3, [r6, #8]
   e16aa:	681a      	ldr	r2, [r3, #0]
    case kTfLiteFloat32: {
      if (NumDimensions(input) == 1) {
   e16ac:	2a01      	cmp	r2, #1
   e16ae:	d105      	bne.n	e16bc <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0xd4>
        Softmax1DFloat(input, output, params);
   e16b0:	463a      	mov	r2, r7
   e16b2:	4621      	mov	r1, r4
   e16b4:	4630      	mov	r0, r6
   e16b6:	f7ff fd27 	bl	e1108 <_ZN6tflite3ops5micro11activations14Softmax1DFloatEPK12TfLiteTensorPS3_P19TfLiteSoftmaxParams>
   e16ba:	e042      	b.n	e1742 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x15a>
        return kTfLiteOk;
      }
      if (NumDimensions(input) == 2) {
   e16bc:	2a02      	cmp	r2, #2
   e16be:	d105      	bne.n	e16cc <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0xe4>
        Softmax2DFloat(input, output, params);
   e16c0:	463a      	mov	r2, r7
   e16c2:	4621      	mov	r1, r4
   e16c4:	4630      	mov	r0, r6
   e16c6:	f7ff fd2a 	bl	e111e <_ZN6tflite3ops5micro11activations14Softmax2DFloatEPK12TfLiteTensorPS3_P19TfLiteSoftmaxParams>
   e16ca:	e03a      	b.n	e1742 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x15a>
        return kTfLiteOk;
      }
      if (NumDimensions(input) == 4) {
   e16cc:	2a04      	cmp	r2, #4
   e16ce:	d105      	bne.n	e16dc <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0xf4>
        Softmax4DFloat(input, output, params);
   e16d0:	463a      	mov	r2, r7
   e16d2:	4621      	mov	r1, r4
   e16d4:	4630      	mov	r0, r6
   e16d6:	f7ff fd2d 	bl	e1134 <_ZN6tflite3ops5micro11activations14Softmax4DFloatEPK12TfLiteTensorPS3_P19TfLiteSoftmaxParams>
   e16da:	e032      	b.n	e1742 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x15a>
        return kTfLiteOk;
      }
      context->ReportError(
          context, "Only 1D, 2D and 4D tensors supported currently, got %dD.",
          NumDimensions(input));
   e16dc:	4628      	mov	r0, r5
   e16de:	696b      	ldr	r3, [r5, #20]
   e16e0:	493f      	ldr	r1, [pc, #252]	; (e17e0 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1f8>)
   e16e2:	4798      	blx	r3
      return kTfLiteError;
   e16e4:	4640      	mov	r0, r8
   e16e6:	e069      	b.n	e17bc <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1d4>
  TF_LITE_ENSURE_STATUS(
      CalculateSoftmaxOpData(context, input, output, params, data));

  // TODO(ahentz): consider an implementation that works for many (all?)
  // dimensions.
  switch (input->type) {
   e16e8:	f1b8 0f03 	cmp.w	r8, #3
   e16ec:	d160      	bne.n	e17b0 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1c8>
   e16ee:	68b3      	ldr	r3, [r6, #8]
   e16f0:	681f      	ldr	r7, [r3, #0]
          context, "Only 1D, 2D and 4D tensors supported currently, got %dD.",
          NumDimensions(input));
      return kTfLiteError;
    }
    case kTfLiteUInt8: {
      if (NumDimensions(input) == 1) {
   e16f2:	2f01      	cmp	r7, #1
   e16f4:	d127      	bne.n	e1746 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x15e>
  // TODO(ahentz): this is arguably a dirty trick. Since the implementation
  // always traverses the last dimension of a 4D tensor, we will pretend our 1D
  // tensor is 4D in a special way. We will convert a (Y) shape into a (1,
  // 1, 1, Y) shape.
  const int input_size = input->dims->data[0];
  const int32_t shape_data[4] = {1, 1, 1, input_size};
   e16f6:	ad0a      	add	r5, sp, #40	; 0x28
                        TfLiteSoftmaxParams* params, OpData* data) {
  // TODO(ahentz): this is arguably a dirty trick. Since the implementation
  // always traverses the last dimension of a 4D tensor, we will pretend our 1D
  // tensor is 4D in a special way. We will convert a (Y) shape into a (1,
  // 1, 1, Y) shape.
  const int input_size = input->dims->data[0];
   e16f8:	f8d3 8004 	ldr.w	r8, [r3, #4]
  const int32_t shape_data[4] = {1, 1, 1, input_size};
   e16fc:	2210      	movs	r2, #16
   e16fe:	2100      	movs	r1, #0
   e1700:	4628      	mov	r0, r5
   e1702:	f007 fa39 	bl	e8b78 <memset>
   e1706:	970a      	str	r7, [sp, #40]	; 0x28
   e1708:	970b      	str	r7, [sp, #44]	; 0x2c
   e170a:	970c      	str	r7, [sp, #48]	; 0x30
   e170c:	f8cd 8034 	str.w	r8, [sp, #52]	; 0x34
      TFLITE_CHECK(false && "No shape resizing supported on this platform");
#else   // TF_LITE_STATIC_MEMORY
      delete[] dims_pointer_;
#endif  // TF_LITE_STATIC_MEMORY
    }
    size_ = dimensions_count;
   e1710:	2304      	movs	r3, #4
   e1712:	930f      	str	r3, [sp, #60]	; 0x3c
  }

  inline void ReplaceWith(int dimensions_count, const int32* dims_data) {
    Resize(dimensions_count);
    int32* dst_dims = DimsData();
    std::memcpy(dst_dims, dims_data, dimensions_count * sizeof(int32));
   e1714:	e895 000f 	ldmia.w	r5, {r0, r1, r2, r3}
   e1718:	af10      	add	r7, sp, #64	; 0x40
   e171a:	e887 000f 	stmia.w	r7, {r0, r1, r2, r3}
  const int batch_size = input->dims->data[0];
  const int input_size = input->dims->data[1];
  const int32_t shape_data[4] = {batch_size, 1, 1, input_size};
  RuntimeShape shape(4, shape_data);
  SoftmaxParams op_params;
  op_params.input_multiplier = data->input_multiplier;
   e171e:	9b06      	ldr	r3, [sp, #24]
   e1720:	9316      	str	r3, [sp, #88]	; 0x58
  op_params.input_left_shift = data->input_left_shift;
   e1722:	9b07      	ldr	r3, [sp, #28]
   e1724:	9317      	str	r3, [sp, #92]	; 0x5c
  op_params.diff_min = data->diff_min;
   e1726:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e1728:	931a      	str	r3, [sp, #104]	; 0x68
   e172a:	b104      	cbz	r4, e172e <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x146>
   e172c:	6864      	ldr	r4, [r4, #4]
  tflite::reference_ops::Softmax(op_params, shape,
                                 GetTensorData<uint8_t>(input), shape,
                                 GetTensorData<uint8_t>(output));
   e172e:	9400      	str	r4, [sp, #0]
   e1730:	ab0f      	add	r3, sp, #60	; 0x3c
   e1732:	a814      	add	r0, sp, #80	; 0x50
   e1734:	6872      	ldr	r2, [r6, #4]
   e1736:	4619      	mov	r1, r3
   e1738:	f7ff feaa 	bl	e1490 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph>
  // tensor is 4D in a special way. We will convert a (X, Y) shape into a (X,
  // 1, 1, Y) shape.
  const int batch_size = input->dims->data[0];
  const int input_size = input->dims->data[1];
  const int32_t shape_data[4] = {batch_size, 1, 1, input_size};
  RuntimeShape shape(4, shape_data);
   e173c:	a80f      	add	r0, sp, #60	; 0x3c
  SoftmaxParams op_params;
  op_params.input_multiplier = data->input_multiplier;
  op_params.input_left_shift = data->input_left_shift;
  op_params.diff_min = data->diff_min;
  tflite::reference_ops::Softmax(
      op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e173e:	f7f5 ff14 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
        Softmax2DQuantized(input, output, params, data);
        return kTfLiteOk;
      }
      if (NumDimensions(input) == 4) {
        Softmax4DQuantized(input, output, params, data);
        return kTfLiteOk;
   e1742:	2000      	movs	r0, #0
   e1744:	e03a      	b.n	e17bc <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1d4>
    case kTfLiteUInt8: {
      if (NumDimensions(input) == 1) {
        Softmax1DQuantized(input, output, params, data);
        return kTfLiteOk;
      }
      if (NumDimensions(input) == 2) {
   e1746:	2f02      	cmp	r7, #2
   e1748:	d10f      	bne.n	e176a <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x182>
  // always traverses the last dimension of a 4D tensor, we will pretend our 2D
  // tensor is 4D in a special way. We will convert a (X, Y) shape into a (X,
  // 1, 1, Y) shape.
  const int batch_size = input->dims->data[0];
  const int input_size = input->dims->data[1];
  const int32_t shape_data[4] = {batch_size, 1, 1, input_size};
   e174a:	ad0a      	add	r5, sp, #40	; 0x28
   e174c:	2210      	movs	r2, #16
   e174e:	2100      	movs	r1, #0
   e1750:	4628      	mov	r0, r5
                        TfLiteSoftmaxParams* params, OpData* data) {
  // TODO(ahentz): this is arguably a dirty trick. Since the implementation
  // always traverses the last dimension of a 4D tensor, we will pretend our 2D
  // tensor is 4D in a special way. We will convert a (X, Y) shape into a (X,
  // 1, 1, Y) shape.
  const int batch_size = input->dims->data[0];
   e1752:	f8d3 8004 	ldr.w	r8, [r3, #4]
  const int input_size = input->dims->data[1];
   e1756:	689f      	ldr	r7, [r3, #8]
  const int32_t shape_data[4] = {batch_size, 1, 1, input_size};
   e1758:	f007 fa0e 	bl	e8b78 <memset>
   e175c:	2301      	movs	r3, #1
   e175e:	930b      	str	r3, [sp, #44]	; 0x2c
   e1760:	930c      	str	r3, [sp, #48]	; 0x30
   e1762:	f8cd 8028 	str.w	r8, [sp, #40]	; 0x28
   e1766:	970d      	str	r7, [sp, #52]	; 0x34
   e1768:	e7d2      	b.n	e1710 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x128>
      }
      if (NumDimensions(input) == 2) {
        Softmax2DQuantized(input, output, params, data);
        return kTfLiteOk;
      }
      if (NumDimensions(input) == 4) {
   e176a:	2f04      	cmp	r7, #4
   e176c:	d11c      	bne.n	e17a8 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1c0>
}

void Softmax4DQuantized(const TfLiteTensor* input, TfLiteTensor* output,
                        TfLiteSoftmaxParams* params, OpData* data) {
  SoftmaxParams op_params;
  op_params.input_multiplier = data->input_multiplier;
   e176e:	9b06      	ldr	r3, [sp, #24]
   e1770:	9316      	str	r3, [sp, #88]	; 0x58
  op_params.input_left_shift = data->input_left_shift;
   e1772:	9b07      	ldr	r3, [sp, #28]
   e1774:	9317      	str	r3, [sp, #92]	; 0x5c
  op_params.diff_min = data->diff_min;
  tflite::reference_ops::Softmax(
      op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e1776:	4631      	mov	r1, r6
void Softmax4DQuantized(const TfLiteTensor* input, TfLiteTensor* output,
                        TfLiteSoftmaxParams* params, OpData* data) {
  SoftmaxParams op_params;
  op_params.input_multiplier = data->input_multiplier;
  op_params.input_left_shift = data->input_left_shift;
  op_params.diff_min = data->diff_min;
   e1778:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e177a:	931a      	str	r3, [sp, #104]	; 0x68
  tflite::reference_ops::Softmax(
      op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e177c:	a80a      	add	r0, sp, #40	; 0x28
   e177e:	f7f6 f9a4 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorShape(output), GetTensorData<uint8_t>(output));
   e1782:	4621      	mov	r1, r4
   e1784:	a80f      	add	r0, sp, #60	; 0x3c
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e1786:	6875      	ldr	r5, [r6, #4]
   e1788:	f7f6 f99f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e178c:	b104      	cbz	r4, e1790 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1a8>
   e178e:	6864      	ldr	r4, [r4, #4]
   e1790:	9400      	str	r4, [sp, #0]
   e1792:	ab0f      	add	r3, sp, #60	; 0x3c
   e1794:	462a      	mov	r2, r5
   e1796:	a90a      	add	r1, sp, #40	; 0x28
   e1798:	a814      	add	r0, sp, #80	; 0x50
   e179a:	f7ff fe79 	bl	e1490 <_ZN6tflite13reference_ops7SoftmaxERKNS_13SoftmaxParamsERKNS_12RuntimeShapeEPKhS6_Ph>
   e179e:	a80f      	add	r0, sp, #60	; 0x3c
   e17a0:	f7f5 fee3 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  SoftmaxParams op_params;
  op_params.input_multiplier = data->input_multiplier;
  op_params.input_left_shift = data->input_left_shift;
  op_params.diff_min = data->diff_min;
  tflite::reference_ops::Softmax(
      op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e17a4:	a80a      	add	r0, sp, #40	; 0x28
   e17a6:	e7ca      	b.n	e173e <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x156>
        Softmax4DQuantized(input, output, params, data);
        return kTfLiteOk;
      }
      context->ReportError(
          context, "Only 2D and 4D tensors supported currently, got %dD.",
          NumDimensions(input));
   e17a8:	696b      	ldr	r3, [r5, #20]
   e17aa:	490e      	ldr	r1, [pc, #56]	; (e17e4 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1fc>)
   e17ac:	463a      	mov	r2, r7
   e17ae:	e002      	b.n	e17b6 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x1ce>
      return kTfLiteError;
    }
    default:
      context->ReportError(
          context, "Only float32 and uint8_t supported currently, got %d.",
          input->type);
   e17b0:	696b      	ldr	r3, [r5, #20]
   e17b2:	490d      	ldr	r1, [pc, #52]	; (e17e8 <_ZN6tflite3ops5micro11activations11SoftmaxEvalEP13TfLiteContextP10TfLiteNode+0x200>)
   e17b4:	4642      	mov	r2, r8
   e17b6:	4628      	mov	r0, r5
   e17b8:	4798      	blx	r3
  const TfLiteTensor* input = GetInput(context, node, 0);
  TfLiteTensor* output = GetOutput(context, node, 0);

  OpData local_data_object;
  OpData* data = &local_data_object;
  TF_LITE_ENSURE_STATUS(
   e17ba:	2001      	movs	r0, #1
      context->ReportError(
          context, "Only float32 and uint8_t supported currently, got %d.",
          input->type);
      return kTfLiteError;
  }
}
   e17bc:	b01f      	add	sp, #124	; 0x7c
   e17be:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
   e17c2:	bf00      	nop
   e17c4:	000eccce 	.word	0x000eccce
   e17c8:	000ebf19 	.word	0x000ebf19
   e17cc:	000ebe6b 	.word	0x000ebe6b
   e17d0:	000eb3b9 	.word	0x000eb3b9
   e17d4:	3b800000 	.word	0x3b800000
   e17d8:	000ebf33 	.word	0x000ebf33
   e17dc:	000eb58e 	.word	0x000eb58e
   e17e0:	000ebf55 	.word	0x000ebf55
   e17e4:	000ebf8e 	.word	0x000ebf8e
   e17e8:	000ebfc3 	.word	0x000ebfc3

000e17ec <_ZN6tflite3ops5micro5split7PrepareEP13TfLiteContextP10TfLiteNode>:
namespace micro {
namespace split {

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   e17ec:	2000      	movs	r0, #0
   e17ee:	4770      	bx	lr

000e17f0 <_ZN6tflite3ops5micro14Register_SPLITEv>:
}  // namespace split

TfLiteRegistration* Register_SPLIT() {
  static TfLiteRegistration r = {nullptr, nullptr, split::Prepare, split::Eval};
  return &r;
}
   e17f0:	4800      	ldr	r0, [pc, #0]	; (e17f4 <_ZN6tflite3ops5micro14Register_SPLITEv+0x4>)
   e17f2:	4770      	bx	lr
   e17f4:	2003c190 	.word	0x2003c190

000e17f8 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori>:
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e17f8:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e17fc:	684c      	ldr	r4, [r1, #4]
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
   e17fe:	6896      	ldr	r6, [r2, #8]
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1800:	6865      	ldr	r5, [r4, #4]

  const int split_dimensions = input_dims->size;
   e1802:	f8d6 c000 	ldr.w	ip, [r6]
inline const TfLiteTensor* GetIntermediates(TfLiteContext* context,
                                            TfLiteNode* node, int index) {
  return &context->tensors[node->intermediates->data[index]];
}
inline int NumInputs(const TfLiteNode* node) { return node->inputs->size; }
inline int NumOutputs(const TfLiteNode* node) { return node->outputs->size; }
   e1806:	6827      	ldr	r7, [r4, #0]
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1808:	6884      	ldr	r4, [r0, #8]

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;
   e180a:	2b00      	cmp	r3, #0
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e180c:	f04f 0e38 	mov.w	lr, #56	; 0x38
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1810:	b085      	sub	sp, #20
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1812:	fb0e 4405 	mla	r4, lr, r5, r4

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;
   e1816:	bfb8      	it	lt
   e1818:	4463      	addlt	r3, ip

  TFLITE_DCHECK_LT(axis, split_dimensions);
   e181a:	4563      	cmp	r3, ip
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e181c:	9102      	str	r1, [sp, #8]
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e181e:	68a4      	ldr	r4, [r4, #8]

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;

  TFLITE_DCHECK_LT(axis, split_dimensions);
   e1820:	db01      	blt.n	e1826 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2e>
   e1822:	f003 fe67 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(output_dims->size, split_dimensions);
   e1826:	6825      	ldr	r5, [r4, #0]
   e1828:	45ac      	cmp	ip, r5
   e182a:	d1fa      	bne.n	e1822 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2a>
   e182c:	009d      	lsls	r5, r3, #2
   e182e:	eb04 0e05 	add.w	lr, r4, r5

  int64_t split_size = output_dims->data[axis] * output_count;

  TFLITE_DCHECK_EQ(split_size, input_dims->data[axis]);
   e1832:	4435      	add	r5, r6
   e1834:	f8de 4004 	ldr.w	r4, [lr, #4]
   e1838:	686d      	ldr	r5, [r5, #4]
   e183a:	437c      	muls	r4, r7
   e183c:	42ac      	cmp	r4, r5
   e183e:	d1f0      	bne.n	e1822 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2a>
   e1840:	2401      	movs	r4, #1
   e1842:	2500      	movs	r5, #0
   e1844:	e9cd 4500 	strd	r4, r5, [sp]
   e1848:	46b2      	mov	sl, r6
   e184a:	f04f 0800 	mov.w	r8, #0
  int64_t outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e184e:	4598      	cmp	r8, r3
   e1850:	da14      	bge.n	e187c <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x84>
    outer_size *= input_dims->data[i];
   e1852:	f85a 9f04 	ldr.w	r9, [sl, #4]!
   e1856:	9900      	ldr	r1, [sp, #0]
   e1858:	464c      	mov	r4, r9
   e185a:	17e5      	asrs	r5, r4, #31
   e185c:	fb01 f405 	mul.w	r4, r1, r5
   e1860:	9901      	ldr	r1, [sp, #4]
   e1862:	fb09 4b01 	mla	fp, r9, r1, r4
   e1866:	9900      	ldr	r1, [sp, #0]
   e1868:	fba1 4509 	umull	r4, r5, r1, r9
   e186c:	e9cd 4500 	strd	r4, r5, [sp]
   e1870:	9901      	ldr	r1, [sp, #4]
   e1872:	4459      	add	r1, fp
   e1874:	9101      	str	r1, [sp, #4]

  int64_t split_size = output_dims->data[axis] * output_count;

  TFLITE_DCHECK_EQ(split_size, input_dims->data[axis]);
  int64_t outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e1876:	f108 0801 	add.w	r8, r8, #1
   e187a:	e7e8      	b.n	e184e <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x56>
   e187c:	3301      	adds	r3, #1
   e187e:	f10c 0c01 	add.w	ip, ip, #1
    outer_size *= input_dims->data[i];
  }

  int64_t base_inner_size = 1;
   e1882:	2401      	movs	r4, #1
   e1884:	2500      	movs	r5, #0
   e1886:	3301      	adds	r3, #1
  for (int i = axis + 1; i < split_dimensions; ++i) {
   e1888:	4563      	cmp	r3, ip
   e188a:	d00b      	beq.n	e18a4 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xac>
    base_inner_size *= input_dims->data[i];
   e188c:	f856 a023 	ldr.w	sl, [r6, r3, lsl #2]
   e1890:	ea4f 79ea 	mov.w	r9, sl, asr #31
   e1894:	fb04 f809 	mul.w	r8, r4, r9
   e1898:	fb0a 8805 	mla	r8, sl, r5, r8
   e189c:	fba4 450a 	umull	r4, r5, r4, sl
   e18a0:	4445      	add	r5, r8
  for (int i = 0; i < axis; ++i) {
    outer_size *= input_dims->data[i];
  }

  int64_t base_inner_size = 1;
  for (int i = axis + 1; i < split_dimensions; ++i) {
   e18a2:	e7f0      	b.n	e1886 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x8e>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e18a4:	f8d2 c004 	ldr.w	ip, [r2, #4]
   e18a8:	f04f 0800 	mov.w	r8, #0
   e18ac:	f04f 0900 	mov.w	r9, #0
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
   e18b0:	e9dd 2300 	ldrd	r2, r3, [sp]
   e18b4:	4590      	cmp	r8, r2
   e18b6:	eb79 0303 	sbcs.w	r3, r9, r3
   e18ba:	f8cd 800c 	str.w	r8, [sp, #12]
   e18be:	da2a      	bge.n	e1916 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x11e>
   e18c0:	2600      	movs	r6, #0
    for (int i = 0; i < output_count; ++i) {
   e18c2:	42be      	cmp	r6, r7
   e18c4:	da22      	bge.n	e190c <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x114>
      TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
   e18c6:	9b02      	ldr	r3, [sp, #8]
   e18c8:	685b      	ldr	r3, [r3, #4]
   e18ca:	eb03 0386 	add.w	r3, r3, r6, lsl #2
   e18ce:	2138      	movs	r1, #56	; 0x38
   e18d0:	685a      	ldr	r2, [r3, #4]
   e18d2:	6883      	ldr	r3, [r0, #8]
   e18d4:	fb01 3302 	mla	r3, r1, r2, r3

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e18d8:	b103      	cbz	r3, e18dc <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xe4>
   e18da:	685b      	ldr	r3, [r3, #4]
      T* output_data = GetTensorData<T>(t);
      const int copy_size = output_dims->data[axis] * base_inner_size;
   e18dc:	f8de 2004 	ldr.w	r2, [lr, #4]
   e18e0:	9903      	ldr	r1, [sp, #12]
   e18e2:	4362      	muls	r2, r4
   e18e4:	fb02 fb01 	mul.w	fp, r2, r1
   e18e8:	eb03 038b 	add.w	r3, r3, fp, lsl #2
   e18ec:	46e2      	mov	sl, ip
      T* output_ptr = output_data + k * copy_size;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   e18ee:	f04f 0b00 	mov.w	fp, #0
   e18f2:	4593      	cmp	fp, r2
   e18f4:	da06      	bge.n	e1904 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x10c>
   e18f6:	ecfa 7a01 	vldmia	sl!, {s15}
   e18fa:	f10b 0b01 	add.w	fp, fp, #1
   e18fe:	ece3 7a01 	vstmia	r3!, {s15}
   e1902:	e7f6      	b.n	e18f2 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xfa>
      input_ptr += copy_size;
   e1904:	eb0c 0c82 	add.w	ip, ip, r2, lsl #2
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
    for (int i = 0; i < output_count; ++i) {
   e1908:	3601      	adds	r6, #1
   e190a:	e7da      	b.n	e18c2 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xca>
   e190c:	f118 0801 	adds.w	r8, r8, #1
   e1910:	f149 0900 	adc.w	r9, r9, #0
  for (int i = axis + 1; i < split_dimensions; ++i) {
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
   e1914:	e7cc      	b.n	e18b0 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xb8>
      input_ptr += copy_size;
    }
  }

  return kTfLiteOk;
}
   e1916:	2000      	movs	r0, #0
   e1918:	b005      	add	sp, #20
   e191a:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000e191e <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori>:
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e191e:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e1922:	684c      	ldr	r4, [r1, #4]
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
   e1924:	6896      	ldr	r6, [r2, #8]
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1926:	6865      	ldr	r5, [r4, #4]

  const int split_dimensions = input_dims->size;
   e1928:	f8d6 c000 	ldr.w	ip, [r6]
   e192c:	6827      	ldr	r7, [r4, #0]
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e192e:	6884      	ldr	r4, [r0, #8]

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;
   e1930:	2b00      	cmp	r3, #0
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1932:	f04f 0e38 	mov.w	lr, #56	; 0x38
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1936:	b085      	sub	sp, #20
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1938:	fb0e 4405 	mla	r4, lr, r5, r4

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;
   e193c:	bfb8      	it	lt
   e193e:	4463      	addlt	r3, ip

  TFLITE_DCHECK_LT(axis, split_dimensions);
   e1940:	4563      	cmp	r3, ip
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1942:	9102      	str	r1, [sp, #8]
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1944:	68a4      	ldr	r4, [r4, #8]

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;

  TFLITE_DCHECK_LT(axis, split_dimensions);
   e1946:	db01      	blt.n	e194c <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2e>
   e1948:	f003 fdd4 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(output_dims->size, split_dimensions);
   e194c:	6825      	ldr	r5, [r4, #0]
   e194e:	45ac      	cmp	ip, r5
   e1950:	d1fa      	bne.n	e1948 <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2a>
   e1952:	009d      	lsls	r5, r3, #2
   e1954:	eb04 0e05 	add.w	lr, r4, r5

  int64_t split_size = output_dims->data[axis] * output_count;

  TFLITE_DCHECK_EQ(split_size, input_dims->data[axis]);
   e1958:	4435      	add	r5, r6
   e195a:	f8de 4004 	ldr.w	r4, [lr, #4]
   e195e:	686d      	ldr	r5, [r5, #4]
   e1960:	437c      	muls	r4, r7
   e1962:	42ac      	cmp	r4, r5
   e1964:	d1f0      	bne.n	e1948 <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2a>
   e1966:	2401      	movs	r4, #1
   e1968:	2500      	movs	r5, #0
   e196a:	e9cd 4500 	strd	r4, r5, [sp]
   e196e:	46b2      	mov	sl, r6
   e1970:	f04f 0800 	mov.w	r8, #0
  int64_t outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e1974:	4598      	cmp	r8, r3
   e1976:	da14      	bge.n	e19a2 <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x84>
    outer_size *= input_dims->data[i];
   e1978:	f85a 9f04 	ldr.w	r9, [sl, #4]!
   e197c:	9900      	ldr	r1, [sp, #0]
   e197e:	464c      	mov	r4, r9
   e1980:	17e5      	asrs	r5, r4, #31
   e1982:	fb01 f405 	mul.w	r4, r1, r5
   e1986:	9901      	ldr	r1, [sp, #4]
   e1988:	fb09 4b01 	mla	fp, r9, r1, r4
   e198c:	9900      	ldr	r1, [sp, #0]
   e198e:	fba1 4509 	umull	r4, r5, r1, r9
   e1992:	e9cd 4500 	strd	r4, r5, [sp]
   e1996:	9901      	ldr	r1, [sp, #4]
   e1998:	4459      	add	r1, fp
   e199a:	9101      	str	r1, [sp, #4]

  int64_t split_size = output_dims->data[axis] * output_count;

  TFLITE_DCHECK_EQ(split_size, input_dims->data[axis]);
  int64_t outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e199c:	f108 0801 	add.w	r8, r8, #1
   e19a0:	e7e8      	b.n	e1974 <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x56>
   e19a2:	3301      	adds	r3, #1
   e19a4:	f10c 0c01 	add.w	ip, ip, #1
    outer_size *= input_dims->data[i];
  }

  int64_t base_inner_size = 1;
   e19a8:	2401      	movs	r4, #1
   e19aa:	2500      	movs	r5, #0
   e19ac:	3301      	adds	r3, #1
  for (int i = axis + 1; i < split_dimensions; ++i) {
   e19ae:	4563      	cmp	r3, ip
   e19b0:	d00b      	beq.n	e19ca <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xac>
    base_inner_size *= input_dims->data[i];
   e19b2:	f856 a023 	ldr.w	sl, [r6, r3, lsl #2]
   e19b6:	ea4f 79ea 	mov.w	r9, sl, asr #31
   e19ba:	fb04 f809 	mul.w	r8, r4, r9
   e19be:	fb0a 8805 	mla	r8, sl, r5, r8
   e19c2:	fba4 450a 	umull	r4, r5, r4, sl
   e19c6:	4445      	add	r5, r8
  for (int i = 0; i < axis; ++i) {
    outer_size *= input_dims->data[i];
  }

  int64_t base_inner_size = 1;
  for (int i = axis + 1; i < split_dimensions; ++i) {
   e19c8:	e7f0      	b.n	e19ac <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x8e>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e19ca:	6856      	ldr	r6, [r2, #4]
   e19cc:	f04f 0800 	mov.w	r8, #0
   e19d0:	f04f 0900 	mov.w	r9, #0
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
   e19d4:	e9dd 2300 	ldrd	r2, r3, [sp]
   e19d8:	4590      	cmp	r8, r2
   e19da:	eb79 0303 	sbcs.w	r3, r9, r3
   e19de:	f8cd 800c 	str.w	r8, [sp, #12]
   e19e2:	da27      	bge.n	e1a34 <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x116>
   e19e4:	f04f 0c00 	mov.w	ip, #0
    for (int i = 0; i < output_count; ++i) {
   e19e8:	45bc      	cmp	ip, r7
   e19ea:	da1e      	bge.n	e1a2a <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x10c>
      TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
   e19ec:	9b02      	ldr	r3, [sp, #8]
   e19ee:	685b      	ldr	r3, [r3, #4]
   e19f0:	eb03 038c 	add.w	r3, r3, ip, lsl #2
   e19f4:	2138      	movs	r1, #56	; 0x38
   e19f6:	685a      	ldr	r2, [r3, #4]
   e19f8:	6883      	ldr	r3, [r0, #8]
   e19fa:	fb01 3302 	mla	r3, r1, r2, r3

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e19fe:	b103      	cbz	r3, e1a02 <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xe4>
   e1a00:	685b      	ldr	r3, [r3, #4]
      T* output_data = GetTensorData<T>(t);
      const int copy_size = output_dims->data[axis] * base_inner_size;
   e1a02:	f8de 2004 	ldr.w	r2, [lr, #4]
   e1a06:	9903      	ldr	r1, [sp, #12]
   e1a08:	4362      	muls	r2, r4
   e1a0a:	fb02 3301 	mla	r3, r2, r1, r3
      T* output_ptr = output_data + k * copy_size;
   e1a0e:	46b2      	mov	sl, r6
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   e1a10:	ebc6 0b0a 	rsb	fp, r6, sl
   e1a14:	4593      	cmp	fp, r2
   e1a16:	da04      	bge.n	e1a22 <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x104>
   e1a18:	f81a bb01 	ldrb.w	fp, [sl], #1
   e1a1c:	f803 bb01 	strb.w	fp, [r3], #1
   e1a20:	e7f6      	b.n	e1a10 <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xf2>
      input_ptr += copy_size;
   e1a22:	4416      	add	r6, r2
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
    for (int i = 0; i < output_count; ++i) {
   e1a24:	f10c 0c01 	add.w	ip, ip, #1
   e1a28:	e7de      	b.n	e19e8 <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xca>
   e1a2a:	f118 0801 	adds.w	r8, r8, #1
   e1a2e:	f149 0900 	adc.w	r9, r9, #0
  for (int i = axis + 1; i < split_dimensions; ++i) {
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
   e1a32:	e7cf      	b.n	e19d4 <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xb6>
      input_ptr += copy_size;
    }
  }

  return kTfLiteOk;
}
   e1a34:	2000      	movs	r0, #0
   e1a36:	b005      	add	sp, #20
   e1a38:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000e1a3c <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori>:
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1a3c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e1a40:	684c      	ldr	r4, [r1, #4]
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
   e1a42:	6896      	ldr	r6, [r2, #8]
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1a44:	6865      	ldr	r5, [r4, #4]

  const int split_dimensions = input_dims->size;
   e1a46:	f8d6 c000 	ldr.w	ip, [r6]
   e1a4a:	6827      	ldr	r7, [r4, #0]
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1a4c:	6884      	ldr	r4, [r0, #8]

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;
   e1a4e:	2b00      	cmp	r3, #0
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1a50:	f04f 0e38 	mov.w	lr, #56	; 0x38
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1a54:	b085      	sub	sp, #20
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1a56:	fb0e 4405 	mla	r4, lr, r5, r4

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;
   e1a5a:	bfb8      	it	lt
   e1a5c:	4463      	addlt	r3, ip

  TFLITE_DCHECK_LT(axis, split_dimensions);
   e1a5e:	4563      	cmp	r3, ip
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1a60:	9102      	str	r1, [sp, #8]
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1a62:	68a4      	ldr	r4, [r4, #8]

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;

  TFLITE_DCHECK_LT(axis, split_dimensions);
   e1a64:	db01      	blt.n	e1a6a <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2e>
   e1a66:	f003 fd45 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(output_dims->size, split_dimensions);
   e1a6a:	6825      	ldr	r5, [r4, #0]
   e1a6c:	45ac      	cmp	ip, r5
   e1a6e:	d1fa      	bne.n	e1a66 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2a>
   e1a70:	009d      	lsls	r5, r3, #2
   e1a72:	eb04 0e05 	add.w	lr, r4, r5

  int64_t split_size = output_dims->data[axis] * output_count;

  TFLITE_DCHECK_EQ(split_size, input_dims->data[axis]);
   e1a76:	4435      	add	r5, r6
   e1a78:	f8de 4004 	ldr.w	r4, [lr, #4]
   e1a7c:	686d      	ldr	r5, [r5, #4]
   e1a7e:	437c      	muls	r4, r7
   e1a80:	42ac      	cmp	r4, r5
   e1a82:	d1f0      	bne.n	e1a66 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2a>
   e1a84:	2401      	movs	r4, #1
   e1a86:	2500      	movs	r5, #0
   e1a88:	e9cd 4500 	strd	r4, r5, [sp]
   e1a8c:	46b2      	mov	sl, r6
   e1a8e:	f04f 0800 	mov.w	r8, #0
  int64_t outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e1a92:	4598      	cmp	r8, r3
   e1a94:	da14      	bge.n	e1ac0 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x84>
    outer_size *= input_dims->data[i];
   e1a96:	f85a 9f04 	ldr.w	r9, [sl, #4]!
   e1a9a:	9900      	ldr	r1, [sp, #0]
   e1a9c:	464c      	mov	r4, r9
   e1a9e:	17e5      	asrs	r5, r4, #31
   e1aa0:	fb01 f405 	mul.w	r4, r1, r5
   e1aa4:	9901      	ldr	r1, [sp, #4]
   e1aa6:	fb09 4b01 	mla	fp, r9, r1, r4
   e1aaa:	9900      	ldr	r1, [sp, #0]
   e1aac:	fba1 4509 	umull	r4, r5, r1, r9
   e1ab0:	e9cd 4500 	strd	r4, r5, [sp]
   e1ab4:	9901      	ldr	r1, [sp, #4]
   e1ab6:	4459      	add	r1, fp
   e1ab8:	9101      	str	r1, [sp, #4]

  int64_t split_size = output_dims->data[axis] * output_count;

  TFLITE_DCHECK_EQ(split_size, input_dims->data[axis]);
  int64_t outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e1aba:	f108 0801 	add.w	r8, r8, #1
   e1abe:	e7e8      	b.n	e1a92 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x56>
   e1ac0:	3301      	adds	r3, #1
   e1ac2:	f10c 0c01 	add.w	ip, ip, #1
    outer_size *= input_dims->data[i];
  }

  int64_t base_inner_size = 1;
   e1ac6:	2401      	movs	r4, #1
   e1ac8:	2500      	movs	r5, #0
   e1aca:	3301      	adds	r3, #1
  for (int i = axis + 1; i < split_dimensions; ++i) {
   e1acc:	4563      	cmp	r3, ip
   e1ace:	d00b      	beq.n	e1ae8 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xac>
    base_inner_size *= input_dims->data[i];
   e1ad0:	f856 a023 	ldr.w	sl, [r6, r3, lsl #2]
   e1ad4:	ea4f 79ea 	mov.w	r9, sl, asr #31
   e1ad8:	fb04 f809 	mul.w	r8, r4, r9
   e1adc:	fb0a 8805 	mla	r8, sl, r5, r8
   e1ae0:	fba4 450a 	umull	r4, r5, r4, sl
   e1ae4:	4445      	add	r5, r8
  for (int i = 0; i < axis; ++i) {
    outer_size *= input_dims->data[i];
  }

  int64_t base_inner_size = 1;
  for (int i = axis + 1; i < split_dimensions; ++i) {
   e1ae6:	e7f0      	b.n	e1aca <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x8e>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e1ae8:	6856      	ldr	r6, [r2, #4]
   e1aea:	f04f 0800 	mov.w	r8, #0
   e1aee:	f04f 0900 	mov.w	r9, #0
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
   e1af2:	e9dd 2300 	ldrd	r2, r3, [sp]
   e1af6:	4590      	cmp	r8, r2
   e1af8:	eb79 0303 	sbcs.w	r3, r9, r3
   e1afc:	f8cd 800c 	str.w	r8, [sp, #12]
   e1b00:	da27      	bge.n	e1b52 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x116>
   e1b02:	f04f 0c00 	mov.w	ip, #0
    for (int i = 0; i < output_count; ++i) {
   e1b06:	45bc      	cmp	ip, r7
   e1b08:	da1e      	bge.n	e1b48 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x10c>
      TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
   e1b0a:	9b02      	ldr	r3, [sp, #8]
   e1b0c:	685b      	ldr	r3, [r3, #4]
   e1b0e:	eb03 038c 	add.w	r3, r3, ip, lsl #2
   e1b12:	2138      	movs	r1, #56	; 0x38
   e1b14:	685a      	ldr	r2, [r3, #4]
   e1b16:	6883      	ldr	r3, [r0, #8]
   e1b18:	fb01 3302 	mla	r3, r1, r2, r3

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e1b1c:	b103      	cbz	r3, e1b20 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xe4>
   e1b1e:	685b      	ldr	r3, [r3, #4]
      T* output_data = GetTensorData<T>(t);
      const int copy_size = output_dims->data[axis] * base_inner_size;
   e1b20:	f8de 2004 	ldr.w	r2, [lr, #4]
   e1b24:	9903      	ldr	r1, [sp, #12]
   e1b26:	4362      	muls	r2, r4
   e1b28:	fb02 3301 	mla	r3, r2, r1, r3
      T* output_ptr = output_data + k * copy_size;
   e1b2c:	46b2      	mov	sl, r6
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   e1b2e:	ebc6 0b0a 	rsb	fp, r6, sl
   e1b32:	4593      	cmp	fp, r2
   e1b34:	da04      	bge.n	e1b40 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x104>
   e1b36:	f91a bb01 	ldrsb.w	fp, [sl], #1
   e1b3a:	f803 bb01 	strb.w	fp, [r3], #1
   e1b3e:	e7f6      	b.n	e1b2e <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xf2>
      input_ptr += copy_size;
   e1b40:	4416      	add	r6, r2
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
    for (int i = 0; i < output_count; ++i) {
   e1b42:	f10c 0c01 	add.w	ip, ip, #1
   e1b46:	e7de      	b.n	e1b06 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xca>
   e1b48:	f118 0801 	adds.w	r8, r8, #1
   e1b4c:	f149 0900 	adc.w	r9, r9, #0
  for (int i = axis + 1; i < split_dimensions; ++i) {
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
   e1b50:	e7cf      	b.n	e1af2 <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xb6>
      input_ptr += copy_size;
    }
  }

  return kTfLiteOk;
}
   e1b52:	2000      	movs	r0, #0
   e1b54:	b005      	add	sp, #20
   e1b56:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000e1b5a <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori>:
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1b5a:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e1b5e:	684c      	ldr	r4, [r1, #4]
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
   e1b60:	6896      	ldr	r6, [r2, #8]
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1b62:	6865      	ldr	r5, [r4, #4]

  const int split_dimensions = input_dims->size;
   e1b64:	f8d6 c000 	ldr.w	ip, [r6]
   e1b68:	6827      	ldr	r7, [r4, #0]
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1b6a:	6884      	ldr	r4, [r0, #8]

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;
   e1b6c:	2b00      	cmp	r3, #0
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1b6e:	f04f 0e38 	mov.w	lr, #56	; 0x38
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1b72:	b085      	sub	sp, #20
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1b74:	fb0e 4405 	mla	r4, lr, r5, r4

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;
   e1b78:	bfb8      	it	lt
   e1b7a:	4463      	addlt	r3, ip

  TFLITE_DCHECK_LT(axis, split_dimensions);
   e1b7c:	4563      	cmp	r3, ip
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1b7e:	9102      	str	r1, [sp, #8]
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1b80:	68a4      	ldr	r4, [r4, #8]

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;

  TFLITE_DCHECK_LT(axis, split_dimensions);
   e1b82:	db01      	blt.n	e1b88 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2e>
   e1b84:	f003 fcb6 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(output_dims->size, split_dimensions);
   e1b88:	6825      	ldr	r5, [r4, #0]
   e1b8a:	45ac      	cmp	ip, r5
   e1b8c:	d1fa      	bne.n	e1b84 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2a>
   e1b8e:	009d      	lsls	r5, r3, #2
   e1b90:	eb04 0e05 	add.w	lr, r4, r5

  int64_t split_size = output_dims->data[axis] * output_count;

  TFLITE_DCHECK_EQ(split_size, input_dims->data[axis]);
   e1b94:	4435      	add	r5, r6
   e1b96:	f8de 4004 	ldr.w	r4, [lr, #4]
   e1b9a:	686d      	ldr	r5, [r5, #4]
   e1b9c:	437c      	muls	r4, r7
   e1b9e:	42ac      	cmp	r4, r5
   e1ba0:	d1f0      	bne.n	e1b84 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2a>
   e1ba2:	2401      	movs	r4, #1
   e1ba4:	2500      	movs	r5, #0
   e1ba6:	e9cd 4500 	strd	r4, r5, [sp]
   e1baa:	46b2      	mov	sl, r6
   e1bac:	f04f 0800 	mov.w	r8, #0
  int64_t outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e1bb0:	4598      	cmp	r8, r3
   e1bb2:	da14      	bge.n	e1bde <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x84>
    outer_size *= input_dims->data[i];
   e1bb4:	f85a 9f04 	ldr.w	r9, [sl, #4]!
   e1bb8:	9900      	ldr	r1, [sp, #0]
   e1bba:	464c      	mov	r4, r9
   e1bbc:	17e5      	asrs	r5, r4, #31
   e1bbe:	fb01 f405 	mul.w	r4, r1, r5
   e1bc2:	9901      	ldr	r1, [sp, #4]
   e1bc4:	fb09 4b01 	mla	fp, r9, r1, r4
   e1bc8:	9900      	ldr	r1, [sp, #0]
   e1bca:	fba1 4509 	umull	r4, r5, r1, r9
   e1bce:	e9cd 4500 	strd	r4, r5, [sp]
   e1bd2:	9901      	ldr	r1, [sp, #4]
   e1bd4:	4459      	add	r1, fp
   e1bd6:	9101      	str	r1, [sp, #4]

  int64_t split_size = output_dims->data[axis] * output_count;

  TFLITE_DCHECK_EQ(split_size, input_dims->data[axis]);
  int64_t outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e1bd8:	f108 0801 	add.w	r8, r8, #1
   e1bdc:	e7e8      	b.n	e1bb0 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x56>
   e1bde:	3301      	adds	r3, #1
   e1be0:	f10c 0c01 	add.w	ip, ip, #1
    outer_size *= input_dims->data[i];
  }

  int64_t base_inner_size = 1;
   e1be4:	2401      	movs	r4, #1
   e1be6:	2500      	movs	r5, #0
   e1be8:	3301      	adds	r3, #1
  for (int i = axis + 1; i < split_dimensions; ++i) {
   e1bea:	4563      	cmp	r3, ip
   e1bec:	d00b      	beq.n	e1c06 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xac>
    base_inner_size *= input_dims->data[i];
   e1bee:	f856 a023 	ldr.w	sl, [r6, r3, lsl #2]
   e1bf2:	ea4f 79ea 	mov.w	r9, sl, asr #31
   e1bf6:	fb04 f809 	mul.w	r8, r4, r9
   e1bfa:	fb0a 8805 	mla	r8, sl, r5, r8
   e1bfe:	fba4 450a 	umull	r4, r5, r4, sl
   e1c02:	4445      	add	r5, r8
  for (int i = 0; i < axis; ++i) {
    outer_size *= input_dims->data[i];
  }

  int64_t base_inner_size = 1;
  for (int i = axis + 1; i < split_dimensions; ++i) {
   e1c04:	e7f0      	b.n	e1be8 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x8e>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e1c06:	f8d2 c004 	ldr.w	ip, [r2, #4]
   e1c0a:	f04f 0800 	mov.w	r8, #0
   e1c0e:	f04f 0900 	mov.w	r9, #0
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
   e1c12:	e9dd 2300 	ldrd	r2, r3, [sp]
   e1c16:	4590      	cmp	r8, r2
   e1c18:	eb79 0303 	sbcs.w	r3, r9, r3
   e1c1c:	f8cd 800c 	str.w	r8, [sp, #12]
   e1c20:	da29      	bge.n	e1c76 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x11c>
   e1c22:	2600      	movs	r6, #0
    for (int i = 0; i < output_count; ++i) {
   e1c24:	42be      	cmp	r6, r7
   e1c26:	da21      	bge.n	e1c6c <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x112>
      TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
   e1c28:	9b02      	ldr	r3, [sp, #8]
   e1c2a:	685b      	ldr	r3, [r3, #4]
   e1c2c:	eb03 0386 	add.w	r3, r3, r6, lsl #2
   e1c30:	2138      	movs	r1, #56	; 0x38
   e1c32:	685a      	ldr	r2, [r3, #4]
   e1c34:	6883      	ldr	r3, [r0, #8]
   e1c36:	fb01 3302 	mla	r3, r1, r2, r3

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e1c3a:	b103      	cbz	r3, e1c3e <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xe4>
   e1c3c:	685b      	ldr	r3, [r3, #4]
      T* output_data = GetTensorData<T>(t);
      const int copy_size = output_dims->data[axis] * base_inner_size;
   e1c3e:	f8de 2004 	ldr.w	r2, [lr, #4]
      T* output_ptr = output_data + k * copy_size;
   e1c42:	9903      	ldr	r1, [sp, #12]
  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
    for (int i = 0; i < output_count; ++i) {
      TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
      T* output_data = GetTensorData<T>(t);
      const int copy_size = output_dims->data[axis] * base_inner_size;
   e1c44:	4362      	muls	r2, r4
      T* output_ptr = output_data + k * copy_size;
   e1c46:	fb02 fb01 	mul.w	fp, r2, r1
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   e1c4a:	f04f 0a00 	mov.w	sl, #0
   e1c4e:	eb03 034b 	add.w	r3, r3, fp, lsl #1
   e1c52:	4592      	cmp	sl, r2
   e1c54:	da06      	bge.n	e1c64 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x10a>
   e1c56:	f93c b01a 	ldrsh.w	fp, [ip, sl, lsl #1]
   e1c5a:	f823 b01a 	strh.w	fp, [r3, sl, lsl #1]
   e1c5e:	f10a 0a01 	add.w	sl, sl, #1
   e1c62:	e7f6      	b.n	e1c52 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xf8>
      input_ptr += copy_size;
   e1c64:	eb0c 0c42 	add.w	ip, ip, r2, lsl #1
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
    for (int i = 0; i < output_count; ++i) {
   e1c68:	3601      	adds	r6, #1
   e1c6a:	e7db      	b.n	e1c24 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xca>
   e1c6c:	f118 0801 	adds.w	r8, r8, #1
   e1c70:	f149 0900 	adc.w	r9, r9, #0
  for (int i = axis + 1; i < split_dimensions; ++i) {
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
   e1c74:	e7cd      	b.n	e1c12 <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xb8>
      input_ptr += copy_size;
    }
  }

  return kTfLiteOk;
}
   e1c76:	2000      	movs	r0, #0
   e1c78:	b005      	add	sp, #20
   e1c7a:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000e1c7e <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori>:
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1c7e:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e1c82:	684c      	ldr	r4, [r1, #4]
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
   e1c84:	6896      	ldr	r6, [r2, #8]
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1c86:	6865      	ldr	r5, [r4, #4]

  const int split_dimensions = input_dims->size;
   e1c88:	f8d6 c000 	ldr.w	ip, [r6]
   e1c8c:	6827      	ldr	r7, [r4, #0]
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1c8e:	6884      	ldr	r4, [r0, #8]

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;
   e1c90:	2b00      	cmp	r3, #0
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1c92:	f04f 0e38 	mov.w	lr, #56	; 0x38
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1c96:	b085      	sub	sp, #20
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1c98:	fb0e 4405 	mla	r4, lr, r5, r4

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;
   e1c9c:	bfb8      	it	lt
   e1c9e:	4463      	addlt	r3, ip

  TFLITE_DCHECK_LT(axis, split_dimensions);
   e1ca0:	4563      	cmp	r3, ip
TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}

template <typename T>
TfLiteStatus SplitImpl(TfLiteContext* context, TfLiteNode* node,
   e1ca2:	9102      	str	r1, [sp, #8]
                       const TfLiteTensor* input, int axis_value) {
  const int output_count = NumOutputs(node);
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* output_dims = output0->dims;
   e1ca4:	68a4      	ldr	r4, [r4, #8]

  const int split_dimensions = input_dims->size;
  int axis = axis_value < 0 ? axis_value + split_dimensions : axis_value;

  TFLITE_DCHECK_LT(axis, split_dimensions);
   e1ca6:	db01      	blt.n	e1cac <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2e>
   e1ca8:	f003 fc24 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(output_dims->size, split_dimensions);
   e1cac:	6825      	ldr	r5, [r4, #0]
   e1cae:	45ac      	cmp	ip, r5
   e1cb0:	d1fa      	bne.n	e1ca8 <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2a>
   e1cb2:	009d      	lsls	r5, r3, #2
   e1cb4:	eb04 0e05 	add.w	lr, r4, r5

  int64_t split_size = output_dims->data[axis] * output_count;

  TFLITE_DCHECK_EQ(split_size, input_dims->data[axis]);
   e1cb8:	4435      	add	r5, r6
   e1cba:	f8de 4004 	ldr.w	r4, [lr, #4]
   e1cbe:	686d      	ldr	r5, [r5, #4]
   e1cc0:	437c      	muls	r4, r7
   e1cc2:	42ac      	cmp	r4, r5
   e1cc4:	d1f0      	bne.n	e1ca8 <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x2a>
   e1cc6:	2401      	movs	r4, #1
   e1cc8:	2500      	movs	r5, #0
   e1cca:	e9cd 4500 	strd	r4, r5, [sp]
   e1cce:	46b2      	mov	sl, r6
   e1cd0:	f04f 0800 	mov.w	r8, #0
  int64_t outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e1cd4:	4598      	cmp	r8, r3
   e1cd6:	da14      	bge.n	e1d02 <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x84>
    outer_size *= input_dims->data[i];
   e1cd8:	f85a 9f04 	ldr.w	r9, [sl, #4]!
   e1cdc:	9900      	ldr	r1, [sp, #0]
   e1cde:	464c      	mov	r4, r9
   e1ce0:	17e5      	asrs	r5, r4, #31
   e1ce2:	fb01 f405 	mul.w	r4, r1, r5
   e1ce6:	9901      	ldr	r1, [sp, #4]
   e1ce8:	fb09 4b01 	mla	fp, r9, r1, r4
   e1cec:	9900      	ldr	r1, [sp, #0]
   e1cee:	fba1 4509 	umull	r4, r5, r1, r9
   e1cf2:	e9cd 4500 	strd	r4, r5, [sp]
   e1cf6:	9901      	ldr	r1, [sp, #4]
   e1cf8:	4459      	add	r1, fp
   e1cfa:	9101      	str	r1, [sp, #4]

  int64_t split_size = output_dims->data[axis] * output_count;

  TFLITE_DCHECK_EQ(split_size, input_dims->data[axis]);
  int64_t outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e1cfc:	f108 0801 	add.w	r8, r8, #1
   e1d00:	e7e8      	b.n	e1cd4 <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x56>
   e1d02:	3301      	adds	r3, #1
   e1d04:	f10c 0c01 	add.w	ip, ip, #1
    outer_size *= input_dims->data[i];
  }

  int64_t base_inner_size = 1;
   e1d08:	2401      	movs	r4, #1
   e1d0a:	2500      	movs	r5, #0
   e1d0c:	3301      	adds	r3, #1
  for (int i = axis + 1; i < split_dimensions; ++i) {
   e1d0e:	4563      	cmp	r3, ip
   e1d10:	d00b      	beq.n	e1d2a <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xac>
    base_inner_size *= input_dims->data[i];
   e1d12:	f856 a023 	ldr.w	sl, [r6, r3, lsl #2]
   e1d16:	ea4f 79ea 	mov.w	r9, sl, asr #31
   e1d1a:	fb04 f809 	mul.w	r8, r4, r9
   e1d1e:	fb0a 8805 	mla	r8, sl, r5, r8
   e1d22:	fba4 450a 	umull	r4, r5, r4, sl
   e1d26:	4445      	add	r5, r8
  for (int i = 0; i < axis; ++i) {
    outer_size *= input_dims->data[i];
  }

  int64_t base_inner_size = 1;
  for (int i = axis + 1; i < split_dimensions; ++i) {
   e1d28:	e7f0      	b.n	e1d0c <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x8e>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e1d2a:	f8d2 c004 	ldr.w	ip, [r2, #4]
   e1d2e:	f04f 0800 	mov.w	r8, #0
   e1d32:	f04f 0900 	mov.w	r9, #0
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
   e1d36:	e9dd 2300 	ldrd	r2, r3, [sp]
   e1d3a:	4590      	cmp	r8, r2
   e1d3c:	eb79 0303 	sbcs.w	r3, r9, r3
   e1d40:	f8cd 800c 	str.w	r8, [sp, #12]
   e1d44:	da29      	bge.n	e1d9a <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x11c>
   e1d46:	2600      	movs	r6, #0
    for (int i = 0; i < output_count; ++i) {
   e1d48:	42be      	cmp	r6, r7
   e1d4a:	da21      	bge.n	e1d90 <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x112>
      TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
   e1d4c:	9b02      	ldr	r3, [sp, #8]
   e1d4e:	685b      	ldr	r3, [r3, #4]
   e1d50:	eb03 0386 	add.w	r3, r3, r6, lsl #2
   e1d54:	2138      	movs	r1, #56	; 0x38
   e1d56:	685a      	ldr	r2, [r3, #4]
   e1d58:	6883      	ldr	r3, [r0, #8]
   e1d5a:	fb01 3302 	mla	r3, r1, r2, r3

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e1d5e:	b103      	cbz	r3, e1d62 <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xe4>
   e1d60:	685b      	ldr	r3, [r3, #4]
      T* output_data = GetTensorData<T>(t);
      const int copy_size = output_dims->data[axis] * base_inner_size;
   e1d62:	f8de 2004 	ldr.w	r2, [lr, #4]
      T* output_ptr = output_data + k * copy_size;
   e1d66:	9903      	ldr	r1, [sp, #12]
  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
    for (int i = 0; i < output_count; ++i) {
      TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
      T* output_data = GetTensorData<T>(t);
      const int copy_size = output_dims->data[axis] * base_inner_size;
   e1d68:	4362      	muls	r2, r4
      T* output_ptr = output_data + k * copy_size;
   e1d6a:	fb02 fb01 	mul.w	fp, r2, r1
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   e1d6e:	f04f 0a00 	mov.w	sl, #0
   e1d72:	eb03 038b 	add.w	r3, r3, fp, lsl #2
   e1d76:	4592      	cmp	sl, r2
   e1d78:	da06      	bge.n	e1d88 <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0x10a>
   e1d7a:	f85c 102a 	ldr.w	r1, [ip, sl, lsl #2]
   e1d7e:	f843 102a 	str.w	r1, [r3, sl, lsl #2]
   e1d82:	f10a 0a01 	add.w	sl, sl, #1
   e1d86:	e7f6      	b.n	e1d76 <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xf8>
      input_ptr += copy_size;
   e1d88:	eb0c 0c82 	add.w	ip, ip, r2, lsl #2
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
    for (int i = 0; i < output_count; ++i) {
   e1d8c:	3601      	adds	r6, #1
   e1d8e:	e7db      	b.n	e1d48 <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xca>
   e1d90:	f118 0801 	adds.w	r8, r8, #1
   e1d94:	f149 0900 	adc.w	r9, r9, #0
  for (int i = axis + 1; i < split_dimensions; ++i) {
    base_inner_size *= input_dims->data[i];
  }

  const T* input_ptr = GetTensorData<T>(input);
  for (int k = 0; k < outer_size; ++k) {
   e1d98:	e7cd      	b.n	e1d36 <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori+0xb8>
      input_ptr += copy_size;
    }
  }

  return kTfLiteOk;
}
   e1d9a:	2000      	movs	r0, #0
   e1d9c:	b005      	add	sp, #20
   e1d9e:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	...

000e1da4 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e1da4:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
   e1da8:	680a      	ldr	r2, [r1, #0]
   e1daa:	f8d0 e008 	ldr.w	lr, [r0, #8]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e1dae:	6857      	ldr	r7, [r2, #4]
   e1db0:	2338      	movs	r3, #56	; 0x38
   e1db2:	fb03 e707 	mla	r7, r3, r7, lr
   e1db6:	4605      	mov	r5, r0
  const TfLiteTensor* input = GetInput(context, node, 1);

  // Dynamic output tensors are needed if axis tensor is not constant.
  // But Micro doesn't support dynamic memeory allocation, so we only support
  // constant axis tensor for now.
  TF_LITE_ENSURE_MSG(context, IsConstantTensor(axis),
   e1db8:	f897 8014 	ldrb.w	r8, [r7, #20]
   e1dbc:	f1b8 0f01 	cmp.w	r8, #1
   e1dc0:	d003      	beq.n	e1dca <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0x26>
   e1dc2:	6943      	ldr	r3, [r0, #20]
   e1dc4:	4926      	ldr	r1, [pc, #152]	; (e1e60 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xbc>)
   e1dc6:	4798      	blx	r3
   e1dc8:	e046      	b.n	e1e58 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xb4>
   e1dca:	6896      	ldr	r6, [r2, #8]
   e1dcc:	435e      	muls	r6, r3
                     "Non constant axis tensor not supported");

  int axis_value = GetTensorData<int32_t>(axis)[0];
   e1dce:	687b      	ldr	r3, [r7, #4]
   e1dd0:	681b      	ldr	r3, [r3, #0]
   e1dd2:	eb0e 0206 	add.w	r2, lr, r6
  if (axis_value < 0) {
   e1dd6:	2b00      	cmp	r3, #0
   e1dd8:	6897      	ldr	r7, [r2, #8]
   e1dda:	da0a      	bge.n	e1df2 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0x4e>
    axis_value += NumDimensions(input);
  }

  TF_LITE_ENSURE(context, axis_value >= 0);
   e1ddc:	683c      	ldr	r4, [r7, #0]
   e1dde:	191b      	adds	r3, r3, r4
   e1de0:	d507      	bpl.n	e1df2 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0x4e>
   e1de2:	4b20      	ldr	r3, [pc, #128]	; (e1e64 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xc0>)
   e1de4:	9300      	str	r3, [sp, #0]
   e1de6:	6945      	ldr	r5, [r0, #20]
   e1de8:	4a1f      	ldr	r2, [pc, #124]	; (e1e68 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xc4>)
   e1dea:	4920      	ldr	r1, [pc, #128]	; (e1e6c <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xc8>)
   e1dec:	2357      	movs	r3, #87	; 0x57
   e1dee:	47a8      	blx	r5
   e1df0:	e032      	b.n	e1e58 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xb4>
  TF_LITE_ENSURE(context, axis_value < NumDimensions(input));
   e1df2:	6838      	ldr	r0, [r7, #0]
   e1df4:	4283      	cmp	r3, r0
   e1df6:	db08      	blt.n	e1e0a <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0x66>
   e1df8:	4b1d      	ldr	r3, [pc, #116]	; (e1e70 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xcc>)
   e1dfa:	9300      	str	r3, [sp, #0]
   e1dfc:	696c      	ldr	r4, [r5, #20]
   e1dfe:	4a1a      	ldr	r2, [pc, #104]	; (e1e68 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xc4>)
   e1e00:	491a      	ldr	r1, [pc, #104]	; (e1e6c <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xc8>)
   e1e02:	2358      	movs	r3, #88	; 0x58
   e1e04:	4628      	mov	r0, r5
   e1e06:	47a0      	blx	r4
   e1e08:	e026      	b.n	e1e58 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xb4>

  switch (input->type) {
   e1e0a:	f81e 0006 	ldrb.w	r0, [lr, r6]
   e1e0e:	1e44      	subs	r4, r0, #1
   e1e10:	2c08      	cmp	r4, #8
   e1e12:	d81a      	bhi.n	e1e4a <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xa6>
   e1e14:	e8df f004 	tbb	[pc, r4]
   e1e18:	19091505 	.word	0x19091505
   e1e1c:	19111919 	.word	0x19111919
   e1e20:	0d          	.byte	0x0d
   e1e21:	00          	.byte	0x00
    case kTfLiteFloat32: {
      return SplitImpl<float>(context, node, input, axis_value);
   e1e22:	4628      	mov	r0, r5
   e1e24:	f7ff fce8 	bl	e17f8 <_ZN6tflite3ops5micro5split9SplitImplIfEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori>
   e1e28:	e017      	b.n	e1e5a <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xb6>
    }
    case kTfLiteUInt8: {
      return SplitImpl<uint8_t>(context, node, input, axis_value);
   e1e2a:	4628      	mov	r0, r5
   e1e2c:	f7ff fd77 	bl	e191e <_ZN6tflite3ops5micro5split9SplitImplIhEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori>
   e1e30:	e013      	b.n	e1e5a <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xb6>
    }
    case kTfLiteInt8: {
      return SplitImpl<int8_t>(context, node, input, axis_value);
   e1e32:	4628      	mov	r0, r5
   e1e34:	f7ff fe02 	bl	e1a3c <_ZN6tflite3ops5micro5split9SplitImplIaEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori>
   e1e38:	e00f      	b.n	e1e5a <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xb6>
    }
    case kTfLiteInt16: {
      return SplitImpl<int16_t>(context, node, input, axis_value);
   e1e3a:	4628      	mov	r0, r5
   e1e3c:	f7ff fe8d 	bl	e1b5a <_ZN6tflite3ops5micro5split9SplitImplIsEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori>
   e1e40:	e00b      	b.n	e1e5a <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xb6>
    }
    case kTfLiteInt32: {
      return SplitImpl<int32_t>(context, node, input, axis_value);
   e1e42:	4628      	mov	r0, r5
   e1e44:	f7ff ff1b 	bl	e1c7e <_ZN6tflite3ops5micro5split9SplitImplIlEE12TfLiteStatusP13TfLiteContextP10TfLiteNodePK12TfLiteTensori>
   e1e48:	e007      	b.n	e1e5a <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xb6>
    }
    default:
      context->ReportError(context, "Type %s currently not supported.",
   e1e4a:	696c      	ldr	r4, [r5, #20]
   e1e4c:	f7f2 f96e 	bl	d412c <TfLiteTypeGetName>
                           TfLiteTypeGetName(input->type));
   e1e50:	4908      	ldr	r1, [pc, #32]	; (e1e74 <_ZN6tflite3ops5micro5split4EvalEP13TfLiteContextP10TfLiteNode+0xd0>)
   e1e52:	4602      	mov	r2, r0
   e1e54:	4628      	mov	r0, r5
   e1e56:	47a0      	blx	r4
      return kTfLiteError;
   e1e58:	2001      	movs	r0, #1
  }
#undef TF_LITE_SPLIT

  return kTfLiteOk;
}
   e1e5a:	b002      	add	sp, #8
   e1e5c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   e1e60:	000ec053 	.word	0x000ec053
   e1e64:	000ec1d2 	.word	0x000ec1d2
   e1e68:	000ec126 	.word	0x000ec126
   e1e6c:	000eb58e 	.word	0x000eb58e
   e1e70:	000ec1e2 	.word	0x000ec1e2
   e1e74:	000ec204 	.word	0x000ec204

000e1e78 <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi>:
}

inline void StridedSlicePadIndices(tflite::StridedSliceParams* p,
                                   int dim_count) {
  // Add indices and mask bits to fully include extra dimensions
  TFLITE_CHECK_LE(dim_count, 4);
   e1e78:	2904      	cmp	r1, #4
  if (v < lo) return lo;
  return v;
}

inline void StridedSlicePadIndices(tflite::StridedSliceParams* p,
                                   int dim_count) {
   e1e7a:	b570      	push	{r4, r5, r6, lr}
  // Add indices and mask bits to fully include extra dimensions
  TFLITE_CHECK_LE(dim_count, 4);
   e1e7c:	dd01      	ble.n	e1e82 <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi+0xa>
   e1e7e:	f003 fb39 	bl	e54f4 <abort>
  TFLITE_CHECK_GE(dim_count, p->start_indices_count);
   e1e82:	f990 3000 	ldrsb.w	r3, [r0]
   e1e86:	428b      	cmp	r3, r1
   e1e88:	dcf9      	bgt.n	e1e7e <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi+0x6>
  TFLITE_CHECK_EQ(p->start_indices_count, p->stop_indices_count);
   e1e8a:	f990 200a 	ldrsb.w	r2, [r0, #10]
   e1e8e:	429a      	cmp	r2, r3
   e1e90:	d1f5      	bne.n	e1e7e <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi+0x6>
  TFLITE_CHECK_EQ(p->stop_indices_count, p->strides_count);
   e1e92:	f990 3014 	ldrsb.w	r3, [r0, #20]
   e1e96:	4293      	cmp	r3, r2
   e1e98:	d1f1      	bne.n	e1e7e <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi+0x6>

  const int pad_count = dim_count - p->start_indices_count;

  // Pad indices at start, so move arrays by pad_count.
  for (int i = p->start_indices_count - 1; i >= 0; --i) {
   e1e9a:	1e5d      	subs	r5, r3, #1
   e1e9c:	eb00 0443 	add.w	r4, r0, r3, lsl #1
   e1ea0:	eb00 0241 	add.w	r2, r0, r1, lsl #1
   e1ea4:	1acb      	subs	r3, r1, r3
   e1ea6:	2d00      	cmp	r5, #0
   e1ea8:	db0c      	blt.n	e1ec4 <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi+0x4c>
    p->strides[i + pad_count] = p->strides[i];
   e1eaa:	f9b4 6014 	ldrsh.w	r6, [r4, #20]
   e1eae:	8296      	strh	r6, [r2, #20]
    p->start_indices[i + pad_count] = p->start_indices[i];
   e1eb0:	f9b4 6000 	ldrsh.w	r6, [r4]
   e1eb4:	8016      	strh	r6, [r2, #0]
    p->stop_indices[i + pad_count] = p->stop_indices[i];
   e1eb6:	f9b4 600a 	ldrsh.w	r6, [r4, #10]
   e1eba:	8156      	strh	r6, [r2, #10]
  TFLITE_CHECK_EQ(p->stop_indices_count, p->strides_count);

  const int pad_count = dim_count - p->start_indices_count;

  // Pad indices at start, so move arrays by pad_count.
  for (int i = p->start_indices_count - 1; i >= 0; --i) {
   e1ebc:	3d01      	subs	r5, #1
   e1ebe:	3c02      	subs	r4, #2
   e1ec0:	3a02      	subs	r2, #2
   e1ec2:	e7f0      	b.n	e1ea6 <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi+0x2e>
   e1ec4:	2400      	movs	r4, #0
   e1ec6:	4602      	mov	r2, r0
    p->strides[i + pad_count] = p->strides[i];
    p->start_indices[i + pad_count] = p->start_indices[i];
    p->stop_indices[i + pad_count] = p->stop_indices[i];
  }
  for (int i = 0; i < pad_count; ++i) {
    p->start_indices[i] = 0;
   e1ec8:	4626      	mov	r6, r4
    p->stop_indices[i] = 1;
   e1eca:	2501      	movs	r5, #1
  for (int i = p->start_indices_count - 1; i >= 0; --i) {
    p->strides[i + pad_count] = p->strides[i];
    p->start_indices[i + pad_count] = p->start_indices[i];
    p->stop_indices[i + pad_count] = p->stop_indices[i];
  }
  for (int i = 0; i < pad_count; ++i) {
   e1ecc:	429c      	cmp	r4, r3
   e1ece:	f102 0202 	add.w	r2, r2, #2
   e1ed2:	da04      	bge.n	e1ede <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi+0x66>
    p->start_indices[i] = 0;
   e1ed4:	8016      	strh	r6, [r2, #0]
    p->stop_indices[i] = 1;
   e1ed6:	8155      	strh	r5, [r2, #10]
    p->strides[i] = 1;
   e1ed8:	8295      	strh	r5, [r2, #20]
  for (int i = p->start_indices_count - 1; i >= 0; --i) {
    p->strides[i + pad_count] = p->strides[i];
    p->start_indices[i + pad_count] = p->start_indices[i];
    p->stop_indices[i + pad_count] = p->stop_indices[i];
  }
  for (int i = 0; i < pad_count; ++i) {
   e1eda:	3401      	adds	r4, #1
   e1edc:	e7f6      	b.n	e1ecc <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi+0x54>
    p->stop_indices[i] = 1;
    p->strides[i] = 1;
  }

  // Pad masks with 0s or 1s as required.
  p->shrink_axis_mask <<= pad_count;
   e1ede:	f9b0 2026 	ldrsh.w	r2, [r0, #38]	; 0x26
   e1ee2:	409a      	lsls	r2, r3
   e1ee4:	84c2      	strh	r2, [r0, #38]	; 0x26
  p->ellipsis_mask <<= pad_count;
   e1ee6:	f9b0 2020 	ldrsh.w	r2, [r0, #32]
   e1eea:	409a      	lsls	r2, r3
   e1eec:	8402      	strh	r2, [r0, #32]
  p->new_axis_mask <<= pad_count;
   e1eee:	f9b0 2024 	ldrsh.w	r2, [r0, #36]	; 0x24
  p->begin_mask <<= pad_count;
  p->end_mask <<= pad_count;
  p->begin_mask |= (1 << pad_count) - 1;
   e1ef2:	2401      	movs	r4, #1
  }

  // Pad masks with 0s or 1s as required.
  p->shrink_axis_mask <<= pad_count;
  p->ellipsis_mask <<= pad_count;
  p->new_axis_mask <<= pad_count;
   e1ef4:	409a      	lsls	r2, r3
  p->begin_mask <<= pad_count;
  p->end_mask <<= pad_count;
  p->begin_mask |= (1 << pad_count) - 1;
   e1ef6:	409c      	lsls	r4, r3
  }

  // Pad masks with 0s or 1s as required.
  p->shrink_axis_mask <<= pad_count;
  p->ellipsis_mask <<= pad_count;
  p->new_axis_mask <<= pad_count;
   e1ef8:	8482      	strh	r2, [r0, #36]	; 0x24
  p->begin_mask <<= pad_count;
  p->end_mask <<= pad_count;
   e1efa:	f9b0 2022 	ldrsh.w	r2, [r0, #34]	; 0x22
  p->begin_mask |= (1 << pad_count) - 1;
   e1efe:	3c01      	subs	r4, #1
  // Pad masks with 0s or 1s as required.
  p->shrink_axis_mask <<= pad_count;
  p->ellipsis_mask <<= pad_count;
  p->new_axis_mask <<= pad_count;
  p->begin_mask <<= pad_count;
  p->end_mask <<= pad_count;
   e1f00:	fa02 f503 	lsl.w	r5, r2, r3
  p->begin_mask |= (1 << pad_count) - 1;
   e1f04:	b222      	sxth	r2, r4
   e1f06:	f9b0 401e 	ldrsh.w	r4, [r0, #30]
   e1f0a:	fa04 f303 	lsl.w	r3, r4, r3
  p->end_mask |= (1 << pad_count) - 1;

  p->start_indices_count = dim_count;
   e1f0e:	b249      	sxtb	r1, r1
  p->shrink_axis_mask <<= pad_count;
  p->ellipsis_mask <<= pad_count;
  p->new_axis_mask <<= pad_count;
  p->begin_mask <<= pad_count;
  p->end_mask <<= pad_count;
  p->begin_mask |= (1 << pad_count) - 1;
   e1f10:	4313      	orrs	r3, r2
  p->end_mask |= (1 << pad_count) - 1;
   e1f12:	432a      	orrs	r2, r5
  p->shrink_axis_mask <<= pad_count;
  p->ellipsis_mask <<= pad_count;
  p->new_axis_mask <<= pad_count;
  p->begin_mask <<= pad_count;
  p->end_mask <<= pad_count;
  p->begin_mask |= (1 << pad_count) - 1;
   e1f14:	83c3      	strh	r3, [r0, #30]
  p->end_mask |= (1 << pad_count) - 1;
   e1f16:	8442      	strh	r2, [r0, #34]	; 0x22

  p->start_indices_count = dim_count;
   e1f18:	7001      	strb	r1, [r0, #0]
  p->stop_indices_count = dim_count;
   e1f1a:	7281      	strb	r1, [r0, #10]
  p->strides_count = dim_count;
   e1f1c:	7501      	strb	r1, [r0, #20]
   e1f1e:	bd70      	pop	{r4, r5, r6, pc}

000e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>:

// Return the index for the first element along that axis. This index will be a
// positive integer between [0, axis_size - 1] that can be used to index
// directly into the data.
inline int StartForAxis(const tflite::StridedSliceParams& params,
                        const RuntimeShape& input_shape, int axis) {
   e1f20:	b510      	push	{r4, lr}
   e1f22:	4603      	mov	r3, r0
   e1f24:	4608      	mov	r0, r1
  const auto begin_mask = params.begin_mask;
  const auto* start_indices = params.start_indices;
  const auto* strides = params.strides;
  // Begin with the specified index.
  int start = start_indices[axis];
   e1f26:	eb03 0142 	add.w	r1, r3, r2, lsl #1

  // begin_mask override
  if (begin_mask & 1 << axis) {
   e1f2a:	f9b3 301e 	ldrsh.w	r3, [r3, #30]
                        const RuntimeShape& input_shape, int axis) {
  const auto begin_mask = params.begin_mask;
  const auto* start_indices = params.start_indices;
  const auto* strides = params.strides;
  // Begin with the specified index.
  int start = start_indices[axis];
   e1f2e:	f9b1 4002 	ldrsh.w	r4, [r1, #2]

  // begin_mask override
  if (begin_mask & 1 << axis) {
   e1f32:	4113      	asrs	r3, r2
   e1f34:	07db      	lsls	r3, r3, #31
   e1f36:	d507      	bpl.n	e1f48 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi+0x28>
    if (strides[axis] > 0) {
   e1f38:	f9b1 3016 	ldrsh.w	r3, [r1, #22]
   e1f3c:	2b00      	cmp	r3, #0
      // clamped below (Note: We could have set them to 0 and axis_size-1, but
      // use lowest() and max() to maintain symmetry with StopForAxis())
      start = std::numeric_limits<int>::lowest();
    } else {
      // Backward iteration - use the last element.
      start = std::numeric_limits<int>::max();
   e1f3e:	bfcc      	ite	gt
   e1f40:	f04f 4400 	movgt.w	r4, #2147483648	; 0x80000000
   e1f44:	f06f 4400 	mvnle.w	r4, #2147483648	; 0x80000000
    }
  }

  // Handle negative indices
  int axis_size = input_shape.Dims(axis);
   e1f48:	4611      	mov	r1, r2
   e1f4a:	f7f5 fb19 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  if (start < 0) {
   e1f4e:	2c00      	cmp	r4, #0
    start += axis_size;
   e1f50:	bfb8      	it	lt
   e1f52:	1824      	addlt	r4, r4, r0
namespace tflite {
namespace strided_slice {

// Use until std::clamp() is available from C++17.
inline int Clamp(const int v, const int lo, const int hi) {
  TFLITE_DCHECK(!(hi < lo));
   e1f54:	3801      	subs	r0, #1
   e1f56:	d501      	bpl.n	e1f5c <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi+0x3c>
   e1f58:	f003 facc 	bl	e54f4 <abort>
  if (hi < v) return hi;
   e1f5c:	4284      	cmp	r4, r0
   e1f5e:	bfd8      	it	le
   e1f60:	ea24 70e4 	bicle.w	r0, r4, r4, asr #31

  // Clamping
  start = Clamp(start, 0, axis_size - 1);

  return start;
}
   e1f64:	bd10      	pop	{r4, pc}

000e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>:
// element. ie. So if you were iterating through all elements of a 1D array of
// size 4, this function would return 4 as the stop, because it is one past the
// "real" indices of 0, 1, 2 & 3.
inline int StopForAxis(const tflite::StridedSliceParams& params,
                       const RuntimeShape& input_shape, int axis,
                       int start_for_axis) {
   e1f66:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
   e1f68:	4615      	mov	r5, r2
   e1f6a:	460f      	mov	r7, r1
  const auto* stop_indices = params.stop_indices;
  const auto* strides = params.strides;

  // Begin with the specified index
  const bool shrink_axis = shrink_axis_mask & (1 << axis);
  int stop = stop_indices[axis];
   e1f6c:	eb00 0145 	add.w	r1, r0, r5, lsl #1
// size 4, this function would return 4 as the stop, because it is one past the
// "real" indices of 0, 1, 2 & 3.
inline int StopForAxis(const tflite::StridedSliceParams& params,
                       const RuntimeShape& input_shape, int axis,
                       int start_for_axis) {
  const auto end_mask = params.end_mask;
   e1f70:	f9b0 2022 	ldrsh.w	r2, [r0, #34]	; 0x22
  const auto* stop_indices = params.stop_indices;
  const auto* strides = params.strides;

  // Begin with the specified index
  const bool shrink_axis = shrink_axis_mask & (1 << axis);
  int stop = stop_indices[axis];
   e1f74:	f9b1 400c 	ldrsh.w	r4, [r1, #12]

  // When shrinking an axis, the end position does not matter (and can be
  // incorrect when negative indexing is used, see Issue #19260). Always use
  // start_for_axis + 1 to generate a length 1 slice, since start_for_axis has
  // already been adjusted for negative indices.
  if (shrink_axis) {
   e1f78:	f9b0 1026 	ldrsh.w	r1, [r0, #38]	; 0x26
   e1f7c:	4129      	asrs	r1, r5
   e1f7e:	07c9      	lsls	r1, r1, #31
    stop = start_for_axis + 1;
   e1f80:	bf48      	it	mi
   e1f82:	1c5c      	addmi	r4, r3, #1
  }

  // end_mask override
  if (end_mask & (1 << axis)) {
   e1f84:	fa42 f305 	asr.w	r3, r2, r5
   e1f88:	07da      	lsls	r2, r3, #31
                       const RuntimeShape& input_shape, int axis,
                       int start_for_axis) {
  const auto end_mask = params.end_mask;
  const auto shrink_axis_mask = params.shrink_axis_mask;
  const auto* stop_indices = params.stop_indices;
  const auto* strides = params.strides;
   e1f8a:	f100 0616 	add.w	r6, r0, #22
  if (shrink_axis) {
    stop = start_for_axis + 1;
  }

  // end_mask override
  if (end_mask & (1 << axis)) {
   e1f8e:	d507      	bpl.n	e1fa0 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii+0x3a>
    if (strides[axis] > 0) {
   e1f90:	f936 3015 	ldrsh.w	r3, [r6, r5, lsl #1]
      // Forward iteration - use the last element. These values will get
      // clamped below
      stop = std::numeric_limits<int>::max();
    } else {
      // Backward iteration - use the first element.
      stop = std::numeric_limits<int>::lowest();
   e1f94:	2b00      	cmp	r3, #0
   e1f96:	bfcc      	ite	gt
   e1f98:	f06f 4400 	mvngt.w	r4, #2147483648	; 0x80000000
   e1f9c:	f04f 4400 	movle.w	r4, #2147483648	; 0x80000000
    }
  }

  // Handle negative indices
  const int axis_size = input_shape.Dims(axis);
   e1fa0:	4629      	mov	r1, r5
   e1fa2:	4638      	mov	r0, r7
   e1fa4:	f7f5 faec 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  }

  // Clamping
  // Because the end index points one past the last element, we need slightly
  // different clamping ranges depending on the direction.
  if (strides[axis] > 0) {
   e1fa8:	f936 3015 	ldrsh.w	r3, [r6, r5, lsl #1]
    }
  }

  // Handle negative indices
  const int axis_size = input_shape.Dims(axis);
  if (stop < 0) {
   e1fac:	2c00      	cmp	r4, #0
    stop += axis_size;
   e1fae:	bfb8      	it	lt
   e1fb0:	1824      	addlt	r4, r4, r0
  }

  // Clamping
  // Because the end index points one past the last element, we need slightly
  // different clamping ranges depending on the direction.
  if (strides[axis] > 0) {
   e1fb2:	2b00      	cmp	r3, #0
   e1fb4:	dd08      	ble.n	e1fc8 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii+0x62>
namespace tflite {
namespace strided_slice {

// Use until std::clamp() is available from C++17.
inline int Clamp(const int v, const int lo, const int hi) {
  TFLITE_DCHECK(!(hi < lo));
   e1fb6:	2800      	cmp	r0, #0
   e1fb8:	da01      	bge.n	e1fbe <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii+0x58>
   e1fba:	f003 fa9b 	bl	e54f4 <abort>
  if (hi < v) return hi;
   e1fbe:	4284      	cmp	r4, r0
   e1fc0:	dc09      	bgt.n	e1fd6 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii+0x70>
   e1fc2:	ea24 70e4 	bic.w	r0, r4, r4, asr #31
   e1fc6:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
  if (strides[axis] > 0) {
    // Forward iteration
    stop = Clamp(stop, 0, axis_size);
  } else {
    // Backward iteration
    stop = Clamp(stop, -1, axis_size - 1);
   e1fc8:	3801      	subs	r0, #1
namespace tflite {
namespace strided_slice {

// Use until std::clamp() is available from C++17.
inline int Clamp(const int v, const int lo, const int hi) {
  TFLITE_DCHECK(!(hi < lo));
   e1fca:	1c43      	adds	r3, r0, #1
   e1fcc:	dbf5      	blt.n	e1fba <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii+0x54>
  if (hi < v) return hi;
   e1fce:	4284      	cmp	r4, r0
   e1fd0:	bfd8      	it	le
   e1fd2:	ea44 70e4 	orrle.w	r0, r4, r4, asr #31
    // Backward iteration
    stop = Clamp(stop, -1, axis_size - 1);
  }

  return stop;
}
   e1fd6:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

000e1fd8 <_ZN6tflite3ops5micro13strided_slice19StridedSliceContextC1EP13TfLiteContextP10TfLiteNode>:
constexpr int kEndTensor = 2;
constexpr int kStridesTensor = 3;
constexpr int kOutputTensor = 0;

struct StridedSliceContext {
  StridedSliceContext(TfLiteContext* context, TfLiteNode* node) {
   e1fd8:	b5f0      	push	{r4, r5, r6, r7, lr}
    params = reinterpret_cast<TfLiteStridedSliceParams*>(node->builtin_data);
   e1fda:	6954      	ldr	r4, [r2, #20]
   e1fdc:	6004      	str	r4, [r0, #0]
   e1fde:	6814      	ldr	r4, [r2, #0]
   e1fe0:	688d      	ldr	r5, [r1, #8]
   e1fe2:	6866      	ldr	r6, [r4, #4]
   e1fe4:	2438      	movs	r4, #56	; 0x38
   e1fe6:	fb04 5506 	mla	r5, r4, r6, r5
    input = GetInput(context, node, kInputTensor);
   e1fea:	6045      	str	r5, [r0, #4]
   e1fec:	6816      	ldr	r6, [r2, #0]
    begin = GetInput(context, node, kBeginTensor);
   e1fee:	688f      	ldr	r7, [r1, #8]
   e1ff0:	68b6      	ldr	r6, [r6, #8]
   e1ff2:	fb04 7606 	mla	r6, r4, r6, r7
   e1ff6:	6086      	str	r6, [r0, #8]
   e1ff8:	6816      	ldr	r6, [r2, #0]
    end = GetInput(context, node, kEndTensor);
   e1ffa:	688f      	ldr	r7, [r1, #8]
   e1ffc:	68f6      	ldr	r6, [r6, #12]
   e1ffe:	fb04 7606 	mla	r6, r4, r6, r7
   e2002:	60c6      	str	r6, [r0, #12]
   e2004:	6816      	ldr	r6, [r2, #0]
    strides = GetInput(context, node, kStridesTensor);
   e2006:	688f      	ldr	r7, [r1, #8]
   e2008:	6936      	ldr	r6, [r6, #16]
   e200a:	fb04 7606 	mla	r6, r4, r6, r7
   e200e:	6106      	str	r6, [r0, #16]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e2010:	6852      	ldr	r2, [r2, #4]
    output = GetOutput(context, node, kOutputTensor);
   e2012:	6889      	ldr	r1, [r1, #8]
   e2014:	6852      	ldr	r2, [r2, #4]
   e2016:	fb04 1402 	mla	r4, r4, r2, r1
   e201a:	6144      	str	r4, [r0, #20]
#include "tensorflow/lite/c/builtin_op_data.h"
#include "tensorflow/lite/c/c_api_internal.h"

namespace tflite {

inline int NumDimensions(const TfLiteTensor* t) { return t->dims->size; }
   e201c:	68aa      	ldr	r2, [r5, #8]
   e201e:	6812      	ldr	r2, [r2, #0]
    dims = NumDimensions(input);
   e2020:	6182      	str	r2, [r0, #24]
  }
   e2022:	bdf0      	pop	{r4, r5, r6, r7, pc}

000e2024 <_ZN6tflite3ops5micro13strided_slice23BuildStridedSliceParamsEPNS2_19StridedSliceContextE>:
// This Op only supports 1-4D cases and since we use the reference 4D
// implementation, the 1-3D tensors are mapped to 4D.
const int kMaxDim = 4;

tflite::StridedSliceParams BuildStridedSliceParams(
    StridedSliceContext* op_context) {
   e2024:	b570      	push	{r4, r5, r6, lr}
  tflite::StridedSliceParams op_params;
  op_params.start_indices_count = op_context->dims;
   e2026:	698e      	ldr	r6, [r1, #24]
  op_params.stop_indices_count = op_context->dims;
  op_params.strides_count = op_context->dims;
   e2028:	4603      	mov	r3, r0
const int kMaxDim = 4;

tflite::StridedSliceParams BuildStridedSliceParams(
    StridedSliceContext* op_context) {
  tflite::StridedSliceParams op_params;
  op_params.start_indices_count = op_context->dims;
   e202a:	b272      	sxtb	r2, r6
  op_params.stop_indices_count = op_context->dims;
  op_params.strides_count = op_context->dims;
   e202c:	f803 2f14 	strb.w	r2, [r3, #20]!
const int kMaxDim = 4;

tflite::StridedSliceParams BuildStridedSliceParams(
    StridedSliceContext* op_context) {
  tflite::StridedSliceParams op_params;
  op_params.start_indices_count = op_context->dims;
   e2030:	7002      	strb	r2, [r0, #0]
  op_params.stop_indices_count = op_context->dims;
   e2032:	7282      	strb	r2, [r0, #10]
  op_params.strides_count = op_context->dims;

  for (int i = 0; i < op_context->dims; ++i) {
   e2034:	2400      	movs	r4, #0
   e2036:	42b4      	cmp	r4, r6
   e2038:	da15      	bge.n	e2066 <_ZN6tflite3ops5micro13strided_slice23BuildStridedSliceParamsEPNS2_19StridedSliceContextE+0x42>
    op_params.start_indices[i] = GetTensorData<int32_t>(op_context->begin)[i];
   e203a:	688a      	ldr	r2, [r1, #8]
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e203c:	b102      	cbz	r2, e2040 <_ZN6tflite3ops5micro13strided_slice23BuildStridedSliceParamsEPNS2_19StridedSliceContextE+0x1c>
   e203e:	6852      	ldr	r2, [r2, #4]
   e2040:	f852 2024 	ldr.w	r2, [r2, r4, lsl #2]
   e2044:	f823 2c12 	strh.w	r2, [r3, #-18]
    op_params.stop_indices[i] = GetTensorData<int32_t>(op_context->end)[i];
   e2048:	68ca      	ldr	r2, [r1, #12]
   e204a:	00a5      	lsls	r5, r4, #2
   e204c:	b102      	cbz	r2, e2050 <_ZN6tflite3ops5micro13strided_slice23BuildStridedSliceParamsEPNS2_19StridedSliceContextE+0x2c>
   e204e:	6852      	ldr	r2, [r2, #4]
   e2050:	5952      	ldr	r2, [r2, r5]
   e2052:	f823 2c08 	strh.w	r2, [r3, #-8]
    op_params.strides[i] = GetTensorData<int32_t>(op_context->strides)[i];
   e2056:	690a      	ldr	r2, [r1, #16]
   e2058:	b102      	cbz	r2, e205c <_ZN6tflite3ops5micro13strided_slice23BuildStridedSliceParamsEPNS2_19StridedSliceContextE+0x38>
   e205a:	6852      	ldr	r2, [r2, #4]
   e205c:	5952      	ldr	r2, [r2, r5]
   e205e:	f823 2f02 	strh.w	r2, [r3, #2]!
  tflite::StridedSliceParams op_params;
  op_params.start_indices_count = op_context->dims;
  op_params.stop_indices_count = op_context->dims;
  op_params.strides_count = op_context->dims;

  for (int i = 0; i < op_context->dims; ++i) {
   e2062:	3401      	adds	r4, #1
   e2064:	e7e7      	b.n	e2036 <_ZN6tflite3ops5micro13strided_slice23BuildStridedSliceParamsEPNS2_19StridedSliceContextE+0x12>
    op_params.start_indices[i] = GetTensorData<int32_t>(op_context->begin)[i];
    op_params.stop_indices[i] = GetTensorData<int32_t>(op_context->end)[i];
    op_params.strides[i] = GetTensorData<int32_t>(op_context->strides)[i];
  }

  op_params.begin_mask = op_context->params->begin_mask;
   e2066:	680b      	ldr	r3, [r1, #0]
   e2068:	681a      	ldr	r2, [r3, #0]
  op_params.ellipsis_mask = 0;
  op_params.end_mask = op_context->params->end_mask;
   e206a:	6859      	ldr	r1, [r3, #4]
    op_params.start_indices[i] = GetTensorData<int32_t>(op_context->begin)[i];
    op_params.stop_indices[i] = GetTensorData<int32_t>(op_context->end)[i];
    op_params.strides[i] = GetTensorData<int32_t>(op_context->strides)[i];
  }

  op_params.begin_mask = op_context->params->begin_mask;
   e206c:	83c2      	strh	r2, [r0, #30]
  op_params.ellipsis_mask = 0;
  op_params.end_mask = op_context->params->end_mask;
  op_params.new_axis_mask = 0;
  op_params.shrink_axis_mask = op_context->params->shrink_axis_mask;
   e206e:	691b      	ldr	r3, [r3, #16]
    op_params.strides[i] = GetTensorData<int32_t>(op_context->strides)[i];
  }

  op_params.begin_mask = op_context->params->begin_mask;
  op_params.ellipsis_mask = 0;
  op_params.end_mask = op_context->params->end_mask;
   e2070:	8441      	strh	r1, [r0, #34]	; 0x22
    op_params.stop_indices[i] = GetTensorData<int32_t>(op_context->end)[i];
    op_params.strides[i] = GetTensorData<int32_t>(op_context->strides)[i];
  }

  op_params.begin_mask = op_context->params->begin_mask;
  op_params.ellipsis_mask = 0;
   e2072:	2200      	movs	r2, #0
   e2074:	8402      	strh	r2, [r0, #32]
  op_params.end_mask = op_context->params->end_mask;
  op_params.new_axis_mask = 0;
   e2076:	8482      	strh	r2, [r0, #36]	; 0x24
  op_params.shrink_axis_mask = op_context->params->shrink_axis_mask;
   e2078:	84c3      	strh	r3, [r0, #38]	; 0x26
  return op_params;
}
   e207a:	bd70      	pop	{r4, r5, r6, pc}

000e207c <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE>:

// Processes the indexing tensors (begin, end and strides) to resize the
// output tensor. This function is callable from both Prepare() and Eval() as
// long as the caller ensures the indexing tensors are present.
TfLiteStatus CheckOutputSize(TfLiteContext* context,
                             StridedSliceContext* op_context) {
   e207c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e2080:	ed2d 8b02 	vpush	{d8}
   e2084:	460f      	mov	r7, r1
   e2086:	b095      	sub	sp, #84	; 0x54
  using ::tflite::strided_slice::StartForAxis;
  using ::tflite::strided_slice::StopForAxis;
  TfLiteIntArray* output_shape = op_context->output->dims;
   e2088:	694b      	ldr	r3, [r1, #20]

// Processes the indexing tensors (begin, end and strides) to resize the
// output tensor. This function is callable from both Prepare() and Eval() as
// long as the caller ensures the indexing tensors are present.
TfLiteStatus CheckOutputSize(TfLiteContext* context,
                             StridedSliceContext* op_context) {
   e208a:	4605      	mov	r5, r0
  using ::tflite::strided_slice::StartForAxis;
  using ::tflite::strided_slice::StopForAxis;
  TfLiteIntArray* output_shape = op_context->output->dims;
  int shape_size = 0;
  auto op_params = BuildStridedSliceParams(op_context);
   e208c:	a80a      	add	r0, sp, #40	; 0x28
// long as the caller ensures the indexing tensors are present.
TfLiteStatus CheckOutputSize(TfLiteContext* context,
                             StridedSliceContext* op_context) {
  using ::tflite::strided_slice::StartForAxis;
  using ::tflite::strided_slice::StopForAxis;
  TfLiteIntArray* output_shape = op_context->output->dims;
   e208e:	f8d3 8008 	ldr.w	r8, [r3, #8]
  int shape_size = 0;
  auto op_params = BuildStridedSliceParams(op_context);
   e2092:	f7ff ffc7 	bl	e2024 <_ZN6tflite3ops5micro13strided_slice23BuildStridedSliceParamsEPNS2_19StridedSliceContextE>
  auto input_shape = GetTensorShape(op_context->input);
   e2096:	6879      	ldr	r1, [r7, #4]
   e2098:	a805      	add	r0, sp, #20
   e209a:	f7f5 fd16 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
TfLiteStatus CheckOutputSize(TfLiteContext* context,
                             StridedSliceContext* op_context) {
  using ::tflite::strided_slice::StartForAxis;
  using ::tflite::strided_slice::StopForAxis;
  TfLiteIntArray* output_shape = op_context->output->dims;
  int shape_size = 0;
   e209e:	2600      	movs	r6, #0
  auto op_params = BuildStridedSliceParams(op_context);
  auto input_shape = GetTensorShape(op_context->input);
  for (int idx = 0; idx < op_context->dims; ++idx) {
   e20a0:	f8d7 9018 	ldr.w	r9, [r7, #24]
   e20a4:	4634      	mov	r4, r6
   e20a6:	454c      	cmp	r4, r9
   e20a8:	da4b      	bge.n	e2142 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0xc6>
    int32_t stride = GetTensorData<int32_t>(op_context->strides)[idx];
   e20aa:	693b      	ldr	r3, [r7, #16]
   e20ac:	b103      	cbz	r3, e20b0 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0x34>
   e20ae:	685b      	ldr	r3, [r3, #4]
   e20b0:	f853 3024 	ldr.w	r3, [r3, r4, lsl #2]
   e20b4:	ee08 3a10 	vmov	s16, r3
    TF_LITE_ENSURE_MSG(context, stride != 0, "stride value has to be non-zero");
   e20b8:	b923      	cbnz	r3, e20c4 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0x48>
   e20ba:	696b      	ldr	r3, [r5, #20]
   e20bc:	492c      	ldr	r1, [pc, #176]	; (e2170 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0xf4>)
   e20be:	4628      	mov	r0, r5
   e20c0:	4798      	blx	r3
   e20c2:	e039      	b.n	e2138 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0xbc>
    int32_t begin = StartForAxis(op_params, input_shape, idx);
   e20c4:	4622      	mov	r2, r4
   e20c6:	a905      	add	r1, sp, #20
   e20c8:	a80a      	add	r0, sp, #40	; 0x28
   e20ca:	f7ff ff29 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
    int32_t end = StopForAxis(op_params, input_shape, idx, begin);
   e20ce:	4622      	mov	r2, r4
  auto op_params = BuildStridedSliceParams(op_context);
  auto input_shape = GetTensorShape(op_context->input);
  for (int idx = 0; idx < op_context->dims; ++idx) {
    int32_t stride = GetTensorData<int32_t>(op_context->strides)[idx];
    TF_LITE_ENSURE_MSG(context, stride != 0, "stride value has to be non-zero");
    int32_t begin = StartForAxis(op_params, input_shape, idx);
   e20d0:	4682      	mov	sl, r0
    int32_t end = StopForAxis(op_params, input_shape, idx, begin);
   e20d2:	4603      	mov	r3, r0
   e20d4:	a905      	add	r1, sp, #20
   e20d6:	a80a      	add	r0, sp, #40	; 0x28
   e20d8:	f7ff ff45 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>

    // When shrinking an axis, the end position does not matter (and can be
    // incorrect when negative indexing is used, see Issue #19260). Always use
    // begin + 1 to generate a length 1 slice, since begin has
    // already been adjusted for negative indices by StartForAxis.
    const bool shrink_axis = op_context->params->shrink_axis_mask & (1 << idx);
   e20dc:	683b      	ldr	r3, [r7, #0]
   e20de:	691a      	ldr	r2, [r3, #16]
   e20e0:	4122      	asrs	r2, r4
    if (shrink_axis) {
   e20e2:	f012 0b01 	ands.w	fp, r2, #1
      end = begin + 1;
   e20e6:	bf18      	it	ne
   e20e8:	f10a 0001 	addne.w	r0, sl, #1
  using ::ceil;

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  ceil(float __x)
  { return __builtin_ceilf(__x); }
   e20ec:	ebca 0000 	rsb	r0, sl, r0
   e20f0:	ee07 0a90 	vmov	s15, r0
   e20f4:	eeb8 0ac8 	vcvt.f32.s32	s0, s16
   e20f8:	eef8 7ae7 	vcvt.f32.s32	s15, s15
   e20fc:	ee87 0a80 	vdiv.f32	s0, s15, s0
   e2100:	f004 fac0 	bl	e6684 <ceilf>
    }

    // This is valid for both positive and negative strides
    int32_t dim_shape = std::ceil((end - begin) / static_cast<float>(stride));
    dim_shape = dim_shape < 0 ? 0 : dim_shape;
    if (!shrink_axis) {
   e2104:	f1bb 0f00 	cmp.w	fp, #0
   e2108:	d119      	bne.n	e213e <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0xc2>
      TF_LITE_ENSURE_EQ(context, output_shape->data[shape_size], dim_shape);
   e210a:	eb08 0286 	add.w	r2, r8, r6, lsl #2
   e210e:	6852      	ldr	r2, [r2, #4]
    if (shrink_axis) {
      end = begin + 1;
    }

    // This is valid for both positive and negative strides
    int32_t dim_shape = std::ceil((end - begin) / static_cast<float>(stride));
   e2110:	eebd 0ac0 	vcvt.s32.f32	s0, s0
    dim_shape = dim_shape < 0 ? 0 : dim_shape;
   e2114:	ee10 3a10 	vmov	r3, s0
   e2118:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
    if (!shrink_axis) {
      TF_LITE_ENSURE_EQ(context, output_shape->data[shape_size], dim_shape);
   e211c:	4293      	cmp	r3, r2
   e211e:	d00d      	beq.n	e213c <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0xc0>
   e2120:	9303      	str	r3, [sp, #12]
   e2122:	4b14      	ldr	r3, [pc, #80]	; (e2174 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0xf8>)
   e2124:	9301      	str	r3, [sp, #4]
   e2126:	696c      	ldr	r4, [r5, #20]
   e2128:	4b13      	ldr	r3, [pc, #76]	; (e2178 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0xfc>)
   e212a:	9300      	str	r3, [sp, #0]
   e212c:	9202      	str	r2, [sp, #8]
   e212e:	2373      	movs	r3, #115	; 0x73
   e2130:	4a12      	ldr	r2, [pc, #72]	; (e217c <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0x100>)
   e2132:	4913      	ldr	r1, [pc, #76]	; (e2180 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0x104>)
   e2134:	4628      	mov	r0, r5
   e2136:	47a0      	blx	r4
   e2138:	2401      	movs	r4, #1
   e213a:	e010      	b.n	e215e <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0xe2>
      shape_size++;
   e213c:	3601      	adds	r6, #1
  using ::tflite::strided_slice::StopForAxis;
  TfLiteIntArray* output_shape = op_context->output->dims;
  int shape_size = 0;
  auto op_params = BuildStridedSliceParams(op_context);
  auto input_shape = GetTensorShape(op_context->input);
  for (int idx = 0; idx < op_context->dims; ++idx) {
   e213e:	3401      	adds	r4, #1
   e2140:	e7b1      	b.n	e20a6 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0x2a>
    if (!shrink_axis) {
      TF_LITE_ENSURE_EQ(context, output_shape->data[shape_size], dim_shape);
      shape_size++;
    }
  }
  TF_LITE_ENSURE_EQ(context, output_shape->size, shape_size);
   e2142:	f8d8 3000 	ldr.w	r3, [r8]
   e2146:	42b3      	cmp	r3, r6
   e2148:	d008      	beq.n	e215c <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0xe0>
   e214a:	9302      	str	r3, [sp, #8]
   e214c:	4b0d      	ldr	r3, [pc, #52]	; (e2184 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0x108>)
   e214e:	9301      	str	r3, [sp, #4]
   e2150:	4b0d      	ldr	r3, [pc, #52]	; (e2188 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0x10c>)
   e2152:	9300      	str	r3, [sp, #0]
   e2154:	9603      	str	r6, [sp, #12]
   e2156:	696c      	ldr	r4, [r5, #20]
   e2158:	2377      	movs	r3, #119	; 0x77
   e215a:	e7e9      	b.n	e2130 <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE+0xb4>
  return kTfLiteOk;
   e215c:	2400      	movs	r4, #0
  using ::tflite::strided_slice::StartForAxis;
  using ::tflite::strided_slice::StopForAxis;
  TfLiteIntArray* output_shape = op_context->output->dims;
  int shape_size = 0;
  auto op_params = BuildStridedSliceParams(op_context);
  auto input_shape = GetTensorShape(op_context->input);
   e215e:	a805      	add	r0, sp, #20
   e2160:	f7f5 fa03 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      shape_size++;
    }
  }
  TF_LITE_ENSURE_EQ(context, output_shape->size, shape_size);
  return kTfLiteOk;
}
   e2164:	4620      	mov	r0, r4
   e2166:	b015      	add	sp, #84	; 0x54
   e2168:	ecbd 8b02 	vpop	{d8}
   e216c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e2170:	000ec225 	.word	0x000ec225
   e2174:	000ec3ad 	.word	0x000ec3ad
   e2178:	000ec3b7 	.word	0x000ec3b7
   e217c:	000ec2f9 	.word	0x000ec2f9
   e2180:	000eb3b9 	.word	0x000eb3b9
   e2184:	000ec3d6 	.word	0x000ec3d6
   e2188:	000ec3e1 	.word	0x000ec3e1

000e218c <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   e218c:	b570      	push	{r4, r5, r6, lr}
}
inline const TfLiteTensor* GetIntermediates(TfLiteContext* context,
                                            TfLiteNode* node, int index) {
  return &context->tensors[node->intermediates->data[index]];
}
inline int NumInputs(const TfLiteNode* node) { return node->inputs->size; }
   e218e:	680b      	ldr	r3, [r1, #0]
   e2190:	681b      	ldr	r3, [r3, #0]
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 4);
   e2192:	2b04      	cmp	r3, #4
  }
  TF_LITE_ENSURE_EQ(context, output_shape->size, shape_size);
  return kTfLiteOk;
}

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   e2194:	b08c      	sub	sp, #48	; 0x30
   e2196:	4605      	mov	r5, r0
   e2198:	460a      	mov	r2, r1
  TF_LITE_ENSURE_EQ(context, NumInputs(node), 4);
   e219a:	d00d      	beq.n	e21b8 <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x2c>
   e219c:	9302      	str	r3, [sp, #8]
   e219e:	4b16      	ldr	r3, [pc, #88]	; (e21f8 <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x6c>)
   e21a0:	9301      	str	r3, [sp, #4]
   e21a2:	2204      	movs	r2, #4
   e21a4:	4b15      	ldr	r3, [pc, #84]	; (e21fc <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x70>)
   e21a6:	9300      	str	r3, [sp, #0]
   e21a8:	9203      	str	r2, [sp, #12]
   e21aa:	6944      	ldr	r4, [r0, #20]
   e21ac:	237c      	movs	r3, #124	; 0x7c
   e21ae:	4a14      	ldr	r2, [pc, #80]	; (e2200 <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x74>)
   e21b0:	4914      	ldr	r1, [pc, #80]	; (e2204 <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x78>)
   e21b2:	47a0      	blx	r4
   e21b4:	2001      	movs	r0, #1
   e21b6:	e01d      	b.n	e21f4 <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x68>
inline int NumOutputs(const TfLiteNode* node) { return node->outputs->size; }
   e21b8:	684b      	ldr	r3, [r1, #4]
   e21ba:	681c      	ldr	r4, [r3, #0]
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
   e21bc:	2c01      	cmp	r4, #1
   e21be:	d009      	beq.n	e21d4 <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x48>
   e21c0:	4b11      	ldr	r3, [pc, #68]	; (e2208 <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x7c>)
   e21c2:	9301      	str	r3, [sp, #4]
   e21c4:	2601      	movs	r6, #1
   e21c6:	4b11      	ldr	r3, [pc, #68]	; (e220c <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x80>)
   e21c8:	9300      	str	r3, [sp, #0]
   e21ca:	9603      	str	r6, [sp, #12]
   e21cc:	9402      	str	r4, [sp, #8]
   e21ce:	6944      	ldr	r4, [r0, #20]
   e21d0:	237d      	movs	r3, #125	; 0x7d
   e21d2:	e7ec      	b.n	e21ae <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x22>
  StridedSliceContext op_context(context, node);
   e21d4:	4601      	mov	r1, r0
   e21d6:	a805      	add	r0, sp, #20
   e21d8:	f7ff fefe 	bl	e1fd8 <_ZN6tflite3ops5micro13strided_slice19StridedSliceContextC1EP13TfLiteContextP10TfLiteNode>
  TF_LITE_ENSURE_MSG(context, op_context.dims <= kMaxDim,
   e21dc:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e21de:	2b04      	cmp	r3, #4
   e21e0:	dd04      	ble.n	e21ec <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x60>
   e21e2:	696b      	ldr	r3, [r5, #20]
   e21e4:	490a      	ldr	r1, [pc, #40]	; (e2210 <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x84>)
   e21e6:	4628      	mov	r0, r5
   e21e8:	4798      	blx	r3
   e21ea:	e7e3      	b.n	e21b4 <_ZN6tflite3ops5micro13strided_slice7PrepareEP13TfLiteContextP10TfLiteNode+0x28>
                     "input dim should not exceed 4");
  return CheckOutputSize(context, &op_context);
   e21ec:	a905      	add	r1, sp, #20
   e21ee:	4628      	mov	r0, r5
   e21f0:	f7ff ff44 	bl	e207c <_ZN6tflite3ops5micro13strided_slice15CheckOutputSizeEP13TfLiteContextPNS2_19StridedSliceContextE>
}
   e21f4:	b00c      	add	sp, #48	; 0x30
   e21f6:	bd70      	pop	{r4, r5, r6, pc}
   e21f8:	000ec4c4 	.word	0x000ec4c4
   e21fc:	000eb3d3 	.word	0x000eb3d3
   e2200:	000ec2f9 	.word	0x000ec2f9
   e2204:	000eb3b9 	.word	0x000eb3b9
   e2208:	000ecdd6 	.word	0x000ecdd6
   e220c:	000eb3e3 	.word	0x000eb3e3
   e2210:	000ec3f4 	.word	0x000ec3f4

000e2214 <_ZN6tflite3ops5micro22Register_STRIDED_SLICEEv>:
TfLiteRegistration* Register_STRIDED_SLICE() {
  static TfLiteRegistration r = {
      nullptr, nullptr, strided_slice::Prepare,
      strided_slice::Eval<strided_slice::kReference>};
  return &r;
}
   e2214:	4800      	ldr	r0, [pc, #0]	; (e2218 <_ZN6tflite3ops5micro22Register_STRIDED_SLICEEv+0x4>)
   e2216:	4770      	bx	lr
   e2218:	2003c1b0 	.word	0x2003c1b0

000e221c <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_>:

namespace tflite {

namespace reference_ops {
template <typename T>
inline void StridedSlice(const tflite::StridedSliceParams& op_params,
   e221c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e2220:	b0a1      	sub	sp, #132	; 0x84
   e2222:	461e      	mov	r6, r3
   e2224:	460f      	mov	r7, r1
   e2226:	920a      	str	r2, [sp, #40]	; 0x28
                         const RuntimeShape& unextended_input_shape,
                         const T* input_data,
                         const RuntimeShape& unextended_output_shape,
                         T* output_data) {
  // Note that the output_shape is not used herein.
  tflite::StridedSliceParams params_copy = op_params;
   e2228:	4603      	mov	r3, r0
   e222a:	ac16      	add	r4, sp, #88	; 0x58
   e222c:	f100 0528 	add.w	r5, r0, #40	; 0x28
   e2230:	6818      	ldr	r0, [r3, #0]
   e2232:	6859      	ldr	r1, [r3, #4]
   e2234:	4622      	mov	r2, r4
   e2236:	c203      	stmia	r2!, {r0, r1}
   e2238:	3308      	adds	r3, #8
   e223a:	42ab      	cmp	r3, r5
   e223c:	4614      	mov	r4, r2
   e223e:	d1f7      	bne.n	e2230 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x14>

  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 4);
   e2240:	683b      	ldr	r3, [r7, #0]
   e2242:	2b04      	cmp	r3, #4
   e2244:	dd01      	ble.n	e224a <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x2e>
   e2246:	f003 f955 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   e224a:	6833      	ldr	r3, [r6, #0]
   e224c:	2b04      	cmp	r3, #4
   e224e:	dcfa      	bgt.n	e2246 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x2a>
  // (a) as Dims<4>-dependent code is eliminated, the reliance on this should be
  // reduced, and (b) some kernels are stricly 4-D, but then the shapes of their
  // inputs should already be 4-D, so this function should not be needed.
  inline static RuntimeShape ExtendedShape(int new_shape_size,
                                           const RuntimeShape& shape) {
    return RuntimeShape(new_shape_size, shape, 1);
   e2250:	ad0c      	add	r5, sp, #48	; 0x30
   e2252:	2301      	movs	r3, #1
   e2254:	463a      	mov	r2, r7
   e2256:	2104      	movs	r1, #4
   e2258:	4628      	mov	r0, r5
   e225a:	f7f5 f9ca 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   e225e:	2301      	movs	r3, #1
   e2260:	4632      	mov	r2, r6
   e2262:	2104      	movs	r1, #4
   e2264:	a811      	add	r0, sp, #68	; 0x44
   e2266:	f7f5 f9c4 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  // Reverse and pad to 4 dimensions because that is what the runtime code
  // requires (ie. all shapes must be 4D and are given backwards).
  strided_slice::StridedSlicePadIndices(&params_copy, 4);
   e226a:	2104      	movs	r1, #4
   e226c:	a816      	add	r0, sp, #88	; 0x58
   e226e:	f7ff fe03 	bl	e1e78 <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi>

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
   e2272:	2200      	movs	r2, #0
   e2274:	4629      	mov	r1, r5
   e2276:	a816      	add	r0, sp, #88	; 0x58
   e2278:	f7ff fe52 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
   e227c:	2200      	movs	r2, #0
   e227e:	4603      	mov	r3, r0
   e2280:	4629      	mov	r1, r5

  // Reverse and pad to 4 dimensions because that is what the runtime code
  // requires (ie. all shapes must be 4D and are given backwards).
  strided_slice::StridedSlicePadIndices(&params_copy, 4);

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
   e2282:	4604      	mov	r4, r0
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
   e2284:	a816      	add	r0, sp, #88	; 0x58
   e2286:	f7ff fe6e 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
   e228a:	2201      	movs	r2, #1
  // requires (ie. all shapes must be 4D and are given backwards).
  strided_slice::StridedSlicePadIndices(&params_copy, 4);

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
   e228c:	9003      	str	r0, [sp, #12]
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
   e228e:	4629      	mov	r1, r5
   e2290:	a816      	add	r0, sp, #88	; 0x58
   e2292:	f7ff fe45 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
   e2296:	2201      	movs	r2, #1
   e2298:	4603      	mov	r3, r0
  strided_slice::StridedSlicePadIndices(&params_copy, 4);

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
   e229a:	9004      	str	r0, [sp, #16]
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
   e229c:	4629      	mov	r1, r5
   e229e:	a816      	add	r0, sp, #88	; 0x58
   e22a0:	f7ff fe61 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
   e22a4:	2202      	movs	r2, #2
  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
   e22a6:	9005      	str	r0, [sp, #20]
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
   e22a8:	4629      	mov	r1, r5
   e22aa:	a816      	add	r0, sp, #88	; 0x58
   e22ac:	f7ff fe38 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
   e22b0:	2202      	movs	r2, #2
   e22b2:	4603      	mov	r3, r0
   e22b4:	4629      	mov	r1, r5
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
   e22b6:	4680      	mov	r8, r0
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
   e22b8:	a816      	add	r0, sp, #88	; 0x58
   e22ba:	f7ff fe54 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
   e22be:	2203      	movs	r2, #3
   e22c0:	4629      	mov	r1, r5
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
   e22c2:	4681      	mov	r9, r0
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
   e22c4:	a816      	add	r0, sp, #88	; 0x58
   e22c6:	f7ff fe2b 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);
   e22ca:	2203      	movs	r2, #3
   e22cc:	4603      	mov	r3, r0
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
   e22ce:	4682      	mov	sl, r0
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);
   e22d0:	4629      	mov	r1, r5
   e22d2:	a816      	add	r0, sp, #88	; 0x58
   e22d4:	f7ff fe47 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>

  T* out_ptr = output_data;
  for (int in_b = start_b;
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
   e22d8:	f9bd 306e 	ldrsh.w	r3, [sp, #110]	; 0x6e
   e22dc:	9306      	str	r3, [sp, #24]
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
   e22de:	f9bd 3070 	ldrsh.w	r3, [sp, #112]	; 0x70
   e22e2:	9307      	str	r3, [sp, #28]
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
   e22e4:	f9bd 3072 	ldrsh.w	r3, [sp, #114]	; 0x72
   e22e8:	9308      	str	r3, [sp, #32]
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e22ea:	f9bd 3074 	ldrsh.w	r3, [sp, #116]	; 0x74
   e22ee:	9309      	str	r3, [sp, #36]	; 0x24
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);
   e22f0:	4683      	mov	fp, r0
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
                 in_d, stop_d, params_copy.strides[3]);
             in_d += params_copy.strides[3]) {
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
   e22f2:	950b      	str	r5, [sp, #44]	; 0x2c

inline bool LoopCondition(int index, int stop, int stride) {
  // True when we have reached the end of an axis and should loop.
  return stride > 0 ? index >= stop : index <= stop;
   e22f4:	9b06      	ldr	r3, [sp, #24]
   e22f6:	2b00      	cmp	r3, #0
   e22f8:	9b03      	ldr	r3, [sp, #12]
   e22fa:	dd04      	ble.n	e2306 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xea>
   e22fc:	429c      	cmp	r4, r3
   e22fe:	bfb4      	ite	lt
   e2300:	2300      	movlt	r3, #0
   e2302:	2301      	movge	r3, #1
   e2304:	e003      	b.n	e230e <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xf2>
   e2306:	429c      	cmp	r4, r3
   e2308:	bfcc      	ite	gt
   e230a:	2300      	movgt	r3, #0
   e230c:	2301      	movle	r3, #1
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);

  T* out_ptr = output_data;
  for (int in_b = start_b;
   e230e:	2b00      	cmp	r3, #0
   e2310:	d146      	bne.n	e23a0 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x184>
   e2312:	9d04      	ldr	r5, [sp, #16]
   e2314:	9b07      	ldr	r3, [sp, #28]
   e2316:	2b00      	cmp	r3, #0
   e2318:	9b05      	ldr	r3, [sp, #20]
   e231a:	dd04      	ble.n	e2326 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x10a>
   e231c:	429d      	cmp	r5, r3
   e231e:	bfb4      	ite	lt
   e2320:	2300      	movlt	r3, #0
   e2322:	2301      	movge	r3, #1
   e2324:	e003      	b.n	e232e <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x112>
   e2326:	429d      	cmp	r5, r3
   e2328:	bfcc      	ite	gt
   e232a:	2300      	movgt	r3, #0
   e232c:	2301      	movle	r3, #1
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
   e232e:	2b00      	cmp	r3, #0
   e2330:	d133      	bne.n	e239a <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x17e>
   e2332:	4646      	mov	r6, r8
   e2334:	9b08      	ldr	r3, [sp, #32]
   e2336:	2b00      	cmp	r3, #0
   e2338:	dd04      	ble.n	e2344 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x128>
   e233a:	454e      	cmp	r6, r9
   e233c:	bfb4      	ite	lt
   e233e:	2300      	movlt	r3, #0
   e2340:	2301      	movge	r3, #1
   e2342:	e003      	b.n	e234c <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x130>
   e2344:	454e      	cmp	r6, r9
   e2346:	bfcc      	ite	gt
   e2348:	2300      	movgt	r3, #0
   e234a:	2301      	movle	r3, #1
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
   e234c:	bb13      	cbnz	r3, e2394 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x178>
   e234e:	4657      	mov	r7, sl
   e2350:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e2352:	2b00      	cmp	r3, #0
   e2354:	dd04      	ble.n	e2360 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x144>
   e2356:	455f      	cmp	r7, fp
   e2358:	bfb4      	ite	lt
   e235a:	2300      	movlt	r3, #0
   e235c:	2301      	movge	r3, #1
   e235e:	e003      	b.n	e2368 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x14c>
   e2360:	455f      	cmp	r7, fp
   e2362:	bfcc      	ite	gt
   e2364:	2300      	movgt	r3, #0
   e2366:	2301      	movle	r3, #1
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e2368:	b98b      	cbnz	r3, e238e <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x172>
                 in_d, stop_d, params_copy.strides[3]);
             in_d += params_copy.strides[3]) {
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
   e236a:	9700      	str	r7, [sp, #0]
   e236c:	4633      	mov	r3, r6
   e236e:	462a      	mov	r2, r5
   e2370:	4621      	mov	r1, r4
   e2372:	980b      	ldr	r0, [sp, #44]	; 0x2c
   e2374:	f7f5 f969 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   e2378:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e237a:	9a2a      	ldr	r2, [sp, #168]	; 0xa8
   e237c:	eb03 0080 	add.w	r0, r3, r0, lsl #2
   e2380:	6803      	ldr	r3, [r0, #0]
   e2382:	f842 3b04 	str.w	r3, [r2], #4
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e2386:	9b09      	ldr	r3, [sp, #36]	; 0x24
                 in_d, stop_d, params_copy.strides[3]);
             in_d += params_copy.strides[3]) {
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
   e2388:	922a      	str	r2, [sp, #168]	; 0xa8
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e238a:	441f      	add	r7, r3
   e238c:	e7e0      	b.n	e2350 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x134>
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
   e238e:	9b08      	ldr	r3, [sp, #32]
   e2390:	441e      	add	r6, r3
   e2392:	e7cf      	b.n	e2334 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x118>

  T* out_ptr = output_data;
  for (int in_b = start_b;
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
   e2394:	9b07      	ldr	r3, [sp, #28]
   e2396:	441d      	add	r5, r3
   e2398:	e7bc      	b.n	e2314 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xf8>
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);

  T* out_ptr = output_data;
  for (int in_b = start_b;
   e239a:	9b06      	ldr	r3, [sp, #24]
   e239c:	441c      	add	r4, r3
   e239e:	e7a9      	b.n	e22f4 <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xd8>
  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape input_shape =
      RuntimeShape::ExtendedShape(4, unextended_input_shape);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   e23a0:	a811      	add	r0, sp, #68	; 0x44
   e23a2:	f7f5 f8e2 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  tflite::StridedSliceParams params_copy = op_params;

  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape input_shape =
      RuntimeShape::ExtendedShape(4, unextended_input_shape);
   e23a6:	a80c      	add	r0, sp, #48	; 0x30
   e23a8:	f7f5 f8df 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
        }
      }
    }
  }
}
   e23ac:	b021      	add	sp, #132	; 0x84
   e23ae:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000e23b2 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_>:

namespace tflite {

namespace reference_ops {
template <typename T>
inline void StridedSlice(const tflite::StridedSliceParams& op_params,
   e23b2:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e23b6:	b0a1      	sub	sp, #132	; 0x84
   e23b8:	461e      	mov	r6, r3
   e23ba:	460f      	mov	r7, r1
   e23bc:	920a      	str	r2, [sp, #40]	; 0x28
                         const RuntimeShape& unextended_input_shape,
                         const T* input_data,
                         const RuntimeShape& unextended_output_shape,
                         T* output_data) {
  // Note that the output_shape is not used herein.
  tflite::StridedSliceParams params_copy = op_params;
   e23be:	4603      	mov	r3, r0
   e23c0:	ac16      	add	r4, sp, #88	; 0x58
   e23c2:	f100 0528 	add.w	r5, r0, #40	; 0x28
   e23c6:	6818      	ldr	r0, [r3, #0]
   e23c8:	6859      	ldr	r1, [r3, #4]
   e23ca:	4622      	mov	r2, r4
   e23cc:	c203      	stmia	r2!, {r0, r1}
   e23ce:	3308      	adds	r3, #8
   e23d0:	42ab      	cmp	r3, r5
   e23d2:	4614      	mov	r4, r2
   e23d4:	d1f7      	bne.n	e23c6 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x14>

  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 4);
   e23d6:	683b      	ldr	r3, [r7, #0]
   e23d8:	2b04      	cmp	r3, #4
   e23da:	dd01      	ble.n	e23e0 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x2e>
   e23dc:	f003 f88a 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   e23e0:	6833      	ldr	r3, [r6, #0]
   e23e2:	2b04      	cmp	r3, #4
   e23e4:	dcfa      	bgt.n	e23dc <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x2a>
   e23e6:	ad0c      	add	r5, sp, #48	; 0x30
   e23e8:	2301      	movs	r3, #1
   e23ea:	463a      	mov	r2, r7
   e23ec:	2104      	movs	r1, #4
   e23ee:	4628      	mov	r0, r5
   e23f0:	f7f5 f8ff 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   e23f4:	2301      	movs	r3, #1
   e23f6:	4632      	mov	r2, r6
   e23f8:	2104      	movs	r1, #4
   e23fa:	a811      	add	r0, sp, #68	; 0x44
   e23fc:	f7f5 f8f9 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  // Reverse and pad to 4 dimensions because that is what the runtime code
  // requires (ie. all shapes must be 4D and are given backwards).
  strided_slice::StridedSlicePadIndices(&params_copy, 4);
   e2400:	2104      	movs	r1, #4
   e2402:	a816      	add	r0, sp, #88	; 0x58
   e2404:	f7ff fd38 	bl	e1e78 <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi>

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
   e2408:	2200      	movs	r2, #0
   e240a:	4629      	mov	r1, r5
   e240c:	a816      	add	r0, sp, #88	; 0x58
   e240e:	f7ff fd87 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
   e2412:	2200      	movs	r2, #0
   e2414:	4603      	mov	r3, r0
   e2416:	4629      	mov	r1, r5

  // Reverse and pad to 4 dimensions because that is what the runtime code
  // requires (ie. all shapes must be 4D and are given backwards).
  strided_slice::StridedSlicePadIndices(&params_copy, 4);

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
   e2418:	4604      	mov	r4, r0
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
   e241a:	a816      	add	r0, sp, #88	; 0x58
   e241c:	f7ff fda3 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
   e2420:	2201      	movs	r2, #1
  // requires (ie. all shapes must be 4D and are given backwards).
  strided_slice::StridedSlicePadIndices(&params_copy, 4);

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
   e2422:	9003      	str	r0, [sp, #12]
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
   e2424:	4629      	mov	r1, r5
   e2426:	a816      	add	r0, sp, #88	; 0x58
   e2428:	f7ff fd7a 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
   e242c:	2201      	movs	r2, #1
   e242e:	4603      	mov	r3, r0
  strided_slice::StridedSlicePadIndices(&params_copy, 4);

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
   e2430:	9004      	str	r0, [sp, #16]
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
   e2432:	4629      	mov	r1, r5
   e2434:	a816      	add	r0, sp, #88	; 0x58
   e2436:	f7ff fd96 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
   e243a:	2202      	movs	r2, #2
  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
   e243c:	9005      	str	r0, [sp, #20]
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
   e243e:	4629      	mov	r1, r5
   e2440:	a816      	add	r0, sp, #88	; 0x58
   e2442:	f7ff fd6d 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
   e2446:	2202      	movs	r2, #2
   e2448:	4603      	mov	r3, r0
   e244a:	4629      	mov	r1, r5
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
   e244c:	4680      	mov	r8, r0
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
   e244e:	a816      	add	r0, sp, #88	; 0x58
   e2450:	f7ff fd89 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
   e2454:	2203      	movs	r2, #3
   e2456:	4629      	mov	r1, r5
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
   e2458:	4681      	mov	r9, r0
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
   e245a:	a816      	add	r0, sp, #88	; 0x58
   e245c:	f7ff fd60 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);
   e2460:	2203      	movs	r2, #3
   e2462:	4603      	mov	r3, r0
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
   e2464:	4682      	mov	sl, r0
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);
   e2466:	4629      	mov	r1, r5
   e2468:	a816      	add	r0, sp, #88	; 0x58
   e246a:	f7ff fd7c 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>

  T* out_ptr = output_data;
  for (int in_b = start_b;
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
   e246e:	f9bd 306e 	ldrsh.w	r3, [sp, #110]	; 0x6e
   e2472:	9306      	str	r3, [sp, #24]
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
   e2474:	f9bd 3070 	ldrsh.w	r3, [sp, #112]	; 0x70
   e2478:	9307      	str	r3, [sp, #28]
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
   e247a:	f9bd 3072 	ldrsh.w	r3, [sp, #114]	; 0x72
   e247e:	9308      	str	r3, [sp, #32]
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e2480:	f9bd 3074 	ldrsh.w	r3, [sp, #116]	; 0x74
   e2484:	9309      	str	r3, [sp, #36]	; 0x24
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);
   e2486:	4683      	mov	fp, r0
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
                 in_d, stop_d, params_copy.strides[3]);
             in_d += params_copy.strides[3]) {
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
   e2488:	950b      	str	r5, [sp, #44]	; 0x2c
   e248a:	9b06      	ldr	r3, [sp, #24]
   e248c:	2b00      	cmp	r3, #0
   e248e:	9b03      	ldr	r3, [sp, #12]
   e2490:	dd04      	ble.n	e249c <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xea>
   e2492:	429c      	cmp	r4, r3
   e2494:	bfb4      	ite	lt
   e2496:	2300      	movlt	r3, #0
   e2498:	2301      	movge	r3, #1
   e249a:	e003      	b.n	e24a4 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xf2>
   e249c:	429c      	cmp	r4, r3
   e249e:	bfcc      	ite	gt
   e24a0:	2300      	movgt	r3, #0
   e24a2:	2301      	movle	r3, #1
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);

  T* out_ptr = output_data;
  for (int in_b = start_b;
   e24a4:	2b00      	cmp	r3, #0
   e24a6:	d144      	bne.n	e2532 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x180>
   e24a8:	9d04      	ldr	r5, [sp, #16]
   e24aa:	9b07      	ldr	r3, [sp, #28]
   e24ac:	2b00      	cmp	r3, #0
   e24ae:	9b05      	ldr	r3, [sp, #20]
   e24b0:	dd04      	ble.n	e24bc <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x10a>
   e24b2:	429d      	cmp	r5, r3
   e24b4:	bfb4      	ite	lt
   e24b6:	2300      	movlt	r3, #0
   e24b8:	2301      	movge	r3, #1
   e24ba:	e003      	b.n	e24c4 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x112>
   e24bc:	429d      	cmp	r5, r3
   e24be:	bfcc      	ite	gt
   e24c0:	2300      	movgt	r3, #0
   e24c2:	2301      	movle	r3, #1
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
   e24c4:	2b00      	cmp	r3, #0
   e24c6:	d131      	bne.n	e252c <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x17a>
   e24c8:	4646      	mov	r6, r8
   e24ca:	9b08      	ldr	r3, [sp, #32]
   e24cc:	2b00      	cmp	r3, #0
   e24ce:	dd04      	ble.n	e24da <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x128>
   e24d0:	454e      	cmp	r6, r9
   e24d2:	bfb4      	ite	lt
   e24d4:	2300      	movlt	r3, #0
   e24d6:	2301      	movge	r3, #1
   e24d8:	e003      	b.n	e24e2 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x130>
   e24da:	454e      	cmp	r6, r9
   e24dc:	bfcc      	ite	gt
   e24de:	2300      	movgt	r3, #0
   e24e0:	2301      	movle	r3, #1
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
   e24e2:	bb03      	cbnz	r3, e2526 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x174>
   e24e4:	4657      	mov	r7, sl
   e24e6:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e24e8:	2b00      	cmp	r3, #0
   e24ea:	dd04      	ble.n	e24f6 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x144>
   e24ec:	455f      	cmp	r7, fp
   e24ee:	bfb4      	ite	lt
   e24f0:	2300      	movlt	r3, #0
   e24f2:	2301      	movge	r3, #1
   e24f4:	e003      	b.n	e24fe <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x14c>
   e24f6:	455f      	cmp	r7, fp
   e24f8:	bfcc      	ite	gt
   e24fa:	2300      	movgt	r3, #0
   e24fc:	2301      	movle	r3, #1
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e24fe:	b97b      	cbnz	r3, e2520 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x16e>
                 in_d, stop_d, params_copy.strides[3]);
             in_d += params_copy.strides[3]) {
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
   e2500:	9700      	str	r7, [sp, #0]
   e2502:	4633      	mov	r3, r6
   e2504:	462a      	mov	r2, r5
   e2506:	4621      	mov	r1, r4
   e2508:	980b      	ldr	r0, [sp, #44]	; 0x2c
   e250a:	f7f5 f89e 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   e250e:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e2510:	9a2a      	ldr	r2, [sp, #168]	; 0xa8
   e2512:	5c1b      	ldrb	r3, [r3, r0]
   e2514:	f802 3b01 	strb.w	r3, [r2], #1
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e2518:	9b09      	ldr	r3, [sp, #36]	; 0x24
                 in_d, stop_d, params_copy.strides[3]);
             in_d += params_copy.strides[3]) {
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
   e251a:	922a      	str	r2, [sp, #168]	; 0xa8
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e251c:	441f      	add	r7, r3
   e251e:	e7e2      	b.n	e24e6 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x134>
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
   e2520:	9b08      	ldr	r3, [sp, #32]
   e2522:	441e      	add	r6, r3
   e2524:	e7d1      	b.n	e24ca <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x118>

  T* out_ptr = output_data;
  for (int in_b = start_b;
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
   e2526:	9b07      	ldr	r3, [sp, #28]
   e2528:	441d      	add	r5, r3
   e252a:	e7be      	b.n	e24aa <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xf8>
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);

  T* out_ptr = output_data;
  for (int in_b = start_b;
   e252c:	9b06      	ldr	r3, [sp, #24]
   e252e:	441c      	add	r4, r3
   e2530:	e7ab      	b.n	e248a <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xd8>
  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape input_shape =
      RuntimeShape::ExtendedShape(4, unextended_input_shape);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   e2532:	a811      	add	r0, sp, #68	; 0x44
   e2534:	f7f5 f819 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  tflite::StridedSliceParams params_copy = op_params;

  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape input_shape =
      RuntimeShape::ExtendedShape(4, unextended_input_shape);
   e2538:	a80c      	add	r0, sp, #48	; 0x30
   e253a:	f7f5 f816 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
        }
      }
    }
  }
}
   e253e:	b021      	add	sp, #132	; 0x84
   e2540:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000e2544 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_>:

namespace tflite {

namespace reference_ops {
template <typename T>
inline void StridedSlice(const tflite::StridedSliceParams& op_params,
   e2544:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e2548:	b0a1      	sub	sp, #132	; 0x84
   e254a:	461e      	mov	r6, r3
   e254c:	460f      	mov	r7, r1
   e254e:	920a      	str	r2, [sp, #40]	; 0x28
                         const RuntimeShape& unextended_input_shape,
                         const T* input_data,
                         const RuntimeShape& unextended_output_shape,
                         T* output_data) {
  // Note that the output_shape is not used herein.
  tflite::StridedSliceParams params_copy = op_params;
   e2550:	4603      	mov	r3, r0
   e2552:	ac16      	add	r4, sp, #88	; 0x58
   e2554:	f100 0528 	add.w	r5, r0, #40	; 0x28
   e2558:	6818      	ldr	r0, [r3, #0]
   e255a:	6859      	ldr	r1, [r3, #4]
   e255c:	4622      	mov	r2, r4
   e255e:	c203      	stmia	r2!, {r0, r1}
   e2560:	3308      	adds	r3, #8
   e2562:	42ab      	cmp	r3, r5
   e2564:	4614      	mov	r4, r2
   e2566:	d1f7      	bne.n	e2558 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x14>

  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 4);
   e2568:	683b      	ldr	r3, [r7, #0]
   e256a:	2b04      	cmp	r3, #4
   e256c:	dd01      	ble.n	e2572 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x2e>
   e256e:	f002 ffc1 	bl	e54f4 <abort>
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
   e2572:	6833      	ldr	r3, [r6, #0]
   e2574:	2b04      	cmp	r3, #4
   e2576:	dcfa      	bgt.n	e256e <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x2a>
   e2578:	ad0c      	add	r5, sp, #48	; 0x30
   e257a:	2301      	movs	r3, #1
   e257c:	463a      	mov	r2, r7
   e257e:	2104      	movs	r1, #4
   e2580:	4628      	mov	r0, r5
   e2582:	f7f5 f836 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
   e2586:	2301      	movs	r3, #1
   e2588:	4632      	mov	r2, r6
   e258a:	2104      	movs	r1, #4
   e258c:	a811      	add	r0, sp, #68	; 0x44
   e258e:	f7f5 f830 	bl	d75f2 <_ZN6tflite12RuntimeShapeC1EiRKS0_i>
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);

  // Reverse and pad to 4 dimensions because that is what the runtime code
  // requires (ie. all shapes must be 4D and are given backwards).
  strided_slice::StridedSlicePadIndices(&params_copy, 4);
   e2592:	2104      	movs	r1, #4
   e2594:	a816      	add	r0, sp, #88	; 0x58
   e2596:	f7ff fc6f 	bl	e1e78 <_ZN6tflite13strided_slice22StridedSlicePadIndicesEPNS_18StridedSliceParamsEi>

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
   e259a:	2200      	movs	r2, #0
   e259c:	4629      	mov	r1, r5
   e259e:	a816      	add	r0, sp, #88	; 0x58
   e25a0:	f7ff fcbe 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
   e25a4:	2200      	movs	r2, #0
   e25a6:	4603      	mov	r3, r0
   e25a8:	4629      	mov	r1, r5

  // Reverse and pad to 4 dimensions because that is what the runtime code
  // requires (ie. all shapes must be 4D and are given backwards).
  strided_slice::StridedSlicePadIndices(&params_copy, 4);

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
   e25aa:	4604      	mov	r4, r0
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
   e25ac:	a816      	add	r0, sp, #88	; 0x58
   e25ae:	f7ff fcda 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
   e25b2:	2201      	movs	r2, #1
  // requires (ie. all shapes must be 4D and are given backwards).
  strided_slice::StridedSlicePadIndices(&params_copy, 4);

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
   e25b4:	9003      	str	r0, [sp, #12]
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
   e25b6:	4629      	mov	r1, r5
   e25b8:	a816      	add	r0, sp, #88	; 0x58
   e25ba:	f7ff fcb1 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
   e25be:	2201      	movs	r2, #1
   e25c0:	4603      	mov	r3, r0
  strided_slice::StridedSlicePadIndices(&params_copy, 4);

  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
   e25c2:	9004      	str	r0, [sp, #16]
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
   e25c4:	4629      	mov	r1, r5
   e25c6:	a816      	add	r0, sp, #88	; 0x58
   e25c8:	f7ff fccd 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
   e25cc:	2202      	movs	r2, #2
  const int start_b = strided_slice::StartForAxis(params_copy, input_shape, 0);
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
   e25ce:	9005      	str	r0, [sp, #20]
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
   e25d0:	4629      	mov	r1, r5
   e25d2:	a816      	add	r0, sp, #88	; 0x58
   e25d4:	f7ff fca4 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
   e25d8:	2202      	movs	r2, #2
   e25da:	4603      	mov	r3, r0
   e25dc:	4629      	mov	r1, r5
  const int stop_b =
      strided_slice::StopForAxis(params_copy, input_shape, 0, start_b);
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
   e25de:	4680      	mov	r8, r0
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
   e25e0:	a816      	add	r0, sp, #88	; 0x58
   e25e2:	f7ff fcc0 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
   e25e6:	2203      	movs	r2, #3
   e25e8:	4629      	mov	r1, r5
  const int start_h = strided_slice::StartForAxis(params_copy, input_shape, 1);
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
   e25ea:	4681      	mov	r9, r0
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
   e25ec:	a816      	add	r0, sp, #88	; 0x58
   e25ee:	f7ff fc97 	bl	e1f20 <_ZN6tflite13strided_slice12StartForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEi>
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);
   e25f2:	2203      	movs	r2, #3
   e25f4:	4603      	mov	r3, r0
  const int stop_h =
      strided_slice::StopForAxis(params_copy, input_shape, 1, start_h);
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
   e25f6:	4682      	mov	sl, r0
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);
   e25f8:	4629      	mov	r1, r5
   e25fa:	a816      	add	r0, sp, #88	; 0x58
   e25fc:	f7ff fcb3 	bl	e1f66 <_ZN6tflite13strided_slice11StopForAxisERKNS_18StridedSliceParamsERKNS_12RuntimeShapeEii>

  T* out_ptr = output_data;
  for (int in_b = start_b;
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
   e2600:	f9bd 306e 	ldrsh.w	r3, [sp, #110]	; 0x6e
   e2604:	9306      	str	r3, [sp, #24]
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
   e2606:	f9bd 3070 	ldrsh.w	r3, [sp, #112]	; 0x70
   e260a:	9307      	str	r3, [sp, #28]
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
   e260c:	f9bd 3072 	ldrsh.w	r3, [sp, #114]	; 0x72
   e2610:	9308      	str	r3, [sp, #32]
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e2612:	f9bd 3074 	ldrsh.w	r3, [sp, #116]	; 0x74
   e2616:	9309      	str	r3, [sp, #36]	; 0x24
  const int start_w = strided_slice::StartForAxis(params_copy, input_shape, 2);
  const int stop_w =
      strided_slice::StopForAxis(params_copy, input_shape, 2, start_w);
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);
   e2618:	4683      	mov	fp, r0
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
                 in_d, stop_d, params_copy.strides[3]);
             in_d += params_copy.strides[3]) {
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
   e261a:	950b      	str	r5, [sp, #44]	; 0x2c
   e261c:	9b06      	ldr	r3, [sp, #24]
   e261e:	2b00      	cmp	r3, #0
   e2620:	9b03      	ldr	r3, [sp, #12]
   e2622:	dd04      	ble.n	e262e <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xea>
   e2624:	429c      	cmp	r4, r3
   e2626:	bfb4      	ite	lt
   e2628:	2300      	movlt	r3, #0
   e262a:	2301      	movge	r3, #1
   e262c:	e003      	b.n	e2636 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xf2>
   e262e:	429c      	cmp	r4, r3
   e2630:	bfcc      	ite	gt
   e2632:	2300      	movgt	r3, #0
   e2634:	2301      	movle	r3, #1
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);

  T* out_ptr = output_data;
  for (int in_b = start_b;
   e2636:	2b00      	cmp	r3, #0
   e2638:	d144      	bne.n	e26c4 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x180>
   e263a:	9d04      	ldr	r5, [sp, #16]
   e263c:	9b07      	ldr	r3, [sp, #28]
   e263e:	2b00      	cmp	r3, #0
   e2640:	9b05      	ldr	r3, [sp, #20]
   e2642:	dd04      	ble.n	e264e <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x10a>
   e2644:	429d      	cmp	r5, r3
   e2646:	bfb4      	ite	lt
   e2648:	2300      	movlt	r3, #0
   e264a:	2301      	movge	r3, #1
   e264c:	e003      	b.n	e2656 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x112>
   e264e:	429d      	cmp	r5, r3
   e2650:	bfcc      	ite	gt
   e2652:	2300      	movgt	r3, #0
   e2654:	2301      	movle	r3, #1
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
   e2656:	2b00      	cmp	r3, #0
   e2658:	d131      	bne.n	e26be <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x17a>
   e265a:	4646      	mov	r6, r8
   e265c:	9b08      	ldr	r3, [sp, #32]
   e265e:	2b00      	cmp	r3, #0
   e2660:	dd04      	ble.n	e266c <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x128>
   e2662:	454e      	cmp	r6, r9
   e2664:	bfb4      	ite	lt
   e2666:	2300      	movlt	r3, #0
   e2668:	2301      	movge	r3, #1
   e266a:	e003      	b.n	e2674 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x130>
   e266c:	454e      	cmp	r6, r9
   e266e:	bfcc      	ite	gt
   e2670:	2300      	movgt	r3, #0
   e2672:	2301      	movle	r3, #1
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
   e2674:	bb03      	cbnz	r3, e26b8 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x174>
   e2676:	4657      	mov	r7, sl
   e2678:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e267a:	2b00      	cmp	r3, #0
   e267c:	dd04      	ble.n	e2688 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x144>
   e267e:	455f      	cmp	r7, fp
   e2680:	bfb4      	ite	lt
   e2682:	2300      	movlt	r3, #0
   e2684:	2301      	movge	r3, #1
   e2686:	e003      	b.n	e2690 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x14c>
   e2688:	455f      	cmp	r7, fp
   e268a:	bfcc      	ite	gt
   e268c:	2300      	movgt	r3, #0
   e268e:	2301      	movle	r3, #1
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e2690:	b97b      	cbnz	r3, e26b2 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x16e>
                 in_d, stop_d, params_copy.strides[3]);
             in_d += params_copy.strides[3]) {
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
   e2692:	9700      	str	r7, [sp, #0]
   e2694:	4633      	mov	r3, r6
   e2696:	462a      	mov	r2, r5
   e2698:	4621      	mov	r1, r4
   e269a:	980b      	ldr	r0, [sp, #44]	; 0x2c
   e269c:	f7f4 ffd5 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   e26a0:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e26a2:	9a2a      	ldr	r2, [sp, #168]	; 0xa8
   e26a4:	561b      	ldrsb	r3, [r3, r0]
   e26a6:	f802 3b01 	strb.w	r3, [r2], #1
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e26aa:	9b09      	ldr	r3, [sp, #36]	; 0x24
                 in_d, stop_d, params_copy.strides[3]);
             in_d += params_copy.strides[3]) {
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
   e26ac:	922a      	str	r2, [sp, #168]	; 0xa8
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
           !strided_slice::LoopCondition(in_w, stop_w, params_copy.strides[2]);
           in_w += params_copy.strides[2]) {
        for (int in_d = start_d; !strided_slice::LoopCondition(
   e26ae:	441f      	add	r7, r3
   e26b0:	e7e2      	b.n	e2678 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x134>
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
         !strided_slice::LoopCondition(in_h, stop_h, params_copy.strides[1]);
         in_h += params_copy.strides[1]) {
      for (int in_w = start_w;
   e26b2:	9b08      	ldr	r3, [sp, #32]
   e26b4:	441e      	add	r6, r3
   e26b6:	e7d1      	b.n	e265c <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0x118>

  T* out_ptr = output_data;
  for (int in_b = start_b;
       !strided_slice::LoopCondition(in_b, stop_b, params_copy.strides[0]);
       in_b += params_copy.strides[0]) {
    for (int in_h = start_h;
   e26b8:	9b07      	ldr	r3, [sp, #28]
   e26ba:	441d      	add	r5, r3
   e26bc:	e7be      	b.n	e263c <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xf8>
  const int start_d = strided_slice::StartForAxis(params_copy, input_shape, 3);
  const int stop_d =
      strided_slice::StopForAxis(params_copy, input_shape, 3, start_d);

  T* out_ptr = output_data;
  for (int in_b = start_b;
   e26be:	9b06      	ldr	r3, [sp, #24]
   e26c0:	441c      	add	r4, r3
   e26c2:	e7ab      	b.n	e261c <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_+0xd8>
  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape input_shape =
      RuntimeShape::ExtendedShape(4, unextended_input_shape);
  const RuntimeShape output_shape =
      RuntimeShape::ExtendedShape(4, unextended_output_shape);
   e26c4:	a811      	add	r0, sp, #68	; 0x44
   e26c6:	f7f4 ff50 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  tflite::StridedSliceParams params_copy = op_params;

  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 4);
  const RuntimeShape input_shape =
      RuntimeShape::ExtendedShape(4, unextended_input_shape);
   e26ca:	a80c      	add	r0, sp, #48	; 0x30
   e26cc:	f7f4 ff4d 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
          *out_ptr++ = input_data[Offset(input_shape, in_b, in_h, in_w, in_d)];
        }
      }
    }
  }
}
   e26d0:	b021      	add	sp, #132	; 0x84
   e26d2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	...

000e26d8 <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode>:
                     "input dim should not exceed 4");
  return CheckOutputSize(context, &op_context);
}

template <KernelType kernel_type>
TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e26d8:	b510      	push	{r4, lr}
   e26da:	b09e      	sub	sp, #120	; 0x78
  StridedSliceContext op_context(context, node);
   e26dc:	460a      	mov	r2, r1
                     "input dim should not exceed 4");
  return CheckOutputSize(context, &op_context);
}

template <KernelType kernel_type>
TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e26de:	4604      	mov	r4, r0
  StridedSliceContext op_context(context, node);
   e26e0:	4601      	mov	r1, r0
   e26e2:	a80d      	add	r0, sp, #52	; 0x34
   e26e4:	f7ff fc78 	bl	e1fd8 <_ZN6tflite3ops5micro13strided_slice19StridedSliceContextC1EP13TfLiteContextP10TfLiteNode>
  auto op_params = BuildStridedSliceParams(&op_context);
   e26e8:	a90d      	add	r1, sp, #52	; 0x34
   e26ea:	a814      	add	r0, sp, #80	; 0x50
   e26ec:	f7ff fc9a 	bl	e2024 <_ZN6tflite3ops5micro13strided_slice23BuildStridedSliceParamsEPNS2_19StridedSliceContextE>
  kernel_type::StridedSlice(op_params, GetTensorShape(op_context.input), \
                            GetTensorData<data_type>(op_context.input),  \
                            GetTensorShape(op_context.output),           \
                            GetTensorData<data_type>(op_context.output))

  switch (op_context.input->type) {
   e26f0:	990e      	ldr	r1, [sp, #56]	; 0x38
   e26f2:	780a      	ldrb	r2, [r1, #0]
   e26f4:	2a03      	cmp	r2, #3
   e26f6:	d01a      	beq.n	e272e <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x56>
   e26f8:	2a09      	cmp	r2, #9
   e26fa:	d036      	beq.n	e276a <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x92>
   e26fc:	2a01      	cmp	r2, #1
   e26fe:	d14b      	bne.n	e2798 <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xc0>
    case kTfLiteFloat32:
      if (kernel_type == kReference) {
        TF_LITE_STRIDED_SLICE(reference_ops, float);
   e2700:	a803      	add	r0, sp, #12
   e2702:	f7f5 f9e2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e2706:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   e2708:	b10a      	cbz	r2, e270e <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x36>
   e270a:	6854      	ldr	r4, [r2, #4]
   e270c:	e000      	b.n	e2710 <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x38>
   e270e:	4614      	mov	r4, r2
   e2710:	9912      	ldr	r1, [sp, #72]	; 0x48
   e2712:	a808      	add	r0, sp, #32
   e2714:	f7f5 f9d9 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e2718:	9b12      	ldr	r3, [sp, #72]	; 0x48

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e271a:	b103      	cbz	r3, e271e <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x46>
   e271c:	685b      	ldr	r3, [r3, #4]
   e271e:	9300      	str	r3, [sp, #0]
   e2720:	4622      	mov	r2, r4
   e2722:	ab08      	add	r3, sp, #32
   e2724:	a903      	add	r1, sp, #12
   e2726:	a814      	add	r0, sp, #80	; 0x50
   e2728:	f7ff fd78 	bl	e221c <_ZN6tflite13reference_ops12StridedSliceIfEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_>
   e272c:	e015      	b.n	e275a <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x82>
      }
      break;
    case kTfLiteUInt8:
      if (kernel_type == kReference) {
        TF_LITE_STRIDED_SLICE(reference_ops, uint8_t);
   e272e:	a803      	add	r0, sp, #12
   e2730:	f7f5 f9cb 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e2734:	9a0e      	ldr	r2, [sp, #56]	; 0x38
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e2736:	b10a      	cbz	r2, e273c <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x64>
   e2738:	6854      	ldr	r4, [r2, #4]
   e273a:	e000      	b.n	e273e <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x66>
   e273c:	4614      	mov	r4, r2
   e273e:	9912      	ldr	r1, [sp, #72]	; 0x48
   e2740:	a808      	add	r0, sp, #32
   e2742:	f7f5 f9c2 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e2746:	9b12      	ldr	r3, [sp, #72]	; 0x48

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e2748:	b103      	cbz	r3, e274c <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x74>
   e274a:	685b      	ldr	r3, [r3, #4]
   e274c:	9300      	str	r3, [sp, #0]
   e274e:	4622      	mov	r2, r4
   e2750:	ab08      	add	r3, sp, #32
   e2752:	a903      	add	r1, sp, #12
   e2754:	a814      	add	r0, sp, #80	; 0x50
   e2756:	f7ff fe2c 	bl	e23b2 <_ZN6tflite13reference_ops12StridedSliceIhEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_>
   e275a:	a808      	add	r0, sp, #32
   e275c:	f7f4 ff05 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   e2760:	a803      	add	r0, sp, #12
   e2762:	f7f4 ff02 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
                           "by StridedSlice.",
                           op_context.input->type);
      return kTfLiteError;
  }
#undef TF_LITE_STRIDED_SLICE
  return kTfLiteOk;
   e2766:	2000      	movs	r0, #0
      break;
    case kTfLiteUInt8:
      if (kernel_type == kReference) {
        TF_LITE_STRIDED_SLICE(reference_ops, uint8_t);
      }
      break;
   e2768:	e01b      	b.n	e27a2 <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xca>
    case kTfLiteInt8:
      if (kernel_type == kReference) {
        TF_LITE_STRIDED_SLICE(reference_ops, int8_t);
   e276a:	a803      	add	r0, sp, #12
   e276c:	f7f5 f9ad 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e2770:	9a0e      	ldr	r2, [sp, #56]	; 0x38
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e2772:	b10a      	cbz	r2, e2778 <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xa0>
   e2774:	6854      	ldr	r4, [r2, #4]
   e2776:	e000      	b.n	e277a <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xa2>
   e2778:	4614      	mov	r4, r2
   e277a:	9912      	ldr	r1, [sp, #72]	; 0x48
   e277c:	a808      	add	r0, sp, #32
   e277e:	f7f5 f9a4 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e2782:	9b12      	ldr	r3, [sp, #72]	; 0x48

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e2784:	b103      	cbz	r3, e2788 <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xb0>
   e2786:	685b      	ldr	r3, [r3, #4]
   e2788:	9300      	str	r3, [sp, #0]
   e278a:	4622      	mov	r2, r4
   e278c:	ab08      	add	r3, sp, #32
   e278e:	a903      	add	r1, sp, #12
   e2790:	a814      	add	r0, sp, #80	; 0x50
   e2792:	f7ff fed7 	bl	e2544 <_ZN6tflite13reference_ops12StridedSliceIaEEvRKNS_18StridedSliceParamsERKNS_12RuntimeShapeEPKT_S7_PS8_>
   e2796:	e7e0      	b.n	e275a <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0x82>
      }
      break;
    default:
      context->ReportError(context,
   e2798:	4620      	mov	r0, r4
   e279a:	6963      	ldr	r3, [r4, #20]
   e279c:	4902      	ldr	r1, [pc, #8]	; (e27a8 <_ZN6tflite3ops5micro13strided_slice4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode+0xd0>)
   e279e:	4798      	blx	r3
                           "Type %d is currently not supported "
                           "by StridedSlice.",
                           op_context.input->type);
      return kTfLiteError;
   e27a0:	2001      	movs	r0, #1
  }
#undef TF_LITE_STRIDED_SLICE
  return kTfLiteOk;
}
   e27a2:	b01e      	add	sp, #120	; 0x78
   e27a4:	bd10      	pop	{r4, pc}
   e27a6:	bf00      	nop
   e27a8:	000ec4c6 	.word	0x000ec4c6

000e27ac <_ZN6tflite3ops5micro4svdf4InitEP13TfLiteContextPKcj>:
// Output tensor.
constexpr int kOutputTensor = 0;

void* Init(TfLiteContext* context, const char* buffer, size_t length) {
  return nullptr;
}
   e27ac:	2000      	movs	r0, #0
   e27ae:	4770      	bx	lr

000e27b0 <_ZN6tflite3ops5micro4svdf4FreeEP13TfLiteContextPv>:

void Free(TfLiteContext* context, void* buffer) {}
   e27b0:	4770      	bx	lr
	...

000e27b4 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_>:

static inline void ApplyTimeWeightsBiasAndActivation(
    int batch_size, int memory_size, int num_filters, int num_units, int rank,
    const TfLiteTensor* weights_time, const TfLiteTensor* bias,
    TfLiteFusedActivation activation, TfLiteTensor* activation_state,
    TfLiteTensor* scratch, TfLiteTensor* output) {
   e27b4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e27b8:	b087      	sub	sp, #28
   e27ba:	4693      	mov	fp, r2
   e27bc:	9101      	str	r1, [sp, #4]
   e27be:	fb01 f10b 	mul.w	r1, r1, fp
   e27c2:	0089      	lsls	r1, r1, #2
   e27c4:	9103      	str	r1, [sp, #12]
   e27c6:	ea4f 018b 	mov.w	r1, fp, lsl #2
   e27ca:	9104      	str	r1, [sp, #16]
   e27cc:	9901      	ldr	r1, [sp, #4]
   e27ce:	f89d 204c 	ldrb.w	r2, [sp, #76]	; 0x4c
   e27d2:	9205      	str	r2, [sp, #20]
   e27d4:	2500      	movs	r5, #0
   e27d6:	ea21 76e1 	bic.w	r6, r1, r1, asr #31
   e27da:	9a16      	ldr	r2, [sp, #88]	; 0x58
    float* scratch_ptr_batch = GetTensorData<float>(scratch) + b * num_filters;
    const float* vector1_ptr = GetTensorData<float>(weights_time);
    const float* vector2_ptr =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int i = 0; i < num_filters; ++i) {
      *scratch_ptr_batch = 0.f;
   e27dc:	ed9f 7a77 	vldr	s14, [pc, #476]	; e29bc <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x208>

static inline void ApplyTimeWeightsBiasAndActivation(
    int batch_size, int memory_size, int num_filters, int num_units, int rank,
    const TfLiteTensor* weights_time, const TfLiteTensor* bias,
    TfLiteFusedActivation activation, TfLiteTensor* activation_state,
    TfLiteTensor* scratch, TfLiteTensor* output) {
   e27e0:	9300      	str	r3, [sp, #0]
   e27e2:	00b6      	lsls	r6, r6, #2
   e27e4:	46ae      	mov	lr, r5
  // Compute matmul(activation_state, weights_time).
  // The rightmost column is used to save temporary output (with the size of
  // num_filters). This is achieved by starting at
  // GetTensorData<float>(activation_state), and having the stride equal to
  // memory_size.
  for (int b = 0; b < batch_size; ++b) {
   e27e6:	46ac      	mov	ip, r5
   e27e8:	4584      	cmp	ip, r0
   e27ea:	da38      	bge.n	e285e <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0xaa>
   e27ec:	9915      	ldr	r1, [sp, #84]	; 0x54
   e27ee:	b109      	cbz	r1, e27f4 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x40>
   e27f0:	6849      	ldr	r1, [r1, #4]
   e27f2:	e000      	b.n	e27f6 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x42>
   e27f4:	9915      	ldr	r1, [sp, #84]	; 0x54
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e27f6:	9c11      	ldr	r4, [sp, #68]	; 0x44
    // Perform batched vector dot product:
    float* scratch_ptr_batch = GetTensorData<float>(scratch) + b * num_filters;
   e27f8:	4429      	add	r1, r5
   e27fa:	b10c      	cbz	r4, e2800 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x4c>
   e27fc:	6867      	ldr	r7, [r4, #4]
   e27fe:	e000      	b.n	e2802 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x4e>
   e2800:	9f11      	ldr	r7, [sp, #68]	; 0x44

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e2802:	9c14      	ldr	r4, [sp, #80]	; 0x50
   e2804:	b10c      	cbz	r4, e280a <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x56>
   e2806:	6864      	ldr	r4, [r4, #4]
   e2808:	e000      	b.n	e280c <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x58>
   e280a:	9c14      	ldr	r4, [sp, #80]	; 0x50
    const float* vector1_ptr = GetTensorData<float>(weights_time);
    const float* vector2_ptr =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
   e280c:	4474      	add	r4, lr
    for (int i = 0; i < num_filters; ++i) {
   e280e:	f04f 0800 	mov.w	r8, #0
   e2812:	45d8      	cmp	r8, fp
   e2814:	da1c      	bge.n	e2850 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x9c>
      *scratch_ptr_batch = 0.f;
   e2816:	eca1 7a01 	vstmia	r1!, {s14}
   e281a:	46a2      	mov	sl, r4
   e281c:	9702      	str	r7, [sp, #8]
      for (int j = 0; j < memory_size; ++j) {
   e281e:	f04f 0900 	mov.w	r9, #0
   e2822:	9b01      	ldr	r3, [sp, #4]
   e2824:	4599      	cmp	r9, r3
   e2826:	da0e      	bge.n	e2846 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x92>
        *scratch_ptr_batch += *vector1_ptr++ * *vector2_ptr++;
   e2828:	9b02      	ldr	r3, [sp, #8]
   e282a:	ecfa 6a01 	vldmia	sl!, {s13}
   e282e:	ecb3 6a01 	vldmia	r3!, {s12}
   e2832:	ed51 7a01 	vldr	s15, [r1, #-4]
   e2836:	9302      	str	r3, [sp, #8]
   e2838:	eee6 7a26 	vfma.f32	s15, s12, s13
    const float* vector1_ptr = GetTensorData<float>(weights_time);
    const float* vector2_ptr =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int i = 0; i < num_filters; ++i) {
      *scratch_ptr_batch = 0.f;
      for (int j = 0; j < memory_size; ++j) {
   e283c:	f109 0901 	add.w	r9, r9, #1
        *scratch_ptr_batch += *vector1_ptr++ * *vector2_ptr++;
   e2840:	ed41 7a01 	vstr	s15, [r1, #-4]
    const float* vector1_ptr = GetTensorData<float>(weights_time);
    const float* vector2_ptr =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int i = 0; i < num_filters; ++i) {
      *scratch_ptr_batch = 0.f;
      for (int j = 0; j < memory_size; ++j) {
   e2844:	e7ed      	b.n	e2822 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x6e>
   e2846:	4437      	add	r7, r6
   e2848:	4434      	add	r4, r6
    // Perform batched vector dot product:
    float* scratch_ptr_batch = GetTensorData<float>(scratch) + b * num_filters;
    const float* vector1_ptr = GetTensorData<float>(weights_time);
    const float* vector2_ptr =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int i = 0; i < num_filters; ++i) {
   e284a:	f108 0801 	add.w	r8, r8, #1
   e284e:	e7e0      	b.n	e2812 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x5e>
   e2850:	9b03      	ldr	r3, [sp, #12]
   e2852:	449e      	add	lr, r3
   e2854:	9b04      	ldr	r3, [sp, #16]
  // Compute matmul(activation_state, weights_time).
  // The rightmost column is used to save temporary output (with the size of
  // num_filters). This is achieved by starting at
  // GetTensorData<float>(activation_state), and having the stride equal to
  // memory_size.
  for (int b = 0; b < batch_size; ++b) {
   e2856:	f10c 0c01 	add.w	ip, ip, #1
   e285a:	441d      	add	r5, r3
   e285c:	e7c4      	b.n	e27e8 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x34>
      scratch_ptr_batch++;
    }
  }

  // Initialize output with bias if provided.
  if (bias) {
   e285e:	9b12      	ldr	r3, [sp, #72]	; 0x48
   e2860:	b333      	cbz	r3, e28b0 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0xfc>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e2862:	f8d3 c004 	ldr.w	ip, [r3, #4]

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e2866:	b10a      	cbz	r2, e286c <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0xb8>
   e2868:	6851      	ldr	r1, [r2, #4]
   e286a:	e000      	b.n	e286e <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0xba>
   e286c:	4611      	mov	r1, r2
   e286e:	9b00      	ldr	r3, [sp, #0]
    // TODO(kreeger): doc me - VectorBatchVectorAssign
    const float* bias_data = GetTensorData<float>(bias);
    float* output_data = GetTensorData<float>(output);
    for (int i = 0; i < batch_size; ++i) {
   e2870:	2400      	movs	r4, #0
   e2872:	ea4f 0e83 	mov.w	lr, r3, lsl #2
   e2876:	4284      	cmp	r4, r0
   e2878:	db0b      	blt.n	e2892 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0xde>
   e287a:	9b00      	ldr	r3, [sp, #0]
   e287c:	ea4f 0983 	mov.w	r9, r3, lsl #2
   e2880:	9b10      	ldr	r3, [sp, #64]	; 0x40
        *output_ptr++ = *bias_ptr++;
      }
    }
  } else {
    float* output_data = GetTensorData<float>(output);
    for (int i = 0; i < batch_size * num_units; ++i) {
   e2882:	2500      	movs	r5, #0
   e2884:	ea23 7ee3 	bic.w	lr, r3, r3, asr #31
   e2888:	ea4f 0e8e 	mov.w	lr, lr, lsl #2
   e288c:	462e      	mov	r6, r5
   e288e:	462f      	mov	r7, r5
   e2890:	e021      	b.n	e28d6 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x122>
   e2892:	460e      	mov	r6, r1
    // TODO(kreeger): doc me - VectorBatchVectorAssign
    const float* bias_data = GetTensorData<float>(bias);
    float* output_data = GetTensorData<float>(output);
    for (int i = 0; i < batch_size; ++i) {
      float* output_ptr = output_data + i * num_units;
      const float* bias_ptr = bias_data;
   e2894:	4667      	mov	r7, ip
      for (int j = 0; j < num_units; ++j) {
   e2896:	2500      	movs	r5, #0
   e2898:	9b00      	ldr	r3, [sp, #0]
   e289a:	429d      	cmp	r5, r3
   e289c:	da05      	bge.n	e28aa <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0xf6>
        *output_ptr++ = *bias_ptr++;
   e289e:	f857 8b04 	ldr.w	r8, [r7], #4
   e28a2:	f846 8b04 	str.w	r8, [r6], #4
    const float* bias_data = GetTensorData<float>(bias);
    float* output_data = GetTensorData<float>(output);
    for (int i = 0; i < batch_size; ++i) {
      float* output_ptr = output_data + i * num_units;
      const float* bias_ptr = bias_data;
      for (int j = 0; j < num_units; ++j) {
   e28a6:	3501      	adds	r5, #1
   e28a8:	e7f6      	b.n	e2898 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0xe4>
  // Initialize output with bias if provided.
  if (bias) {
    // TODO(kreeger): doc me - VectorBatchVectorAssign
    const float* bias_data = GetTensorData<float>(bias);
    float* output_data = GetTensorData<float>(output);
    for (int i = 0; i < batch_size; ++i) {
   e28aa:	3401      	adds	r4, #1
   e28ac:	4471      	add	r1, lr
   e28ae:	e7e2      	b.n	e2876 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0xc2>
   e28b0:	b10a      	cbz	r2, e28b6 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x102>
   e28b2:	6854      	ldr	r4, [r2, #4]
   e28b4:	e000      	b.n	e28b8 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x104>
   e28b6:	4614      	mov	r4, r2
        *output_ptr++ = *bias_ptr++;
      }
    }
  } else {
    float* output_data = GetTensorData<float>(output);
    for (int i = 0; i < batch_size * num_units; ++i) {
   e28b8:	9b00      	ldr	r3, [sp, #0]
   e28ba:	2100      	movs	r1, #0
   e28bc:	fb03 f500 	mul.w	r5, r3, r0
      *output_data++ = 0.0f;
   e28c0:	2600      	movs	r6, #0
        *output_ptr++ = *bias_ptr++;
      }
    }
  } else {
    float* output_data = GetTensorData<float>(output);
    for (int i = 0; i < batch_size * num_units; ++i) {
   e28c2:	42a9      	cmp	r1, r5
   e28c4:	dad9      	bge.n	e287a <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0xc6>
      *output_data++ = 0.0f;
   e28c6:	f844 6b04 	str.w	r6, [r4], #4
        *output_ptr++ = *bias_ptr++;
      }
    }
  } else {
    float* output_data = GetTensorData<float>(output);
    for (int i = 0; i < batch_size * num_units; ++i) {
   e28ca:	3101      	adds	r1, #1
   e28cc:	e7f9      	b.n	e28c2 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x10e>
   e28ce:	9b04      	ldr	r3, [sp, #16]
      *output_data++ = 0.0f;
    }
  }

  // Reduction sum.
  for (int b = 0; b < batch_size; ++b) {
   e28d0:	3701      	adds	r7, #1
   e28d2:	441e      	add	r6, r3
   e28d4:	444d      	add	r5, r9
   e28d6:	4287      	cmp	r7, r0
   e28d8:	da25      	bge.n	e2926 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x172>
   e28da:	b10a      	cbz	r2, e28e0 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x12c>
   e28dc:	6851      	ldr	r1, [r2, #4]
   e28de:	e000      	b.n	e28e2 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x12e>
   e28e0:	4611      	mov	r1, r2
   e28e2:	9b15      	ldr	r3, [sp, #84]	; 0x54
   e28e4:	b10b      	cbz	r3, e28ea <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x136>
   e28e6:	685c      	ldr	r4, [r3, #4]
   e28e8:	e000      	b.n	e28ec <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x138>
   e28ea:	9c15      	ldr	r4, [sp, #84]	; 0x54
    float* output_ptr_batch = GetTensorData<float>(output) + b * num_units;
    float* scratch_ptr_batch = GetTensorData<float>(scratch) + b * num_filters;
   e28ec:	4434      	add	r4, r6
   e28ee:	4429      	add	r1, r5

    // Reduction sum vector
    const float* input_vector_ptr = scratch_ptr_batch;
    for (int i = 0; i < num_units; ++i) {
   e28f0:	f04f 0c00 	mov.w	ip, #0
   e28f4:	9b00      	ldr	r3, [sp, #0]
   e28f6:	459c      	cmp	ip, r3
   e28f8:	dae9      	bge.n	e28ce <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x11a>
   e28fa:	46a2      	mov	sl, r4
   e28fc:	f04f 0800 	mov.w	r8, #0
      for (int j = 0; j < rank; j++) {
   e2900:	9b10      	ldr	r3, [sp, #64]	; 0x40
   e2902:	4598      	cmp	r8, r3
   e2904:	da0a      	bge.n	e291c <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x168>
        output_ptr_batch[i] += *input_vector_ptr++;
   e2906:	edd1 7a00 	vldr	s15, [r1]
   e290a:	ecba 7a01 	vldmia	sl!, {s14}
   e290e:	ee77 7a87 	vadd.f32	s15, s15, s14
    float* scratch_ptr_batch = GetTensorData<float>(scratch) + b * num_filters;

    // Reduction sum vector
    const float* input_vector_ptr = scratch_ptr_batch;
    for (int i = 0; i < num_units; ++i) {
      for (int j = 0; j < rank; j++) {
   e2912:	f108 0801 	add.w	r8, r8, #1
        output_ptr_batch[i] += *input_vector_ptr++;
   e2916:	edc1 7a00 	vstr	s15, [r1]
    float* scratch_ptr_batch = GetTensorData<float>(scratch) + b * num_filters;

    // Reduction sum vector
    const float* input_vector_ptr = scratch_ptr_batch;
    for (int i = 0; i < num_units; ++i) {
      for (int j = 0; j < rank; j++) {
   e291a:	e7f1      	b.n	e2900 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x14c>
   e291c:	4474      	add	r4, lr
    float* output_ptr_batch = GetTensorData<float>(output) + b * num_units;
    float* scratch_ptr_batch = GetTensorData<float>(scratch) + b * num_filters;

    // Reduction sum vector
    const float* input_vector_ptr = scratch_ptr_batch;
    for (int i = 0; i < num_units; ++i) {
   e291e:	f10c 0c01 	add.w	ip, ip, #1
   e2922:	3104      	adds	r1, #4
   e2924:	e7e6      	b.n	e28f4 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x140>
   e2926:	2400      	movs	r4, #0
inline float ActivationValFloat(TfLiteFusedActivation act, float a) {
  switch (act) {
    case kTfLiteActNone:
      return a;
    case kTfLiteActRelu:
      return a < 0.f ? 0.f : a;
   e2928:	ed9f 7a24 	vldr	s14, [pc, #144]	; e29bc <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x208>
   e292c:	4625      	mov	r5, r4
      }
    }
  }

  // Apply activation.
  for (int b = 0; b < batch_size; ++b) {
   e292e:	4285      	cmp	r5, r0
   e2930:	da20      	bge.n	e2974 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1c0>
   e2932:	b10a      	cbz	r2, e2938 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x184>
   e2934:	6851      	ldr	r1, [r2, #4]
   e2936:	e000      	b.n	e293a <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x186>
   e2938:	4611      	mov	r1, r2
    float* output_ptr_batch = GetTensorData<float>(output) + b * num_units;
   e293a:	4421      	add	r1, r4
    for (int i = 0; i < num_units; ++i) {
   e293c:	2600      	movs	r6, #0
   e293e:	9b00      	ldr	r3, [sp, #0]
   e2940:	429e      	cmp	r6, r3
   e2942:	da14      	bge.n	e296e <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1ba>
namespace ops {
namespace micro {

// Returns the floating point value for a fused activation:
inline float ActivationValFloat(TfLiteFusedActivation act, float a) {
  switch (act) {
   e2944:	9b05      	ldr	r3, [sp, #20]
      *output_ptr_batch = ActivationValFloat(activation, *output_ptr_batch);
   e2946:	edd1 7a00 	vldr	s15, [r1]
   e294a:	b163      	cbz	r3, e2966 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1b2>
   e294c:	2b01      	cmp	r3, #1
   e294e:	d107      	bne.n	e2960 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1ac>
    case kTfLiteActNone:
      return a;
    case kTfLiteActRelu:
      return a < 0.f ? 0.f : a;
   e2950:	eef5 7a40 	vcmp.f32	s15, #0.0
   e2954:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e2958:	bf48      	it	mi
   e295a:	eef0 7a47 	vmovmi.f32	s15, s14
   e295e:	e002      	b.n	e2966 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1b2>
    default:
      // TODO(kreeger): Implement more activations.
      exit(1);
   e2960:	2001      	movs	r0, #1
   e2962:	f006 f8db 	bl	e8b1c <exit>
   e2966:	ece1 7a01 	vstmia	r1!, {s15}
  }

  // Apply activation.
  for (int b = 0; b < batch_size; ++b) {
    float* output_ptr_batch = GetTensorData<float>(output) + b * num_units;
    for (int i = 0; i < num_units; ++i) {
   e296a:	3601      	adds	r6, #1
   e296c:	e7e7      	b.n	e293e <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x18a>
      }
    }
  }

  // Apply activation.
  for (int b = 0; b < batch_size; ++b) {
   e296e:	3501      	adds	r5, #1
   e2970:	444c      	add	r4, r9
   e2972:	e7dc      	b.n	e292e <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x17a>
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int f = 0; f < num_filters; ++f) {
      // Shift the vector left:
      float* batch_ptr = state_ptr_batch;
      float* batch_start = state_ptr_batch + 1;
      float* batch_end = state_ptr_batch + memory_size;
   e2974:	9b01      	ldr	r3, [sp, #4]
      while (batch_start != batch_end) {
        *batch_ptr++ = *batch_start++;
      }
      state_ptr_batch[memory_size - 1] = 0.0f;
   e2976:	2200      	movs	r2, #0
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int f = 0; f < num_filters; ++f) {
      // Shift the vector left:
      float* batch_ptr = state_ptr_batch;
      float* batch_start = state_ptr_batch + 1;
      float* batch_end = state_ptr_batch + memory_size;
   e2978:	0099      	lsls	r1, r3, #2
      while (batch_start != batch_end) {
        *batch_ptr++ = *batch_start++;
      }
      state_ptr_batch[memory_size - 1] = 0.0f;
   e297a:	4615      	mov	r5, r2
   e297c:	2700      	movs	r7, #0
    }
  }

  // Left shift the activation_state to make room for next cycle's activation.
  // TODO(alanchiao): explore collapsing this into a single loop.
  for (int b = 0; b < batch_size; ++b) {
   e297e:	4285      	cmp	r5, r0
   e2980:	da19      	bge.n	e29b6 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x202>
   e2982:	9b14      	ldr	r3, [sp, #80]	; 0x50
   e2984:	b10b      	cbz	r3, e298a <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1d6>
   e2986:	685b      	ldr	r3, [r3, #4]
   e2988:	e000      	b.n	e298c <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1d8>
   e298a:	9b14      	ldr	r3, [sp, #80]	; 0x50
    float* state_ptr_batch =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
   e298c:	4413      	add	r3, r2
    for (int f = 0; f < num_filters; ++f) {
   e298e:	2600      	movs	r6, #0
   e2990:	455e      	cmp	r6, fp
   e2992:	da0c      	bge.n	e29ae <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1fa>
      // Shift the vector left:
      float* batch_ptr = state_ptr_batch;
      float* batch_start = state_ptr_batch + 1;
   e2994:	1d1c      	adds	r4, r3, #4
      float* batch_end = state_ptr_batch + memory_size;
   e2996:	440b      	add	r3, r1
      while (batch_start != batch_end) {
   e2998:	429c      	cmp	r4, r3
   e299a:	d004      	beq.n	e29a6 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1f2>
        *batch_ptr++ = *batch_start++;
   e299c:	f854 eb04 	ldr.w	lr, [r4], #4
   e29a0:	f844 ec08 	str.w	lr, [r4, #-8]
    for (int f = 0; f < num_filters; ++f) {
      // Shift the vector left:
      float* batch_ptr = state_ptr_batch;
      float* batch_start = state_ptr_batch + 1;
      float* batch_end = state_ptr_batch + memory_size;
      while (batch_start != batch_end) {
   e29a4:	e7f8      	b.n	e2998 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1e4>
        *batch_ptr++ = *batch_start++;
      }
      state_ptr_batch[memory_size - 1] = 0.0f;
   e29a6:	f843 7c04 	str.w	r7, [r3, #-4]
  // Left shift the activation_state to make room for next cycle's activation.
  // TODO(alanchiao): explore collapsing this into a single loop.
  for (int b = 0; b < batch_size; ++b) {
    float* state_ptr_batch =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int f = 0; f < num_filters; ++f) {
   e29aa:	3601      	adds	r6, #1
   e29ac:	e7f0      	b.n	e2990 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1dc>
   e29ae:	9b03      	ldr	r3, [sp, #12]
    }
  }

  // Left shift the activation_state to make room for next cycle's activation.
  // TODO(alanchiao): explore collapsing this into a single loop.
  for (int b = 0; b < batch_size; ++b) {
   e29b0:	3501      	adds	r5, #1
   e29b2:	441a      	add	r2, r3
   e29b4:	e7e3      	b.n	e297e <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_+0x1ca>
      }
      state_ptr_batch[memory_size - 1] = 0.0f;
      state_ptr_batch += memory_size;
    }
  }
}
   e29b6:	b007      	add	sp, #28
   e29b8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e29bc:	00000000 	.word	0x00000000

000e29c0 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode>:
  return nullptr;
}

void Free(TfLiteContext* context, void* buffer) {}

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   e29c0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  // [4] = Activation State (variable),
  //         {2, batch_size, memory_size * num_filters}
  // TODO(kreeger): Use input tensor as variable until scratch tensor allocation
  // has been implemented (cl/263032056)
  // TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);
  TF_LITE_ENSURE_EQ(context, node->inputs->size, 6);
   e29c4:	680d      	ldr	r5, [r1, #0]
   e29c6:	682b      	ldr	r3, [r5, #0]
   e29c8:	2b06      	cmp	r3, #6
  return nullptr;
}

void Free(TfLiteContext* context, void* buffer) {}

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   e29ca:	b087      	sub	sp, #28
   e29cc:	4607      	mov	r7, r0
   e29ce:	4689      	mov	r9, r1
  // [4] = Activation State (variable),
  //         {2, batch_size, memory_size * num_filters}
  // TODO(kreeger): Use input tensor as variable until scratch tensor allocation
  // has been implemented (cl/263032056)
  // TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);
  TF_LITE_ENSURE_EQ(context, node->inputs->size, 6);
   e29d0:	d00e      	beq.n	e29f0 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x30>
   e29d2:	9302      	str	r3, [sp, #8]
   e29d4:	4b9f      	ldr	r3, [pc, #636]	; (e2c54 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x294>)
   e29d6:	9301      	str	r3, [sp, #4]
   e29d8:	2206      	movs	r2, #6
   e29da:	4b9f      	ldr	r3, [pc, #636]	; (e2c58 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x298>)
   e29dc:	9203      	str	r2, [sp, #12]
   e29de:	9300      	str	r3, [sp, #0]
   e29e0:	6944      	ldr	r4, [r0, #20]
   e29e2:	4a9e      	ldr	r2, [pc, #632]	; (e2c5c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x29c>)
   e29e4:	499e      	ldr	r1, [pc, #632]	; (e2c60 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2a0>)
   e29e6:	f44f 739f 	mov.w	r3, #318	; 0x13e
   e29ea:	47a0      	blx	r4
   e29ec:	2001      	movs	r0, #1
   e29ee:	e297      	b.n	e2f20 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x560>
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e29f0:	68a9      	ldr	r1, [r5, #8]
   e29f2:	6883      	ldr	r3, [r0, #8]
   e29f4:	686c      	ldr	r4, [r5, #4]
   e29f6:	2238      	movs	r2, #56	; 0x38
   e29f8:	4351      	muls	r1, r2
   e29fa:	1858      	adds	r0, r3, r1
   e29fc:	9105      	str	r1, [sp, #20]
}

inline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
   e29fe:	6929      	ldr	r1, [r5, #16]

  // Define input constants based on input tensor definition above:
  const int rank = params->rank;
  const int input_size = input->dims->data[1];
  const int batch_size = input->dims->data[0];
  const int num_filters = weights_feature->dims->data[0];
   e2a00:	6880      	ldr	r0, [r0, #8]
  if (use_tensor) {
   e2a02:	f1b1 3fff 	cmp.w	r1, #4294967295	; 0xffffffff
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e2a06:	fb02 f404 	mul.w	r4, r2, r4
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
    return &context
                ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e2a0a:	bf18      	it	ne
   e2a0c:	fb02 3e01 	mlane	lr, r2, r1, r3
  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);
  TfLiteTensor* activation_state =
      &context->tensors[node->inputs->data[kInputActivationStateTensor]];

  // Define input constants based on input tensor definition above:
  const int rank = params->rank;
   e2a10:	f8d9 2014 	ldr.w	r2, [r9, #20]
  const int input_size = input->dims->data[1];
  const int batch_size = input->dims->data[0];
  const int num_filters = weights_feature->dims->data[0];
   e2a14:	6841      	ldr	r1, [r0, #4]
  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);
  TfLiteTensor* activation_state =
      &context->tensors[node->inputs->data[kInputActivationStateTensor]];

  // Define input constants based on input tensor definition above:
  const int rank = params->rank;
   e2a16:	6812      	ldr	r2, [r2, #0]
  const int input_size = input->dims->data[1];
  const int batch_size = input->dims->data[0];
  const int num_filters = weights_feature->dims->data[0];
  TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);
   e2a18:	fb91 fbf2 	sdiv	fp, r1, r2
   e2a1c:	fb02 121b 	mls	r2, r2, fp, r1
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e2a20:	eb03 0604 	add.w	r6, r3, r4
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
    return &context
                ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
  }
  return nullptr;
   e2a24:	bf08      	it	eq
   e2a26:	f04f 0e00 	moveq.w	lr, #0
   e2a2a:	b152      	cbz	r2, e2a42 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x82>
   e2a2c:	2300      	movs	r3, #0
   e2a2e:	9303      	str	r3, [sp, #12]
   e2a30:	4b8c      	ldr	r3, [pc, #560]	; (e2c64 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2a4>)
   e2a32:	9301      	str	r3, [sp, #4]
   e2a34:	4b8c      	ldr	r3, [pc, #560]	; (e2c68 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2a8>)
   e2a36:	9300      	str	r3, [sp, #0]
   e2a38:	9202      	str	r2, [sp, #8]
   e2a3a:	697c      	ldr	r4, [r7, #20]
   e2a3c:	f240 134d 	movw	r3, #333	; 0x14d
   e2a40:	e21e      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
  const int num_units = num_filters / rank;
  const int memory_size = weights_time->dims->data[1];

  // Validate Input Tensor:
  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);
   e2a42:	5d1c      	ldrb	r4, [r3, r4]
   e2a44:	2c01      	cmp	r4, #1
   e2a46:	d00a      	beq.n	e2a5e <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x9e>
   e2a48:	4b88      	ldr	r3, [pc, #544]	; (e2c6c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2ac>)
   e2a4a:	9301      	str	r3, [sp, #4]
   e2a4c:	2501      	movs	r5, #1
   e2a4e:	4b88      	ldr	r3, [pc, #544]	; (e2c70 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2b0>)
   e2a50:	9300      	str	r3, [sp, #0]
   e2a52:	9503      	str	r5, [sp, #12]
   e2a54:	9402      	str	r4, [sp, #8]
   e2a56:	697c      	ldr	r4, [r7, #20]
   e2a58:	f44f 73a9 	mov.w	r3, #338	; 0x152
   e2a5c:	e210      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
  TfLiteTensor* activation_state =
      &context->tensors[node->inputs->data[kInputActivationStateTensor]];

  // Define input constants based on input tensor definition above:
  const int rank = params->rank;
  const int input_size = input->dims->data[1];
   e2a5e:	68b6      	ldr	r6, [r6, #8]
#include "tensorflow/lite/c/builtin_op_data.h"
#include "tensorflow/lite/c/c_api_internal.h"

namespace tflite {

inline int NumDimensions(const TfLiteTensor* t) { return t->dims->size; }
   e2a60:	6832      	ldr	r2, [r6, #0]
  const int num_units = num_filters / rank;
  const int memory_size = weights_time->dims->data[1];

  // Validate Input Tensor:
  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);
  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 2);
   e2a62:	2a02      	cmp	r2, #2
   e2a64:	d00a      	beq.n	e2a7c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0xbc>
   e2a66:	2302      	movs	r3, #2
   e2a68:	9303      	str	r3, [sp, #12]
   e2a6a:	4b82      	ldr	r3, [pc, #520]	; (e2c74 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2b4>)
   e2a6c:	9301      	str	r3, [sp, #4]
   e2a6e:	4b82      	ldr	r3, [pc, #520]	; (e2c78 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2b8>)
   e2a70:	9300      	str	r3, [sp, #0]
   e2a72:	9202      	str	r2, [sp, #8]
   e2a74:	697d      	ldr	r5, [r7, #20]
   e2a76:	f240 1353 	movw	r3, #339	; 0x153
   e2a7a:	e22f      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
   e2a7c:	f8d0 8000 	ldr.w	r8, [r0]

  // Validate Weights Feature Input Tensor:
  TF_LITE_ENSURE_EQ(context, NumDimensions(weights_feature), 2);
   e2a80:	f1b8 0f02 	cmp.w	r8, #2
   e2a84:	d00a      	beq.n	e2a9c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0xdc>
   e2a86:	4b7b      	ldr	r3, [pc, #492]	; (e2c74 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2b4>)
   e2a88:	9301      	str	r3, [sp, #4]
   e2a8a:	4b7c      	ldr	r3, [pc, #496]	; (e2c7c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2bc>)
   e2a8c:	9300      	str	r3, [sp, #0]
   e2a8e:	9203      	str	r2, [sp, #12]
   e2a90:	f8cd 8008 	str.w	r8, [sp, #8]
   e2a94:	697d      	ldr	r5, [r7, #20]
   e2a96:	f44f 73ab 	mov.w	r3, #342	; 0x156
   e2a9a:	e21f      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
  TfLiteTensor* activation_state =
      &context->tensors[node->inputs->data[kInputActivationStateTensor]];

  // Define input constants based on input tensor definition above:
  const int rank = params->rank;
  const int input_size = input->dims->data[1];
   e2a9c:	f8d6 c008 	ldr.w	ip, [r6, #8]
  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);
  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 2);

  // Validate Weights Feature Input Tensor:
  TF_LITE_ENSURE_EQ(context, NumDimensions(weights_feature), 2);
  TF_LITE_ENSURE_EQ(context, weights_feature->dims->data[1], input_size);
   e2aa0:	6882      	ldr	r2, [r0, #8]
   e2aa2:	4594      	cmp	ip, r2
   e2aa4:	d00a      	beq.n	e2abc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0xfc>
   e2aa6:	4b76      	ldr	r3, [pc, #472]	; (e2c80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2c0>)
   e2aa8:	9301      	str	r3, [sp, #4]
   e2aaa:	4b76      	ldr	r3, [pc, #472]	; (e2c84 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2c4>)
   e2aac:	9300      	str	r3, [sp, #0]
   e2aae:	f8cd c00c 	str.w	ip, [sp, #12]
   e2ab2:	9202      	str	r2, [sp, #8]
   e2ab4:	697d      	ldr	r5, [r7, #20]
   e2ab6:	f240 1357 	movw	r3, #343	; 0x157
   e2aba:	e20f      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e2abc:	68ea      	ldr	r2, [r5, #12]
   e2abe:	f04f 0c38 	mov.w	ip, #56	; 0x38
   e2ac2:	fb0c fc02 	mul.w	ip, ip, r2
   e2ac6:	eb03 020c 	add.w	r2, r3, ip
   e2aca:	9204      	str	r2, [sp, #16]
  const int input_size = input->dims->data[1];
  const int batch_size = input->dims->data[0];
  const int num_filters = weights_feature->dims->data[0];
  TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);
  const int num_units = num_filters / rank;
  const int memory_size = weights_time->dims->data[1];
   e2acc:	6890      	ldr	r0, [r2, #8]
#include "tensorflow/lite/c/builtin_op_data.h"
#include "tensorflow/lite/c/c_api_internal.h"

namespace tflite {

inline int NumDimensions(const TfLiteTensor* t) { return t->dims->size; }
   e2ace:	6802      	ldr	r2, [r0, #0]
  // Validate Weights Feature Input Tensor:
  TF_LITE_ENSURE_EQ(context, NumDimensions(weights_feature), 2);
  TF_LITE_ENSURE_EQ(context, weights_feature->dims->data[1], input_size);

  // Validate Weights Time Input Tensor:
  TF_LITE_ENSURE_EQ(context, NumDimensions(weights_time), 2);
   e2ad0:	2a02      	cmp	r2, #2
   e2ad2:	d00a      	beq.n	e2aea <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x12a>
   e2ad4:	4b67      	ldr	r3, [pc, #412]	; (e2c74 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2b4>)
   e2ad6:	9301      	str	r3, [sp, #4]
   e2ad8:	4b6b      	ldr	r3, [pc, #428]	; (e2c88 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2c8>)
   e2ada:	9300      	str	r3, [sp, #0]
   e2adc:	f8cd 800c 	str.w	r8, [sp, #12]
   e2ae0:	9202      	str	r2, [sp, #8]
   e2ae2:	697d      	ldr	r5, [r7, #20]
   e2ae4:	f44f 73ad 	mov.w	r3, #346	; 0x15a
   e2ae8:	e1f8      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
  TF_LITE_ENSURE_EQ(context, weights_time->dims->data[0], num_filters);
   e2aea:	6842      	ldr	r2, [r0, #4]
   e2aec:	4291      	cmp	r1, r2
   e2aee:	d009      	beq.n	e2b04 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x144>
   e2af0:	4b66      	ldr	r3, [pc, #408]	; (e2c8c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2cc>)
   e2af2:	9301      	str	r3, [sp, #4]
   e2af4:	4b66      	ldr	r3, [pc, #408]	; (e2c90 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2d0>)
   e2af6:	9300      	str	r3, [sp, #0]
   e2af8:	9103      	str	r1, [sp, #12]
   e2afa:	9202      	str	r2, [sp, #8]
   e2afc:	697d      	ldr	r5, [r7, #20]
   e2afe:	f240 135b 	movw	r3, #347	; 0x15b
   e2b02:	e1eb      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
  TF_LITE_ENSURE_EQ(context, weights_time->dims->data[1], memory_size);

  // Validate Optional Bias Input Tensor:
  if (bias) {
   e2b04:	f1be 0f00 	cmp.w	lr, #0
   e2b08:	d01e      	beq.n	e2b48 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x188>
    TF_LITE_ENSURE_EQ(context, bias->dims->data[0], num_units);
   e2b0a:	f8de 2008 	ldr.w	r2, [lr, #8]
   e2b0e:	6852      	ldr	r2, [r2, #4]
   e2b10:	4593      	cmp	fp, r2
   e2b12:	d00a      	beq.n	e2b2a <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x16a>
   e2b14:	4b5f      	ldr	r3, [pc, #380]	; (e2c94 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2d4>)
   e2b16:	9301      	str	r3, [sp, #4]
   e2b18:	4b5f      	ldr	r3, [pc, #380]	; (e2c98 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2d8>)
   e2b1a:	9300      	str	r3, [sp, #0]
   e2b1c:	f8cd b00c 	str.w	fp, [sp, #12]
   e2b20:	9202      	str	r2, [sp, #8]
   e2b22:	697d      	ldr	r5, [r7, #20]
   e2b24:	f44f 73b0 	mov.w	r3, #352	; 0x160
   e2b28:	e1d8      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
    TF_LITE_ENSURE_EQ(context, bias->type, kTfLiteFloat32);
   e2b2a:	f89e 2000 	ldrb.w	r2, [lr]
   e2b2e:	2a01      	cmp	r2, #1
   e2b30:	d00a      	beq.n	e2b48 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x188>
   e2b32:	4b4e      	ldr	r3, [pc, #312]	; (e2c6c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2ac>)
   e2b34:	9301      	str	r3, [sp, #4]
   e2b36:	2401      	movs	r4, #1
   e2b38:	4b58      	ldr	r3, [pc, #352]	; (e2c9c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2dc>)
   e2b3a:	9300      	str	r3, [sp, #0]
   e2b3c:	9403      	str	r4, [sp, #12]
   e2b3e:	9202      	str	r2, [sp, #8]
   e2b40:	697d      	ldr	r5, [r7, #20]
   e2b42:	f240 1361 	movw	r3, #353	; 0x161
   e2b46:	e1c9      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
      GetInput(context, node, kWeightsFeatureTensor);
  const TfLiteTensor* weights_time =
      GetInput(context, node, kWeightsTimeTensor);
  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);
  TfLiteTensor* activation_state =
      &context->tensors[node->inputs->data[kInputActivationStateTensor]];
   e2b48:	696a      	ldr	r2, [r5, #20]
   e2b4a:	f04f 0a38 	mov.w	sl, #56	; 0x38
   e2b4e:	fb0a f202 	mul.w	r2, sl, r2
   e2b52:	eb03 0e02 	add.w	lr, r3, r2
    TF_LITE_ENSURE_EQ(context, bias->dims->data[0], num_units);
    TF_LITE_ENSURE_EQ(context, bias->type, kTfLiteFloat32);
  }

  // Validate Activation State Input Tensor:
  TF_LITE_ENSURE_EQ(context, activation_state->type, kTfLiteFloat32);
   e2b56:	5c9c      	ldrb	r4, [r3, r2]
   e2b58:	2c01      	cmp	r4, #1
   e2b5a:	d00a      	beq.n	e2b72 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x1b2>
   e2b5c:	4b43      	ldr	r3, [pc, #268]	; (e2c6c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2ac>)
   e2b5e:	9301      	str	r3, [sp, #4]
   e2b60:	2501      	movs	r5, #1
   e2b62:	4b4f      	ldr	r3, [pc, #316]	; (e2ca0 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2e0>)
   e2b64:	9300      	str	r3, [sp, #0]
   e2b66:	9503      	str	r5, [sp, #12]
   e2b68:	9402      	str	r4, [sp, #8]
   e2b6a:	697c      	ldr	r4, [r7, #20]
   e2b6c:	f240 1365 	movw	r3, #357	; 0x165
   e2b70:	e186      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
   e2b72:	f8de e008 	ldr.w	lr, [lr, #8]
   e2b76:	f8de 2000 	ldr.w	r2, [lr]
  TF_LITE_ENSURE_EQ(context, NumDimensions(activation_state), 2);
   e2b7a:	2a02      	cmp	r2, #2
   e2b7c:	d00a      	beq.n	e2b94 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x1d4>
   e2b7e:	2302      	movs	r3, #2
   e2b80:	9303      	str	r3, [sp, #12]
   e2b82:	4b3c      	ldr	r3, [pc, #240]	; (e2c74 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2b4>)
   e2b84:	9301      	str	r3, [sp, #4]
   e2b86:	4b47      	ldr	r3, [pc, #284]	; (e2ca4 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2e4>)
   e2b88:	9300      	str	r3, [sp, #0]
   e2b8a:	9202      	str	r2, [sp, #8]
   e2b8c:	697d      	ldr	r5, [r7, #20]
   e2b8e:	f44f 73b3 	mov.w	r3, #358	; 0x166
   e2b92:	e1a3      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
      &context->tensors[node->inputs->data[kInputActivationStateTensor]];

  // Define input constants based on input tensor definition above:
  const int rank = params->rank;
  const int input_size = input->dims->data[1];
  const int batch_size = input->dims->data[0];
   e2b94:	f8d6 8004 	ldr.w	r8, [r6, #4]
  }

  // Validate Activation State Input Tensor:
  TF_LITE_ENSURE_EQ(context, activation_state->type, kTfLiteFloat32);
  TF_LITE_ENSURE_EQ(context, NumDimensions(activation_state), 2);
  TF_LITE_ENSURE_EQ(context, activation_state->dims->data[0], batch_size);
   e2b98:	f8de 6004 	ldr.w	r6, [lr, #4]
   e2b9c:	45b0      	cmp	r8, r6
   e2b9e:	d00a      	beq.n	e2bb6 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x1f6>
   e2ba0:	4b41      	ldr	r3, [pc, #260]	; (e2ca8 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2e8>)
   e2ba2:	9301      	str	r3, [sp, #4]
   e2ba4:	4b41      	ldr	r3, [pc, #260]	; (e2cac <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2ec>)
   e2ba6:	9300      	str	r3, [sp, #0]
   e2ba8:	f8cd 800c 	str.w	r8, [sp, #12]
   e2bac:	9602      	str	r6, [sp, #8]
   e2bae:	697d      	ldr	r5, [r7, #20]
   e2bb0:	f240 1367 	movw	r3, #359	; 0x167
   e2bb4:	e192      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
  const int input_size = input->dims->data[1];
  const int batch_size = input->dims->data[0];
  const int num_filters = weights_feature->dims->data[0];
  TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);
  const int num_units = num_filters / rank;
  const int memory_size = weights_time->dims->data[1];
   e2bb6:	6880      	ldr	r0, [r0, #8]

  // Validate Activation State Input Tensor:
  TF_LITE_ENSURE_EQ(context, activation_state->type, kTfLiteFloat32);
  TF_LITE_ENSURE_EQ(context, NumDimensions(activation_state), 2);
  TF_LITE_ENSURE_EQ(context, activation_state->dims->data[0], batch_size);
  TF_LITE_ENSURE_EQ(context, activation_state->dims->data[1],
   e2bb8:	f8de 6008 	ldr.w	r6, [lr, #8]
   e2bbc:	fb00 fe01 	mul.w	lr, r0, r1
   e2bc0:	4576      	cmp	r6, lr
   e2bc2:	d00a      	beq.n	e2bda <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x21a>
   e2bc4:	4b3a      	ldr	r3, [pc, #232]	; (e2cb0 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2f0>)
   e2bc6:	9301      	str	r3, [sp, #4]
   e2bc8:	4b3a      	ldr	r3, [pc, #232]	; (e2cb4 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2f4>)
   e2bca:	9300      	str	r3, [sp, #0]
   e2bcc:	f8cd e00c 	str.w	lr, [sp, #12]
   e2bd0:	9602      	str	r6, [sp, #8]
   e2bd2:	697d      	ldr	r5, [r7, #20]
   e2bd4:	f240 1369 	movw	r3, #361	; 0x169
   e2bd8:	e180      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
  //       ApplyTimeWeightsBiasAndActivation():
  //         float, {2, batch_size, num_filters}
  // TODO(kreeger): Use input tensor as variable until scratch tensor allocation
  // has been implemented (cl/263032056)
  // TfLiteTensor* scratch_tensor = GetTemporary(context, node, 0);
  TfLiteTensor* scratch_tensor = &context->tensors[node->inputs->data[5]];
   e2bda:	69ad      	ldr	r5, [r5, #24]
   e2bdc:	fb0a fa05 	mul.w	sl, sl, r5
   e2be0:	eb03 060a 	add.w	r6, r3, sl

  TF_LITE_ENSURE_EQ(context, scratch_tensor->type, kTfLiteFloat32);
   e2be4:	f813 500a 	ldrb.w	r5, [r3, sl]
   e2be8:	2d01      	cmp	r5, #1
   e2bea:	d009      	beq.n	e2c00 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x240>
   e2bec:	4b1f      	ldr	r3, [pc, #124]	; (e2c6c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2ac>)
   e2bee:	9301      	str	r3, [sp, #4]
   e2bf0:	4b31      	ldr	r3, [pc, #196]	; (e2cb8 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2f8>)
   e2bf2:	9300      	str	r3, [sp, #0]
   e2bf4:	9403      	str	r4, [sp, #12]
   e2bf6:	9502      	str	r5, [sp, #8]
   e2bf8:	697d      	ldr	r5, [r7, #20]
   e2bfa:	f44f 73ba 	mov.w	r3, #372	; 0x174
   e2bfe:	e16d      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
   e2c00:	68b4      	ldr	r4, [r6, #8]
   e2c02:	6826      	ldr	r6, [r4, #0]
  TF_LITE_ENSURE_EQ(context, NumDimensions(scratch_tensor), 2);
   e2c04:	2e02      	cmp	r6, #2
   e2c06:	d009      	beq.n	e2c1c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x25c>
   e2c08:	4b1a      	ldr	r3, [pc, #104]	; (e2c74 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2b4>)
   e2c0a:	9301      	str	r3, [sp, #4]
   e2c0c:	4b2b      	ldr	r3, [pc, #172]	; (e2cbc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2fc>)
   e2c0e:	9300      	str	r3, [sp, #0]
   e2c10:	9203      	str	r2, [sp, #12]
   e2c12:	9602      	str	r6, [sp, #8]
   e2c14:	697c      	ldr	r4, [r7, #20]
   e2c16:	f240 1375 	movw	r3, #373	; 0x175
   e2c1a:	e131      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
  TF_LITE_ENSURE_EQ(context, scratch_tensor->dims->data[0], batch_size);
   e2c1c:	6862      	ldr	r2, [r4, #4]
   e2c1e:	4590      	cmp	r8, r2
   e2c20:	d00a      	beq.n	e2c38 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x278>
   e2c22:	4b21      	ldr	r3, [pc, #132]	; (e2ca8 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2e8>)
   e2c24:	9301      	str	r3, [sp, #4]
   e2c26:	4b26      	ldr	r3, [pc, #152]	; (e2cc0 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x300>)
   e2c28:	9300      	str	r3, [sp, #0]
   e2c2a:	f8cd 800c 	str.w	r8, [sp, #12]
   e2c2e:	9202      	str	r2, [sp, #8]
   e2c30:	697c      	ldr	r4, [r7, #20]
   e2c32:	f44f 73bb 	mov.w	r3, #374	; 0x176
   e2c36:	e123      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
  TF_LITE_ENSURE_EQ(context, scratch_tensor->dims->data[1], num_filters);
   e2c38:	68a2      	ldr	r2, [r4, #8]
   e2c3a:	4291      	cmp	r1, r2
   e2c3c:	d044      	beq.n	e2cc8 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x308>
   e2c3e:	4b13      	ldr	r3, [pc, #76]	; (e2c8c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2cc>)
   e2c40:	9301      	str	r3, [sp, #4]
   e2c42:	4b20      	ldr	r3, [pc, #128]	; (e2cc4 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x304>)
   e2c44:	9300      	str	r3, [sp, #0]
   e2c46:	9103      	str	r1, [sp, #12]
   e2c48:	9202      	str	r2, [sp, #8]
   e2c4a:	697c      	ldr	r4, [r7, #20]
   e2c4c:	f240 1377 	movw	r3, #375	; 0x177
   e2c50:	e116      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
   e2c52:	bf00      	nop
   e2c54:	000e8c70 	.word	0x000e8c70
   e2c58:	000ec5a5 	.word	0x000ec5a5
   e2c5c:	000ec4fa 	.word	0x000ec4fa
   e2c60:	000eb3b9 	.word	0x000eb3b9
   e2c64:	000eccce 	.word	0x000eccce
   e2c68:	000ec5b8 	.word	0x000ec5b8
   e2c6c:	000ebc41 	.word	0x000ebc41
   e2c70:	000eb3f4 	.word	0x000eb3f4
   e2c74:	000ebd87 	.word	0x000ebd87
   e2c78:	000ec1ef 	.word	0x000ec1ef
   e2c7c:	000ec5cb 	.word	0x000ec5cb
   e2c80:	000ec5ea 	.word	0x000ec5ea
   e2c84:	000ec5f5 	.word	0x000ec5f5
   e2c88:	000ec614 	.word	0x000ec614
   e2c8c:	000ec6c9 	.word	0x000ec6c9
   e2c90:	000ec90e 	.word	0x000ec90e
   e2c94:	000ec630 	.word	0x000ec630
   e2c98:	000ec63a 	.word	0x000ec63a
   e2c9c:	000ec64e 	.word	0x000ec64e
   e2ca0:	000ec659 	.word	0x000ec659
   e2ca4:	000ec670 	.word	0x000ec670
   e2ca8:	000ec690 	.word	0x000ec690
   e2cac:	000ec69b 	.word	0x000ec69b
   e2cb0:	000ec6bb 	.word	0x000ec6bb
   e2cb4:	000ec6d5 	.word	0x000ec6d5
   e2cb8:	000ec6f5 	.word	0x000ec6f5
   e2cbc:	000ec70a 	.word	0x000ec70a
   e2cc0:	000ec728 	.word	0x000ec728
   e2cc4:	000ec746 	.word	0x000ec746
   e2cc8:	9a05      	ldr	r2, [sp, #20]
   e2cca:	5c9c      	ldrb	r4, [r3, r2]
}

// Determines whether it is a hybrid op - one that has float inputs and
// quantized weights.
inline bool IsHybridOp(const TfLiteTensor* input, const TfLiteTensor* weight) {
  return ((weight->type == kTfLiteUInt8 || weight->type == kTfLiteInt8) &&
   e2ccc:	2c03      	cmp	r4, #3
   e2cce:	d002      	beq.n	e2cd6 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x316>
   e2cd0:	2c09      	cmp	r4, #9
   e2cd2:	f040 810a 	bne.w	e2eea <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x52a>
  // TODO(kreeger): Handle full quant svdf b/139435798
  if (is_hybrid_op) {
    // Validate Input Tensor dtypes:
    TF_LITE_ENSURE(context, weights_feature->type == kTfLiteUInt8 ||
                                weights_feature->type == kTfLiteInt8);
    TF_LITE_ENSURE(context, weights_time->type == kTfLiteUInt8 ||
   e2cd6:	f813 200c 	ldrb.w	r2, [r3, ip]
   e2cda:	2a03      	cmp	r2, #3
   e2cdc:	d007      	beq.n	e2cee <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x32e>
   e2cde:	2a09      	cmp	r2, #9
   e2ce0:	d005      	beq.n	e2cee <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x32e>
   e2ce2:	4b91      	ldr	r3, [pc, #580]	; (e2f28 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x568>)
   e2ce4:	9300      	str	r3, [sp, #0]
   e2ce6:	697c      	ldr	r4, [r7, #20]
   e2ce8:	f240 1381 	movw	r3, #385	; 0x181
   e2cec:	e026      	b.n	e2d3c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x37c>
    // Validate Scratch Tensors:
    // [0] = (shared - see above for usage)
    // [1] = Input Quantized, int8_t/uint8_t, {2, batch_size, input_size}
    // [2] = Scaling Factors, float, {1, batch_size}
    // [3] = Float Weights Time, float, {2, num_filters, memory_size}
    TF_LITE_ENSURE_EQ(context, node->temporaries->size, 4);
   e2cee:	f8d9 500c 	ldr.w	r5, [r9, #12]
   e2cf2:	682a      	ldr	r2, [r5, #0]
   e2cf4:	2a04      	cmp	r2, #4
   e2cf6:	d00a      	beq.n	e2d0e <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x34e>
   e2cf8:	2304      	movs	r3, #4
   e2cfa:	9303      	str	r3, [sp, #12]
   e2cfc:	4b8b      	ldr	r3, [pc, #556]	; (e2f2c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x56c>)
   e2cfe:	9301      	str	r3, [sp, #4]
   e2d00:	4b8b      	ldr	r3, [pc, #556]	; (e2f30 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x570>)
   e2d02:	9300      	str	r3, [sp, #0]
   e2d04:	9202      	str	r2, [sp, #8]
   e2d06:	697c      	ldr	r4, [r7, #20]
   e2d08:	f44f 73c4 	mov.w	r3, #392	; 0x188
   e2d0c:	e0b8      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
}
inline TfLiteTensor* GetTemporary(TfLiteContext* context, TfLiteNode* node,
                                  int index) {
  return &context->tensors[flatbuffers::EndianScalar(
      node->temporaries->data[index])];
   e2d0e:	68ae      	ldr	r6, [r5, #8]
   e2d10:	68ec      	ldr	r4, [r5, #12]
   e2d12:	692d      	ldr	r5, [r5, #16]
   e2d14:	2238      	movs	r2, #56	; 0x38
   e2d16:	4356      	muls	r6, r2
   e2d18:	4354      	muls	r4, r2
   e2d1a:	436a      	muls	r2, r5
    TfLiteTensor* scratch_input_quantized = GetTemporary(context, node, 1);
    TfLiteTensor* scratch_scaling_factors = GetTemporary(context, node, 2);
    TfLiteTensor* scratch_float_weights_time = GetTemporary(context, node, 3);

    // Validate Input Quantized Scratch Tensor:
    TF_LITE_ENSURE(context, scratch_input_quantized->type == kTfLiteUInt8 ||
   e2d1c:	5d9d      	ldrb	r5, [r3, r6]
   e2d1e:	2d03      	cmp	r5, #3
   e2d20:	eb03 0a06 	add.w	sl, r3, r6
   e2d24:	eb03 0c04 	add.w	ip, r3, r4
   e2d28:	eb03 0e02 	add.w	lr, r3, r2
   e2d2c:	d00b      	beq.n	e2d46 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x386>
   e2d2e:	2d09      	cmp	r5, #9
   e2d30:	d009      	beq.n	e2d46 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x386>
   e2d32:	4b80      	ldr	r3, [pc, #512]	; (e2f34 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x574>)
   e2d34:	9300      	str	r3, [sp, #0]
   e2d36:	697c      	ldr	r4, [r7, #20]
   e2d38:	f240 138f 	movw	r3, #399	; 0x18f
   e2d3c:	4a7e      	ldr	r2, [pc, #504]	; (e2f38 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x578>)
   e2d3e:	497f      	ldr	r1, [pc, #508]	; (e2f3c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x57c>)
   e2d40:	4638      	mov	r0, r7
   e2d42:	47a0      	blx	r4
   e2d44:	e652      	b.n	e29ec <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2c>
                                scratch_input_quantized->type == kTfLiteInt8);
    TF_LITE_ENSURE_EQ(context, scratch_input_quantized->dims->data[0],
   e2d46:	f8da 5008 	ldr.w	r5, [sl, #8]
   e2d4a:	686d      	ldr	r5, [r5, #4]
   e2d4c:	45a8      	cmp	r8, r5
   e2d4e:	d00a      	beq.n	e2d66 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x3a6>
   e2d50:	4b7b      	ldr	r3, [pc, #492]	; (e2f40 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x580>)
   e2d52:	9301      	str	r3, [sp, #4]
   e2d54:	4b7b      	ldr	r3, [pc, #492]	; (e2f44 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x584>)
   e2d56:	9300      	str	r3, [sp, #0]
   e2d58:	f8cd 800c 	str.w	r8, [sp, #12]
   e2d5c:	9502      	str	r5, [sp, #8]
   e2d5e:	697c      	ldr	r4, [r7, #20]
   e2d60:	f240 1391 	movw	r3, #401	; 0x191
   e2d64:	e08c      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
                      batch_size);

    // Validate Scaling Factors Scratch Tensor:
    TF_LITE_ENSURE_EQ(context, scratch_scaling_factors->type, kTfLiteFloat32);
   e2d66:	5d1e      	ldrb	r6, [r3, r4]
   e2d68:	2e01      	cmp	r6, #1
   e2d6a:	d00a      	beq.n	e2d82 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x3c2>
   e2d6c:	4b76      	ldr	r3, [pc, #472]	; (e2f48 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x588>)
   e2d6e:	9301      	str	r3, [sp, #4]
   e2d70:	2401      	movs	r4, #1
   e2d72:	4b76      	ldr	r3, [pc, #472]	; (e2f4c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x58c>)
   e2d74:	9300      	str	r3, [sp, #0]
   e2d76:	9403      	str	r4, [sp, #12]
   e2d78:	9602      	str	r6, [sp, #8]
   e2d7a:	697d      	ldr	r5, [r7, #20]
   e2d7c:	f44f 73ca 	mov.w	r3, #404	; 0x194
   e2d80:	e0ac      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
   e2d82:	f8dc 4008 	ldr.w	r4, [ip, #8]
#include "tensorflow/lite/c/builtin_op_data.h"
#include "tensorflow/lite/c/c_api_internal.h"

namespace tflite {

inline int NumDimensions(const TfLiteTensor* t) { return t->dims->size; }
   e2d86:	6825      	ldr	r5, [r4, #0]
    TF_LITE_ENSURE_EQ(context, NumDimensions(scratch_scaling_factors), 1);
   e2d88:	2d01      	cmp	r5, #1
   e2d8a:	d009      	beq.n	e2da0 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x3e0>
   e2d8c:	4b70      	ldr	r3, [pc, #448]	; (e2f50 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x590>)
   e2d8e:	9301      	str	r3, [sp, #4]
   e2d90:	4b70      	ldr	r3, [pc, #448]	; (e2f54 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x594>)
   e2d92:	9300      	str	r3, [sp, #0]
   e2d94:	9603      	str	r6, [sp, #12]
   e2d96:	9502      	str	r5, [sp, #8]
   e2d98:	697c      	ldr	r4, [r7, #20]
   e2d9a:	f240 1395 	movw	r3, #405	; 0x195
   e2d9e:	e06f      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
    TF_LITE_ENSURE_EQ(context, scratch_scaling_factors->dims->data[0],
   e2da0:	6864      	ldr	r4, [r4, #4]
   e2da2:	45a0      	cmp	r8, r4
   e2da4:	d00a      	beq.n	e2dbc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x3fc>
   e2da6:	4b66      	ldr	r3, [pc, #408]	; (e2f40 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x580>)
   e2da8:	9301      	str	r3, [sp, #4]
   e2daa:	4b6b      	ldr	r3, [pc, #428]	; (e2f58 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x598>)
   e2dac:	9300      	str	r3, [sp, #0]
   e2dae:	f8cd 800c 	str.w	r8, [sp, #12]
   e2db2:	9402      	str	r4, [sp, #8]
   e2db4:	697c      	ldr	r4, [r7, #20]
   e2db6:	f240 1397 	movw	r3, #407	; 0x197
   e2dba:	e061      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
                      batch_size);

    // Validate Float Weights Time Scratch Tensor:
    TF_LITE_ENSURE_EQ(context, scratch_float_weights_time->type,
   e2dbc:	5c9c      	ldrb	r4, [r3, r2]
   e2dbe:	2c01      	cmp	r4, #1
   e2dc0:	d009      	beq.n	e2dd6 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x416>
   e2dc2:	4b61      	ldr	r3, [pc, #388]	; (e2f48 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x588>)
   e2dc4:	9301      	str	r3, [sp, #4]
   e2dc6:	4b65      	ldr	r3, [pc, #404]	; (e2f5c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x59c>)
   e2dc8:	9300      	str	r3, [sp, #0]
   e2dca:	9503      	str	r5, [sp, #12]
   e2dcc:	9402      	str	r4, [sp, #8]
   e2dce:	697c      	ldr	r4, [r7, #20]
   e2dd0:	f240 139b 	movw	r3, #411	; 0x19b
   e2dd4:	e054      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
   e2dd6:	f8de 3008 	ldr.w	r3, [lr, #8]
   e2dda:	681a      	ldr	r2, [r3, #0]
                      kTfLiteFloat32);
    TF_LITE_ENSURE_EQ(context, NumDimensions(scratch_float_weights_time), 2);
   e2ddc:	2a02      	cmp	r2, #2
   e2dde:	d00a      	beq.n	e2df6 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x436>
   e2de0:	2302      	movs	r3, #2
   e2de2:	9303      	str	r3, [sp, #12]
   e2de4:	4b5e      	ldr	r3, [pc, #376]	; (e2f60 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5a0>)
   e2de6:	9301      	str	r3, [sp, #4]
   e2de8:	4b5e      	ldr	r3, [pc, #376]	; (e2f64 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5a4>)
   e2dea:	9300      	str	r3, [sp, #0]
   e2dec:	9202      	str	r2, [sp, #8]
   e2dee:	697d      	ldr	r5, [r7, #20]
   e2df0:	f44f 73ce 	mov.w	r3, #412	; 0x19c
   e2df4:	e072      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
    TF_LITE_ENSURE_EQ(context, scratch_float_weights_time->dims->data[0],
   e2df6:	685a      	ldr	r2, [r3, #4]
   e2df8:	4291      	cmp	r1, r2
   e2dfa:	d009      	beq.n	e2e10 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x450>
   e2dfc:	4b5a      	ldr	r3, [pc, #360]	; (e2f68 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5a8>)
   e2dfe:	9301      	str	r3, [sp, #4]
   e2e00:	4b5a      	ldr	r3, [pc, #360]	; (e2f6c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5ac>)
   e2e02:	9300      	str	r3, [sp, #0]
   e2e04:	9103      	str	r1, [sp, #12]
   e2e06:	9202      	str	r2, [sp, #8]
   e2e08:	697d      	ldr	r5, [r7, #20]
   e2e0a:	f44f 73cf 	mov.w	r3, #414	; 0x19e
   e2e0e:	e065      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
                      num_filters);
    TF_LITE_ENSURE_EQ(context, scratch_float_weights_time->dims->data[1],
   e2e10:	689b      	ldr	r3, [r3, #8]
   e2e12:	4298      	cmp	r0, r3
   e2e14:	d009      	beq.n	e2e2a <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x46a>
   e2e16:	9302      	str	r3, [sp, #8]
   e2e18:	4b55      	ldr	r3, [pc, #340]	; (e2f70 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5b0>)
   e2e1a:	9301      	str	r3, [sp, #4]
   e2e1c:	4b55      	ldr	r3, [pc, #340]	; (e2f74 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5b4>)
   e2e1e:	9300      	str	r3, [sp, #0]
   e2e20:	9003      	str	r0, [sp, #12]
   e2e22:	697d      	ldr	r5, [r7, #20]
   e2e24:	f44f 73d0 	mov.w	r3, #416	; 0x1a0
   e2e28:	e058      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
      weights_time_ptr = GetTensorData<int8_t>(weights_time);
    }
    SymmetricDequantize(weights_time_ptr,
                        NumElements(scratch_float_weights_time),
                        weights_time->params.scale,
                        GetTensorData<float>(scratch_float_weights_time));
   e2e2a:	9b04      	ldr	r3, [sp, #16]
   e2e2c:	f8de 2004 	ldr.w	r2, [lr, #4]
   e2e30:	ed93 0a03 	vldr	s0, [r3, #12]
   e2e34:	4341      	muls	r1, r0
   e2e36:	6858      	ldr	r0, [r3, #4]
   e2e38:	f7f4 fb54 	bl	d74e4 <_ZN6tflite19SymmetricDequantizeEPKaifPf>
    // TF_LITE_ENSURE_EQ(context, node->temporaries->size, 1);
  }

  // Validate Tensor Output:
  // [0] = float, {2, batch_size, num_units}
  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);
   e2e3c:	f8d9 3004 	ldr.w	r3, [r9, #4]
   e2e40:	681d      	ldr	r5, [r3, #0]
   e2e42:	2d01      	cmp	r5, #1
   e2e44:	d00a      	beq.n	e2e5c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x49c>
   e2e46:	4b42      	ldr	r3, [pc, #264]	; (e2f50 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x590>)
   e2e48:	9301      	str	r3, [sp, #4]
   e2e4a:	2401      	movs	r4, #1
   e2e4c:	4b4a      	ldr	r3, [pc, #296]	; (e2f78 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5b8>)
   e2e4e:	9300      	str	r3, [sp, #0]
   e2e50:	9403      	str	r4, [sp, #12]
   e2e52:	9502      	str	r5, [sp, #8]
   e2e54:	697d      	ldr	r5, [r7, #20]
   e2e56:	f44f 73e0 	mov.w	r3, #448	; 0x1c0
   e2e5a:	e03f      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e2e5c:	685a      	ldr	r2, [r3, #4]
   e2e5e:	2338      	movs	r3, #56	; 0x38
   e2e60:	4353      	muls	r3, r2
   e2e62:	68ba      	ldr	r2, [r7, #8]
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  TF_LITE_ENSURE_EQ(context, output->type, kTfLiteFloat32);
   e2e64:	5cd4      	ldrb	r4, [r2, r3]
   e2e66:	2c01      	cmp	r4, #1
   e2e68:	eb02 0103 	add.w	r1, r2, r3
   e2e6c:	d00c      	beq.n	e2e88 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c8>
   e2e6e:	4b36      	ldr	r3, [pc, #216]	; (e2f48 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x588>)
   e2e70:	9301      	str	r3, [sp, #4]
   e2e72:	4b42      	ldr	r3, [pc, #264]	; (e2f7c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5bc>)
   e2e74:	9300      	str	r3, [sp, #0]
   e2e76:	9503      	str	r5, [sp, #12]
   e2e78:	9402      	str	r4, [sp, #8]
   e2e7a:	697c      	ldr	r4, [r7, #20]
   e2e7c:	f44f 73e1 	mov.w	r3, #450	; 0x1c2
   e2e80:	4a2d      	ldr	r2, [pc, #180]	; (e2f38 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x578>)
   e2e82:	493f      	ldr	r1, [pc, #252]	; (e2f80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5c0>)
   e2e84:	4638      	mov	r0, r7
   e2e86:	e5b0      	b.n	e29ea <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2a>
   e2e88:	688b      	ldr	r3, [r1, #8]
#include "tensorflow/lite/c/builtin_op_data.h"
#include "tensorflow/lite/c/c_api_internal.h"

namespace tflite {

inline int NumDimensions(const TfLiteTensor* t) { return t->dims->size; }
   e2e8a:	681a      	ldr	r2, [r3, #0]
  TF_LITE_ENSURE_EQ(context, NumDimensions(output), 2);
   e2e8c:	2a02      	cmp	r2, #2
   e2e8e:	d00a      	beq.n	e2ea6 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4e6>
   e2e90:	2302      	movs	r3, #2
   e2e92:	9303      	str	r3, [sp, #12]
   e2e94:	4b32      	ldr	r3, [pc, #200]	; (e2f60 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5a0>)
   e2e96:	9301      	str	r3, [sp, #4]
   e2e98:	4b3a      	ldr	r3, [pc, #232]	; (e2f84 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5c4>)
   e2e9a:	9300      	str	r3, [sp, #0]
   e2e9c:	9202      	str	r2, [sp, #8]
   e2e9e:	697d      	ldr	r5, [r7, #20]
   e2ea0:	f240 13c3 	movw	r3, #451	; 0x1c3
   e2ea4:	e01a      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
  TF_LITE_ENSURE_EQ(context, output->dims->data[0], batch_size);
   e2ea6:	685a      	ldr	r2, [r3, #4]
   e2ea8:	4590      	cmp	r8, r2
   e2eaa:	d00a      	beq.n	e2ec2 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x502>
   e2eac:	4b24      	ldr	r3, [pc, #144]	; (e2f40 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x580>)
   e2eae:	9301      	str	r3, [sp, #4]
   e2eb0:	4b35      	ldr	r3, [pc, #212]	; (e2f88 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5c8>)
   e2eb2:	9300      	str	r3, [sp, #0]
   e2eb4:	f8cd 800c 	str.w	r8, [sp, #12]
   e2eb8:	9202      	str	r2, [sp, #8]
   e2eba:	697d      	ldr	r5, [r7, #20]
   e2ebc:	f44f 73e2 	mov.w	r3, #452	; 0x1c4
   e2ec0:	e00c      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
  TF_LITE_ENSURE_EQ(context, output->dims->data[1], num_units);
   e2ec2:	689b      	ldr	r3, [r3, #8]
   e2ec4:	459b      	cmp	fp, r3
   e2ec6:	d00e      	beq.n	e2ee6 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x526>
   e2ec8:	9302      	str	r3, [sp, #8]
   e2eca:	4b30      	ldr	r3, [pc, #192]	; (e2f8c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5cc>)
   e2ecc:	9301      	str	r3, [sp, #4]
   e2ece:	4b30      	ldr	r3, [pc, #192]	; (e2f90 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5d0>)
   e2ed0:	9300      	str	r3, [sp, #0]
   e2ed2:	f8cd b00c 	str.w	fp, [sp, #12]
   e2ed6:	697d      	ldr	r5, [r7, #20]
   e2ed8:	f240 13c5 	movw	r3, #453	; 0x1c5
   e2edc:	4a16      	ldr	r2, [pc, #88]	; (e2f38 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x578>)
   e2ede:	4928      	ldr	r1, [pc, #160]	; (e2f80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5c0>)
   e2ee0:	4638      	mov	r0, r7
   e2ee2:	47a8      	blx	r5
   e2ee4:	e582      	b.n	e29ec <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x2c>

  return kTfLiteOk;
   e2ee6:	2000      	movs	r0, #0
   e2ee8:	e01a      	b.n	e2f20 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x560>
                        NumElements(scratch_float_weights_time),
                        weights_time->params.scale,
                        GetTensorData<float>(scratch_float_weights_time));
  } else {
    // Validate Input Tensor dtypes:
    TF_LITE_ENSURE_EQ(context, weights_feature->type, kTfLiteFloat32);
   e2eea:	2c01      	cmp	r4, #1
   e2eec:	d00a      	beq.n	e2f04 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x544>
   e2eee:	4b16      	ldr	r3, [pc, #88]	; (e2f48 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x588>)
   e2ef0:	9301      	str	r3, [sp, #4]
   e2ef2:	2501      	movs	r5, #1
   e2ef4:	4b27      	ldr	r3, [pc, #156]	; (e2f94 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5d4>)
   e2ef6:	9300      	str	r3, [sp, #0]
   e2ef8:	9503      	str	r5, [sp, #12]
   e2efa:	9402      	str	r4, [sp, #8]
   e2efc:	697c      	ldr	r4, [r7, #20]
   e2efe:	f44f 73da 	mov.w	r3, #436	; 0x1b4
   e2f02:	e7bd      	b.n	e2e80 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x4c0>
    TF_LITE_ENSURE_EQ(context, weights_time->type, kTfLiteFloat32);
   e2f04:	f813 300c 	ldrb.w	r3, [r3, ip]
   e2f08:	2b01      	cmp	r3, #1
   e2f0a:	d097      	beq.n	e2e3c <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x47c>
   e2f0c:	9302      	str	r3, [sp, #8]
   e2f0e:	4b0e      	ldr	r3, [pc, #56]	; (e2f48 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x588>)
   e2f10:	9301      	str	r3, [sp, #4]
   e2f12:	4b21      	ldr	r3, [pc, #132]	; (e2f98 <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x5d8>)
   e2f14:	9300      	str	r3, [sp, #0]
   e2f16:	9403      	str	r4, [sp, #12]
   e2f18:	697d      	ldr	r5, [r7, #20]
   e2f1a:	f240 13b5 	movw	r3, #437	; 0x1b5
   e2f1e:	e7dd      	b.n	e2edc <_ZN6tflite3ops5micro4svdf7PrepareEP13TfLiteContextP10TfLiteNode+0x51c>
  TF_LITE_ENSURE_EQ(context, NumDimensions(output), 2);
  TF_LITE_ENSURE_EQ(context, output->dims->data[0], batch_size);
  TF_LITE_ENSURE_EQ(context, output->dims->data[1], num_units);

  return kTfLiteOk;
}
   e2f20:	b007      	add	sp, #28
   e2f22:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e2f26:	bf00      	nop
   e2f28:	000ec764 	.word	0x000ec764
   e2f2c:	000ec4c4 	.word	0x000ec4c4
   e2f30:	000ec7ac 	.word	0x000ec7ac
   e2f34:	000ec7c4 	.word	0x000ec7c4
   e2f38:	000ec4fa 	.word	0x000ec4fa
   e2f3c:	000eb58e 	.word	0x000eb58e
   e2f40:	000ec690 	.word	0x000ec690
   e2f44:	000ec822 	.word	0x000ec822
   e2f48:	000ebc41 	.word	0x000ebc41
   e2f4c:	000ec849 	.word	0x000ec849
   e2f50:	000ecdd6 	.word	0x000ecdd6
   e2f54:	000ec867 	.word	0x000ec867
   e2f58:	000ec88e 	.word	0x000ec88e
   e2f5c:	000ec8b5 	.word	0x000ec8b5
   e2f60:	000ebd87 	.word	0x000ebd87
   e2f64:	000ec8d6 	.word	0x000ec8d6
   e2f68:	000ec6c9 	.word	0x000ec6c9
   e2f6c:	000ec900 	.word	0x000ec900
   e2f70:	000ec92a 	.word	0x000ec92a
   e2f74:	000ec936 	.word	0x000ec936
   e2f78:	000eb5c9 	.word	0x000eb5c9
   e2f7c:	000eb400 	.word	0x000eb400
   e2f80:	000eb3b9 	.word	0x000eb3b9
   e2f84:	000ec976 	.word	0x000ec976
   e2f88:	000ec98c 	.word	0x000ec98c
   e2f8c:	000ec630 	.word	0x000ec630
   e2f90:	000ec9a2 	.word	0x000ec9a2
   e2f94:	000ec960 	.word	0x000ec960
   e2f98:	000ec8c3 	.word	0x000ec8c3

000e2f9c <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e2f9c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e2fa0:	ed2d 8b02 	vpush	{d8}
   e2fa4:	b097      	sub	sp, #92	; 0x5c
   e2fa6:	680a      	ldr	r2, [r1, #0]
  auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);
   e2fa8:	694b      	ldr	r3, [r1, #20]
   e2faa:	9309      	str	r3, [sp, #36]	; 0x24
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e2fac:	6893      	ldr	r3, [r2, #8]
   e2fae:	6855      	ldr	r5, [r2, #4]
   e2fb0:	f04f 0c38 	mov.w	ip, #56	; 0x38
   e2fb4:	fb0c fe03 	mul.w	lr, ip, r3
}

inline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
   e2fb8:	6913      	ldr	r3, [r2, #16]
  TF_LITE_ENSURE_EQ(context, output->dims->data[1], num_units);

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e2fba:	4607      	mov	r7, r0
   e2fbc:	6880      	ldr	r0, [r0, #8]
  if (use_tensor) {
   e2fbe:	1c5c      	adds	r4, r3, #1
    return &context
                ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e2fc0:	bf14      	ite	ne
   e2fc2:	fb0c 0303 	mlane	r3, ip, r3, r0
  }
  return nullptr;
   e2fc6:	2300      	moveq	r3, #0
   e2fc8:	930b      	str	r3, [sp, #44]	; 0x2c
  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);

  // TODO(kreeger): Use input tensor as variable until scratch tensor allocation
  // has been implemented (cl/263032056)
  // TfLiteTensor* scratch = GetTemporary(context, node, /*index=*/0);
  TfLiteTensor* scratch = &context->tensors[node->inputs->data[5]];
   e2fca:	6993      	ldr	r3, [r2, #24]

  TfLiteTensor* activation_state =
      &context->tensors[node->inputs->data[kInputActivationStateTensor]];
   e2fcc:	6954      	ldr	r4, [r2, #20]
  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);

  // TODO(kreeger): Use input tensor as variable until scratch tensor allocation
  // has been implemented (cl/263032056)
  // TfLiteTensor* scratch = GetTemporary(context, node, /*index=*/0);
  TfLiteTensor* scratch = &context->tensors[node->inputs->data[5]];
   e2fce:	fb0c 0303 	mla	r3, ip, r3, r0
   e2fd2:	930e      	str	r3, [sp, #56]	; 0x38

  TfLiteTensor* activation_state =
      &context->tensors[node->inputs->data[kInputActivationStateTensor]];
   e2fd4:	fb0c 0304 	mla	r3, ip, r4, r0
   e2fd8:	9308      	str	r3, [sp, #32]
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e2fda:	684b      	ldr	r3, [r1, #4]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e2fdc:	eb00 060e 	add.w	r6, r0, lr
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e2fe0:	685b      	ldr	r3, [r3, #4]
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  switch (weights_feature->type) {
   e2fe2:	f810 e00e 	ldrb.w	lr, [r0, lr]
   e2fe6:	fb0c 0303 	mla	r3, ip, r3, r0
   e2fea:	f1be 0f03 	cmp.w	lr, #3
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e2fee:	fb0c 0505 	mla	r5, ip, r5, r0
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e2ff2:	930d      	str	r3, [sp, #52]	; 0x34
   e2ff4:	f000 809f 	beq.w	e3136 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x19a>
   e2ff8:	f1be 0f09 	cmp.w	lr, #9
   e2ffc:	f000 809b 	beq.w	e3136 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x19a>
   e3000:	f1be 0f01 	cmp.w	lr, #1
   e3004:	f040 816d 	bne.w	e32e2 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x346>
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e3008:	68d3      	ldr	r3, [r2, #12]
   e300a:	2238      	movs	r2, #56	; 0x38
   e300c:	fb02 0303 	mla	r3, r2, r3, r0
   e3010:	930c      	str	r3, [sp, #48]	; 0x30
                          const TfLiteTensor* weights_time,
                          const TfLiteTensor* bias,
                          const TfLiteSVDFParams* params, TfLiteTensor* scratch,
                          TfLiteTensor* activation_state,
                          TfLiteTensor* output) {
  const int rank = params->rank;
   e3012:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e3014:	681b      	ldr	r3, [r3, #0]
   e3016:	930f      	str	r3, [sp, #60]	; 0x3c
  const int batch_size = input->dims->data[0];
   e3018:	68ab      	ldr	r3, [r5, #8]
   e301a:	f8d3 b004 	ldr.w	fp, [r3, #4]
  const int input_size = input->dims->data[1];
   e301e:	689b      	ldr	r3, [r3, #8]
   e3020:	930a      	str	r3, [sp, #40]	; 0x28
  const int num_filters = weights_feature->dims->data[0];
   e3022:	68b3      	ldr	r3, [r6, #8]
   e3024:	685a      	ldr	r2, [r3, #4]
  const int num_units = num_filters / rank;
   e3026:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   e3028:	fb92 f3f3 	sdiv	r3, r2, r3
   e302c:	9310      	str	r3, [sp, #64]	; 0x40
  const int memory_size = weights_time->dims->data[1];
   e302e:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   e3030:	689b      	ldr	r3, [r3, #8]
   e3032:	f8d3 a008 	ldr.w	sl, [r3, #8]
  for (int b = 0; b < batch_size; ++b) {
    float* state_ptr_batch =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int c = 0; c < num_filters; ++c) {
      float* state_ptr = state_ptr_batch + c * memory_size;
      state_ptr[memory_size - 1] = 0.0f;
   e3036:	f10a 4380 	add.w	r3, sl, #1073741824	; 0x40000000
   e303a:	3b01      	subs	r3, #1
   e303c:	009b      	lsls	r3, r3, #2
   e303e:	fb0a f702 	mul.w	r7, sl, r2
   e3042:	00bf      	lsls	r7, r7, #2
   e3044:	f103 0804 	add.w	r8, r3, #4
   e3048:	4618      	mov	r0, r3
  const int memory_size = weights_time->dims->data[1];

  // Clear the activation (activation_state's leftmost column).
  // TODO(ghodrat): Add a test which initialize activation_state with invalid
  // values in leftmost column and make sure it passes.
  for (int b = 0; b < batch_size; ++b) {
   e304a:	f04f 0e00 	mov.w	lr, #0
    float* state_ptr_batch =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int c = 0; c < num_filters; ++c) {
      float* state_ptr = state_ptr_batch + c * memory_size;
      state_ptr[memory_size - 1] = 0.0f;
   e304e:	f04f 0900 	mov.w	r9, #0
  const int memory_size = weights_time->dims->data[1];

  // Clear the activation (activation_state's leftmost column).
  // TODO(ghodrat): Add a test which initialize activation_state with invalid
  // values in leftmost column and make sure it passes.
  for (int b = 0; b < batch_size; ++b) {
   e3052:	45f3      	cmp	fp, lr
   e3054:	dd13      	ble.n	e307e <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0xe2>
   e3056:	9908      	ldr	r1, [sp, #32]
   e3058:	b109      	cbz	r1, e305e <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0xc2>
   e305a:	6849      	ldr	r1, [r1, #4]
   e305c:	e000      	b.n	e3060 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0xc4>
   e305e:	9908      	ldr	r1, [sp, #32]
   e3060:	4401      	add	r1, r0
    float* state_ptr_batch =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int c = 0; c < num_filters; ++c) {
   e3062:	f04f 0c00 	mov.w	ip, #0
   e3066:	4562      	cmp	r2, ip
   e3068:	dd05      	ble.n	e3076 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0xda>
      float* state_ptr = state_ptr_batch + c * memory_size;
      state_ptr[memory_size - 1] = 0.0f;
   e306a:	f8c1 9000 	str.w	r9, [r1]
  // TODO(ghodrat): Add a test which initialize activation_state with invalid
  // values in leftmost column and make sure it passes.
  for (int b = 0; b < batch_size; ++b) {
    float* state_ptr_batch =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int c = 0; c < num_filters; ++c) {
   e306e:	f10c 0c01 	add.w	ip, ip, #1
   e3072:	4441      	add	r1, r8
   e3074:	e7f7      	b.n	e3066 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0xca>
  const int memory_size = weights_time->dims->data[1];

  // Clear the activation (activation_state's leftmost column).
  // TODO(ghodrat): Add a test which initialize activation_state with invalid
  // values in leftmost column and make sure it passes.
  for (int b = 0; b < batch_size; ++b) {
   e3076:	f10e 0e01 	add.w	lr, lr, #1
   e307a:	4438      	add	r0, r7
   e307c:	e7e9      	b.n	e3052 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0xb6>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e307e:	6871      	ldr	r1, [r6, #4]
   e3080:	9111      	str	r1, [sp, #68]	; 0x44
   e3082:	6869      	ldr	r1, [r5, #4]
   e3084:	9112      	str	r1, [sp, #72]	; 0x48

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e3086:	9908      	ldr	r1, [sp, #32]
   e3088:	b109      	cbz	r1, e308e <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0xf2>
   e308a:	6849      	ldr	r1, [r1, #4]
   e308c:	e000      	b.n	e3090 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0xf4>
   e308e:	9908      	ldr	r1, [sp, #32]
   e3090:	980a      	ldr	r0, [sp, #40]	; 0x28
   e3092:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
   e3096:	0080      	lsls	r0, r0, #2
  // stride equal to memory_size.

  // Perform batched matrix vector multiply accumulate operation:
  const float* matrix = GetTensorData<float>(weights_feature);
  const float* vector = GetTensorData<float>(input);
  float* result = &GetTensorData<float>(activation_state)[memory_size - 1];
   e3098:	4419      	add	r1, r3
   e309a:	ea22 77e2 	bic.w	r7, r2, r2, asr #31
      const float* vector_in_batch = vector + i * input_size;
      for (int k = 0; k < input_size; ++k) {
        dot_prod += *matrix_ptr++ * *vector_in_batch++;
      }
      *result_in_batch += dot_prod;
      result_in_batch += memory_size;
   e309e:	3304      	adds	r3, #4
   e30a0:	9015      	str	r0, [sp, #84]	; 0x54
   e30a2:	fb03 f007 	mul.w	r0, r3, r7
   e30a6:	9014      	str	r0, [sp, #80]	; 0x50
   e30a8:	2000      	movs	r0, #0
  // Perform batched matrix vector multiply accumulate operation:
  const float* matrix = GetTensorData<float>(weights_feature);
  const float* vector = GetTensorData<float>(input);
  float* result = &GetTensorData<float>(activation_state)[memory_size - 1];
  float* result_in_batch = result;
  for (int i = 0; i < batch_size; ++i) {
   e30aa:	4606      	mov	r6, r0
   e30ac:	45b3      	cmp	fp, r6
   e30ae:	dd2f      	ble.n	e3110 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x174>
    const float* matrix_ptr = matrix;
    for (int j = 0; j < num_filters; ++j) {
      float dot_prod = 0.0f;
      const float* vector_in_batch = vector + i * input_size;
   e30b0:	9d12      	ldr	r5, [sp, #72]	; 0x48
   e30b2:	f8dd c044 	ldr.w	ip, [sp, #68]	; 0x44
   e30b6:	eb05 0580 	add.w	r5, r5, r0, lsl #2
   e30ba:	9513      	str	r5, [sp, #76]	; 0x4c
   e30bc:	f04f 0e00 	mov.w	lr, #0
   e30c0:	460d      	mov	r5, r1
  const float* vector = GetTensorData<float>(input);
  float* result = &GetTensorData<float>(activation_state)[memory_size - 1];
  float* result_in_batch = result;
  for (int i = 0; i < batch_size; ++i) {
    const float* matrix_ptr = matrix;
    for (int j = 0; j < num_filters; ++j) {
   e30c2:	4572      	cmp	r2, lr
   e30c4:	dd1e      	ble.n	e3104 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x168>
   e30c6:	f8dd 904c 	ldr.w	r9, [sp, #76]	; 0x4c
   e30ca:	ed9f 7a8d 	vldr	s14, [pc, #564]	; e3300 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x364>
   e30ce:	4667      	mov	r7, ip
   e30d0:	f04f 0800 	mov.w	r8, #0
      float dot_prod = 0.0f;
      const float* vector_in_batch = vector + i * input_size;
      for (int k = 0; k < input_size; ++k) {
   e30d4:	9c0a      	ldr	r4, [sp, #40]	; 0x28
   e30d6:	4544      	cmp	r4, r8
   e30d8:	dd08      	ble.n	e30ec <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x150>
        dot_prod += *matrix_ptr++ * *vector_in_batch++;
   e30da:	ecf7 6a01 	vldmia	r7!, {s13}
   e30de:	ecf9 7a01 	vldmia	r9!, {s15}
  for (int i = 0; i < batch_size; ++i) {
    const float* matrix_ptr = matrix;
    for (int j = 0; j < num_filters; ++j) {
      float dot_prod = 0.0f;
      const float* vector_in_batch = vector + i * input_size;
      for (int k = 0; k < input_size; ++k) {
   e30e2:	f108 0801 	add.w	r8, r8, #1
        dot_prod += *matrix_ptr++ * *vector_in_batch++;
   e30e6:	eea6 7aa7 	vfma.f32	s14, s13, s15
   e30ea:	e7f3      	b.n	e30d4 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x138>
      }
      *result_in_batch += dot_prod;
   e30ec:	edd5 7a00 	vldr	s15, [r5]
   e30f0:	9c15      	ldr	r4, [sp, #84]	; 0x54
   e30f2:	ee77 7a87 	vadd.f32	s15, s15, s14
   e30f6:	44a4      	add	ip, r4
   e30f8:	edc5 7a00 	vstr	s15, [r5]
  const float* vector = GetTensorData<float>(input);
  float* result = &GetTensorData<float>(activation_state)[memory_size - 1];
  float* result_in_batch = result;
  for (int i = 0; i < batch_size; ++i) {
    const float* matrix_ptr = matrix;
    for (int j = 0; j < num_filters; ++j) {
   e30fc:	f10e 0e01 	add.w	lr, lr, #1
      const float* vector_in_batch = vector + i * input_size;
      for (int k = 0; k < input_size; ++k) {
        dot_prod += *matrix_ptr++ * *vector_in_batch++;
      }
      *result_in_batch += dot_prod;
      result_in_batch += memory_size;
   e3100:	441d      	add	r5, r3
   e3102:	e7de      	b.n	e30c2 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x126>
   e3104:	9c14      	ldr	r4, [sp, #80]	; 0x50
   e3106:	4421      	add	r1, r4
   e3108:	9c0a      	ldr	r4, [sp, #40]	; 0x28
  // Perform batched matrix vector multiply accumulate operation:
  const float* matrix = GetTensorData<float>(weights_feature);
  const float* vector = GetTensorData<float>(input);
  float* result = &GetTensorData<float>(activation_state)[memory_size - 1];
  float* result_in_batch = result;
  for (int i = 0; i < batch_size; ++i) {
   e310a:	3601      	adds	r6, #1
   e310c:	4420      	add	r0, r4
   e310e:	e7cd      	b.n	e30ac <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x110>
    }
  }

  ApplyTimeWeightsBiasAndActivation(
      batch_size, memory_size, num_filters, num_units, rank, weights_time, bias,
      params->activation, activation_state, scratch, output);
   e3110:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   e3112:	9306      	str	r3, [sp, #24]
   e3114:	9b0e      	ldr	r3, [sp, #56]	; 0x38
   e3116:	9305      	str	r3, [sp, #20]
   e3118:	9b08      	ldr	r3, [sp, #32]
   e311a:	9304      	str	r3, [sp, #16]
   e311c:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e311e:	791b      	ldrb	r3, [r3, #4]
   e3120:	9303      	str	r3, [sp, #12]
   e3122:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e3124:	9302      	str	r3, [sp, #8]
   e3126:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   e3128:	9301      	str	r3, [sp, #4]
   e312a:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   e312c:	9300      	str	r3, [sp, #0]
   e312e:	4651      	mov	r1, sl
   e3130:	9b10      	ldr	r3, [sp, #64]	; 0x40
   e3132:	4658      	mov	r0, fp
   e3134:	e0d1      	b.n	e32da <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x33e>
   e3136:	68cf      	ldr	r7, [r1, #12]
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
}
inline TfLiteTensor* GetTemporary(TfLiteContext* context, TfLiteNode* node,
                                  int index) {
  return &context->tensors[flatbuffers::EndianScalar(
      node->temporaries->data[index])];
   e3138:	68ba      	ldr	r2, [r7, #8]
   e313a:	68fb      	ldr	r3, [r7, #12]
   e313c:	693f      	ldr	r7, [r7, #16]
   e313e:	2138      	movs	r1, #56	; 0x38
   e3140:	fb01 0202 	mla	r2, r1, r2, r0
   e3144:	fb01 0303 	mla	r3, r1, r3, r0
   e3148:	fb01 0107 	mla	r1, r1, r7, r0
   e314c:	9110      	str	r1, [sp, #64]	; 0x40
    const TfLiteTensor* weights_feature, const TfLiteTensor* weights_time,
    const TfLiteTensor* bias, const TfLiteSVDFParams* params,
    TfLiteTensor* scratch, TfLiteTensor* scaling_factors,
    TfLiteTensor* input_quantized, TfLiteTensor* activation_state,
    TfLiteTensor* output) {
  const int rank = params->rank;
   e314e:	9909      	ldr	r1, [sp, #36]	; 0x24
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e3150:	6868      	ldr	r0, [r5, #4]
   e3152:	6809      	ldr	r1, [r1, #0]
   e3154:	910f      	str	r1, [sp, #60]	; 0x3c
  const int batch_size = input->dims->data[0];
   e3156:	68a9      	ldr	r1, [r5, #8]
   e3158:	f8d1 a004 	ldr.w	sl, [r1, #4]
  const int input_size = input->dims->data[1];
   e315c:	6889      	ldr	r1, [r1, #8]
   e315e:	910a      	str	r1, [sp, #40]	; 0x28
  const int num_filters = weights_feature->dims->data[0];
   e3160:	68b1      	ldr	r1, [r6, #8]
   e3162:	f8d1 b004 	ldr.w	fp, [r1, #4]
  const int num_units = num_filters / rank;
   e3166:	990f      	ldr	r1, [sp, #60]	; 0x3c
   e3168:	fb9b f1f1 	sdiv	r1, fp, r1
   e316c:	9111      	str	r1, [sp, #68]	; 0x44
  const int memory_size = weights_time->dims->data[1];
   e316e:	9910      	ldr	r1, [sp, #64]	; 0x40
   e3170:	6889      	ldr	r1, [r1, #8]
   e3172:	6889      	ldr	r1, [r1, #8]
   e3174:	910c      	str	r1, [sp, #48]	; 0x30
   e3176:	6871      	ldr	r1, [r6, #4]
   e3178:	9114      	str	r1, [sp, #80]	; 0x50

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e317a:	b112      	cbz	r2, e3182 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x1e6>
   e317c:	f8d2 9004 	ldr.w	r9, [r2, #4]
   e3180:	e000      	b.n	e3184 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x1e8>
   e3182:	4691      	mov	r9, r2
   e3184:	b10b      	cbz	r3, e318a <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x1ee>
   e3186:	685f      	ldr	r7, [r3, #4]
   e3188:	e000      	b.n	e318c <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x1f0>
   e318a:	461f      	mov	r7, r3
  for (int b = 0; b < batch_size; ++b) {
    float* state_ptr_batch =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int c = 0; c < num_filters; ++c) {
      float* state_ptr = state_ptr_batch + c * memory_size;
      state_ptr[memory_size - 1] = 0.0;
   e318c:	9b0c      	ldr	r3, [sp, #48]	; 0x30

  // Initialize the pointer to storage for scaling factors.
  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors);

  // Initialize the weights scale.
  const float weights_feature_scale = weights_feature->params.scale;
   e318e:	ed96 8a03 	vldr	s16, [r6, #12]
  for (int b = 0; b < batch_size; ++b) {
    float* state_ptr_batch =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int c = 0; c < num_filters; ++c) {
      float* state_ptr = state_ptr_batch + c * memory_size;
      state_ptr[memory_size - 1] = 0.0;
   e3192:	eddf 7a5b 	vldr	s15, [pc, #364]	; e3300 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x364>
   e3196:	f103 4280 	add.w	r2, r3, #1073741824	; 0x40000000
   e319a:	3a01      	subs	r2, #1
   e319c:	0096      	lsls	r6, r2, #2
   e319e:	fb03 f10b 	mul.w	r1, r3, fp
   e31a2:	0089      	lsls	r1, r1, #2
   e31a4:	f106 0804 	add.w	r8, r6, #4
   e31a8:	4632      	mov	r2, r6

  // Clear the activation (activation_state's leftmost column).
  // TODO(ghodrat): Add a test which initialize activation_state with invalid
  // values in the leftmost column and make sure it passes.
  // TODO(kreeger): Use a port of tensor_utils when ready (b/140272187).
  for (int b = 0; b < batch_size; ++b) {
   e31aa:	f04f 0e00 	mov.w	lr, #0
   e31ae:	45f2      	cmp	sl, lr
   e31b0:	dd13      	ble.n	e31da <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x23e>
   e31b2:	9b08      	ldr	r3, [sp, #32]
   e31b4:	b10b      	cbz	r3, e31ba <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x21e>
   e31b6:	685b      	ldr	r3, [r3, #4]
   e31b8:	e000      	b.n	e31bc <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x220>
   e31ba:	9b08      	ldr	r3, [sp, #32]
   e31bc:	4413      	add	r3, r2
    float* state_ptr_batch =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int c = 0; c < num_filters; ++c) {
   e31be:	f04f 0c00 	mov.w	ip, #0
   e31c2:	45e3      	cmp	fp, ip
   e31c4:	dd05      	ble.n	e31d2 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x236>
      float* state_ptr = state_ptr_batch + c * memory_size;
      state_ptr[memory_size - 1] = 0.0;
   e31c6:	edc3 7a00 	vstr	s15, [r3]
  // values in the leftmost column and make sure it passes.
  // TODO(kreeger): Use a port of tensor_utils when ready (b/140272187).
  for (int b = 0; b < batch_size; ++b) {
    float* state_ptr_batch =
        GetTensorData<float>(activation_state) + b * memory_size * num_filters;
    for (int c = 0; c < num_filters; ++c) {
   e31ca:	f10c 0c01 	add.w	ip, ip, #1
   e31ce:	4443      	add	r3, r8
   e31d0:	e7f7      	b.n	e31c2 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x226>

  // Clear the activation (activation_state's leftmost column).
  // TODO(ghodrat): Add a test which initialize activation_state with invalid
  // values in the leftmost column and make sure it passes.
  // TODO(kreeger): Use a port of tensor_utils when ready (b/140272187).
  for (int b = 0; b < batch_size; ++b) {
   e31d2:	f10e 0e01 	add.w	lr, lr, #1
   e31d6:	440a      	add	r2, r1
   e31d8:	e7e9      	b.n	e31ae <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x212>
    }
  }

  // Determine if input pointer batch is a zero based vector:
  bool is_zero_vector = true;
  for (int i = 0; i < batch_size * input_size && is_zero_vector; ++i) {
   e31da:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e31dc:	4601      	mov	r1, r0
   e31de:	fb03 fe0a 	mul.w	lr, r3, sl
   e31e2:	2200      	movs	r2, #0
   e31e4:	2301      	movs	r3, #1
   e31e6:	4596      	cmp	lr, r2
   e31e8:	dd0b      	ble.n	e3202 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x266>
   e31ea:	b163      	cbz	r3, e3206 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x26a>
    if (input_ptr_batch[i] != 0.0f) {
   e31ec:	ecf1 7a01 	vldmia	r1!, {s15}
   e31f0:	eef5 7a40 	vcmp.f32	s15, #0.0
   e31f4:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e31f8:	bf0c      	ite	eq
   e31fa:	2301      	moveq	r3, #1
   e31fc:	2300      	movne	r3, #0
    }
  }

  // Determine if input pointer batch is a zero based vector:
  bool is_zero_vector = true;
  for (int i = 0; i < batch_size * input_size && is_zero_vector; ++i) {
   e31fe:	3201      	adds	r2, #1
   e3200:	e7f1      	b.n	e31e6 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x24a>
    if (input_ptr_batch[i] != 0.0f) {
      is_zero_vector = false;
    }
  }

  if (!is_zero_vector) {
   e3202:	2b00      	cmp	r3, #0
   e3204:	d156      	bne.n	e32b4 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x318>
    SignedSymmetricPerChannelQuantize(input_ptr_batch, input->dims, 0,
                                      quantized_input_ptr_batch,
                                      scaling_factors_ptr);
   e3206:	9700      	str	r7, [sp, #0]
   e3208:	464b      	mov	r3, r9
   e320a:	2200      	movs	r2, #0
   e320c:	68a9      	ldr	r1, [r5, #8]
   e320e:	f7f4 f8d1 	bl	d73b4 <_ZN6tflite33SignedSymmetricPerChannelQuantizeEPKfP14TfLiteIntArrayiPaPf>
   e3212:	463b      	mov	r3, r7
   e3214:	4639      	mov	r1, r7

    // Quantize input from float to int8.
    for (int b = 0; b < batch_size; ++b) {
   e3216:	2200      	movs	r2, #0
   e3218:	4592      	cmp	sl, r2
   e321a:	dd07      	ble.n	e322c <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x290>
      scaling_factors_ptr[b] *= weights_feature_scale;
   e321c:	edd1 7a00 	vldr	s15, [r1]
   e3220:	ee67 7a88 	vmul.f32	s15, s15, s16
    SignedSymmetricPerChannelQuantize(input_ptr_batch, input->dims, 0,
                                      quantized_input_ptr_batch,
                                      scaling_factors_ptr);

    // Quantize input from float to int8.
    for (int b = 0; b < batch_size; ++b) {
   e3224:	3201      	adds	r2, #1
      scaling_factors_ptr[b] *= weights_feature_scale;
   e3226:	ece1 7a01 	vstmia	r1!, {s15}
   e322a:	e7f5      	b.n	e3218 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x27c>
   e322c:	9a08      	ldr	r2, [sp, #32]
   e322e:	b10a      	cbz	r2, e3234 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x298>
   e3230:	6851      	ldr	r1, [r2, #4]
   e3232:	e000      	b.n	e3236 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x29a>
   e3234:	9908      	ldr	r1, [sp, #32]
         ++i, quantized_input_ptr_batch += input_size) {
      const float batch_scaling_factor = scaling_factors_ptr[i];

      // Get the address of the first row:
      const int8_t* row_ptr = weights_feature_ptr;
      for (int j = 0; j < num_filters; ++j, result += memory_size) {
   e3236:	1d32      	adds	r2, r6, #4
   e3238:	ea2b 7eeb 	bic.w	lr, fp, fp, asr #31
   e323c:	fb02 f00e 	mul.w	r0, r2, lr
   e3240:	9013      	str	r0, [sp, #76]	; 0x4c
   e3242:	980a      	ldr	r0, [sp, #40]	; 0x28
   e3244:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    // Compute conv1d(inputs, weights_feature).
    // The rightmost column of activation_state is used to save the current
    // cycle activation. This is achieved by starting at
    // GetTensorData<float>(activation_state)[memory_size - 1] and having the
    // stride equal to memory_size. (Matrix batch vector multiply accumulate)
    float* result = &GetTensorData<float>(activation_state)[memory_size - 1];
   e3248:	4431      	add	r1, r6
    for (int i = 0; i < batch_size;
   e324a:	2700      	movs	r7, #0
   e324c:	9015      	str	r0, [sp, #84]	; 0x54
   e324e:	45ba      	cmp	sl, r7
   e3250:	dd30      	ble.n	e32b4 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x318>
         ++i, quantized_input_ptr_batch += input_size) {
      const float batch_scaling_factor = scaling_factors_ptr[i];
   e3252:	ecf3 6a01 	vldmia	r3!, {s13}

      // Get the address of the first row:
      const int8_t* row_ptr = weights_feature_ptr;
   e3256:	f8dd 8050 	ldr.w	r8, [sp, #80]	; 0x50
    // GetTensorData<float>(activation_state)[memory_size - 1] and having the
    // stride equal to memory_size. (Matrix batch vector multiply accumulate)
    float* result = &GetTensorData<float>(activation_state)[memory_size - 1];
    for (int i = 0; i < batch_size;
         ++i, quantized_input_ptr_batch += input_size) {
      const float batch_scaling_factor = scaling_factors_ptr[i];
   e325a:	460e      	mov	r6, r1

      // Get the address of the first row:
      const int8_t* row_ptr = weights_feature_ptr;
      for (int j = 0; j < num_filters; ++j, result += memory_size) {
   e325c:	f04f 0c00 	mov.w	ip, #0
   e3260:	45e3      	cmp	fp, ip
   e3262:	dd21      	ble.n	e32a8 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x30c>
   e3264:	2000      	movs	r0, #0
   e3266:	4605      	mov	r5, r0
        // Initialize the dot product sum for the row to 0.
        int32_t dotprod = 0;
        for (int k = 0; k < input_size; ++k, ++row_ptr) {
   e3268:	9c0a      	ldr	r4, [sp, #40]	; 0x28
   e326a:	4284      	cmp	r4, r0
   e326c:	dd0c      	ble.n	e3288 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x2ec>
          dotprod += (*row_ptr) * (quantized_input_ptr_batch[k]);
   e326e:	f918 4000 	ldrsb.w	r4, [r8, r0]
   e3272:	46a6      	mov	lr, r4
   e3274:	f919 4000 	ldrsb.w	r4, [r9, r0]
   e3278:	9412      	str	r4, [sp, #72]	; 0x48
   e327a:	4674      	mov	r4, lr
   e327c:	f8bd e048 	ldrh.w	lr, [sp, #72]	; 0x48
      // Get the address of the first row:
      const int8_t* row_ptr = weights_feature_ptr;
      for (int j = 0; j < num_filters; ++j, result += memory_size) {
        // Initialize the dot product sum for the row to 0.
        int32_t dotprod = 0;
        for (int k = 0; k < input_size; ++k, ++row_ptr) {
   e3280:	3001      	adds	r0, #1
          dotprod += (*row_ptr) * (quantized_input_ptr_batch[k]);
   e3282:	fb14 550e 	smlabb	r5, r4, lr, r5
   e3286:	e7ef      	b.n	e3268 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x2cc>
        }
        *result += dotprod * batch_scaling_factor;
   e3288:	ee07 5a90 	vmov	s15, r5
   e328c:	ed96 7a00 	vldr	s14, [r6]
   e3290:	9815      	ldr	r0, [sp, #84]	; 0x54
   e3292:	eef8 7ae7 	vcvt.f32.s32	s15, s15
   e3296:	4480      	add	r8, r0
   e3298:	eea6 7aa7 	vfma.f32	s14, s13, s15
         ++i, quantized_input_ptr_batch += input_size) {
      const float batch_scaling_factor = scaling_factors_ptr[i];

      // Get the address of the first row:
      const int8_t* row_ptr = weights_feature_ptr;
      for (int j = 0; j < num_filters; ++j, result += memory_size) {
   e329c:	f10c 0c01 	add.w	ip, ip, #1
        // Initialize the dot product sum for the row to 0.
        int32_t dotprod = 0;
        for (int k = 0; k < input_size; ++k, ++row_ptr) {
          dotprod += (*row_ptr) * (quantized_input_ptr_batch[k]);
        }
        *result += dotprod * batch_scaling_factor;
   e32a0:	ed86 7a00 	vstr	s14, [r6]
         ++i, quantized_input_ptr_batch += input_size) {
      const float batch_scaling_factor = scaling_factors_ptr[i];

      // Get the address of the first row:
      const int8_t* row_ptr = weights_feature_ptr;
      for (int j = 0; j < num_filters; ++j, result += memory_size) {
   e32a4:	4416      	add	r6, r2
   e32a6:	e7db      	b.n	e3260 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x2c4>
   e32a8:	9813      	ldr	r0, [sp, #76]	; 0x4c
   e32aa:	4401      	add	r1, r0
   e32ac:	980a      	ldr	r0, [sp, #40]	; 0x28
    // The rightmost column of activation_state is used to save the current
    // cycle activation. This is achieved by starting at
    // GetTensorData<float>(activation_state)[memory_size - 1] and having the
    // stride equal to memory_size. (Matrix batch vector multiply accumulate)
    float* result = &GetTensorData<float>(activation_state)[memory_size - 1];
    for (int i = 0; i < batch_size;
   e32ae:	3701      	adds	r7, #1
   e32b0:	4481      	add	r9, r0
   e32b2:	e7cc      	b.n	e324e <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x2b2>

  // TODO(alanchiao): can optimize hybrid case ~5% by unrolling loop in applying
  // time weights so that the inner loop multiplies eight elements at a time.
  ApplyTimeWeightsBiasAndActivation(
      batch_size, memory_size, num_filters, num_units, rank, weights_time, bias,
      params->activation, activation_state, scratch, output);
   e32b4:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   e32b6:	9306      	str	r3, [sp, #24]
   e32b8:	9b0e      	ldr	r3, [sp, #56]	; 0x38
   e32ba:	9305      	str	r3, [sp, #20]
   e32bc:	9b08      	ldr	r3, [sp, #32]
   e32be:	9304      	str	r3, [sp, #16]
   e32c0:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e32c2:	990c      	ldr	r1, [sp, #48]	; 0x30
   e32c4:	791b      	ldrb	r3, [r3, #4]
   e32c6:	9303      	str	r3, [sp, #12]
   e32c8:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e32ca:	9302      	str	r3, [sp, #8]
   e32cc:	9b10      	ldr	r3, [sp, #64]	; 0x40
   e32ce:	9301      	str	r3, [sp, #4]
   e32d0:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   e32d2:	9300      	str	r3, [sp, #0]
   e32d4:	9b11      	ldr	r3, [sp, #68]	; 0x44
   e32d6:	465a      	mov	r2, fp
   e32d8:	4650      	mov	r0, sl
   e32da:	f7ff fa6b 	bl	e27b4 <_ZN6tflite3ops5micro4svdf12_GLOBAL__N_1L33ApplyTimeWeightsBiasAndActivationEiiiiiPK12TfLiteTensorS6_21TfLiteFusedActivationPS4_S8_S8_>
      TfLiteTensor* scratch_float_weights_time = GetTemporary(context, node, 3);
      EvalHybridSVDF(context, node, input, weights_feature,
                     scratch_float_weights_time, bias, params, scratch,
                     scratch_scaling_factors, scratch_input_quantized,
                     activation_state, output);
      return kTfLiteOk;
   e32de:	2000      	movs	r0, #0
   e32e0:	e008      	b.n	e32f4 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x358>
      break;
    }

    default:
      // TODO(kreeger): Handle this case for full quant svdf b/139435798
      context->ReportError(context, "Type %s not currently supported.",
   e32e2:	4670      	mov	r0, lr
   e32e4:	697c      	ldr	r4, [r7, #20]
   e32e6:	f7f0 ff21 	bl	d412c <TfLiteTypeGetName>
                           TfLiteTypeGetName(weights_feature->type));
   e32ea:	4906      	ldr	r1, [pc, #24]	; (e3304 <_ZN6tflite3ops5micro4svdf4EvalEP13TfLiteContextP10TfLiteNode+0x368>)
   e32ec:	4602      	mov	r2, r0
   e32ee:	4638      	mov	r0, r7
   e32f0:	47a0      	blx	r4
      return kTfLiteError;
   e32f2:	2001      	movs	r0, #1
  }
  return kTfLiteOk;
}
   e32f4:	b017      	add	sp, #92	; 0x5c
   e32f6:	ecbd 8b02 	vpop	{d8}
   e32fa:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e32fe:	bf00      	nop
   e3300:	00000000 	.word	0x00000000
   e3304:	000eba67 	.word	0x000eba67

000e3308 <_ZN6tflite3ops5micro13Register_SVDFEv>:

TfLiteRegistration* Register_SVDF() {
  static TfLiteRegistration r = {svdf::Init, svdf::Free, svdf::Prepare,
                                 svdf::Eval};
  return &r;
}
   e3308:	4800      	ldr	r0, [pc, #0]	; (e330c <_ZN6tflite3ops5micro13Register_SVDFEv+0x4>)
   e330a:	4770      	bx	lr
   e330c:	2003c1d0 	.word	0x2003c1d0

000e3310 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_17PrepareEP13TfLiteContextP10TfLiteNode>:

constexpr int kInputTensor = 0;

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   e3310:	2000      	movs	r0, #0
   e3312:	4770      	bx	lr

000e3314 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode>:
  }

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e3314:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e3318:	680b      	ldr	r3, [r1, #0]
   e331a:	6885      	ldr	r5, [r0, #8]
  TfLiteUnpackParams* data =
      reinterpret_cast<TfLiteUnpackParams*>(node->builtin_data);
   e331c:	694a      	ldr	r2, [r1, #20]
  }

  return kTfLiteOk;
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e331e:	b085      	sub	sp, #20
   e3320:	9001      	str	r0, [sp, #4]
   e3322:	6858      	ldr	r0, [r3, #4]
   e3324:	2338      	movs	r3, #56	; 0x38
   e3326:	4358      	muls	r0, r3
   e3328:	182b      	adds	r3, r5, r0
  TfLiteUnpackParams* data =
      reinterpret_cast<TfLiteUnpackParams*>(node->builtin_data);

  const TfLiteTensor* input = GetInput(context, node, kInputTensor);

  switch (input->type) {
   e332a:	5c28      	ldrb	r0, [r5, r0]
   e332c:	1e46      	subs	r6, r0, #1
   e332e:	2e08      	cmp	r6, #8
   e3330:	f200 81c3 	bhi.w	e36ba <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x3a6>
   e3334:	e8df f016 	tbh	[pc, r6, lsl #1]
   e3338:	007a0009 	.word	0x007a0009
   e333c:	01c100e7 	.word	0x01c100e7
   e3340:	01c101c1 	.word	0x01c101c1
   e3344:	01c101c1 	.word	0x01c101c1
   e3348:	0154      	.short	0x0154
}

template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
   e334a:	6848      	ldr	r0, [r1, #4]
  const TfLiteIntArray* input_dims = input->dims;
   e334c:	f8d3 c008 	ldr.w	ip, [r3, #8]
  const TfLiteIntArray* output_dims = output0->dims;
   e3350:	6840      	ldr	r0, [r0, #4]

  const TfLiteTensor* input = GetInput(context, node, kInputTensor);

  switch (input->type) {
    case kTfLiteFloat32: {
      return UnpackImpl<float>(context, node, input, data->num, data->axis);
   e3352:	f8d2 8000 	ldr.w	r8, [r2]
   e3356:	6852      	ldr	r2, [r2, #4]
template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteIntArray* output_dims = output0->dims;
   e3358:	2638      	movs	r6, #56	; 0x38
   e335a:	fb06 5500 	mla	r5, r6, r0, r5
  const int dimensions = input_dims->size;

  if (axis < 0) {
   e335e:	2a00      	cmp	r2, #0
template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteIntArray* output_dims = output0->dims;
   e3360:	68af      	ldr	r7, [r5, #8]
  const int dimensions = input_dims->size;
   e3362:	f8dc 5000 	ldr.w	r5, [ip]

  if (axis < 0) {
    axis += NumDimensions(input);
   e3366:	bfb8      	it	lt
   e3368:	1952      	addlt	r2, r2, r5
  }

  TFLITE_DCHECK_LT(axis, dimensions);
   e336a:	4295      	cmp	r5, r2
   e336c:	dc01      	bgt.n	e3372 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x5e>
   e336e:	f002 f8c1 	bl	e54f4 <abort>
   e3372:	46e6      	mov	lr, ip
   e3374:	2000      	movs	r0, #0
   e3376:	2601      	movs	r6, #1

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e3378:	4282      	cmp	r2, r0
   e337a:	dd05      	ble.n	e3388 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x74>
    outer_size *= input_dims->data[i];
   e337c:	f85e 9f04 	ldr.w	r9, [lr, #4]!
  }

  TFLITE_DCHECK_LT(axis, dimensions);

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e3380:	3001      	adds	r0, #1
    outer_size *= input_dims->data[i];
   e3382:	fb09 f606 	mul.w	r6, r9, r6
   e3386:	e7f7      	b.n	e3378 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x64>
   e3388:	1c50      	adds	r0, r2, #1
   e338a:	f105 0e01 	add.w	lr, r5, #1
  }
  int copy_size = 1;
   e338e:	2201      	movs	r2, #1
   e3390:	3001      	adds	r0, #1
  for (int i = axis + 1; i < dimensions; ++i) {
   e3392:	4570      	cmp	r0, lr
   e3394:	d003      	beq.n	e339e <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x8a>
    copy_size *= input_dims->data[i];
   e3396:	f85c 5020 	ldr.w	r5, [ip, r0, lsl #2]
   e339a:	436a      	muls	r2, r5
   e339c:	e7f8      	b.n	e3390 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x7c>
  }
  int output_size = 1;
  for (int i = 0; i < output_dims->size; ++i) {
   e339e:	f8d7 c000 	ldr.w	ip, [r7]
   e33a2:	4638      	mov	r0, r7
   e33a4:	2501      	movs	r5, #1
   e33a6:	2700      	movs	r7, #0
   e33a8:	45bc      	cmp	ip, r7
   e33aa:	dd05      	ble.n	e33b8 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xa4>
    output_size *= output_dims->data[i];
   e33ac:	f850 ef04 	ldr.w	lr, [r0, #4]!
  int copy_size = 1;
  for (int i = axis + 1; i < dimensions; ++i) {
    copy_size *= input_dims->data[i];
  }
  int output_size = 1;
  for (int i = 0; i < output_dims->size; ++i) {
   e33b0:	3701      	adds	r7, #1
    output_size *= output_dims->data[i];
   e33b2:	fb0e f505 	mul.w	r5, lr, r5
   e33b6:	e7f7      	b.n	e33a8 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x94>
  }
  TFLITE_DCHECK_EQ(output_size, copy_size * outer_size);
   e33b8:	fb02 f006 	mul.w	r0, r2, r6
   e33bc:	4285      	cmp	r5, r0
   e33be:	d1d6      	bne.n	e336e <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x5a>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e33c0:	685b      	ldr	r3, [r3, #4]
   e33c2:	9302      	str	r3, [sp, #8]
   e33c4:	fb02 f308 	mul.w	r3, r2, r8
   e33c8:	009b      	lsls	r3, r3, #2
   e33ca:	2000      	movs	r0, #0
   e33cc:	ea4f 0982 	mov.w	r9, r2, lsl #2
   e33d0:	9303      	str	r3, [sp, #12]

  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
   e33d2:	4605      	mov	r5, r0
   e33d4:	45a8      	cmp	r8, r5
   e33d6:	dc01      	bgt.n	e33dc <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xc8>

  const TfLiteTensor* input = GetInput(context, node, kInputTensor);

  switch (input->type) {
    case kTfLiteFloat32: {
      return UnpackImpl<float>(context, node, input, data->num, data->axis);
   e33d8:	2000      	movs	r0, #0
   e33da:	e177      	b.n	e36cc <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x3b8>
  TFLITE_DCHECK_EQ(output_size, copy_size * outer_size);

  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
   e33dc:	684b      	ldr	r3, [r1, #4]
   e33de:	eb03 0385 	add.w	r3, r3, r5, lsl #2
   e33e2:	2438      	movs	r4, #56	; 0x38
   e33e4:	685f      	ldr	r7, [r3, #4]
   e33e6:	9b01      	ldr	r3, [sp, #4]
   e33e8:	689b      	ldr	r3, [r3, #8]
   e33ea:	fb04 3307 	mla	r3, r4, r7, r3

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e33ee:	b103      	cbz	r3, e33f2 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xde>
   e33f0:	685b      	ldr	r3, [r3, #4]
   e33f2:	2700      	movs	r7, #0
    T* output_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   e33f4:	46bc      	mov	ip, r7
   e33f6:	4566      	cmp	r6, ip
   e33f8:	dd15      	ble.n	e3426 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x112>
   e33fa:	9c02      	ldr	r4, [sp, #8]
   e33fc:	eb00 0e07 	add.w	lr, r0, r7
   e3400:	44a6      	add	lr, r4
   e3402:	469b      	mov	fp, r3
      T* output_ptr = output_data + copy_size * k;
      int loc = k * output_count * copy_size + i * copy_size;
      const T* input_ptr = input_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   e3404:	f04f 0a00 	mov.w	sl, #0
   e3408:	4552      	cmp	r2, sl
   e340a:	dd06      	ble.n	e341a <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x106>
   e340c:	ecfe 7a01 	vldmia	lr!, {s15}
   e3410:	f10a 0a01 	add.w	sl, sl, #1
   e3414:	eceb 7a01 	vstmia	fp!, {s15}
   e3418:	e7f6      	b.n	e3408 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xf4>
   e341a:	9c03      	ldr	r4, [sp, #12]
  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
    T* output_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   e341c:	f10c 0c01 	add.w	ip, ip, #1
   e3420:	4427      	add	r7, r4
   e3422:	444b      	add	r3, r9
   e3424:	e7e7      	b.n	e33f6 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xe2>
  }
  TFLITE_DCHECK_EQ(output_size, copy_size * outer_size);

  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
   e3426:	3501      	adds	r5, #1
   e3428:	4448      	add	r0, r9
   e342a:	e7d3      	b.n	e33d4 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xc0>
}

template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
   e342c:	6848      	ldr	r0, [r1, #4]
  const TfLiteIntArray* input_dims = input->dims;
   e342e:	f8d3 c008 	ldr.w	ip, [r3, #8]
  const TfLiteIntArray* output_dims = output0->dims;
   e3432:	6840      	ldr	r0, [r0, #4]
  switch (input->type) {
    case kTfLiteFloat32: {
      return UnpackImpl<float>(context, node, input, data->num, data->axis);
    }
    case kTfLiteInt32: {
      return UnpackImpl<int32_t>(context, node, input, data->num, data->axis);
   e3434:	f8d2 8000 	ldr.w	r8, [r2]
   e3438:	6852      	ldr	r2, [r2, #4]
template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteIntArray* output_dims = output0->dims;
   e343a:	2638      	movs	r6, #56	; 0x38
   e343c:	fb06 5500 	mla	r5, r6, r0, r5
  const int dimensions = input_dims->size;

  if (axis < 0) {
   e3440:	2a00      	cmp	r2, #0
template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteIntArray* output_dims = output0->dims;
   e3442:	68ae      	ldr	r6, [r5, #8]
  const int dimensions = input_dims->size;
   e3444:	f8dc 5000 	ldr.w	r5, [ip]

  if (axis < 0) {
    axis += NumDimensions(input);
   e3448:	bfb8      	it	lt
   e344a:	1952      	addlt	r2, r2, r5
  }

  TFLITE_DCHECK_LT(axis, dimensions);
   e344c:	4295      	cmp	r5, r2
   e344e:	dd8e      	ble.n	e336e <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x5a>
   e3450:	46e6      	mov	lr, ip
   e3452:	2000      	movs	r0, #0
   e3454:	2701      	movs	r7, #1

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e3456:	4282      	cmp	r2, r0
   e3458:	dd05      	ble.n	e3466 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x152>
    outer_size *= input_dims->data[i];
   e345a:	f85e 9f04 	ldr.w	r9, [lr, #4]!
  }

  TFLITE_DCHECK_LT(axis, dimensions);

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e345e:	3001      	adds	r0, #1
    outer_size *= input_dims->data[i];
   e3460:	fb09 f707 	mul.w	r7, r9, r7
   e3464:	e7f7      	b.n	e3456 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x142>
   e3466:	1c50      	adds	r0, r2, #1
   e3468:	f105 0e01 	add.w	lr, r5, #1
  }
  int copy_size = 1;
   e346c:	2201      	movs	r2, #1
   e346e:	3001      	adds	r0, #1
  for (int i = axis + 1; i < dimensions; ++i) {
   e3470:	4570      	cmp	r0, lr
   e3472:	d003      	beq.n	e347c <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x168>
    copy_size *= input_dims->data[i];
   e3474:	f85c 5020 	ldr.w	r5, [ip, r0, lsl #2]
   e3478:	436a      	muls	r2, r5
   e347a:	e7f8      	b.n	e346e <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x15a>
  }
  int output_size = 1;
  for (int i = 0; i < output_dims->size; ++i) {
   e347c:	f8d6 c000 	ldr.w	ip, [r6]
   e3480:	4630      	mov	r0, r6
   e3482:	2501      	movs	r5, #1
   e3484:	2600      	movs	r6, #0
   e3486:	45b4      	cmp	ip, r6
   e3488:	dd05      	ble.n	e3496 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x182>
    output_size *= output_dims->data[i];
   e348a:	f850 ef04 	ldr.w	lr, [r0, #4]!
  int copy_size = 1;
  for (int i = axis + 1; i < dimensions; ++i) {
    copy_size *= input_dims->data[i];
  }
  int output_size = 1;
  for (int i = 0; i < output_dims->size; ++i) {
   e348e:	3601      	adds	r6, #1
    output_size *= output_dims->data[i];
   e3490:	fb0e f505 	mul.w	r5, lr, r5
   e3494:	e7f7      	b.n	e3486 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x172>
  }
  TFLITE_DCHECK_EQ(output_size, copy_size * outer_size);
   e3496:	fb02 f007 	mul.w	r0, r2, r7
   e349a:	4285      	cmp	r5, r0
   e349c:	f47f af67 	bne.w	e336e <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x5a>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e34a0:	685b      	ldr	r3, [r3, #4]
   e34a2:	9302      	str	r3, [sp, #8]
   e34a4:	fb02 f308 	mul.w	r3, r2, r8
   e34a8:	009b      	lsls	r3, r3, #2
   e34aa:	2500      	movs	r5, #0
   e34ac:	ea4f 0c82 	mov.w	ip, r2, lsl #2
   e34b0:	9303      	str	r3, [sp, #12]

  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
   e34b2:	462e      	mov	r6, r5
    TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
   e34b4:	f04f 0938 	mov.w	r9, #56	; 0x38
  }
  TFLITE_DCHECK_EQ(output_size, copy_size * outer_size);

  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
   e34b8:	45b0      	cmp	r8, r6
   e34ba:	dd8d      	ble.n	e33d8 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xc4>
    TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
   e34bc:	684b      	ldr	r3, [r1, #4]
   e34be:	eb03 0386 	add.w	r3, r3, r6, lsl #2
   e34c2:	6858      	ldr	r0, [r3, #4]
   e34c4:	9b01      	ldr	r3, [sp, #4]
   e34c6:	689b      	ldr	r3, [r3, #8]
   e34c8:	fb09 3300 	mla	r3, r9, r0, r3

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e34cc:	b103      	cbz	r3, e34d0 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1bc>
   e34ce:	685b      	ldr	r3, [r3, #4]
   e34d0:	f04f 0e00 	mov.w	lr, #0
    T* output_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   e34d4:	46f2      	mov	sl, lr
   e34d6:	4557      	cmp	r7, sl
   e34d8:	dd12      	ble.n	e3500 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1ec>
      T* output_ptr = output_data + copy_size * k;
      int loc = k * output_count * copy_size + i * copy_size;
      const T* input_ptr = input_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   e34da:	9c02      	ldr	r4, [sp, #8]
   e34dc:	eb05 0b0e 	add.w	fp, r5, lr
  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
    T* output_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   e34e0:	2000      	movs	r0, #0
      T* output_ptr = output_data + copy_size * k;
      int loc = k * output_count * copy_size + i * copy_size;
      const T* input_ptr = input_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   e34e2:	44a3      	add	fp, r4
   e34e4:	4282      	cmp	r2, r0
   e34e6:	dd05      	ble.n	e34f4 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1e0>
   e34e8:	f85b 4020 	ldr.w	r4, [fp, r0, lsl #2]
   e34ec:	f843 4020 	str.w	r4, [r3, r0, lsl #2]
   e34f0:	3001      	adds	r0, #1
   e34f2:	e7f7      	b.n	e34e4 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1d0>
   e34f4:	9803      	ldr	r0, [sp, #12]
  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
    T* output_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   e34f6:	f10a 0a01 	add.w	sl, sl, #1
   e34fa:	4486      	add	lr, r0
   e34fc:	4463      	add	r3, ip
   e34fe:	e7ea      	b.n	e34d6 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1c2>
  }
  TFLITE_DCHECK_EQ(output_size, copy_size * outer_size);

  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
   e3500:	3601      	adds	r6, #1
   e3502:	4465      	add	r5, ip
   e3504:	e7d8      	b.n	e34b8 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x1a4>
    }
    case kTfLiteInt32: {
      return UnpackImpl<int32_t>(context, node, input, data->num, data->axis);
    }
    case kTfLiteUInt8: {
      return UnpackImpl<uint8_t>(context, node, input, data->num, data->axis);
   e3506:	6810      	ldr	r0, [r2, #0]
   e3508:	9002      	str	r0, [sp, #8]
}

template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
   e350a:	6848      	ldr	r0, [r1, #4]
  const TfLiteIntArray* input_dims = input->dims;
   e350c:	f8d3 c008 	ldr.w	ip, [r3, #8]
  const TfLiteIntArray* output_dims = output0->dims;
   e3510:	6840      	ldr	r0, [r0, #4]
    }
    case kTfLiteInt32: {
      return UnpackImpl<int32_t>(context, node, input, data->num, data->axis);
    }
    case kTfLiteUInt8: {
      return UnpackImpl<uint8_t>(context, node, input, data->num, data->axis);
   e3512:	6852      	ldr	r2, [r2, #4]
template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteIntArray* output_dims = output0->dims;
   e3514:	2638      	movs	r6, #56	; 0x38
   e3516:	fb06 5500 	mla	r5, r6, r0, r5
  const int dimensions = input_dims->size;

  if (axis < 0) {
   e351a:	2a00      	cmp	r2, #0
template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteIntArray* output_dims = output0->dims;
   e351c:	68af      	ldr	r7, [r5, #8]
  const int dimensions = input_dims->size;
   e351e:	f8dc 5000 	ldr.w	r5, [ip]

  if (axis < 0) {
    axis += NumDimensions(input);
   e3522:	bfb8      	it	lt
   e3524:	1952      	addlt	r2, r2, r5
  }

  TFLITE_DCHECK_LT(axis, dimensions);
   e3526:	4295      	cmp	r5, r2
   e3528:	f77f af21 	ble.w	e336e <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x5a>
   e352c:	46e6      	mov	lr, ip
   e352e:	2000      	movs	r0, #0
   e3530:	2601      	movs	r6, #1

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e3532:	4282      	cmp	r2, r0
   e3534:	dd05      	ble.n	e3542 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x22e>
    outer_size *= input_dims->data[i];
   e3536:	f85e 8f04 	ldr.w	r8, [lr, #4]!
  }

  TFLITE_DCHECK_LT(axis, dimensions);

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e353a:	3001      	adds	r0, #1
    outer_size *= input_dims->data[i];
   e353c:	fb08 f606 	mul.w	r6, r8, r6
   e3540:	e7f7      	b.n	e3532 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x21e>
   e3542:	1c50      	adds	r0, r2, #1
   e3544:	f105 0e01 	add.w	lr, r5, #1
  }
  int copy_size = 1;
   e3548:	2201      	movs	r2, #1
   e354a:	3001      	adds	r0, #1
  for (int i = axis + 1; i < dimensions; ++i) {
   e354c:	4570      	cmp	r0, lr
   e354e:	d003      	beq.n	e3558 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x244>
    copy_size *= input_dims->data[i];
   e3550:	f85c 5020 	ldr.w	r5, [ip, r0, lsl #2]
   e3554:	436a      	muls	r2, r5
   e3556:	e7f8      	b.n	e354a <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x236>
  }
  int output_size = 1;
  for (int i = 0; i < output_dims->size; ++i) {
   e3558:	f8d7 c000 	ldr.w	ip, [r7]
   e355c:	4638      	mov	r0, r7
   e355e:	2501      	movs	r5, #1
   e3560:	2700      	movs	r7, #0
   e3562:	45bc      	cmp	ip, r7
   e3564:	dd05      	ble.n	e3572 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x25e>
    output_size *= output_dims->data[i];
   e3566:	f850 ef04 	ldr.w	lr, [r0, #4]!
  int copy_size = 1;
  for (int i = axis + 1; i < dimensions; ++i) {
    copy_size *= input_dims->data[i];
  }
  int output_size = 1;
  for (int i = 0; i < output_dims->size; ++i) {
   e356a:	3701      	adds	r7, #1
    output_size *= output_dims->data[i];
   e356c:	fb0e f505 	mul.w	r5, lr, r5
   e3570:	e7f7      	b.n	e3562 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x24e>
  }
  TFLITE_DCHECK_EQ(output_size, copy_size * outer_size);
   e3572:	fb02 f006 	mul.w	r0, r2, r6
   e3576:	4285      	cmp	r5, r0
   e3578:	f47f aef9 	bne.w	e336e <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x5a>
   e357c:	6858      	ldr	r0, [r3, #4]
   e357e:	9b02      	ldr	r3, [sp, #8]
   e3580:	4247      	negs	r7, r0
   e3582:	fb02 f903 	mul.w	r9, r2, r3

  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
   e3586:	2500      	movs	r5, #0
   e3588:	9b02      	ldr	r3, [sp, #8]
   e358a:	42ab      	cmp	r3, r5
   e358c:	f77f af24 	ble.w	e33d8 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xc4>
    TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
   e3590:	684b      	ldr	r3, [r1, #4]
   e3592:	9c01      	ldr	r4, [sp, #4]
   e3594:	eb03 0385 	add.w	r3, r3, r5, lsl #2
   e3598:	68a4      	ldr	r4, [r4, #8]
   e359a:	685b      	ldr	r3, [r3, #4]
   e359c:	f04f 0e38 	mov.w	lr, #56	; 0x38
   e35a0:	fb0e 4303 	mla	r3, lr, r3, r4
   e35a4:	b103      	cbz	r3, e35a8 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x294>
   e35a6:	685b      	ldr	r3, [r3, #4]
   e35a8:	46be      	mov	lr, r7
   e35aa:	4684      	mov	ip, r0
    T* output_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   e35ac:	f04f 0800 	mov.w	r8, #0
   e35b0:	4546      	cmp	r6, r8
   e35b2:	dd11      	ble.n	e35d8 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x2c4>
   e35b4:	461c      	mov	r4, r3
   e35b6:	46e2      	mov	sl, ip
      T* output_ptr = output_data + copy_size * k;
      int loc = k * output_count * copy_size + i * copy_size;
      const T* input_ptr = input_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   e35b8:	eb0a 0b0e 	add.w	fp, sl, lr
   e35bc:	455a      	cmp	r2, fp
   e35be:	dd04      	ble.n	e35ca <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x2b6>
   e35c0:	f81a bb01 	ldrb.w	fp, [sl], #1
   e35c4:	f804 bb01 	strb.w	fp, [r4], #1
   e35c8:	e7f6      	b.n	e35b8 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x2a4>
  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
    T* output_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   e35ca:	f108 0801 	add.w	r8, r8, #1
   e35ce:	44cc      	add	ip, r9
   e35d0:	4413      	add	r3, r2
   e35d2:	ebc9 0e0e 	rsb	lr, r9, lr
   e35d6:	e7eb      	b.n	e35b0 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x29c>
  }
  TFLITE_DCHECK_EQ(output_size, copy_size * outer_size);

  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
   e35d8:	3501      	adds	r5, #1
   e35da:	4410      	add	r0, r2
   e35dc:	1abf      	subs	r7, r7, r2
   e35de:	e7d3      	b.n	e3588 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x274>
    }
    case kTfLiteUInt8: {
      return UnpackImpl<uint8_t>(context, node, input, data->num, data->axis);
    }
    case kTfLiteInt8: {
      return UnpackImpl<int8_t>(context, node, input, data->num, data->axis);
   e35e0:	6810      	ldr	r0, [r2, #0]
   e35e2:	9002      	str	r0, [sp, #8]
}

template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
   e35e4:	6848      	ldr	r0, [r1, #4]
  const TfLiteIntArray* input_dims = input->dims;
   e35e6:	f8d3 c008 	ldr.w	ip, [r3, #8]
  const TfLiteIntArray* output_dims = output0->dims;
   e35ea:	6840      	ldr	r0, [r0, #4]
    }
    case kTfLiteUInt8: {
      return UnpackImpl<uint8_t>(context, node, input, data->num, data->axis);
    }
    case kTfLiteInt8: {
      return UnpackImpl<int8_t>(context, node, input, data->num, data->axis);
   e35ec:	6852      	ldr	r2, [r2, #4]
template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteIntArray* output_dims = output0->dims;
   e35ee:	2638      	movs	r6, #56	; 0x38
   e35f0:	fb06 5500 	mla	r5, r6, r0, r5
  const int dimensions = input_dims->size;

  if (axis < 0) {
   e35f4:	2a00      	cmp	r2, #0
template <typename T>
TfLiteStatus UnpackImpl(TfLiteContext* context, TfLiteNode* node,
                        const TfLiteTensor* input, int output_count, int axis) {
  const TfLiteTensor* output0 = &context->tensors[node->outputs->data[0]];
  const TfLiteIntArray* input_dims = input->dims;
  const TfLiteIntArray* output_dims = output0->dims;
   e35f6:	68af      	ldr	r7, [r5, #8]
  const int dimensions = input_dims->size;
   e35f8:	f8dc 5000 	ldr.w	r5, [ip]

  if (axis < 0) {
    axis += NumDimensions(input);
   e35fc:	bfb8      	it	lt
   e35fe:	1952      	addlt	r2, r2, r5
  }

  TFLITE_DCHECK_LT(axis, dimensions);
   e3600:	4295      	cmp	r5, r2
   e3602:	f77f aeb4 	ble.w	e336e <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x5a>
   e3606:	46e6      	mov	lr, ip
   e3608:	2000      	movs	r0, #0
   e360a:	2601      	movs	r6, #1

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e360c:	4282      	cmp	r2, r0
   e360e:	dd05      	ble.n	e361c <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x308>
    outer_size *= input_dims->data[i];
   e3610:	f85e 8f04 	ldr.w	r8, [lr, #4]!
  }

  TFLITE_DCHECK_LT(axis, dimensions);

  int outer_size = 1;
  for (int i = 0; i < axis; ++i) {
   e3614:	3001      	adds	r0, #1
    outer_size *= input_dims->data[i];
   e3616:	fb08 f606 	mul.w	r6, r8, r6
   e361a:	e7f7      	b.n	e360c <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x2f8>
   e361c:	1c50      	adds	r0, r2, #1
   e361e:	f105 0e01 	add.w	lr, r5, #1
  }
  int copy_size = 1;
   e3622:	2201      	movs	r2, #1
   e3624:	3001      	adds	r0, #1
  for (int i = axis + 1; i < dimensions; ++i) {
   e3626:	4570      	cmp	r0, lr
   e3628:	d003      	beq.n	e3632 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x31e>
    copy_size *= input_dims->data[i];
   e362a:	f85c 5020 	ldr.w	r5, [ip, r0, lsl #2]
   e362e:	436a      	muls	r2, r5
   e3630:	e7f8      	b.n	e3624 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x310>
  }
  int output_size = 1;
  for (int i = 0; i < output_dims->size; ++i) {
   e3632:	f8d7 c000 	ldr.w	ip, [r7]
   e3636:	4638      	mov	r0, r7
   e3638:	2501      	movs	r5, #1
   e363a:	2700      	movs	r7, #0
   e363c:	45bc      	cmp	ip, r7
   e363e:	dd05      	ble.n	e364c <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x338>
    output_size *= output_dims->data[i];
   e3640:	f850 ef04 	ldr.w	lr, [r0, #4]!
  int copy_size = 1;
  for (int i = axis + 1; i < dimensions; ++i) {
    copy_size *= input_dims->data[i];
  }
  int output_size = 1;
  for (int i = 0; i < output_dims->size; ++i) {
   e3644:	3701      	adds	r7, #1
    output_size *= output_dims->data[i];
   e3646:	fb0e f505 	mul.w	r5, lr, r5
   e364a:	e7f7      	b.n	e363c <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x328>
  }
  TFLITE_DCHECK_EQ(output_size, copy_size * outer_size);
   e364c:	fb02 f006 	mul.w	r0, r2, r6
   e3650:	4285      	cmp	r5, r0
   e3652:	f47f ae8c 	bne.w	e336e <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x5a>
   e3656:	6858      	ldr	r0, [r3, #4]
   e3658:	9b02      	ldr	r3, [sp, #8]
   e365a:	4247      	negs	r7, r0
   e365c:	fb02 f903 	mul.w	r9, r2, r3

  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
   e3660:	2500      	movs	r5, #0
   e3662:	9b02      	ldr	r3, [sp, #8]
   e3664:	42ab      	cmp	r3, r5
   e3666:	f77f aeb7 	ble.w	e33d8 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0xc4>
    TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
   e366a:	684b      	ldr	r3, [r1, #4]
   e366c:	9c01      	ldr	r4, [sp, #4]
   e366e:	eb03 0385 	add.w	r3, r3, r5, lsl #2
   e3672:	68a4      	ldr	r4, [r4, #8]
   e3674:	685b      	ldr	r3, [r3, #4]
   e3676:	f04f 0e38 	mov.w	lr, #56	; 0x38
   e367a:	fb0e 4303 	mla	r3, lr, r3, r4
   e367e:	b103      	cbz	r3, e3682 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x36e>
   e3680:	685b      	ldr	r3, [r3, #4]
   e3682:	46be      	mov	lr, r7
   e3684:	4684      	mov	ip, r0
    T* output_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   e3686:	f04f 0800 	mov.w	r8, #0
   e368a:	4546      	cmp	r6, r8
   e368c:	dd11      	ble.n	e36b2 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x39e>
   e368e:	461c      	mov	r4, r3
   e3690:	46e2      	mov	sl, ip
      T* output_ptr = output_data + copy_size * k;
      int loc = k * output_count * copy_size + i * copy_size;
      const T* input_ptr = input_data + loc;
      for (int j = 0; j < copy_size; ++j) output_ptr[j] = input_ptr[j];
   e3692:	eb0a 0b0e 	add.w	fp, sl, lr
   e3696:	455a      	cmp	r2, fp
   e3698:	dd04      	ble.n	e36a4 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x390>
   e369a:	f91a bb01 	ldrsb.w	fp, [sl], #1
   e369e:	f804 bb01 	strb.w	fp, [r4], #1
   e36a2:	e7f6      	b.n	e3692 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x37e>
  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
    TfLiteTensor* t = &context->tensors[node->outputs->data[i]];
    T* output_data = GetTensorData<T>(t);
    for (int k = 0; k < outer_size; ++k) {
   e36a4:	f108 0801 	add.w	r8, r8, #1
   e36a8:	44cc      	add	ip, r9
   e36aa:	4413      	add	r3, r2
   e36ac:	ebc9 0e0e 	rsb	lr, r9, lr
   e36b0:	e7eb      	b.n	e368a <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x376>
  }
  TFLITE_DCHECK_EQ(output_size, copy_size * outer_size);

  const T* input_data = GetTensorData<T>(input);

  for (int i = 0; i < output_count; ++i) {
   e36b2:	3501      	adds	r5, #1
   e36b4:	4410      	add	r0, r2
   e36b6:	1abf      	subs	r7, r7, r2
   e36b8:	e7d3      	b.n	e3662 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x34e>
    }
    case kTfLiteInt8: {
      return UnpackImpl<int8_t>(context, node, input, data->num, data->axis);
    }
    default: {
      context->ReportError(context, "Type '%s' is not supported by unpack.",
   e36ba:	9b01      	ldr	r3, [sp, #4]
   e36bc:	695d      	ldr	r5, [r3, #20]
   e36be:	f7f0 fd35 	bl	d412c <TfLiteTypeGetName>
                           TfLiteTypeGetName(input->type));
   e36c2:	4904      	ldr	r1, [pc, #16]	; (e36d4 <_ZN6tflite3ops5micro6unpack12_GLOBAL__N_14EvalEP13TfLiteContextP10TfLiteNode+0x3c0>)
   e36c4:	4602      	mov	r2, r0
   e36c6:	9801      	ldr	r0, [sp, #4]
   e36c8:	47a8      	blx	r5
      return kTfLiteError;
   e36ca:	2001      	movs	r0, #1
    }
  }

  return kTfLiteOk;
}
   e36cc:	b005      	add	sp, #20
   e36ce:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e36d2:	bf00      	nop
   e36d4:	000ec9b8 	.word	0x000ec9b8

000e36d8 <_ZN6tflite3ops5micro15Register_UNPACKEv>:

TfLiteRegistration* Register_UNPACK() {
  static TfLiteRegistration r = {nullptr, nullptr, unpack::Prepare,
                                 unpack::Eval};
  return &r;
}
   e36d8:	4800      	ldr	r0, [pc, #0]	; (e36dc <_ZN6tflite3ops5micro15Register_UNPACKEv+0x4>)
   e36da:	4770      	bx	lr
   e36dc:	2003c1f0 	.word	0x2003c1f0

000e36e0 <_ZN6tflite3ops5micro14depthwise_conv4InitEP13TfLiteContextPKcj>:

}  // namespace

void* Init(TfLiteContext* context, const char* buffer, size_t length) {
  return nullptr;
}
   e36e0:	2000      	movs	r0, #0
   e36e2:	4770      	bx	lr

000e36e4 <_ZN6tflite3ops5micro14depthwise_conv4FreeEP13TfLiteContextPv>:

void Free(TfLiteContext* context, void* buffer) {}
   e36e4:	4770      	bx	lr

000e36e6 <_ZN6tflite3ops5micro14depthwise_conv7PrepareEP13TfLiteContextP10TfLiteNode>:

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  return kTfLiteOk;
}
   e36e6:	2000      	movs	r0, #0
   e36e8:	4770      	bx	lr

000e36ea <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa>:
    const DepthwiseParams& params, const int32* output_multiplier,
    const int32* output_shift, const RuntimeShape& input_shape,
    const int8* input_data, const RuntimeShape& filter_shape,
    const int8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int8* output_data) {
   e36ea:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e36ee:	b0a5      	sub	sp, #148	; 0x94
   e36f0:	469b      	mov	fp, r3
  // Get parameters.
  // TODO(b/141565753): Re-introduce ScopedProfilingLabel on Micro.
  const int stride_width = params.stride_width;
   e36f2:	f9b0 300a 	ldrsh.w	r3, [r0, #10]
   e36f6:	930f      	str	r3, [sp, #60]	; 0x3c
  const int stride_height = params.stride_height;
   e36f8:	f9b0 300c 	ldrsh.w	r3, [r0, #12]
   e36fc:	9310      	str	r3, [sp, #64]	; 0x40
  const int dilation_width_factor = params.dilation_width_factor;
   e36fe:	f9b0 300e 	ldrsh.w	r3, [r0, #14]
   e3702:	9311      	str	r3, [sp, #68]	; 0x44
  const int dilation_height_factor = params.dilation_height_factor;
   e3704:	f9b0 3010 	ldrsh.w	r3, [r0, #16]
   e3708:	9312      	str	r3, [sp, #72]	; 0x48
  const int pad_width = params.padding_values.width;
   e370a:	f9b0 3002 	ldrsh.w	r3, [r0, #2]
   e370e:	9313      	str	r3, [sp, #76]	; 0x4c
  const int pad_height = params.padding_values.height;
   e3710:	f9b0 3004 	ldrsh.w	r3, [r0, #4]
   e3714:	9314      	str	r3, [sp, #80]	; 0x50
  const int depth_multiplier = params.depth_multiplier;
   e3716:	f9b0 3012 	ldrsh.w	r3, [r0, #18]
   e371a:	9308      	str	r3, [sp, #32]
  const int32 input_offset = params.input_offset;
   e371c:	6943      	ldr	r3, [r0, #20]
   e371e:	9315      	str	r3, [sp, #84]	; 0x54
  const int32 output_offset = params.output_offset;
   e3720:	69c3      	ldr	r3, [r0, #28]
   e3722:	9316      	str	r3, [sp, #88]	; 0x58
  const int32 output_activation_min = params.quantized_activation_min;
   e3724:	6a83      	ldr	r3, [r0, #40]	; 0x28
   e3726:	930b      	str	r3, [sp, #44]	; 0x2c
  const int32 output_activation_max = params.quantized_activation_max;
   e3728:	6ac3      	ldr	r3, [r0, #44]	; 0x2c
   e372a:	930c      	str	r3, [sp, #48]	; 0x30

  // Check dimensions of the tensors.
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e372c:	f8db 3000 	ldr.w	r3, [fp]
    const DepthwiseParams& params, const int32* output_multiplier,
    const int32* output_shift, const RuntimeShape& input_shape,
    const int8* input_data, const RuntimeShape& filter_shape,
    const int8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int8* output_data) {
   e3730:	9122      	str	r1, [sp, #136]	; 0x88
  const int32 output_offset = params.output_offset;
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;

  // Check dimensions of the tensors.
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e3732:	2b04      	cmp	r3, #4
    const DepthwiseParams& params, const int32* output_multiplier,
    const int32* output_shift, const RuntimeShape& input_shape,
    const int8* input_data, const RuntimeShape& filter_shape,
    const int8* filter_data, const RuntimeShape& bias_shape,
    const int32* bias_data, const RuntimeShape& output_shape,
    int8* output_data) {
   e3734:	9223      	str	r2, [sp, #140]	; 0x8c
   e3736:	f8dd a0cc 	ldr.w	sl, [sp, #204]	; 0xcc
  const int32 output_offset = params.output_offset;
  const int32 output_activation_min = params.quantized_activation_min;
  const int32 output_activation_max = params.quantized_activation_max;

  // Check dimensions of the tensors.
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e373a:	d001      	beq.n	e3740 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x56>
   e373c:	f001 feda 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
   e3740:	9b2f      	ldr	r3, [sp, #188]	; 0xbc
   e3742:	681b      	ldr	r3, [r3, #0]
   e3744:	2b04      	cmp	r3, #4
   e3746:	d1f9      	bne.n	e373c <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x52>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   e3748:	f8da 3000 	ldr.w	r3, [sl]
   e374c:	2b04      	cmp	r3, #4
   e374e:	d1f5      	bne.n	e373c <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x52>

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
   e3750:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e3752:	9a0c      	ldr	r2, [sp, #48]	; 0x30
   e3754:	4293      	cmp	r3, r2
   e3756:	dcf1      	bgt.n	e373c <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x52>
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   e3758:	2300      	movs	r3, #0
   e375a:	4619      	mov	r1, r3
   e375c:	4652      	mov	r2, sl
   e375e:	4658      	mov	r0, fp
   e3760:	f7f9 fabf 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e3764:	2303      	movs	r3, #3
   e3766:	4619      	mov	r1, r3
   e3768:	4652      	mov	r2, sl
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   e376a:	9017      	str	r0, [sp, #92]	; 0x5c
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e376c:	982f      	ldr	r0, [sp, #188]	; 0xbc
   e376e:	f7f9 fab8 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_height = input_shape.Dims(1);
   e3772:	2101      	movs	r1, #1
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e3774:	4604      	mov	r4, r0
  const int input_height = input_shape.Dims(1);
   e3776:	4658      	mov	r0, fp
   e3778:	f7f3 ff02 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   e377c:	2102      	movs	r1, #2
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
   e377e:	9018      	str	r0, [sp, #96]	; 0x60
  const int input_width = input_shape.Dims(2);
   e3780:	4658      	mov	r0, fp
   e3782:	f7f3 fefd 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_depth = input_shape.Dims(3);
   e3786:	2103      	movs	r1, #3

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   e3788:	9019      	str	r0, [sp, #100]	; 0x64
  const int input_depth = input_shape.Dims(3);
   e378a:	4658      	mov	r0, fp
   e378c:	f7f3 fef8 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_height = filter_shape.Dims(1);
   e3790:	2101      	movs	r1, #1
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
   e3792:	900d      	str	r0, [sp, #52]	; 0x34
  const int filter_height = filter_shape.Dims(1);
   e3794:	982f      	ldr	r0, [sp, #188]	; 0xbc
   e3796:	f7f3 fef3 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_width = filter_shape.Dims(2);
   e379a:	2102      	movs	r1, #2
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
   e379c:	901a      	str	r0, [sp, #104]	; 0x68
  const int filter_width = filter_shape.Dims(2);
   e379e:	982f      	ldr	r0, [sp, #188]	; 0xbc
   e37a0:	f7f3 feee 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   e37a4:	2101      	movs	r1, #1
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
   e37a6:	901b      	str	r0, [sp, #108]	; 0x6c
  const int output_height = output_shape.Dims(1);
   e37a8:	4650      	mov	r0, sl
   e37aa:	f7f3 fee9 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   e37ae:	2102      	movs	r1, #2
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   e37b0:	901c      	str	r0, [sp, #112]	; 0x70
  const int output_width = output_shape.Dims(2);
   e37b2:	4650      	mov	r0, sl
   e37b4:	f7f3 fee4 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
   e37b8:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   e37ba:	9a08      	ldr	r2, [sp, #32]
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   e37bc:	901d      	str	r0, [sp, #116]	; 0x74
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
   e37be:	4353      	muls	r3, r2
   e37c0:	429c      	cmp	r4, r3
   e37c2:	d1bb      	bne.n	e373c <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x52>
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
   e37c4:	9831      	ldr	r0, [sp, #196]	; 0xc4
   e37c6:	f7f9 fa7c 	bl	dccc2 <_ZNK6tflite12RuntimeShape8FlatSizeEv>
   e37ca:	4284      	cmp	r4, r0
   e37cc:	d1b6      	bne.n	e373c <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x52>
   e37ce:	f04f 0900 	mov.w	r9, #0

  for (int batch = 0; batch < batches; ++batch) {
   e37d2:	9b17      	ldr	r3, [sp, #92]	; 0x5c
   e37d4:	4599      	cmp	r9, r3
   e37d6:	f280 80ab 	bge.w	e3930 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x246>
   e37da:	9b14      	ldr	r3, [sp, #80]	; 0x50
   e37dc:	425b      	negs	r3, r3
   e37de:	9309      	str	r3, [sp, #36]	; 0x24
   e37e0:	2300      	movs	r3, #0
   e37e2:	9303      	str	r3, [sp, #12]
    for (int out_y = 0; out_y < output_height; ++out_y) {
   e37e4:	9b03      	ldr	r3, [sp, #12]
   e37e6:	9a1c      	ldr	r2, [sp, #112]	; 0x70
   e37e8:	4293      	cmp	r3, r2
   e37ea:	f280 8083 	bge.w	e38f4 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x20a>
   e37ee:	9b13      	ldr	r3, [sp, #76]	; 0x4c
   e37f0:	425b      	negs	r3, r3
   e37f2:	930a      	str	r3, [sp, #40]	; 0x28
   e37f4:	2300      	movs	r3, #0
   e37f6:	9304      	str	r3, [sp, #16]
      for (int out_x = 0; out_x < output_width; ++out_x) {
   e37f8:	9b04      	ldr	r3, [sp, #16]
   e37fa:	9a1d      	ldr	r2, [sp, #116]	; 0x74
   e37fc:	4293      	cmp	r3, r2
   e37fe:	da71      	bge.n	e38e4 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x1fa>
   e3800:	f04f 0800 	mov.w	r8, #0
   e3804:	f8cd 8014 	str.w	r8, [sp, #20]
        for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
   e3808:	9b05      	ldr	r3, [sp, #20]
   e380a:	9a0d      	ldr	r2, [sp, #52]	; 0x34
   e380c:	4293      	cmp	r3, r2
   e380e:	da61      	bge.n	e38d4 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x1ea>
   e3810:	9a32      	ldr	r2, [sp, #200]	; 0xc8
   e3812:	ea4f 0388 	mov.w	r3, r8, lsl #2
   e3816:	441a      	add	r2, r3
   e3818:	9221      	str	r2, [sp, #132]	; 0x84
   e381a:	9a22      	ldr	r2, [sp, #136]	; 0x88
   e381c:	441a      	add	r2, r3
   e381e:	9220      	str	r2, [sp, #128]	; 0x80
   e3820:	9a23      	ldr	r2, [sp, #140]	; 0x8c
   e3822:	18d3      	adds	r3, r2, r3
   e3824:	931f      	str	r3, [sp, #124]	; 0x7c
   e3826:	2400      	movs	r4, #0
          for (int m = 0; m < depth_multiplier; ++m) {
   e3828:	9b08      	ldr	r3, [sp, #32]
   e382a:	429c      	cmp	r4, r3
   e382c:	da4c      	bge.n	e38c8 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x1de>
   e382e:	eb08 0304 	add.w	r3, r8, r4
            const int output_channel = m + in_channel * depth_multiplier;
            const int in_x_origin = (out_x * stride_width) - pad_width;
            const int in_y_origin = (out_y * stride_height) - pad_height;
            int32 acc = 0;
   e3832:	2500      	movs	r5, #0

  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
          for (int m = 0; m < depth_multiplier; ++m) {
   e3834:	9e09      	ldr	r6, [sp, #36]	; 0x24
   e3836:	930e      	str	r3, [sp, #56]	; 0x38
            const int output_channel = m + in_channel * depth_multiplier;
            const int in_x_origin = (out_x * stride_width) - pad_width;
            const int in_y_origin = (out_y * stride_height) - pad_height;
            int32 acc = 0;
            for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   e3838:	9506      	str	r5, [sp, #24]
   e383a:	9b06      	ldr	r3, [sp, #24]
   e383c:	9a1a      	ldr	r2, [sp, #104]	; 0x68
   e383e:	4293      	cmp	r3, r2
   e3840:	da1c      	bge.n	e387c <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x192>
   e3842:	2300      	movs	r3, #0
   e3844:	9f0a      	ldr	r7, [sp, #40]	; 0x28
   e3846:	9307      	str	r3, [sp, #28]
              for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   e3848:	9b07      	ldr	r3, [sp, #28]
   e384a:	9a1b      	ldr	r2, [sp, #108]	; 0x6c
   e384c:	4293      	cmp	r3, r2
   e384e:	da0f      	bge.n	e3870 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x186>
                const int in_x = in_x_origin + dilation_width_factor * filter_x;
                const int in_y =
                    in_y_origin + dilation_height_factor * filter_y;
                // Zero padding by omitting the areas outside the image.
                const bool is_point_inside_image =
                    (in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
   e3850:	2f00      	cmp	r7, #0
   e3852:	db07      	blt.n	e3864 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x17a>
   e3854:	9b19      	ldr	r3, [sp, #100]	; 0x64
   e3856:	42bb      	cmp	r3, r7
   e3858:	dd04      	ble.n	e3864 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x17a>
   e385a:	2e00      	cmp	r6, #0
   e385c:	db02      	blt.n	e3864 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x17a>
   e385e:	9b18      	ldr	r3, [sp, #96]	; 0x60
   e3860:	42b3      	cmp	r3, r6
   e3862:	dc4a      	bgt.n	e38fa <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x210>
            const int output_channel = m + in_channel * depth_multiplier;
            const int in_x_origin = (out_x * stride_width) - pad_width;
            const int in_y_origin = (out_y * stride_height) - pad_height;
            int32 acc = 0;
            for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
              for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   e3864:	9b07      	ldr	r3, [sp, #28]
   e3866:	3301      	adds	r3, #1
   e3868:	9307      	str	r3, [sp, #28]
   e386a:	9b11      	ldr	r3, [sp, #68]	; 0x44
   e386c:	441f      	add	r7, r3
   e386e:	e7eb      	b.n	e3848 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x15e>
          for (int m = 0; m < depth_multiplier; ++m) {
            const int output_channel = m + in_channel * depth_multiplier;
            const int in_x_origin = (out_x * stride_width) - pad_width;
            const int in_y_origin = (out_y * stride_height) - pad_height;
            int32 acc = 0;
            for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   e3870:	9b06      	ldr	r3, [sp, #24]
   e3872:	3301      	adds	r3, #1
   e3874:	9306      	str	r3, [sp, #24]
   e3876:	9b12      	ldr	r3, [sp, #72]	; 0x48
   e3878:	441e      	add	r6, r3
   e387a:	e7de      	b.n	e383a <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x150>
                  // accumulator depth is smaller than 2^16.
                  acc += filter_val * (input_val + input_offset);
                }
              }
            }
            if (bias_data) {
   e387c:	9b32      	ldr	r3, [sp, #200]	; 0xc8
   e387e:	b11b      	cbz	r3, e3888 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x19e>
              acc += bias_data[output_channel];
   e3880:	9b21      	ldr	r3, [sp, #132]	; 0x84
   e3882:	f853 3024 	ldr.w	r3, [r3, r4, lsl #2]
   e3886:	441d      	add	r5, r3
            }
            acc = MultiplyByQuantizedMultiplier(
   e3888:	9b1f      	ldr	r3, [sp, #124]	; 0x7c
   e388a:	f853 2024 	ldr.w	r2, [r3, r4, lsl #2]
   e388e:	9b20      	ldr	r3, [sp, #128]	; 0x80
   e3890:	4628      	mov	r0, r5
   e3892:	f853 1024 	ldr.w	r1, [r3, r4, lsl #2]
   e3896:	f7f9 fa33 	bl	dcd00 <_ZN6tflite29MultiplyByQuantizedMultiplierElli>
                acc, output_multiplier[output_channel],
                output_shift[output_channel]);
            acc += output_offset;
   e389a:	9b16      	ldr	r3, [sp, #88]	; 0x58
            acc = std::max(acc, output_activation_min);
            acc = std::min(acc, output_activation_max);
            output_data[Offset(output_shape, batch, out_y, out_x,
   e389c:	9a03      	ldr	r2, [sp, #12]
              acc += bias_data[output_channel];
            }
            acc = MultiplyByQuantizedMultiplier(
                acc, output_multiplier[output_channel],
                output_shift[output_channel]);
            acc += output_offset;
   e389e:	4418      	add	r0, r3
   e38a0:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e38a2:	4283      	cmp	r3, r0
   e38a4:	bfb8      	it	lt
   e38a6:	4603      	movlt	r3, r0
   e38a8:	461d      	mov	r5, r3
   e38aa:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   e38ac:	429d      	cmp	r5, r3
   e38ae:	bfa8      	it	ge
   e38b0:	461d      	movge	r5, r3
            acc = std::max(acc, output_activation_min);
            acc = std::min(acc, output_activation_max);
            output_data[Offset(output_shape, batch, out_y, out_x,
   e38b2:	9b0e      	ldr	r3, [sp, #56]	; 0x38
   e38b4:	9300      	str	r3, [sp, #0]
   e38b6:	4649      	mov	r1, r9
   e38b8:	9b04      	ldr	r3, [sp, #16]
   e38ba:	4650      	mov	r0, sl
   e38bc:	f7f3 fec5 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                               output_channel)] = static_cast<int8_t>(acc);
   e38c0:	9b34      	ldr	r3, [sp, #208]	; 0xd0

  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
          for (int m = 0; m < depth_multiplier; ++m) {
   e38c2:	3401      	adds	r4, #1
                output_shift[output_channel]);
            acc += output_offset;
            acc = std::max(acc, output_activation_min);
            acc = std::min(acc, output_activation_max);
            output_data[Offset(output_shape, batch, out_y, out_x,
                               output_channel)] = static_cast<int8_t>(acc);
   e38c4:	541d      	strb	r5, [r3, r0]

  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
          for (int m = 0; m < depth_multiplier; ++m) {
   e38c6:	e7af      	b.n	e3828 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x13e>
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int in_channel = 0; in_channel < input_depth; ++in_channel) {
   e38c8:	9b05      	ldr	r3, [sp, #20]
   e38ca:	3301      	adds	r3, #1
   e38cc:	9305      	str	r3, [sp, #20]
   e38ce:	9b08      	ldr	r3, [sp, #32]
   e38d0:	4498      	add	r8, r3
   e38d2:	e799      	b.n	e3808 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x11e>
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   e38d4:	9b04      	ldr	r3, [sp, #16]
   e38d6:	9a0f      	ldr	r2, [sp, #60]	; 0x3c
   e38d8:	3301      	adds	r3, #1
   e38da:	9304      	str	r3, [sp, #16]
   e38dc:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e38de:	4413      	add	r3, r2
   e38e0:	930a      	str	r3, [sp, #40]	; 0x28
   e38e2:	e789      	b.n	e37f8 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x10e>
  const int output_width = output_shape.Dims(2);
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

  for (int batch = 0; batch < batches; ++batch) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   e38e4:	9b03      	ldr	r3, [sp, #12]
   e38e6:	9a10      	ldr	r2, [sp, #64]	; 0x40
   e38e8:	3301      	adds	r3, #1
   e38ea:	9303      	str	r3, [sp, #12]
   e38ec:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e38ee:	4413      	add	r3, r2
   e38f0:	9309      	str	r3, [sp, #36]	; 0x24
   e38f2:	e777      	b.n	e37e4 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0xfa>
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

  for (int batch = 0; batch < batches; ++batch) {
   e38f4:	f109 0901 	add.w	r9, r9, #1
   e38f8:	e76b      	b.n	e37d2 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0xe8>
                // Zero padding by omitting the areas outside the image.
                const bool is_point_inside_image =
                    (in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                    (in_y < input_height);
                if (is_point_inside_image) {
                  int32 input_val = input_data[Offset(input_shape, batch, in_y,
   e38fa:	9b05      	ldr	r3, [sp, #20]
   e38fc:	9300      	str	r3, [sp, #0]
   e38fe:	4632      	mov	r2, r6
   e3900:	463b      	mov	r3, r7
   e3902:	4649      	mov	r1, r9
   e3904:	4658      	mov	r0, fp
   e3906:	f7f3 fea0 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                                                      in_x, in_channel)];
                  int32 filter_val = filter_data[Offset(
   e390a:	9b0e      	ldr	r3, [sp, #56]	; 0x38
                // Zero padding by omitting the areas outside the image.
                const bool is_point_inside_image =
                    (in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                    (in_y < input_height);
                if (is_point_inside_image) {
                  int32 input_val = input_data[Offset(input_shape, batch, in_y,
   e390c:	901e      	str	r0, [sp, #120]	; 0x78
                                                      in_x, in_channel)];
                  int32 filter_val = filter_data[Offset(
   e390e:	9300      	str	r3, [sp, #0]
   e3910:	9a06      	ldr	r2, [sp, #24]
   e3912:	9b07      	ldr	r3, [sp, #28]
   e3914:	982f      	ldr	r0, [sp, #188]	; 0xbc
   e3916:	2100      	movs	r1, #0
   e3918:	f7f3 fe97 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                  // long as the filter size (filter_y * filter_x * in_channel)
                  // does not exceed 2^16, which is the case in all the models
                  // we have seen so far.
                  // TODO(jianlijianli): Add a check to make sure the
                  // accumulator depth is smaller than 2^16.
                  acc += filter_val * (input_val + input_offset);
   e391c:	9a1e      	ldr	r2, [sp, #120]	; 0x78
   e391e:	9b2e      	ldr	r3, [sp, #184]	; 0xb8
   e3920:	569b      	ldrsb	r3, [r3, r2]
   e3922:	9a15      	ldr	r2, [sp, #84]	; 0x54
   e3924:	4413      	add	r3, r2
   e3926:	9a30      	ldr	r2, [sp, #192]	; 0xc0
   e3928:	5612      	ldrsb	r2, [r2, r0]
   e392a:	fb02 5503 	mla	r5, r2, r3, r5
   e392e:	e799      	b.n	e3864 <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa+0x17a>
          }
        }
      }
    }
  }
}
   e3930:	b025      	add	sp, #148	; 0x94
   e3932:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	...

000e3938 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf>:
inline void DepthwiseConv(
    const DepthwiseParams& params, const RuntimeShape& input_shape,
    const float* input_data, const RuntimeShape& filter_shape,
    const float* filter_data, const RuntimeShape& bias_shape,
    const float* bias_data, const RuntimeShape& output_shape,
    float* output_data) {
   e3938:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e393c:	ed2d 8b04 	vpush	{d8-d9}
   e3940:	b09d      	sub	sp, #116	; 0x74
   e3942:	4698      	mov	r8, r3
  const int stride_width = params.stride_width;
   e3944:	f9b0 300a 	ldrsh.w	r3, [r0, #10]
   e3948:	930d      	str	r3, [sp, #52]	; 0x34
  const int stride_height = params.stride_height;
   e394a:	f9b0 300c 	ldrsh.w	r3, [r0, #12]
   e394e:	930e      	str	r3, [sp, #56]	; 0x38
  const int dilation_width_factor = params.dilation_width_factor;
   e3950:	f9b0 300e 	ldrsh.w	r3, [r0, #14]
   e3954:	930f      	str	r3, [sp, #60]	; 0x3c
  const int dilation_height_factor = params.dilation_height_factor;
   e3956:	f9b0 3010 	ldrsh.w	r3, [r0, #16]
   e395a:	9310      	str	r3, [sp, #64]	; 0x40
  const int pad_width = params.padding_values.width;
   e395c:	f9b0 3002 	ldrsh.w	r3, [r0, #2]
   e3960:	9311      	str	r3, [sp, #68]	; 0x44
  const int pad_height = params.padding_values.height;
   e3962:	f9b0 3004 	ldrsh.w	r3, [r0, #4]
   e3966:	9312      	str	r3, [sp, #72]	; 0x48
  const int depth_multiplier = params.depth_multiplier;
   e3968:	f9b0 3012 	ldrsh.w	r3, [r0, #18]
   e396c:	9307      	str	r3, [sp, #28]
  const float output_activation_min = params.float_activation_min;
  const float output_activation_max = params.float_activation_max;
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e396e:	680b      	ldr	r3, [r1, #0]
inline void DepthwiseConv(
    const DepthwiseParams& params, const RuntimeShape& input_shape,
    const float* input_data, const RuntimeShape& filter_shape,
    const float* filter_data, const RuntimeShape& bias_shape,
    const float* bias_data, const RuntimeShape& output_shape,
    float* output_data) {
   e3970:	921b      	str	r2, [sp, #108]	; 0x6c
  const int pad_width = params.padding_values.width;
  const int pad_height = params.padding_values.height;
  const int depth_multiplier = params.depth_multiplier;
  const float output_activation_min = params.float_activation_min;
  const float output_activation_max = params.float_activation_max;
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e3972:	2b04      	cmp	r3, #4
inline void DepthwiseConv(
    const DepthwiseParams& params, const RuntimeShape& input_shape,
    const float* input_data, const RuntimeShape& filter_shape,
    const float* filter_data, const RuntimeShape& bias_shape,
    const float* bias_data, const RuntimeShape& output_shape,
    float* output_data) {
   e3974:	460f      	mov	r7, r1
   e3976:	f8dd 90b4 	ldr.w	r9, [sp, #180]	; 0xb4
  const int dilation_width_factor = params.dilation_width_factor;
  const int dilation_height_factor = params.dilation_height_factor;
  const int pad_width = params.padding_values.width;
  const int pad_height = params.padding_values.height;
  const int depth_multiplier = params.depth_multiplier;
  const float output_activation_min = params.float_activation_min;
   e397a:	edd0 8a0c 	vldr	s17, [r0, #48]	; 0x30
  const float output_activation_max = params.float_activation_max;
   e397e:	ed90 9a0d 	vldr	s18, [r0, #52]	; 0x34
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e3982:	d001      	beq.n	e3988 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x50>
   e3984:	f001 fdb6 	bl	e54f4 <abort>
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
   e3988:	f8d8 3000 	ldr.w	r3, [r8]
   e398c:	2b04      	cmp	r3, #4
   e398e:	d1f9      	bne.n	e3984 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x4c>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   e3990:	f8d9 3000 	ldr.w	r3, [r9]
   e3994:	2b04      	cmp	r3, #4
   e3996:	d1f5      	bne.n	e3984 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x4c>

  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   e3998:	2300      	movs	r3, #0
   e399a:	4619      	mov	r1, r3
   e399c:	464a      	mov	r2, r9
   e399e:	4638      	mov	r0, r7
   e39a0:	f7f9 f99f 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e39a4:	2303      	movs	r3, #3
   e39a6:	4619      	mov	r1, r3
   e39a8:	464a      	mov	r2, r9
  const float output_activation_max = params.float_activation_max;
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   e39aa:	9013      	str	r0, [sp, #76]	; 0x4c
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e39ac:	4640      	mov	r0, r8
   e39ae:	f7f9 f998 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_height = input_shape.Dims(1);
   e39b2:	2101      	movs	r1, #1
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e39b4:	4604      	mov	r4, r0
  const int input_height = input_shape.Dims(1);
   e39b6:	4638      	mov	r0, r7
   e39b8:	f7f3 fde2 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   e39bc:	2102      	movs	r1, #2
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
   e39be:	9014      	str	r0, [sp, #80]	; 0x50
  const int input_width = input_shape.Dims(2);
   e39c0:	4638      	mov	r0, r7
   e39c2:	f7f3 fddd 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_depth = input_shape.Dims(3);
   e39c6:	2103      	movs	r1, #3
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   e39c8:	9015      	str	r0, [sp, #84]	; 0x54
  const int input_depth = input_shape.Dims(3);
   e39ca:	4638      	mov	r0, r7
   e39cc:	f7f3 fdd8 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_height = filter_shape.Dims(1);
   e39d0:	2101      	movs	r1, #1

  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
   e39d2:	900b      	str	r0, [sp, #44]	; 0x2c
  const int filter_height = filter_shape.Dims(1);
   e39d4:	4640      	mov	r0, r8
   e39d6:	f7f3 fdd3 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_width = filter_shape.Dims(2);
   e39da:	2102      	movs	r1, #2
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
   e39dc:	9016      	str	r0, [sp, #88]	; 0x58
  const int filter_width = filter_shape.Dims(2);
   e39de:	4640      	mov	r0, r8
   e39e0:	f7f3 fdce 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   e39e4:	2101      	movs	r1, #1
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
   e39e6:	9017      	str	r0, [sp, #92]	; 0x5c
  const int output_height = output_shape.Dims(1);
   e39e8:	4648      	mov	r0, r9
   e39ea:	f7f3 fdc9 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   e39ee:	2102      	movs	r1, #2
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   e39f0:	9018      	str	r0, [sp, #96]	; 0x60
  const int output_width = output_shape.Dims(2);
   e39f2:	4648      	mov	r0, r9
   e39f4:	f7f3 fdc4 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
   e39f8:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e39fa:	9a07      	ldr	r2, [sp, #28]
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   e39fc:	9019      	str	r0, [sp, #100]	; 0x64
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
   e39fe:	4353      	muls	r3, r2
   e3a00:	429c      	cmp	r4, r3
   e3a02:	d1bf      	bne.n	e3984 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x4c>
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
   e3a04:	982b      	ldr	r0, [sp, #172]	; 0xac
   e3a06:	f7f9 f95c 	bl	dccc2 <_ZNK6tflite12RuntimeShape8FlatSizeEv>
   e3a0a:	4284      	cmp	r4, r0
   e3a0c:	d1ba      	bne.n	e3984 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x4c>
   e3a0e:	f04f 0b00 	mov.w	fp, #0

  for (int b = 0; b < batches; ++b) {
   e3a12:	9b13      	ldr	r3, [sp, #76]	; 0x4c
   e3a14:	459b      	cmp	fp, r3
   e3a16:	f280 80ad 	bge.w	e3b74 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x23c>
   e3a1a:	9b12      	ldr	r3, [sp, #72]	; 0x48
   e3a1c:	425b      	negs	r3, r3
   e3a1e:	9309      	str	r3, [sp, #36]	; 0x24
   e3a20:	2300      	movs	r3, #0
   e3a22:	9302      	str	r3, [sp, #8]
    for (int out_y = 0; out_y < output_height; ++out_y) {
   e3a24:	9b02      	ldr	r3, [sp, #8]
   e3a26:	9a18      	ldr	r2, [sp, #96]	; 0x60
   e3a28:	4293      	cmp	r3, r2
   e3a2a:	f280 80a0 	bge.w	e3b6e <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x236>
   e3a2e:	9b11      	ldr	r3, [sp, #68]	; 0x44
   e3a30:	425b      	negs	r3, r3
   e3a32:	9308      	str	r3, [sp, #32]
   e3a34:	2300      	movs	r3, #0
   e3a36:	9303      	str	r3, [sp, #12]
      for (int out_x = 0; out_x < output_width; ++out_x) {
   e3a38:	9b03      	ldr	r3, [sp, #12]
   e3a3a:	9a19      	ldr	r2, [sp, #100]	; 0x64
   e3a3c:	4293      	cmp	r3, r2
   e3a3e:	f280 808e 	bge.w	e3b5e <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x226>
   e3a42:	2400      	movs	r4, #0
   e3a44:	9404      	str	r4, [sp, #16]
        for (int ic = 0; ic < input_depth; ++ic) {
   e3a46:	9b04      	ldr	r3, [sp, #16]
   e3a48:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   e3a4a:	4293      	cmp	r3, r2
   e3a4c:	da7f      	bge.n	e3b4e <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x216>
   e3a4e:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   e3a50:	eb03 0384 	add.w	r3, r3, r4, lsl #2
   e3a54:	930a      	str	r3, [sp, #40]	; 0x28
   e3a56:	2300      	movs	r3, #0
   e3a58:	9305      	str	r3, [sp, #20]
          for (int m = 0; m < depth_multiplier; m++) {
   e3a5a:	9b05      	ldr	r3, [sp, #20]
   e3a5c:	9a07      	ldr	r2, [sp, #28]
   e3a5e:	4293      	cmp	r3, r2
   e3a60:	da6f      	bge.n	e3b42 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x20a>
   e3a62:	4423      	add	r3, r4
   e3a64:	930c      	str	r3, [sp, #48]	; 0x30
   e3a66:	9d09      	ldr	r5, [sp, #36]	; 0x24
            const int oc = m + ic * depth_multiplier;
            const int in_x_origin = (out_x * stride_width) - pad_width;
            const int in_y_origin = (out_y * stride_height) - pad_height;
            float total = 0.f;
   e3a68:	ed9f 8a45 	vldr	s16, [pc, #276]	; e3b80 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x248>
            for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   e3a6c:	2300      	movs	r3, #0
   e3a6e:	9306      	str	r3, [sp, #24]
   e3a70:	9b06      	ldr	r3, [sp, #24]
   e3a72:	9a16      	ldr	r2, [sp, #88]	; 0x58
   e3a74:	4293      	cmp	r3, r2
   e3a76:	da38      	bge.n	e3aea <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x1b2>
   e3a78:	9e08      	ldr	r6, [sp, #32]
   e3a7a:	f04f 0a00 	mov.w	sl, #0
              for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   e3a7e:	9b17      	ldr	r3, [sp, #92]	; 0x5c
   e3a80:	459a      	cmp	sl, r3
   e3a82:	da2c      	bge.n	e3ade <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x1a6>
                const int in_x = in_x_origin + dilation_width_factor * filter_x;
                const int in_y =
                    in_y_origin + dilation_height_factor * filter_y;
                // If the location is outside the bounds of the input image,
                // use zero as a default value.
                if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
   e3a84:	2e00      	cmp	r6, #0
   e3a86:	db25      	blt.n	e3ad4 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x19c>
   e3a88:	9b15      	ldr	r3, [sp, #84]	; 0x54
   e3a8a:	42b3      	cmp	r3, r6
   e3a8c:	dd22      	ble.n	e3ad4 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x19c>
   e3a8e:	2d00      	cmp	r5, #0
   e3a90:	db20      	blt.n	e3ad4 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x19c>
   e3a92:	9b14      	ldr	r3, [sp, #80]	; 0x50
   e3a94:	42ab      	cmp	r3, r5
   e3a96:	dd1d      	ble.n	e3ad4 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x19c>
                    (in_y < input_height)) {
                  float input_value =
                      input_data[Offset(input_shape, b, in_y, in_x, ic)];
   e3a98:	9b04      	ldr	r3, [sp, #16]
   e3a9a:	9300      	str	r3, [sp, #0]
   e3a9c:	462a      	mov	r2, r5
   e3a9e:	4633      	mov	r3, r6
   e3aa0:	4659      	mov	r1, fp
   e3aa2:	4638      	mov	r0, r7
   e3aa4:	f7f3 fdd1 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                  float filter_value = filter_data[Offset(
   e3aa8:	9b0c      	ldr	r3, [sp, #48]	; 0x30
                // If the location is outside the bounds of the input image,
                // use zero as a default value.
                if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                    (in_y < input_height)) {
                  float input_value =
                      input_data[Offset(input_shape, b, in_y, in_x, ic)];
   e3aaa:	901a      	str	r0, [sp, #104]	; 0x68
                  float filter_value = filter_data[Offset(
   e3aac:	9300      	str	r3, [sp, #0]
   e3aae:	9a06      	ldr	r2, [sp, #24]
   e3ab0:	4653      	mov	r3, sl
   e3ab2:	2100      	movs	r1, #0
   e3ab4:	4640      	mov	r0, r8
   e3ab6:	f7f3 fdc8 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                // If the location is outside the bounds of the input image,
                // use zero as a default value.
                if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                    (in_y < input_height)) {
                  float input_value =
                      input_data[Offset(input_shape, b, in_y, in_x, ic)];
   e3aba:	9a1a      	ldr	r2, [sp, #104]	; 0x68
   e3abc:	9b1b      	ldr	r3, [sp, #108]	; 0x6c
   e3abe:	eb03 0382 	add.w	r3, r3, r2, lsl #2
                  float filter_value = filter_data[Offset(
                      filter_shape, 0, filter_y, filter_x, oc)];
   e3ac2:	9a2a      	ldr	r2, [sp, #168]	; 0xa8
                  total += (input_value * filter_value);
   e3ac4:	ed93 7a00 	vldr	s14, [r3]
                if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                    (in_y < input_height)) {
                  float input_value =
                      input_data[Offset(input_shape, b, in_y, in_x, ic)];
                  float filter_value = filter_data[Offset(
                      filter_shape, 0, filter_y, filter_x, oc)];
   e3ac8:	eb02 0080 	add.w	r0, r2, r0, lsl #2
                  total += (input_value * filter_value);
   e3acc:	edd0 7a00 	vldr	s15, [r0]
   e3ad0:	eea7 8a27 	vfma.f32	s16, s14, s15
   e3ad4:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
            const int oc = m + ic * depth_multiplier;
            const int in_x_origin = (out_x * stride_width) - pad_width;
            const int in_y_origin = (out_y * stride_height) - pad_height;
            float total = 0.f;
            for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
              for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   e3ad6:	f10a 0a01 	add.w	sl, sl, #1
   e3ada:	441e      	add	r6, r3
   e3adc:	e7cf      	b.n	e3a7e <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x146>
          for (int m = 0; m < depth_multiplier; m++) {
            const int oc = m + ic * depth_multiplier;
            const int in_x_origin = (out_x * stride_width) - pad_width;
            const int in_y_origin = (out_y * stride_height) - pad_height;
            float total = 0.f;
            for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   e3ade:	9b06      	ldr	r3, [sp, #24]
   e3ae0:	3301      	adds	r3, #1
   e3ae2:	9306      	str	r3, [sp, #24]
   e3ae4:	9b10      	ldr	r3, [sp, #64]	; 0x40
   e3ae6:	441d      	add	r5, r3
   e3ae8:	e7c2      	b.n	e3a70 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x138>
                  total += (input_value * filter_value);
                }
              }
            }
            float bias_value = 0.0f;
            if (bias_data) {
   e3aea:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   e3aec:	b11b      	cbz	r3, e3af6 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x1be>
              bias_value = bias_data[oc];
   e3aee:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e3af0:	edd3 9a00 	vldr	s19, [r3]
   e3af4:	e001      	b.n	e3afa <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x1c2>
                      filter_shape, 0, filter_y, filter_x, oc)];
                  total += (input_value * filter_value);
                }
              }
            }
            float bias_value = 0.0f;
   e3af6:	eddf 9a22 	vldr	s19, [pc, #136]	; e3b80 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x248>
            if (bias_data) {
              bias_value = bias_data[oc];
            }
            output_data[Offset(output_shape, b, out_y, out_x, oc)] =
   e3afa:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   e3afc:	9300      	str	r3, [sp, #0]
   e3afe:	9a02      	ldr	r2, [sp, #8]
   e3b00:	9b03      	ldr	r3, [sp, #12]
   e3b02:	4659      	mov	r1, fp
   e3b04:	4648      	mov	r0, r9
   e3b06:	f7f3 fda0 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   e3b0a:	9b2e      	ldr	r3, [sp, #184]	; 0xb8
                ActivationFunctionWithMinMax(total + bias_value,
   e3b0c:	ee78 7a29 	vadd.f32	s15, s16, s19
            }
            float bias_value = 0.0f;
            if (bias_data) {
              bias_value = bias_data[oc];
            }
            output_data[Offset(output_shape, b, out_y, out_x, oc)] =
   e3b10:	eb03 0080 	add.w	r0, r3, r0, lsl #2
      return __a;
   e3b14:	eef4 8ae7 	vcmpe.f32	s17, s15

  for (int b = 0; b < batches; ++b) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int ic = 0; ic < input_depth; ++ic) {
          for (int m = 0; m < depth_multiplier; m++) {
   e3b18:	9b05      	ldr	r3, [sp, #20]
   e3b1a:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e3b1e:	bfc8      	it	gt
   e3b20:	eef0 7a68 	vmovgt.f32	s15, s17
   e3b24:	3301      	adds	r3, #1
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
   e3b26:	eeb4 9a67 	vcmp.f32	s18, s15
   e3b2a:	9305      	str	r3, [sp, #20]
   e3b2c:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e3b2e:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e3b32:	bf48      	it	mi
   e3b34:	eef0 7a49 	vmovmi.f32	s15, s18
   e3b38:	3304      	adds	r3, #4
              bias_value = bias_data[oc];
            }
            output_data[Offset(output_shape, b, out_y, out_x, oc)] =
                ActivationFunctionWithMinMax(total + bias_value,
                                             output_activation_min,
                                             output_activation_max);
   e3b3a:	edc0 7a00 	vstr	s15, [r0]
   e3b3e:	930a      	str	r3, [sp, #40]	; 0x28

  for (int b = 0; b < batches; ++b) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int ic = 0; ic < input_depth; ++ic) {
          for (int m = 0; m < depth_multiplier; m++) {
   e3b40:	e78b      	b.n	e3a5a <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x122>
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

  for (int b = 0; b < batches; ++b) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int ic = 0; ic < input_depth; ++ic) {
   e3b42:	9b04      	ldr	r3, [sp, #16]
   e3b44:	3301      	adds	r3, #1
   e3b46:	9304      	str	r3, [sp, #16]
   e3b48:	9b07      	ldr	r3, [sp, #28]
   e3b4a:	441c      	add	r4, r3
   e3b4c:	e77b      	b.n	e3a46 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x10e>
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

  for (int b = 0; b < batches; ++b) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   e3b4e:	9b03      	ldr	r3, [sp, #12]
   e3b50:	9a0d      	ldr	r2, [sp, #52]	; 0x34
   e3b52:	3301      	adds	r3, #1
   e3b54:	9303      	str	r3, [sp, #12]
   e3b56:	9b08      	ldr	r3, [sp, #32]
   e3b58:	4413      	add	r3, r2
   e3b5a:	9308      	str	r3, [sp, #32]
   e3b5c:	e76c      	b.n	e3a38 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0x100>
  const int output_width = output_shape.Dims(2);
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

  for (int b = 0; b < batches; ++b) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   e3b5e:	9b02      	ldr	r3, [sp, #8]
   e3b60:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   e3b62:	3301      	adds	r3, #1
   e3b64:	9302      	str	r3, [sp, #8]
   e3b66:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e3b68:	4413      	add	r3, r2
   e3b6a:	9309      	str	r3, [sp, #36]	; 0x24
   e3b6c:	e75a      	b.n	e3a24 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0xec>
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

  for (int b = 0; b < batches; ++b) {
   e3b6e:	f10b 0b01 	add.w	fp, fp, #1
   e3b72:	e74e      	b.n	e3a12 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf+0xda>
          }
        }
      }
    }
  }
}
   e3b74:	b01d      	add	sp, #116	; 0x74
   e3b76:	ecbd 8b04 	vpop	{d8-d9}
   e3b7a:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e3b7e:	bf00      	nop
   e3b80:	00000000 	.word	0x00000000

000e3b84 <_ZN6tflite3ops5micro26Register_DEPTHWISE_CONV_2DEv>:

TfLiteRegistration* Register_DEPTHWISE_CONV_2D() {
  static TfLiteRegistration r = {depthwise_conv::Init, depthwise_conv::Free,
                                 depthwise_conv::Prepare, depthwise_conv::Eval};
  return &r;
}
   e3b84:	4800      	ldr	r0, [pc, #0]	; (e3b88 <_ZN6tflite3ops5micro26Register_DEPTHWISE_CONV_2DEv+0x4>)
   e3b86:	4770      	bx	lr
   e3b88:	2003c210 	.word	0x2003c210

000e3b8c <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph>:
         right_shift;
}

template <DepthwiseConvOutputRounding output_rounding>
struct DepthwiseConvBasicKernel {
  static inline void Run(const DepthwiseParams& params,
   e3b8c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e3b90:	b0a5      	sub	sp, #148	; 0x94
   e3b92:	469a      	mov	sl, r3
                         const uint8* input_data,
                         const RuntimeShape& filter_shape,
                         const uint8* filter_data,
                         const RuntimeShape& bias_shape, const int32* bias_data,
                         const RuntimeShape& output_shape, uint8* output_data) {
    const int stride_width = params.stride_width;
   e3b94:	f9b0 300a 	ldrsh.w	r3, [r0, #10]
   e3b98:	930f      	str	r3, [sp, #60]	; 0x3c
    const int stride_height = params.stride_height;
   e3b9a:	f9b0 300c 	ldrsh.w	r3, [r0, #12]
   e3b9e:	9310      	str	r3, [sp, #64]	; 0x40
    const int dilation_width_factor = params.dilation_width_factor;
   e3ba0:	f9b0 300e 	ldrsh.w	r3, [r0, #14]
   e3ba4:	9311      	str	r3, [sp, #68]	; 0x44
    const int dilation_height_factor = params.dilation_height_factor;
   e3ba6:	f9b0 3010 	ldrsh.w	r3, [r0, #16]
   e3baa:	9312      	str	r3, [sp, #72]	; 0x48
    const int pad_width = params.padding_values.width;
   e3bac:	f9b0 3002 	ldrsh.w	r3, [r0, #2]
   e3bb0:	9313      	str	r3, [sp, #76]	; 0x4c
    const int pad_height = params.padding_values.height;
   e3bb2:	f9b0 3004 	ldrsh.w	r3, [r0, #4]
   e3bb6:	9314      	str	r3, [sp, #80]	; 0x50
    const int depth_multiplier = params.depth_multiplier;
   e3bb8:	f9b0 3012 	ldrsh.w	r3, [r0, #18]
   e3bbc:	9308      	str	r3, [sp, #32]
    const int32 output_activation_min = params.quantized_activation_min;
   e3bbe:	6a83      	ldr	r3, [r0, #40]	; 0x28
   e3bc0:	930b      	str	r3, [sp, #44]	; 0x2c
    const int32 output_activation_max = params.quantized_activation_max;
   e3bc2:	6ac3      	ldr	r3, [r0, #44]	; 0x2c
   e3bc4:	930c      	str	r3, [sp, #48]	; 0x30
    const int32 input_offset = params.input_offset;
   e3bc6:	6943      	ldr	r3, [r0, #20]
   e3bc8:	9315      	str	r3, [sp, #84]	; 0x54
    const int32 filter_offset = params.weights_offset;
   e3bca:	6983      	ldr	r3, [r0, #24]
   e3bcc:	9316      	str	r3, [sp, #88]	; 0x58
    const int32 output_offset = params.output_offset;
   e3bce:	69c3      	ldr	r3, [r0, #28]
   e3bd0:	9317      	str	r3, [sp, #92]	; 0x5c
    const int32 output_multiplier = params.output_multiplier;
   e3bd2:	6a03      	ldr	r3, [r0, #32]
   e3bd4:	9318      	str	r3, [sp, #96]	; 0x60
    const int output_shift = params.output_shift;
   e3bd6:	6a43      	ldr	r3, [r0, #36]	; 0x24
   e3bd8:	9319      	str	r3, [sp, #100]	; 0x64
    TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e3bda:	680b      	ldr	r3, [r1, #0]
         right_shift;
}

template <DepthwiseConvOutputRounding output_rounding>
struct DepthwiseConvBasicKernel {
  static inline void Run(const DepthwiseParams& params,
   e3bdc:	9223      	str	r2, [sp, #140]	; 0x8c
    const int32 input_offset = params.input_offset;
    const int32 filter_offset = params.weights_offset;
    const int32 output_offset = params.output_offset;
    const int32 output_multiplier = params.output_multiplier;
    const int output_shift = params.output_shift;
    TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e3bde:	2b04      	cmp	r3, #4
         right_shift;
}

template <DepthwiseConvOutputRounding output_rounding>
struct DepthwiseConvBasicKernel {
  static inline void Run(const DepthwiseParams& params,
   e3be0:	4689      	mov	r9, r1
    const int32 input_offset = params.input_offset;
    const int32 filter_offset = params.weights_offset;
    const int32 output_offset = params.output_offset;
    const int32 output_multiplier = params.output_multiplier;
    const int output_shift = params.output_shift;
    TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e3be2:	d001      	beq.n	e3be8 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x5c>
   e3be4:	f001 fc86 	bl	e54f4 <abort>
    TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
   e3be8:	f8da 3000 	ldr.w	r3, [sl]
   e3bec:	2b04      	cmp	r3, #4
   e3bee:	d1f9      	bne.n	e3be4 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x58>
    TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   e3bf0:	9b31      	ldr	r3, [sp, #196]	; 0xc4
   e3bf2:	681b      	ldr	r3, [r3, #0]
   e3bf4:	2b04      	cmp	r3, #4
   e3bf6:	d1f5      	bne.n	e3be4 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x58>

    TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
   e3bf8:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e3bfa:	9a0c      	ldr	r2, [sp, #48]	; 0x30
   e3bfc:	4293      	cmp	r3, r2
   e3bfe:	dcf1      	bgt.n	e3be4 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x58>
    const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   e3c00:	2300      	movs	r3, #0
   e3c02:	4619      	mov	r1, r3
   e3c04:	9a31      	ldr	r2, [sp, #196]	; 0xc4
   e3c06:	4648      	mov	r0, r9
   e3c08:	f7f9 f86b 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
    const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e3c0c:	2303      	movs	r3, #3
   e3c0e:	4619      	mov	r1, r3
   e3c10:	9a31      	ldr	r2, [sp, #196]	; 0xc4
    TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
    TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
    TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

    TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
    const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   e3c12:	901a      	str	r0, [sp, #104]	; 0x68
    const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e3c14:	4650      	mov	r0, sl
   e3c16:	f7f9 f864 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
    const int input_height = input_shape.Dims(1);
   e3c1a:	2101      	movs	r1, #1
    TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
    TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

    TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
    const int batches = MatchingDim(input_shape, 0, output_shape, 0);
    const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e3c1c:	4604      	mov	r4, r0
    const int input_height = input_shape.Dims(1);
   e3c1e:	4648      	mov	r0, r9
   e3c20:	f7f3 fcae 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    const int input_width = input_shape.Dims(2);
   e3c24:	2102      	movs	r1, #2
    TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

    TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
    const int batches = MatchingDim(input_shape, 0, output_shape, 0);
    const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
    const int input_height = input_shape.Dims(1);
   e3c26:	901b      	str	r0, [sp, #108]	; 0x6c
    const int input_width = input_shape.Dims(2);
   e3c28:	4648      	mov	r0, r9
   e3c2a:	f7f3 fca9 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    const int input_depth = input_shape.Dims(3);
   e3c2e:	2103      	movs	r1, #3

    TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
    const int batches = MatchingDim(input_shape, 0, output_shape, 0);
    const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
    const int input_height = input_shape.Dims(1);
    const int input_width = input_shape.Dims(2);
   e3c30:	901c      	str	r0, [sp, #112]	; 0x70
    const int input_depth = input_shape.Dims(3);
   e3c32:	4648      	mov	r0, r9
   e3c34:	f7f3 fca4 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    const int filter_height = filter_shape.Dims(1);
   e3c38:	2101      	movs	r1, #1
    TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
    const int batches = MatchingDim(input_shape, 0, output_shape, 0);
    const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
    const int input_height = input_shape.Dims(1);
    const int input_width = input_shape.Dims(2);
    const int input_depth = input_shape.Dims(3);
   e3c3a:	900d      	str	r0, [sp, #52]	; 0x34
    const int filter_height = filter_shape.Dims(1);
   e3c3c:	4650      	mov	r0, sl
   e3c3e:	f7f3 fc9f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    const int filter_width = filter_shape.Dims(2);
   e3c42:	2102      	movs	r1, #2
    const int batches = MatchingDim(input_shape, 0, output_shape, 0);
    const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
    const int input_height = input_shape.Dims(1);
    const int input_width = input_shape.Dims(2);
    const int input_depth = input_shape.Dims(3);
    const int filter_height = filter_shape.Dims(1);
   e3c44:	901d      	str	r0, [sp, #116]	; 0x74
    const int filter_width = filter_shape.Dims(2);
   e3c46:	4650      	mov	r0, sl
   e3c48:	f7f3 fc9a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    const int output_height = output_shape.Dims(1);
   e3c4c:	2101      	movs	r1, #1
    const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
    const int input_height = input_shape.Dims(1);
    const int input_width = input_shape.Dims(2);
    const int input_depth = input_shape.Dims(3);
    const int filter_height = filter_shape.Dims(1);
    const int filter_width = filter_shape.Dims(2);
   e3c4e:	901e      	str	r0, [sp, #120]	; 0x78
    const int output_height = output_shape.Dims(1);
   e3c50:	9831      	ldr	r0, [sp, #196]	; 0xc4
   e3c52:	f7f3 fc95 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    const int output_width = output_shape.Dims(2);
   e3c56:	2102      	movs	r1, #2
    const int input_height = input_shape.Dims(1);
    const int input_width = input_shape.Dims(2);
    const int input_depth = input_shape.Dims(3);
    const int filter_height = filter_shape.Dims(1);
    const int filter_width = filter_shape.Dims(2);
    const int output_height = output_shape.Dims(1);
   e3c58:	901f      	str	r0, [sp, #124]	; 0x7c
    const int output_width = output_shape.Dims(2);
   e3c5a:	9831      	ldr	r0, [sp, #196]	; 0xc4
   e3c5c:	f7f3 fc90 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
    TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
   e3c60:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   e3c62:	9a08      	ldr	r2, [sp, #32]
    const int input_width = input_shape.Dims(2);
    const int input_depth = input_shape.Dims(3);
    const int filter_height = filter_shape.Dims(1);
    const int filter_width = filter_shape.Dims(2);
    const int output_height = output_shape.Dims(1);
    const int output_width = output_shape.Dims(2);
   e3c64:	9020      	str	r0, [sp, #128]	; 0x80
    TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
   e3c66:	4353      	muls	r3, r2
   e3c68:	429c      	cmp	r4, r3
   e3c6a:	d1bb      	bne.n	e3be4 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x58>
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
   e3c6c:	982f      	ldr	r0, [sp, #188]	; 0xbc
   e3c6e:	f7f9 f828 	bl	dccc2 <_ZNK6tflite12RuntimeShape8FlatSizeEv>
   e3c72:	4284      	cmp	r4, r0
   e3c74:	d1b6      	bne.n	e3be4 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x58>
   e3c76:	f04f 0b00 	mov.w	fp, #0

    for (int b = 0; b < batches; ++b) {
   e3c7a:	9b1a      	ldr	r3, [sp, #104]	; 0x68
   e3c7c:	459b      	cmp	fp, r3
   e3c7e:	f280 80a1 	bge.w	e3dc4 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x238>
   e3c82:	9b14      	ldr	r3, [sp, #80]	; 0x50
   e3c84:	425b      	negs	r3, r3
   e3c86:	9309      	str	r3, [sp, #36]	; 0x24
   e3c88:	2300      	movs	r3, #0
   e3c8a:	9303      	str	r3, [sp, #12]
      for (int out_y = 0; out_y < output_height; ++out_y) {
   e3c8c:	9b03      	ldr	r3, [sp, #12]
   e3c8e:	9a1f      	ldr	r2, [sp, #124]	; 0x7c
   e3c90:	4293      	cmp	r3, r2
   e3c92:	f280 8094 	bge.w	e3dbe <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x232>
   e3c96:	9b13      	ldr	r3, [sp, #76]	; 0x4c
   e3c98:	425b      	negs	r3, r3
   e3c9a:	930a      	str	r3, [sp, #40]	; 0x28
   e3c9c:	2300      	movs	r3, #0
   e3c9e:	9304      	str	r3, [sp, #16]
        for (int out_x = 0; out_x < output_width; ++out_x) {
   e3ca0:	9b04      	ldr	r3, [sp, #16]
   e3ca2:	9a20      	ldr	r2, [sp, #128]	; 0x80
   e3ca4:	4293      	cmp	r3, r2
   e3ca6:	f280 8082 	bge.w	e3dae <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x222>
   e3caa:	2500      	movs	r5, #0
   e3cac:	9505      	str	r5, [sp, #20]
          for (int ic = 0; ic < input_depth; ++ic) {
   e3cae:	9b05      	ldr	r3, [sp, #20]
   e3cb0:	9a0d      	ldr	r2, [sp, #52]	; 0x34
   e3cb2:	4293      	cmp	r3, r2
   e3cb4:	da73      	bge.n	e3d9e <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x212>
   e3cb6:	9b30      	ldr	r3, [sp, #192]	; 0xc0
   e3cb8:	eb03 0385 	add.w	r3, r3, r5, lsl #2
   e3cbc:	9322      	str	r3, [sp, #136]	; 0x88
   e3cbe:	2600      	movs	r6, #0
            for (int m = 0; m < depth_multiplier; m++) {
   e3cc0:	9b08      	ldr	r3, [sp, #32]
   e3cc2:	429e      	cmp	r6, r3
   e3cc4:	da65      	bge.n	e3d92 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x206>
   e3cc6:	1973      	adds	r3, r6, r5
              const int oc = m + ic * depth_multiplier;
              const int in_x_origin = (out_x * stride_width) - pad_width;
              const int in_y_origin = (out_y * stride_height) - pad_height;
              int32 acc = 0;
   e3cc8:	2400      	movs	r4, #0

    for (int b = 0; b < batches; ++b) {
      for (int out_y = 0; out_y < output_height; ++out_y) {
        for (int out_x = 0; out_x < output_width; ++out_x) {
          for (int ic = 0; ic < input_depth; ++ic) {
            for (int m = 0; m < depth_multiplier; m++) {
   e3cca:	9f09      	ldr	r7, [sp, #36]	; 0x24
   e3ccc:	930e      	str	r3, [sp, #56]	; 0x38
              const int oc = m + ic * depth_multiplier;
              const int in_x_origin = (out_x * stride_width) - pad_width;
              const int in_y_origin = (out_y * stride_height) - pad_height;
              int32 acc = 0;
              for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   e3cce:	9406      	str	r4, [sp, #24]
   e3cd0:	9b06      	ldr	r3, [sp, #24]
   e3cd2:	9a1d      	ldr	r2, [sp, #116]	; 0x74
   e3cd4:	4293      	cmp	r3, r2
   e3cd6:	da3a      	bge.n	e3d4e <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x1c2>
   e3cd8:	2300      	movs	r3, #0
   e3cda:	f8dd 8028 	ldr.w	r8, [sp, #40]	; 0x28
   e3cde:	9307      	str	r3, [sp, #28]
                for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   e3ce0:	9b07      	ldr	r3, [sp, #28]
   e3ce2:	9a1e      	ldr	r2, [sp, #120]	; 0x78
   e3ce4:	4293      	cmp	r3, r2
   e3ce6:	da2c      	bge.n	e3d42 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x1b6>
                      in_x_origin + dilation_width_factor * filter_x;
                  const int in_y =
                      in_y_origin + dilation_height_factor * filter_y;
                  // If the location is outside the bounds of the input image,
                  // use zero as a default value.
                  if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
   e3ce8:	f1b8 0f00 	cmp.w	r8, #0
   e3cec:	db23      	blt.n	e3d36 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x1aa>
   e3cee:	9b1c      	ldr	r3, [sp, #112]	; 0x70
   e3cf0:	4543      	cmp	r3, r8
   e3cf2:	dd20      	ble.n	e3d36 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x1aa>
   e3cf4:	2f00      	cmp	r7, #0
   e3cf6:	db1e      	blt.n	e3d36 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x1aa>
   e3cf8:	9b1b      	ldr	r3, [sp, #108]	; 0x6c
   e3cfa:	42bb      	cmp	r3, r7
   e3cfc:	dd1b      	ble.n	e3d36 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x1aa>
                      (in_y < input_height)) {
                    int32 input_val =
                        input_data[Offset(input_shape, b, in_y, in_x, ic)];
   e3cfe:	9b05      	ldr	r3, [sp, #20]
   e3d00:	9300      	str	r3, [sp, #0]
   e3d02:	463a      	mov	r2, r7
   e3d04:	4643      	mov	r3, r8
   e3d06:	4659      	mov	r1, fp
   e3d08:	4648      	mov	r0, r9
   e3d0a:	f7f3 fc9e 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                    int32 filter_val = filter_data[Offset(
   e3d0e:	9b0e      	ldr	r3, [sp, #56]	; 0x38
                  // If the location is outside the bounds of the input image,
                  // use zero as a default value.
                  if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&
                      (in_y < input_height)) {
                    int32 input_val =
                        input_data[Offset(input_shape, b, in_y, in_x, ic)];
   e3d10:	9021      	str	r0, [sp, #132]	; 0x84
                    int32 filter_val = filter_data[Offset(
   e3d12:	9300      	str	r3, [sp, #0]
   e3d14:	9a06      	ldr	r2, [sp, #24]
   e3d16:	9b07      	ldr	r3, [sp, #28]
   e3d18:	2100      	movs	r1, #0
   e3d1a:	4650      	mov	r0, sl
   e3d1c:	f7f3 fc95 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                        filter_shape, 0, filter_y, filter_x, oc)];
                    acc += (filter_val + filter_offset) *
   e3d20:	9b2e      	ldr	r3, [sp, #184]	; 0xb8
   e3d22:	9a16      	ldr	r2, [sp, #88]	; 0x58
   e3d24:	5c1b      	ldrb	r3, [r3, r0]
   e3d26:	9921      	ldr	r1, [sp, #132]	; 0x84
   e3d28:	4413      	add	r3, r2
   e3d2a:	9a23      	ldr	r2, [sp, #140]	; 0x8c
   e3d2c:	5c52      	ldrb	r2, [r2, r1]
   e3d2e:	9915      	ldr	r1, [sp, #84]	; 0x54
   e3d30:	440a      	add	r2, r1
   e3d32:	fb02 4403 	mla	r4, r2, r3, r4
              const int oc = m + ic * depth_multiplier;
              const int in_x_origin = (out_x * stride_width) - pad_width;
              const int in_y_origin = (out_y * stride_height) - pad_height;
              int32 acc = 0;
              for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
                for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   e3d36:	9b07      	ldr	r3, [sp, #28]
   e3d38:	3301      	adds	r3, #1
   e3d3a:	9307      	str	r3, [sp, #28]
   e3d3c:	9b11      	ldr	r3, [sp, #68]	; 0x44
   e3d3e:	4498      	add	r8, r3
   e3d40:	e7ce      	b.n	e3ce0 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x154>
            for (int m = 0; m < depth_multiplier; m++) {
              const int oc = m + ic * depth_multiplier;
              const int in_x_origin = (out_x * stride_width) - pad_width;
              const int in_y_origin = (out_y * stride_height) - pad_height;
              int32 acc = 0;
              for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   e3d42:	9b06      	ldr	r3, [sp, #24]
   e3d44:	3301      	adds	r3, #1
   e3d46:	9306      	str	r3, [sp, #24]
   e3d48:	9b12      	ldr	r3, [sp, #72]	; 0x48
   e3d4a:	441f      	add	r7, r3
   e3d4c:	e7c0      	b.n	e3cd0 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x144>
                    acc += (filter_val + filter_offset) *
                           (input_val + input_offset);
                  }
                }
              }
              if (bias_data) {
   e3d4e:	9b30      	ldr	r3, [sp, #192]	; 0xc0
   e3d50:	b11b      	cbz	r3, e3d5a <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x1ce>
                acc += bias_data[oc];
   e3d52:	9b22      	ldr	r3, [sp, #136]	; 0x88
   e3d54:	f853 3026 	ldr.w	r3, [r3, r6, lsl #2]
   e3d58:	441c      	add	r4, r3
}

template <>
inline int32 DepthwiseConvRound<DepthwiseConvOutputRounding::kAwayFromZero>(
    int32 x, int32 quantized_multiplier, int shift) {
  return MultiplyByQuantizedMultiplier(x, quantized_multiplier, shift);
   e3d5a:	9a19      	ldr	r2, [sp, #100]	; 0x64
   e3d5c:	9918      	ldr	r1, [sp, #96]	; 0x60
   e3d5e:	4620      	mov	r0, r4
   e3d60:	f7f8 ffce 	bl	dcd00 <_ZN6tflite29MultiplyByQuantizedMultiplierElli>
              if (bias_data) {
                acc += bias_data[oc];
              }
              acc = DepthwiseConvRound<output_rounding>(acc, output_multiplier,
                                                        output_shift);
              acc += output_offset;
   e3d64:	9b17      	ldr	r3, [sp, #92]	; 0x5c
              acc = std::max(acc, output_activation_min);
              acc = std::min(acc, output_activation_max);
              output_data[Offset(output_shape, b, out_y, out_x, oc)] =
   e3d66:	9a03      	ldr	r2, [sp, #12]
              if (bias_data) {
                acc += bias_data[oc];
              }
              acc = DepthwiseConvRound<output_rounding>(acc, output_multiplier,
                                                        output_shift);
              acc += output_offset;
   e3d68:	4418      	add	r0, r3
   e3d6a:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e3d6c:	4283      	cmp	r3, r0
   e3d6e:	bfb8      	it	lt
   e3d70:	4603      	movlt	r3, r0
   e3d72:	461c      	mov	r4, r3
   e3d74:	9b0c      	ldr	r3, [sp, #48]	; 0x30
              acc = std::max(acc, output_activation_min);
              acc = std::min(acc, output_activation_max);
              output_data[Offset(output_shape, b, out_y, out_x, oc)] =
   e3d76:	9831      	ldr	r0, [sp, #196]	; 0xc4
   e3d78:	429c      	cmp	r4, r3
   e3d7a:	bfa8      	it	ge
   e3d7c:	461c      	movge	r4, r3
   e3d7e:	9b0e      	ldr	r3, [sp, #56]	; 0x38
   e3d80:	9300      	str	r3, [sp, #0]
   e3d82:	4659      	mov	r1, fp
   e3d84:	9b04      	ldr	r3, [sp, #16]
   e3d86:	f7f3 fc60 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   e3d8a:	9b32      	ldr	r3, [sp, #200]	; 0xc8

    for (int b = 0; b < batches; ++b) {
      for (int out_y = 0; out_y < output_height; ++out_y) {
        for (int out_x = 0; out_x < output_width; ++out_x) {
          for (int ic = 0; ic < input_depth; ++ic) {
            for (int m = 0; m < depth_multiplier; m++) {
   e3d8c:	3601      	adds	r6, #1
              acc = DepthwiseConvRound<output_rounding>(acc, output_multiplier,
                                                        output_shift);
              acc += output_offset;
              acc = std::max(acc, output_activation_min);
              acc = std::min(acc, output_activation_max);
              output_data[Offset(output_shape, b, out_y, out_x, oc)] =
   e3d8e:	541c      	strb	r4, [r3, r0]

    for (int b = 0; b < batches; ++b) {
      for (int out_y = 0; out_y < output_height; ++out_y) {
        for (int out_x = 0; out_x < output_width; ++out_x) {
          for (int ic = 0; ic < input_depth; ++ic) {
            for (int m = 0; m < depth_multiplier; m++) {
   e3d90:	e796      	b.n	e3cc0 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x134>
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

    for (int b = 0; b < batches; ++b) {
      for (int out_y = 0; out_y < output_height; ++out_y) {
        for (int out_x = 0; out_x < output_width; ++out_x) {
          for (int ic = 0; ic < input_depth; ++ic) {
   e3d92:	9b05      	ldr	r3, [sp, #20]
   e3d94:	3301      	adds	r3, #1
   e3d96:	9305      	str	r3, [sp, #20]
   e3d98:	9b08      	ldr	r3, [sp, #32]
   e3d9a:	441d      	add	r5, r3
   e3d9c:	e787      	b.n	e3cae <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x122>
    TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

    for (int b = 0; b < batches; ++b) {
      for (int out_y = 0; out_y < output_height; ++out_y) {
        for (int out_x = 0; out_x < output_width; ++out_x) {
   e3d9e:	9b04      	ldr	r3, [sp, #16]
   e3da0:	9a0f      	ldr	r2, [sp, #60]	; 0x3c
   e3da2:	3301      	adds	r3, #1
   e3da4:	9304      	str	r3, [sp, #16]
   e3da6:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e3da8:	4413      	add	r3, r2
   e3daa:	930a      	str	r3, [sp, #40]	; 0x28
   e3dac:	e778      	b.n	e3ca0 <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x114>
    const int output_width = output_shape.Dims(2);
    TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

    for (int b = 0; b < batches; ++b) {
      for (int out_y = 0; out_y < output_height; ++out_y) {
   e3dae:	9b03      	ldr	r3, [sp, #12]
   e3db0:	9a10      	ldr	r2, [sp, #64]	; 0x40
   e3db2:	3301      	adds	r3, #1
   e3db4:	9303      	str	r3, [sp, #12]
   e3db6:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e3db8:	4413      	add	r3, r2
   e3dba:	9309      	str	r3, [sp, #36]	; 0x24
   e3dbc:	e766      	b.n	e3c8c <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0x100>
    const int output_height = output_shape.Dims(1);
    const int output_width = output_shape.Dims(2);
    TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);

    for (int b = 0; b < batches; ++b) {
   e3dbe:	f10b 0b01 	add.w	fp, fp, #1
   e3dc2:	e75a      	b.n	e3c7a <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph+0xee>
            }
          }
        }
      }
    }
  }
   e3dc4:	b025      	add	sp, #148	; 0x94
   e3dc6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	...

000e3dcc <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode>:
        GetTensorShape(bias), GetTensorData<int32_t>(bias),
        GetTensorShape(output), GetTensorData<uint8_t>(output));
  }
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e3dcc:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e3dd0:	f5ad 7d69 	sub.w	sp, sp, #932	; 0x3a4
   e3dd4:	684b      	ldr	r3, [r1, #4]
   e3dd6:	f8d0 a008 	ldr.w	sl, [r0, #8]
   e3dda:	930c      	str	r3, [sp, #48]	; 0x30
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e3ddc:	685b      	ldr	r3, [r3, #4]
   e3dde:	f8d1 b000 	ldr.w	fp, [r1]
  auto* params =
      reinterpret_cast<TfLiteDepthwiseConvParams*>(node->builtin_data);
   e3de2:	694d      	ldr	r5, [r1, #20]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e3de4:	f8db 7008 	ldr.w	r7, [fp, #8]
        GetTensorShape(bias), GetTensorData<int32_t>(bias),
        GetTensorShape(output), GetTensorData<uint8_t>(output));
  }
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e3de8:	910a      	str	r1, [sp, #40]	; 0x28
  return (tensor->is_variable) ? tensor : nullptr;
}
inline TfLiteTensor* GetOutput(TfLiteContext* context, TfLiteNode* node,
                               int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->outputs->data[index])];
   e3dea:	2238      	movs	r2, #56	; 0x38
   e3dec:	fb02 a303 	mla	r3, r2, r3, sl
   e3df0:	9309      	str	r3, [sp, #36]	; 0x24
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e3df2:	f8db 3004 	ldr.w	r3, [fp, #4]
   e3df6:	4353      	muls	r3, r2
   e3df8:	930b      	str	r3, [sp, #44]	; 0x2c
   e3dfa:	eb0a 0903 	add.w	r9, sl, r3
}
inline const TfLiteTensor* GetIntermediates(TfLiteContext* context,
                                            TfLiteNode* node, int index) {
  return &context->tensors[node->intermediates->data[index]];
}
inline int NumInputs(const TfLiteNode* node) { return node->inputs->size; }
   e3dfe:	f8db 3000 	ldr.w	r3, [fp]

  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  const TfLiteTensor* filter = GetInput(context, node, kFilterTensor);
  const TfLiteTensor* bias =
      (NumInputs(node) == 3) ? GetInput(context, node, kBiasTensor) : nullptr;
   e3e02:	2b03      	cmp	r3, #3
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e3e04:	bf08      	it	eq
   e3e06:	f8db 400c 	ldreq.w	r4, [fp, #12]
   e3e0a:	fb02 a707 	mla	r7, r2, r7, sl
   e3e0e:	bf08      	it	eq
   e3e10:	fb02 a404 	mlaeq	r4, r2, r4, sl

  const TfLiteType data_type = input->type;
   e3e14:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   e3e16:	f81a 2002 	ldrb.w	r2, [sl, r2]
   e3e1a:	920d      	str	r2, [sp, #52]	; 0x34
   e3e1c:	f8d9 2008 	ldr.w	r2, [r9, #8]

namespace tflite {

inline int NumDimensions(const TfLiteTensor* t) { return t->dims->size; }
inline int SizeOfDimension(const TfLiteTensor* t, int dim) {
  return t->dims->data[dim];
   e3e20:	68d1      	ldr	r1, [r2, #12]
   e3e22:	6892      	ldr	r2, [r2, #8]
   e3e24:	9213      	str	r2, [sp, #76]	; 0x4c
   e3e26:	68ba      	ldr	r2, [r7, #8]
   e3e28:	9114      	str	r1, [sp, #80]	; 0x50
   e3e2a:	68d1      	ldr	r1, [r2, #12]
   e3e2c:	6892      	ldr	r2, [r2, #8]
   e3e2e:	9211      	str	r2, [sp, #68]	; 0x44
  int width = SizeOfDimension(input, 2);
  int height = SizeOfDimension(input, 1);
  int filter_width = SizeOfDimension(filter, 2);
  int filter_height = SizeOfDimension(filter, 1);
  int out_width = ComputeOutSize(params->padding, width, filter_width,
   e3e30:	782a      	ldrb	r2, [r5, #0]
   e3e32:	920e      	str	r2, [sp, #56]	; 0x38
   e3e34:	686a      	ldr	r2, [r5, #4]
   e3e36:	920f      	str	r2, [sp, #60]	; 0x3c
                                 params->stride_width);
  int out_height = ComputeOutSize(params->padding, height, filter_height,
   e3e38:	68aa      	ldr	r2, [r5, #8]
   e3e3a:	9112      	str	r1, [sp, #72]	; 0x48
   e3e3c:	9210      	str	r2, [sp, #64]	; 0x40
                                  params->stride_height);
  OpData data;
  if (input->type != kTfLiteFloat32) {
   e3e3e:	9a0d      	ldr	r2, [sp, #52]	; 0x34

  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  const TfLiteTensor* filter = GetInput(context, node, kFilterTensor);
  const TfLiteTensor* bias =
      (NumInputs(node) == 3) ? GetInput(context, node, kBiasTensor) : nullptr;
   e3e40:	bf18      	it	ne
   e3e42:	2400      	movne	r4, #0
  int out_width = ComputeOutSize(params->padding, width, filter_width,
                                 params->stride_width);
  int out_height = ComputeOutSize(params->padding, height, filter_height,
                                  params->stride_height);
  OpData data;
  if (input->type != kTfLiteFloat32) {
   e3e44:	2a01      	cmp	r2, #1
        GetTensorShape(bias), GetTensorData<int32_t>(bias),
        GetTensorShape(output), GetTensorData<uint8_t>(output));
  }
}

TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   e3e46:	4606      	mov	r6, r0
  int out_width = ComputeOutSize(params->padding, width, filter_width,
                                 params->stride_width);
  int out_height = ComputeOutSize(params->padding, height, filter_height,
                                  params->stride_height);
  OpData data;
  if (input->type != kTfLiteFloat32) {
   e3e48:	d02b      	beq.n	e3ea2 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0xd6>
    TF_LITE_ENSURE_EQ(context, filter->quantization.type,
   e3e4a:	f897 8030 	ldrb.w	r8, [r7, #48]	; 0x30
   e3e4e:	f1b8 0f01 	cmp.w	r8, #1
   e3e52:	d010      	beq.n	e3e76 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0xaa>
   e3e54:	4baa      	ldr	r3, [pc, #680]	; (e4100 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x334>)
   e3e56:	9301      	str	r3, [sp, #4]
   e3e58:	2401      	movs	r4, #1
   e3e5a:	4baa      	ldr	r3, [pc, #680]	; (e4104 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x338>)
   e3e5c:	9300      	str	r3, [sp, #0]
   e3e5e:	9403      	str	r4, [sp, #12]
   e3e60:	f8cd 8008 	str.w	r8, [sp, #8]
   e3e64:	6945      	ldr	r5, [r0, #20]
   e3e66:	4aa8      	ldr	r2, [pc, #672]	; (e4108 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x33c>)
   e3e68:	49a8      	ldr	r1, [pc, #672]	; (e410c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x340>)
   e3e6a:	f240 13cd 	movw	r3, #461	; 0x1cd
   e3e6e:	47a8      	blx	r5
   e3e70:	4620      	mov	r0, r4
   e3e72:	f000 bc8e 	b.w	e4792 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x9c6>
                      kTfLiteAffineQuantization);

    const auto* affine_quantization =
        reinterpret_cast<TfLiteAffineQuantization*>(
            filter->quantization.params);
   e3e76:	6b7a      	ldr	r2, [r7, #52]	; 0x34
    TF_LITE_ENSURE(context, affine_quantization);
   e3e78:	b92a      	cbnz	r2, e3e86 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0xba>
   e3e7a:	4ba5      	ldr	r3, [pc, #660]	; (e4110 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x344>)
   e3e7c:	9300      	str	r3, [sp, #0]
   e3e7e:	6944      	ldr	r4, [r0, #20]
   e3e80:	f44f 73e9 	mov.w	r3, #466	; 0x1d2
   e3e84:	e006      	b.n	e3e94 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0xc8>
    TF_LITE_ENSURE(context, affine_quantization->scale);
   e3e86:	6812      	ldr	r2, [r2, #0]
   e3e88:	b95a      	cbnz	r2, e3ea2 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0xd6>
   e3e8a:	4ba2      	ldr	r3, [pc, #648]	; (e4114 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x348>)
   e3e8c:	9300      	str	r3, [sp, #0]
   e3e8e:	6944      	ldr	r4, [r0, #20]
   e3e90:	f240 13d3 	movw	r3, #467	; 0x1d3
   e3e94:	4630      	mov	r0, r6
   e3e96:	4a9c      	ldr	r2, [pc, #624]	; (e4108 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x33c>)
   e3e98:	499f      	ldr	r1, [pc, #636]	; (e4118 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x34c>)
   e3e9a:	47a0      	blx	r4
   e3e9c:	4640      	mov	r0, r8
   e3e9e:	f000 bc78 	b.w	e4792 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x9c6>
                             int height, int filter_width, int filter_height,
                             int out_width, int out_height,
                             const TfLiteType data_type, OpData* data) {
  bool has_bias = node->inputs->size == 3;
  // Check number of inputs/outputs
  TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);
   e3ea2:	3b02      	subs	r3, #2
   e3ea4:	2b01      	cmp	r3, #1
   e3ea6:	d908      	bls.n	e3eba <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0xee>
   e3ea8:	4b9c      	ldr	r3, [pc, #624]	; (e411c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x350>)
   e3eaa:	9300      	str	r3, [sp, #0]
   e3eac:	6974      	ldr	r4, [r6, #20]
   e3eae:	4a96      	ldr	r2, [pc, #600]	; (e4108 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x33c>)
   e3eb0:	4999      	ldr	r1, [pc, #612]	; (e4118 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x34c>)
   e3eb2:	2343      	movs	r3, #67	; 0x43
   e3eb4:	4630      	mov	r0, r6
   e3eb6:	47a0      	blx	r4
   e3eb8:	e2b8      	b.n	e442c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x660>
  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);
   e3eba:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   e3ebc:	681b      	ldr	r3, [r3, #0]
   e3ebe:	2b01      	cmp	r3, #1
   e3ec0:	d00d      	beq.n	e3ede <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x112>
   e3ec2:	9302      	str	r3, [sp, #8]
   e3ec4:	4b96      	ldr	r3, [pc, #600]	; (e4120 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x354>)
   e3ec6:	9301      	str	r3, [sp, #4]
   e3ec8:	2201      	movs	r2, #1
   e3eca:	4b96      	ldr	r3, [pc, #600]	; (e4124 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x358>)
   e3ecc:	9203      	str	r2, [sp, #12]
   e3ece:	9300      	str	r3, [sp, #0]
   e3ed0:	6974      	ldr	r4, [r6, #20]
   e3ed2:	4a8d      	ldr	r2, [pc, #564]	; (e4108 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x33c>)
   e3ed4:	498d      	ldr	r1, [pc, #564]	; (e410c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x340>)
   e3ed6:	2344      	movs	r3, #68	; 0x44
   e3ed8:	4630      	mov	r0, r6
   e3eda:	47a0      	blx	r4
   e3edc:	e2a6      	b.n	e442c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x660>
  // Matching GetWindowedOutputSize in TensorFlow.
  auto padding = params->padding;
  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
      params->dilation_height_factor, params->dilation_width_factor, height,
      width, filter_height, filter_width, padding, &out_height, &out_width);
   e3ede:	696b      	ldr	r3, [r5, #20]
   e3ee0:	f8d5 8018 	ldr.w	r8, [r5, #24]
   e3ee4:	9315      	str	r3, [sp, #84]	; 0x54

inline TfLitePaddingValues ComputePaddingHeightWidth(
    int stride_height, int stride_width, int dilation_rate_height,
    int dilation_rate_width, int in_height, int in_width, int filter_height,
    int filter_width, TfLitePadding padding, int* out_height, int* out_width) {
  *out_width = ComputeOutSize(padding, in_width, filter_width, stride_width,
   e3ee6:	9300      	str	r3, [sp, #0]
   e3ee8:	9a12      	ldr	r2, [sp, #72]	; 0x48
   e3eea:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   e3eec:	9914      	ldr	r1, [sp, #80]	; 0x50
   e3eee:	980e      	ldr	r0, [sp, #56]	; 0x38
   e3ef0:	f7f9 fa77 	bl	dd3e2 <_ZN6tflite14ComputeOutSizeE13TfLitePaddingiiii>
                              dilation_rate_width);
  *out_height = ComputeOutSize(padding, in_height, filter_height, stride_height,
   e3ef4:	f8cd 8000 	str.w	r8, [sp]

inline TfLitePaddingValues ComputePaddingHeightWidth(
    int stride_height, int stride_width, int dilation_rate_height,
    int dilation_rate_width, int in_height, int in_width, int filter_height,
    int filter_width, TfLitePadding padding, int* out_height, int* out_width) {
  *out_width = ComputeOutSize(padding, in_width, filter_width, stride_width,
   e3ef8:	9016      	str	r0, [sp, #88]	; 0x58
                              dilation_rate_width);
  *out_height = ComputeOutSize(padding, in_height, filter_height, stride_height,
   e3efa:	9b10      	ldr	r3, [sp, #64]	; 0x40
   e3efc:	9a11      	ldr	r2, [sp, #68]	; 0x44
   e3efe:	9913      	ldr	r1, [sp, #76]	; 0x4c
   e3f00:	980e      	ldr	r0, [sp, #56]	; 0x38
   e3f02:	f7f9 fa6e 	bl	dd3e2 <_ZN6tflite14ComputeOutSizeE13TfLitePaddingiiii>
inline int ComputePaddingWithOffset(int stride, int dilation_rate, int in_size,
                                    int filter_size, int out_size,
                                    int* offset) {
  int effective_filter_size = (filter_size - 1) * dilation_rate + 1;
  int total_padding =
      ((out_size - 1) * stride + effective_filter_size - in_size);
   e3f06:	9b11      	ldr	r3, [sp, #68]	; 0x44
   e3f08:	9a15      	ldr	r2, [sp, #84]	; 0x54
   e3f0a:	990f      	ldr	r1, [sp, #60]	; 0x3c
   e3f0c:	3b01      	subs	r3, #1
   e3f0e:	fb08 f803 	mul.w	r8, r8, r3
   e3f12:	9b10      	ldr	r3, [sp, #64]	; 0x40
   e3f14:	f108 0801 	add.w	r8, r8, #1
   e3f18:	3801      	subs	r0, #1
   e3f1a:	fb03 8000 	mla	r0, r3, r0, r8
   e3f1e:	9b13      	ldr	r3, [sp, #76]	; 0x4c
   e3f20:	1ac0      	subs	r0, r0, r3
   e3f22:	9b12      	ldr	r3, [sp, #72]	; 0x48
   e3f24:	3b01      	subs	r3, #1
   e3f26:	4353      	muls	r3, r2
   e3f28:	9a16      	ldr	r2, [sp, #88]	; 0x58
   e3f2a:	3301      	adds	r3, #1
   e3f2c:	3a01      	subs	r2, #1
   e3f2e:	fb01 3302 	mla	r3, r1, r2, r3
   e3f32:	9a14      	ldr	r2, [sp, #80]	; 0x50
   e3f34:	1a9b      	subs	r3, r3, r2
  total_padding = total_padding > 0 ? total_padding : 0;
   e3f36:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
   e3f3a:	105a      	asrs	r2, r3, #1
   e3f3c:	f003 0301 	and.w	r3, r3, #1
   e3f40:	9362      	str	r3, [sp, #392]	; 0x188

  // Note that quantized inference requires that all tensors have their
  // parameters set. This is usually done during quantized training.
  if (data_type != kTfLiteFloat32) {
   e3f42:	9b0d      	ldr	r3, [sp, #52]	; 0x34
  // Matching GetWindowedOutputSize in TensorFlow.
  auto padding = params->padding;
  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
      params->dilation_height_factor, params->dilation_width_factor, height,
      width, filter_height, filter_width, padding, &out_height, &out_width);
   e3f44:	9260      	str	r2, [sp, #384]	; 0x180
   e3f46:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
   e3f4a:	1042      	asrs	r2, r0, #1

  // Note that quantized inference requires that all tensors have their
  // parameters set. This is usually done during quantized training.
  if (data_type != kTfLiteFloat32) {
   e3f4c:	2b01      	cmp	r3, #1
  // Matching GetWindowedOutputSize in TensorFlow.
  auto padding = params->padding;
  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
      params->dilation_height_factor, params->dilation_width_factor, height,
      width, filter_height, filter_width, padding, &out_height, &out_width);
   e3f4e:	f000 0001 	and.w	r0, r0, #1
   e3f52:	9261      	str	r2, [sp, #388]	; 0x184
   e3f54:	9063      	str	r0, [sp, #396]	; 0x18c

  // Note that quantized inference requires that all tensors have their
  // parameters set. This is usually done during quantized training.
  if (data_type != kTfLiteFloat32) {
   e3f56:	d02d      	beq.n	e3fb4 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x1e8>
}

inline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
   e3f58:	f8db 000c 	ldr.w	r0, [fp, #12]
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e3f5c:	f8db 1004 	ldr.w	r1, [fp, #4]
   e3f60:	f8db 2008 	ldr.w	r2, [fp, #8]
   e3f64:	2338      	movs	r3, #56	; 0x38

inline const TfLiteTensor* GetOptionalInputTensor(TfLiteContext* context,
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
   e3f66:	f1b0 3fff 	cmp.w	r0, #4294967295	; 0xffffffff
  return t->dims->data[dim];
}
inline const TfLiteTensor* GetInput(TfLiteContext* context, TfLiteNode* node,
                                    int index) {
  return &context
              ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e3f6a:	fb03 a101 	mla	r1, r3, r1, sl
   e3f6e:	fb03 a202 	mla	r2, r3, r2, sl
                                                  const TfLiteNode* node,
                                                  int index) {
  const bool use_tensor = node->inputs->data[index] != kOptionalTensor;
  if (use_tensor) {
    return &context
                ->tensors[flatbuffers::EndianScalar(node->inputs->data[index])];
   e3f72:	bf18      	it	ne
   e3f74:	fb03 a300 	mlane	r3, r3, r0, sl
    const TfLiteTensor* filter = GetInput(context, node, kFilterTensor);
    const TfLiteTensor* bias =
        GetOptionalInputTensor(context, node, kBiasTensor);
    TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

    TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams(
   e3f78:	a8a6      	add	r0, sp, #664	; 0x298
   e3f7a:	9007      	str	r0, [sp, #28]
   e3f7c:	a866      	add	r0, sp, #408	; 0x198
   e3f7e:	9006      	str	r0, [sp, #24]
   e3f80:	a8e7      	add	r0, sp, #924	; 0x39c
   e3f82:	9005      	str	r0, [sp, #20]
   e3f84:	a8e6      	add	r0, sp, #920	; 0x398
   e3f86:	9004      	str	r0, [sp, #16]
   e3f88:	a865      	add	r0, sp, #404	; 0x194
   e3f8a:	9003      	str	r0, [sp, #12]
   e3f8c:	a864      	add	r0, sp, #400	; 0x190
   e3f8e:	9002      	str	r0, [sp, #8]
   e3f90:	f105 0010 	add.w	r0, r5, #16
   e3f94:	9001      	str	r0, [sp, #4]
   e3f96:	980c      	ldr	r0, [sp, #48]	; 0x30
   e3f98:	6840      	ldr	r0, [r0, #4]
   e3f9a:	f04f 0e38 	mov.w	lr, #56	; 0x38
   e3f9e:	fb0e a000 	mla	r0, lr, r0, sl
  }
  return nullptr;
   e3fa2:	bf08      	it	eq
   e3fa4:	2300      	moveq	r3, #0
   e3fa6:	9000      	str	r0, [sp, #0]
   e3fa8:	4630      	mov	r0, r6
   e3faa:	f000 fe7b 	bl	e4ca4 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_>
   e3fae:	2800      	cmp	r0, #0
   e3fb0:	f040 823c 	bne.w	e442c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x660>
                                        filter_width, filter_height, out_width,
                                        out_height, data_type, &data));

  // TODO(aselle): Consider whether float conv and quantized conv should be
  // separate ops to avoid dispatch overhead here.
  switch (input->type) {  // Already know in/out types are same.
   e3fb4:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e3fb6:	f81a 8003 	ldrb.w	r8, [sl, r3]
   e3fba:	f1b8 0f03 	cmp.w	r8, #3
   e3fbe:	f040 80bb 	bne.w	e4138 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x36c>

void EvalQuantized(TfLiteContext* context, TfLiteNode* node,
                   TfLiteDepthwiseConvParams* params, OpData* data,
                   const TfLiteTensor* input, const TfLiteTensor* filter,
                   const TfLiteTensor* bias, TfLiteTensor* output) {
  const int32_t input_offset = -input->params.zero_point;
   e3fc2:	f8d9 3010 	ldr.w	r3, [r9, #16]
  const int32_t output_offset = output->params.zero_point;

  tflite::DepthwiseParams op_params;
  // Padding type is ignored, but still set.
  op_params.padding_type = PaddingType::kSame;
  op_params.padding_values.width = data->padding.width;
   e3fc6:	9960      	ldr	r1, [sp, #384]	; 0x180
void EvalQuantized(TfLiteContext* context, TfLiteNode* node,
                   TfLiteDepthwiseConvParams* params, OpData* data,
                   const TfLiteTensor* input, const TfLiteTensor* filter,
                   const TfLiteTensor* bias, TfLiteTensor* output) {
  const int32_t input_offset = -input->params.zero_point;
  const int32_t filter_offset = -filter->params.zero_point;
   e3fc8:	693a      	ldr	r2, [r7, #16]

void EvalQuantized(TfLiteContext* context, TfLiteNode* node,
                   TfLiteDepthwiseConvParams* params, OpData* data,
                   const TfLiteTensor* input, const TfLiteTensor* filter,
                   const TfLiteTensor* bias, TfLiteTensor* output) {
  const int32_t input_offset = -input->params.zero_point;
   e3fca:	f1c3 0a00 	rsb	sl, r3, #0
  const int32_t filter_offset = -filter->params.zero_point;
  const int32_t output_offset = output->params.zero_point;
   e3fce:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e3fd0:	6918      	ldr	r0, [r3, #16]

  tflite::DepthwiseParams op_params;
  // Padding type is ignored, but still set.
  op_params.padding_type = PaddingType::kSame;
  op_params.padding_values.width = data->padding.width;
   e3fd2:	f8ad 114a 	strh.w	r1, [sp, #330]	; 0x14a
  const int32_t filter_offset = -filter->params.zero_point;
  const int32_t output_offset = output->params.zero_point;

  tflite::DepthwiseParams op_params;
  // Padding type is ignored, but still set.
  op_params.padding_type = PaddingType::kSame;
   e3fd6:	2301      	movs	r3, #1
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
   e3fd8:	9961      	ldr	r1, [sp, #388]	; 0x184
  const int32_t filter_offset = -filter->params.zero_point;
  const int32_t output_offset = output->params.zero_point;

  tflite::DepthwiseParams op_params;
  // Padding type is ignored, but still set.
  op_params.padding_type = PaddingType::kSame;
   e3fda:	f88d 3148 	strb.w	r3, [sp, #328]	; 0x148
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
   e3fde:	f8ad 114c 	strh.w	r1, [sp, #332]	; 0x14c
  op_params.stride_width = params->stride_width;
   e3fe2:	6869      	ldr	r1, [r5, #4]
   e3fe4:	f8ad 1152 	strh.w	r1, [sp, #338]	; 0x152
  op_params.stride_height = params->stride_height;
   e3fe8:	68a9      	ldr	r1, [r5, #8]
   e3fea:	f8ad 1154 	strh.w	r1, [sp, #340]	; 0x154
  op_params.dilation_width_factor = 1;
   e3fee:	f8ad 3156 	strh.w	r3, [sp, #342]	; 0x156
  op_params.dilation_height_factor = 1;
   e3ff2:	f8ad 3158 	strh.w	r3, [sp, #344]	; 0x158
void EvalQuantized(TfLiteContext* context, TfLiteNode* node,
                   TfLiteDepthwiseConvParams* params, OpData* data,
                   const TfLiteTensor* input, const TfLiteTensor* filter,
                   const TfLiteTensor* bias, TfLiteTensor* output) {
  const int32_t input_offset = -input->params.zero_point;
  const int32_t filter_offset = -filter->params.zero_point;
   e3ff6:	4252      	negs	r2, r2
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = 1;
  op_params.dilation_height_factor = 1;
  op_params.depth_multiplier = params->depth_multiplier;
   e3ff8:	68e9      	ldr	r1, [r5, #12]
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
   e3ffa:	9258      	str	r2, [sp, #352]	; 0x160
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
   e3ffc:	9a64      	ldr	r2, [sp, #400]	; 0x190
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = 1;
  op_params.dilation_height_factor = 1;
  op_params.depth_multiplier = params->depth_multiplier;
   e3ffe:	f8ad 115a 	strh.w	r1, [sp, #346]	; 0x15a
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
   e4002:	925a      	str	r2, [sp, #360]	; 0x168
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = 1;
  op_params.dilation_height_factor = 1;
  op_params.depth_multiplier = params->depth_multiplier;
  op_params.quantized_activation_min = data->output_activation_min;
   e4004:	99e6      	ldr	r1, [sp, #920]	; 0x398
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  // Legacy ops used mixed left and right shifts. Now all are +ve-means-left.
  op_params.output_shift = -data->output_shift;
   e4006:	9a65      	ldr	r2, [sp, #404]	; 0x194
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = 1;
  op_params.dilation_height_factor = 1;
  op_params.depth_multiplier = params->depth_multiplier;
  op_params.quantized_activation_min = data->output_activation_min;
   e4008:	915c      	str	r1, [sp, #368]	; 0x170
  op_params.quantized_activation_max = data->output_activation_max;
   e400a:	99e7      	ldr	r1, [sp, #924]	; 0x39c
   e400c:	915d      	str	r1, [sp, #372]	; 0x174
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  // Legacy ops used mixed left and right shifts. Now all are +ve-means-left.
  op_params.output_shift = -data->output_shift;
   e400e:	4252      	negs	r2, r2
  op_params.depth_multiplier = params->depth_multiplier;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
   e4010:	9059      	str	r0, [sp, #356]	; 0x164
  op_params.output_multiplier = data->output_multiplier;
  // Legacy ops used mixed left and right shifts. Now all are +ve-means-left.
  op_params.output_shift = -data->output_shift;

  // Figure out if we can use the optimized path for this set of parameters.
  const int filter_width = GetTensorShape(filter).Dims(2);
   e4012:	4639      	mov	r1, r7
   e4014:	a84d      	add	r0, sp, #308	; 0x134
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  // Legacy ops used mixed left and right shifts. Now all are +ve-means-left.
  op_params.output_shift = -data->output_shift;
   e4016:	925b      	str	r2, [sp, #364]	; 0x16c
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = 1;
  op_params.dilation_height_factor = 1;
   e4018:	930b      	str	r3, [sp, #44]	; 0x2c
  op_params.depth_multiplier = params->depth_multiplier;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  op_params.input_offset = input_offset;
   e401a:	f8cd a15c 	str.w	sl, [sp, #348]	; 0x15c
  op_params.output_multiplier = data->output_multiplier;
  // Legacy ops used mixed left and right shifts. Now all are +ve-means-left.
  op_params.output_shift = -data->output_shift;

  // Figure out if we can use the optimized path for this set of parameters.
  const int filter_width = GetTensorShape(filter).Dims(2);
   e401e:	f7f3 fd54 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e4022:	2102      	movs	r1, #2
   e4024:	a84d      	add	r0, sp, #308	; 0x134
   e4026:	f7f3 faab 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e402a:	4605      	mov	r5, r0
   e402c:	a84d      	add	r0, sp, #308	; 0x134
   e402e:	f7f3 fa9c 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  const int input_depth = GetTensorShape(input).Dims(3);
   e4032:	4649      	mov	r1, r9
   e4034:	a84d      	add	r0, sp, #308	; 0x134
   e4036:	f7f3 fd48 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e403a:	4641      	mov	r1, r8
   e403c:	a84d      	add	r0, sp, #308	; 0x134
   e403e:	f7f3 fa9f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e4042:	4683      	mov	fp, r0
   e4044:	a84d      	add	r0, sp, #308	; 0x134
   e4046:	f7f3 fa90 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  const int output_depth = GetTensorShape(filter).Dims(3);
   e404a:	4639      	mov	r1, r7
   e404c:	a84d      	add	r0, sp, #308	; 0x134
   e404e:	f7f3 fd3c 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e4052:	4641      	mov	r1, r8
   e4054:	a84d      	add	r0, sp, #308	; 0x134
   e4056:	f7f3 fa93 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e405a:	4680      	mov	r8, r0
   e405c:	a84d      	add	r0, sp, #308	; 0x134
   e405e:	f7f3 fa84 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  const int filter_height = GetTensorShape(filter).Dims(1);
   e4062:	4639      	mov	r1, r7
   e4064:	a84d      	add	r0, sp, #308	; 0x134
   e4066:	f7f3 fd30 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e406a:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e406c:	a84d      	add	r0, sp, #308	; 0x134
   e406e:	4619      	mov	r1, r3
   e4070:	f7f3 fa86 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
   e4074:	900b      	str	r0, [sp, #44]	; 0x2c
   e4076:	a84d      	add	r0, sp, #308	; 0x134
   e4078:	f7f3 fa77 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  const int needed_size =
      output_depth * filter_width * filter_height * input_depth;
   e407c:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e407e:	fb08 f805 	mul.w	r8, r8, r5
   e4082:	fb03 f308 	mul.w	r3, r3, r8
  bool use_optimized_path = false;
  if ((filter_width == 8) && (input_offset == 0) && (input_depth == 1) &&
   e4086:	2d08      	cmp	r5, #8
  const int filter_width = GetTensorShape(filter).Dims(2);
  const int input_depth = GetTensorShape(input).Dims(3);
  const int output_depth = GetTensorShape(filter).Dims(3);
  const int filter_height = GetTensorShape(filter).Dims(1);
  const int needed_size =
      output_depth * filter_width * filter_height * input_depth;
   e4088:	fb0b f303 	mul.w	r3, fp, r3
   e408c:	ad3e      	add	r5, sp, #248	; 0xf8
   e408e:	f50d 7886 	add.w	r8, sp, #268	; 0x10c
  bool use_optimized_path = false;
  if ((filter_width == 8) && (input_offset == 0) && (input_depth == 1) &&
   e4092:	f040 8351 	bne.w	e4738 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x96c>
   e4096:	f1ba 0f00 	cmp.w	sl, #0
   e409a:	f040 834d 	bne.w	e4738 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x96c>
   e409e:	f1bb 0f01 	cmp.w	fp, #1
   e40a2:	f040 8349 	bne.w	e4738 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x96c>
   e40a6:	f5b3 6f80 	cmp.w	r3, #1024	; 0x400
   e40aa:	f300 8345 	bgt.w	e4738 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x96c>
    // with an allocation mechanism available through the context API.
    // Use the address of the node as a proxy for its identity, since we need
    // to ensure the weight values are consistent between calls, and there's
    // no easy way to do that quickly other than relying on the identity of
    // the owning node.
    static TfLiteNode* initialized_node_address = node;
   e40ae:	f8df b07c 	ldr.w	fp, [pc, #124]	; e412c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x360>
   e40b2:	f8df a07c 	ldr.w	sl, [pc, #124]	; e4130 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x364>
   e40b6:	f8db 3000 	ldr.w	r3, [fp]
   e40ba:	f013 0f01 	tst.w	r3, #1
   e40be:	d109      	bne.n	e40d4 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x308>
   e40c0:	4658      	mov	r0, fp
   e40c2:	f7f0 f805 	bl	d40d0 <__cxa_guard_acquire>
   e40c6:	b128      	cbz	r0, e40d4 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x308>
   e40c8:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e40ca:	f8ca 3000 	str.w	r3, [sl]
   e40ce:	4658      	mov	r0, fp
   e40d0:	f7f0 f803 	bl	d40da <__cxa_guard_release>
    if (initialized_node_address == node) {
   e40d4:	f8da 3000 	ldr.w	r3, [sl]
   e40d8:	9a0a      	ldr	r2, [sp, #40]	; 0x28
   e40da:	429a      	cmp	r2, r3
   e40dc:	f000 808b 	beq.w	e41f6 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x42a>
      use_optimized_path = true;
    } else {
      static bool has_warned = false;
      if (!has_warned) {
   e40e0:	f8df a050 	ldr.w	sl, [pc, #80]	; e4134 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x368>
   e40e4:	f89a 3000 	ldrb.w	r3, [sl]
   e40e8:	2b00      	cmp	r3, #0
   e40ea:	f040 8325 	bne.w	e4738 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x96c>
        context->ReportError(
            context,
            "Multiple depthwise conv ops match optimization parameters, but "
            "only the first will use the fast path, because there's only one "
            "RAM cache available");
   e40ee:	6973      	ldr	r3, [r6, #20]
   e40f0:	490d      	ldr	r1, [pc, #52]	; (e4128 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x35c>)
   e40f2:	4630      	mov	r0, r6
   e40f4:	4798      	blx	r3
        has_warned = true;
   e40f6:	2301      	movs	r3, #1
   e40f8:	f88a 3000 	strb.w	r3, [sl]
   e40fc:	e31c      	b.n	e4738 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x96c>
   e40fe:	bf00      	nop
   e4100:	000eb5dd 	.word	0x000eb5dd
   e4104:	000eb5f7 	.word	0x000eb5f7
   e4108:	000ec9de 	.word	0x000ec9de
   e410c:	000eb3b9 	.word	0x000eb3b9
   e4110:	000eb611 	.word	0x000eb611
   e4114:	000eb625 	.word	0x000eb625
   e4118:	000eb58e 	.word	0x000eb58e
   e411c:	000eb5a5 	.word	0x000eb5a5
   e4120:	000ecdd6 	.word	0x000ecdd6
   e4124:	000eb5c9 	.word	0x000eb5c9
   e4128:	000ecaa6 	.word	0x000ecaa6
   e412c:	2003e3d0 	.word	0x2003e3d0
   e4130:	2003e3c8 	.word	0x2003e3c8
   e4134:	2003e3cc 	.word	0x2003e3cc
                                        filter_width, filter_height, out_width,
                                        out_height, data_type, &data));

  // TODO(aselle): Consider whether float conv and quantized conv should be
  // separate ops to avoid dispatch overhead here.
  switch (input->type) {  // Already know in/out types are same.
   e4138:	f1b8 0f09 	cmp.w	r8, #9
   e413c:	f040 8101 	bne.w	e4342 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x576>
                             TfLiteDepthwiseConvParams* params, OpData* data,
                             const TfLiteTensor* input,
                             const TfLiteTensor* filter,
                             const TfLiteTensor* bias, TfLiteTensor* output) {
  DepthwiseParams op_params;
  op_params.padding_type = PaddingType::kSame;
   e4140:	2301      	movs	r3, #1
   e4142:	f88d 3148 	strb.w	r3, [sp, #328]	; 0x148
  op_params.padding_values.width = data->padding.width;
   e4146:	9b60      	ldr	r3, [sp, #384]	; 0x180
   e4148:	f8ad 314a 	strh.w	r3, [sp, #330]	; 0x14a
  op_params.padding_values.height = data->padding.height;
   e414c:	9b61      	ldr	r3, [sp, #388]	; 0x184
   e414e:	f8ad 314c 	strh.w	r3, [sp, #332]	; 0x14c
  op_params.stride_width = params->stride_width;
   e4152:	686b      	ldr	r3, [r5, #4]
   e4154:	f8ad 3152 	strh.w	r3, [sp, #338]	; 0x152
  op_params.stride_height = params->stride_height;
   e4158:	68ab      	ldr	r3, [r5, #8]
   e415a:	f8ad 3154 	strh.w	r3, [sp, #340]	; 0x154
  op_params.dilation_width_factor = params->dilation_width_factor;
   e415e:	696b      	ldr	r3, [r5, #20]
   e4160:	f8ad 3156 	strh.w	r3, [sp, #342]	; 0x156
  op_params.dilation_height_factor = params->dilation_height_factor;
   e4164:	69ab      	ldr	r3, [r5, #24]
   e4166:	f8ad 3158 	strh.w	r3, [sp, #344]	; 0x158
  op_params.depth_multiplier = params->depth_multiplier;
   e416a:	68eb      	ldr	r3, [r5, #12]
   e416c:	f8ad 315a 	strh.w	r3, [sp, #346]	; 0x15a
  op_params.input_offset = -input->params.zero_point;
   e4170:	f8d9 3010 	ldr.w	r3, [r9, #16]
   e4174:	425b      	negs	r3, r3
   e4176:	9357      	str	r3, [sp, #348]	; 0x15c
  op_params.weights_offset = 0;
   e4178:	2300      	movs	r3, #0
   e417a:	9358      	str	r3, [sp, #352]	; 0x160
  op_params.output_offset = output->params.zero_point;
   e417c:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e417e:	691b      	ldr	r3, [r3, #16]
   e4180:	9359      	str	r3, [sp, #356]	; 0x164
  // TODO(b/130439627): Use calculated value for clamping.
  op_params.quantized_activation_min = std::numeric_limits<int8_t>::min();
   e4182:	f06f 037f 	mvn.w	r3, #127	; 0x7f
  op_params.quantized_activation_max = std::numeric_limits<int8_t>::max();

  reference_integer_ops::DepthwiseConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
   e4186:	4649      	mov	r1, r9
  op_params.depth_multiplier = params->depth_multiplier;
  op_params.input_offset = -input->params.zero_point;
  op_params.weights_offset = 0;
  op_params.output_offset = output->params.zero_point;
  // TODO(b/130439627): Use calculated value for clamping.
  op_params.quantized_activation_min = std::numeric_limits<int8_t>::min();
   e4188:	935c      	str	r3, [sp, #368]	; 0x170
  op_params.quantized_activation_max = std::numeric_limits<int8_t>::max();

  reference_integer_ops::DepthwiseConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
   e418a:	a83e      	add	r0, sp, #248	; 0xf8
  op_params.input_offset = -input->params.zero_point;
  op_params.weights_offset = 0;
  op_params.output_offset = output->params.zero_point;
  // TODO(b/130439627): Use calculated value for clamping.
  op_params.quantized_activation_min = std::numeric_limits<int8_t>::min();
  op_params.quantized_activation_max = std::numeric_limits<int8_t>::max();
   e418c:	237f      	movs	r3, #127	; 0x7f

  reference_integer_ops::DepthwiseConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
      GetTensorData<int8>(input), GetTensorShape(filter),
   e418e:	ae43      	add	r6, sp, #268	; 0x10c
  op_params.input_offset = -input->params.zero_point;
  op_params.weights_offset = 0;
  op_params.output_offset = output->params.zero_point;
  // TODO(b/130439627): Use calculated value for clamping.
  op_params.quantized_activation_min = std::numeric_limits<int8_t>::min();
  op_params.quantized_activation_max = std::numeric_limits<int8_t>::max();
   e4190:	935d      	str	r3, [sp, #372]	; 0x174

  reference_integer_ops::DepthwiseConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
   e4192:	f7f3 fc9a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorData<int8>(input), GetTensorShape(filter),
   e4196:	4639      	mov	r1, r7
   e4198:	4630      	mov	r0, r6
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e419a:	f8d9 9004 	ldr.w	r9, [r9, #4]
   e419e:	f7f3 fc94 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e41a2:	f8d7 a004 	ldr.w	sl, [r7, #4]
      GetTensorData<int8>(filter), GetTensorShape(bias),
   e41a6:	af48      	add	r7, sp, #288	; 0x120
   e41a8:	4621      	mov	r1, r4
   e41aa:	4638      	mov	r0, r7
   e41ac:	f7f3 fc8d 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e41b0:	b104      	cbz	r4, e41b4 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x3e8>
   e41b2:	6864      	ldr	r4, [r4, #4]
      GetTensorData<int32>(bias), GetTensorShape(output),
   e41b4:	9909      	ldr	r1, [sp, #36]	; 0x24
   e41b6:	ad4d      	add	r5, sp, #308	; 0x134
   e41b8:	4628      	mov	r0, r5
   e41ba:	f7f3 fc86 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorData<int8>(output));
   e41be:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e41c0:	685b      	ldr	r3, [r3, #4]
   e41c2:	9306      	str	r3, [sp, #24]
   e41c4:	aaa6      	add	r2, sp, #664	; 0x298
   e41c6:	ab3e      	add	r3, sp, #248	; 0xf8
   e41c8:	a966      	add	r1, sp, #408	; 0x198
   e41ca:	a852      	add	r0, sp, #328	; 0x148
   e41cc:	9505      	str	r5, [sp, #20]
   e41ce:	9404      	str	r4, [sp, #16]
   e41d0:	9703      	str	r7, [sp, #12]
   e41d2:	f8cd a008 	str.w	sl, [sp, #8]
   e41d6:	9601      	str	r6, [sp, #4]
   e41d8:	f8cd 9000 	str.w	r9, [sp]
   e41dc:	f7ff fa85 	bl	e36ea <_ZN6tflite21reference_integer_ops23DepthwiseConvPerChannelERKNS_15DepthwiseParamsEPKlS5_RKNS_12RuntimeShapeEPKaS8_SA_S8_S5_S8_Pa>
  reference_integer_ops::DepthwiseConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
      GetTensorData<int8>(input), GetTensorShape(filter),
      GetTensorData<int8>(filter), GetTensorShape(bias),
      GetTensorData<int32>(bias), GetTensorShape(output),
   e41e0:	4628      	mov	r0, r5
   e41e2:	f7f3 f9c2 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>

  reference_integer_ops::DepthwiseConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
      GetTensorData<int8>(input), GetTensorShape(filter),
      GetTensorData<int8>(filter), GetTensorShape(bias),
   e41e6:	4638      	mov	r0, r7
   e41e8:	f7f3 f9bf 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.quantized_activation_max = std::numeric_limits<int8_t>::max();

  reference_integer_ops::DepthwiseConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
      GetTensorData<int8>(input), GetTensorShape(filter),
   e41ec:	4630      	mov	r0, r6
   e41ee:	f7f3 f9bc 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.quantized_activation_min = std::numeric_limits<int8_t>::min();
  op_params.quantized_activation_max = std::numeric_limits<int8_t>::max();

  reference_integer_ops::DepthwiseConvPerChannel(
      op_params, data->per_channel_output_multiplier,
      data->per_channel_output_shift, GetTensorShape(input),
   e41f2:	a83e      	add	r0, sp, #248	; 0xf8
   e41f4:	e0a1      	b.n	e433a <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x56e>
      }
    }
  }
  if (use_optimized_path) {
    DepthwiseConvOptimizedForFilterWidthEight(
        context, op_params, GetTensorShape(input),
   e41f6:	4649      	mov	r1, r9
   e41f8:	a848      	add	r0, sp, #288	; 0x120
   e41fa:	f7f3 fc66 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e41fe:	f8d9 3004 	ldr.w	r3, [r9, #4]
   e4202:	931a      	str	r3, [sp, #104]	; 0x68
        GetTensorData<uint8_t>(input), GetTensorShape(filter),
   e4204:	4639      	mov	r1, r7
   e4206:	4640      	mov	r0, r8
   e4208:	f7f3 fc5f 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e420c:	687b      	ldr	r3, [r7, #4]
   e420e:	931b      	str	r3, [sp, #108]	; 0x6c
        GetTensorData<uint8_t>(filter), GetTensorShape(bias),
   e4210:	4621      	mov	r1, r4
   e4212:	4628      	mov	r0, r5
   e4214:	f7f3 fc59 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e4218:	2c00      	cmp	r4, #0
   e421a:	f000 8287 	beq.w	e472c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x960>
   e421e:	6863      	ldr	r3, [r4, #4]
   e4220:	9316      	str	r3, [sp, #88]	; 0x58
        GetTensorData<int32_t>(bias), GetTensorShape(output),
   e4222:	9909      	ldr	r1, [sp, #36]	; 0x24
   e4224:	a839      	add	r0, sp, #228	; 0xe4
   e4226:	f7f3 fc50 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e422a:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e422c:	685b      	ldr	r3, [r3, #4]
   e422e:	9326      	str	r3, [sp, #152]	; 0x98
    TfLiteContext* context, const DepthwiseParams& params,
    const RuntimeShape& input_shape, const uint8* input_data,
    const RuntimeShape& filter_shape, const uint8* filter_data,
    const RuntimeShape& bias_shape, const int32* bias_data,
    const RuntimeShape& output_shape, uint8* output_data) {
  const int stride_width = params.stride_width;
   e4230:	f9bd 3152 	ldrsh.w	r3, [sp, #338]	; 0x152
   e4234:	9319      	str	r3, [sp, #100]	; 0x64
  const int stride_height = params.stride_height;
   e4236:	f9bd 3154 	ldrsh.w	r3, [sp, #340]	; 0x154
   e423a:	931c      	str	r3, [sp, #112]	; 0x70
  const int pad_width = params.padding_values.width;
   e423c:	f9bd 314a 	ldrsh.w	r3, [sp, #330]	; 0x14a
   e4240:	931d      	str	r3, [sp, #116]	; 0x74
  const int pad_height = params.padding_values.height;
   e4242:	f9bd 314c 	ldrsh.w	r3, [sp, #332]	; 0x14c
   e4246:	931e      	str	r3, [sp, #120]	; 0x78
  const int depth_multiplier = params.depth_multiplier;
   e4248:	f9bd 315a 	ldrsh.w	r3, [sp, #346]	; 0x15a
   e424c:	9317      	str	r3, [sp, #92]	; 0x5c
  const int32 output_activation_min = params.quantized_activation_min;
   e424e:	9b5c      	ldr	r3, [sp, #368]	; 0x170
   e4250:	931f      	str	r3, [sp, #124]	; 0x7c
  const int32 output_activation_max = params.quantized_activation_max;
   e4252:	9b5d      	ldr	r3, [sp, #372]	; 0x174
   e4254:	9320      	str	r3, [sp, #128]	; 0x80
  const int32 input_offset = params.input_offset;
   e4256:	9b57      	ldr	r3, [sp, #348]	; 0x15c
   e4258:	9327      	str	r3, [sp, #156]	; 0x9c
  const int32 filter_offset = params.weights_offset;
   e425a:	9b58      	ldr	r3, [sp, #352]	; 0x160
   e425c:	9321      	str	r3, [sp, #132]	; 0x84
  const int32 output_offset = params.output_offset;
   e425e:	9b59      	ldr	r3, [sp, #356]	; 0x164
   e4260:	9328      	str	r3, [sp, #160]	; 0xa0
  const int32 output_multiplier = params.output_multiplier;
   e4262:	9b5a      	ldr	r3, [sp, #360]	; 0x168
   e4264:	9329      	str	r3, [sp, #164]	; 0xa4
  const int output_shift = params.output_shift;
   e4266:	9b5b      	ldr	r3, [sp, #364]	; 0x16c
   e4268:	932a      	str	r3, [sp, #168]	; 0xa8
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e426a:	9b48      	ldr	r3, [sp, #288]	; 0x120
   e426c:	2b04      	cmp	r3, #4
   e426e:	f040 80df 	bne.w	e4430 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x664>
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
   e4272:	9b43      	ldr	r3, [sp, #268]	; 0x10c
   e4274:	2b04      	cmp	r3, #4
   e4276:	f040 80db 	bne.w	e4430 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x664>
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);
   e427a:	9c39      	ldr	r4, [sp, #228]	; 0xe4
   e427c:	2c04      	cmp	r4, #4
   e427e:	f040 80d7 	bne.w	e4430 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x664>

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
   e4282:	9b1f      	ldr	r3, [sp, #124]	; 0x7c
   e4284:	9a20      	ldr	r2, [sp, #128]	; 0x80
   e4286:	4293      	cmp	r3, r2
   e4288:	f300 80d2 	bgt.w	e4430 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x664>
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   e428c:	2300      	movs	r3, #0
   e428e:	4619      	mov	r1, r3
   e4290:	aa39      	add	r2, sp, #228	; 0xe4
   e4292:	a848      	add	r0, sp, #288	; 0x120
   e4294:	f7f8 fd25 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e4298:	2303      	movs	r3, #3
   e429a:	4619      	mov	r1, r3
   e429c:	aa39      	add	r2, sp, #228	; 0xe4
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
   e429e:	902b      	str	r0, [sp, #172]	; 0xac
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e42a0:	a843      	add	r0, sp, #268	; 0x10c
   e42a2:	f7f8 fd1e 	bl	dcce2 <_ZN6tflite11MatchingDimERKNS_12RuntimeShapeEiS2_i>
  const int input_height = input_shape.Dims(1);
   e42a6:	2101      	movs	r1, #1
  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 4);
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
   e42a8:	4682      	mov	sl, r0
  const int input_height = input_shape.Dims(1);
   e42aa:	a848      	add	r0, sp, #288	; 0x120
   e42ac:	f7f3 f968 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_width = input_shape.Dims(2);
   e42b0:	2102      	movs	r1, #2
  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 4);

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
   e42b2:	9018      	str	r0, [sp, #96]	; 0x60
  const int input_width = input_shape.Dims(2);
   e42b4:	a848      	add	r0, sp, #288	; 0x120
   e42b6:	f7f3 f963 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int input_depth = input_shape.Dims(3);
   e42ba:	2103      	movs	r1, #3

  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
   e42bc:	900e      	str	r0, [sp, #56]	; 0x38
  const int input_depth = input_shape.Dims(3);
   e42be:	a848      	add	r0, sp, #288	; 0x120
   e42c0:	f7f3 f95e 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_height = filter_shape.Dims(1);
   e42c4:	2101      	movs	r1, #1
  TFLITE_DCHECK_LE(output_activation_min, output_activation_max);
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
   e42c6:	900a      	str	r0, [sp, #40]	; 0x28
  const int filter_height = filter_shape.Dims(1);
   e42c8:	a843      	add	r0, sp, #268	; 0x10c
   e42ca:	f7f3 f959 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int filter_width = filter_shape.Dims(2);
   e42ce:	2102      	movs	r1, #2
  const int batches = MatchingDim(input_shape, 0, output_shape, 0);
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
   e42d0:	9009      	str	r0, [sp, #36]	; 0x24
  const int filter_width = filter_shape.Dims(2);
   e42d2:	a843      	add	r0, sp, #268	; 0x10c
   e42d4:	f7f3 f954 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_height = output_shape.Dims(1);
   e42d8:	2101      	movs	r1, #1
  const int output_depth = MatchingDim(filter_shape, 3, output_shape, 3);
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
   e42da:	4683      	mov	fp, r0
  const int output_height = output_shape.Dims(1);
   e42dc:	a839      	add	r0, sp, #228	; 0xe4
   e42de:	f7f3 f94f 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  const int output_width = output_shape.Dims(2);
   e42e2:	2102      	movs	r1, #2
  const int input_height = input_shape.Dims(1);
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
   e42e4:	902c      	str	r0, [sp, #176]	; 0xb0
  const int output_width = output_shape.Dims(2);
   e42e6:	a839      	add	r0, sp, #228	; 0xe4
   e42e8:	f7f3 f94a 	bl	d7580 <_ZNK6tflite12RuntimeShape4DimsEi>
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
   e42ec:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e42ee:	9a17      	ldr	r2, [sp, #92]	; 0x5c
  const int input_width = input_shape.Dims(2);
  const int input_depth = input_shape.Dims(3);
  const int filter_height = filter_shape.Dims(1);
  const int filter_width = filter_shape.Dims(2);
  const int output_height = output_shape.Dims(1);
  const int output_width = output_shape.Dims(2);
   e42f0:	902d      	str	r0, [sp, #180]	; 0xb4
  TFLITE_DCHECK_EQ(output_depth, input_depth * depth_multiplier);
   e42f2:	4353      	muls	r3, r2
   e42f4:	459a      	cmp	sl, r3
   e42f6:	f040 809b 	bne.w	e4430 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x664>
  TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_depth);
   e42fa:	a83e      	add	r0, sp, #248	; 0xf8
   e42fc:	f7f8 fce1 	bl	dccc2 <_ZNK6tflite12RuntimeShape8FlatSizeEv>
   e4300:	4582      	cmp	sl, r0
   e4302:	f040 8095 	bne.w	e4430 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x664>

  static int16_t reshaped_filter_data[kReshapedFilterDataSize];
  const int needed_size =
      output_depth * filter_width * filter_height * input_depth;
   e4306:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e4308:	fb0b f20a 	mul.w	r2, fp, sl
   e430c:	435a      	muls	r2, r3
   e430e:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e4310:	435a      	muls	r2, r3
  if (needed_size > kReshapedFilterDataSize) {
   e4312:	f5b2 6f80 	cmp.w	r2, #1024	; 0x400
   e4316:	f340 808d 	ble.w	e4434 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x668>
    context->ReportError(
        context,
        "Size too large for reshaped weight buffer (%d needed, %d available)",
        needed_size, kReshapedFilterDataSize);
   e431a:	6974      	ldr	r4, [r6, #20]
   e431c:	4962      	ldr	r1, [pc, #392]	; (e44a8 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6dc>)
   e431e:	f44f 6380 	mov.w	r3, #1024	; 0x400
   e4322:	4630      	mov	r0, r6
   e4324:	47a0      	blx	r4
  if (use_optimized_path) {
    DepthwiseConvOptimizedForFilterWidthEight(
        context, op_params, GetTensorShape(input),
        GetTensorData<uint8_t>(input), GetTensorShape(filter),
        GetTensorData<uint8_t>(filter), GetTensorShape(bias),
        GetTensorData<int32_t>(bias), GetTensorShape(output),
   e4326:	a839      	add	r0, sp, #228	; 0xe4
   e4328:	f7f3 f91f 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  }
  if (use_optimized_path) {
    DepthwiseConvOptimizedForFilterWidthEight(
        context, op_params, GetTensorShape(input),
        GetTensorData<uint8_t>(input), GetTensorShape(filter),
        GetTensorData<uint8_t>(filter), GetTensorShape(bias),
   e432c:	a83e      	add	r0, sp, #248	; 0xf8
   e432e:	f7f3 f91c 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
    }
  }
  if (use_optimized_path) {
    DepthwiseConvOptimizedForFilterWidthEight(
        context, op_params, GetTensorShape(input),
        GetTensorData<uint8_t>(input), GetTensorShape(filter),
   e4332:	a843      	add	r0, sp, #268	; 0x10c
   e4334:	f7f3 f919 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
      }
    }
  }
  if (use_optimized_path) {
    DepthwiseConvOptimizedForFilterWidthEight(
        context, op_params, GetTensorShape(input),
   e4338:	a848      	add	r0, sp, #288	; 0x120
        GetTensorData<uint8_t>(filter), GetTensorShape(bias),
        GetTensorData<int32_t>(bias), GetTensorShape(output),
        GetTensorData<uint8_t>(output));
  } else {
    tflite::reference_ops::DepthwiseConv(
        op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e433a:	f7f3 f916 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
    default:
      context->ReportError(context, "Type %s (%d) not supported.",
                           TfLiteTypeGetName(input->type), input->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
   e433e:	2000      	movs	r0, #0
   e4340:	e227      	b.n	e4792 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x9c6>
                                        filter_width, filter_height, out_width,
                                        out_height, data_type, &data));

  // TODO(aselle): Consider whether float conv and quantized conv should be
  // separate ops to avoid dispatch overhead here.
  switch (input->type) {  // Already know in/out types are same.
   e4342:	f1b8 0f01 	cmp.w	r8, #1
   e4346:	d166      	bne.n	e4416 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x64a>
void EvalFloat(TfLiteContext* context, TfLiteNode* node,
               TfLiteDepthwiseConvParams* params, OpData* data,
               const TfLiteTensor* input, const TfLiteTensor* filter,
               const TfLiteTensor* bias, TfLiteTensor* output) {
  float output_activation_min, output_activation_max;
  CalculateActivationRange(params->activation, &output_activation_min,
   e4348:	7c2b      	ldrb	r3, [r5, #16]
// Calculates the useful range of an activation layer given its activation
// tensor.a
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
   e434a:	2b01      	cmp	r3, #1
   e434c:	d011      	beq.n	e4372 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x5a6>
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
   e434e:	2b03      	cmp	r3, #3
   e4350:	d012      	beq.n	e4378 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x5ac>
  } else if (activation == kTfLiteActRelu1) {
    *activation_min = -1;
    *activation_max = 1;
  } else {
    *activation_min = std::numeric_limits<T>::lowest();
    *activation_max = std::numeric_limits<T>::max();
   e4352:	ed9f 7a56 	vldr	s14, [pc, #344]	; e44ac <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6e0>
   e4356:	eddf 6a56 	vldr	s13, [pc, #344]	; e44b0 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6e4>
   e435a:	2b02      	cmp	r3, #2
   e435c:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   e4360:	bf18      	it	ne
   e4362:	eef0 7a47 	vmovne.f32	s15, s14
   e4366:	eebf 7a00 	vmov.f32	s14, #240	; 0xbf800000 -1.0
   e436a:	bf18      	it	ne
   e436c:	eeb0 7a66 	vmovne.f32	s14, s13
   e4370:	e006      	b.n	e4380 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x5b4>
template <typename T>
void CalculateActivationRange(TfLiteFusedActivation activation,
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
   e4372:	eddf 7a4e 	vldr	s15, [pc, #312]	; e44ac <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6e0>
   e4376:	e001      	b.n	e437c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x5b0>
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
    *activation_max = 6;
   e4378:	eef1 7a08 	vmov.f32	s15, #24	; 0x40c00000  6.0
                              T* activation_min, T* activation_max) {
  if (activation == kTfLiteActRelu) {
    *activation_min = 0;
    *activation_max = std::numeric_limits<T>::max();
  } else if (activation == kTfLiteActRelu6) {
    *activation_min = 0;
   e437c:	ed9f 7a4d 	vldr	s14, [pc, #308]	; e44b4 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6e8>
                           &output_activation_max);

  tflite::DepthwiseParams op_params;
  // Padding type is ignored, but still set.
  op_params.padding_type = PaddingType::kSame;
  op_params.padding_values.width = data->padding.width;
   e4380:	9a60      	ldr	r2, [sp, #384]	; 0x180
   e4382:	f8ad 214a 	strh.w	r2, [sp, #330]	; 0x14a
  CalculateActivationRange(params->activation, &output_activation_min,
                           &output_activation_max);

  tflite::DepthwiseParams op_params;
  // Padding type is ignored, but still set.
  op_params.padding_type = PaddingType::kSame;
   e4386:	2301      	movs	r3, #1
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
   e4388:	9a61      	ldr	r2, [sp, #388]	; 0x184
  CalculateActivationRange(params->activation, &output_activation_min,
                           &output_activation_max);

  tflite::DepthwiseParams op_params;
  // Padding type is ignored, but still set.
  op_params.padding_type = PaddingType::kSame;
   e438a:	f88d 3148 	strb.w	r3, [sp, #328]	; 0x148
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
   e438e:	f8ad 214c 	strh.w	r2, [sp, #332]	; 0x14c
  op_params.stride_width = params->stride_width;
   e4392:	686a      	ldr	r2, [r5, #4]
   e4394:	f8ad 2152 	strh.w	r2, [sp, #338]	; 0x152
  op_params.stride_height = params->stride_height;
   e4398:	68aa      	ldr	r2, [r5, #8]
   e439a:	f8ad 2154 	strh.w	r2, [sp, #340]	; 0x154
  op_params.dilation_width_factor = 1;
   e439e:	f8ad 3156 	strh.w	r3, [sp, #342]	; 0x156
  op_params.dilation_height_factor = 1;
   e43a2:	f8ad 3158 	strh.w	r3, [sp, #344]	; 0x158
  op_params.depth_multiplier = params->depth_multiplier;
   e43a6:	68eb      	ldr	r3, [r5, #12]
   e43a8:	f8ad 315a 	strh.w	r3, [sp, #346]	; 0x15a
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;

  tflite::reference_ops::DepthwiseConv(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
   e43ac:	4649      	mov	r1, r9
   e43ae:	a83e      	add	r0, sp, #248	; 0xf8
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = 1;
  op_params.dilation_height_factor = 1;
  op_params.depth_multiplier = params->depth_multiplier;
  op_params.float_activation_min = output_activation_min;
   e43b0:	ed8d 7a5e 	vstr	s14, [sp, #376]	; 0x178
  op_params.float_activation_max = output_activation_max;
   e43b4:	edcd 7a5f 	vstr	s15, [sp, #380]	; 0x17c

  tflite::reference_ops::DepthwiseConv(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
      GetTensorShape(filter), GetTensorData<float>(filter),
      GetTensorShape(bias), GetTensorData<float>(bias), GetTensorShape(output),
   e43b8:	ad48      	add	r5, sp, #288	; 0x120
  op_params.depth_multiplier = params->depth_multiplier;
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;

  tflite::reference_ops::DepthwiseConv(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
   e43ba:	f7f3 fb86 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorShape(filter), GetTensorData<float>(filter),
   e43be:	4639      	mov	r1, r7
   e43c0:	a843      	add	r0, sp, #268	; 0x10c
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e43c2:	f8d9 8004 	ldr.w	r8, [r9, #4]
   e43c6:	f7f3 fb80 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
      GetTensorShape(bias), GetTensorData<float>(bias), GetTensorShape(output),
   e43ca:	4621      	mov	r1, r4
   e43cc:	4628      	mov	r0, r5
   e43ce:	f8d7 9004 	ldr.w	r9, [r7, #4]
   e43d2:	f7f3 fb7a 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e43d6:	b104      	cbz	r4, e43da <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x60e>
   e43d8:	6864      	ldr	r4, [r4, #4]
   e43da:	9909      	ldr	r1, [sp, #36]	; 0x24
   e43dc:	af4d      	add	r7, sp, #308	; 0x134
   e43de:	4638      	mov	r0, r7
   e43e0:	f7f3 fb73 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>

namespace tflite {

template <typename T>
inline T* GetTensorData(TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<T*>(tensor->data.raw) : nullptr;
   e43e4:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e43e6:	b10b      	cbz	r3, e43ec <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x620>
   e43e8:	685e      	ldr	r6, [r3, #4]
   e43ea:	e000      	b.n	e43ee <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x622>
   e43ec:	9e09      	ldr	r6, [sp, #36]	; 0x24
      GetTensorData<float>(output));
   e43ee:	9604      	str	r6, [sp, #16]
   e43f0:	ab43      	add	r3, sp, #268	; 0x10c
   e43f2:	4642      	mov	r2, r8
   e43f4:	a93e      	add	r1, sp, #248	; 0xf8
   e43f6:	a852      	add	r0, sp, #328	; 0x148
   e43f8:	9703      	str	r7, [sp, #12]
   e43fa:	9402      	str	r4, [sp, #8]
   e43fc:	9501      	str	r5, [sp, #4]
   e43fe:	f8cd 9000 	str.w	r9, [sp]
   e4402:	f7ff fa99 	bl	e3938 <_ZN6tflite13reference_ops13DepthwiseConvERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_Pf>
  op_params.float_activation_max = output_activation_max;

  tflite::reference_ops::DepthwiseConv(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
      GetTensorShape(filter), GetTensorData<float>(filter),
      GetTensorShape(bias), GetTensorData<float>(bias), GetTensorShape(output),
   e4406:	4638      	mov	r0, r7
   e4408:	f7f3 f8af 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   e440c:	4628      	mov	r0, r5
   e440e:	f7f3 f8ac 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;

  tflite::reference_ops::DepthwiseConv(
      op_params, GetTensorShape(input), GetTensorData<float>(input),
      GetTensorShape(filter), GetTensorData<float>(filter),
   e4412:	a843      	add	r0, sp, #268	; 0x10c
   e4414:	e6eb      	b.n	e41ee <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x422>
      break;
    case kTfLiteUInt8:
      EvalQuantized(context, node, params, &data, input, filter, bias, output);
      break;
    default:
      context->ReportError(context, "Type %s (%d) not supported.",
   e4416:	4640      	mov	r0, r8
   e4418:	6974      	ldr	r4, [r6, #20]
   e441a:	f7ef fe87 	bl	d412c <TfLiteTypeGetName>
                           TfLiteTypeGetName(input->type), input->type);
   e441e:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e4420:	4925      	ldr	r1, [pc, #148]	; (e44b8 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6ec>)
   e4422:	f81a 3003 	ldrb.w	r3, [sl, r3]
   e4426:	4602      	mov	r2, r0
   e4428:	4630      	mov	r0, r6
   e442a:	47a0      	blx	r4
            filter->quantization.params);
    TF_LITE_ENSURE(context, affine_quantization);
    TF_LITE_ENSURE(context, affine_quantization->scale);
  }

  TF_LITE_ENSURE_STATUS(CalculateOpData(context, node, params, width, height,
   e442c:	2001      	movs	r0, #1
   e442e:	e1b0      	b.n	e4792 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x9c6>
  const int32 input_offset = params.input_offset;
  const int32 filter_offset = params.weights_offset;
  const int32 output_offset = params.output_offset;
  const int32 output_multiplier = params.output_multiplier;
  const int output_shift = params.output_shift;
  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 4);
   e4430:	f001 f860 	bl	e54f4 <abort>
    return;
  }

  RuntimeShape reshaped_filter_shape;
  reshaped_filter_shape.BuildFrom(
      {1, output_depth, filter_height, filter_width});
   e4434:	2301      	movs	r3, #1
   e4436:	9335      	str	r3, [sp, #212]	; 0xd4
    const int dimensions_count =
        std::distance(src_iterable.begin(), src_iterable.end());
    Resize(dimensions_count);
    int32* data = DimsData();
    for (auto it : src_iterable) {
      *data = it;
   e4438:	934e      	str	r3, [sp, #312]	; 0x138

  // If this is the first time through, repack the weights into a cached buffer
  // so that they can be accessed sequentially.
  static bool is_reshaped_filter_initialized = false;
  if (!is_reshaped_filter_initialized) {
   e443a:	4b20      	ldr	r3, [pc, #128]	; (e44bc <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6f0>)
      TFLITE_CHECK(false && "No shape resizing supported on this platform");
#else   // TF_LITE_STATIC_MEMORY
      delete[] dims_pointer_;
#endif  // TF_LITE_STATIC_MEMORY
    }
    size_ = dimensions_count;
   e443c:	944d      	str	r4, [sp, #308]	; 0x134
   e443e:	781c      	ldrb	r4, [r3, #0]
    return;
  }

  RuntimeShape reshaped_filter_shape;
  reshaped_filter_shape.BuildFrom(
      {1, output_depth, filter_height, filter_width});
   e4440:	9a09      	ldr	r2, [sp, #36]	; 0x24
   e4442:	f8cd a0d8 	str.w	sl, [sp, #216]	; 0xd8
   e4446:	9237      	str	r2, [sp, #220]	; 0xdc
   e4448:	f8cd b0e0 	str.w	fp, [sp, #224]	; 0xe0
    const int dimensions_count =
        std::distance(src_iterable.begin(), src_iterable.end());
    Resize(dimensions_count);
    int32* data = DimsData();
    for (auto it : src_iterable) {
      *data = it;
   e444c:	f8cd a13c 	str.w	sl, [sp, #316]	; 0x13c
   e4450:	9250      	str	r2, [sp, #320]	; 0x140
   e4452:	f8cd b144 	str.w	fp, [sp, #324]	; 0x144

  // If this is the first time through, repack the weights into a cached buffer
  // so that they can be accessed sequentially.
  static bool is_reshaped_filter_initialized = false;
  if (!is_reshaped_filter_initialized) {
   e4456:	2c00      	cmp	r4, #0
   e4458:	d137      	bne.n	e44ca <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6fe>
              filter_data + Offset(filter_shape, 0, filter_y, filter_x, oc);
          int16_t* reshaped_filter =
              reshaped_filter_data +
              Offset(reshaped_filter_shape, 0, oc, filter_y, filter_x);
          *reshaped_filter =
              static_cast<int16_t>(*current_filter) + filter_offset;
   e445a:	4f19      	ldr	r7, [pc, #100]	; (e44c0 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6f4>)

  // If this is the first time through, repack the weights into a cached buffer
  // so that they can be accessed sequentially.
  static bool is_reshaped_filter_initialized = false;
  if (!is_reshaped_filter_initialized) {
    for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   e445c:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e445e:	42a3      	cmp	r3, r4
   e4460:	dd30      	ble.n	e44c4 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6f8>
   e4462:	2500      	movs	r5, #0
      for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   e4464:	45ab      	cmp	fp, r5
   e4466:	dd1c      	ble.n	e44a2 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6d6>
   e4468:	2600      	movs	r6, #0
        for (int oc = 0; oc < output_depth; ++oc) {
   e446a:	45b2      	cmp	sl, r6
   e446c:	dd17      	ble.n	e449e <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x6d2>
          const uint8* current_filter =
              filter_data + Offset(filter_shape, 0, filter_y, filter_x, oc);
   e446e:	9600      	str	r6, [sp, #0]
   e4470:	462b      	mov	r3, r5
   e4472:	4622      	mov	r2, r4
   e4474:	2100      	movs	r1, #0
   e4476:	a843      	add	r0, sp, #268	; 0x10c
   e4478:	f7f3 f8e7 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
          int16_t* reshaped_filter =
              reshaped_filter_data +
              Offset(reshaped_filter_shape, 0, oc, filter_y, filter_x);
   e447c:	4632      	mov	r2, r6
  if (!is_reshaped_filter_initialized) {
    for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
      for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
        for (int oc = 0; oc < output_depth; ++oc) {
          const uint8* current_filter =
              filter_data + Offset(filter_shape, 0, filter_y, filter_x, oc);
   e447e:	4680      	mov	r8, r0
          int16_t* reshaped_filter =
              reshaped_filter_data +
              Offset(reshaped_filter_shape, 0, oc, filter_y, filter_x);
   e4480:	4623      	mov	r3, r4
   e4482:	9500      	str	r5, [sp, #0]
   e4484:	2100      	movs	r1, #0
   e4486:	a84d      	add	r0, sp, #308	; 0x134
   e4488:	f7f3 f8df 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
          *reshaped_filter =
              static_cast<int16_t>(*current_filter) + filter_offset;
   e448c:	9b1b      	ldr	r3, [sp, #108]	; 0x6c
   e448e:	9a21      	ldr	r2, [sp, #132]	; 0x84
   e4490:	f813 3008 	ldrb.w	r3, [r3, r8]
   e4494:	4413      	add	r3, r2
   e4496:	f827 3010 	strh.w	r3, [r7, r0, lsl #1]
  // so that they can be accessed sequentially.
  static bool is_reshaped_filter_initialized = false;
  if (!is_reshaped_filter_initialized) {
    for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
      for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
        for (int oc = 0; oc < output_depth; ++oc) {
   e449a:	3601      	adds	r6, #1
   e449c:	e7e5      	b.n	e446a <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x69e>
  // If this is the first time through, repack the weights into a cached buffer
  // so that they can be accessed sequentially.
  static bool is_reshaped_filter_initialized = false;
  if (!is_reshaped_filter_initialized) {
    for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
      for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   e449e:	3501      	adds	r5, #1
   e44a0:	e7e0      	b.n	e4464 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x698>

  // If this is the first time through, repack the weights into a cached buffer
  // so that they can be accessed sequentially.
  static bool is_reshaped_filter_initialized = false;
  if (!is_reshaped_filter_initialized) {
    for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
   e44a2:	3401      	adds	r4, #1
   e44a4:	e7da      	b.n	e445c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x690>
   e44a6:	bf00      	nop
   e44a8:	000ecb39 	.word	0x000ecb39
   e44ac:	7f7fffff 	.word	0x7f7fffff
   e44b0:	ff7fffff 	.word	0xff7fffff
   e44b4:	00000000 	.word	0x00000000
   e44b8:	000eb640 	.word	0x000eb640
   e44bc:	2003dbc5 	.word	0x2003dbc5
   e44c0:	2003dbc6 	.word	0x2003dbc6
          *reshaped_filter =
              static_cast<int16_t>(*current_filter) + filter_offset;
        }
      }
    }
    is_reshaped_filter_initialized = true;
   e44c4:	4b9a      	ldr	r3, [pc, #616]	; (e4730 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x964>)
   e44c6:	2201      	movs	r2, #1
   e44c8:	701a      	strb	r2, [r3, #0]
  // If this is the first time through, repack the weights into a cached buffer
  // so that they can be accessed sequentially.
  static bool is_reshaped_filter_initialized = false;
  if (!is_reshaped_filter_initialized) {
    for (int filter_y = 0; filter_y < filter_height; ++filter_y) {
      for (int filter_x = 0; filter_x < filter_width; ++filter_x) {
   e44ca:	2300      	movs	r3, #0
   e44cc:	930b      	str	r3, [sp, #44]	; 0x2c
                    Offset(filter_shape, 0, filter_y, filter_x_start, oc);
                for (int filter_x = filter_x_start; filter_x < filter_x_end;
                     ++filter_x) {
                  int32 input_val = *current_input;
                  current_input += input_depth;
                  int32 filter_val = *current_filter;
   e44ce:	f1ca 0300 	rsb	r3, sl, #0
   e44d2:	9333      	str	r3, [sp, #204]	; 0xcc
      }
    }
    is_reshaped_filter_initialized = true;
  }

  for (int b = 0; b < batches; ++b) {
   e44d4:	9b2b      	ldr	r3, [sp, #172]	; 0xac
   e44d6:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
   e44d8:	4293      	cmp	r3, r2
   e44da:	f340 8123 	ble.w	e4724 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x958>
   e44de:	9b1e      	ldr	r3, [sp, #120]	; 0x78
   e44e0:	9a18      	ldr	r2, [sp, #96]	; 0x60
   e44e2:	4413      	add	r3, r2
   e44e4:	9313      	str	r3, [sp, #76]	; 0x4c
   e44e6:	9b1e      	ldr	r3, [sp, #120]	; 0x78
   e44e8:	425b      	negs	r3, r3
   e44ea:	930c      	str	r3, [sp, #48]	; 0x30
   e44ec:	2300      	movs	r3, #0
   e44ee:	930f      	str	r3, [sp, #60]	; 0x3c
    for (int out_y = 0; out_y < output_height; ++out_y) {
   e44f0:	9b2c      	ldr	r3, [sp, #176]	; 0xb0
   e44f2:	9a0f      	ldr	r2, [sp, #60]	; 0x3c
   e44f4:	4293      	cmp	r3, r2
   e44f6:	f340 8111 	ble.w	e471c <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x950>
   e44fa:	9a0c      	ldr	r2, [sp, #48]	; 0x30
   e44fc:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e44fe:	9818      	ldr	r0, [sp, #96]	; 0x60
   e4500:	9909      	ldr	r1, [sp, #36]	; 0x24
   e4502:	4413      	add	r3, r2
   e4504:	9a13      	ldr	r2, [sp, #76]	; 0x4c
   e4506:	4298      	cmp	r0, r3
   e4508:	bfc8      	it	gt
   e450a:	460a      	movgt	r2, r1
   e450c:	9b1d      	ldr	r3, [sp, #116]	; 0x74
   e450e:	922e      	str	r2, [sp, #184]	; 0xb8
   e4510:	ebc3 030b 	rsb	r3, r3, fp
   e4514:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   e4516:	930d      	str	r3, [sp, #52]	; 0x34
   e4518:	9b1d      	ldr	r3, [sp, #116]	; 0x74
   e451a:	4413      	add	r3, r2
   e451c:	9314      	str	r3, [sp, #80]	; 0x50
   e451e:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   e4520:	9a0c      	ldr	r2, [sp, #48]	; 0x30
   e4522:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
   e4526:	9331      	str	r3, [sp, #196]	; 0xc4
   e4528:	9b13      	ldr	r3, [sp, #76]	; 0x4c
   e452a:	2a00      	cmp	r2, #0
   e452c:	eba3 0300 	sub.w	r3, r3, r0
   e4530:	bfa8      	it	ge
   e4532:	2300      	movge	r3, #0
   e4534:	9324      	str	r3, [sp, #144]	; 0x90
   e4536:	2300      	movs	r3, #0
   e4538:	9310      	str	r3, [sp, #64]	; 0x40
      for (int out_x = 0; out_x < output_width; ++out_x) {
   e453a:	9b2d      	ldr	r3, [sp, #180]	; 0xb4
   e453c:	9a10      	ldr	r2, [sp, #64]	; 0x40
   e453e:	4293      	cmp	r3, r2
   e4540:	f340 80e1 	ble.w	e4706 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x93a>
   e4544:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   e4546:	9a0e      	ldr	r2, [sp, #56]	; 0x38
   e4548:	990d      	ldr	r1, [sp, #52]	; 0x34
   e454a:	ebcb 0303 	rsb	r3, fp, r3
   e454e:	9325      	str	r3, [sp, #148]	; 0x94
   e4550:	9b14      	ldr	r3, [sp, #80]	; 0x50
   e4552:	1a9b      	subs	r3, r3, r2
   e4554:	9330      	str	r3, [sp, #192]	; 0xc0
   e4556:	9b14      	ldr	r3, [sp, #80]	; 0x50
   e4558:	f04f 0800 	mov.w	r8, #0
   e455c:	428a      	cmp	r2, r1
   e455e:	bfc8      	it	gt
   e4560:	465b      	movgt	r3, fp
   e4562:	932f      	str	r3, [sp, #188]	; 0xbc
   e4564:	f8cd 8044 	str.w	r8, [sp, #68]	; 0x44
        for (int ic = 0; ic < input_depth; ++ic) {
   e4568:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e456a:	9a11      	ldr	r2, [sp, #68]	; 0x44
   e456c:	4293      	cmp	r3, r2
   e456e:	f340 80bf 	ble.w	e46f0 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x924>
   e4572:	9b16      	ldr	r3, [sp, #88]	; 0x58
   e4574:	eb03 0388 	add.w	r3, r3, r8, lsl #2
   e4578:	9332      	str	r3, [sp, #200]	; 0xc8
   e457a:	f04f 0900 	mov.w	r9, #0
          for (int m = 0; m < depth_multiplier; m++) {
   e457e:	9b17      	ldr	r3, [sp, #92]	; 0x5c
   e4580:	454b      	cmp	r3, r9
   e4582:	f340 80af 	ble.w	e46e4 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x918>
   e4586:	eb09 0308 	add.w	r3, r9, r8
   e458a:	9315      	str	r3, [sp, #84]	; 0x54
            }
            int in_y = in_y_start;
            int in_x_start = in_x_origin;
            int filter_x_start = 0;
            bool is_out_of_x_bounds = false;
            if (in_x_origin < 0) {
   e458c:	9b25      	ldr	r3, [sp, #148]	; 0x94
              is_out_of_x_bounds = true;
            }
            int filter_x_end = filter_width;
            if ((in_x_origin + filter_width) >= input_width) {
              filter_x_end -= (in_x_origin + filter_width) - input_width;
              is_out_of_x_bounds = true;
   e458e:	9a0d      	ldr	r2, [sp, #52]	; 0x34
            }
            for (int filter_y = filter_y_start; filter_y < filter_y_end;
   e4590:	9d24      	ldr	r5, [sp, #144]	; 0x90
            }
            int in_y = in_y_start;
            int in_x_start = in_x_origin;
            int filter_x_start = 0;
            bool is_out_of_x_bounds = false;
            if (in_x_origin < 0) {
   e4592:	2b00      	cmp	r3, #0
              in_x_start = 0;
              filter_x_start = 0 - in_x_origin;
   e4594:	bfbd      	ittte	lt
   e4596:	9b30      	ldrlt	r3, [sp, #192]	; 0xc0
   e4598:	9312      	strlt	r3, [sp, #72]	; 0x48
            int in_y = in_y_start;
            int in_x_start = in_x_origin;
            int filter_x_start = 0;
            bool is_out_of_x_bounds = false;
            if (in_x_origin < 0) {
              in_x_start = 0;
   e459a:	2300      	movlt	r3, #0
            }
            int in_y = in_y_start;
            int in_x_start = in_x_origin;
            int filter_x_start = 0;
            bool is_out_of_x_bounds = false;
            if (in_x_origin < 0) {
   e459c:	9322      	strge	r3, [sp, #136]	; 0x88
              in_x_start = 0;
   e459e:	bfb8      	it	lt
   e45a0:	9322      	strlt	r3, [sp, #136]	; 0x88
              is_out_of_x_bounds = true;
            }
            int filter_x_end = filter_width;
            if ((in_x_origin + filter_width) >= input_width) {
              filter_x_end -= (in_x_origin + filter_width) - input_width;
              is_out_of_x_bounds = true;
   e45a2:	9b0e      	ldr	r3, [sp, #56]	; 0x38
              filter_y_end -= (in_y_origin + filter_height) - input_height;
            }
            int in_y = in_y_start;
            int in_x_start = in_x_origin;
            int filter_x_start = 0;
            bool is_out_of_x_bounds = false;
   e45a4:	bfaa      	itet	ge
   e45a6:	2600      	movge	r6, #0
            if (in_x_origin < 0) {
              in_x_start = 0;
              filter_x_start = 0 - in_x_origin;
              is_out_of_x_bounds = true;
   e45a8:	2601      	movlt	r6, #1
            if ((in_y_origin + filter_height) >= input_height) {
              filter_y_end -= (in_y_origin + filter_height) - input_height;
            }
            int in_y = in_y_start;
            int in_x_start = in_x_origin;
            int filter_x_start = 0;
   e45aa:	9612      	strge	r6, [sp, #72]	; 0x48
        for (int ic = 0; ic < input_depth; ++ic) {
          for (int m = 0; m < depth_multiplier; m++) {
            const int oc = m + ic * depth_multiplier;
            const int in_x_origin = (out_x * stride_width) - pad_width;
            const int in_y_origin = (out_y * stride_height) - pad_height;
            int32 acc = 0;
   e45ac:	2400      	movs	r4, #0
              is_out_of_x_bounds = true;
            }
            int filter_x_end = filter_width;
            if ((in_x_origin + filter_width) >= input_width) {
              filter_x_end -= (in_x_origin + filter_width) - input_width;
              is_out_of_x_bounds = true;
   e45ae:	4293      	cmp	r3, r2
   e45b0:	bfd8      	it	le
   e45b2:	2601      	movle	r6, #1
   e45b4:	9b31      	ldr	r3, [sp, #196]	; 0xc4
   e45b6:	9a24      	ldr	r2, [sp, #144]	; 0x90
   e45b8:	1a9a      	subs	r2, r3, r2
            }
            for (int filter_y = filter_y_start; filter_y < filter_y_end;
   e45ba:	9b2e      	ldr	r3, [sp, #184]	; 0xb8
   e45bc:	42ab      	cmp	r3, r5
   e45be:	442a      	add	r2, r5
   e45c0:	dd6d      	ble.n	e469e <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x8d2>
                 ++filter_y, ++in_y) {
              const uint8* current_input =
                  input_data + Offset(input_shape, b, in_y, in_x_start, ic);
   e45c2:	9b11      	ldr	r3, [sp, #68]	; 0x44
   e45c4:	9300      	str	r3, [sp, #0]
   e45c6:	990b      	ldr	r1, [sp, #44]	; 0x2c
   e45c8:	9b22      	ldr	r3, [sp, #136]	; 0x88
   e45ca:	a848      	add	r0, sp, #288	; 0x120
   e45cc:	f7f3 f83d 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   e45d0:	9b1a      	ldr	r3, [sp, #104]	; 0x68
   e45d2:	9023      	str	r0, [sp, #140]	; 0x8c
              if ((filter_width == 8) && !is_out_of_x_bounds) {
   e45d4:	f1bb 0f08 	cmp.w	fp, #8
              is_out_of_x_bounds = true;
            }
            for (int filter_y = filter_y_start; filter_y < filter_y_end;
                 ++filter_y, ++in_y) {
              const uint8* current_input =
                  input_data + Offset(input_shape, b, in_y, in_x_start, ic);
   e45d8:	eb03 0700 	add.w	r7, r3, r0
              if ((filter_width == 8) && !is_out_of_x_bounds) {
   e45dc:	d13c      	bne.n	e4658 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x88c>
   e45de:	2e00      	cmp	r6, #0
   e45e0:	d13a      	bne.n	e4658 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x88c>
                int16* current_filter =
                    reshaped_filter_data + Offset(reshaped_filter_shape, 0, oc,
   e45e2:	9b12      	ldr	r3, [sp, #72]	; 0x48
   e45e4:	9300      	str	r3, [sp, #0]
   e45e6:	9a15      	ldr	r2, [sp, #84]	; 0x54
   e45e8:	462b      	mov	r3, r5
   e45ea:	4631      	mov	r1, r6
   e45ec:	a84d      	add	r0, sp, #308	; 0x134
   e45ee:	f7f3 f82c 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                                                  filter_y, filter_x_start);
   e45f2:	4b50      	ldr	r3, [pc, #320]	; (e4734 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x968>)
                const uint32_t input_vals0 =
                    *reinterpret_cast<const uint32_t*>(current_input);
   e45f4:	9a23      	ldr	r2, [sp, #140]	; 0x8c
              const uint8* current_input =
                  input_data + Offset(input_shape, b, in_y, in_x_start, ic);
              if ((filter_width == 8) && !is_out_of_x_bounds) {
                int16* current_filter =
                    reshaped_filter_data + Offset(reshaped_filter_shape, 0, oc,
                                                  filter_y, filter_x_start);
   e45f6:	eb03 0040 	add.w	r0, r3, r0, lsl #1
                const uint32_t input_vals0 =
                    *reinterpret_cast<const uint32_t*>(current_input);
   e45fa:	9b1a      	ldr	r3, [sp, #104]	; 0x68
                current_input += 4;
                const int32_t filter_vals0 =
                    *reinterpret_cast<const int32_t*>(current_filter);
   e45fc:	f8d0 c000 	ldr.w	ip, [r0]
              if ((filter_width == 8) && !is_out_of_x_bounds) {
                int16* current_filter =
                    reshaped_filter_data + Offset(reshaped_filter_shape, 0, oc,
                                                  filter_y, filter_x_start);
                const uint32_t input_vals0 =
                    *reinterpret_cast<const uint32_t*>(current_input);
   e4600:	5899      	ldr	r1, [r3, r2]
                const int32_t filter_vals0 =
                    *reinterpret_cast<const int32_t*>(current_filter);
                current_filter += 2;
                const uint8 input_val0 = input_vals0 & 0xff;
                const int16 filter_val0 = filter_vals0 & 0xffff;
                acc += filter_val0 * input_val0;
   e4602:	fa0f f28c 	sxth.w	r2, ip
   e4606:	b2cb      	uxtb	r3, r1
   e4608:	fb02 4203 	mla	r2, r2, r3, r4
                const uint8 input_val1 = (input_vals0 >> 8) & 0xff;
                const int16 filter_val1 = (filter_vals0 >> 16) & 0xffff;
                acc += filter_val1 * input_val1;
   e460c:	ea4f 4e2c 	mov.w	lr, ip, asr #16
   e4610:	f3c1 2307 	ubfx	r3, r1, #8, #8
   e4614:	fb0e 2e03 	mla	lr, lr, r3, r2

                const int32_t filter_vals1 =
                    *reinterpret_cast<const int32_t*>(current_filter);
   e4618:	6843      	ldr	r3, [r0, #4]
                current_filter += 2;
                const uint8 input_val2 = (input_vals0 >> 16) & 0xff;
                const int16 filter_val2 = filter_vals1 & 0xffff;
                acc += filter_val2 * input_val2;
   e461a:	f3c1 4c07 	ubfx	ip, r1, #16, #8
   e461e:	b21a      	sxth	r2, r3
                const uint8 input_val3 = (input_vals0 >> 24) & 0xff;
                const int16 filter_val3 = (filter_vals1 >> 16) & 0xffff;
                acc += filter_val3 * input_val3;
   e4620:	0e09      	lsrs	r1, r1, #24
   e4622:	141b      	asrs	r3, r3, #16
                const int32_t filter_vals1 =
                    *reinterpret_cast<const int32_t*>(current_filter);
                current_filter += 2;
                const uint8 input_val2 = (input_vals0 >> 16) & 0xff;
                const int16 filter_val2 = filter_vals1 & 0xffff;
                acc += filter_val2 * input_val2;
   e4624:	fb02 e20c 	mla	r2, r2, ip, lr
                const uint8 input_val3 = (input_vals0 >> 24) & 0xff;
                const int16 filter_val3 = (filter_vals1 >> 16) & 0xffff;
                acc += filter_val3 * input_val3;
   e4628:	fb01 2203 	mla	r2, r1, r3, r2

                const uint32_t input_vals1 =
                    *reinterpret_cast<const uint32_t*>(current_input);
   e462c:	687b      	ldr	r3, [r7, #4]
                const int32_t filter_vals2 =
                    *reinterpret_cast<const int32_t*>(current_filter);
   e462e:	6881      	ldr	r1, [r0, #8]
                current_filter += 2;
                const uint8 input_val4 = input_vals1 & 0xff;
                const int16 filter_val4 = filter_vals2 & 0xffff;
                acc += filter_val4 * input_val4;
   e4630:	b2dc      	uxtb	r4, r3
   e4632:	b20f      	sxth	r7, r1
   e4634:	fb07 2204 	mla	r2, r7, r4, r2
                const uint8 input_val5 = (input_vals1 >> 8) & 0xff;
                const int16 filter_val5 = (filter_vals2 >> 16) & 0xffff;
                acc += filter_val5 * input_val5;
   e4638:	1409      	asrs	r1, r1, #16
   e463a:	f3c3 2707 	ubfx	r7, r3, #8, #8
   e463e:	fb01 2207 	mla	r2, r1, r7, r2

                const int32_t filter_vals3 =
                    *reinterpret_cast<const int32_t*>(current_filter);
   e4642:	68c1      	ldr	r1, [r0, #12]
                const uint8 input_val6 = (input_vals1 >> 16) & 0xff;
                const int16 filter_val6 = filter_vals3 & 0xffff;
                acc += filter_val6 * input_val6;
   e4644:	f3c3 4007 	ubfx	r0, r3, #16, #8
   e4648:	b20c      	sxth	r4, r1
   e464a:	fb04 2400 	mla	r4, r4, r0, r2
                const uint8 input_val7 = (input_vals1 >> 24) & 0xff;
                const int16 filter_val7 = (filter_vals3 >> 16) & 0xffff;
                acc += filter_val7 * input_val7;
   e464e:	1409      	asrs	r1, r1, #16
   e4650:	0e1b      	lsrs	r3, r3, #24
   e4652:	fb03 4401 	mla	r4, r3, r1, r4
   e4656:	e020      	b.n	e469a <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x8ce>
              } else {
                const uint8* current_filter =
                    filter_data +
                    Offset(filter_shape, 0, filter_y, filter_x_start, oc);
   e4658:	9b15      	ldr	r3, [sp, #84]	; 0x54
   e465a:	9300      	str	r3, [sp, #0]
   e465c:	462a      	mov	r2, r5
   e465e:	9b12      	ldr	r3, [sp, #72]	; 0x48
   e4660:	2100      	movs	r1, #0
   e4662:	a843      	add	r0, sp, #268	; 0x10c
   e4664:	f7f2 fff1 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
   e4668:	9b1b      	ldr	r3, [sp, #108]	; 0x6c
                for (int filter_x = filter_x_start; filter_x < filter_x_end;
                     ++filter_x) {
                  int32 input_val = *current_input;
   e466a:	9a0a      	ldr	r2, [sp, #40]	; 0x28
   e466c:	4418      	add	r0, r3
                acc += filter_val7 * input_val7;
              } else {
                const uint8* current_filter =
                    filter_data +
                    Offset(filter_shape, 0, filter_y, filter_x_start, oc);
                for (int filter_x = filter_x_start; filter_x < filter_x_end;
   e466e:	9b12      	ldr	r3, [sp, #72]	; 0x48
                     ++filter_x) {
                  int32 input_val = *current_input;
   e4670:	f1c2 0e00 	rsb	lr, r2, #0
   e4674:	9a0a      	ldr	r2, [sp, #40]	; 0x28
   e4676:	4417      	add	r7, r2
                acc += filter_val7 * input_val7;
              } else {
                const uint8* current_filter =
                    filter_data +
                    Offset(filter_shape, 0, filter_y, filter_x_start, oc);
                for (int filter_x = filter_x_start; filter_x < filter_x_end;
   e4678:	9a2f      	ldr	r2, [sp, #188]	; 0xbc
   e467a:	429a      	cmp	r2, r3
   e467c:	4450      	add	r0, sl
   e467e:	dd0c      	ble.n	e469a <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x8ce>
                  int32 input_val = *current_input;
                  current_input += input_depth;
                  int32 filter_val = *current_filter;
                  current_filter += output_depth;
                  acc +=
                      (filter_val + filter_offset) * (input_val + input_offset);
   e4680:	9a33      	ldr	r2, [sp, #204]	; 0xcc
   e4682:	9921      	ldr	r1, [sp, #132]	; 0x84
   e4684:	5c82      	ldrb	r2, [r0, r2]
   e4686:	eb02 0c01 	add.w	ip, r2, r1
   e468a:	f817 100e 	ldrb.w	r1, [r7, lr]
   e468e:	9a27      	ldr	r2, [sp, #156]	; 0x9c
   e4690:	4411      	add	r1, r2
   e4692:	fb01 440c 	mla	r4, r1, ip, r4
                acc += filter_val7 * input_val7;
              } else {
                const uint8* current_filter =
                    filter_data +
                    Offset(filter_shape, 0, filter_y, filter_x_start, oc);
                for (int filter_x = filter_x_start; filter_x < filter_x_end;
   e4696:	3301      	adds	r3, #1
   e4698:	e7ec      	b.n	e4674 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x8a8>
            int filter_x_end = filter_width;
            if ((in_x_origin + filter_width) >= input_width) {
              filter_x_end -= (in_x_origin + filter_width) - input_width;
              is_out_of_x_bounds = true;
            }
            for (int filter_y = filter_y_start; filter_y < filter_y_end;
   e469a:	3501      	adds	r5, #1
   e469c:	e78a      	b.n	e45b4 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x7e8>
                  acc +=
                      (filter_val + filter_offset) * (input_val + input_offset);
                }
              }
            }
            if (bias_data) {
   e469e:	9b16      	ldr	r3, [sp, #88]	; 0x58
   e46a0:	b11b      	cbz	r3, e46aa <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x8de>
              acc += bias_data[oc];
   e46a2:	9b32      	ldr	r3, [sp, #200]	; 0xc8
   e46a4:	f853 3029 	ldr.w	r3, [r3, r9, lsl #2]
   e46a8:	441c      	add	r4, r3
}

template <>
inline int32 DepthwiseConvRound<DepthwiseConvOutputRounding::kAwayFromZero>(
    int32 x, int32 quantized_multiplier, int shift) {
  return MultiplyByQuantizedMultiplier(x, quantized_multiplier, shift);
   e46aa:	9a2a      	ldr	r2, [sp, #168]	; 0xa8
   e46ac:	9929      	ldr	r1, [sp, #164]	; 0xa4
   e46ae:	4620      	mov	r0, r4
   e46b0:	f7f8 fb26 	bl	dcd00 <_ZN6tflite29MultiplyByQuantizedMultiplierElli>
            }
            acc = reference_ops::depthwise_conv::DepthwiseConvRound<
                DepthwiseConvOutputRounding::kAwayFromZero>(
                acc, output_multiplier, output_shift);
            acc += output_offset;
   e46b4:	9b28      	ldr	r3, [sp, #160]	; 0xa0
            acc = std::max(acc, output_activation_min);
            acc = std::min(acc, output_activation_max);
            output_data[Offset(output_shape, b, out_y, out_x, oc)] =
   e46b6:	9a0f      	ldr	r2, [sp, #60]	; 0x3c
   e46b8:	990b      	ldr	r1, [sp, #44]	; 0x2c
              acc += bias_data[oc];
            }
            acc = reference_ops::depthwise_conv::DepthwiseConvRound<
                DepthwiseConvOutputRounding::kAwayFromZero>(
                acc, output_multiplier, output_shift);
            acc += output_offset;
   e46ba:	4418      	add	r0, r3
   e46bc:	9b1f      	ldr	r3, [sp, #124]	; 0x7c
   e46be:	4283      	cmp	r3, r0
   e46c0:	bfb8      	it	lt
   e46c2:	4603      	movlt	r3, r0
   e46c4:	461c      	mov	r4, r3
   e46c6:	9b20      	ldr	r3, [sp, #128]	; 0x80
   e46c8:	429c      	cmp	r4, r3
   e46ca:	bfa8      	it	ge
   e46cc:	461c      	movge	r4, r3
            acc = std::max(acc, output_activation_min);
            acc = std::min(acc, output_activation_max);
            output_data[Offset(output_shape, b, out_y, out_x, oc)] =
   e46ce:	9b15      	ldr	r3, [sp, #84]	; 0x54
   e46d0:	9300      	str	r3, [sp, #0]
   e46d2:	a839      	add	r0, sp, #228	; 0xe4
   e46d4:	9b10      	ldr	r3, [sp, #64]	; 0x40
   e46d6:	f7f2 ffb8 	bl	d764a <_ZN6tflite6OffsetERKNS_12RuntimeShapeEiiii>
                static_cast<uint8>(acc);
   e46da:	9b26      	ldr	r3, [sp, #152]	; 0x98

  for (int b = 0; b < batches; ++b) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int ic = 0; ic < input_depth; ++ic) {
          for (int m = 0; m < depth_multiplier; m++) {
   e46dc:	f109 0901 	add.w	r9, r9, #1
                acc, output_multiplier, output_shift);
            acc += output_offset;
            acc = std::max(acc, output_activation_min);
            acc = std::min(acc, output_activation_max);
            output_data[Offset(output_shape, b, out_y, out_x, oc)] =
                static_cast<uint8>(acc);
   e46e0:	541c      	strb	r4, [r3, r0]
   e46e2:	e74c      	b.n	e457e <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x7b2>
  }

  for (int b = 0; b < batches; ++b) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
        for (int ic = 0; ic < input_depth; ++ic) {
   e46e4:	9b11      	ldr	r3, [sp, #68]	; 0x44
   e46e6:	3301      	adds	r3, #1
   e46e8:	9311      	str	r3, [sp, #68]	; 0x44
   e46ea:	9b17      	ldr	r3, [sp, #92]	; 0x5c
   e46ec:	4498      	add	r8, r3
   e46ee:	e73b      	b.n	e4568 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x79c>
    is_reshaped_filter_initialized = true;
  }

  for (int b = 0; b < batches; ++b) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
      for (int out_x = 0; out_x < output_width; ++out_x) {
   e46f0:	9b10      	ldr	r3, [sp, #64]	; 0x40
   e46f2:	9a19      	ldr	r2, [sp, #100]	; 0x64
   e46f4:	3301      	adds	r3, #1
   e46f6:	9310      	str	r3, [sp, #64]	; 0x40
   e46f8:	9b0d      	ldr	r3, [sp, #52]	; 0x34
   e46fa:	4413      	add	r3, r2
   e46fc:	930d      	str	r3, [sp, #52]	; 0x34
   e46fe:	9b14      	ldr	r3, [sp, #80]	; 0x50
   e4700:	1a9b      	subs	r3, r3, r2
   e4702:	9314      	str	r3, [sp, #80]	; 0x50
   e4704:	e719      	b.n	e453a <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x76e>
    }
    is_reshaped_filter_initialized = true;
  }

  for (int b = 0; b < batches; ++b) {
    for (int out_y = 0; out_y < output_height; ++out_y) {
   e4706:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
   e4708:	9a1c      	ldr	r2, [sp, #112]	; 0x70
   e470a:	3301      	adds	r3, #1
   e470c:	930f      	str	r3, [sp, #60]	; 0x3c
   e470e:	9b13      	ldr	r3, [sp, #76]	; 0x4c
   e4710:	1a9b      	subs	r3, r3, r2
   e4712:	9313      	str	r3, [sp, #76]	; 0x4c
   e4714:	9b0c      	ldr	r3, [sp, #48]	; 0x30
   e4716:	4413      	add	r3, r2
   e4718:	930c      	str	r3, [sp, #48]	; 0x30
   e471a:	e6e9      	b.n	e44f0 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x724>
      }
    }
    is_reshaped_filter_initialized = true;
  }

  for (int b = 0; b < batches; ++b) {
   e471c:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
   e471e:	3301      	adds	r3, #1
   e4720:	930b      	str	r3, [sp, #44]	; 0x2c
   e4722:	e6d7      	b.n	e44d4 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x708>
        "Size too large for reshaped weight buffer (%d needed, %d available)",
        needed_size, kReshapedFilterDataSize);
    return;
  }

  RuntimeShape reshaped_filter_shape;
   e4724:	a84d      	add	r0, sp, #308	; 0x134
   e4726:	f7f2 ff20 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
   e472a:	e5fc      	b.n	e4326 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x55a>
}

template <typename T>
inline const T* GetTensorData(const TfLiteTensor* tensor) {
  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
                           : nullptr;
   e472c:	9416      	str	r4, [sp, #88]	; 0x58
   e472e:	e578      	b.n	e4222 <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x456>
   e4730:	2003dbc5 	.word	0x2003dbc5
   e4734:	2003dbc6 	.word	0x2003dbc6
        GetTensorData<uint8_t>(filter), GetTensorShape(bias),
        GetTensorData<int32_t>(bias), GetTensorShape(output),
        GetTensorData<uint8_t>(output));
  } else {
    tflite::reference_ops::DepthwiseConv(
        op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e4738:	4649      	mov	r1, r9
   e473a:	a84d      	add	r0, sp, #308	; 0x134
   e473c:	f7f3 f9c5 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
        GetTensorShape(filter), GetTensorData<uint8_t>(filter),
   e4740:	4639      	mov	r1, r7
   e4742:	a848      	add	r0, sp, #288	; 0x120
   e4744:	f8d9 9004 	ldr.w	r9, [r9, #4]
   e4748:	f7f3 f9bf 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
        GetTensorShape(bias), GetTensorData<int32_t>(bias),
   e474c:	4621      	mov	r1, r4
   e474e:	4640      	mov	r0, r8
   e4750:	687f      	ldr	r7, [r7, #4]
   e4752:	f7f3 f9ba 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
   e4756:	b104      	cbz	r4, e475a <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x98e>
   e4758:	6864      	ldr	r4, [r4, #4]
        GetTensorShape(output), GetTensorData<uint8_t>(output));
   e475a:	9909      	ldr	r1, [sp, #36]	; 0x24
   e475c:	4628      	mov	r0, r5
   e475e:	f7f3 f9b4 	bl	d7aca <_ZN6tflite14GetTensorShapeEPK12TfLiteTensor>
  return depthwise_conv::DepthwiseConvBasicKernel<
      DepthwiseConvOutputRounding::kAwayFromZero>::Run(params, input_shape,
                                                       input_data, filter_shape,
                                                       filter_data, bias_shape,
                                                       bias_data, output_shape,
                                                       output_data);
   e4762:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e4764:	685b      	ldr	r3, [r3, #4]
   e4766:	9304      	str	r3, [sp, #16]
   e4768:	464a      	mov	r2, r9
   e476a:	ab48      	add	r3, sp, #288	; 0x120
   e476c:	a94d      	add	r1, sp, #308	; 0x134
   e476e:	a852      	add	r0, sp, #328	; 0x148
   e4770:	9503      	str	r5, [sp, #12]
   e4772:	9402      	str	r4, [sp, #8]
   e4774:	e88d 0180 	stmia.w	sp, {r7, r8}
   e4778:	f7ff fa08 	bl	e3b8c <_ZN6tflite13reference_ops14depthwise_conv24DepthwiseConvBasicKernelILNS_27DepthwiseConvOutputRoundingE1EE3RunERKNS_15DepthwiseParamsERKNS_12RuntimeShapeEPKhSA_SC_SA_PKlSA_Ph>
   e477c:	4628      	mov	r0, r5
   e477e:	f7f2 fef4 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
        GetTensorData<uint8_t>(output));
  } else {
    tflite::reference_ops::DepthwiseConv(
        op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
        GetTensorShape(filter), GetTensorData<uint8_t>(filter),
        GetTensorShape(bias), GetTensorData<int32_t>(bias),
   e4782:	4640      	mov	r0, r8
   e4784:	f7f2 fef1 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
        GetTensorData<int32_t>(bias), GetTensorShape(output),
        GetTensorData<uint8_t>(output));
  } else {
    tflite::reference_ops::DepthwiseConv(
        op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
        GetTensorShape(filter), GetTensorData<uint8_t>(filter),
   e4788:	a848      	add	r0, sp, #288	; 0x120
   e478a:	f7f2 feee 	bl	d756a <_ZN6tflite12RuntimeShapeD1Ev>
        GetTensorData<uint8_t>(filter), GetTensorShape(bias),
        GetTensorData<int32_t>(bias), GetTensorShape(output),
        GetTensorData<uint8_t>(output));
  } else {
    tflite::reference_ops::DepthwiseConv(
        op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
   e478e:	a84d      	add	r0, sp, #308	; 0x134
   e4790:	e5d3      	b.n	e433a <_ZN6tflite3ops5micro14depthwise_conv4EvalEP13TfLiteContextP10TfLiteNode+0x56e>
      context->ReportError(context, "Type %s (%d) not supported.",
                           TfLiteTypeGetName(input->type), input->type);
      return kTfLiteError;
  }
  return kTfLiteOk;
}
   e4792:	f50d 7d69 	add.w	sp, sp, #932	; 0x3a4
   e4796:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e479a:	bf00      	nop

000e479c <_ZN6tflite19GreedyMemoryPlannerD1Ev>:
  buffer_offsets_ = reinterpret_cast<int*>(next_free);
}

GreedyMemoryPlanner::~GreedyMemoryPlanner() {
  // We don't own the scratch buffer, so don't deallocate anything.
}
   e479c:	4770      	bx	lr

000e479e <_ZN6tflite19GreedyMemoryPlanner14GetBufferCountEv>:
    line[kLineWidth] = 0;
    error_reporter->Report("%s", line);
  }
}

int GreedyMemoryPlanner::GetBufferCount() { return buffer_count_; }
   e479e:	6880      	ldr	r0, [r0, #8]
   e47a0:	4770      	bx	lr

000e47a2 <_ZN6tflite19GreedyMemoryPlannerD0Ev>:
  next_free += sizeof(ListEntry) * max_buffer_count_;

  buffer_offsets_ = reinterpret_cast<int*>(next_free);
}

GreedyMemoryPlanner::~GreedyMemoryPlanner() {
   e47a2:	b510      	push	{r4, lr}
  // We don't own the scratch buffer, so don't deallocate anything.
}
   e47a4:	2128      	movs	r1, #40	; 0x28
  next_free += sizeof(ListEntry) * max_buffer_count_;

  buffer_offsets_ = reinterpret_cast<int*>(next_free);
}

GreedyMemoryPlanner::~GreedyMemoryPlanner() {
   e47a6:	4604      	mov	r4, r0
  // We don't own the scratch buffer, so don't deallocate anything.
}
   e47a8:	f001 fd03 	bl	e61b2 <_ZdlPvj>
   e47ac:	4620      	mov	r0, r4
   e47ae:	bd10      	pop	{r4, pc}

000e47b0 <_ZN6tflite19GreedyMemoryPlanner9AddBufferEPNS_13ErrorReporterEiii>:

TfLiteStatus GreedyMemoryPlanner::AddBuffer(
    tflite::ErrorReporter* error_reporter, int size, int first_time_used,
    int last_time_used) {
   e47b0:	b570      	push	{r4, r5, r6, lr}
   e47b2:	4616      	mov	r6, r2
  if (buffer_count_ >= max_buffer_count_) {
   e47b4:	6884      	ldr	r4, [r0, #8]
   e47b6:	6842      	ldr	r2, [r0, #4]
   e47b8:	4294      	cmp	r4, r2
  // We don't own the scratch buffer, so don't deallocate anything.
}

TfLiteStatus GreedyMemoryPlanner::AddBuffer(
    tflite::ErrorReporter* error_reporter, int size, int first_time_used,
    int last_time_used) {
   e47ba:	460d      	mov	r5, r1
  if (buffer_count_ >= max_buffer_count_) {
   e47bc:	db05      	blt.n	e47ca <_ZN6tflite19GreedyMemoryPlanner9AddBufferEPNS_13ErrorReporterEiii+0x1a>
    error_reporter->Report("Too many buffers (max is %d)", max_buffer_count_);
   e47be:	490b      	ldr	r1, [pc, #44]	; (e47ec <_ZN6tflite19GreedyMemoryPlanner9AddBufferEPNS_13ErrorReporterEiii+0x3c>)
   e47c0:	4628      	mov	r0, r5
   e47c2:	f7f0 fe93 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
    return kTfLiteError;
   e47c6:	2001      	movs	r0, #1
   e47c8:	bd70      	pop	{r4, r5, r6, pc}
  }
  BufferRequirements* current = &requirements_[buffer_count_];
   e47ca:	68c5      	ldr	r5, [r0, #12]
   e47cc:	210c      	movs	r1, #12
   e47ce:	4361      	muls	r1, r4
   e47d0:	186c      	adds	r4, r5, r1
  current->size = size;
   e47d2:	506e      	str	r6, [r5, r1]
  current->first_time_used = first_time_used;
   e47d4:	6063      	str	r3, [r4, #4]
  current->last_time_used = last_time_used;
   e47d6:	9b04      	ldr	r3, [sp, #16]
   e47d8:	60a3      	str	r3, [r4, #8]
  ++buffer_count_;
   e47da:	6883      	ldr	r3, [r0, #8]
   e47dc:	3301      	adds	r3, #1
   e47de:	6083      	str	r3, [r0, #8]
  need_to_calculate_offsets_ = true;
   e47e0:	2301      	movs	r3, #1
   e47e2:	f880 3024 	strb.w	r3, [r0, #36]	; 0x24
  return kTfLiteOk;
   e47e6:	2000      	movs	r0, #0
}
   e47e8:	bd70      	pop	{r4, r5, r6, pc}
   e47ea:	bf00      	nop
   e47ec:	000ecb7d 	.word	0x000ecb7d

000e47f0 <_ZN6tflite18ReverseSortInPlaceEPiS0_i>:
namespace tflite {

// Simple stable in-place sort function. Not time-efficient for large arrays.
// Would normally be in an anonymous namespace to keep it private, but we want
// to be able to test it externally.
void ReverseSortInPlace(int* values, int* ids, int size) {
   e47f0:	b5f0      	push	{r4, r5, r6, r7, lr}
   e47f2:	4696      	mov	lr, r2
   e47f4:	4604      	mov	r4, r0
   e47f6:	460b      	mov	r3, r1
  bool any_swapped;
  do {
    any_swapped = false;
    for (int i = 1; i < size; ++i) {
   e47f8:	2501      	movs	r5, #1
// Would normally be in an anonymous namespace to keep it private, but we want
// to be able to test it externally.
void ReverseSortInPlace(int* values, int* ids, int size) {
  bool any_swapped;
  do {
    any_swapped = false;
   e47fa:	2600      	movs	r6, #0
    for (int i = 1; i < size; ++i) {
   e47fc:	4575      	cmp	r5, lr
   e47fe:	da0f      	bge.n	e4820 <_ZN6tflite18ReverseSortInPlaceEPiS0_i+0x30>
      if (values[i - 1] < values[i]) {
   e4800:	6827      	ldr	r7, [r4, #0]
   e4802:	f854 2f04 	ldr.w	r2, [r4, #4]!
   e4806:	4297      	cmp	r7, r2
   e4808:	da07      	bge.n	e481a <_ZN6tflite18ReverseSortInPlaceEPiS0_i+0x2a>
        const int value_temp = values[i - 1];
        values[i - 1] = values[i];
   e480a:	f844 2c04 	str.w	r2, [r4, #-4]
        values[i] = value_temp;
   e480e:	6027      	str	r7, [r4, #0]
        const int id_temp = ids[i - 1];
        ids[i - 1] = ids[i];
   e4810:	e893 0044 	ldmia.w	r3, {r2, r6}
   e4814:	601e      	str	r6, [r3, #0]
        ids[i] = id_temp;
   e4816:	605a      	str	r2, [r3, #4]
        any_swapped = true;
   e4818:	2601      	movs	r6, #1
// to be able to test it externally.
void ReverseSortInPlace(int* values, int* ids, int size) {
  bool any_swapped;
  do {
    any_swapped = false;
    for (int i = 1; i < size; ++i) {
   e481a:	3501      	adds	r5, #1
   e481c:	3304      	adds	r3, #4
   e481e:	e7ed      	b.n	e47fc <_ZN6tflite18ReverseSortInPlaceEPiS0_i+0xc>
// Simple stable in-place sort function. Not time-efficient for large arrays.
// Would normally be in an anonymous namespace to keep it private, but we want
// to be able to test it externally.
void ReverseSortInPlace(int* values, int* ids, int size) {
  bool any_swapped;
  do {
   e4820:	2e00      	cmp	r6, #0
   e4822:	d1e7      	bne.n	e47f4 <_ZN6tflite18ReverseSortInPlaceEPiS0_i+0x4>
        ids[i] = id_temp;
        any_swapped = true;
      }
    }
  } while (any_swapped);
}
   e4824:	bdf0      	pop	{r4, r5, r6, r7, pc}
	...

000e4828 <_ZN6tflite19GreedyMemoryPlannerC1EPhi>:

GreedyMemoryPlanner::GreedyMemoryPlanner(unsigned char* scratch_buffer,
                                         int scratch_buffer_size)
    : buffer_count_(0), need_to_calculate_offsets_(true) {
   e4828:	4b0c      	ldr	r3, [pc, #48]	; (e485c <_ZN6tflite19GreedyMemoryPlannerC1EPhi+0x34>)
   e482a:	6003      	str	r3, [r0, #0]
   e482c:	2300      	movs	r3, #0
   e482e:	6083      	str	r3, [r0, #8]
   e4830:	2301      	movs	r3, #1
   e4832:	f880 3024 	strb.w	r3, [r0, #36]	; 0x24
                              sizeof(int) +  // buffer_sizes_sorted_by_size_
                              sizeof(int) +  // buffer_ids_sorted_by_size_
                              sizeof(ListEntry) +  // buffers_sorted_by_offset_
                              sizeof(int);         // buffer_offsets_;
  // Allocate the arrays we need within the scratch buffer arena.
  max_buffer_count_ = scratch_buffer_size / per_buffer_size;
   e4836:	2324      	movs	r3, #36	; 0x24
   e4838:	fb92 f2f3 	sdiv	r2, r2, r3

  unsigned char* next_free = scratch_buffer;
  requirements_ = reinterpret_cast<BufferRequirements*>(next_free);
  next_free += sizeof(BufferRequirements) * max_buffer_count_;
   e483c:	230c      	movs	r3, #12
   e483e:	4353      	muls	r3, r2
      }
    }
  } while (any_swapped);
}

GreedyMemoryPlanner::GreedyMemoryPlanner(unsigned char* scratch_buffer,
   e4840:	b510      	push	{r4, lr}
                              sizeof(int) +  // buffer_sizes_sorted_by_size_
                              sizeof(int) +  // buffer_ids_sorted_by_size_
                              sizeof(ListEntry) +  // buffers_sorted_by_offset_
                              sizeof(int);         // buffer_offsets_;
  // Allocate the arrays we need within the scratch buffer arena.
  max_buffer_count_ = scratch_buffer_size / per_buffer_size;
   e4842:	6042      	str	r2, [r0, #4]

  unsigned char* next_free = scratch_buffer;
  requirements_ = reinterpret_cast<BufferRequirements*>(next_free);
   e4844:	60c1      	str	r1, [r0, #12]
  next_free += sizeof(BufferRequirements) * max_buffer_count_;

  buffer_sizes_sorted_by_size_ = reinterpret_cast<int*>(next_free);
  next_free += sizeof(int) * max_buffer_count_;
   e4846:	0092      	lsls	r2, r2, #2
  // Allocate the arrays we need within the scratch buffer arena.
  max_buffer_count_ = scratch_buffer_size / per_buffer_size;

  unsigned char* next_free = scratch_buffer;
  requirements_ = reinterpret_cast<BufferRequirements*>(next_free);
  next_free += sizeof(BufferRequirements) * max_buffer_count_;
   e4848:	4419      	add	r1, r3

  buffer_sizes_sorted_by_size_ = reinterpret_cast<int*>(next_free);
   e484a:	6101      	str	r1, [r0, #16]
  next_free += sizeof(int) * max_buffer_count_;
   e484c:	4411      	add	r1, r2

  buffer_ids_sorted_by_size_ = reinterpret_cast<int*>(next_free);
  next_free += sizeof(int) * max_buffer_count_;
   e484e:	440a      	add	r2, r1

  buffers_sorted_by_offset_ = reinterpret_cast<ListEntry*>(next_free);
   e4850:	6182      	str	r2, [r0, #24]
  next_free += sizeof(ListEntry) * max_buffer_count_;

  buffer_offsets_ = reinterpret_cast<int*>(next_free);
   e4852:	441a      	add	r2, r3
  next_free += sizeof(BufferRequirements) * max_buffer_count_;

  buffer_sizes_sorted_by_size_ = reinterpret_cast<int*>(next_free);
  next_free += sizeof(int) * max_buffer_count_;

  buffer_ids_sorted_by_size_ = reinterpret_cast<int*>(next_free);
   e4854:	6141      	str	r1, [r0, #20]
  next_free += sizeof(int) * max_buffer_count_;

  buffers_sorted_by_offset_ = reinterpret_cast<ListEntry*>(next_free);
  next_free += sizeof(ListEntry) * max_buffer_count_;

  buffer_offsets_ = reinterpret_cast<int*>(next_free);
   e4856:	6202      	str	r2, [r0, #32]
}
   e4858:	bd10      	pop	{r4, pc}
   e485a:	bf00      	nop
   e485c:	000ecc00 	.word	0x000ecc00

000e4860 <_ZNK6tflite19GreedyMemoryPlanner22DoesEntryOverlapInTimeEPKNS0_9ListEntryEii>:
  return kTfLiteOk;
}

bool GreedyMemoryPlanner::DoesEntryOverlapInTime(
    const GreedyMemoryPlanner::ListEntry* entry, const int first_time_used,
    const int last_time_used) const {
   e4860:	b510      	push	{r4, lr}
  const BufferRequirements* entry_requirements =
      &requirements_[entry->requirements_index];
   e4862:	684c      	ldr	r4, [r1, #4]
   e4864:	68c1      	ldr	r1, [r0, #12]
   e4866:	200c      	movs	r0, #12
   e4868:	fb00 1104 	mla	r1, r0, r4, r1
  if (entry_requirements->first_time_used > last_time_used) {
   e486c:	6848      	ldr	r0, [r1, #4]
   e486e:	4298      	cmp	r0, r3
   e4870:	dc05      	bgt.n	e487e <_ZNK6tflite19GreedyMemoryPlanner22DoesEntryOverlapInTimeEPKNS0_9ListEntryEii+0x1e>
    return false;
  }
  if (first_time_used > entry_requirements->last_time_used) {
   e4872:	6888      	ldr	r0, [r1, #8]
   e4874:	4290      	cmp	r0, r2
   e4876:	bfb4      	ite	lt
   e4878:	2000      	movlt	r0, #0
   e487a:	2001      	movge	r0, #1
   e487c:	bd10      	pop	{r4, pc}
    const GreedyMemoryPlanner::ListEntry* entry, const int first_time_used,
    const int last_time_used) const {
  const BufferRequirements* entry_requirements =
      &requirements_[entry->requirements_index];
  if (entry_requirements->first_time_used > last_time_used) {
    return false;
   e487e:	2000      	movs	r0, #0
  }
  if (first_time_used > entry_requirements->last_time_used) {
    return false;
  }
  return true;
}
   e4880:	bd10      	pop	{r4, pc}

000e4882 <_ZN6tflite19GreedyMemoryPlanner30NextSimultaneouslyActiveBufferEPKNS0_9ListEntryEii>:

GreedyMemoryPlanner::ListEntry*
GreedyMemoryPlanner::NextSimultaneouslyActiveBuffer(
    const GreedyMemoryPlanner::ListEntry* start, const int first_time_used,
    const int last_time_used) {
   e4882:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   e4886:	4605      	mov	r5, r0
   e4888:	4616      	mov	r6, r2
   e488a:	461f      	mov	r7, r3
  ListEntry* result = nullptr;
  ListEntry* candidate_next_entry;
  if (start == nullptr) {
   e488c:	b919      	cbnz	r1, e4896 <_ZN6tflite19GreedyMemoryPlanner30NextSimultaneouslyActiveBufferEPKNS0_9ListEntryEii+0x14>
    candidate_next_entry = &buffers_sorted_by_offset_[0];
   e488e:	6984      	ldr	r4, [r0, #24]
    }
    if (candidate_next_entry->next_entry_index == -1) {
      break;
    }
    candidate_next_entry =
        &buffers_sorted_by_offset_[candidate_next_entry->next_entry_index];
   e4890:	f04f 080c 	mov.w	r8, #12
   e4894:	e00d      	b.n	e48b2 <_ZN6tflite19GreedyMemoryPlanner30NextSimultaneouslyActiveBufferEPKNS0_9ListEntryEii+0x30>
  ListEntry* result = nullptr;
  ListEntry* candidate_next_entry;
  if (start == nullptr) {
    candidate_next_entry = &buffers_sorted_by_offset_[0];
  } else {
    if (start->next_entry_index == -1) {
   e4896:	688b      	ldr	r3, [r1, #8]
   e4898:	1c59      	adds	r1, r3, #1
   e489a:	d013      	beq.n	e48c4 <_ZN6tflite19GreedyMemoryPlanner30NextSimultaneouslyActiveBufferEPKNS0_9ListEntryEii+0x42>
      return nullptr;
    }
    candidate_next_entry = &buffers_sorted_by_offset_[start->next_entry_index];
   e489c:	6982      	ldr	r2, [r0, #24]
   e489e:	240c      	movs	r4, #12
   e48a0:	fb04 2403 	mla	r4, r4, r3, r2
   e48a4:	e7f4      	b.n	e4890 <_ZN6tflite19GreedyMemoryPlanner30NextSimultaneouslyActiveBufferEPKNS0_9ListEntryEii+0xe>
    if (DoesEntryOverlapInTime(candidate_next_entry, first_time_used,
                               last_time_used)) {
      result = candidate_next_entry;
      break;
    }
    if (candidate_next_entry->next_entry_index == -1) {
   e48a6:	68a3      	ldr	r3, [r4, #8]
   e48a8:	1c5a      	adds	r2, r3, #1
   e48aa:	d00f      	beq.n	e48cc <_ZN6tflite19GreedyMemoryPlanner30NextSimultaneouslyActiveBufferEPKNS0_9ListEntryEii+0x4a>
      break;
    }
    candidate_next_entry =
        &buffers_sorted_by_offset_[candidate_next_entry->next_entry_index];
   e48ac:	69ac      	ldr	r4, [r5, #24]
   e48ae:	fb08 4403 	mla	r4, r8, r3, r4
      return nullptr;
    }
    candidate_next_entry = &buffers_sorted_by_offset_[start->next_entry_index];
  }
  do {
    if (DoesEntryOverlapInTime(candidate_next_entry, first_time_used,
   e48b2:	463b      	mov	r3, r7
   e48b4:	4632      	mov	r2, r6
   e48b6:	4621      	mov	r1, r4
   e48b8:	4628      	mov	r0, r5
   e48ba:	f7ff ffd1 	bl	e4860 <_ZNK6tflite19GreedyMemoryPlanner22DoesEntryOverlapInTimeEPKNS0_9ListEntryEii>
   e48be:	2800      	cmp	r0, #0
   e48c0:	d0f1      	beq.n	e48a6 <_ZN6tflite19GreedyMemoryPlanner30NextSimultaneouslyActiveBufferEPKNS0_9ListEntryEii+0x24>
   e48c2:	e002      	b.n	e48ca <_ZN6tflite19GreedyMemoryPlanner30NextSimultaneouslyActiveBufferEPKNS0_9ListEntryEii+0x48>
  ListEntry* candidate_next_entry;
  if (start == nullptr) {
    candidate_next_entry = &buffers_sorted_by_offset_[0];
  } else {
    if (start->next_entry_index == -1) {
      return nullptr;
   e48c4:	2000      	movs	r0, #0
   e48c6:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   e48ca:	4620      	mov	r0, r4
    }
    candidate_next_entry =
        &buffers_sorted_by_offset_[candidate_next_entry->next_entry_index];
  } while (true);
  return result;
}
   e48cc:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

000e48d0 <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv>:

void GreedyMemoryPlanner::CalculateOffsetsIfNeeded() {
   e48d0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  if (!need_to_calculate_offsets_ || (buffer_count_ == 0)) {
   e48d4:	f890 3024 	ldrb.w	r3, [r0, #36]	; 0x24
        &buffers_sorted_by_offset_[candidate_next_entry->next_entry_index];
  } while (true);
  return result;
}

void GreedyMemoryPlanner::CalculateOffsetsIfNeeded() {
   e48d8:	b085      	sub	sp, #20
   e48da:	4604      	mov	r4, r0
  if (!need_to_calculate_offsets_ || (buffer_count_ == 0)) {
   e48dc:	2b00      	cmp	r3, #0
   e48de:	f000 8089 	beq.w	e49f4 <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0x124>
   e48e2:	6883      	ldr	r3, [r0, #8]
   e48e4:	2b00      	cmp	r3, #0
   e48e6:	f000 8085 	beq.w	e49f4 <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0x124>
    return;
  }
  need_to_calculate_offsets_ = false;
   e48ea:	2300      	movs	r3, #0
   e48ec:	f880 3024 	strb.w	r3, [r0, #36]	; 0x24
  // This helps find a more compact layout. Intuitively, you can think
  // about putting the large buffers in place first, and then the
  // smaller buffers can fit in the gaps, rather than fragmenting the
  // gaps with small buffers at the beginning.
  for (int i = 0; i < buffer_count_; ++i) {
    buffer_sizes_sorted_by_size_[i] = requirements_[i].size;
   e48f0:	250c      	movs	r5, #12
    buffer_ids_sorted_by_size_[i] = i;
    buffer_offsets_[i] = -1;
   e48f2:	f04f 31ff 	mov.w	r1, #4294967295	; 0xffffffff
  // Start off by ordering the buffers in descending order of size.
  // This helps find a more compact layout. Intuitively, you can think
  // about putting the large buffers in place first, and then the
  // smaller buffers can fit in the gaps, rather than fragmenting the
  // gaps with small buffers at the beginning.
  for (int i = 0; i < buffer_count_; ++i) {
   e48f6:	68a2      	ldr	r2, [r4, #8]
   e48f8:	429a      	cmp	r2, r3
   e48fa:	dd0e      	ble.n	e491a <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0x4a>
    buffer_sizes_sorted_by_size_[i] = requirements_[i].size;
   e48fc:	68e0      	ldr	r0, [r4, #12]
   e48fe:	fb05 f203 	mul.w	r2, r5, r3
   e4902:	5880      	ldr	r0, [r0, r2]
   e4904:	6922      	ldr	r2, [r4, #16]
   e4906:	f842 0023 	str.w	r0, [r2, r3, lsl #2]
    buffer_ids_sorted_by_size_[i] = i;
   e490a:	6962      	ldr	r2, [r4, #20]
   e490c:	f842 3023 	str.w	r3, [r2, r3, lsl #2]
    buffer_offsets_[i] = -1;
   e4910:	6a22      	ldr	r2, [r4, #32]
   e4912:	f842 1023 	str.w	r1, [r2, r3, lsl #2]
  // Start off by ordering the buffers in descending order of size.
  // This helps find a more compact layout. Intuitively, you can think
  // about putting the large buffers in place first, and then the
  // smaller buffers can fit in the gaps, rather than fragmenting the
  // gaps with small buffers at the beginning.
  for (int i = 0; i < buffer_count_; ++i) {
   e4916:	3301      	adds	r3, #1
   e4918:	e7ed      	b.n	e48f6 <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0x26>
    buffer_offsets_[i] = -1;
  }
  // This sorting algorithm is naive, and may end up taking a very long time
  // with hundreds of buffers.
  ReverseSortInPlace(buffer_sizes_sorted_by_size_, buffer_ids_sorted_by_size_,
                     buffer_count_);
   e491a:	6961      	ldr	r1, [r4, #20]
   e491c:	6920      	ldr	r0, [r4, #16]
   e491e:	f7ff ff67 	bl	e47f0 <_ZN6tflite18ReverseSortInPlaceEPiS0_i>

  // Put the largest buffer at offset zero to start the process.
  ListEntry* first_entry = &buffers_sorted_by_offset_[0];
   e4922:	f8d4 8018 	ldr.w	r8, [r4, #24]
  first_entry->offset = 0;
   e4926:	2300      	movs	r3, #0
   e4928:	f8c8 3000 	str.w	r3, [r8]
  first_entry->requirements_index = buffer_ids_sorted_by_size_[0];
   e492c:	6962      	ldr	r2, [r4, #20]
   e492e:	6812      	ldr	r2, [r2, #0]
   e4930:	f8c8 2004 	str.w	r2, [r8, #4]
  first_entry->next_entry_index = -1;
   e4934:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
   e4938:	f8c8 2008 	str.w	r2, [r8, #8]
  next_free_entry_ = 1;
  buffer_offsets_[buffer_ids_sorted_by_size_[0]] = 0;
   e493c:	6962      	ldr	r2, [r4, #20]
  // Put the largest buffer at offset zero to start the process.
  ListEntry* first_entry = &buffers_sorted_by_offset_[0];
  first_entry->offset = 0;
  first_entry->requirements_index = buffer_ids_sorted_by_size_[0];
  first_entry->next_entry_index = -1;
  next_free_entry_ = 1;
   e493e:	2501      	movs	r5, #1
   e4940:	61e5      	str	r5, [r4, #28]
  buffer_offsets_[buffer_ids_sorted_by_size_[0]] = 0;
   e4942:	6811      	ldr	r1, [r2, #0]
   e4944:	6a22      	ldr	r2, [r4, #32]
   e4946:	f842 3021 	str.w	r3, [r2, r1, lsl #2]
  // Work through the rest of the buffers to find a good gap to place each one.
  for (int i = 1; i < buffer_count_; ++i) {
    // The id is the order the buffer was originally added by the client.
    const int buffer_id = buffer_ids_sorted_by_size_[i];
    // Look at what size and time range the buffer needs to be active.
    BufferRequirements* wanted_requirements = &requirements_[buffer_id];
   e494a:	f04f 090c 	mov.w	r9, #12
  first_entry->next_entry_index = -1;
  next_free_entry_ = 1;
  buffer_offsets_[buffer_ids_sorted_by_size_[0]] = 0;

  // Work through the rest of the buffers to find a good gap to place each one.
  for (int i = 1; i < buffer_count_; ++i) {
   e494e:	68a3      	ldr	r3, [r4, #8]
   e4950:	42ab      	cmp	r3, r5
   e4952:	dd4f      	ble.n	e49f4 <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0x124>
    // The id is the order the buffer was originally added by the client.
    const int buffer_id = buffer_ids_sorted_by_size_[i];
   e4954:	6963      	ldr	r3, [r4, #20]
    // Look at what size and time range the buffer needs to be active.
    BufferRequirements* wanted_requirements = &requirements_[buffer_id];
   e4956:	f8d4 b00c 	ldr.w	fp, [r4, #12]
  buffer_offsets_[buffer_ids_sorted_by_size_[0]] = 0;

  // Work through the rest of the buffers to find a good gap to place each one.
  for (int i = 1; i < buffer_count_; ++i) {
    // The id is the order the buffer was originally added by the client.
    const int buffer_id = buffer_ids_sorted_by_size_[i];
   e495a:	f853 a025 	ldr.w	sl, [r3, r5, lsl #2]
    // Look at what size and time range the buffer needs to be active.
    BufferRequirements* wanted_requirements = &requirements_[buffer_id];
   e495e:	fb09 f20a 	mul.w	r2, r9, sl
   e4962:	eb0b 0302 	add.w	r3, fp, r2
    const int wanted_size = wanted_requirements->size;
   e4966:	f85b 2002 	ldr.w	r2, [fp, r2]
   e496a:	9201      	str	r2, [sp, #4]
    // buffers are stored in the order of their starting position in the arena
    // so that it's easy to find the next buffer in memory, and so the gap.
    // The candidate_entry variable holds the buffer that we're considering
    // placing the current buffer after.
    ListEntry* prior_entry = nullptr;
    int candidate_offset = 0;
   e496c:	2600      	movs	r6, #0
    // The id is the order the buffer was originally added by the client.
    const int buffer_id = buffer_ids_sorted_by_size_[i];
    // Look at what size and time range the buffer needs to be active.
    BufferRequirements* wanted_requirements = &requirements_[buffer_id];
    const int wanted_size = wanted_requirements->size;
    const int wanted_first_time_used = wanted_requirements->first_time_used;
   e496e:	685a      	ldr	r2, [r3, #4]
    const int wanted_last_time_used = wanted_requirements->last_time_used;
   e4970:	689b      	ldr	r3, [r3, #8]
    // The id is the order the buffer was originally added by the client.
    const int buffer_id = buffer_ids_sorted_by_size_[i];
    // Look at what size and time range the buffer needs to be active.
    BufferRequirements* wanted_requirements = &requirements_[buffer_id];
    const int wanted_size = wanted_requirements->size;
    const int wanted_first_time_used = wanted_requirements->first_time_used;
   e4972:	9202      	str	r2, [sp, #8]
    const int wanted_last_time_used = wanted_requirements->last_time_used;
   e4974:	9303      	str	r3, [sp, #12]
    // Find the first buffer that's active in our time range. All placed
    // buffers are stored in the order of their starting position in the arena
    // so that it's easy to find the next buffer in memory, and so the gap.
    // The candidate_entry variable holds the buffer that we're considering
    // placing the current buffer after.
    ListEntry* prior_entry = nullptr;
   e4976:	4637      	mov	r7, r6
    int candidate_offset = 0;
    // Loop through the offset-ordered list of buffers, looking for gaps.
    while (true) {
      // Find out what the next active buffer is.
      ListEntry* next_entry = NextSimultaneouslyActiveBuffer(
          prior_entry, wanted_first_time_used, wanted_last_time_used);
   e4978:	9b03      	ldr	r3, [sp, #12]
   e497a:	9a02      	ldr	r2, [sp, #8]
   e497c:	4639      	mov	r1, r7
   e497e:	4620      	mov	r0, r4
   e4980:	f7ff ff7f 	bl	e4882 <_ZN6tflite19GreedyMemoryPlanner30NextSimultaneouslyActiveBufferEPKNS0_9ListEntryEii>

      if (prior_entry) {
   e4984:	b14f      	cbz	r7, e499a <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0xca>
        BufferRequirements* candidate_requirements =
            &requirements_[prior_entry->requirements_index];
        const int prior_entry_offset =
            prior_entry->offset + candidate_requirements->size;
   e4986:	687b      	ldr	r3, [r7, #4]
   e4988:	fb09 f303 	mul.w	r3, r9, r3
   e498c:	f85b 2003 	ldr.w	r2, [fp, r3]
   e4990:	683b      	ldr	r3, [r7, #0]
   e4992:	4413      	add	r3, r2
   e4994:	429e      	cmp	r6, r3
   e4996:	bfb8      	it	lt
   e4998:	461e      	movlt	r6, r3
        if (prior_entry_offset > candidate_offset) {
          candidate_offset = prior_entry_offset;
        }
      }
      if (next_entry == nullptr) {
   e499a:	b978      	cbnz	r0, e49bc <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0xec>
    }
    // At this point, we've either found a gap (possibly at the end of the
    // list) and want to place the buffer there, or there are no other active
    // buffers in this time range and so we can put it at offset zero.
    // Record the buffer's offset in our plan.
    buffer_offsets_[buffer_id] = candidate_offset;
   e499c:	6a23      	ldr	r3, [r4, #32]
   e499e:	f843 602a 	str.w	r6, [r3, sl, lsl #2]
    // Add the newly-placed buffer to our offset-ordered list, so that
    // subsequent passes can fit in their buffers around it.
    ListEntry* new_entry = &buffers_sorted_by_offset_[next_free_entry_];
   e49a2:	69e3      	ldr	r3, [r4, #28]
   e49a4:	69a2      	ldr	r2, [r4, #24]
   e49a6:	fb09 f303 	mul.w	r3, r9, r3
   e49aa:	18d7      	adds	r7, r2, r3
    new_entry->offset = candidate_offset;
   e49ac:	50d6      	str	r6, [r2, r3]
    new_entry->requirements_index = buffer_id;
   e49ae:	f8c7 a004 	str.w	sl, [r7, #4]
    const int new_entry_index = next_free_entry_;
   e49b2:	69e0      	ldr	r0, [r4, #28]
    ++next_free_entry_;
   e49b4:	1c43      	adds	r3, r0, #1
   e49b6:	61e3      	str	r3, [r4, #28]
   e49b8:	4643      	mov	r3, r8
   e49ba:	e011      	b.n	e49e0 <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0x110>
        // here.
        break;
      }
      // Find out how much space there is between us and the next buffer.
      const int gap = next_entry->offset - candidate_offset;
      if (gap >= wanted_size) {
   e49bc:	6803      	ldr	r3, [r0, #0]
   e49be:	9a01      	ldr	r2, [sp, #4]
   e49c0:	1b9b      	subs	r3, r3, r6
   e49c2:	429a      	cmp	r2, r3
   e49c4:	4607      	mov	r7, r0
   e49c6:	dcd7      	bgt.n	e4978 <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0xa8>
   e49c8:	e7e8      	b.n	e499c <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0xcc>
        // We're at the end of the list, so just add the new entry here.
        current_entry->next_entry_index = new_entry_index;
        new_entry->next_entry_index = -1;
        break;
      }
      ListEntry* next_entry = &buffers_sorted_by_offset_[next_entry_index];
   e49ca:	fb09 f102 	mul.w	r1, r9, r2
   e49ce:	f8d4 e018 	ldr.w	lr, [r4, #24]
   e49d2:	eb0e 0c01 	add.w	ip, lr, r1
      if (next_entry->offset > candidate_offset) {
   e49d6:	f85e 1001 	ldr.w	r1, [lr, r1]
   e49da:	428e      	cmp	r6, r1
   e49dc:	db06      	blt.n	e49ec <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0x11c>
   e49de:	4663      	mov	r3, ip
    ++next_free_entry_;
    ListEntry* current_entry = first_entry;
    // Make sure that we insert the buffer at the correct place in the ordered
    // list.
    while (true) {
      const int next_entry_index = current_entry->next_entry_index;
   e49e0:	689a      	ldr	r2, [r3, #8]
      if (next_entry_index == -1) {
   e49e2:	1c51      	adds	r1, r2, #1
   e49e4:	d1f1      	bne.n	e49ca <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0xfa>
        // We're at the end of the list, so just add the new entry here.
        current_entry->next_entry_index = new_entry_index;
   e49e6:	6098      	str	r0, [r3, #8]
        new_entry->next_entry_index = -1;
   e49e8:	60ba      	str	r2, [r7, #8]
   e49ea:	e001      	b.n	e49f0 <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0x120>
      }
      ListEntry* next_entry = &buffers_sorted_by_offset_[next_entry_index];
      if (next_entry->offset > candidate_offset) {
        // We're at the right spot to do an insertion and retain the sorting
        // order, so place the new entry here.
        new_entry->next_entry_index = current_entry->next_entry_index;
   e49ec:	60ba      	str	r2, [r7, #8]
        current_entry->next_entry_index = new_entry_index;
   e49ee:	6098      	str	r0, [r3, #8]
  first_entry->next_entry_index = -1;
  next_free_entry_ = 1;
  buffer_offsets_[buffer_ids_sorted_by_size_[0]] = 0;

  // Work through the rest of the buffers to find a good gap to place each one.
  for (int i = 1; i < buffer_count_; ++i) {
   e49f0:	3501      	adds	r5, #1
   e49f2:	e7ac      	b.n	e494e <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv+0x7e>
        break;
      }
      current_entry = next_entry;
    }
  }
}
   e49f4:	b005      	add	sp, #20
   e49f6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000e49fa <_ZN6tflite19GreedyMemoryPlanner20GetMaximumMemorySizeEv>:

int GreedyMemoryPlanner::GetMaximumMemorySize() {
   e49fa:	b570      	push	{r4, r5, r6, lr}
   e49fc:	4604      	mov	r4, r0
  CalculateOffsetsIfNeeded();
   e49fe:	f7ff ff67 	bl	e48d0 <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv>
  if (buffer_count_ == 0) {
   e4a02:	68a0      	ldr	r0, [r4, #8]
   e4a04:	b198      	cbz	r0, e4a2e <_ZN6tflite19GreedyMemoryPlanner20GetMaximumMemorySizeEv+0x34>
    return 0;
  }
  ListEntry* entry = &buffers_sorted_by_offset_[0];
   e4a06:	69a1      	ldr	r1, [r4, #24]
  int max_size = 0;
   e4a08:	2000      	movs	r0, #0
int GreedyMemoryPlanner::GetMaximumMemorySize() {
  CalculateOffsetsIfNeeded();
  if (buffer_count_ == 0) {
    return 0;
  }
  ListEntry* entry = &buffers_sorted_by_offset_[0];
   e4a0a:	460b      	mov	r3, r1
  int max_size = 0;
  while (entry) {
    BufferRequirements* requirements =
        &requirements_[entry->requirements_index];
    const int current_size = entry->offset + requirements->size;
   e4a0c:	250c      	movs	r5, #12
  if (buffer_count_ == 0) {
    return 0;
  }
  ListEntry* entry = &buffers_sorted_by_offset_[0];
  int max_size = 0;
  while (entry) {
   e4a0e:	b173      	cbz	r3, e4a2e <_ZN6tflite19GreedyMemoryPlanner20GetMaximumMemorySizeEv+0x34>
    BufferRequirements* requirements =
        &requirements_[entry->requirements_index];
    const int current_size = entry->offset + requirements->size;
   e4a10:	685a      	ldr	r2, [r3, #4]
   e4a12:	68e6      	ldr	r6, [r4, #12]
   e4a14:	436a      	muls	r2, r5
   e4a16:	58b6      	ldr	r6, [r6, r2]
   e4a18:	681a      	ldr	r2, [r3, #0]
    if (current_size > max_size) {
      max_size = current_size;
    }
    if (entry->next_entry_index == -1) {
   e4a1a:	689b      	ldr	r3, [r3, #8]
  ListEntry* entry = &buffers_sorted_by_offset_[0];
  int max_size = 0;
  while (entry) {
    BufferRequirements* requirements =
        &requirements_[entry->requirements_index];
    const int current_size = entry->offset + requirements->size;
   e4a1c:	4432      	add	r2, r6
   e4a1e:	4290      	cmp	r0, r2
   e4a20:	bfb8      	it	lt
   e4a22:	4610      	movlt	r0, r2
    if (current_size > max_size) {
      max_size = current_size;
    }
    if (entry->next_entry_index == -1) {
   e4a24:	1c5a      	adds	r2, r3, #1
   e4a26:	d002      	beq.n	e4a2e <_ZN6tflite19GreedyMemoryPlanner20GetMaximumMemorySizeEv+0x34>
      break;
    }
    entry = &buffers_sorted_by_offset_[entry->next_entry_index];
   e4a28:	fb05 1303 	mla	r3, r5, r3, r1
   e4a2c:	e7ef      	b.n	e4a0e <_ZN6tflite19GreedyMemoryPlanner20GetMaximumMemorySizeEv+0x14>
  }
  return max_size;
}
   e4a2e:	bd70      	pop	{r4, r5, r6, pc}

000e4a30 <_ZN6tflite19GreedyMemoryPlanner18GetOffsetForBufferEPNS_13ErrorReporterEiPi>:
}

int GreedyMemoryPlanner::GetBufferCount() { return buffer_count_; }

TfLiteStatus GreedyMemoryPlanner::GetOffsetForBuffer(
    tflite::ErrorReporter* error_reporter, int buffer_index, int* offset) {
   e4a30:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
   e4a32:	4614      	mov	r4, r2
   e4a34:	4605      	mov	r5, r0
   e4a36:	460f      	mov	r7, r1
   e4a38:	461e      	mov	r6, r3
  CalculateOffsetsIfNeeded();
   e4a3a:	f7ff ff49 	bl	e48d0 <_ZN6tflite19GreedyMemoryPlanner24CalculateOffsetsIfNeededEv>
  if ((buffer_index < 0) || (buffer_index >= buffer_count_)) {
   e4a3e:	2c00      	cmp	r4, #0
   e4a40:	db02      	blt.n	e4a48 <_ZN6tflite19GreedyMemoryPlanner18GetOffsetForBufferEPNS_13ErrorReporterEiPi+0x18>
   e4a42:	68ab      	ldr	r3, [r5, #8]
   e4a44:	429c      	cmp	r4, r3
   e4a46:	db07      	blt.n	e4a58 <_ZN6tflite19GreedyMemoryPlanner18GetOffsetForBufferEPNS_13ErrorReporterEiPi+0x28>
    error_reporter->Report("buffer index %d is outside range 0 to %d",
                           buffer_index, buffer_count_);
   e4a48:	68ab      	ldr	r3, [r5, #8]
   e4a4a:	4906      	ldr	r1, [pc, #24]	; (e4a64 <_ZN6tflite19GreedyMemoryPlanner18GetOffsetForBufferEPNS_13ErrorReporterEiPi+0x34>)
   e4a4c:	4622      	mov	r2, r4
   e4a4e:	4638      	mov	r0, r7
   e4a50:	f7f0 fd4c 	bl	d54ec <_ZN6tflite13ErrorReporter6ReportEPKcz>
   e4a54:	2001      	movs	r0, #1
   e4a56:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    return kTfLiteError;
  }
  *offset = buffer_offsets_[buffer_index];
   e4a58:	6a2b      	ldr	r3, [r5, #32]
   e4a5a:	f853 3024 	ldr.w	r3, [r3, r4, lsl #2]
   e4a5e:	6033      	str	r3, [r6, #0]
  return kTfLiteOk;
   e4a60:	2000      	movs	r0, #0
}
   e4a62:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
   e4a64:	000ecb9a 	.word	0x000ecb9a

000e4a68 <_ZZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_ENKUlfE_clEf>:
                                           TfLiteTensor* output,
                                           int32_t* act_min, int32_t* act_max) {
  const auto scale = output->params.scale;
  const auto zero_point = output->params.zero_point;

  auto quantize = [scale, zero_point](float f) {
   e4a68:	b510      	push	{r4, lr}
    { return __builtin_rint(__x); }

#ifndef __CORRECT_ISO_CPP11_MATH_H_PROTO
  constexpr float
  round(float __x)
  { return __builtin_roundf(__x); }
   e4a6a:	edd0 7a00 	vldr	s15, [r0]
   e4a6e:	ee80 0a27 	vdiv.f32	s0, s0, s15
   e4a72:	4604      	mov	r4, r0
   e4a74:	f001 ff34 	bl	e68e0 <roundf>
    return zero_point + static_cast<int32_t>(TfLiteRound(f / scale));
  };
   e4a78:	6863      	ldr	r3, [r4, #4]
   e4a7a:	eefd 7ac0 	vcvt.s32.f32	s15, s0
   e4a7e:	ee17 0a90 	vmov	r0, s15
   e4a82:	4418      	add	r0, r3
   e4a84:	bd10      	pop	{r4, pc}
	...

000e4a88 <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_>:

namespace {
void CalculateActivationRangeQuantizedImpl(TfLiteFusedActivation activation,
                                           int32_t qmin, int32_t qmax,
                                           TfLiteTensor* output,
                                           int32_t* act_min, int32_t* act_max) {
   e4a88:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}

  auto quantize = [scale, zero_point](float f) {
    return zero_point + static_cast<int32_t>(TfLiteRound(f / scale));
  };

  if (activation == kTfLiteActRelu) {
   e4a8a:	2801      	cmp	r0, #1

namespace {
void CalculateActivationRangeQuantizedImpl(TfLiteFusedActivation activation,
                                           int32_t qmin, int32_t qmax,
                                           TfLiteTensor* output,
                                           int32_t* act_min, int32_t* act_max) {
   e4a8c:	4615      	mov	r5, r2
  const auto scale = output->params.scale;
  const auto zero_point = output->params.zero_point;
   e4a8e:	691a      	ldr	r2, [r3, #16]

  auto quantize = [scale, zero_point](float f) {
    return zero_point + static_cast<int32_t>(TfLiteRound(f / scale));
  };
   e4a90:	68db      	ldr	r3, [r3, #12]

namespace {
void CalculateActivationRangeQuantizedImpl(TfLiteFusedActivation activation,
                                           int32_t qmin, int32_t qmax,
                                           TfLiteTensor* output,
                                           int32_t* act_min, int32_t* act_max) {
   e4a92:	9e08      	ldr	r6, [sp, #32]
   e4a94:	9c09      	ldr	r4, [sp, #36]	; 0x24
  const auto scale = output->params.scale;
  const auto zero_point = output->params.zero_point;

  auto quantize = [scale, zero_point](float f) {
    return zero_point + static_cast<int32_t>(TfLiteRound(f / scale));
  };
   e4a96:	9300      	str	r3, [sp, #0]

namespace {
void CalculateActivationRangeQuantizedImpl(TfLiteFusedActivation activation,
                                           int32_t qmin, int32_t qmax,
                                           TfLiteTensor* output,
                                           int32_t* act_min, int32_t* act_max) {
   e4a98:	460f      	mov	r7, r1
  const auto scale = output->params.scale;
  const auto zero_point = output->params.zero_point;

  auto quantize = [scale, zero_point](float f) {
    return zero_point + static_cast<int32_t>(TfLiteRound(f / scale));
  };
   e4a9a:	9201      	str	r2, [sp, #4]

  if (activation == kTfLiteActRelu) {
   e4a9c:	d109      	bne.n	e4ab2 <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_+0x2a>
    *act_min = std::max(qmin, quantize(0.0));
   e4a9e:	ed9f 0a18 	vldr	s0, [pc, #96]	; e4b00 <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_+0x78>
   e4aa2:	4668      	mov	r0, sp
   e4aa4:	f7ff ffe0 	bl	e4a68 <_ZZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_ENKUlfE_clEf>
   e4aa8:	42b8      	cmp	r0, r7
   e4aaa:	bfac      	ite	ge
   e4aac:	6030      	strge	r0, [r6, #0]
   e4aae:	6037      	strlt	r7, [r6, #0]
   e4ab0:	e023      	b.n	e4afa <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_+0x72>
    *act_max = qmax;
  } else if (activation == kTfLiteActRelu6) {
   e4ab2:	2803      	cmp	r0, #3
   e4ab4:	d10b      	bne.n	e4ace <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_+0x46>
    *act_min = std::max(qmin, quantize(0.0));
   e4ab6:	ed9f 0a12 	vldr	s0, [pc, #72]	; e4b00 <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_+0x78>
   e4aba:	4668      	mov	r0, sp
   e4abc:	f7ff ffd4 	bl	e4a68 <_ZZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_ENKUlfE_clEf>
    *act_max = std::min(qmax, quantize(6.0));
   e4ac0:	eeb1 0a08 	vmov.f32	s0, #24	; 0x40c00000  6.0

  if (activation == kTfLiteActRelu) {
    *act_min = std::max(qmin, quantize(0.0));
    *act_max = qmax;
  } else if (activation == kTfLiteActRelu6) {
    *act_min = std::max(qmin, quantize(0.0));
   e4ac4:	42b8      	cmp	r0, r7
   e4ac6:	bfac      	ite	ge
   e4ac8:	6030      	strge	r0, [r6, #0]
   e4aca:	6037      	strlt	r7, [r6, #0]
   e4acc:	e00c      	b.n	e4ae8 <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_+0x60>
    *act_max = std::min(qmax, quantize(6.0));
  } else if (activation == kTfLiteActRelu1) {
   e4ace:	2802      	cmp	r0, #2
   e4ad0:	d112      	bne.n	e4af8 <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_+0x70>
    *act_min = std::max(qmin, quantize(-1.0));
   e4ad2:	eebf 0a00 	vmov.f32	s0, #240	; 0xbf800000 -1.0
   e4ad6:	4668      	mov	r0, sp
   e4ad8:	f7ff ffc6 	bl	e4a68 <_ZZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_ENKUlfE_clEf>
    *act_max = std::min(qmax, quantize(1.0));
   e4adc:	eeb7 0a00 	vmov.f32	s0, #112	; 0x3f800000  1.0
    *act_max = qmax;
  } else if (activation == kTfLiteActRelu6) {
    *act_min = std::max(qmin, quantize(0.0));
    *act_max = std::min(qmax, quantize(6.0));
  } else if (activation == kTfLiteActRelu1) {
    *act_min = std::max(qmin, quantize(-1.0));
   e4ae0:	42b8      	cmp	r0, r7
   e4ae2:	bfac      	ite	ge
   e4ae4:	6030      	strge	r0, [r6, #0]
   e4ae6:	6037      	strlt	r7, [r6, #0]
    *act_max = std::min(qmax, quantize(1.0));
   e4ae8:	4668      	mov	r0, sp
   e4aea:	f7ff ffbd 	bl	e4a68 <_ZZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_ENKUlfE_clEf>
   e4aee:	4285      	cmp	r5, r0
   e4af0:	bfd4      	ite	le
   e4af2:	6025      	strle	r5, [r4, #0]
   e4af4:	6020      	strgt	r0, [r4, #0]
   e4af6:	e001      	b.n	e4afc <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_+0x74>
  } else {
    *act_min = qmin;
   e4af8:	6031      	str	r1, [r6, #0]
    *act_max = qmax;
   e4afa:	6025      	str	r5, [r4, #0]
  }
}
   e4afc:	b003      	add	sp, #12
   e4afe:	bdf0      	pop	{r4, r5, r6, r7, pc}
   e4b00:	00000000 	.word	0x00000000

000e4b04 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_PS2_Pd>:

TfLiteStatus GetQuantizedConvolutionMultipler(TfLiteContext* context,
                                              const TfLiteTensor* input,
                                              const TfLiteTensor* filter,
                                              TfLiteTensor* output,
                                              double* multiplier) {
   e4b04:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
  const double input_product_scale = input->params.scale * filter->params.scale;
   e4b06:	edd2 7a03 	vldr	s15, [r2, #12]
   e4b0a:	ed91 7a03 	vldr	s14, [r1, #12]
   e4b0e:	ee67 7a27 	vmul.f32	s15, s14, s15

TfLiteStatus GetQuantizedConvolutionMultipler(TfLiteContext* context,
                                              const TfLiteTensor* input,
                                              const TfLiteTensor* filter,
                                              TfLiteTensor* output,
                                              double* multiplier) {
   e4b12:	4604      	mov	r4, r0
  const double input_product_scale = input->params.scale * filter->params.scale;
   e4b14:	ee17 0a90 	vmov	r0, s15

TfLiteStatus GetQuantizedConvolutionMultipler(TfLiteContext* context,
                                              const TfLiteTensor* input,
                                              const TfLiteTensor* filter,
                                              TfLiteTensor* output,
                                              double* multiplier) {
   e4b18:	461d      	mov	r5, r3
  const double input_product_scale = input->params.scale * filter->params.scale;
   e4b1a:	f003 fc2f 	bl	e837c <__aeabi_f2d>
  TF_LITE_ENSURE(context, input_product_scale >= 0);
   e4b1e:	2200      	movs	r2, #0
   e4b20:	2300      	movs	r3, #0
TfLiteStatus GetQuantizedConvolutionMultipler(TfLiteContext* context,
                                              const TfLiteTensor* input,
                                              const TfLiteTensor* filter,
                                              TfLiteTensor* output,
                                              double* multiplier) {
  const double input_product_scale = input->params.scale * filter->params.scale;
   e4b22:	4606      	mov	r6, r0
   e4b24:	460f      	mov	r7, r1
  TF_LITE_ENSURE(context, input_product_scale >= 0);
   e4b26:	f003 ff03 	bl	e8930 <__aeabi_dcmpge>
   e4b2a:	b948      	cbnz	r0, e4b40 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_PS2_Pd+0x3c>
   e4b2c:	4b0c      	ldr	r3, [pc, #48]	; (e4b60 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_PS2_Pd+0x5c>)
   e4b2e:	9300      	str	r3, [sp, #0]
   e4b30:	4620      	mov	r0, r4
   e4b32:	6965      	ldr	r5, [r4, #20]
   e4b34:	4a0b      	ldr	r2, [pc, #44]	; (e4b64 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_PS2_Pd+0x60>)
   e4b36:	490c      	ldr	r1, [pc, #48]	; (e4b68 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_PS2_Pd+0x64>)
   e4b38:	2376      	movs	r3, #118	; 0x76
   e4b3a:	47a8      	blx	r5
   e4b3c:	2001      	movs	r0, #1
   e4b3e:	e00c      	b.n	e4b5a <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_PS2_Pd+0x56>
  *multiplier = input_product_scale / output->params.scale;
   e4b40:	68e8      	ldr	r0, [r5, #12]
   e4b42:	f003 fc1b 	bl	e837c <__aeabi_f2d>
   e4b46:	460b      	mov	r3, r1
   e4b48:	4602      	mov	r2, r0
   e4b4a:	4639      	mov	r1, r7
   e4b4c:	4630      	mov	r0, r6
   e4b4e:	f003 fd93 	bl	e8678 <__aeabi_ddiv>
   e4b52:	9b08      	ldr	r3, [sp, #32]
   e4b54:	e9c3 0100 	strd	r0, r1, [r3]

  return kTfLiteOk;
   e4b58:	2000      	movs	r0, #0
}
   e4b5a:	b003      	add	sp, #12
   e4b5c:	bdf0      	pop	{r4, r5, r6, r7, pc}
   e4b5e:	bf00      	nop
   e4b60:	000eccb7 	.word	0x000eccb7
   e4b64:	000ecc18 	.word	0x000ecc18
   e4b68:	000eb58e 	.word	0x000eb58e
   e4b6c:	00000000 	.word	0x00000000

000e4b70 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd>:
TfLiteStatus GetQuantizedConvolutionMultipler(TfLiteContext* context,
                                              const TfLiteTensor* input,
                                              const TfLiteTensor* filter,
                                              const TfLiteTensor* bias,
                                              TfLiteTensor* output,
                                              double* multiplier) {
   e4b70:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  const double input_product_scale = input->params.scale * filter->params.scale;
   e4b74:	ed91 7a03 	vldr	s14, [r1, #12]
   e4b78:	edd2 7a03 	vldr	s15, [r2, #12]
TfLiteStatus GetQuantizedConvolutionMultipler(TfLiteContext* context,
                                              const TfLiteTensor* input,
                                              const TfLiteTensor* filter,
                                              const TfLiteTensor* bias,
                                              TfLiteTensor* output,
                                              double* multiplier) {
   e4b7c:	b087      	sub	sp, #28
  const double input_product_scale = input->params.scale * filter->params.scale;
   e4b7e:	ee67 7a27 	vmul.f32	s15, s14, s15
TfLiteStatus GetQuantizedConvolutionMultipler(TfLiteContext* context,
                                              const TfLiteTensor* input,
                                              const TfLiteTensor* filter,
                                              const TfLiteTensor* bias,
                                              TfLiteTensor* output,
                                              double* multiplier) {
   e4b82:	4604      	mov	r4, r0
   e4b84:	461e      	mov	r6, r3
  const double input_product_scale = input->params.scale * filter->params.scale;
   e4b86:	ee17 0a90 	vmov	r0, s15
TfLiteStatus GetQuantizedConvolutionMultipler(TfLiteContext* context,
                                              const TfLiteTensor* input,
                                              const TfLiteTensor* filter,
                                              const TfLiteTensor* bias,
                                              TfLiteTensor* output,
                                              double* multiplier) {
   e4b8a:	9b11      	ldr	r3, [sp, #68]	; 0x44
   e4b8c:	9305      	str	r3, [sp, #20]
   e4b8e:	460d      	mov	r5, r1
   e4b90:	4690      	mov	r8, r2
  const double input_product_scale = input->params.scale * filter->params.scale;
   e4b92:	f003 fbf3 	bl	e837c <__aeabi_f2d>
TfLiteStatus GetQuantizedConvolutionMultipler(TfLiteContext* context,
                                              const TfLiteTensor* input,
                                              const TfLiteTensor* filter,
                                              const TfLiteTensor* bias,
                                              TfLiteTensor* output,
                                              double* multiplier) {
   e4b96:	f8dd 9040 	ldr.w	r9, [sp, #64]	; 0x40
  const double input_product_scale = input->params.scale * filter->params.scale;
   e4b9a:	4682      	mov	sl, r0
   e4b9c:	468b      	mov	fp, r1
  // TODO(ahentz): The following conditions must be guaranteed by the training
  // pipeline.
  if (bias) {
   e4b9e:	b316      	cbz	r6, e4be6 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd+0x76>
    const double bias_scale = bias->params.scale;
   e4ba0:	68f0      	ldr	r0, [r6, #12]
   e4ba2:	f003 fbeb 	bl	e837c <__aeabi_f2d>
   e4ba6:	e9cd 0102 	strd	r0, r1, [sp, #8]
_GLIBCXX_BEGIN_NAMESPACE_VERSION

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR double
  abs(double __x)
  { return __builtin_fabs(__x); }
   e4baa:	4602      	mov	r2, r0
   e4bac:	460b      	mov	r3, r1
   e4bae:	4650      	mov	r0, sl
   e4bb0:	4659      	mov	r1, fp
   e4bb2:	f003 fa83 	bl	e80bc <__aeabi_dsub>
    min(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
   e4bb6:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
   e4bba:	4606      	mov	r6, r0
   e4bbc:	f021 4700 	bic.w	r7, r1, #2147483648	; 0x80000000
   e4bc0:	4650      	mov	r0, sl
   e4bc2:	4659      	mov	r1, fp
   e4bc4:	f003 febe 	bl	e8944 <__aeabi_dcmpgt>
   e4bc8:	b108      	cbz	r0, e4bce <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd+0x5e>
	return __b;
   e4bca:	e9dd ab02 	ldrd	sl, fp, [sp, #8]
    TF_LITE_ENSURE(context,
   e4bce:	a315      	add	r3, pc, #84	; (adr r3, e4c24 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd+0xb4>)
   e4bd0:	e9d3 2300 	ldrd	r2, r3, [r3]
   e4bd4:	4650      	mov	r0, sl
   e4bd6:	4659      	mov	r1, fp
   e4bd8:	f003 fc24 	bl	e8424 <__aeabi_dmul>
   e4bdc:	4632      	mov	r2, r6
   e4bde:	463b      	mov	r3, r7
   e4be0:	f003 fea6 	bl	e8930 <__aeabi_dcmpge>
   e4be4:	b150      	cbz	r0, e4bfc <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd+0x8c>
                   std::abs(input_product_scale - bias_scale) <=
                       1e-6 * std::min(input_product_scale, bias_scale));
  }
  return GetQuantizedConvolutionMultipler(context, input, filter, output,
                                          multiplier);
   e4be6:	9b05      	ldr	r3, [sp, #20]
   e4be8:	9310      	str	r3, [sp, #64]	; 0x40
   e4bea:	4642      	mov	r2, r8
   e4bec:	464b      	mov	r3, r9
   e4bee:	4629      	mov	r1, r5
   e4bf0:	4620      	mov	r0, r4
}
   e4bf2:	b007      	add	sp, #28
   e4bf4:	e8bd 4ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    TF_LITE_ENSURE(context,
                   std::abs(input_product_scale - bias_scale) <=
                       1e-6 * std::min(input_product_scale, bias_scale));
  }
  return GetQuantizedConvolutionMultipler(context, input, filter, output,
                                          multiplier);
   e4bf8:	f7ff bf84 	b.w	e4b04 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_PS2_Pd>
  const double input_product_scale = input->params.scale * filter->params.scale;
  // TODO(ahentz): The following conditions must be guaranteed by the training
  // pipeline.
  if (bias) {
    const double bias_scale = bias->params.scale;
    TF_LITE_ENSURE(context,
   e4bfc:	4b06      	ldr	r3, [pc, #24]	; (e4c18 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd+0xa8>)
   e4bfe:	9300      	str	r3, [sp, #0]
   e4c00:	4620      	mov	r0, r4
   e4c02:	6965      	ldr	r5, [r4, #20]
   e4c04:	4a05      	ldr	r2, [pc, #20]	; (e4c1c <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd+0xac>)
   e4c06:	4906      	ldr	r1, [pc, #24]	; (e4c20 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd+0xb0>)
   e4c08:	236a      	movs	r3, #106	; 0x6a
   e4c0a:	47a8      	blx	r5
                   std::abs(input_product_scale - bias_scale) <=
                       1e-6 * std::min(input_product_scale, bias_scale));
  }
  return GetQuantizedConvolutionMultipler(context, input, filter, output,
                                          multiplier);
}
   e4c0c:	2001      	movs	r0, #1
   e4c0e:	b007      	add	sp, #28
   e4c10:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e4c14:	f3af 8000 	nop.w
   e4c18:	000eccd0 	.word	0x000eccd0
   e4c1c:	000ecc18 	.word	0x000ecc18
   e4c20:	000eb58e 	.word	0x000eb58e
   e4c24:	a0b5ed8d 	.word	0xa0b5ed8d
   e4c28:	3eb0c6f7 	.word	0x3eb0c6f7

000e4c2c <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_>:

TfLiteStatus CalculateActivationRangeQuantized(TfLiteContext* context,
                                               TfLiteFusedActivation activation,
                                               TfLiteTensor* output,
                                               int32_t* act_min,
                                               int32_t* act_max) {
   e4c2c:	b573      	push	{r0, r1, r4, r5, r6, lr}
   e4c2e:	460d      	mov	r5, r1
  int32_t qmin = 0;
  int32_t qmax = 0;
  if (output->type == kTfLiteUInt8) {
   e4c30:	7811      	ldrb	r1, [r2, #0]
   e4c32:	2903      	cmp	r1, #3

TfLiteStatus CalculateActivationRangeQuantized(TfLiteContext* context,
                                               TfLiteFusedActivation activation,
                                               TfLiteTensor* output,
                                               int32_t* act_min,
                                               int32_t* act_max) {
   e4c34:	4614      	mov	r4, r2
  int32_t qmin = 0;
  int32_t qmax = 0;
  if (output->type == kTfLiteUInt8) {
   e4c36:	d00c      	beq.n	e4c52 <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_+0x26>
    qmin = std::numeric_limits<uint8_t>::min();
    qmax = std::numeric_limits<uint8_t>::max();
  } else if (output->type == kTfLiteInt8) {
   e4c38:	2909      	cmp	r1, #9
   e4c3a:	d00d      	beq.n	e4c58 <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_+0x2c>
    qmin = std::numeric_limits<int8_t>::min();
    qmax = std::numeric_limits<int8_t>::max();
  } else if (output->type == kTfLiteInt16) {
   e4c3c:	2907      	cmp	r1, #7
   e4c3e:	d00f      	beq.n	e4c60 <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_+0x34>
    qmin = std::numeric_limits<int16_t>::min();
    qmax = std::numeric_limits<int16_t>::max();
  } else {
    TF_LITE_ENSURE(context, false);
   e4c40:	4b0e      	ldr	r3, [pc, #56]	; (e4c7c <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_+0x50>)
   e4c42:	9300      	str	r3, [sp, #0]
   e4c44:	6944      	ldr	r4, [r0, #20]
   e4c46:	4a0e      	ldr	r2, [pc, #56]	; (e4c80 <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_+0x54>)
   e4c48:	490e      	ldr	r1, [pc, #56]	; (e4c84 <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_+0x58>)
   e4c4a:	23a9      	movs	r3, #169	; 0xa9
   e4c4c:	47a0      	blx	r4
   e4c4e:	2001      	movs	r0, #1
   e4c50:	e011      	b.n	e4c76 <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_+0x4a>
                                               int32_t* act_max) {
  int32_t qmin = 0;
  int32_t qmax = 0;
  if (output->type == kTfLiteUInt8) {
    qmin = std::numeric_limits<uint8_t>::min();
    qmax = std::numeric_limits<uint8_t>::max();
   e4c52:	22ff      	movs	r2, #255	; 0xff
                                               int32_t* act_min,
                                               int32_t* act_max) {
  int32_t qmin = 0;
  int32_t qmax = 0;
  if (output->type == kTfLiteUInt8) {
    qmin = std::numeric_limits<uint8_t>::min();
   e4c54:	2100      	movs	r1, #0
   e4c56:	e006      	b.n	e4c66 <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_+0x3a>
    qmax = std::numeric_limits<uint8_t>::max();
  } else if (output->type == kTfLiteInt8) {
    qmin = std::numeric_limits<int8_t>::min();
    qmax = std::numeric_limits<int8_t>::max();
   e4c58:	227f      	movs	r2, #127	; 0x7f
  int32_t qmax = 0;
  if (output->type == kTfLiteUInt8) {
    qmin = std::numeric_limits<uint8_t>::min();
    qmax = std::numeric_limits<uint8_t>::max();
  } else if (output->type == kTfLiteInt8) {
    qmin = std::numeric_limits<int8_t>::min();
   e4c5a:	f06f 017f 	mvn.w	r1, #127	; 0x7f
   e4c5e:	e002      	b.n	e4c66 <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_+0x3a>
    qmax = std::numeric_limits<int8_t>::max();
  } else if (output->type == kTfLiteInt16) {
    qmin = std::numeric_limits<int16_t>::min();
   e4c60:	4909      	ldr	r1, [pc, #36]	; (e4c88 <_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPlS5_+0x5c>)
    qmax = std::numeric_limits<int16_t>::max();
   e4c62:	f647 72ff 	movw	r2, #32767	; 0x7fff
  } else {
    TF_LITE_ENSURE(context, false);
  }

  CalculateActivationRangeQuantizedImpl(activation, qmin, qmax, output, act_min,
                                        act_max);
   e4c66:	9806      	ldr	r0, [sp, #24]
   e4c68:	9001      	str	r0, [sp, #4]
   e4c6a:	9300      	str	r3, [sp, #0]
   e4c6c:	4628      	mov	r0, r5
   e4c6e:	4623      	mov	r3, r4
   e4c70:	f7ff ff0a 	bl	e4a88 <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_>
  return kTfLiteOk;
   e4c74:	2000      	movs	r0, #0
}
   e4c76:	b002      	add	sp, #8
   e4c78:	bd70      	pop	{r4, r5, r6, pc}
   e4c7a:	bf00      	nop
   e4c7c:	000ecd2f 	.word	0x000ecd2f
   e4c80:	000ecc18 	.word	0x000ecc18
   e4c84:	000eb58e 	.word	0x000eb58e
   e4c88:	ffff8000 	.word	0xffff8000

000e4c8c <_ZN6tflite29CalculateActivationRangeUint8E21TfLiteFusedActivationP12TfLiteTensorPlS3_>:

void CalculateActivationRangeUint8(TfLiteFusedActivation activation,
                                   TfLiteTensor* output, int32_t* act_min,
                                   int32_t* act_max) {
   e4c8c:	b507      	push	{r0, r1, r2, lr}
  const int32_t qmin = std::numeric_limits<uint8_t>::min();
  const int32_t qmax = std::numeric_limits<uint8_t>::max();

  CalculateActivationRangeQuantizedImpl(activation, qmin, qmax, output, act_min,
                                        act_max);
   e4c8e:	e88d 000c 	stmia.w	sp, {r2, r3}
   e4c92:	460b      	mov	r3, r1
   e4c94:	22ff      	movs	r2, #255	; 0xff
   e4c96:	2100      	movs	r1, #0
   e4c98:	f7ff fef6 	bl	e4a88 <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_>
}
   e4c9c:	b003      	add	sp, #12
   e4c9e:	f85d fb04 	ldr.w	pc, [sp], #4
	...

000e4ca4 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_>:
TfLiteStatus PopulateConvolutionQuantizationParams(
    TfLiteContext* context, const TfLiteTensor* input,
    const TfLiteTensor* filter, const TfLiteTensor* bias, TfLiteTensor* output,
    const TfLiteFusedActivation& activation, int32_t* multiplier, int* shift,
    int32_t* output_activation_min, int32_t* output_activation_max,
    int32_t* per_channel_multiplier, int* per_channel_shift) {
   e4ca4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  TF_LITE_ENSURE_EQ(context, input->quantization.type,
   e4ca8:	f891 8030 	ldrb.w	r8, [r1, #48]	; 0x30
TfLiteStatus PopulateConvolutionQuantizationParams(
    TfLiteContext* context, const TfLiteTensor* input,
    const TfLiteTensor* filter, const TfLiteTensor* bias, TfLiteTensor* output,
    const TfLiteFusedActivation& activation, int32_t* multiplier, int* shift,
    int32_t* output_activation_min, int32_t* output_activation_max,
    int32_t* per_channel_multiplier, int* per_channel_shift) {
   e4cac:	b08d      	sub	sp, #52	; 0x34
  TF_LITE_ENSURE_EQ(context, input->quantization.type,
   e4cae:	f1b8 0f01 	cmp.w	r8, #1
TfLiteStatus PopulateConvolutionQuantizationParams(
    TfLiteContext* context, const TfLiteTensor* input,
    const TfLiteTensor* filter, const TfLiteTensor* bias, TfLiteTensor* output,
    const TfLiteFusedActivation& activation, int32_t* multiplier, int* shift,
    int32_t* output_activation_min, int32_t* output_activation_max,
    int32_t* per_channel_multiplier, int* per_channel_shift) {
   e4cb2:	4604      	mov	r4, r0
   e4cb4:	460e      	mov	r6, r1
   e4cb6:	4617      	mov	r7, r2
   e4cb8:	9307      	str	r3, [sp, #28]
  TF_LITE_ENSURE_EQ(context, input->quantization.type,
   e4cba:	d00a      	beq.n	e4cd2 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x2e>
   e4cbc:	4b63      	ldr	r3, [pc, #396]	; (e4e4c <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1a8>)
   e4cbe:	9301      	str	r3, [sp, #4]
   e4cc0:	2501      	movs	r5, #1
   e4cc2:	4b63      	ldr	r3, [pc, #396]	; (e4e50 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1ac>)
   e4cc4:	9300      	str	r3, [sp, #0]
   e4cc6:	9503      	str	r5, [sp, #12]
   e4cc8:	f8cd 8008 	str.w	r8, [sp, #8]
   e4ccc:	6944      	ldr	r4, [r0, #20]
   e4cce:	2321      	movs	r3, #33	; 0x21
   e4cd0:	e033      	b.n	e4d3a <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x96>
                    kTfLiteAffineQuantization);
  TF_LITE_ENSURE_EQ(context, filter->quantization.type,
   e4cd2:	f892 5030 	ldrb.w	r5, [r2, #48]	; 0x30
   e4cd6:	2d01      	cmp	r5, #1
   e4cd8:	d00d      	beq.n	e4cf6 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x52>
   e4cda:	4b5c      	ldr	r3, [pc, #368]	; (e4e4c <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1a8>)
   e4cdc:	9301      	str	r3, [sp, #4]
   e4cde:	4b5d      	ldr	r3, [pc, #372]	; (e4e54 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1b0>)
   e4ce0:	9502      	str	r5, [sp, #8]
   e4ce2:	9300      	str	r3, [sp, #0]
   e4ce4:	f8cd 800c 	str.w	r8, [sp, #12]
   e4ce8:	6944      	ldr	r4, [r0, #20]
   e4cea:	4a5b      	ldr	r2, [pc, #364]	; (e4e58 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1b4>)
   e4cec:	495b      	ldr	r1, [pc, #364]	; (e4e5c <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1b8>)
   e4cee:	2323      	movs	r3, #35	; 0x23
   e4cf0:	47a0      	blx	r4
   e4cf2:	4645      	mov	r5, r8
   e4cf4:	e0a6      	b.n	e4e44 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1a0>
  // TF_LITE_ENSURE_EQ(context, bias->quantization.type,
  // kTfLiteAffineQuantization);

  // Check data type.
  const auto* affine_quantization =
      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);
   e4cf6:	6b51      	ldr	r1, [r2, #52]	; 0x34
  TF_LITE_ENSURE(context, affine_quantization);
   e4cf8:	b921      	cbnz	r1, e4d04 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x60>
   e4cfa:	4b59      	ldr	r3, [pc, #356]	; (e4e60 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1bc>)
   e4cfc:	9300      	str	r3, [sp, #0]
   e4cfe:	6944      	ldr	r4, [r0, #20]
   e4d00:	232d      	movs	r3, #45	; 0x2d
   e4d02:	e005      	b.n	e4d10 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x6c>
  TF_LITE_ENSURE(context, affine_quantization->scale);
   e4d04:	680b      	ldr	r3, [r1, #0]
   e4d06:	b93b      	cbnz	r3, e4d18 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x74>
   e4d08:	4b56      	ldr	r3, [pc, #344]	; (e4e64 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1c0>)
   e4d0a:	9300      	str	r3, [sp, #0]
   e4d0c:	6944      	ldr	r4, [r0, #20]
   e4d0e:	232e      	movs	r3, #46	; 0x2e
   e4d10:	4a51      	ldr	r2, [pc, #324]	; (e4e58 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1b4>)
   e4d12:	4955      	ldr	r1, [pc, #340]	; (e4e68 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1c4>)
   e4d14:	47a0      	blx	r4
   e4d16:	e095      	b.n	e4e44 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1a0>
  const bool is_per_channel = affine_quantization->scale->size > 1;
   e4d18:	f8d3 b000 	ldr.w	fp, [r3]
  if (is_per_channel) {
   e4d1c:	f1bb 0f01 	cmp.w	fp, #1
   e4d20:	dd2f      	ble.n	e4d82 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0xde>
    //  Currently only Int8 is supported for per channel quantization.
    TF_LITE_ENSURE_EQ(context, input->type, kTfLiteInt8);
   e4d22:	7832      	ldrb	r2, [r6, #0]
   e4d24:	2a09      	cmp	r2, #9
   e4d26:	d00c      	beq.n	e4d42 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x9e>
   e4d28:	2309      	movs	r3, #9
   e4d2a:	9303      	str	r3, [sp, #12]
   e4d2c:	4b4f      	ldr	r3, [pc, #316]	; (e4e6c <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1c8>)
   e4d2e:	9301      	str	r3, [sp, #4]
   e4d30:	4b4f      	ldr	r3, [pc, #316]	; (e4e70 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1cc>)
   e4d32:	9300      	str	r3, [sp, #0]
   e4d34:	9202      	str	r2, [sp, #8]
   e4d36:	6944      	ldr	r4, [r0, #20]
   e4d38:	2332      	movs	r3, #50	; 0x32
   e4d3a:	4a47      	ldr	r2, [pc, #284]	; (e4e58 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1b4>)
   e4d3c:	4947      	ldr	r1, [pc, #284]	; (e4e5c <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1b8>)
   e4d3e:	47a0      	blx	r4
   e4d40:	e080      	b.n	e4e44 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1a0>
    TF_LITE_ENSURE_EQ(context, filter->type, kTfLiteInt8);
   e4d42:	f897 e000 	ldrb.w	lr, [r7]
   e4d46:	f1be 0f09 	cmp.w	lr, #9
   e4d4a:	d009      	beq.n	e4d60 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0xbc>
   e4d4c:	4b47      	ldr	r3, [pc, #284]	; (e4e6c <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1c8>)
   e4d4e:	9301      	str	r3, [sp, #4]
   e4d50:	4b48      	ldr	r3, [pc, #288]	; (e4e74 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1d0>)
   e4d52:	9300      	str	r3, [sp, #0]
   e4d54:	9203      	str	r2, [sp, #12]
   e4d56:	f8cd e008 	str.w	lr, [sp, #8]
   e4d5a:	6944      	ldr	r4, [r0, #20]
   e4d5c:	2333      	movs	r3, #51	; 0x33
   e4d5e:	e7ec      	b.n	e4d3a <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x96>
    TF_LITE_ENSURE_EQ(
   e4d60:	68ba      	ldr	r2, [r7, #8]
   e4d62:	6889      	ldr	r1, [r1, #8]
   e4d64:	eb02 0281 	add.w	r2, r2, r1, lsl #2
   e4d68:	6852      	ldr	r2, [r2, #4]
   e4d6a:	4593      	cmp	fp, r2
   e4d6c:	d009      	beq.n	e4d82 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0xde>
   e4d6e:	4b42      	ldr	r3, [pc, #264]	; (e4e78 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1d4>)
   e4d70:	9301      	str	r3, [sp, #4]
   e4d72:	4b42      	ldr	r3, [pc, #264]	; (e4e7c <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1d8>)
   e4d74:	9300      	str	r3, [sp, #0]
   e4d76:	9203      	str	r2, [sp, #12]
   e4d78:	f8cd b008 	str.w	fp, [sp, #8]
   e4d7c:	6944      	ldr	r4, [r0, #20]
   e4d7e:	2336      	movs	r3, #54	; 0x36
   e4d80:	e7db      	b.n	e4d3a <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x96>
        filter->dims->data[affine_quantization->quantized_dimension]);
  }

  // Populate multiplier and shift using affine quantization.
  const int num_channels = affine_quantization->scale->size;
  const float input_scale = input->params.scale;
   e4d82:	edd6 7a03 	vldr	s15, [r6, #12]
  const float output_scale = output->params.scale;
   e4d86:	9a16      	ldr	r2, [sp, #88]	; 0x58
        filter->dims->data[affine_quantization->quantized_dimension]);
  }

  // Populate multiplier and shift using affine quantization.
  const int num_channels = affine_quantization->scale->size;
  const float input_scale = input->params.scale;
   e4d88:	edcd 7a05 	vstr	s15, [sp, #20]
  const float output_scale = output->params.scale;
   e4d8c:	edd2 7a03 	vldr	s15, [r2, #12]
  const float* filter_scales = affine_quantization->scale->data;
   e4d90:	1d1d      	adds	r5, r3, #4
  }

  // Populate multiplier and shift using affine quantization.
  const int num_channels = affine_quantization->scale->size;
  const float input_scale = input->params.scale;
  const float output_scale = output->params.scale;
   e4d92:	edcd 7a06 	vstr	s15, [sp, #24]
  const float* filter_scales = affine_quantization->scale->data;
  for (int i = 0; i < num_channels; ++i) {
   e4d96:	f04f 0a00 	mov.w	sl, #0
   e4d9a:	45da      	cmp	sl, fp
   e4d9c:	da2a      	bge.n	e4df4 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x150>
    const double effective_output_scale = static_cast<double>(input_scale) *
                                          filter_scale /
                                          static_cast<double>(output_scale);
    int32_t significand;
    int shift;
    QuantizeMultiplier(effective_output_scale, &significand, &shift);
   e4d9e:	f855 0b04 	ldr.w	r0, [r5], #4
   e4da2:	f003 faeb 	bl	e837c <__aeabi_f2d>
   e4da6:	4680      	mov	r8, r0
   e4da8:	9805      	ldr	r0, [sp, #20]
   e4daa:	4689      	mov	r9, r1
   e4dac:	f003 fae6 	bl	e837c <__aeabi_f2d>
   e4db0:	4602      	mov	r2, r0
   e4db2:	460b      	mov	r3, r1
   e4db4:	4640      	mov	r0, r8
   e4db6:	4649      	mov	r1, r9
   e4db8:	f003 fb34 	bl	e8424 <__aeabi_dmul>
   e4dbc:	4680      	mov	r8, r0
   e4dbe:	9806      	ldr	r0, [sp, #24]
   e4dc0:	4689      	mov	r9, r1
   e4dc2:	f003 fadb 	bl	e837c <__aeabi_f2d>
   e4dc6:	4602      	mov	r2, r0
   e4dc8:	460b      	mov	r3, r1
   e4dca:	4640      	mov	r0, r8
   e4dcc:	4649      	mov	r1, r9
   e4dce:	f003 fc53 	bl	e8678 <__aeabi_ddiv>
   e4dd2:	ec41 0b10 	vmov	d0, r0, r1
   e4dd6:	a90a      	add	r1, sp, #40	; 0x28
   e4dd8:	a809      	add	r0, sp, #36	; 0x24
   e4dda:	f000 f867 	bl	e4eac <_ZN6tflite18QuantizeMultiplierEdPlPi>
    per_channel_multiplier[i] = significand;
   e4dde:	9a1c      	ldr	r2, [sp, #112]	; 0x70
   e4de0:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e4de2:	f842 302a 	str.w	r3, [r2, sl, lsl #2]
    per_channel_shift[i] = shift;
   e4de6:	9a1d      	ldr	r2, [sp, #116]	; 0x74
   e4de8:	9b0a      	ldr	r3, [sp, #40]	; 0x28
   e4dea:	f842 302a 	str.w	r3, [r2, sl, lsl #2]
  // Populate multiplier and shift using affine quantization.
  const int num_channels = affine_quantization->scale->size;
  const float input_scale = input->params.scale;
  const float output_scale = output->params.scale;
  const float* filter_scales = affine_quantization->scale->data;
  for (int i = 0; i < num_channels; ++i) {
   e4dee:	f10a 0a01 	add.w	sl, sl, #1
   e4df2:	e7d2      	b.n	e4d9a <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0xf6>
  }

  // Populate scalar quantization parameters.
  // This check on legacy quantization parameters is kept only for backward
  // compatibility.
  if (input->type == kTfLiteUInt8) {
   e4df4:	7833      	ldrb	r3, [r6, #0]
   e4df6:	2b03      	cmp	r3, #3
   e4df8:	d123      	bne.n	e4e42 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x19e>
    // Check bias scale == input scale * filter scale.
    double real_multiplier = 0.0;
   e4dfa:	ab0c      	add	r3, sp, #48	; 0x30
   e4dfc:	2000      	movs	r0, #0
   e4dfe:	2100      	movs	r1, #0
   e4e00:	e963 0102 	strd	r0, r1, [r3, #-8]!
    TF_LITE_ENSURE_STATUS(GetQuantizedConvolutionMultipler(
   e4e04:	9301      	str	r3, [sp, #4]
   e4e06:	9b16      	ldr	r3, [sp, #88]	; 0x58
   e4e08:	9300      	str	r3, [sp, #0]
   e4e0a:	463a      	mov	r2, r7
   e4e0c:	9b07      	ldr	r3, [sp, #28]
   e4e0e:	4631      	mov	r1, r6
   e4e10:	4620      	mov	r0, r4
   e4e12:	f7ff fead 	bl	e4b70 <_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd>
   e4e16:	4605      	mov	r5, r0
   e4e18:	b108      	cbz	r0, e4e1e <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x17a>
   e4e1a:	2501      	movs	r5, #1
   e4e1c:	e012      	b.n	e4e44 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1a0>
        context, input, filter, bias, output, &real_multiplier));
    int exponent;

    // Populate quantization parameteters with multiplier and shift.
    QuantizeMultiplier(real_multiplier, multiplier, &exponent);
   e4e1e:	a909      	add	r1, sp, #36	; 0x24
   e4e20:	9818      	ldr	r0, [sp, #96]	; 0x60
   e4e22:	ed9d 0b0a 	vldr	d0, [sp, #40]	; 0x28
   e4e26:	f000 f841 	bl	e4eac <_ZN6tflite18QuantizeMultiplierEdPlPi>
    *shift = -exponent;
   e4e2a:	9b09      	ldr	r3, [sp, #36]	; 0x24
   e4e2c:	9a19      	ldr	r2, [sp, #100]	; 0x64
    CalculateActivationRangeUint8(activation, output, output_activation_min,
                                  output_activation_max);
   e4e2e:	9817      	ldr	r0, [sp, #92]	; 0x5c
   e4e30:	9916      	ldr	r1, [sp, #88]	; 0x58
        context, input, filter, bias, output, &real_multiplier));
    int exponent;

    // Populate quantization parameteters with multiplier and shift.
    QuantizeMultiplier(real_multiplier, multiplier, &exponent);
    *shift = -exponent;
   e4e32:	425b      	negs	r3, r3
   e4e34:	6013      	str	r3, [r2, #0]
    CalculateActivationRangeUint8(activation, output, output_activation_min,
                                  output_activation_max);
   e4e36:	7800      	ldrb	r0, [r0, #0]
   e4e38:	9b1b      	ldr	r3, [sp, #108]	; 0x6c
   e4e3a:	9a1a      	ldr	r2, [sp, #104]	; 0x68
   e4e3c:	f7ff ff26 	bl	e4c8c <_ZN6tflite29CalculateActivationRangeUint8E21TfLiteFusedActivationP12TfLiteTensorPlS3_>
   e4e40:	e000      	b.n	e4e44 <_ZN6tflite37PopulateConvolutionQuantizationParamsEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_RK21TfLiteFusedActivationPlPiS9_S9_S9_SA_+0x1a0>
  }
  return kTfLiteOk;
   e4e42:	2500      	movs	r5, #0
}
   e4e44:	4628      	mov	r0, r5
   e4e46:	b00d      	add	sp, #52	; 0x34
   e4e48:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e4e4c:	000eb5dd 	.word	0x000eb5dd
   e4e50:	000ecd35 	.word	0x000ecd35
   e4e54:	000eb5f7 	.word	0x000eb5f7
   e4e58:	000ecc18 	.word	0x000ecc18
   e4e5c:	000eb3b9 	.word	0x000eb3b9
   e4e60:	000eb611 	.word	0x000eb611
   e4e64:	000eb625 	.word	0x000eb625
   e4e68:	000eb58e 	.word	0x000eb58e
   e4e6c:	000ec816 	.word	0x000ec816
   e4e70:	000eb3f4 	.word	0x000eb3f4
   e4e74:	000ecd4e 	.word	0x000ecd4e
   e4e78:	000ecd5b 	.word	0x000ecd5b
   e4e7c:	000ecd98 	.word	0x000ecd98

000e4e80 <_ZN6tflite28CalculateActivationRangeInt8E21TfLiteFusedActivationP12TfLiteTensorPlS3_>:
                                        act_max);
}

void CalculateActivationRangeInt8(TfLiteFusedActivation activation,
                                  TfLiteTensor* output, int32_t* act_min,
                                  int32_t* act_max) {
   e4e80:	b507      	push	{r0, r1, r2, lr}
  const int32_t qmin = std::numeric_limits<int8_t>::min();
  const int32_t qmax = std::numeric_limits<int8_t>::max();

  CalculateActivationRangeQuantizedImpl(activation, qmin, qmax, output, act_min,
                                        act_max);
   e4e82:	e88d 000c 	stmia.w	sp, {r2, r3}
   e4e86:	460b      	mov	r3, r1
   e4e88:	227f      	movs	r2, #127	; 0x7f
   e4e8a:	f06f 017f 	mvn.w	r1, #127	; 0x7f
   e4e8e:	f7ff fdfb 	bl	e4a88 <_ZN6tflite12_GLOBAL__N_137CalculateActivationRangeQuantizedImplE21TfLiteFusedActivationllP12TfLiteTensorPlS4_>
}
   e4e92:	b003      	add	sp, #12
   e4e94:	f85d fb04 	ldr.w	pc, [sp], #4

000e4e98 <_ZN6tflite14HaveSameShapesEPK12TfLiteTensorS2_>:

bool HaveSameShapes(const TfLiteTensor* input1, const TfLiteTensor* input2) {
   e4e98:	b508      	push	{r3, lr}
  return TfLiteIntArrayEqual(input1->dims, input2->dims);
   e4e9a:	6889      	ldr	r1, [r1, #8]
   e4e9c:	6880      	ldr	r0, [r0, #8]
   e4e9e:	f7ef f937 	bl	d4110 <TfLiteIntArrayEqual>
}
   e4ea2:	3000      	adds	r0, #0
   e4ea4:	bf18      	it	ne
   e4ea6:	2001      	movne	r0, #1
   e4ea8:	bd08      	pop	{r3, pc}
	...

000e4eac <_ZN6tflite18QuantizeMultiplierEdPlPi>:
constexpr uint32_t kFractionRoundingMask = 0x003fffff;
constexpr uint32_t kFractionRoundingThreshold = 0x00200000;
}  // namespace

void QuantizeMultiplier(double double_multiplier, int32_t* quantized_multiplier,
                        int* shift) {
   e4eac:	b538      	push	{r3, r4, r5, lr}
  if (double_multiplier == 0.) {
   e4eae:	2200      	movs	r2, #0
constexpr uint32_t kFractionRoundingMask = 0x003fffff;
constexpr uint32_t kFractionRoundingThreshold = 0x00200000;
}  // namespace

void QuantizeMultiplier(double double_multiplier, int32_t* quantized_multiplier,
                        int* shift) {
   e4eb0:	ed2d 8b02 	vpush	{d8}
   e4eb4:	eeb0 8a40 	vmov.f32	s16, s0
   e4eb8:	eef0 8a60 	vmov.f32	s17, s1
   e4ebc:	4605      	mov	r5, r0
   e4ebe:	460c      	mov	r4, r1
  if (double_multiplier == 0.) {
   e4ec0:	2300      	movs	r3, #0
   e4ec2:	ec51 0b10 	vmov	r0, r1, d0
   e4ec6:	f003 fd15 	bl	e88f4 <__aeabi_dcmpeq>
   e4eca:	b118      	cbz	r0, e4ed4 <_ZN6tflite18QuantizeMultiplierEdPlPi+0x28>
    *quantized_multiplier = 0;
   e4ecc:	2300      	movs	r3, #0
   e4ece:	602b      	str	r3, [r5, #0]
    *shift = 0;
   e4ed0:	6023      	str	r3, [r4, #0]
   e4ed2:	e02d      	b.n	e4f30 <_ZN6tflite18QuantizeMultiplierEdPlPi+0x84>
  // example on microcontrollers) then use an alternative implementation
  // that only requires integer and bitwise operations. To enable this, you
  // need to set the define during the build process for your platform.
  int64_t q_fixed = IntegerFrExp(double_multiplier, shift);
#else   // TFLITE_EMULATE_FLOAT
  const double q = std::frexp(double_multiplier, shift);
   e4ed4:	4620      	mov	r0, r4
   e4ed6:	eeb0 0a48 	vmov.f32	s0, s16
   e4eda:	eef0 0a68 	vmov.f32	s1, s17
   e4ede:	f001 fb43 	bl	e6568 <frexp>
   e4ee2:	2200      	movs	r2, #0
   e4ee4:	4b14      	ldr	r3, [pc, #80]	; (e4f38 <_ZN6tflite18QuantizeMultiplierEdPlPi+0x8c>)
   e4ee6:	ec51 0b10 	vmov	r0, r1, d0
   e4eea:	f003 fa9b 	bl	e8424 <__aeabi_dmul>
   e4eee:	ec41 0b10 	vmov	d0, r0, r1
   e4ef2:	f001 fb6f 	bl	e65d4 <round>
  auto q_fixed = static_cast<int64_t>(TfLiteRound(q * (1ll << 31)));
   e4ef6:	ec51 0b10 	vmov	r0, r1, d0
   e4efa:	f003 fdc5 	bl	e8a88 <__aeabi_d2lz>
#endif  // TFLITE_EMULATE_FLOAT
  TFLITE_CHECK(q_fixed <= (1ll << 31));
   e4efe:	f04f 4200 	mov.w	r2, #2147483648	; 0x80000000
   e4f02:	2300      	movs	r3, #0
   e4f04:	4282      	cmp	r2, r0
   e4f06:	418b      	sbcs	r3, r1
   e4f08:	da01      	bge.n	e4f0e <_ZN6tflite18QuantizeMultiplierEdPlPi+0x62>
   e4f0a:	f000 faf3 	bl	e54f4 <abort>
  if (q_fixed == (1ll << 31)) {
   e4f0e:	2900      	cmp	r1, #0
   e4f10:	bf01      	itttt	eq
   e4f12:	f1b0 4f00 	cmpeq.w	r0, #2147483648	; 0x80000000
    q_fixed /= 2;
    ++*shift;
   e4f16:	6823      	ldreq	r3, [r4, #0]
   e4f18:	3301      	addeq	r3, #1
   e4f1a:	6023      	streq	r3, [r4, #0]
  // that we're effectively flushing tiny double_multiplier's to zero.
  // We could conceivably handle values in the range (roughly) [32, 63]
  // as 'denormals' i.e. (shift==0, q_fixed < 2^30). In that point of view
  // the present handling is just doing 'flush denormals to zero'. We could
  // reconsider and actually generate nonzero denormals if a need arises.
  if (*shift < -31) {
   e4f1c:	6823      	ldr	r3, [r4, #0]
  const double q = std::frexp(double_multiplier, shift);
  auto q_fixed = static_cast<int64_t>(TfLiteRound(q * (1ll << 31)));
#endif  // TFLITE_EMULATE_FLOAT
  TFLITE_CHECK(q_fixed <= (1ll << 31));
  if (q_fixed == (1ll << 31)) {
    q_fixed /= 2;
   e4f1e:	bf08      	it	eq
   e4f20:	f04f 4080 	moveq.w	r0, #1073741824	; 0x40000000
  // that we're effectively flushing tiny double_multiplier's to zero.
  // We could conceivably handle values in the range (roughly) [32, 63]
  // as 'denormals' i.e. (shift==0, q_fixed < 2^30). In that point of view
  // the present handling is just doing 'flush denormals to zero'. We could
  // reconsider and actually generate nonzero denormals if a need arises.
  if (*shift < -31) {
   e4f24:	331f      	adds	r3, #31
    *shift = 0;
   e4f26:	bfbe      	ittt	lt
   e4f28:	2300      	movlt	r3, #0
    q_fixed = 0;
   e4f2a:	2000      	movlt	r0, #0
  // We could conceivably handle values in the range (roughly) [32, 63]
  // as 'denormals' i.e. (shift==0, q_fixed < 2^30). In that point of view
  // the present handling is just doing 'flush denormals to zero'. We could
  // reconsider and actually generate nonzero denormals if a need arises.
  if (*shift < -31) {
    *shift = 0;
   e4f2c:	6023      	strlt	r3, [r4, #0]
    q_fixed = 0;
  }
  *quantized_multiplier = static_cast<int32_t>(q_fixed);
   e4f2e:	6028      	str	r0, [r5, #0]
}
   e4f30:	ecbd 8b02 	vpop	{d8}
   e4f34:	bd38      	pop	{r3, r4, r5, pc}
   e4f36:	bf00      	nop
   e4f38:	41e00000 	.word	0x41e00000

000e4f3c <_ZN6tflite32QuantizeMultiplierGreaterThanOneEdPlPi>:

void QuantizeMultiplierGreaterThanOne(double double_multiplier,
                                      int32_t* quantized_multiplier,
                                      int* left_shift) {
   e4f3c:	b538      	push	{r3, r4, r5, lr}
  TFLITE_CHECK_GT(double_multiplier, 1.);
   e4f3e:	2200      	movs	r2, #0
  *quantized_multiplier = static_cast<int32_t>(q_fixed);
}

void QuantizeMultiplierGreaterThanOne(double double_multiplier,
                                      int32_t* quantized_multiplier,
                                      int* left_shift) {
   e4f40:	ed2d 8b02 	vpush	{d8}
   e4f44:	eeb0 8a40 	vmov.f32	s16, s0
   e4f48:	eef0 8a60 	vmov.f32	s17, s1
   e4f4c:	4605      	mov	r5, r0
   e4f4e:	460c      	mov	r4, r1
  TFLITE_CHECK_GT(double_multiplier, 1.);
   e4f50:	4b0a      	ldr	r3, [pc, #40]	; (e4f7c <_ZN6tflite32QuantizeMultiplierGreaterThanOneEdPlPi+0x40>)
   e4f52:	ec51 0b10 	vmov	r0, r1, d0
   e4f56:	f003 fcf5 	bl	e8944 <__aeabi_dcmpgt>
   e4f5a:	b908      	cbnz	r0, e4f60 <_ZN6tflite32QuantizeMultiplierGreaterThanOneEdPlPi+0x24>
   e4f5c:	f000 faca 	bl	e54f4 <abort>
  QuantizeMultiplier(double_multiplier, quantized_multiplier, left_shift);
   e4f60:	4621      	mov	r1, r4
   e4f62:	4628      	mov	r0, r5
   e4f64:	eeb0 0a48 	vmov.f32	s0, s16
   e4f68:	eef0 0a68 	vmov.f32	s1, s17
   e4f6c:	f7ff ff9e 	bl	e4eac <_ZN6tflite18QuantizeMultiplierEdPlPi>
  TFLITE_CHECK_GE(*left_shift, 0);
   e4f70:	6823      	ldr	r3, [r4, #0]
   e4f72:	2b00      	cmp	r3, #0
   e4f74:	dbf2      	blt.n	e4f5c <_ZN6tflite32QuantizeMultiplierGreaterThanOneEdPlPi+0x20>
}
   e4f76:	ecbd 8b02 	vpop	{d8}
   e4f7a:	bd38      	pop	{r3, r4, r5, pc}
   e4f7c:	3ff00000 	.word	0x3ff00000

000e4f80 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi>:

void QuantizeMultiplierSmallerThanOneExp(double double_multiplier,
                                         int32_t* quantized_multiplier,
                                         int* left_shift) {
   e4f80:	b530      	push	{r4, r5, lr}
  TFLITE_CHECK_LT(double_multiplier, 1.);
   e4f82:	2200      	movs	r2, #0
  TFLITE_CHECK_GE(*left_shift, 0);
}

void QuantizeMultiplierSmallerThanOneExp(double double_multiplier,
                                         int32_t* quantized_multiplier,
                                         int* left_shift) {
   e4f84:	b085      	sub	sp, #20
   e4f86:	4605      	mov	r5, r0
   e4f88:	460c      	mov	r4, r1
  TFLITE_CHECK_LT(double_multiplier, 1.);
   e4f8a:	4b11      	ldr	r3, [pc, #68]	; (e4fd0 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi+0x50>)
   e4f8c:	ec51 0b10 	vmov	r0, r1, d0
   e4f90:	ed8d 0b00 	vstr	d0, [sp]
   e4f94:	f003 fcb8 	bl	e8908 <__aeabi_dcmplt>
   e4f98:	ed9d 0b00 	vldr	d0, [sp]
   e4f9c:	b908      	cbnz	r0, e4fa2 <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi+0x22>
   e4f9e:	f000 faa9 	bl	e54f4 <abort>
  TFLITE_CHECK_GT(double_multiplier, 0.);
   e4fa2:	2200      	movs	r2, #0
   e4fa4:	2300      	movs	r3, #0
   e4fa6:	ec51 0b10 	vmov	r0, r1, d0
   e4faa:	ed8d 0b00 	vstr	d0, [sp]
   e4fae:	f003 fcc9 	bl	e8944 <__aeabi_dcmpgt>
   e4fb2:	2800      	cmp	r0, #0
   e4fb4:	d0f3      	beq.n	e4f9e <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi+0x1e>
  int shift;
  QuantizeMultiplier(double_multiplier, quantized_multiplier, &shift);
   e4fb6:	a903      	add	r1, sp, #12
   e4fb8:	4628      	mov	r0, r5
   e4fba:	ed9d 0b00 	vldr	d0, [sp]
   e4fbe:	f7ff ff75 	bl	e4eac <_ZN6tflite18QuantizeMultiplierEdPlPi>
  TFLITE_CHECK_LE(shift, 0);
   e4fc2:	9b03      	ldr	r3, [sp, #12]
   e4fc4:	2b00      	cmp	r3, #0
   e4fc6:	dcea      	bgt.n	e4f9e <_ZN6tflite35QuantizeMultiplierSmallerThanOneExpEdPlPi+0x1e>
  *left_shift = shift;
   e4fc8:	6023      	str	r3, [r4, #0]
}
   e4fca:	b005      	add	sp, #20
   e4fcc:	bd30      	pop	{r4, r5, pc}
   e4fce:	bf00      	nop
   e4fd0:	3ff00000 	.word	0x3ff00000
   e4fd4:	00000000 	.word	0x00000000

000e4fd8 <_ZN6tflite24PreprocessSoftmaxScalingEddiPlPi>:
  }
}

void PreprocessSoftmaxScaling(double beta, double input_scale,
                              int input_integer_bits,
                              int32_t* quantized_multiplier, int* left_shift) {
   e4fd8:	b5f0      	push	{r4, r5, r6, r7, lr}
  if (IntegerDoubleCompare(input_beta_real_multiplier, (1ll << 31) - 1.0) > 0) {
    input_beta_real_multiplier = (1ll << 31) - 1.0;
  }
#else   // TFLITE_EMULATE_FLOAT
  const double input_beta_real_multiplier = std::min(
      beta * input_scale * (1 << (31 - input_integer_bits)), (1ll << 31) - 1.0);
   e4fda:	2301      	movs	r3, #1
   e4fdc:	f1c0 001f 	rsb	r0, r0, #31
  }
}

void PreprocessSoftmaxScaling(double beta, double input_scale,
                              int input_integer_bits,
                              int32_t* quantized_multiplier, int* left_shift) {
   e4fe0:	b085      	sub	sp, #20
  if (IntegerDoubleCompare(input_beta_real_multiplier, (1ll << 31) - 1.0) > 0) {
    input_beta_real_multiplier = (1ll << 31) - 1.0;
  }
#else   // TFLITE_EMULATE_FLOAT
  const double input_beta_real_multiplier = std::min(
      beta * input_scale * (1 << (31 - input_integer_bits)), (1ll << 31) - 1.0);
   e4fe2:	fa03 f000 	lsl.w	r0, r3, r0
  }
}

void PreprocessSoftmaxScaling(double beta, double input_scale,
                              int input_integer_bits,
                              int32_t* quantized_multiplier, int* left_shift) {
   e4fe6:	ed8d 0b02 	vstr	d0, [sp, #8]
   e4fea:	ed8d 1b00 	vstr	d1, [sp]
   e4fee:	4615      	mov	r5, r2
   e4ff0:	460c      	mov	r4, r1
  if (IntegerDoubleCompare(input_beta_real_multiplier, (1ll << 31) - 1.0) > 0) {
    input_beta_real_multiplier = (1ll << 31) - 1.0;
  }
#else   // TFLITE_EMULATE_FLOAT
  const double input_beta_real_multiplier = std::min(
      beta * input_scale * (1 << (31 - input_integer_bits)), (1ll << 31) - 1.0);
   e4ff2:	f003 f9b1 	bl	e8358 <__aeabi_i2d>
   e4ff6:	ed9d 1b00 	vldr	d1, [sp]
   e4ffa:	ed9d 0b02 	vldr	d0, [sp, #8]
   e4ffe:	ec53 2b11 	vmov	r2, r3, d1
   e5002:	4606      	mov	r6, r0
   e5004:	460f      	mov	r7, r1
   e5006:	ec51 0b10 	vmov	r0, r1, d0
   e500a:	f003 fa0b 	bl	e8424 <__aeabi_dmul>
   e500e:	4602      	mov	r2, r0
   e5010:	460b      	mov	r3, r1
   e5012:	4630      	mov	r0, r6
   e5014:	4639      	mov	r1, r7
   e5016:	f003 fa05 	bl	e8424 <__aeabi_dmul>
    min(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
   e501a:	a309      	add	r3, pc, #36	; (adr r3, e5040 <_ZN6tflite24PreprocessSoftmaxScalingEddiPlPi+0x68>)
   e501c:	e9d3 2300 	ldrd	r2, r3, [r3]
   e5020:	e9cd 0100 	strd	r0, r1, [sp]
   e5024:	f003 fc8e 	bl	e8944 <__aeabi_dcmpgt>
   e5028:	ed9d 0b00 	vldr	d0, [sp]
   e502c:	b108      	cbz	r0, e5032 <_ZN6tflite24PreprocessSoftmaxScalingEddiPlPi+0x5a>
	return __b;
   e502e:	ed9f 0b04 	vldr	d0, [pc, #16]	; e5040 <_ZN6tflite24PreprocessSoftmaxScalingEddiPlPi+0x68>
#endif  // TFLITE_EMULATE_FLOAT

  QuantizeMultiplierGreaterThanOne(input_beta_real_multiplier,
                                   quantized_multiplier, left_shift);
   e5032:	4629      	mov	r1, r5
   e5034:	4620      	mov	r0, r4
}
   e5036:	b005      	add	sp, #20
   e5038:	e8bd 40f0 	ldmia.w	sp!, {r4, r5, r6, r7, lr}
  const double input_beta_real_multiplier = std::min(
      beta * input_scale * (1 << (31 - input_integer_bits)), (1ll << 31) - 1.0);
#endif  // TFLITE_EMULATE_FLOAT

  QuantizeMultiplierGreaterThanOne(input_beta_real_multiplier,
                                   quantized_multiplier, left_shift);
   e503c:	f7ff bf7e 	b.w	e4f3c <_ZN6tflite32QuantizeMultiplierGreaterThanOneEdPlPi>
   e5040:	ffc00000 	.word	0xffc00000
   e5044:	41dfffff 	.word	0x41dfffff

000e5048 <_ZN6tflite20CalculateInputRadiusEiii>:
                                              reverse_scaling_divisor,
                                              reverse_scaling_left_shift);
}

int CalculateInputRadius(int input_integer_bits, int input_left_shift,
                         int total_signed_bits) {
   e5048:	e92d 4370 	stmdb	sp!, {r4, r5, r6, r8, r9, lr}
   e504c:	4604      	mov	r4, r0
      (1ll << (total_signed_bits - input_integer_bits)) /
      (1ll << input_left_shift);
  // Tighten bound using floor.  Suppose that we could use the exact value.
  // After scaling the difference, the result would be at the maximum.  Thus we
  // must ensure that our value has lower magnitude.
  return static_cast<int>(std::floor(max_input_rescaled));
   e504e:	2001      	movs	r0, #1
   e5050:	40a0      	lsls	r0, r4
   e5052:	3801      	subs	r0, #1
                                              reverse_scaling_divisor,
                                              reverse_scaling_left_shift);
}

int CalculateInputRadius(int input_integer_bits, int input_left_shift,
                         int total_signed_bits) {
   e5054:	460e      	mov	r6, r1
   e5056:	4615      	mov	r5, r2
      (1ll << (total_signed_bits - input_integer_bits)) /
      (1ll << input_left_shift);
  // Tighten bound using floor.  Suppose that we could use the exact value.
  // After scaling the difference, the result would be at the maximum.  Thus we
  // must ensure that our value has lower magnitude.
  return static_cast<int>(std::floor(max_input_rescaled));
   e5058:	f003 f97e 	bl	e8358 <__aeabi_i2d>
   e505c:	1b2a      	subs	r2, r5, r4
   e505e:	4680      	mov	r8, r0
   e5060:	4689      	mov	r9, r1
   e5062:	2001      	movs	r0, #1
   e5064:	2100      	movs	r1, #0
   e5066:	f003 f819 	bl	e809c <__aeabi_llsl>
   e506a:	f003 f9ad 	bl	e83c8 <__aeabi_l2d>
   e506e:	460b      	mov	r3, r1
   e5070:	4602      	mov	r2, r0
   e5072:	4649      	mov	r1, r9
   e5074:	4640      	mov	r0, r8
   e5076:	f003 f9d5 	bl	e8424 <__aeabi_dmul>
   e507a:	4632      	mov	r2, r6
   e507c:	4604      	mov	r4, r0
   e507e:	460d      	mov	r5, r1
   e5080:	2001      	movs	r0, #1
   e5082:	2100      	movs	r1, #0
   e5084:	f003 f80a 	bl	e809c <__aeabi_llsl>
   e5088:	f003 f99e 	bl	e83c8 <__aeabi_l2d>
   e508c:	4602      	mov	r2, r0
   e508e:	460b      	mov	r3, r1
   e5090:	4620      	mov	r0, r4
   e5092:	4629      	mov	r1, r5
   e5094:	f003 faf0 	bl	e8678 <__aeabi_ddiv>
   e5098:	ec41 0b10 	vmov	d0, r0, r1
   e509c:	f001 f9d4 	bl	e6448 <floor>
   e50a0:	ec51 0b10 	vmov	r0, r1, d0
   e50a4:	f003 fc58 	bl	e8958 <__aeabi_d2iz>
#endif  // TFLITE_EMULATE_FLOAT
}
   e50a8:	e8bd 8370 	ldmia.w	sp!, {r4, r5, r6, r8, r9, pc}

000e50ac <os_thread_is_current>:
DYNALIB_BEGIN(hal_concurrent)

#if PLATFORM_THREADING
DYNALIB_FN(0, hal_concurrent, __gthread_equal, bool(__gthread_t, __gthread_t))
DYNALIB_FN(1, hal_concurrent, os_thread_create, os_result_t(os_thread_t*, const char*, os_thread_prio_t, os_thread_fn_t, void*, size_t))
DYNALIB_FN(2, hal_concurrent, os_thread_is_current, bool(os_thread_t))
   e50ac:	b508      	push	{r3, lr}
   e50ae:	4b02      	ldr	r3, [pc, #8]	; (e50b8 <os_thread_is_current+0xc>)
   e50b0:	681b      	ldr	r3, [r3, #0]
   e50b2:	689b      	ldr	r3, [r3, #8]
   e50b4:	9301      	str	r3, [sp, #4]
   e50b6:	bd08      	pop	{r3, pc}
   e50b8:	00030248 	.word	0x00030248

000e50bc <os_thread_join>:
DYNALIB_FN(3, hal_concurrent, os_thread_yield, os_result_t(void))
DYNALIB_FN(4, hal_concurrent, os_thread_join, os_result_t(os_thread_t))
   e50bc:	b508      	push	{r3, lr}
   e50be:	4b02      	ldr	r3, [pc, #8]	; (e50c8 <os_thread_join+0xc>)
   e50c0:	681b      	ldr	r3, [r3, #0]
   e50c2:	691b      	ldr	r3, [r3, #16]
   e50c4:	9301      	str	r3, [sp, #4]
   e50c6:	bd08      	pop	{r3, pc}
   e50c8:	00030248 	.word	0x00030248

000e50cc <os_thread_cleanup>:
DYNALIB_FN(5, hal_concurrent, os_thread_cleanup, os_result_t(os_thread_t))
   e50cc:	b508      	push	{r3, lr}
   e50ce:	4b02      	ldr	r3, [pc, #8]	; (e50d8 <os_thread_cleanup+0xc>)
   e50d0:	681b      	ldr	r3, [r3, #0]
   e50d2:	695b      	ldr	r3, [r3, #20]
   e50d4:	9301      	str	r3, [sp, #4]
   e50d6:	bd08      	pop	{r3, pc}
   e50d8:	00030248 	.word	0x00030248

000e50dc <os_mutex_create>:
DYNALIB_FN(8, hal_concurrent, os_timer_create, int(os_timer_t*, unsigned, void(*)(os_timer_t), void*, bool, void*))
DYNALIB_FN(9, hal_concurrent, os_timer_destroy, int(os_timer_t, void*))
DYNALIB_FN(10, hal_concurrent, os_timer_get_id, int(os_timer_t, void**))
DYNALIB_FN(11, hal_concurrent, os_timer_change, int(os_timer_t, os_timer_change_t, bool, unsigned, unsigned, void*))

DYNALIB_FN(12, hal_concurrent, os_mutex_create, int(os_mutex_t*))
   e50dc:	b508      	push	{r3, lr}
   e50de:	4b02      	ldr	r3, [pc, #8]	; (e50e8 <os_mutex_create+0xc>)
   e50e0:	681b      	ldr	r3, [r3, #0]
   e50e2:	6b1b      	ldr	r3, [r3, #48]	; 0x30
   e50e4:	9301      	str	r3, [sp, #4]
   e50e6:	bd08      	pop	{r3, pc}
   e50e8:	00030248 	.word	0x00030248

000e50ec <os_mutex_recursive_create>:
DYNALIB_FN(13, hal_concurrent, os_mutex_destroy, int(os_mutex_t))
DYNALIB_FN(14, hal_concurrent, os_mutex_lock, int(os_mutex_t))
DYNALIB_FN(15, hal_concurrent, os_mutex_trylock, int(os_mutex_t))
DYNALIB_FN(16, hal_concurrent, os_mutex_unlock, int(os_mutex_t))

DYNALIB_FN(17, hal_concurrent, os_mutex_recursive_create, int(os_mutex_recursive_t*))
   e50ec:	b508      	push	{r3, lr}
   e50ee:	4b02      	ldr	r3, [pc, #8]	; (e50f8 <os_mutex_recursive_create+0xc>)
   e50f0:	681b      	ldr	r3, [r3, #0]
   e50f2:	6c5b      	ldr	r3, [r3, #68]	; 0x44
   e50f4:	9301      	str	r3, [sp, #4]
   e50f6:	bd08      	pop	{r3, pc}
   e50f8:	00030248 	.word	0x00030248

000e50fc <HAL_RNG_GetRandomNumber>:

DYNALIB_BEGIN(hal)

#if PLATFORM_ID > 3
DYNALIB_FN(0, hal, HAL_RNG_Configuration, void(void))
DYNALIB_FN(1, hal, HAL_RNG_GetRandomNumber, uint32_t(void))
   e50fc:	b508      	push	{r3, lr}
   e50fe:	4b02      	ldr	r3, [pc, #8]	; (e5108 <HAL_RNG_GetRandomNumber+0xc>)
   e5100:	681b      	ldr	r3, [r3, #0]
   e5102:	685b      	ldr	r3, [r3, #4]
   e5104:	9301      	str	r3, [sp, #4]
   e5106:	bd08      	pop	{r3, pc}
   e5108:	00030218 	.word	0x00030218

000e510c <HAL_Delay_Microseconds>:
#else
#define BASE_IDX 0
#endif

DYNALIB_FN(BASE_IDX + 0, hal, HAL_Delay_Milliseconds, void(uint32_t))
DYNALIB_FN(BASE_IDX + 1, hal, HAL_Delay_Microseconds, void(uint32_t))
   e510c:	b508      	push	{r3, lr}
   e510e:	4b02      	ldr	r3, [pc, #8]	; (e5118 <HAL_Delay_Microseconds+0xc>)
   e5110:	681b      	ldr	r3, [r3, #0]
   e5112:	68db      	ldr	r3, [r3, #12]
   e5114:	9301      	str	r3, [sp, #4]
   e5116:	bd08      	pop	{r3, pc}
   e5118:	00030218 	.word	0x00030218

000e511c <HAL_Timer_Get_Milli_Seconds>:
DYNALIB_FN(BASE_IDX + 2, hal, HAL_Timer_Get_Micro_Seconds, system_tick_t(void))
DYNALIB_FN(BASE_IDX + 3, hal, HAL_Timer_Get_Milli_Seconds, system_tick_t(void))
   e511c:	b508      	push	{r3, lr}
   e511e:	4b02      	ldr	r3, [pc, #8]	; (e5128 <HAL_Timer_Get_Milli_Seconds+0xc>)
   e5120:	681b      	ldr	r3, [r3, #0]
   e5122:	695b      	ldr	r3, [r3, #20]
   e5124:	9301      	str	r3, [sp, #4]
   e5126:	bd08      	pop	{r3, pc}
   e5128:	00030218 	.word	0x00030218

000e512c <HAL_Pin_Map>:
// New HAL functions must be added to the end of this list.
// GNINRAW

DYNALIB_BEGIN(hal_gpio)

DYNALIB_FN(0, hal_gpio, HAL_Pin_Map, Hal_Pin_Info*(void))
   e512c:	b508      	push	{r3, lr}
   e512e:	4b02      	ldr	r3, [pc, #8]	; (e5138 <HAL_Pin_Map+0xc>)
   e5130:	681b      	ldr	r3, [r3, #0]
   e5132:	681b      	ldr	r3, [r3, #0]
   e5134:	9301      	str	r3, [sp, #4]
   e5136:	bd08      	pop	{r3, pc}
   e5138:	0003022c 	.word	0x0003022c

000e513c <HAL_Validate_Pin_Function>:
DYNALIB_FN(1, hal_gpio, HAL_Validate_Pin_Function, PinFunction(pin_t, PinFunction))
   e513c:	b508      	push	{r3, lr}
   e513e:	4b02      	ldr	r3, [pc, #8]	; (e5148 <HAL_Validate_Pin_Function+0xc>)
   e5140:	681b      	ldr	r3, [r3, #0]
   e5142:	685b      	ldr	r3, [r3, #4]
   e5144:	9301      	str	r3, [sp, #4]
   e5146:	bd08      	pop	{r3, pc}
   e5148:	0003022c 	.word	0x0003022c

000e514c <HAL_Pin_Mode>:
DYNALIB_FN(2, hal_gpio, HAL_Pin_Mode, void(pin_t, PinMode))
   e514c:	b508      	push	{r3, lr}
   e514e:	4b02      	ldr	r3, [pc, #8]	; (e5158 <HAL_Pin_Mode+0xc>)
   e5150:	681b      	ldr	r3, [r3, #0]
   e5152:	689b      	ldr	r3, [r3, #8]
   e5154:	9301      	str	r3, [sp, #4]
   e5156:	bd08      	pop	{r3, pc}
   e5158:	0003022c 	.word	0x0003022c

000e515c <HAL_Get_Pin_Mode>:
DYNALIB_FN(3, hal_gpio, HAL_Get_Pin_Mode, PinMode(pin_t))
   e515c:	b508      	push	{r3, lr}
   e515e:	4b02      	ldr	r3, [pc, #8]	; (e5168 <HAL_Get_Pin_Mode+0xc>)
   e5160:	681b      	ldr	r3, [r3, #0]
   e5162:	68db      	ldr	r3, [r3, #12]
   e5164:	9301      	str	r3, [sp, #4]
   e5166:	bd08      	pop	{r3, pc}
   e5168:	0003022c 	.word	0x0003022c

000e516c <HAL_GPIO_Write>:
DYNALIB_FN(4, hal_gpio, HAL_GPIO_Write, void(pin_t, uint8_t))
   e516c:	b508      	push	{r3, lr}
   e516e:	4b02      	ldr	r3, [pc, #8]	; (e5178 <HAL_GPIO_Write+0xc>)
   e5170:	681b      	ldr	r3, [r3, #0]
   e5172:	691b      	ldr	r3, [r3, #16]
   e5174:	9301      	str	r3, [sp, #4]
   e5176:	bd08      	pop	{r3, pc}
   e5178:	0003022c 	.word	0x0003022c

000e517c <HAL_DAC_Write>:
DYNALIB_FN(6, hal_gpio, HAL_Interrupts_Attach, int(uint16_t, HAL_InterruptHandler, void*, InterruptMode, HAL_InterruptExtraConfiguration*))
DYNALIB_FN(7, hal_gpio, HAL_Interrupts_Detach, int(uint16_t))
DYNALIB_FN(8, hal_gpio, HAL_Interrupts_Enable_All, void(void))
DYNALIB_FN(9, hal_gpio, HAL_Interrupts_Disable_All, void(void))

DYNALIB_FN(10, hal_gpio, HAL_DAC_Write, void(pin_t, uint16_t))
   e517c:	b508      	push	{r3, lr}
   e517e:	4b02      	ldr	r3, [pc, #8]	; (e5188 <HAL_DAC_Write+0xc>)
   e5180:	681b      	ldr	r3, [r3, #0]
   e5182:	6a9b      	ldr	r3, [r3, #40]	; 0x28
   e5184:	9301      	str	r3, [sp, #4]
   e5186:	bd08      	pop	{r3, pc}
   e5188:	0003022c 	.word	0x0003022c

000e518c <HAL_PWM_Write_Ext>:
DYNALIB_FN(25, hal_gpio, HAL_DAC_Get_Resolution, uint8_t(pin_t))
DYNALIB_FN(26, hal_gpio, HAL_DAC_Set_Resolution, void(pin_t, uint8_t))
DYNALIB_FN(27, hal_gpio, HAL_DAC_Enable_Buffer, void(pin_t pin, uint8_t state))
DYNALIB_FN(28, hal_gpio, HAL_PWM_Get_Resolution, uint8_t(uint16_t))
DYNALIB_FN(29, hal_gpio, HAL_PWM_Set_Resolution, void(uint16_t, uint8_t))
DYNALIB_FN(30, hal_gpio, HAL_PWM_Write_Ext, void(uint16_t, uint32_t))
   e518c:	b508      	push	{r3, lr}
   e518e:	4b02      	ldr	r3, [pc, #8]	; (e5198 <HAL_PWM_Write_Ext+0xc>)
   e5190:	681b      	ldr	r3, [r3, #0]
   e5192:	6f9b      	ldr	r3, [r3, #120]	; 0x78
   e5194:	9301      	str	r3, [sp, #4]
   e5196:	bd08      	pop	{r3, pc}
   e5198:	0003022c 	.word	0x0003022c

000e519c <HAL_I2C_Write_Data>:
DYNALIB_FN(BASE_IDX + 3, hal_i2c, HAL_I2C_Begin, void(HAL_I2C_Interface, I2C_Mode, uint8_t, void*))
DYNALIB_FN(BASE_IDX + 4, hal_i2c, HAL_I2C_End, void(HAL_I2C_Interface, void*))
DYNALIB_FN(BASE_IDX + 5, hal_i2c, HAL_I2C_Request_Data, uint32_t(HAL_I2C_Interface, uint8_t, uint8_t, uint8_t, void*))
DYNALIB_FN(BASE_IDX + 6, hal_i2c, HAL_I2C_Begin_Transmission, void(HAL_I2C_Interface, uint8_t, void*))
DYNALIB_FN(BASE_IDX + 7, hal_i2c, HAL_I2C_End_Transmission, uint8_t(HAL_I2C_Interface, uint8_t, void*))
DYNALIB_FN(BASE_IDX + 8, hal_i2c, HAL_I2C_Write_Data, uint32_t(HAL_I2C_Interface, uint8_t, void*))
   e519c:	b508      	push	{r3, lr}
   e519e:	4b02      	ldr	r3, [pc, #8]	; (e51a8 <HAL_I2C_Write_Data+0xc>)
   e51a0:	681b      	ldr	r3, [r3, #0]
   e51a2:	6a1b      	ldr	r3, [r3, #32]
   e51a4:	9301      	str	r3, [sp, #4]
   e51a6:	bd08      	pop	{r3, pc}
   e51a8:	00030228 	.word	0x00030228

000e51ac <HAL_I2C_Available_Data>:
DYNALIB_FN(BASE_IDX + 9, hal_i2c, HAL_I2C_Available_Data, int32_t(HAL_I2C_Interface, void*))
   e51ac:	b508      	push	{r3, lr}
   e51ae:	4b02      	ldr	r3, [pc, #8]	; (e51b8 <HAL_I2C_Available_Data+0xc>)
   e51b0:	681b      	ldr	r3, [r3, #0]
   e51b2:	6a5b      	ldr	r3, [r3, #36]	; 0x24
   e51b4:	9301      	str	r3, [sp, #4]
   e51b6:	bd08      	pop	{r3, pc}
   e51b8:	00030228 	.word	0x00030228

000e51bc <HAL_I2C_Read_Data>:
DYNALIB_FN(BASE_IDX + 10, hal_i2c, HAL_I2C_Read_Data, int32_t(HAL_I2C_Interface, void*))
   e51bc:	b508      	push	{r3, lr}
   e51be:	4b02      	ldr	r3, [pc, #8]	; (e51c8 <HAL_I2C_Read_Data+0xc>)
   e51c0:	681b      	ldr	r3, [r3, #0]
   e51c2:	6a9b      	ldr	r3, [r3, #40]	; 0x28
   e51c4:	9301      	str	r3, [sp, #4]
   e51c6:	bd08      	pop	{r3, pc}
   e51c8:	00030228 	.word	0x00030228

000e51cc <HAL_I2C_Peek_Data>:
DYNALIB_FN(BASE_IDX + 11, hal_i2c, HAL_I2C_Peek_Data, int32_t(HAL_I2C_Interface, void*))
   e51cc:	b508      	push	{r3, lr}
   e51ce:	4b02      	ldr	r3, [pc, #8]	; (e51d8 <HAL_I2C_Peek_Data+0xc>)
   e51d0:	681b      	ldr	r3, [r3, #0]
   e51d2:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   e51d4:	9301      	str	r3, [sp, #4]
   e51d6:	bd08      	pop	{r3, pc}
   e51d8:	00030228 	.word	0x00030228

000e51dc <HAL_I2C_Flush_Data>:
DYNALIB_FN(BASE_IDX + 12, hal_i2c, HAL_I2C_Flush_Data, void(HAL_I2C_Interface, void*))
   e51dc:	b508      	push	{r3, lr}
   e51de:	4b02      	ldr	r3, [pc, #8]	; (e51e8 <HAL_I2C_Flush_Data+0xc>)
   e51e0:	681b      	ldr	r3, [r3, #0]
   e51e2:	6b1b      	ldr	r3, [r3, #48]	; 0x30
   e51e4:	9301      	str	r3, [sp, #4]
   e51e6:	bd08      	pop	{r3, pc}
   e51e8:	00030228 	.word	0x00030228

000e51ec <HAL_I2C_Is_Enabled>:
DYNALIB_FN(BASE_IDX + 13, hal_i2c, HAL_I2C_Is_Enabled, bool(HAL_I2C_Interface, void*))
   e51ec:	b508      	push	{r3, lr}
   e51ee:	4b02      	ldr	r3, [pc, #8]	; (e51f8 <HAL_I2C_Is_Enabled+0xc>)
   e51f0:	681b      	ldr	r3, [r3, #0]
   e51f2:	6b5b      	ldr	r3, [r3, #52]	; 0x34
   e51f4:	9301      	str	r3, [sp, #4]
   e51f6:	bd08      	pop	{r3, pc}
   e51f8:	00030228 	.word	0x00030228

000e51fc <HAL_I2C_Init>:
DYNALIB_FN(BASE_IDX + 14, hal_i2c, HAL_I2C_Set_Callback_On_Receive, void(HAL_I2C_Interface, void(*)(int), void*))
DYNALIB_FN(BASE_IDX + 15, hal_i2c, HAL_I2C_Set_Callback_On_Request, void(HAL_I2C_Interface, void(*)(void), void*))
DYNALIB_FN(BASE_IDX + 16, hal_i2c, HAL_I2C_Init, void(HAL_I2C_Interface, void*))
   e51fc:	b508      	push	{r3, lr}
   e51fe:	4b02      	ldr	r3, [pc, #8]	; (e5208 <HAL_I2C_Init+0xc>)
   e5200:	681b      	ldr	r3, [r3, #0]
   e5202:	6c1b      	ldr	r3, [r3, #64]	; 0x40
   e5204:	9301      	str	r3, [sp, #4]
   e5206:	bd08      	pop	{r3, pc}
   e5208:	00030228 	.word	0x00030228

000e520c <inet_inet_ntop>:
DYNALIB_FN(0, hal_inet, inet_inet_addr, in_addr_t(const char*))
DYNALIB_FN(1, hal_inet, inet_inet_aton, int(const char*, struct in_addr*))
DYNALIB_FN(2, hal_inet, inet_inet_network, in_addr_t(const char*))
DYNALIB_FN(3, hal_inet, inet_inet_ntoa, char*(struct in_addr))
DYNALIB_FN(4, hal_inet, inet_inet_ntoa_r, char*(struct in_addr, char*, socklen_t))
DYNALIB_FN(5, hal_inet, inet_inet_ntop, const char*(int, const void*, char*, socklen_t))
   e520c:	b508      	push	{r3, lr}
   e520e:	4b02      	ldr	r3, [pc, #8]	; (e5218 <inet_inet_ntop+0xc>)
   e5210:	681b      	ldr	r3, [r3, #0]
   e5212:	695b      	ldr	r3, [r3, #20]
   e5214:	9301      	str	r3, [sp, #4]
   e5216:	bd08      	pop	{r3, pc}
   e5218:	00030264 	.word	0x00030264

000e521c <netdb_freeaddrinfo>:

DYNALIB_BEGIN(hal_netdb)

DYNALIB_FN(0, hal_netdb, netdb_gethostbyname, struct hostent*(const char*))
DYNALIB_FN(1, hal_netdb, netdb_gethostbyname_r, int(const char*, struct hostent*, char*, size_t, struct hostent**, int*))
DYNALIB_FN(2, hal_netdb, netdb_freeaddrinfo, void(struct addrinfo*))
   e521c:	b508      	push	{r3, lr}
   e521e:	4b02      	ldr	r3, [pc, #8]	; (e5228 <netdb_freeaddrinfo+0xc>)
   e5220:	681b      	ldr	r3, [r3, #0]
   e5222:	689b      	ldr	r3, [r3, #8]
   e5224:	9301      	str	r3, [sp, #4]
   e5226:	bd08      	pop	{r3, pc}
   e5228:	00030268 	.word	0x00030268

000e522c <netdb_getaddrinfo>:
DYNALIB_FN(3, hal_netdb, netdb_getaddrinfo, int(const char*, const char*, const struct addrinfo*, struct addrinfo**))
   e522c:	b508      	push	{r3, lr}
   e522e:	4b02      	ldr	r3, [pc, #8]	; (e5238 <netdb_getaddrinfo+0xc>)
   e5230:	681b      	ldr	r3, [r3, #0]
   e5232:	68db      	ldr	r3, [r3, #12]
   e5234:	9301      	str	r3, [sp, #4]
   e5236:	bd08      	pop	{r3, pc}
   e5238:	00030268 	.word	0x00030268

000e523c <HAL_SPI_Begin>:
// New HAL functions must be added to the end of this list.
// GNINRAW

DYNALIB_BEGIN(hal_spi)

DYNALIB_FN(0, hal_spi, HAL_SPI_Begin, void(HAL_SPI_Interface, uint16_t))
   e523c:	b508      	push	{r3, lr}
   e523e:	4b02      	ldr	r3, [pc, #8]	; (e5248 <HAL_SPI_Begin+0xc>)
   e5240:	681b      	ldr	r3, [r3, #0]
   e5242:	681b      	ldr	r3, [r3, #0]
   e5244:	9301      	str	r3, [sp, #4]
   e5246:	bd08      	pop	{r3, pc}
   e5248:	00030230 	.word	0x00030230

000e524c <HAL_SPI_Set_Bit_Order>:
DYNALIB_FN(1, hal_spi, HAL_SPI_End, void(HAL_SPI_Interface))
DYNALIB_FN(2, hal_spi, HAL_SPI_Set_Bit_Order, void(HAL_SPI_Interface, uint8_t))
   e524c:	b508      	push	{r3, lr}
   e524e:	4b02      	ldr	r3, [pc, #8]	; (e5258 <HAL_SPI_Set_Bit_Order+0xc>)
   e5250:	681b      	ldr	r3, [r3, #0]
   e5252:	689b      	ldr	r3, [r3, #8]
   e5254:	9301      	str	r3, [sp, #4]
   e5256:	bd08      	pop	{r3, pc}
   e5258:	00030230 	.word	0x00030230

000e525c <HAL_SPI_Set_Data_Mode>:
DYNALIB_FN(3, hal_spi, HAL_SPI_Set_Data_Mode, void(HAL_SPI_Interface, uint8_t))
   e525c:	b508      	push	{r3, lr}
   e525e:	4b02      	ldr	r3, [pc, #8]	; (e5268 <HAL_SPI_Set_Data_Mode+0xc>)
   e5260:	681b      	ldr	r3, [r3, #0]
   e5262:	68db      	ldr	r3, [r3, #12]
   e5264:	9301      	str	r3, [sp, #4]
   e5266:	bd08      	pop	{r3, pc}
   e5268:	00030230 	.word	0x00030230

000e526c <HAL_SPI_Set_Clock_Divider>:
DYNALIB_FN(4, hal_spi, HAL_SPI_Set_Clock_Divider, void(HAL_SPI_Interface, uint8_t))
   e526c:	b508      	push	{r3, lr}
   e526e:	4b02      	ldr	r3, [pc, #8]	; (e5278 <HAL_SPI_Set_Clock_Divider+0xc>)
   e5270:	681b      	ldr	r3, [r3, #0]
   e5272:	691b      	ldr	r3, [r3, #16]
   e5274:	9301      	str	r3, [sp, #4]
   e5276:	bd08      	pop	{r3, pc}
   e5278:	00030230 	.word	0x00030230

000e527c <HAL_SPI_Send_Receive_Data>:
DYNALIB_FN(5, hal_spi, HAL_SPI_Send_Receive_Data, uint16_t(HAL_SPI_Interface, uint16_t))
   e527c:	b508      	push	{r3, lr}
   e527e:	4b02      	ldr	r3, [pc, #8]	; (e5288 <HAL_SPI_Send_Receive_Data+0xc>)
   e5280:	681b      	ldr	r3, [r3, #0]
   e5282:	695b      	ldr	r3, [r3, #20]
   e5284:	9301      	str	r3, [sp, #4]
   e5286:	bd08      	pop	{r3, pc}
   e5288:	00030230 	.word	0x00030230

000e528c <HAL_SPI_Init>:
DYNALIB_FN(6, hal_spi, HAL_SPI_Is_Enabled_Old, bool(void))
DYNALIB_FN(7, hal_spi, HAL_SPI_Init, void(HAL_SPI_Interface))
   e528c:	b508      	push	{r3, lr}
   e528e:	4b02      	ldr	r3, [pc, #8]	; (e5298 <HAL_SPI_Init+0xc>)
   e5290:	681b      	ldr	r3, [r3, #0]
   e5292:	69db      	ldr	r3, [r3, #28]
   e5294:	9301      	str	r3, [sp, #4]
   e5296:	bd08      	pop	{r3, pc}
   e5298:	00030230 	.word	0x00030230

000e529c <HAL_SPI_Is_Enabled>:
DYNALIB_FN(8, hal_spi, HAL_SPI_Is_Enabled, bool(HAL_SPI_Interface))
   e529c:	b508      	push	{r3, lr}
   e529e:	4b02      	ldr	r3, [pc, #8]	; (e52a8 <HAL_SPI_Is_Enabled+0xc>)
   e52a0:	681b      	ldr	r3, [r3, #0]
   e52a2:	6a1b      	ldr	r3, [r3, #32]
   e52a4:	9301      	str	r3, [sp, #4]
   e52a6:	bd08      	pop	{r3, pc}
   e52a8:	00030230 	.word	0x00030230

000e52ac <HAL_SPI_Info>:
DYNALIB_FN(9, hal_spi, HAL_SPI_Info, void(HAL_SPI_Interface, hal_spi_info_t*, void*))
   e52ac:	b508      	push	{r3, lr}
   e52ae:	4b02      	ldr	r3, [pc, #8]	; (e52b8 <HAL_SPI_Info+0xc>)
   e52b0:	681b      	ldr	r3, [r3, #0]
   e52b2:	6a5b      	ldr	r3, [r3, #36]	; 0x24
   e52b4:	9301      	str	r3, [sp, #4]
   e52b6:	bd08      	pop	{r3, pc}
   e52b8:	00030230 	.word	0x00030230

000e52bc <HAL_USART_Init>:
#define BASE_IDX 6 // Base index for all subsequent functions
#else
#define BASE_IDX 0
#endif

DYNALIB_FN(BASE_IDX + 0, hal_usart, HAL_USART_Init, void(HAL_USART_Serial, Ring_Buffer*, Ring_Buffer*))
   e52bc:	b508      	push	{r3, lr}
   e52be:	4b02      	ldr	r3, [pc, #8]	; (e52c8 <HAL_USART_Init+0xc>)
   e52c0:	681b      	ldr	r3, [r3, #0]
   e52c2:	681b      	ldr	r3, [r3, #0]
   e52c4:	9301      	str	r3, [sp, #4]
   e52c6:	bd08      	pop	{r3, pc}
   e52c8:	0003023c 	.word	0x0003023c

000e52cc <HAL_USART_Write_Data>:
DYNALIB_FN(BASE_IDX + 1, hal_usart, HAL_USART_Begin, void(HAL_USART_Serial, uint32_t))
DYNALIB_FN(BASE_IDX + 2, hal_usart, HAL_USART_End, void(HAL_USART_Serial))
DYNALIB_FN(BASE_IDX + 3, hal_usart, HAL_USART_Write_Data, uint32_t(HAL_USART_Serial, uint8_t))
   e52cc:	b508      	push	{r3, lr}
   e52ce:	4b02      	ldr	r3, [pc, #8]	; (e52d8 <HAL_USART_Write_Data+0xc>)
   e52d0:	681b      	ldr	r3, [r3, #0]
   e52d2:	68db      	ldr	r3, [r3, #12]
   e52d4:	9301      	str	r3, [sp, #4]
   e52d6:	bd08      	pop	{r3, pc}
   e52d8:	0003023c 	.word	0x0003023c

000e52dc <HAL_USART_Available_Data>:
DYNALIB_FN(BASE_IDX + 4, hal_usart, HAL_USART_Available_Data, int32_t(HAL_USART_Serial))
   e52dc:	b508      	push	{r3, lr}
   e52de:	4b02      	ldr	r3, [pc, #8]	; (e52e8 <HAL_USART_Available_Data+0xc>)
   e52e0:	681b      	ldr	r3, [r3, #0]
   e52e2:	691b      	ldr	r3, [r3, #16]
   e52e4:	9301      	str	r3, [sp, #4]
   e52e6:	bd08      	pop	{r3, pc}
   e52e8:	0003023c 	.word	0x0003023c

000e52ec <HAL_USART_Read_Data>:
DYNALIB_FN(BASE_IDX + 5, hal_usart, HAL_USART_Read_Data, int32_t(HAL_USART_Serial))
   e52ec:	b508      	push	{r3, lr}
   e52ee:	4b02      	ldr	r3, [pc, #8]	; (e52f8 <HAL_USART_Read_Data+0xc>)
   e52f0:	681b      	ldr	r3, [r3, #0]
   e52f2:	695b      	ldr	r3, [r3, #20]
   e52f4:	9301      	str	r3, [sp, #4]
   e52f6:	bd08      	pop	{r3, pc}
   e52f8:	0003023c 	.word	0x0003023c

000e52fc <HAL_USART_Peek_Data>:
DYNALIB_FN(BASE_IDX + 6, hal_usart, HAL_USART_Peek_Data, int32_t(HAL_USART_Serial))
   e52fc:	b508      	push	{r3, lr}
   e52fe:	4b02      	ldr	r3, [pc, #8]	; (e5308 <HAL_USART_Peek_Data+0xc>)
   e5300:	681b      	ldr	r3, [r3, #0]
   e5302:	699b      	ldr	r3, [r3, #24]
   e5304:	9301      	str	r3, [sp, #4]
   e5306:	bd08      	pop	{r3, pc}
   e5308:	0003023c 	.word	0x0003023c

000e530c <HAL_USART_Flush_Data>:
DYNALIB_FN(BASE_IDX + 7, hal_usart, HAL_USART_Flush_Data, void(HAL_USART_Serial))
   e530c:	b508      	push	{r3, lr}
   e530e:	4b02      	ldr	r3, [pc, #8]	; (e5318 <HAL_USART_Flush_Data+0xc>)
   e5310:	681b      	ldr	r3, [r3, #0]
   e5312:	69db      	ldr	r3, [r3, #28]
   e5314:	9301      	str	r3, [sp, #4]
   e5316:	bd08      	pop	{r3, pc}
   e5318:	0003023c 	.word	0x0003023c

000e531c <HAL_USART_Is_Enabled>:
DYNALIB_FN(BASE_IDX + 8, hal_usart, HAL_USART_Is_Enabled, bool(HAL_USART_Serial))
   e531c:	b508      	push	{r3, lr}
   e531e:	4b02      	ldr	r3, [pc, #8]	; (e5328 <HAL_USART_Is_Enabled+0xc>)
   e5320:	681b      	ldr	r3, [r3, #0]
   e5322:	6a1b      	ldr	r3, [r3, #32]
   e5324:	9301      	str	r3, [sp, #4]
   e5326:	bd08      	pop	{r3, pc}
   e5328:	0003023c 	.word	0x0003023c

000e532c <HAL_USART_Available_Data_For_Write>:
DYNALIB_FN(BASE_IDX + 9, hal_usart, HAL_USART_Half_Duplex, void(HAL_USART_Serial, bool))
DYNALIB_FN(BASE_IDX + 10, hal_usart, HAL_USART_Available_Data_For_Write, int32_t(HAL_USART_Serial))
   e532c:	b508      	push	{r3, lr}
   e532e:	4b02      	ldr	r3, [pc, #8]	; (e5338 <HAL_USART_Available_Data_For_Write+0xc>)
   e5330:	681b      	ldr	r3, [r3, #0]
   e5332:	6a9b      	ldr	r3, [r3, #40]	; 0x28
   e5334:	9301      	str	r3, [sp, #4]
   e5336:	bd08      	pop	{r3, pc}
   e5338:	0003023c 	.word	0x0003023c

000e533c <HAL_USB_USART_Init>:
#endif

DYNALIB_BEGIN(hal_usb)

#ifdef USB_CDC_ENABLE
DYNALIB_FN(0, hal_usb, HAL_USB_USART_Init, void(HAL_USB_USART_Serial, const HAL_USB_USART_Config*))
   e533c:	b508      	push	{r3, lr}
   e533e:	4b02      	ldr	r3, [pc, #8]	; (e5348 <HAL_USB_USART_Init+0xc>)
   e5340:	681b      	ldr	r3, [r3, #0]
   e5342:	681b      	ldr	r3, [r3, #0]
   e5344:	9301      	str	r3, [sp, #4]
   e5346:	bd08      	pop	{r3, pc}
   e5348:	0003024c 	.word	0x0003024c

000e534c <HAL_USB_USART_Begin>:
DYNALIB_FN(1, hal_usb, HAL_USB_USART_Begin, void(HAL_USB_USART_Serial, uint32_t, void *))
   e534c:	b508      	push	{r3, lr}
   e534e:	4b02      	ldr	r3, [pc, #8]	; (e5358 <HAL_USB_USART_Begin+0xc>)
   e5350:	681b      	ldr	r3, [r3, #0]
   e5352:	685b      	ldr	r3, [r3, #4]
   e5354:	9301      	str	r3, [sp, #4]
   e5356:	bd08      	pop	{r3, pc}
   e5358:	0003024c 	.word	0x0003024c

000e535c <HAL_USB_USART_Available_Data>:
DYNALIB_FN(2, hal_usb, HAL_USB_USART_End, void(HAL_USB_USART_Serial))
DYNALIB_FN(3, hal_usb, HAL_USB_USART_Baud_Rate, unsigned int(HAL_USB_USART_Serial))
DYNALIB_FN(4, hal_usb, HAL_USB_USART_Available_Data, int32_t(HAL_USB_USART_Serial))
   e535c:	b508      	push	{r3, lr}
   e535e:	4b02      	ldr	r3, [pc, #8]	; (e5368 <HAL_USB_USART_Available_Data+0xc>)
   e5360:	681b      	ldr	r3, [r3, #0]
   e5362:	691b      	ldr	r3, [r3, #16]
   e5364:	9301      	str	r3, [sp, #4]
   e5366:	bd08      	pop	{r3, pc}
   e5368:	0003024c 	.word	0x0003024c

000e536c <HAL_USB_USART_Available_Data_For_Write>:
DYNALIB_FN(5, hal_usb, HAL_USB_USART_Available_Data_For_Write, int32_t(HAL_USB_USART_Serial))
   e536c:	b508      	push	{r3, lr}
   e536e:	4b02      	ldr	r3, [pc, #8]	; (e5378 <HAL_USB_USART_Available_Data_For_Write+0xc>)
   e5370:	681b      	ldr	r3, [r3, #0]
   e5372:	695b      	ldr	r3, [r3, #20]
   e5374:	9301      	str	r3, [sp, #4]
   e5376:	bd08      	pop	{r3, pc}
   e5378:	0003024c 	.word	0x0003024c

000e537c <HAL_USB_USART_Receive_Data>:
DYNALIB_FN(6, hal_usb, HAL_USB_USART_Receive_Data, int32_t(HAL_USB_USART_Serial, uint8_t))
   e537c:	b508      	push	{r3, lr}
   e537e:	4b02      	ldr	r3, [pc, #8]	; (e5388 <HAL_USB_USART_Receive_Data+0xc>)
   e5380:	681b      	ldr	r3, [r3, #0]
   e5382:	699b      	ldr	r3, [r3, #24]
   e5384:	9301      	str	r3, [sp, #4]
   e5386:	bd08      	pop	{r3, pc}
   e5388:	0003024c 	.word	0x0003024c

000e538c <HAL_USB_USART_Send_Data>:
DYNALIB_FN(7, hal_usb, HAL_USB_USART_Send_Data, int32_t(HAL_USB_USART_Serial, uint8_t))
   e538c:	b508      	push	{r3, lr}
   e538e:	4b02      	ldr	r3, [pc, #8]	; (e5398 <HAL_USB_USART_Send_Data+0xc>)
   e5390:	681b      	ldr	r3, [r3, #0]
   e5392:	69db      	ldr	r3, [r3, #28]
   e5394:	9301      	str	r3, [sp, #4]
   e5396:	bd08      	pop	{r3, pc}
   e5398:	0003024c 	.word	0x0003024c

000e539c <HAL_USB_USART_Flush_Data>:
DYNALIB_FN(8, hal_usb, HAL_USB_USART_Flush_Data, void(HAL_USB_USART_Serial))
   e539c:	b508      	push	{r3, lr}
   e539e:	4b02      	ldr	r3, [pc, #8]	; (e53a8 <HAL_USB_USART_Flush_Data+0xc>)
   e53a0:	681b      	ldr	r3, [r3, #0]
   e53a2:	6a1b      	ldr	r3, [r3, #32]
   e53a4:	9301      	str	r3, [sp, #4]
   e53a6:	bd08      	pop	{r3, pc}
   e53a8:	0003024c 	.word	0x0003024c

000e53ac <panic_>:
DYNALIB_FN(9, services, LED_Toggle, void(Led_TypeDef))
DYNALIB_FN(10, services, LED_Fade, void(Led_TypeDef))
DYNALIB_FN(11, services, Get_LED_Brightness, uint8_t(void))

DYNALIB_FN(12, services, set_logger_output, void(debug_output_fn, LoggerOutputLevel)) // Deprecated
DYNALIB_FN(13, services, panic_, void(ePanicCode, void*, void(*)(uint32_t)))
   e53ac:	b508      	push	{r3, lr}
   e53ae:	4b02      	ldr	r3, [pc, #8]	; (e53b8 <panic_+0xc>)
   e53b0:	681b      	ldr	r3, [r3, #0]
   e53b2:	6b5b      	ldr	r3, [r3, #52]	; 0x34
   e53b4:	9301      	str	r3, [sp, #4]
   e53b6:	bd08      	pop	{r3, pc}
   e53b8:	00030260 	.word	0x00030260

000e53bc <set_system_mode>:
#endif

DYNALIB_BEGIN(system)

DYNALIB_FN(0, system, system_mode, System_Mode_TypeDef(void))
DYNALIB_FN(1, system, set_system_mode, void(System_Mode_TypeDef))
   e53bc:	b508      	push	{r3, lr}
   e53be:	4b02      	ldr	r3, [pc, #8]	; (e53c8 <set_system_mode+0xc>)
   e53c0:	681b      	ldr	r3, [r3, #0]
   e53c2:	685b      	ldr	r3, [r3, #4]
   e53c4:	9301      	str	r3, [sp, #4]
   e53c6:	bd08      	pop	{r3, pc}
   e53c8:	00030220 	.word	0x00030220

000e53cc <system_delay_ms>:

DYNALIB_FN(2, system, set_ymodem_serial_flash_update_handler, void(ymodem_serial_flash_update_handler))
DYNALIB_FN(3, system, system_firmwareUpdate, bool(Stream*, void*))
DYNALIB_FN(4, system, system_fileTransfer, bool(system_file_transfer_t*, void*))

DYNALIB_FN(5, system, system_delay_ms, void(unsigned long, bool))
   e53cc:	b508      	push	{r3, lr}
   e53ce:	4b02      	ldr	r3, [pc, #8]	; (e53d8 <system_delay_ms+0xc>)
   e53d0:	681b      	ldr	r3, [r3, #0]
   e53d2:	695b      	ldr	r3, [r3, #20]
   e53d4:	9301      	str	r3, [sp, #4]
   e53d6:	bd08      	pop	{r3, pc}
   e53d8:	00030220 	.word	0x00030220

000e53dc <system_thread_set_state>:
DYNALIB_FN(6, system, system_sleep, int(Spark_Sleep_TypeDef, long, uint32_t, void*))
DYNALIB_FN(7, system, system_sleep_pin, int(uint16_t, uint16_t, long, uint32_t, void*))
DYNALIB_FN(8, system, system_subscribe_event, int(system_event_t, system_event_handler_t*, void*))
DYNALIB_FN(9, system, system_unsubscribe_event, void(system_event_t, system_event_handler_t*, void*))
DYNALIB_FN(10, system, system_button_pushed_duration, uint16_t(uint8_t, void*))
DYNALIB_FN(11, system, system_thread_set_state, void(spark::feature::State, void*))
   e53dc:	b508      	push	{r3, lr}
   e53de:	4b02      	ldr	r3, [pc, #8]	; (e53e8 <system_thread_set_state+0xc>)
   e53e0:	681b      	ldr	r3, [r3, #0]
   e53e2:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   e53e4:	9301      	str	r3, [sp, #4]
   e53e6:	bd08      	pop	{r3, pc}
   e53e8:	00030220 	.word	0x00030220

000e53ec <system_ctrl_set_app_request_handler>:
DYNALIB_FN(BASE_IDX + 6, system, led_pattern_period, uint16_t(int, int, void*))
DYNALIB_FN(BASE_IDX + 7, system, system_set_tester_handlers, int(system_tester_handlers_t*, void*))
DYNALIB_FN(BASE_IDX + 8, system, system_format_diag_data, int(const uint16_t*, size_t, unsigned, appender_fn, void*, void*))

// Control requests
DYNALIB_FN(BASE_IDX + 9, system, system_ctrl_set_app_request_handler, int(ctrl_request_handler_fn, void*))
   e53ec:	b508      	push	{r3, lr}
   e53ee:	4b03      	ldr	r3, [pc, #12]	; (e53fc <system_ctrl_set_app_request_handler+0x10>)
   e53f0:	681b      	ldr	r3, [r3, #0]
   e53f2:	f8d3 3088 	ldr.w	r3, [r3, #136]	; 0x88
   e53f6:	9301      	str	r3, [sp, #4]
   e53f8:	bd08      	pop	{r3, pc}
   e53fa:	0000      	.short	0x0000
   e53fc:	00030220 	.word	0x00030220

000e5400 <system_ctrl_set_result>:
DYNALIB_FN(BASE_IDX + 10, system, system_ctrl_alloc_reply_data, int(ctrl_request*, size_t, void*))
DYNALIB_FN(BASE_IDX + 11, system, system_ctrl_free_request_data, void(ctrl_request*, void*))
DYNALIB_FN(BASE_IDX + 12, system, system_ctrl_set_result, void(ctrl_request*, int, ctrl_completion_handler_fn, void*, void*))
   e5400:	b508      	push	{r3, lr}
   e5402:	4b03      	ldr	r3, [pc, #12]	; (e5410 <system_ctrl_set_result+0x10>)
   e5404:	681b      	ldr	r3, [r3, #0]
   e5406:	f8d3 3094 	ldr.w	r3, [r3, #148]	; 0x94
   e540a:	9301      	str	r3, [sp, #4]
   e540c:	bd08      	pop	{r3, pc}
   e540e:	0000      	.short	0x0000
   e5410:	00030220 	.word	0x00030220

000e5414 <spark_set_random_seed_from_cloud_handler>:
DYNALIB_FN(10, system_cloud, spark_unsubscribe, void(void*))
DYNALIB_FN(11, system_cloud, spark_sync_time, bool(void*))
DYNALIB_FN(12, system_cloud, spark_sync_time_pending, bool(void*))
DYNALIB_FN(13, system_cloud, spark_sync_time_last, system_tick_t(time_t*, void*))
DYNALIB_FN(14, system_cloud, spark_set_connection_property, int(unsigned, unsigned, particle::protocol::connection_properties_t*, void*))
DYNALIB_FN(15, system_cloud, spark_set_random_seed_from_cloud_handler, int(void (*handler)(unsigned int), void*))
   e5414:	b508      	push	{r3, lr}
   e5416:	4b02      	ldr	r3, [pc, #8]	; (e5420 <spark_set_random_seed_from_cloud_handler+0xc>)
   e5418:	681b      	ldr	r3, [r3, #0]
   e541a:	6bdb      	ldr	r3, [r3, #60]	; 0x3c
   e541c:	9301      	str	r3, [sp, #4]
   e541e:	bd08      	pop	{r3, pc}
   e5420:	00030244 	.word	0x00030244

000e5424 <network_connect>:
#endif

DYNALIB_BEGIN(system_net)

DYNALIB_FN(0, system_net, network_config, const void*(network_handle_t, uint32_t, void*))
DYNALIB_FN(1, system_net, network_connect, void(network_handle_t, uint32_t, uint32_t, void*))
   e5424:	b508      	push	{r3, lr}
   e5426:	4b02      	ldr	r3, [pc, #8]	; (e5430 <network_connect+0xc>)
   e5428:	681b      	ldr	r3, [r3, #0]
   e542a:	685b      	ldr	r3, [r3, #4]
   e542c:	9301      	str	r3, [sp, #4]
   e542e:	bd08      	pop	{r3, pc}
   e5430:	00030240 	.word	0x00030240

000e5434 <network_connecting>:
DYNALIB_FN(2, system_net, network_connecting, bool(network_handle_t, uint32_t, void*))
   e5434:	b508      	push	{r3, lr}
   e5436:	4b02      	ldr	r3, [pc, #8]	; (e5440 <network_connecting+0xc>)
   e5438:	681b      	ldr	r3, [r3, #0]
   e543a:	689b      	ldr	r3, [r3, #8]
   e543c:	9301      	str	r3, [sp, #4]
   e543e:	bd08      	pop	{r3, pc}
   e5440:	00030240 	.word	0x00030240

000e5444 <network_disconnect>:
DYNALIB_FN(3, system_net, network_disconnect, void(network_handle_t, uint32_t, void*))
   e5444:	b508      	push	{r3, lr}
   e5446:	4b02      	ldr	r3, [pc, #8]	; (e5450 <network_disconnect+0xc>)
   e5448:	681b      	ldr	r3, [r3, #0]
   e544a:	68db      	ldr	r3, [r3, #12]
   e544c:	9301      	str	r3, [sp, #4]
   e544e:	bd08      	pop	{r3, pc}
   e5450:	00030240 	.word	0x00030240

000e5454 <network_ready>:
DYNALIB_FN(4, system_net, network_ready, bool(network_handle_t, uint32_t, void*))
   e5454:	b508      	push	{r3, lr}
   e5456:	4b02      	ldr	r3, [pc, #8]	; (e5460 <network_ready+0xc>)
   e5458:	681b      	ldr	r3, [r3, #0]
   e545a:	691b      	ldr	r3, [r3, #16]
   e545c:	9301      	str	r3, [sp, #4]
   e545e:	bd08      	pop	{r3, pc}
   e5460:	00030240 	.word	0x00030240

000e5464 <network_on>:
DYNALIB_FN(5, system_net, network_on, void(network_handle_t, uint32_t, uint32_t, void*))
   e5464:	b508      	push	{r3, lr}
   e5466:	4b02      	ldr	r3, [pc, #8]	; (e5470 <network_on+0xc>)
   e5468:	681b      	ldr	r3, [r3, #0]
   e546a:	695b      	ldr	r3, [r3, #20]
   e546c:	9301      	str	r3, [sp, #4]
   e546e:	bd08      	pop	{r3, pc}
   e5470:	00030240 	.word	0x00030240

000e5474 <network_off>:
DYNALIB_FN(6, system_net, network_off, void(network_handle_t, uint32_t, uint32_t, void*))
   e5474:	b508      	push	{r3, lr}
   e5476:	4b02      	ldr	r3, [pc, #8]	; (e5480 <network_off+0xc>)
   e5478:	681b      	ldr	r3, [r3, #0]
   e547a:	699b      	ldr	r3, [r3, #24]
   e547c:	9301      	str	r3, [sp, #4]
   e547e:	bd08      	pop	{r3, pc}
   e5480:	00030240 	.word	0x00030240

000e5484 <network_listen>:
DYNALIB_FN(7, system_net, network_listen, void(network_handle_t, uint32_t, void*))
   e5484:	b508      	push	{r3, lr}
   e5486:	4b02      	ldr	r3, [pc, #8]	; (e5490 <network_listen+0xc>)
   e5488:	681b      	ldr	r3, [r3, #0]
   e548a:	69db      	ldr	r3, [r3, #28]
   e548c:	9301      	str	r3, [sp, #4]
   e548e:	bd08      	pop	{r3, pc}
   e5490:	00030240 	.word	0x00030240

000e5494 <network_listening>:
DYNALIB_FN(8, system_net, network_listening, bool(network_handle_t, uint32_t, void*))
   e5494:	b508      	push	{r3, lr}
   e5496:	4b02      	ldr	r3, [pc, #8]	; (e54a0 <network_listening+0xc>)
   e5498:	681b      	ldr	r3, [r3, #0]
   e549a:	6a1b      	ldr	r3, [r3, #32]
   e549c:	9301      	str	r3, [sp, #4]
   e549e:	bd08      	pop	{r3, pc}
   e54a0:	00030240 	.word	0x00030240

000e54a4 <network_set_listen_timeout>:
DYNALIB_FN(9, system_net, network_has_credentials, bool(network_handle_t, uint32_t, void*))
DYNALIB_FN(10, system_net, network_set_credentials, int(network_handle_t, uint32_t, NetworkCredentials*, void*))
DYNALIB_FN(11, system_net, network_clear_credentials, bool(network_handle_t, uint32_t, NetworkCredentials*, void*))
DYNALIB_FN(12, system_net, network_set_listen_timeout, void(network_handle_t, uint16_t, void*))
   e54a4:	b508      	push	{r3, lr}
   e54a6:	4b02      	ldr	r3, [pc, #8]	; (e54b0 <network_set_listen_timeout+0xc>)
   e54a8:	681b      	ldr	r3, [r3, #0]
   e54aa:	6b1b      	ldr	r3, [r3, #48]	; 0x30
   e54ac:	9301      	str	r3, [sp, #4]
   e54ae:	bd08      	pop	{r3, pc}
   e54b0:	00030240 	.word	0x00030240

000e54b4 <network_get_listen_timeout>:
DYNALIB_FN(13, system_net, network_get_listen_timeout, uint16_t(network_handle_t, uint32_t, void*))
   e54b4:	b508      	push	{r3, lr}
   e54b6:	4b02      	ldr	r3, [pc, #8]	; (e54c0 <network_get_listen_timeout+0xc>)
   e54b8:	681b      	ldr	r3, [r3, #0]
   e54ba:	6b5b      	ldr	r3, [r3, #52]	; 0x34
   e54bc:	9301      	str	r3, [sp, #4]
   e54be:	bd08      	pop	{r3, pc}
   e54c0:	00030240 	.word	0x00030240

000e54c4 <malloc>:
#include <assert.h>
#endif

DYNALIB_BEGIN(rt)

DYNALIB_FN(0, rt, malloc, void*(size_t))
   e54c4:	b508      	push	{r3, lr}
   e54c6:	4b02      	ldr	r3, [pc, #8]	; (e54d0 <malloc+0xc>)
   e54c8:	681b      	ldr	r3, [r3, #0]
   e54ca:	681b      	ldr	r3, [r3, #0]
   e54cc:	9301      	str	r3, [sp, #4]
   e54ce:	bd08      	pop	{r3, pc}
   e54d0:	0003021c 	.word	0x0003021c

000e54d4 <free>:
DYNALIB_FN(1, rt, free, void(void*))
   e54d4:	b508      	push	{r3, lr}
   e54d6:	4b02      	ldr	r3, [pc, #8]	; (e54e0 <free+0xc>)
   e54d8:	681b      	ldr	r3, [r3, #0]
   e54da:	685b      	ldr	r3, [r3, #4]
   e54dc:	9301      	str	r3, [sp, #4]
   e54de:	bd08      	pop	{r3, pc}
   e54e0:	0003021c 	.word	0x0003021c

000e54e4 <vsnprintf>:
DYNALIB_FN(4, rt, siprintf, int(char*, const char*, ...))
DYNALIB_FN(5, rt, sscanf, int(const char*, const char*, ...))
DYNALIB_FN(6, rt, siscanf, int(const char*, const char*, ...))
DYNALIB_FN(7, rt, snprintf, int(char*, size_t, const char*, ...))
DYNALIB_FN(8, rt, sniprintf, int(char*, size_t, const char*, ...))
DYNALIB_FN(9, rt, vsnprintf, int(char*, size_t, const char*, va_list))
   e54e4:	b508      	push	{r3, lr}
   e54e6:	4b02      	ldr	r3, [pc, #8]	; (e54f0 <vsnprintf+0xc>)
   e54e8:	681b      	ldr	r3, [r3, #0]
   e54ea:	6a5b      	ldr	r3, [r3, #36]	; 0x24
   e54ec:	9301      	str	r3, [sp, #4]
   e54ee:	bd08      	pop	{r3, pc}
   e54f0:	0003021c 	.word	0x0003021c

000e54f4 <abort>:
DYNALIB_FN(10, rt, vsniprintf, int(char*, size_t, const char*, va_list))
DYNALIB_FN(11, rt, abort, void(void))
   e54f4:	b508      	push	{r3, lr}
   e54f6:	4b02      	ldr	r3, [pc, #8]	; (e5500 <abort+0xc>)
   e54f8:	681b      	ldr	r3, [r3, #0]
   e54fa:	6adb      	ldr	r3, [r3, #44]	; 0x2c
   e54fc:	9301      	str	r3, [sp, #4]
   e54fe:	bd08      	pop	{r3, pc}
   e5500:	0003021c 	.word	0x0003021c

000e5504 <__errno>:
DYNALIB_FN(12, rt, _malloc_r, void*(struct _reent*, size_t))
DYNALIB_FN(13, rt, _free_r, void(struct _reent*, void*))
DYNALIB_FN(14, rt, _realloc_r, void*(struct _reent*, void*, size_t))
DYNALIB_FN(15, rt, __errno, int*())
   e5504:	b508      	push	{r3, lr}
   e5506:	4b02      	ldr	r3, [pc, #8]	; (e5510 <__errno+0xc>)
   e5508:	681b      	ldr	r3, [r3, #0]
   e550a:	6bdb      	ldr	r3, [r3, #60]	; 0x3c
   e550c:	9301      	str	r3, [sp, #4]
   e550e:	bd08      	pop	{r3, pc}
   e5510:	0003021c 	.word	0x0003021c

000e5514 <__assert_func>:
// on Gen 2 platforms without breaking inter-module dependencies.
// RT is currently being imported into system-part1 from system-part2,
// which is the reverse direction.

#if defined(DYNALIB_IMPORT) && !defined(RT_DYNALIB_NO_DEPENDENCY_BREAKING_IMPORTS)
DYNALIB_FN(16, rt, __assert_func, void(const char*, int, const char*, const char*))
   e5514:	b508      	push	{r3, lr}
   e5516:	4b02      	ldr	r3, [pc, #8]	; (e5520 <__assert_func+0xc>)
   e5518:	681b      	ldr	r3, [r3, #0]
   e551a:	6c1b      	ldr	r3, [r3, #64]	; 0x40
   e551c:	9301      	str	r3, [sp, #4]
   e551e:	bd08      	pop	{r3, pc}
   e5520:	0003021c 	.word	0x0003021c

000e5524 <_Z3mapddddd>:
    }
    return (value - fromStart) * (toEnd - toStart) / (fromEnd - fromStart) + toStart;
}

double map(double value, double fromStart, double fromEnd, double toStart, double toEnd)
{
   e5524:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e5528:	ed2d 8b02 	vpush	{d8}
   e552c:	eeb0 8a44 	vmov.f32	s16, s8
   e5530:	eef0 8a64 	vmov.f32	s17, s9
   e5534:	ec55 4b11 	vmov	r4, r5, d1
   e5538:	ec57 6b12 	vmov	r6, r7, d2
   e553c:	b083      	sub	sp, #12
    if (fromEnd == fromStart) {
   e553e:	ee11 2a10 	vmov	r2, s2
   e5542:	462b      	mov	r3, r5
   e5544:	ee12 0a10 	vmov	r0, s4
   e5548:	4639      	mov	r1, r7
    }
    return (value - fromStart) * (toEnd - toStart) / (fromEnd - fromStart) + toStart;
}

double map(double value, double fromStart, double fromEnd, double toStart, double toEnd)
{
   e554a:	ed8d 0b00 	vstr	d0, [sp]
   e554e:	ec5b ab13 	vmov	sl, fp, d3
    if (fromEnd == fromStart) {
   e5552:	f003 f9cf 	bl	e88f4 <__aeabi_dcmpeq>
   e5556:	ed9d 0b00 	vldr	d0, [sp]
   e555a:	bb38      	cbnz	r0, e55ac <_Z3mapddddd+0x88>
        return value;
    }
    return (value - fromStart) * (toEnd - toStart) / (fromEnd - fromStart) + toStart;
   e555c:	ec51 0b10 	vmov	r0, r1, d0
   e5560:	4622      	mov	r2, r4
   e5562:	462b      	mov	r3, r5
   e5564:	f002 fdaa 	bl	e80bc <__aeabi_dsub>
   e5568:	4652      	mov	r2, sl
   e556a:	4680      	mov	r8, r0
   e556c:	4689      	mov	r9, r1
   e556e:	465b      	mov	r3, fp
   e5570:	ec51 0b18 	vmov	r0, r1, d8
   e5574:	f002 fda2 	bl	e80bc <__aeabi_dsub>
   e5578:	4602      	mov	r2, r0
   e557a:	460b      	mov	r3, r1
   e557c:	4640      	mov	r0, r8
   e557e:	4649      	mov	r1, r9
   e5580:	f002 ff50 	bl	e8424 <__aeabi_dmul>
   e5584:	4622      	mov	r2, r4
   e5586:	4680      	mov	r8, r0
   e5588:	4689      	mov	r9, r1
   e558a:	462b      	mov	r3, r5
   e558c:	4630      	mov	r0, r6
   e558e:	4639      	mov	r1, r7
   e5590:	f002 fd94 	bl	e80bc <__aeabi_dsub>
   e5594:	4602      	mov	r2, r0
   e5596:	460b      	mov	r3, r1
   e5598:	4640      	mov	r0, r8
   e559a:	4649      	mov	r1, r9
   e559c:	f003 f86c 	bl	e8678 <__aeabi_ddiv>
   e55a0:	4652      	mov	r2, sl
   e55a2:	465b      	mov	r3, fp
   e55a4:	f002 fd8c 	bl	e80c0 <__adddf3>
   e55a8:	ec41 0b10 	vmov	d0, r0, r1
}
   e55ac:	b003      	add	sp, #12
   e55ae:	ecbd 8b02 	vpop	{d8}
   e55b2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

000e55b6 <delay>:

void delay(unsigned long ms)
{
    system_delay_ms(ms, false);
   e55b6:	2100      	movs	r1, #0
   e55b8:	f7ff bf08 	b.w	e53cc <system_delay_ms>

000e55bc <_GLOBAL__sub_I__ZN8particle3ble13WiringBleLock6mutex_E>:
    /**
     * Creates a shared mutex.
     */
    RecursiveMutex(os_mutex_recursive_t handle) : handle_(handle) {}

    RecursiveMutex() : handle_(nullptr)
   e55bc:	4802      	ldr	r0, [pc, #8]	; (e55c8 <_GLOBAL__sub_I__ZN8particle3ble13WiringBleLock6mutex_E+0xc>)
   e55be:	2300      	movs	r3, #0
   e55c0:	6003      	str	r3, [r0, #0]
    {
        os_mutex_recursive_create(&handle_);
   e55c2:	f7ff bd93 	b.w	e50ec <os_mutex_recursive_create>
   e55c6:	bf00      	nop
   e55c8:	2003e3d4 	.word	0x2003e3d4

000e55cc <_ZNSt14_Function_baseD1Ev>:
	}
      };

    _Function_base() : _M_manager(nullptr) { }

    ~_Function_base()
   e55cc:	b510      	push	{r4, lr}
    {
      if (_M_manager)
   e55ce:	6883      	ldr	r3, [r0, #8]
	}
      };

    _Function_base() : _M_manager(nullptr) { }

    ~_Function_base()
   e55d0:	4604      	mov	r4, r0
    {
      if (_M_manager)
   e55d2:	b113      	cbz	r3, e55da <_ZNSt14_Function_baseD1Ev+0xe>
	_M_manager(_M_functor, _M_functor, __destroy_functor);
   e55d4:	2203      	movs	r2, #3
   e55d6:	4601      	mov	r1, r0
   e55d8:	4798      	blx	r3
    }
   e55da:	4620      	mov	r0, r4
   e55dc:	bd10      	pop	{r4, pc}

000e55de <_ZN5spark13EthernetClass9listeningEv>:
    uint16_t getListenTimeout(void) {
        return network_get_listen_timeout(*this, 0, NULL);
    }

    bool listening(void) {
        return network_listening(*this, 0, NULL);
   e55de:	2200      	movs	r2, #0
   e55e0:	4611      	mov	r1, r2
   e55e2:	6840      	ldr	r0, [r0, #4]
   e55e4:	f7ff bf56 	b.w	e5494 <network_listening>

000e55e8 <_ZN5spark13EthernetClass16getListenTimeoutEv>:
    void setListenTimeout(uint16_t timeout) {
        network_set_listen_timeout(*this, timeout, NULL);
    }

    uint16_t getListenTimeout(void) {
        return network_get_listen_timeout(*this, 0, NULL);
   e55e8:	2200      	movs	r2, #0
   e55ea:	4611      	mov	r1, r2
   e55ec:	6840      	ldr	r0, [r0, #4]
   e55ee:	f7ff bf61 	b.w	e54b4 <network_get_listen_timeout>

000e55f2 <_ZN5spark13EthernetClass16setListenTimeoutEt>:
    void listen(bool begin=true) {
        network_listen(*this, begin ? 0 : 1, NULL);
    }

    void setListenTimeout(uint16_t timeout) {
        network_set_listen_timeout(*this, timeout, NULL);
   e55f2:	2200      	movs	r2, #0
   e55f4:	6840      	ldr	r0, [r0, #4]
   e55f6:	f7ff bf55 	b.w	e54a4 <network_set_listen_timeout>

000e55fa <_ZN5spark13EthernetClass6listenEb>:
    void disconnect() {
        network_disconnect(*this, NETWORK_DISCONNECT_REASON_USER, NULL);
    }

    void listen(bool begin=true) {
        network_listen(*this, begin ? 0 : 1, NULL);
   e55fa:	2200      	movs	r2, #0
   e55fc:	f081 0101 	eor.w	r1, r1, #1
   e5600:	6840      	ldr	r0, [r0, #4]
   e5602:	f7ff bf3f 	b.w	e5484 <network_listen>

000e5606 <_ZN5spark13EthernetClass3offEv>:
    void on() {
        network_on(*this, 0, 0, NULL);
    }

    void off() {
        network_off(*this, 0, 0, NULL);
   e5606:	2300      	movs	r3, #0
   e5608:	461a      	mov	r2, r3
   e560a:	4619      	mov	r1, r3
   e560c:	6840      	ldr	r0, [r0, #4]
   e560e:	f7ff bf31 	b.w	e5474 <network_off>

000e5612 <_ZN5spark13EthernetClass2onEv>:
    EthernetClass() :
            NetworkClass(NETWORK_INTERFACE_ETHERNET) {
    }

    void on() {
        network_on(*this, 0, 0, NULL);
   e5612:	2300      	movs	r3, #0
   e5614:	461a      	mov	r2, r3
   e5616:	4619      	mov	r1, r3
   e5618:	6840      	ldr	r0, [r0, #4]
   e561a:	f7ff bf23 	b.w	e5464 <network_on>

000e561e <_ZN5spark13EthernetClass5readyEv>:
    bool listening(void) {
        return network_listening(*this, 0, NULL);
    }

    bool ready() {
        return network_ready(*this, 0,  NULL);
   e561e:	2200      	movs	r2, #0
   e5620:	4611      	mov	r1, r2
   e5622:	6840      	ldr	r0, [r0, #4]
   e5624:	f7ff bf16 	b.w	e5454 <network_ready>

000e5628 <_ZN5spark13EthernetClass10connectingEv>:
    void connect(unsigned flags=0) {
        network_connect(*this, flags, 0, NULL);
    }

    bool connecting(void) {
        return network_connecting(*this, 0, NULL);
   e5628:	2200      	movs	r2, #0
   e562a:	4611      	mov	r1, r2
   e562c:	6840      	ldr	r0, [r0, #4]
   e562e:	f7ff bf01 	b.w	e5434 <network_connecting>

000e5632 <_ZN5spark13EthernetClass10disconnectEv>:
    }

    void disconnect() {
        network_disconnect(*this, NETWORK_DISCONNECT_REASON_USER, NULL);
   e5632:	2200      	movs	r2, #0
   e5634:	2102      	movs	r1, #2
   e5636:	6840      	ldr	r0, [r0, #4]
   e5638:	f7ff bf04 	b.w	e5444 <network_disconnect>

000e563c <_ZN5spark13EthernetClass7connectEj>:
    void off() {
        network_off(*this, 0, 0, NULL);
    }

    void connect(unsigned flags=0) {
        network_connect(*this, flags, 0, NULL);
   e563c:	2300      	movs	r3, #0
   e563e:	461a      	mov	r2, r3
   e5640:	6840      	ldr	r0, [r0, #4]
   e5642:	f7ff beef 	b.w	e5424 <network_connect>
	...

000e5648 <_GLOBAL__sub_I__ZN5spark8EthernetE>:
    static NetworkClass& from(network_interface_t nif);

    virtual IPAddress resolve(const char* name);

    explicit NetworkClass(network_interface_t iface)
            : iface_(iface) {
   e5648:	4b02      	ldr	r3, [pc, #8]	; (e5654 <_GLOBAL__sub_I__ZN5spark8EthernetE+0xc>)
   e564a:	2203      	movs	r2, #3
   e564c:	605a      	str	r2, [r3, #4]
    }

class EthernetClass : public NetworkClass {
public:
    EthernetClass() :
            NetworkClass(NETWORK_INTERFACE_ETHERNET) {
   e564e:	4a02      	ldr	r2, [pc, #8]	; (e5658 <_GLOBAL__sub_I__ZN5spark8EthernetE+0x10>)
   e5650:	601a      	str	r2, [r3, #0]
   e5652:	4770      	bx	lr
   e5654:	2003e3d8 	.word	0x2003e3d8
   e5658:	000ecde0 	.word	0x000ecde0

000e565c <_ZN7TwoWireD1Ev>:
private:
  HAL_I2C_Interface _i2c;

public:
  TwoWire(HAL_I2C_Interface i2c);
  virtual ~TwoWire() {};
   e565c:	4770      	bx	lr

000e565e <_ZN7TwoWire5writeEPKhj>:

// must be called in:
// slave tx event callback
// or after beginTransmission(address)
size_t TwoWire::write(const uint8_t *data, size_t quantity)
{
   e565e:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
   e5660:	4606      	mov	r6, r0
   e5662:	4615      	mov	r5, r2
   e5664:	460c      	mov	r4, r1
   e5666:	188f      	adds	r7, r1, r2
  // in master/slave transmitter mode
  for(size_t i = 0; i < quantity; ++i)
   e5668:	42bc      	cmp	r4, r7
   e566a:	d006      	beq.n	e567a <_ZN7TwoWire5writeEPKhj+0x1c>
  {
    write(data[i]);
   e566c:	6833      	ldr	r3, [r6, #0]
   e566e:	f814 1b01 	ldrb.w	r1, [r4], #1
   e5672:	689b      	ldr	r3, [r3, #8]
   e5674:	4630      	mov	r0, r6
   e5676:	4798      	blx	r3
// slave tx event callback
// or after beginTransmission(address)
size_t TwoWire::write(const uint8_t *data, size_t quantity)
{
  // in master/slave transmitter mode
  for(size_t i = 0; i < quantity; ++i)
   e5678:	e7f6      	b.n	e5668 <_ZN7TwoWire5writeEPKhj+0xa>
  {
    write(data[i]);
  }

  return quantity;
}
   e567a:	4628      	mov	r0, r5
   e567c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

000e567e <_ZN7TwoWire5writeEh>:
// must be called in:
// slave tx event callback
// or after beginTransmission(address)
size_t TwoWire::write(uint8_t data)
{
  return HAL_I2C_Write_Data(_i2c, data, NULL);
   e567e:	2200      	movs	r2, #0
   e5680:	7c00      	ldrb	r0, [r0, #16]
   e5682:	f7ff bd8b 	b.w	e519c <HAL_I2C_Write_Data>

000e5686 <_ZN7TwoWire9availableEv>:
// must be called in:
// slave rx event callback
// or after requestFrom(address, numBytes)
int TwoWire::available(void)
{
  return HAL_I2C_Available_Data(_i2c, NULL);
   e5686:	2100      	movs	r1, #0
   e5688:	7c00      	ldrb	r0, [r0, #16]
   e568a:	f7ff bd8f 	b.w	e51ac <HAL_I2C_Available_Data>

000e568e <_ZN7TwoWire4readEv>:
// must be called in:
// slave rx event callback
// or after requestFrom(address, numBytes)
int TwoWire::read(void)
{
  return HAL_I2C_Read_Data(_i2c, NULL);
   e568e:	2100      	movs	r1, #0
   e5690:	7c00      	ldrb	r0, [r0, #16]
   e5692:	f7ff bd93 	b.w	e51bc <HAL_I2C_Read_Data>

000e5696 <_ZN7TwoWire4peekEv>:
// must be called in:
// slave rx event callback
// or after requestFrom(address, numBytes)
int TwoWire::peek(void)
{
  return HAL_I2C_Peek_Data(_i2c, NULL);
   e5696:	2100      	movs	r1, #0
   e5698:	7c00      	ldrb	r0, [r0, #16]
   e569a:	f7ff bd97 	b.w	e51cc <HAL_I2C_Peek_Data>

000e569e <_ZN7TwoWire5flushEv>:
}

void TwoWire::flush(void)
{
  HAL_I2C_Flush_Data(_i2c, NULL);
   e569e:	2100      	movs	r1, #0
   e56a0:	7c00      	ldrb	r0, [r0, #16]
   e56a2:	f7ff bd9b 	b.w	e51dc <HAL_I2C_Flush_Data>

000e56a6 <_ZN7TwoWireD0Ev>:
   e56a6:	b510      	push	{r4, lr}
   e56a8:	2114      	movs	r1, #20
   e56aa:	4604      	mov	r4, r0
   e56ac:	f000 fd81 	bl	e61b2 <_ZdlPvj>
   e56b0:	4620      	mov	r0, r4
   e56b2:	bd10      	pop	{r4, pc}

000e56b4 <_ZN7TwoWireC1E17HAL_I2C_Interface>:
#include "i2c_hal.h"
#include "spark_wiring_thread.h"

// Constructors ////////////////////////////////////////////////////////////////

TwoWire::TwoWire(HAL_I2C_Interface i2c)
   e56b4:	b510      	push	{r4, lr}
   e56b6:	4604      	mov	r4, r0
    virtual int available() = 0;
    virtual int read() = 0;
    virtual int peek() = 0;
    virtual void flush() = 0;

    Stream() {_timeout=1000;}
   e56b8:	f44f 737a 	mov.w	r3, #1000	; 0x3e8
   e56bc:	4608      	mov	r0, r1
   e56be:	60a3      	str	r3, [r4, #8]
  protected:
    void setWriteError(int err = 1) { write_error = err; }
    size_t printf_impl(bool newline, const char* format, ...);

  public:
    Print() : write_error(0) {}
   e56c0:	2100      	movs	r1, #0
   e56c2:	4b04      	ldr	r3, [pc, #16]	; (e56d4 <_ZN7TwoWireC1E17HAL_I2C_Interface+0x20>)
{
  _i2c = i2c;
   e56c4:	7420      	strb	r0, [r4, #16]
   e56c6:	6061      	str	r1, [r4, #4]
#include "i2c_hal.h"
#include "spark_wiring_thread.h"

// Constructors ////////////////////////////////////////////////////////////////

TwoWire::TwoWire(HAL_I2C_Interface i2c)
   e56c8:	6023      	str	r3, [r4, #0]
{
  _i2c = i2c;
  HAL_I2C_Init(_i2c, NULL);
   e56ca:	f7ff fd97 	bl	e51fc <HAL_I2C_Init>

}
   e56ce:	4620      	mov	r0, r4
   e56d0:	bd10      	pop	{r4, pc}
   e56d2:	bf00      	nop
   e56d4:	000ece14 	.word	0x000ece14

000e56d8 <_ZN7TwoWire9isEnabledEv>:
  HAL_I2C_Set_Callback_On_Request(_i2c, function, NULL);
}

bool TwoWire::isEnabled()
{
  return HAL_I2C_Is_Enabled(_i2c, NULL);
   e56d8:	2100      	movs	r1, #0
   e56da:	7c00      	ldrb	r0, [r0, #16]
   e56dc:	f7ff bd86 	b.w	e51ec <HAL_I2C_Is_Enabled>

000e56e0 <_ZN9IPAddressD1Ev>:
    IPAddress(uint8_t first_octet, uint8_t second_octet, uint8_t third_octet, uint8_t fourth_octet);
    IPAddress(uint32_t address);
    IPAddress(const uint8_t* address);
    IPAddress(const HAL_IPAddress& address);

    virtual ~IPAddress() {}
   e56e0:	4770      	bx	lr

000e56e2 <_ZN9IPAddressD0Ev>:
   e56e2:	b510      	push	{r4, lr}
   e56e4:	2118      	movs	r1, #24
   e56e6:	4604      	mov	r4, r0
   e56e8:	f000 fd63 	bl	e61b2 <_ZdlPvj>
   e56ec:	4620      	mov	r0, r4
   e56ee:	bd10      	pop	{r4, pc}

000e56f0 <_ZNK9IPAddress7printToER5Print>:
#endif // Wiring_IPv6
	return address.ipv4==that.address.ipv4;
}

size_t IPAddress::printTo(Print& p) const
{
   e56f0:	b5f0      	push	{r4, r5, r6, r7, lr}
#if Wiring_IPv6
#if HAL_USE_INET_HAL_POSIX
	if (address.v==6) {
   e56f2:	7d03      	ldrb	r3, [r0, #20]
   e56f4:	2b06      	cmp	r3, #6
#endif // Wiring_IPv6
	return address.ipv4==that.address.ipv4;
}

size_t IPAddress::printTo(Print& p) const
{
   e56f6:	b08d      	sub	sp, #52	; 0x34
   e56f8:	460e      	mov	r6, r1
   e56fa:	f100 0704 	add.w	r7, r0, #4
   e56fe:	f04f 0400 	mov.w	r4, #0
#if Wiring_IPv6
#if HAL_USE_INET_HAL_POSIX
	if (address.v==6) {
   e5702:	d002      	beq.n	e570a <_ZNK9IPAddress7printToER5Print+0x1a>
   e5704:	f100 0508 	add.w	r5, r0, #8
   e5708:	e018      	b.n	e573c <_ZNK9IPAddress7printToER5Print+0x4c>
		char buf[INET6_ADDRSTRLEN+1];
		buf[0] = 0;
   e570a:	ad0c      	add	r5, sp, #48	; 0x30
		inet_inet_ntop(AF_INET6, address.ipv6, buf, sizeof(buf));
   e570c:	4639      	mov	r1, r7
{
#if Wiring_IPv6
#if HAL_USE_INET_HAL_POSIX
	if (address.v==6) {
		char buf[INET6_ADDRSTRLEN+1];
		buf[0] = 0;
   e570e:	f805 4d30 	strb.w	r4, [r5, #-48]!
		inet_inet_ntop(AF_INET6, address.ipv6, buf, sizeof(buf));
   e5712:	232f      	movs	r3, #47	; 0x2f
   e5714:	462a      	mov	r2, r5
   e5716:	200a      	movs	r0, #10
   e5718:	f7ff fd78 	bl	e520c <inet_inet_ntop>
    void clearWriteError() { setWriteError(0); }

    virtual size_t write(uint8_t) = 0;
    size_t write(const char *str) {
      if (str == NULL) return 0;
      return write((const uint8_t *)str, strlen(str));
   e571c:	4628      	mov	r0, r5
   e571e:	f003 fa65 	bl	e8bec <strlen>
   e5722:	6833      	ldr	r3, [r6, #0]
   e5724:	4602      	mov	r2, r0
   e5726:	68db      	ldr	r3, [r3, #12]
   e5728:	4629      	mov	r1, r5
   e572a:	4630      	mov	r0, r6
   e572c:	4798      	blx	r3
   e572e:	e00f      	b.n	e5750 <_ZNK9IPAddress7printToER5Print+0x60>
#endif // HAL_USE_INET_HAL_POSIX
#endif // Wiring_IPv6
    size_t n = 0;
    for (int i = 0; i < 4; i++)
    {
        if (n)
   e5730:	b124      	cbz	r4, e573c <_ZNK9IPAddress7printToER5Print+0x4c>
            n += p.print('.');
   e5732:	212e      	movs	r1, #46	; 0x2e
   e5734:	4630      	mov	r0, r6
   e5736:	f000 f9cd 	bl	e5ad4 <_ZN5Print5printEc>
   e573a:	4404      	add	r4, r0
        n += p.print((*this)[i], DEC);
   e573c:	f815 1d01 	ldrb.w	r1, [r5, #-1]!
   e5740:	220a      	movs	r2, #10
   e5742:	4630      	mov	r0, r6
   e5744:	f000 fa0c 	bl	e5b60 <_ZN5Print5printEhi>
#else
#pragma message "HAL_USE_INET_HAL_POSIX is required for IPv6 support in IPAddress::printTo()"
#endif // HAL_USE_INET_HAL_POSIX
#endif // Wiring_IPv6
    size_t n = 0;
    for (int i = 0; i < 4; i++)
   e5748:	42bd      	cmp	r5, r7
    {
        if (n)
            n += p.print('.');
        n += p.print((*this)[i], DEC);
   e574a:	4404      	add	r4, r0
#else
#pragma message "HAL_USE_INET_HAL_POSIX is required for IPv6 support in IPAddress::printTo()"
#endif // HAL_USE_INET_HAL_POSIX
#endif // Wiring_IPv6
    size_t n = 0;
    for (int i = 0; i < 4; i++)
   e574c:	d1f0      	bne.n	e5730 <_ZNK9IPAddress7printToER5Print+0x40>
    {
        if (n)
            n += p.print('.');
        n += p.print((*this)[i], DEC);
   e574e:	4620      	mov	r0, r4
    }
    return n;
}
   e5750:	b00d      	add	sp, #52	; 0x34
   e5752:	bdf0      	pop	{r4, r5, r6, r7, pc}

000e5754 <_ZN9IPAddressC1Ev>:

#if HAL_USE_INET_HAL_POSIX
#include <arpa/inet.h>
#endif // HAL_USE_INET_HAL_POSIX

IPAddress::IPAddress()
   e5754:	b510      	push	{r4, lr}
   e5756:	4b05      	ldr	r3, [pc, #20]	; (e576c <_ZN9IPAddressC1Ev+0x18>)
   e5758:	4604      	mov	r4, r0
        return address;
    }

    virtual size_t printTo(Print& p) const;

    void clear() { memset(&address, 0, sizeof (address)); }
   e575a:	2211      	movs	r2, #17
   e575c:	f840 3b04 	str.w	r3, [r0], #4
   e5760:	2100      	movs	r1, #0
   e5762:	f003 fa09 	bl	e8b78 <memset>
{
    clear();
}
   e5766:	4620      	mov	r0, r4
   e5768:	bd10      	pop	{r4, pc}
   e576a:	bf00      	nop
   e576c:	000ece3c 	.word	0x000ece3c

000e5770 <_ZN9IPAddressC1ERK16_HAL_IPAddress_t>:

IPAddress::IPAddress(const HAL_IPAddress& address)
   e5770:	4603      	mov	r3, r0
   e5772:	4a07      	ldr	r2, [pc, #28]	; (e5790 <_ZN9IPAddressC1ERK16_HAL_IPAddress_t+0x20>)
   e5774:	b510      	push	{r4, lr}
   e5776:	f843 2b04 	str.w	r2, [r3], #4
{
    memcpy(&this->address, &address, sizeof(address));
   e577a:	f101 0210 	add.w	r2, r1, #16
   e577e:	f851 4b04 	ldr.w	r4, [r1], #4
   e5782:	f843 4b04 	str.w	r4, [r3], #4
   e5786:	4291      	cmp	r1, r2
   e5788:	d1f9      	bne.n	e577e <_ZN9IPAddressC1ERK16_HAL_IPAddress_t+0xe>
   e578a:	780a      	ldrb	r2, [r1, #0]
   e578c:	701a      	strb	r2, [r3, #0]
}
   e578e:	bd10      	pop	{r4, pc}
   e5790:	000ece3c 	.word	0x000ece3c

000e5794 <_ZN9IPAddress8set_ipv4Ehhhh>:
    return address.ipv4!=0;
#endif
}

void IPAddress::set_ipv4(uint8_t b0, uint8_t b1, uint8_t b2, uint8_t b3)
{
   e5794:	b510      	push	{r4, lr}
    address.ipv4 = b0<<24 | b1 << 16 | b2 << 8 | b3;
   e5796:	f89d 4008 	ldrb.w	r4, [sp, #8]
   e579a:	ea44 2303 	orr.w	r3, r4, r3, lsl #8
   e579e:	ea43 4202 	orr.w	r2, r3, r2, lsl #16
   e57a2:	ea42 6101 	orr.w	r1, r2, r1, lsl #24
        return &address;
    }

    inline void setVersion(uint8_t version) {
#if HAL_IPv6
        address.v = version;
   e57a6:	2304      	movs	r3, #4
   e57a8:	6041      	str	r1, [r0, #4]
   e57aa:	7503      	strb	r3, [r0, #20]
   e57ac:	bd10      	pop	{r4, pc}

000e57ae <_ZN9IPAddressaSEPKh>:
    setVersion(4);
}

IPAddress& IPAddress::operator=(const uint8_t* address)
{
   e57ae:	b537      	push	{r0, r1, r2, r4, r5, lr}
    set_ipv4(address[0], address[1], address[2], address[3]);
   e57b0:	780d      	ldrb	r5, [r1, #0]
   e57b2:	788b      	ldrb	r3, [r1, #2]
   e57b4:	784a      	ldrb	r2, [r1, #1]
   e57b6:	78c9      	ldrb	r1, [r1, #3]
   e57b8:	9100      	str	r1, [sp, #0]
   e57ba:	4629      	mov	r1, r5
   e57bc:	f7ff ffea 	bl	e5794 <_ZN9IPAddress8set_ipv4Ehhhh>
    return *this;
}
   e57c0:	b003      	add	sp, #12
   e57c2:	bd30      	pop	{r4, r5, pc}

000e57c4 <_GLOBAL__sub_I__ZN5spark3LogE>:
    // This handler doesn't support direct logging
}

// spark::Logger
inline spark::Logger::Logger(const char *name) :
        name_(name) {
   e57c4:	4b01      	ldr	r3, [pc, #4]	; (e57cc <_GLOBAL__sub_I__ZN5spark3LogE+0x8>)
   e57c6:	4a02      	ldr	r2, [pc, #8]	; (e57d0 <_GLOBAL__sub_I__ZN5spark3LogE+0xc>)
   e57c8:	601a      	str	r2, [r3, #0]
   e57ca:	4770      	bx	lr
   e57cc:	2003e3e0 	.word	0x2003e3e0
   e57d0:	000eceb6 	.word	0x000eceb6

000e57d4 <_ZN5spark9MeshClass9listeningEv>:
    uint16_t getListenTimeout(void) {
        return network_get_listen_timeout(*this, 0, NULL);
    }

    bool listening(void) {
        return network_listening(*this, 0, NULL);
   e57d4:	2200      	movs	r2, #0
   e57d6:	4611      	mov	r1, r2
   e57d8:	6840      	ldr	r0, [r0, #4]
   e57da:	f7ff be5b 	b.w	e5494 <network_listening>

000e57de <_ZN5spark9MeshClass16getListenTimeoutEv>:
    void setListenTimeout(uint16_t timeout) {
        network_set_listen_timeout(*this, timeout, NULL);
    }

    uint16_t getListenTimeout(void) {
        return network_get_listen_timeout(*this, 0, NULL);
   e57de:	2200      	movs	r2, #0
   e57e0:	4611      	mov	r1, r2
   e57e2:	6840      	ldr	r0, [r0, #4]
   e57e4:	f7ff be66 	b.w	e54b4 <network_get_listen_timeout>

000e57e8 <_ZN5spark9MeshClass16setListenTimeoutEt>:
    void listen(bool begin=true) {
        network_listen(*this, begin ? 0 : 1, NULL);
    }

    void setListenTimeout(uint16_t timeout) {
        network_set_listen_timeout(*this, timeout, NULL);
   e57e8:	2200      	movs	r2, #0
   e57ea:	6840      	ldr	r0, [r0, #4]
   e57ec:	f7ff be5a 	b.w	e54a4 <network_set_listen_timeout>

000e57f0 <_ZN5spark9MeshClass6listenEb>:
    void disconnect() {
        network_disconnect(*this, NETWORK_DISCONNECT_REASON_USER, NULL);
    }

    void listen(bool begin=true) {
        network_listen(*this, begin ? 0 : 1, NULL);
   e57f0:	2200      	movs	r2, #0
   e57f2:	f081 0101 	eor.w	r1, r1, #1
   e57f6:	6840      	ldr	r0, [r0, #4]
   e57f8:	f7ff be44 	b.w	e5484 <network_listen>

000e57fc <_ZN5spark9MeshClass3offEv>:
    void on() {
        network_on(*this, 0, 0, NULL);
    }

    void off() {
        network_off(*this, 1, 0, NULL);
   e57fc:	2300      	movs	r3, #0
   e57fe:	461a      	mov	r2, r3
   e5800:	2101      	movs	r1, #1
   e5802:	6840      	ldr	r0, [r0, #4]
   e5804:	f7ff be36 	b.w	e5474 <network_off>

000e5808 <_ZN5spark9MeshClass2onEv>:
    MeshClass() :
            NetworkClass(NETWORK_INTERFACE_MESH) {
    }

    void on() {
        network_on(*this, 0, 0, NULL);
   e5808:	2300      	movs	r3, #0
   e580a:	461a      	mov	r2, r3
   e580c:	4619      	mov	r1, r3
   e580e:	6840      	ldr	r0, [r0, #4]
   e5810:	f7ff be28 	b.w	e5464 <network_on>

000e5814 <_ZN5spark9MeshClass5readyEv>:
    bool listening(void) {
        return network_listening(*this, 0, NULL);
    }

    bool ready() {
        return network_ready(*this, 0,  NULL);
   e5814:	2200      	movs	r2, #0
   e5816:	4611      	mov	r1, r2
   e5818:	6840      	ldr	r0, [r0, #4]
   e581a:	f7ff be1b 	b.w	e5454 <network_ready>

000e581e <_ZN5spark9MeshClass10connectingEv>:
    void connect(unsigned flags=0) {
        network_connect(*this, flags, 0, NULL);
    }

    bool connecting(void) {
        return network_connecting(*this, 0, NULL);
   e581e:	2200      	movs	r2, #0
   e5820:	4611      	mov	r1, r2
   e5822:	6840      	ldr	r0, [r0, #4]
   e5824:	f7ff be06 	b.w	e5434 <network_connecting>

000e5828 <_ZN5spark9MeshClass10disconnectEv>:
    }

    void disconnect() {
        network_disconnect(*this, NETWORK_DISCONNECT_REASON_USER, NULL);
   e5828:	2200      	movs	r2, #0
   e582a:	2102      	movs	r1, #2
   e582c:	6840      	ldr	r0, [r0, #4]
   e582e:	f7ff be09 	b.w	e5444 <network_disconnect>

000e5832 <_ZN5spark9MeshClass7connectEj>:
    void off() {
        network_off(*this, 1, 0, NULL);
    }

    void connect(unsigned flags=0) {
        network_connect(*this, flags, 0, NULL);
   e5832:	2300      	movs	r3, #0
   e5834:	461a      	mov	r2, r3
   e5836:	6840      	ldr	r0, [r0, #4]
   e5838:	f7ff bdf4 	b.w	e5424 <network_connect>

000e583c <_ZNKSt14default_deleteIN6Thread4DataEEclEPS1_.isra.6>:
	       enable_if<is_convertible<_Up*, _Tp*>::value>::type>
        default_delete(const default_delete<_Up>&) noexcept { }

      /// Calls @c delete @p __ptr
      void
      operator()(_Tp* __ptr) const
   e583c:	b538      	push	{r3, r4, r5, lr}
      {
	static_assert(!is_void<_Tp>::value,
		      "can't delete pointer to incomplete type");
	static_assert(sizeof(_Tp)>0,
		      "can't delete pointer to incomplete type");
	delete __ptr;
   e583e:	4605      	mov	r5, r0
   e5840:	b188      	cbz	r0, e5866 <_ZNKSt14default_deleteIN6Thread4DataEEclEPS1_.isra.6+0x2a>

      /// Destructor, invokes the deleter if the stored pointer is not null.
      ~unique_ptr() noexcept
      {
	auto& __ptr = std::get<0>(_M_t);
	if (__ptr != nullptr)
   e5842:	6804      	ldr	r4, [r0, #0]
   e5844:	b14c      	cbz	r4, e585a <_ZNKSt14default_deleteIN6Thread4DataEEclEPS1_.isra.6+0x1e>

    _Function_base() : _M_manager(nullptr) { }

    ~_Function_base()
    {
      if (_M_manager)
   e5846:	68a3      	ldr	r3, [r4, #8]
   e5848:	b11b      	cbz	r3, e5852 <_ZNKSt14default_deleteIN6Thread4DataEEclEPS1_.isra.6+0x16>
	_M_manager(_M_functor, _M_functor, __destroy_functor);
   e584a:	2203      	movs	r2, #3
   e584c:	4621      	mov	r1, r4
   e584e:	4620      	mov	r0, r4
   e5850:	4798      	blx	r3
      {
	static_assert(!is_void<_Tp>::value,
		      "can't delete pointer to incomplete type");
	static_assert(sizeof(_Tp)>0,
		      "can't delete pointer to incomplete type");
	delete __ptr;
   e5852:	2110      	movs	r1, #16
   e5854:	4620      	mov	r0, r4
   e5856:	f000 fcac 	bl	e61b2 <_ZdlPvj>
   e585a:	4628      	mov	r0, r5
   e585c:	2114      	movs	r1, #20
      }
   e585e:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
      {
	static_assert(!is_void<_Tp>::value,
		      "can't delete pointer to incomplete type");
	static_assert(sizeof(_Tp)>0,
		      "can't delete pointer to incomplete type");
	delete __ptr;
   e5862:	f000 bca6 	b.w	e61b2 <_ZdlPvj>
   e5866:	bd38      	pop	{r3, r4, r5, pc}

000e5868 <_ZNKSt14default_deleteI3UDPEclEPS0_.isra.8.constprop.13>:
   e5868:	b110      	cbz	r0, e5870 <_ZNKSt14default_deleteI3UDPEclEPS0_.isra.8.constprop.13+0x8>
   e586a:	6803      	ldr	r3, [r0, #0]
   e586c:	685b      	ldr	r3, [r3, #4]
   e586e:	4718      	bx	r3
   e5870:	4770      	bx	lr

000e5872 <_ZN6ThreadD1Ev>:
    Thread(Thread&& thread)
        : d_(std::move(thread.d_))
    {
    }

    ~Thread()
   e5872:	b510      	push	{r4, lr}
      }

      /// Return the stored pointer.
      pointer
      get() const noexcept
      { return std::get<0>(_M_t); }
   e5874:	6803      	ldr	r3, [r0, #0]
   e5876:	4604      	mov	r4, r0
        dispose();
    }

    void dispose()
    {
        if (!isValid())
   e5878:	b1bb      	cbz	r3, e58aa <_ZN6ThreadD1Ev+0x38>
        return isCurrent();
    }

    bool isCurrent() const
    {
        return isValid() && os_thread_is_current(d_->handle);
   e587a:	6858      	ldr	r0, [r3, #4]
   e587c:	f7ff fc16 	bl	e50ac <os_thread_is_current>
   e5880:	b978      	cbnz	r0, e58a2 <_ZN6ThreadD1Ev+0x30>
   e5882:	6823      	ldr	r3, [r4, #0]

        // We shouldn't dispose of current thread
        if (isCurrent())
            return;

        if (!d_->exited) {
   e5884:	7c5a      	ldrb	r2, [r3, #17]
   e5886:	b912      	cbnz	r2, e588e <_ZN6ThreadD1Ev+0x1c>
        d_.reset();
    }

    bool join()
    {
        return isValid() && os_thread_join(d_->handle)==0;
   e5888:	6858      	ldr	r0, [r3, #4]
   e588a:	f7ff fc17 	bl	e50bc <os_thread_join>

        if (!d_->exited) {
            join();
        }

        os_thread_cleanup(d_->handle);
   e588e:	6823      	ldr	r3, [r4, #0]
   e5890:	6858      	ldr	r0, [r3, #4]
   e5892:	f7ff fc1b 	bl	e50cc <os_thread_cleanup>
#endif
    {
      // concept requirements
      __glibcxx_function_requires(_SGIAssignableConcept<_Tp>)

      _Tp __tmp = _GLIBCXX_MOVE(__a);
   e5896:	6820      	ldr	r0, [r4, #0]
      __a = _GLIBCXX_MOVE(__b);
   e5898:	2300      	movs	r3, #0
   e589a:	6023      	str	r3, [r4, #0]
      void
      reset(pointer __p = pointer()) noexcept
      {
	using std::swap;
	swap(std::get<0>(_M_t), __p);
	if (__p != pointer())
   e589c:	b128      	cbz	r0, e58aa <_ZN6ThreadD1Ev+0x38>
	  get_deleter()(__p);
   e589e:	f7ff ffcd 	bl	e583c <_ZNKSt14default_deleteIN6Thread4DataEEclEPS1_.isra.6>

      /// Destructor, invokes the deleter if the stored pointer is not null.
      ~unique_ptr() noexcept
      {
	auto& __ptr = std::get<0>(_M_t);
	if (__ptr != nullptr)
   e58a2:	6820      	ldr	r0, [r4, #0]
   e58a4:	b108      	cbz	r0, e58aa <_ZN6ThreadD1Ev+0x38>
	  get_deleter()(__ptr);
   e58a6:	f7ff ffc9 	bl	e583c <_ZNKSt14default_deleteIN6Thread4DataEEclEPS1_.isra.6>
    }

    ~Thread()
    {
        dispose();
    }
   e58aa:	4620      	mov	r0, r4
   e58ac:	bd10      	pop	{r4, pc}
	...

000e58b0 <_ZN5spark9MeshClassD1Ev>:
    RecursiveMutex mutex_;
    std::unique_ptr<uint8_t[]> buffer_;
    std::atomic_bool exit_;
};

class MeshClass : public NetworkClass, public MeshPublish {
   e58b0:	b538      	push	{r3, r4, r5, lr}
   e58b2:	4b0c      	ldr	r3, [pc, #48]	; (e58e4 <_ZN5spark9MeshClassD1Ev+0x34>)
   e58b4:	6003      	str	r3, [r0, #0]
   e58b6:	4604      	mov	r4, r0

      /// Destructor, invokes the deleter if the stored pointer is not null.
      ~unique_ptr()
      {
	auto& __ptr = std::get<0>(_M_t);
	if (__ptr != nullptr)
   e58b8:	f8d0 01cc 	ldr.w	r0, [r0, #460]	; 0x1cc
   e58bc:	b108      	cbz	r0, e58c2 <_ZN5spark9MeshClassD1Ev+0x12>
      void
      operator()(_Tp* __ptr) const
      {
	static_assert(sizeof(_Tp)>0,
		      "can't delete pointer to incomplete type");
	delete [] __ptr;
   e58be:	f7ee fbf0 	bl	d40a2 <_ZdaPv>

      /// Destructor, invokes the deleter if the stored pointer is not null.
      ~unique_ptr() noexcept
      {
	auto& __ptr = std::get<0>(_M_t);
	if (__ptr != nullptr)
   e58c2:	f8d4 51c4 	ldr.w	r5, [r4, #452]	; 0x1c4
   e58c6:	b135      	cbz	r5, e58d6 <_ZN5spark9MeshClassD1Ev+0x26>
      {
	static_assert(!is_void<_Tp>::value,
		      "can't delete pointer to incomplete type");
	static_assert(sizeof(_Tp)>0,
		      "can't delete pointer to incomplete type");
	delete __ptr;
   e58c8:	4628      	mov	r0, r5
   e58ca:	f7ff ffd2 	bl	e5872 <_ZN6ThreadD1Ev>
   e58ce:	2104      	movs	r1, #4
   e58d0:	4628      	mov	r0, r5
   e58d2:	f000 fc6e 	bl	e61b2 <_ZdlPvj>

      /// Destructor, invokes the deleter if the stored pointer is not null.
      ~unique_ptr() noexcept
      {
	auto& __ptr = std::get<0>(_M_t);
	if (__ptr != nullptr)
   e58d6:	68a0      	ldr	r0, [r4, #8]
   e58d8:	b108      	cbz	r0, e58de <_ZN5spark9MeshClassD1Ev+0x2e>
	  get_deleter()(__ptr);
   e58da:	f7ff ffc5 	bl	e5868 <_ZNKSt14default_deleteI3UDPEclEPS0_.isra.8.constprop.13>
   e58de:	4620      	mov	r0, r4
   e58e0:	bd38      	pop	{r3, r4, r5, pc}
   e58e2:	bf00      	nop
   e58e4:	000ecf24 	.word	0x000ecf24

000e58e8 <_GLOBAL__sub_I__ZN5spark11MeshPublish13Subscriptions20event_handler_existsEPKcPFvS3_S3_EPvN17SubscriptionScope4EnumES3_>:

    return addr;
}

MeshClass Mesh;
} // namespace spark
   e58e8:	b538      	push	{r3, r4, r5, lr}
   e58ea:	4c0e      	ldr	r4, [pc, #56]	; (e5924 <_GLOBAL__sub_I__ZN5spark11MeshPublish13Subscriptions20event_handler_existsEPKcPFvS3_S3_EPvN17SubscriptionScope4EnumES3_+0x3c>)
   e58ec:	4b0e      	ldr	r3, [pc, #56]	; (e5928 <_GLOBAL__sub_I__ZN5spark11MeshPublish13Subscriptions20event_handler_existsEPKcPFvS3_S3_EPvN17SubscriptionScope4EnumES3_+0x40>)
   e58ee:	6023      	str	r3, [r4, #0]

  template<std::size_t _Idx, typename _Head>
    struct _Head_base<_Idx, _Head, false>
    {
      constexpr _Head_base()
      : _M_head_impl() { }
   e58f0:	2500      	movs	r5, #0
   e58f2:	2302      	movs	r3, #2
     */
    RecursiveMutex(os_mutex_recursive_t handle) : handle_(handle) {}

    RecursiveMutex() : handle_(nullptr)
    {
        os_mutex_recursive_create(&handle_);
   e58f4:	f504 70e4 	add.w	r0, r4, #456	; 0x1c8
   e58f8:	6063      	str	r3, [r4, #4]
   e58fa:	60a5      	str	r5, [r4, #8]
   e58fc:	f8c4 51c4 	str.w	r5, [r4, #452]	; 0x1c4
    /**
     * Creates a shared mutex.
     */
    RecursiveMutex(os_mutex_recursive_t handle) : handle_(handle) {}

    RecursiveMutex() : handle_(nullptr)
   e5900:	f8c4 51c8 	str.w	r5, [r4, #456]	; 0x1c8
    {
        os_mutex_recursive_create(&handle_);
   e5904:	f7ff fbf2 	bl	e50ec <os_mutex_recursive_create>
public:
    MeshClass() :
            NetworkClass(NETWORK_INTERFACE_MESH) {
   e5908:	4b08      	ldr	r3, [pc, #32]	; (e592c <_GLOBAL__sub_I__ZN5spark11MeshPublish13Subscriptions20event_handler_existsEPKcPFvS3_S3_EPvN17SubscriptionScope4EnumES3_+0x44>)
   e590a:	f8c4 51cc 	str.w	r5, [r4, #460]	; 0x1cc
      __atomic_base(const __atomic_base&) = delete;
      __atomic_base& operator=(const __atomic_base&) = delete;
      __atomic_base& operator=(const __atomic_base&) volatile = delete;

      // Requires __int_type convertible to _M_i.
      constexpr __atomic_base(__int_type __i) noexcept : _M_i (__i) { }
   e590e:	f884 51d0 	strb.w	r5, [r4, #464]	; 0x1d0
   e5912:	6023      	str	r3, [r4, #0]
    }

    return addr;
}

MeshClass Mesh;
   e5914:	4620      	mov	r0, r4
   e5916:	4a06      	ldr	r2, [pc, #24]	; (e5930 <_GLOBAL__sub_I__ZN5spark11MeshPublish13Subscriptions20event_handler_existsEPKcPFvS3_S3_EPvN17SubscriptionScope4EnumES3_+0x48>)
   e5918:	4906      	ldr	r1, [pc, #24]	; (e5934 <_GLOBAL__sub_I__ZN5spark11MeshPublish13Subscriptions20event_handler_existsEPKcPFvS3_S3_EPvN17SubscriptionScope4EnumES3_+0x4c>)
} // namespace spark
   e591a:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
    }

    return addr;
}

MeshClass Mesh;
   e591e:	f000 bc43 	b.w	e61a8 <__aeabi_atexit>
   e5922:	bf00      	nop
   e5924:	2003e3e4 	.word	0x2003e3e4
   e5928:	000ecf58 	.word	0x000ecf58
   e592c:	000ecf24 	.word	0x000ecf24
   e5930:	2003c2a0 	.word	0x2003c2a0
   e5934:	000e58b1 	.word	0x000e58b1

000e5938 <_ZN5spark12NetworkClass7connectEj>:
        return Network;
    }
}

void NetworkClass::connect(unsigned flags) {
    network_connect(*this, flags, 0, nullptr);
   e5938:	2300      	movs	r3, #0
   e593a:	461a      	mov	r2, r3
   e593c:	6840      	ldr	r0, [r0, #4]
   e593e:	f7ff bd71 	b.w	e5424 <network_connect>

000e5942 <_ZN5spark12NetworkClass10disconnectEv>:
}

void NetworkClass::disconnect() {
    network_disconnect(*this, NETWORK_DISCONNECT_REASON_USER, nullptr);
   e5942:	2200      	movs	r2, #0
   e5944:	2102      	movs	r1, #2
   e5946:	6840      	ldr	r0, [r0, #4]
   e5948:	f7ff bd7c 	b.w	e5444 <network_disconnect>

000e594c <_ZN5spark12NetworkClass10connectingEv>:
}

bool NetworkClass::connecting() {
    return network_connecting(*this, 0, nullptr);
   e594c:	2200      	movs	r2, #0
   e594e:	4611      	mov	r1, r2
   e5950:	6840      	ldr	r0, [r0, #4]
   e5952:	f7ff bd6f 	b.w	e5434 <network_connecting>

000e5956 <_ZN5spark12NetworkClass5readyEv>:
}

bool NetworkClass::ready() {
    return network_ready(*this, 0, nullptr);
   e5956:	2200      	movs	r2, #0
   e5958:	4611      	mov	r1, r2
   e595a:	6840      	ldr	r0, [r0, #4]
   e595c:	f7ff bd7a 	b.w	e5454 <network_ready>

000e5960 <_ZN5spark12NetworkClass2onEv>:
}

void NetworkClass::on() {
    network_on(*this, 0, 0, nullptr);
   e5960:	2300      	movs	r3, #0
   e5962:	461a      	mov	r2, r3
   e5964:	4619      	mov	r1, r3
   e5966:	6840      	ldr	r0, [r0, #4]
   e5968:	f7ff bd7c 	b.w	e5464 <network_on>

000e596c <_ZN5spark12NetworkClass3offEv>:
}

void NetworkClass::off() {
    network_off(*this, 0, 0, nullptr);
   e596c:	2300      	movs	r3, #0
   e596e:	461a      	mov	r2, r3
   e5970:	4619      	mov	r1, r3
   e5972:	6840      	ldr	r0, [r0, #4]
   e5974:	f7ff bd7e 	b.w	e5474 <network_off>

000e5978 <_ZN5spark12NetworkClass6listenEb>:
}

void NetworkClass::listen(bool begin) {
    network_listen(*this, begin ? 0 : 1, nullptr);
   e5978:	2200      	movs	r2, #0
   e597a:	f081 0101 	eor.w	r1, r1, #1
   e597e:	6840      	ldr	r0, [r0, #4]
   e5980:	f7ff bd80 	b.w	e5484 <network_listen>

000e5984 <_ZN5spark12NetworkClass16setListenTimeoutEt>:
}

void NetworkClass::setListenTimeout(uint16_t timeout) {
    network_set_listen_timeout(*this, timeout, nullptr);
   e5984:	2200      	movs	r2, #0
   e5986:	6840      	ldr	r0, [r0, #4]
   e5988:	f7ff bd8c 	b.w	e54a4 <network_set_listen_timeout>

000e598c <_ZN5spark12NetworkClass16getListenTimeoutEv>:
}

uint16_t NetworkClass::getListenTimeout() {
    return network_get_listen_timeout(*this, 0, nullptr);
   e598c:	2200      	movs	r2, #0
   e598e:	4611      	mov	r1, r2
   e5990:	6840      	ldr	r0, [r0, #4]
   e5992:	f7ff bd8f 	b.w	e54b4 <network_get_listen_timeout>

000e5996 <_ZN5spark12NetworkClass9listeningEv>:
}

bool NetworkClass::listening() {
    return network_listening(*this, 0, nullptr);
   e5996:	2200      	movs	r2, #0
   e5998:	4611      	mov	r1, r2
   e599a:	6840      	ldr	r0, [r0, #4]
   e599c:	f7ff bd7a 	b.w	e5494 <network_listening>

000e59a0 <_ZN5spark12NetworkClass7resolveEPKc>:
}

IPAddress NetworkClass::resolve(const char* name) {
   e59a0:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
    IPAddress addr;
#if HAL_USE_INET_HAL_POSIX
    struct addrinfo *ai = nullptr;
   e59a4:	2400      	movs	r4, #0

bool NetworkClass::listening() {
    return network_listening(*this, 0, nullptr);
}

IPAddress NetworkClass::resolve(const char* name) {
   e59a6:	b095      	sub	sp, #84	; 0x54
   e59a8:	4616      	mov	r6, r2
   e59aa:	460d      	mov	r5, r1
   e59ac:	4607      	mov	r7, r0
    IPAddress addr;
   e59ae:	f7ff fed1 	bl	e5754 <_ZN9IPAddressC1Ev>
#if HAL_USE_INET_HAL_POSIX
    struct addrinfo *ai = nullptr;
    struct addrinfo hints = {};
   e59b2:	4621      	mov	r1, r4
   e59b4:	2220      	movs	r2, #32
   e59b6:	a80c      	add	r0, sp, #48	; 0x30
}

IPAddress NetworkClass::resolve(const char* name) {
    IPAddress addr;
#if HAL_USE_INET_HAL_POSIX
    struct addrinfo *ai = nullptr;
   e59b8:	9400      	str	r4, [sp, #0]
    struct addrinfo hints = {};
   e59ba:	f003 f8dd 	bl	e8b78 <memset>
    hints.ai_flags = AI_ADDRCONFIG;
   e59be:	2340      	movs	r3, #64	; 0x40
   e59c0:	930c      	str	r3, [sp, #48]	; 0x30
    hints.ai_family = AF_UNSPEC;
    const int r = getaddrinfo(name, nullptr, &hints, &ai);
   e59c2:	4621      	mov	r1, r4
   e59c4:	466b      	mov	r3, sp
   e59c6:	aa0c      	add	r2, sp, #48	; 0x30
   e59c8:	4630      	mov	r0, r6
   e59ca:	f7ff fc2f 	bl	e522c <netdb_getaddrinfo>
    if (!r) {
   e59ce:	4604      	mov	r4, r0
   e59d0:	2800      	cmp	r0, #0
   e59d2:	d144      	bne.n	e5a5e <_ZN5spark12NetworkClass7resolveEPKc+0xbe>
        bool ok = false;
        // This is not really needed if AI_ADDRCONFIG is properly supported
        bool ipv4 = network_ready(*this, NETWORK_READY_TYPE_IPV4, nullptr);
   e59d4:	4602      	mov	r2, r0
   e59d6:	2101      	movs	r1, #1
   e59d8:	6868      	ldr	r0, [r5, #4]
   e59da:	f7ff fd3b 	bl	e5454 <network_ready>
        bool ipv6 = network_ready(*this, NETWORK_READY_TYPE_IPV6, nullptr);
   e59de:	2102      	movs	r1, #2
    hints.ai_family = AF_UNSPEC;
    const int r = getaddrinfo(name, nullptr, &hints, &ai);
    if (!r) {
        bool ok = false;
        // This is not really needed if AI_ADDRCONFIG is properly supported
        bool ipv4 = network_ready(*this, NETWORK_READY_TYPE_IPV4, nullptr);
   e59e0:	4680      	mov	r8, r0
        bool ipv6 = network_ready(*this, NETWORK_READY_TYPE_IPV6, nullptr);
   e59e2:	4622      	mov	r2, r4
   e59e4:	6868      	ldr	r0, [r5, #4]
   e59e6:	f7ff fd35 	bl	e5454 <network_ready>
        for (auto cur = ai; cur != nullptr && !ok; cur = cur->ai_next) {
   e59ea:	9e00      	ldr	r6, [sp, #0]
    const int r = getaddrinfo(name, nullptr, &hints, &ai);
    if (!r) {
        bool ok = false;
        // This is not really needed if AI_ADDRCONFIG is properly supported
        bool ipv4 = network_ready(*this, NETWORK_READY_TYPE_IPV4, nullptr);
        bool ipv6 = network_ready(*this, NETWORK_READY_TYPE_IPV6, nullptr);
   e59ec:	4681      	mov	r9, r0
    struct addrinfo hints = {};
    hints.ai_flags = AI_ADDRCONFIG;
    hints.ai_family = AF_UNSPEC;
    const int r = getaddrinfo(name, nullptr, &hints, &ai);
    if (!r) {
        bool ok = false;
   e59ee:	4621      	mov	r1, r4
        // This is not really needed if AI_ADDRCONFIG is properly supported
        bool ipv4 = network_ready(*this, NETWORK_READY_TYPE_IPV4, nullptr);
        bool ipv6 = network_ready(*this, NETWORK_READY_TYPE_IPV6, nullptr);
        for (auto cur = ai; cur != nullptr && !ok; cur = cur->ai_next) {
   e59f0:	2e00      	cmp	r6, #0
   e59f2:	d034      	beq.n	e5a5e <_ZN5spark12NetworkClass7resolveEPKc+0xbe>
   e59f4:	2900      	cmp	r1, #0
   e59f6:	d132      	bne.n	e5a5e <_ZN5spark12NetworkClass7resolveEPKc+0xbe>
            // NOTE: using only the first entry that matches the current state of IPv4/IPv6 connectivity
            switch (cur->ai_family) {
   e59f8:	6873      	ldr	r3, [r6, #4]
   e59fa:	2b02      	cmp	r3, #2
   e59fc:	d002      	beq.n	e5a04 <_ZN5spark12NetworkClass7resolveEPKc+0x64>
   e59fe:	2b0a      	cmp	r3, #10
   e5a00:	d009      	beq.n	e5a16 <_ZN5spark12NetworkClass7resolveEPKc+0x76>
   e5a02:	e02a      	b.n	e5a5a <_ZN5spark12NetworkClass7resolveEPKc+0xba>
                case AF_INET: {
                    if (!ipv4) {
   e5a04:	f1b8 0f00 	cmp.w	r8, #0
   e5a08:	d027      	beq.n	e5a5a <_ZN5spark12NetworkClass7resolveEPKc+0xba>
                        continue;
                    }
                    // NOTE: HAL_IPAddress is little-endian
                    auto in = (struct sockaddr_in*)cur->ai_addr;
                    addr = (const uint8_t*)(&in->sin_addr.s_addr);
   e5a0a:	6971      	ldr	r1, [r6, #20]
   e5a0c:	4638      	mov	r0, r7
   e5a0e:	3104      	adds	r1, #4
   e5a10:	f7ff fecd 	bl	e57ae <_ZN9IPAddressaSEPKh>
   e5a14:	e020      	b.n	e5a58 <_ZN5spark12NetworkClass7resolveEPKc+0xb8>
                    ok = true;
                    break;
                }
                case AF_INET6: {
                    if (!ipv6) {
   e5a16:	f1b9 0f00 	cmp.w	r9, #0
   e5a1a:	d01e      	beq.n	e5a5a <_ZN5spark12NetworkClass7resolveEPKc+0xba>
                        continue;
                    }
                    auto in6 = (struct sockaddr_in6*)cur->ai_addr;
   e5a1c:	6974      	ldr	r4, [r6, #20]
                    HAL_IPAddress a = {};
   e5a1e:	2211      	movs	r2, #17
   e5a20:	a801      	add	r0, sp, #4
   e5a22:	f003 f8a9 	bl	e8b78 <memset>
                    a.v = 6;
   e5a26:	2306      	movs	r3, #6
   e5a28:	f88d 3014 	strb.w	r3, [sp, #20]
                    memcpy(a.ipv6, in6->sin6_addr.s6_addr, sizeof(a.ipv6));
   e5a2c:	ad01      	add	r5, sp, #4
   e5a2e:	f104 0308 	add.w	r3, r4, #8
   e5a32:	3418      	adds	r4, #24
   e5a34:	6818      	ldr	r0, [r3, #0]
   e5a36:	6859      	ldr	r1, [r3, #4]
   e5a38:	462a      	mov	r2, r5
   e5a3a:	c203      	stmia	r2!, {r0, r1}
   e5a3c:	3308      	adds	r3, #8
   e5a3e:	42a3      	cmp	r3, r4
   e5a40:	4615      	mov	r5, r2
   e5a42:	d1f7      	bne.n	e5a34 <_ZN5spark12NetworkClass7resolveEPKc+0x94>
                    addr = IPAddress(a);
   e5a44:	a901      	add	r1, sp, #4
   e5a46:	a806      	add	r0, sp, #24

/**
 * The IP address stored in host order.
 *
 */
class IPAddress : public Printable {
   e5a48:	ad07      	add	r5, sp, #28
   e5a4a:	f7ff fe91 	bl	e5770 <_ZN9IPAddressC1ERK16_HAL_IPAddress_t>
   e5a4e:	cd0f      	ldmia	r5!, {r0, r1, r2, r3}
   e5a50:	1d3c      	adds	r4, r7, #4
   e5a52:	c40f      	stmia	r4!, {r0, r1, r2, r3}
   e5a54:	682b      	ldr	r3, [r5, #0]
   e5a56:	7023      	strb	r3, [r4, #0]
                    ok = true;
   e5a58:	2101      	movs	r1, #1
    if (!r) {
        bool ok = false;
        // This is not really needed if AI_ADDRCONFIG is properly supported
        bool ipv4 = network_ready(*this, NETWORK_READY_TYPE_IPV4, nullptr);
        bool ipv6 = network_ready(*this, NETWORK_READY_TYPE_IPV6, nullptr);
        for (auto cur = ai; cur != nullptr && !ok; cur = cur->ai_next) {
   e5a5a:	69f6      	ldr	r6, [r6, #28]
   e5a5c:	e7c8      	b.n	e59f0 <_ZN5spark12NetworkClass7resolveEPKc+0x50>
                    break;
                }
            }
        }
    }
    freeaddrinfo(ai);
   e5a5e:	9800      	ldr	r0, [sp, #0]
   e5a60:	f7ff fbdc 	bl	e521c <netdb_freeaddrinfo>
    return Cellular.resolve(name);
#endif // Wiring_Cellular

#endif // HAL_USE_INET_HAL_POSIX
    return addr;
}
   e5a64:	4638      	mov	r0, r7
   e5a66:	b015      	add	sp, #84	; 0x54
   e5a68:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}

000e5a6c <_GLOBAL__sub_I__ZN5spark7NetworkE>:
   e5a6c:	4b02      	ldr	r3, [pc, #8]	; (e5a78 <_GLOBAL__sub_I__ZN5spark7NetworkE+0xc>)
   e5a6e:	4a03      	ldr	r2, [pc, #12]	; (e5a7c <_GLOBAL__sub_I__ZN5spark7NetworkE+0x10>)
   e5a70:	601a      	str	r2, [r3, #0]
   e5a72:	2200      	movs	r2, #0
   e5a74:	605a      	str	r2, [r3, #4]
   e5a76:	4770      	bx	lr
   e5a78:	2003e5b8 	.word	0x2003e5b8
   e5a7c:	000ecf58 	.word	0x000ecf58

000e5a80 <_ZN5Print5writeEPKhj>:

// Public Methods //////////////////////////////////////////////////////////////

/* default implementation: may be overridden */
size_t Print::write(const uint8_t *buffer, size_t size)
{
   e5a80:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
   e5a82:	4606      	mov	r6, r0
   e5a84:	460d      	mov	r5, r1
   e5a86:	188f      	adds	r7, r1, r2
  size_t n = 0;
   e5a88:	2400      	movs	r4, #0
  while (size--) {
   e5a8a:	42bd      	cmp	r5, r7
   e5a8c:	d00c      	beq.n	e5aa8 <_ZN5Print5writeEPKhj+0x28>
     int chunk = write(*buffer++);
   e5a8e:	6833      	ldr	r3, [r6, #0]
   e5a90:	f815 1b01 	ldrb.w	r1, [r5], #1
   e5a94:	689b      	ldr	r3, [r3, #8]
   e5a96:	4630      	mov	r0, r6
   e5a98:	4798      	blx	r3
     if (chunk>=0)
   e5a9a:	2800      	cmp	r0, #0
   e5a9c:	db01      	blt.n	e5aa2 <_ZN5Print5writeEPKhj+0x22>
         n += chunk;
   e5a9e:	4404      	add	r4, r0

/* default implementation: may be overridden */
size_t Print::write(const uint8_t *buffer, size_t size)
{
  size_t n = 0;
  while (size--) {
   e5aa0:	e7f3      	b.n	e5a8a <_ZN5Print5writeEPKhj+0xa>
     int chunk = write(*buffer++);
   e5aa2:	2c00      	cmp	r4, #0
   e5aa4:	bf08      	it	eq
   e5aa6:	4604      	moveq	r4, r0
             n = chunk;
         break;
     }
  }
  return n;
}
   e5aa8:	4620      	mov	r0, r4
   e5aaa:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

000e5aac <_ZN5Print5writeEPKc>:

    int getWriteError() { return write_error; }
    void clearWriteError() { setWriteError(0); }

    virtual size_t write(uint8_t) = 0;
    size_t write(const char *str) {
   e5aac:	b570      	push	{r4, r5, r6, lr}
   e5aae:	4605      	mov	r5, r0
      if (str == NULL) return 0;
   e5ab0:	460c      	mov	r4, r1
      return write((const uint8_t *)str, strlen(str));
    }
   e5ab2:	4608      	mov	r0, r1
    int getWriteError() { return write_error; }
    void clearWriteError() { setWriteError(0); }

    virtual size_t write(uint8_t) = 0;
    size_t write(const char *str) {
      if (str == NULL) return 0;
   e5ab4:	b149      	cbz	r1, e5aca <_ZN5Print5writeEPKc+0x1e>
      return write((const uint8_t *)str, strlen(str));
   e5ab6:	f003 f899 	bl	e8bec <strlen>
   e5aba:	682b      	ldr	r3, [r5, #0]
   e5abc:	4602      	mov	r2, r0
   e5abe:	4621      	mov	r1, r4
   e5ac0:	4628      	mov	r0, r5
   e5ac2:	68db      	ldr	r3, [r3, #12]
    }
   e5ac4:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
    void clearWriteError() { setWriteError(0); }

    virtual size_t write(uint8_t) = 0;
    size_t write(const char *str) {
      if (str == NULL) return 0;
      return write((const uint8_t *)str, strlen(str));
   e5ac8:	4718      	bx	r3
    }
   e5aca:	bd70      	pop	{r4, r5, r6, pc}

000e5acc <_ZN5Print5printEPKc>:
   e5acc:	b508      	push	{r3, lr}
   e5ace:	f7ff ffed 	bl	e5aac <_ZN5Print5writeEPKc>
   e5ad2:	bd08      	pop	{r3, pc}

000e5ad4 <_ZN5Print5printEc>:
  return write(str);
}

size_t Print::print(char c)
{
  return write(c);
   e5ad4:	6803      	ldr	r3, [r0, #0]
   e5ad6:	689b      	ldr	r3, [r3, #8]
   e5ad8:	4718      	bx	r3

000e5ada <_ZN5Print7printlnEv>:
{
  return print(reinterpret_cast<const char*>(str));
}

size_t Print::println(void)
{
   e5ada:	b538      	push	{r3, r4, r5, lr}
  size_t n = print('\r');
   e5adc:	210d      	movs	r1, #13
{
  return print(reinterpret_cast<const char*>(str));
}

size_t Print::println(void)
{
   e5ade:	4605      	mov	r5, r0
  size_t n = print('\r');
   e5ae0:	f7ff fff8 	bl	e5ad4 <_ZN5Print5printEc>
  n += print('\n');
   e5ae4:	210a      	movs	r1, #10
  return print(reinterpret_cast<const char*>(str));
}

size_t Print::println(void)
{
  size_t n = print('\r');
   e5ae6:	4604      	mov	r4, r0
  n += print('\n');
   e5ae8:	4628      	mov	r0, r5
   e5aea:	f7ff fff3 	bl	e5ad4 <_ZN5Print5printEc>
  return n;
}
   e5aee:	4420      	add	r0, r4
   e5af0:	bd38      	pop	{r3, r4, r5, pc}

000e5af2 <_ZN5Print7printlnEPKc>:

size_t Print::println(const char c[])
{
   e5af2:	b538      	push	{r3, r4, r5, lr}
   e5af4:	4605      	mov	r5, r0
  return n;
}

size_t Print::print(const char str[])
{
  return write(str);
   e5af6:	f7ff ffd9 	bl	e5aac <_ZN5Print5writeEPKc>
   e5afa:	4604      	mov	r4, r0
}

size_t Print::println(const char c[])
{
  size_t n = print(c);
  n += println();
   e5afc:	4628      	mov	r0, r5
   e5afe:	f7ff ffec 	bl	e5ada <_ZN5Print7printlnEv>
  return n;
}
   e5b02:	4420      	add	r0, r4
   e5b04:	bd38      	pop	{r3, r4, r5, pc}

000e5b06 <_ZN5Print11printNumberEmh>:
  return println(reinterpret_cast<const char*>(str));
}

// Private Methods /////////////////////////////////////////////////////////////

size_t Print::printNumber(unsigned long n, uint8_t base) {
   e5b06:	b530      	push	{r4, r5, lr}
   e5b08:	b08b      	sub	sp, #44	; 0x2c
   e5b0a:	460b      	mov	r3, r1
  char buf[8 * sizeof(long) + 1]; // Assumes 8-bit chars plus zero byte.
  char *str = &buf[sizeof(buf) - 1];

  *str = '\0';
   e5b0c:	2100      	movs	r1, #0
   e5b0e:	f88d 1024 	strb.w	r1, [sp, #36]	; 0x24

  // prevent crash if called with base == 1
  if (base < 2) base = 10;
   e5b12:	2a01      	cmp	r2, #1
   e5b14:	bf98      	it	ls
   e5b16:	220a      	movls	r2, #10
   e5b18:	f10d 0423 	add.w	r4, sp, #35	; 0x23

  do {
    unsigned long m = n;
    n /= base;
   e5b1c:	fbb3 f5f2 	udiv	r5, r3, r2
    char c = m - base * n;
   e5b20:	fb05 3312 	mls	r3, r5, r2, r3
   e5b24:	f003 03ff 	and.w	r3, r3, #255	; 0xff
    *--str = c < 10 ? c + '0' : c + 'A' - 10;
   e5b28:	2b09      	cmp	r3, #9
   e5b2a:	bf94      	ite	ls
   e5b2c:	3330      	addls	r3, #48	; 0x30
   e5b2e:	3337      	addhi	r3, #55	; 0x37
   e5b30:	b2db      	uxtb	r3, r3
   e5b32:	4621      	mov	r1, r4
   e5b34:	f804 3901 	strb.w	r3, [r4], #-1
   e5b38:	462b      	mov	r3, r5
  *str = '\0';

  // prevent crash if called with base == 1
  if (base < 2) base = 10;

  do {
   e5b3a:	2d00      	cmp	r5, #0
   e5b3c:	d1ee      	bne.n	e5b1c <_ZN5Print11printNumberEmh+0x16>
    n /= base;
    char c = m - base * n;
    *--str = c < 10 ? c + '0' : c + 'A' - 10;
  } while(n);

  return write(str);
   e5b3e:	f7ff ffb5 	bl	e5aac <_ZN5Print5writeEPKc>
}
   e5b42:	b00b      	add	sp, #44	; 0x2c
   e5b44:	bd30      	pop	{r4, r5, pc}

000e5b46 <_ZN5Print5printEmi>:
    return printNumber(n, base);
  }
}

size_t Print::print(unsigned long n, int base)
{
   e5b46:	b410      	push	{r4}
  if (base == 0) return write(n);
   e5b48:	b92a      	cbnz	r2, e5b56 <_ZN5Print5printEmi+0x10>
   e5b4a:	6803      	ldr	r3, [r0, #0]
  else return printNumber(n, base);
}
   e5b4c:	f85d 4b04 	ldr.w	r4, [sp], #4
  }
}

size_t Print::print(unsigned long n, int base)
{
  if (base == 0) return write(n);
   e5b50:	689b      	ldr	r3, [r3, #8]
   e5b52:	b2c9      	uxtb	r1, r1
   e5b54:	4718      	bx	r3
  else return printNumber(n, base);
   e5b56:	b2d2      	uxtb	r2, r2
}
   e5b58:	f85d 4b04 	ldr.w	r4, [sp], #4
}

size_t Print::print(unsigned long n, int base)
{
  if (base == 0) return write(n);
  else return printNumber(n, base);
   e5b5c:	f7ff bfd3 	b.w	e5b06 <_ZN5Print11printNumberEmh>

000e5b60 <_ZN5Print5printEhi>:
  return write(c);
}

size_t Print::print(unsigned char b, int base)
{
  return print((unsigned long) b, base);
   e5b60:	f7ff bff1 	b.w	e5b46 <_ZN5Print5printEmi>

000e5b64 <_ZN5Print11printf_implEbPKcz>:

  return n;
}

size_t Print::printf_impl(bool newline, const char* format, ...)
{
   e5b64:	b40c      	push	{r2, r3}
   e5b66:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
   e5b6a:	b087      	sub	sp, #28
   e5b6c:	af00      	add	r7, sp, #0
   e5b6e:	f107 0438 	add.w	r4, r7, #56	; 0x38
   e5b72:	4605      	mov	r5, r0
   e5b74:	f854 9b04 	ldr.w	r9, [r4], #4
    const int bufsize = 20;
    char test[bufsize];
    va_list marker;
    va_start(marker, format);
   e5b78:	603c      	str	r4, [r7, #0]

  return n;
}

size_t Print::printf_impl(bool newline, const char* format, ...)
{
   e5b7a:	460e      	mov	r6, r1
    const int bufsize = 20;
    char test[bufsize];
    va_list marker;
    va_start(marker, format);
    size_t n = vsnprintf(test, bufsize, format, marker);
   e5b7c:	4623      	mov	r3, r4
   e5b7e:	464a      	mov	r2, r9
   e5b80:	2114      	movs	r1, #20
   e5b82:	1d38      	adds	r0, r7, #4
   e5b84:	f7ff fcae 	bl	e54e4 <vsnprintf>
    va_end(marker);

    if (n<bufsize)
   e5b88:	2813      	cmp	r0, #19
   e5b8a:	d805      	bhi.n	e5b98 <_ZN5Print11printf_implEbPKcz+0x34>
  return n;
}

size_t Print::print(const char str[])
{
  return write(str);
   e5b8c:	1d39      	adds	r1, r7, #4
   e5b8e:	4628      	mov	r0, r5
   e5b90:	f7ff ff8c 	bl	e5aac <_ZN5Print5writeEPKc>
   e5b94:	4604      	mov	r4, r0
   e5b96:	e013      	b.n	e5bc0 <_ZN5Print11printf_implEbPKcz+0x5c>
    {
        n = print(test);
    }
    else
    {
        char bigger[n+1];
   e5b98:	f100 0308 	add.w	r3, r0, #8
   e5b9c:	f023 0307 	bic.w	r3, r3, #7
        va_start(marker, format);
        n = vsnprintf(bigger, n+1, format, marker);
        va_end(marker);
        n = print(bigger);
   e5ba0:	46e8      	mov	r8, sp
    {
        n = print(test);
    }
    else
    {
        char bigger[n+1];
   e5ba2:	ebad 0d03 	sub.w	sp, sp, r3
        va_start(marker, format);
        n = vsnprintf(bigger, n+1, format, marker);
   e5ba6:	1c41      	adds	r1, r0, #1
   e5ba8:	4623      	mov	r3, r4
   e5baa:	464a      	mov	r2, r9
   e5bac:	4668      	mov	r0, sp
        n = print(test);
    }
    else
    {
        char bigger[n+1];
        va_start(marker, format);
   e5bae:	603c      	str	r4, [r7, #0]
        n = vsnprintf(bigger, n+1, format, marker);
   e5bb0:	f7ff fc98 	bl	e54e4 <vsnprintf>
  return n;
}

size_t Print::print(const char str[])
{
  return write(str);
   e5bb4:	4669      	mov	r1, sp
   e5bb6:	4628      	mov	r0, r5
   e5bb8:	f7ff ff78 	bl	e5aac <_ZN5Print5writeEPKc>
   e5bbc:	4604      	mov	r4, r0
   e5bbe:	46c5      	mov	sp, r8
        va_start(marker, format);
        n = vsnprintf(bigger, n+1, format, marker);
        va_end(marker);
        n = print(bigger);
    }
    if (newline)
   e5bc0:	b11e      	cbz	r6, e5bca <_ZN5Print11printf_implEbPKcz+0x66>
        n += println();
   e5bc2:	4628      	mov	r0, r5
   e5bc4:	f7ff ff89 	bl	e5ada <_ZN5Print7printlnEv>
   e5bc8:	4404      	add	r4, r0
    return n;
}
   e5bca:	4620      	mov	r0, r4
   e5bcc:	371c      	adds	r7, #28
   e5bce:	46bd      	mov	sp, r7
   e5bd0:	e8bd 43f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, lr}
   e5bd4:	b002      	add	sp, #8
   e5bd6:	4770      	bx	lr

000e5bd8 <_ZN8RGBClassD1Ev>:
#include "rgbled.h"

typedef void (raw_rgb_change_handler_t)(uint8_t, uint8_t, uint8_t);
typedef std::function<raw_rgb_change_handler_t> wiring_rgb_change_handler_t;

class RGBClass {
   e5bd8:	b510      	push	{r4, lr}
   e5bda:	4604      	mov	r4, r0
   *  @ingroup functors
   *
   *  Polymorphic function wrapper.
   */
  template<typename _Res, typename... _ArgTypes>
    class function<_Res(_ArgTypes...)>
   e5bdc:	f7ff fcf6 	bl	e55cc <_ZNSt14_Function_baseD1Ev>
   e5be0:	4620      	mov	r0, r4
   e5be2:	bd10      	pop	{r4, pc}

000e5be4 <_GLOBAL__sub_I_RGB>:
	{
	  _Base::_M_init_functor(__functor, std::__addressof(__f.get()));
	}
      };

    _Function_base() : _M_manager(nullptr) { }
   e5be4:	4803      	ldr	r0, [pc, #12]	; (e5bf4 <_GLOBAL__sub_I_RGB+0x10>)
#include "spark_wiring_rgb.h"
#include "spark_wiring_interrupts.h"

#include "core_hal.h"

RGBClass RGB;
   e5be6:	4a04      	ldr	r2, [pc, #16]	; (e5bf8 <_GLOBAL__sub_I_RGB+0x14>)
   e5be8:	4904      	ldr	r1, [pc, #16]	; (e5bfc <_GLOBAL__sub_I_RGB+0x18>)
   e5bea:	2300      	movs	r3, #0
   e5bec:	6083      	str	r3, [r0, #8]
   e5bee:	f000 badb 	b.w	e61a8 <__aeabi_atexit>
   e5bf2:	bf00      	nop
   e5bf4:	2003e5c0 	.word	0x2003e5c0
   e5bf8:	2003c2a0 	.word	0x2003c2a0
   e5bfc:	000e5bd9 	.word	0x000e5bd9

000e5c00 <_ZN8SPIClassD1Ev>:
  Mutex mutex_;
#endif

public:
  SPIClass(HAL_SPI_Interface spi);
  virtual ~SPIClass() {};
   e5c00:	4770      	bx	lr

000e5c02 <_ZN8SPIClassD0Ev>:
   e5c02:	b510      	push	{r4, lr}
   e5c04:	2110      	movs	r1, #16
   e5c06:	4604      	mov	r4, r0
   e5c08:	f000 fad3 	bl	e61b2 <_ZdlPvj>
   e5c0c:	4620      	mov	r0, r4
   e5c0e:	bd10      	pop	{r4, pc}

000e5c10 <_ZN8SPIClassC1E17HAL_SPI_Interface>:
  if (!info->enabled || info->default_settings)
    return particle::__SPISettings();
  return particle::__SPISettings(info->clock, info->bit_order, info->data_mode);
}

SPIClass::SPIClass(HAL_SPI_Interface spi)
   e5c10:	b570      	push	{r4, r5, r6, lr}
   e5c12:	4b08      	ldr	r3, [pc, #32]	; (e5c34 <_ZN8SPIClassC1E17HAL_SPI_Interface+0x24>)
   e5c14:	6003      	str	r3, [r0, #0]
   e5c16:	4604      	mov	r4, r0
    Mutex(os_mutex_t handle) : handle_(handle) {}

    /**
     * Creates a new mutex.
     */
    Mutex() : handle_(nullptr)
   e5c18:	2500      	movs	r5, #0
   e5c1a:	460e      	mov	r6, r1
   e5c1c:	f840 5f0c 	str.w	r5, [r0, #12]!
    {
        os_mutex_create(&handle_);
   e5c20:	f7ff fa5c 	bl	e50dc <os_mutex_create>
{
  _spi = spi;
  HAL_SPI_Init(_spi);
   e5c24:	4630      	mov	r0, r6
  return particle::__SPISettings(info->clock, info->bit_order, info->data_mode);
}

SPIClass::SPIClass(HAL_SPI_Interface spi)
{
  _spi = spi;
   e5c26:	7126      	strb	r6, [r4, #4]
  HAL_SPI_Init(_spi);
   e5c28:	f7ff fb30 	bl	e528c <HAL_SPI_Init>
  dividerReference = SPI_CLK_SYSTEM;     // 0 indicates the system clock
   e5c2c:	60a5      	str	r5, [r4, #8]
}
   e5c2e:	4620      	mov	r0, r4
   e5c30:	bd70      	pop	{r4, r5, r6, pc}
   e5c32:	bf00      	nop
   e5c34:	000ecf8c 	.word	0x000ecf8c

000e5c38 <_ZN8SPIClass5beginEv>:

void SPIClass::begin()
{
    // todo - fetch default pin from HAL
  HAL_SPI_Begin(_spi, SPI_DEFAULT_SS);
   e5c38:	f64f 71ff 	movw	r1, #65535	; 0xffff
   e5c3c:	7900      	ldrb	r0, [r0, #4]
   e5c3e:	f7ff bafd 	b.w	e523c <HAL_SPI_Begin>

000e5c42 <_ZN8SPIClass11setBitOrderEh>:
  HAL_SPI_End(_spi);
}

void SPIClass::setBitOrder(uint8_t bitOrder)
{
  HAL_SPI_Set_Bit_Order(_spi, bitOrder);
   e5c42:	7900      	ldrb	r0, [r0, #4]
   e5c44:	f7ff bb02 	b.w	e524c <HAL_SPI_Set_Bit_Order>

000e5c48 <_ZN8SPIClass11setDataModeEh>:
}

void SPIClass::setDataMode(uint8_t mode)
{
  HAL_SPI_Set_Data_Mode(_spi, mode);
   e5c48:	7900      	ldrb	r0, [r0, #4]
   e5c4a:	f7ff bb07 	b.w	e525c <HAL_SPI_Set_Data_Mode>
	...

000e5c50 <_Z17divisorShiftScaleh>:
uint8_t divisorShiftScale(uint8_t divider)
{
    unsigned result = 0;
    for (; result<arraySize(clock_divisors); result++)
    {
        if (clock_divisors[result]==divider)
   e5c50:	4a05      	ldr	r2, [pc, #20]	; (e5c68 <_Z17divisorShiftScaleh+0x18>)
    SPI_CLOCK_DIV256
};

uint8_t divisorShiftScale(uint8_t divider)
{
    unsigned result = 0;
   e5c52:	2300      	movs	r3, #0
    for (; result<arraySize(clock_divisors); result++)
    {
        if (clock_divisors[result]==divider)
   e5c54:	5c99      	ldrb	r1, [r3, r2]
   e5c56:	4281      	cmp	r1, r0
   e5c58:	d002      	beq.n	e5c60 <_Z17divisorShiftScaleh+0x10>
};

uint8_t divisorShiftScale(uint8_t divider)
{
    unsigned result = 0;
    for (; result<arraySize(clock_divisors); result++)
   e5c5a:	3301      	adds	r3, #1
   e5c5c:	2b08      	cmp	r3, #8
   e5c5e:	d1f9      	bne.n	e5c54 <_Z17divisorShiftScaleh+0x4>
    {
        if (clock_divisors[result]==divider)
            break;
    }
    return result+1;
   e5c60:	1c58      	adds	r0, r3, #1
}
   e5c62:	b2c0      	uxtb	r0, r0
   e5c64:	4770      	bx	lr
   e5c66:	bf00      	nop
   e5c68:	000ecf94 	.word	0x000ecf94

000e5c6c <_ZN8SPIClass19computeClockDividerEjjRhRj>:

void SPIClass::computeClockDivider(unsigned reference, unsigned targetSpeed, uint8_t& divider, unsigned& clock)
{
    clock = reference;
    uint8_t scale = 0;
    clock >>= 1;        // div2 is the first
   e5c6c:	0840      	lsrs	r0, r0, #1
        HAL_SPI_Set_Clock_Divider(_spi, rate);
    }
}

void SPIClass::computeClockDivider(unsigned reference, unsigned targetSpeed, uint8_t& divider, unsigned& clock)
{
   e5c6e:	b530      	push	{r4, r5, lr}
    clock = reference;
    uint8_t scale = 0;
    clock >>= 1;        // div2 is the first
   e5c70:	6018      	str	r0, [r3, #0]
   e5c72:	2400      	movs	r4, #0
    while (clock > targetSpeed && scale<7) {
   e5c74:	6818      	ldr	r0, [r3, #0]
   e5c76:	4288      	cmp	r0, r1
   e5c78:	b2e5      	uxtb	r5, r4
   e5c7a:	d906      	bls.n	e5c8a <_ZN8SPIClass19computeClockDividerEjjRhRj+0x1e>
   e5c7c:	3401      	adds	r4, #1
   e5c7e:	2c08      	cmp	r4, #8
   e5c80:	d002      	beq.n	e5c88 <_ZN8SPIClass19computeClockDividerEjjRhRj+0x1c>
        clock >>= 1;
   e5c82:	0840      	lsrs	r0, r0, #1
   e5c84:	6018      	str	r0, [r3, #0]
void SPIClass::computeClockDivider(unsigned reference, unsigned targetSpeed, uint8_t& divider, unsigned& clock)
{
    clock = reference;
    uint8_t scale = 0;
    clock >>= 1;        // div2 is the first
    while (clock > targetSpeed && scale<7) {
   e5c86:	e7f5      	b.n	e5c74 <_ZN8SPIClass19computeClockDividerEjjRhRj+0x8>
   e5c88:	2507      	movs	r5, #7
        clock >>= 1;
        scale++;
    }
    divider = clock_divisors[scale];
   e5c8a:	4b02      	ldr	r3, [pc, #8]	; (e5c94 <_ZN8SPIClass19computeClockDividerEjjRhRj+0x28>)
   e5c8c:	5d5b      	ldrb	r3, [r3, r5]
   e5c8e:	7013      	strb	r3, [r2, #0]
   e5c90:	bd30      	pop	{r4, r5, pc}
   e5c92:	bf00      	nop
   e5c94:	000ecf94 	.word	0x000ecf94

000e5c98 <_ZN8SPIClass13setClockSpeedEjj>:
}

unsigned SPIClass::setClockSpeed(unsigned value, unsigned value_scale)
{
   e5c98:	b570      	push	{r4, r5, r6, lr}
   e5c9a:	b088      	sub	sp, #32
    // actual speed is the system clock divided by some scalar
    unsigned targetSpeed = value*value_scale;
    hal_spi_info_t info;
    querySpiInfo(_spi, &info);
   e5c9c:	7906      	ldrb	r6, [r0, #4]
}

unsigned SPIClass::setClockSpeed(unsigned value, unsigned value_scale)
{
    // actual speed is the system clock divided by some scalar
    unsigned targetSpeed = value*value_scale;
   e5c9e:	fb02 f501 	mul.w	r5, r2, r1
    }
    divider = clock_divisors[scale];
}

unsigned SPIClass::setClockSpeed(unsigned value, unsigned value_scale)
{
   e5ca2:	4604      	mov	r4, r0
#include "core_hal.h"
#include "spark_macros.h"

static void querySpiInfo(HAL_SPI_Interface spi, hal_spi_info_t* info)
{
  memset(info, 0, sizeof(hal_spi_info_t));
   e5ca4:	2214      	movs	r2, #20
   e5ca6:	2100      	movs	r1, #0
   e5ca8:	a803      	add	r0, sp, #12
   e5caa:	f002 ff65 	bl	e8b78 <memset>
  info->version = HAL_SPI_INFO_VERSION_1;
   e5cae:	230b      	movs	r3, #11
  HAL_SPI_Info(spi, info, nullptr);
   e5cb0:	a903      	add	r1, sp, #12
   e5cb2:	4630      	mov	r0, r6
   e5cb4:	2200      	movs	r2, #0
#include "spark_macros.h"

static void querySpiInfo(HAL_SPI_Interface spi, hal_spi_info_t* info)
{
  memset(info, 0, sizeof(hal_spi_info_t));
  info->version = HAL_SPI_INFO_VERSION_1;
   e5cb6:	f8ad 300c 	strh.w	r3, [sp, #12]
  HAL_SPI_Info(spi, info, nullptr);
   e5cba:	f7ff faf7 	bl	e52ac <HAL_SPI_Info>
    unsigned targetSpeed = value*value_scale;
    hal_spi_info_t info;
    querySpiInfo(_spi, &info);
    uint8_t rate;
    unsigned clock;
    computeClockDivider(info.system_clock, targetSpeed, rate, clock);
   e5cbe:	ab02      	add	r3, sp, #8
   e5cc0:	f10d 0207 	add.w	r2, sp, #7
   e5cc4:	4629      	mov	r1, r5
   e5cc6:	9804      	ldr	r0, [sp, #16]
   e5cc8:	f7ff ffd0 	bl	e5c6c <_ZN8SPIClass19computeClockDividerEjjRhRj>
    HAL_SPI_Set_Clock_Divider(_spi, rate);
   e5ccc:	7920      	ldrb	r0, [r4, #4]
   e5cce:	f89d 1007 	ldrb.w	r1, [sp, #7]
   e5cd2:	f7ff facb 	bl	e526c <HAL_SPI_Set_Clock_Divider>
    return clock;
}
   e5cd6:	9802      	ldr	r0, [sp, #8]
   e5cd8:	b008      	add	sp, #32
   e5cda:	bd70      	pop	{r4, r5, r6, pc}

000e5cdc <_ZN8SPIClass15setClockDividerEh>:
    }
    return result+1;
}

void SPIClass::setClockDivider(uint8_t rate)
{
   e5cdc:	b538      	push	{r3, r4, r5, lr}
   e5cde:	4604      	mov	r4, r0
   e5ce0:	4608      	mov	r0, r1
    if (dividerReference)
   e5ce2:	68a5      	ldr	r5, [r4, #8]
   e5ce4:	b14d      	cbz	r5, e5cfa <_ZN8SPIClass15setClockDividerEh+0x1e>
    {
        // determine the clock speed
        uint8_t scale = divisorShiftScale(rate);
   e5ce6:	f7ff ffb3 	bl	e5c50 <_Z17divisorShiftScaleh>
        unsigned targetSpeed = dividerReference>>scale;
        setClockSpeed(targetSpeed);
   e5cea:	2201      	movs	r2, #1
   e5cec:	fa25 f100 	lsr.w	r1, r5, r0
   e5cf0:	4620      	mov	r0, r4
    }
    else
    {
        HAL_SPI_Set_Clock_Divider(_spi, rate);
    }
}
   e5cf2:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
    if (dividerReference)
    {
        // determine the clock speed
        uint8_t scale = divisorShiftScale(rate);
        unsigned targetSpeed = dividerReference>>scale;
        setClockSpeed(targetSpeed);
   e5cf6:	f7ff bfcf 	b.w	e5c98 <_ZN8SPIClass13setClockSpeedEjj>
    }
    else
    {
        HAL_SPI_Set_Clock_Divider(_spi, rate);
   e5cfa:	7920      	ldrb	r0, [r4, #4]
    }
}
   e5cfc:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
        unsigned targetSpeed = dividerReference>>scale;
        setClockSpeed(targetSpeed);
    }
    else
    {
        HAL_SPI_Set_Clock_Divider(_spi, rate);
   e5d00:	f7ff bab4 	b.w	e526c <HAL_SPI_Set_Clock_Divider>

000e5d04 <_ZN8SPIClass8transferEh>:
    HAL_SPI_Set_Clock_Divider(_spi, rate);
    return clock;
}

byte SPIClass::transfer(byte _data)
{
   e5d04:	b508      	push	{r3, lr}
  return HAL_SPI_Send_Receive_Data(_spi, _data);
   e5d06:	7900      	ldrb	r0, [r0, #4]
   e5d08:	f7ff fab8 	bl	e527c <HAL_SPI_Send_Receive_Data>
}
   e5d0c:	b2c0      	uxtb	r0, r0
   e5d0e:	bd08      	pop	{r3, pc}

000e5d10 <_ZN8SPIClass9isEnabledEv>:
  //To Do
}

bool SPIClass::isEnabled()
{
  return HAL_SPI_Is_Enabled(_spi);
   e5d10:	7900      	ldrb	r0, [r0, #4]
   e5d12:	f7ff bac3 	b.w	e529c <HAL_SPI_Is_Enabled>
	...

000e5d18 <_GLOBAL__sub_I_System>:
    WAKEUP_REASON_RTC = 2,
    WAKEUP_REASON_PIN_OR_RTC = 3
};

struct SleepResult {
    SleepResult() {}
   e5d18:	4b04      	ldr	r3, [pc, #16]	; (e5d2c <_GLOBAL__sub_I_System+0x14>)
   e5d1a:	2000      	movs	r0, #0
   e5d1c:	f64f 72ff 	movw	r2, #65535	; 0xffff
   e5d20:	7018      	strb	r0, [r3, #0]
   e5d22:	8058      	strh	r0, [r3, #2]
   e5d24:	809a      	strh	r2, [r3, #4]

class SystemClass {
public:

    SystemClass(System_Mode_TypeDef mode = DEFAULT) {
        set_system_mode(mode);
   e5d26:	f7ff bb49 	b.w	e53bc <set_system_mode>
   e5d2a:	bf00      	nop
   e5d2c:	2003e5d0 	.word	0x2003e5d0

000e5d30 <_GLOBAL__sub_I_TIME_FORMAT_DEFAULT>:
            calendar_time_cache = Convert_UnixTime_To_CalendarTime(unix_time);
            unix_time_cache = unix_time;
    }
}

const char* TimeClass::format_spec = TIME_FORMAT_DEFAULT;
   e5d30:	4b02      	ldr	r3, [pc, #8]	; (e5d3c <_GLOBAL__sub_I_TIME_FORMAT_DEFAULT+0xc>)
   e5d32:	681a      	ldr	r2, [r3, #0]
   e5d34:	4b02      	ldr	r3, [pc, #8]	; (e5d40 <_GLOBAL__sub_I_TIME_FORMAT_DEFAULT+0x10>)
   e5d36:	601a      	str	r2, [r3, #0]
   e5d38:	4770      	bx	lr
   e5d3a:	bf00      	nop
   e5d3c:	2003c230 	.word	0x2003c230
   e5d40:	2003e5d8 	.word	0x2003e5d8

000e5d44 <_ZN11USARTSerialD1Ev>:
private:
  HAL_USART_Serial _serial;
  bool _blocking;
public:
  USARTSerial(HAL_USART_Serial serial, Ring_Buffer *rx_buffer, Ring_Buffer *tx_buffer);
  virtual ~USARTSerial() {};
   e5d44:	4770      	bx	lr

000e5d46 <_ZN11USARTSerial14blockOnOverrunEb>:
    HAL_USART_Half_Duplex(_serial, Enable);
}

void USARTSerial::blockOnOverrun(bool block)
{
  _blocking = block;
   e5d46:	7441      	strb	r1, [r0, #17]
   e5d48:	4770      	bx	lr

000e5d4a <_ZN11USARTSerial17availableForWriteEv>:
}


int USARTSerial::availableForWrite(void)
{
   e5d4a:	b508      	push	{r3, lr}
  return std::max(0, (int)HAL_USART_Available_Data_For_Write(_serial));
   e5d4c:	7c00      	ldrb	r0, [r0, #16]
   e5d4e:	f7ff faed 	bl	e532c <HAL_USART_Available_Data_For_Write>
}
   e5d52:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
   e5d56:	bd08      	pop	{r3, pc}

000e5d58 <_ZN11USARTSerial9availableEv>:

int USARTSerial::available(void)
{
   e5d58:	b508      	push	{r3, lr}
  return std::max(0, (int)HAL_USART_Available_Data(_serial));
   e5d5a:	7c00      	ldrb	r0, [r0, #16]
   e5d5c:	f7ff fabe 	bl	e52dc <HAL_USART_Available_Data>
}
   e5d60:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
   e5d64:	bd08      	pop	{r3, pc}

000e5d66 <_ZN11USARTSerial4peekEv>:

int USARTSerial::peek(void)
{
   e5d66:	b508      	push	{r3, lr}
  return std::max(-1, (int)HAL_USART_Peek_Data(_serial));
   e5d68:	7c00      	ldrb	r0, [r0, #16]
   e5d6a:	f7ff fac7 	bl	e52fc <HAL_USART_Peek_Data>
}
   e5d6e:	ea30 0020 	bics.w	r0, r0, r0, asr #32
   e5d72:	bf28      	it	cs
   e5d74:	f04f 30ff 	movcs.w	r0, #4294967295	; 0xffffffff
   e5d78:	bd08      	pop	{r3, pc}

000e5d7a <_ZN11USARTSerial4readEv>:

int USARTSerial::read(void)
{
   e5d7a:	b508      	push	{r3, lr}
  return std::max(-1, (int)HAL_USART_Read_Data(_serial));
   e5d7c:	7c00      	ldrb	r0, [r0, #16]
   e5d7e:	f7ff fab5 	bl	e52ec <HAL_USART_Read_Data>
}
   e5d82:	ea30 0020 	bics.w	r0, r0, r0, asr #32
   e5d86:	bf28      	it	cs
   e5d88:	f04f 30ff 	movcs.w	r0, #4294967295	; 0xffffffff
   e5d8c:	bd08      	pop	{r3, pc}

000e5d8e <_ZN11USARTSerial5flushEv>:

void USARTSerial::flush()
{
  HAL_USART_Flush_Data(_serial);
   e5d8e:	7c00      	ldrb	r0, [r0, #16]
   e5d90:	f7ff babc 	b.w	e530c <HAL_USART_Flush_Data>

000e5d94 <_ZN11USARTSerialD0Ev>:
   e5d94:	b510      	push	{r4, lr}
   e5d96:	2114      	movs	r1, #20
   e5d98:	4604      	mov	r4, r0
   e5d9a:	f000 fa0a 	bl	e61b2 <_ZdlPvj>
   e5d9e:	4620      	mov	r0, r4
   e5da0:	bd10      	pop	{r4, pc}

000e5da2 <_ZN11USARTSerial5writeEh>:
}

size_t USARTSerial::write(uint8_t c)
{
   e5da2:	b570      	push	{r4, r5, r6, lr}
  // attempt a write if blocking, or for non-blocking if there is room.
  if (_blocking || HAL_USART_Available_Data_For_Write(_serial) > 0) {
   e5da4:	7c45      	ldrb	r5, [r0, #17]
{
  HAL_USART_Flush_Data(_serial);
}

size_t USARTSerial::write(uint8_t c)
{
   e5da6:	4604      	mov	r4, r0
   e5da8:	460e      	mov	r6, r1
  // attempt a write if blocking, or for non-blocking if there is room.
  if (_blocking || HAL_USART_Available_Data_For_Write(_serial) > 0) {
   e5daa:	b925      	cbnz	r5, e5db6 <_ZN11USARTSerial5writeEh+0x14>
   e5dac:	7c00      	ldrb	r0, [r0, #16]
   e5dae:	f7ff fabd 	bl	e532c <HAL_USART_Available_Data_For_Write>
   e5db2:	2800      	cmp	r0, #0
   e5db4:	dd05      	ble.n	e5dc2 <_ZN11USARTSerial5writeEh+0x20>
    // the HAL always blocks.
	  return HAL_USART_Write_Data(_serial, c);
   e5db6:	4631      	mov	r1, r6
   e5db8:	7c20      	ldrb	r0, [r4, #16]
  }
  return 0;
}
   e5dba:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
size_t USARTSerial::write(uint8_t c)
{
  // attempt a write if blocking, or for non-blocking if there is room.
  if (_blocking || HAL_USART_Available_Data_For_Write(_serial) > 0) {
    // the HAL always blocks.
	  return HAL_USART_Write_Data(_serial, c);
   e5dbe:	f7ff ba85 	b.w	e52cc <HAL_USART_Write_Data>
  }
  return 0;
}
   e5dc2:	4628      	mov	r0, r5
   e5dc4:	bd70      	pop	{r4, r5, r6, pc}
	...

000e5dc8 <_ZN11USARTSerialC1E16HAL_USART_SerialP11Ring_BufferS2_>:
#include "spark_wiring_constants.h"
#include "module_info.h"

// Constructors ////////////////////////////////////////////////////////////////

USARTSerial::USARTSerial(HAL_USART_Serial serial, Ring_Buffer *rx_buffer, Ring_Buffer *tx_buffer)
   e5dc8:	b510      	push	{r4, lr}
   e5dca:	4604      	mov	r4, r0
   e5dcc:	4608      	mov	r0, r1
   e5dce:	4611      	mov	r1, r2
  protected:
    void setWriteError(int err = 1) { write_error = err; }
    size_t printf_impl(bool newline, const char* format, ...);

  public:
    Print() : write_error(0) {}
   e5dd0:	2200      	movs	r2, #0
   e5dd2:	6062      	str	r2, [r4, #4]
   e5dd4:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
   e5dd8:	60a2      	str	r2, [r4, #8]
   e5dda:	4a05      	ldr	r2, [pc, #20]	; (e5df0 <_ZN11USARTSerialC1E16HAL_USART_SerialP11Ring_BufferS2_+0x28>)
   e5ddc:	6022      	str	r2, [r4, #0]
{
  _serial = serial;
  // Default is blocking mode
  _blocking = true;
   e5dde:	2201      	movs	r2, #1

// Constructors ////////////////////////////////////////////////////////////////

USARTSerial::USARTSerial(HAL_USART_Serial serial, Ring_Buffer *rx_buffer, Ring_Buffer *tx_buffer)
{
  _serial = serial;
   e5de0:	7420      	strb	r0, [r4, #16]
  // Default is blocking mode
  _blocking = true;
   e5de2:	7462      	strb	r2, [r4, #17]
  HAL_USART_Init(serial, rx_buffer, tx_buffer);
   e5de4:	461a      	mov	r2, r3
   e5de6:	f7ff fa69 	bl	e52bc <HAL_USART_Init>
}
   e5dea:	4620      	mov	r0, r4
   e5dec:	bd10      	pop	{r4, pc}
   e5dee:	bf00      	nop
   e5df0:	000ecfd0 	.word	0x000ecfd0

000e5df4 <_ZN11USARTSerial9isEnabledEv>:
USARTSerial::operator bool() {
  return true;
}

bool USARTSerial::isEnabled() {
  return HAL_USART_Is_Enabled(_serial);
   e5df4:	7c00      	ldrb	r0, [r0, #16]
   e5df6:	f7ff ba91 	b.w	e531c <HAL_USART_Is_Enabled>
	...

000e5dfc <_Z22__fetch_global_Serial1v>:
static Ring_Buffer* serial1_rx_buffer = NULL;
static Ring_Buffer* serial1_tx_buffer = NULL;
#endif

USARTSerial& __fetch_global_Serial1()
{
   e5dfc:	b538      	push	{r3, r4, r5, lr}
#if ((MODULE_FUNCTION == MOD_FUNC_USER_PART) || (MODULE_FUNCTION == MOD_FUNC_MONO_FIRMWARE))
	static USARTSerial serial1(HAL_USART_SERIAL1, &serial1_rx_buffer, &serial1_tx_buffer);
   e5dfe:	4d0c      	ldr	r5, [pc, #48]	; (e5e30 <_Z22__fetch_global_Serial1v+0x34>)
   e5e00:	6829      	ldr	r1, [r5, #0]
   e5e02:	f011 0401 	ands.w	r4, r1, #1
   e5e06:	d111      	bne.n	e5e2c <_Z22__fetch_global_Serial1v+0x30>
   e5e08:	4628      	mov	r0, r5
   e5e0a:	f7ee f961 	bl	d40d0 <__cxa_guard_acquire>
   e5e0e:	b168      	cbz	r0, e5e2c <_Z22__fetch_global_Serial1v+0x30>
   e5e10:	4a08      	ldr	r2, [pc, #32]	; (e5e34 <_Z22__fetch_global_Serial1v+0x38>)
   e5e12:	4b09      	ldr	r3, [pc, #36]	; (e5e38 <_Z22__fetch_global_Serial1v+0x3c>)
   e5e14:	4809      	ldr	r0, [pc, #36]	; (e5e3c <_Z22__fetch_global_Serial1v+0x40>)
   e5e16:	4621      	mov	r1, r4
   e5e18:	f7ff ffd6 	bl	e5dc8 <_ZN11USARTSerialC1E16HAL_USART_SerialP11Ring_BufferS2_>
   e5e1c:	4628      	mov	r0, r5
   e5e1e:	f7ee f95c 	bl	d40da <__cxa_guard_release>
   e5e22:	4a07      	ldr	r2, [pc, #28]	; (e5e40 <_Z22__fetch_global_Serial1v+0x44>)
   e5e24:	4907      	ldr	r1, [pc, #28]	; (e5e44 <_Z22__fetch_global_Serial1v+0x48>)
   e5e26:	4805      	ldr	r0, [pc, #20]	; (e5e3c <_Z22__fetch_global_Serial1v+0x40>)
   e5e28:	f000 f9be 	bl	e61a8 <__aeabi_atexit>
    serial1_tx_buffer = new Ring_Buffer();
  }
  static USARTSerial serial1(HAL_USART_SERIAL1, serial1_rx_buffer, serial1_tx_buffer);
#endif
	return serial1;
}
   e5e2c:	4803      	ldr	r0, [pc, #12]	; (e5e3c <_Z22__fetch_global_Serial1v+0x40>)
   e5e2e:	bd38      	pop	{r3, r4, r5, pc}
   e5e30:	2003e674 	.word	0x2003e674
   e5e34:	2003e678 	.word	0x2003e678
   e5e38:	2003e5f0 	.word	0x2003e5f0
   e5e3c:	2003e5dc 	.word	0x2003e5dc
   e5e40:	2003c2a0 	.word	0x2003c2a0
   e5e44:	000e5d45 	.word	0x000e5d45

000e5e48 <_ZN9USBSerial14blockOnOverrunEb>:
  HAL_USB_USART_Flush_Data(_serial);
}

void USBSerial::blockOnOverrun(bool block)
{
  _blocking = block;
   e5e48:	7441      	strb	r1, [r0, #17]
   e5e4a:	4770      	bx	lr

000e5e4c <_ZN9USBSerialD1Ev>:
#include "usb_hal.h"
#include "system_task.h"
#include "spark_wiring_startup.h"
#include "concurrent_hal.h"

class USBSerial : public Stream
   e5e4c:	4770      	bx	lr

000e5e4e <_ZN9USBSerial4readEv>:
}


// Read data from buffer
int USBSerial::read()
{
   e5e4e:	b508      	push	{r3, lr}
	return std::max(-1, (int)HAL_USB_USART_Receive_Data(_serial, false));
   e5e50:	2100      	movs	r1, #0
   e5e52:	7c00      	ldrb	r0, [r0, #16]
   e5e54:	f7ff fa92 	bl	e537c <HAL_USB_USART_Receive_Data>
}
   e5e58:	ea30 0020 	bics.w	r0, r0, r0, asr #32
   e5e5c:	bf28      	it	cs
   e5e5e:	f04f 30ff 	movcs.w	r0, #4294967295	; 0xffffffff
   e5e62:	bd08      	pop	{r3, pc}

000e5e64 <_ZN9USBSerial4peekEv>:
{
  _blocking = block;
}

int USBSerial::peek()
{
   e5e64:	b508      	push	{r3, lr}
	return std::max(-1, (int)HAL_USB_USART_Receive_Data(_serial, true));
   e5e66:	2101      	movs	r1, #1
   e5e68:	7c00      	ldrb	r0, [r0, #16]
   e5e6a:	f7ff fa87 	bl	e537c <HAL_USB_USART_Receive_Data>
}
   e5e6e:	ea30 0020 	bics.w	r0, r0, r0, asr #32
   e5e72:	bf28      	it	cs
   e5e74:	f04f 30ff 	movcs.w	r0, #4294967295	; 0xffffffff
   e5e78:	bd08      	pop	{r3, pc}

000e5e7a <_ZN9USBSerial17availableForWriteEv>:
{
	return std::max(-1, (int)HAL_USB_USART_Receive_Data(_serial, false));
}

int USBSerial::availableForWrite()
{
   e5e7a:	b508      	push	{r3, lr}
  return std::max(0, (int)HAL_USB_USART_Available_Data_For_Write(_serial));
   e5e7c:	7c00      	ldrb	r0, [r0, #16]
   e5e7e:	f7ff fa75 	bl	e536c <HAL_USB_USART_Available_Data_For_Write>
}
   e5e82:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
   e5e86:	bd08      	pop	{r3, pc}

000e5e88 <_ZN9USBSerial9availableEv>:

int USBSerial::available()
{
   e5e88:	b508      	push	{r3, lr}
	return std::max(0, (int)HAL_USB_USART_Available_Data(_serial));
   e5e8a:	7c00      	ldrb	r0, [r0, #16]
   e5e8c:	f7ff fa66 	bl	e535c <HAL_USB_USART_Available_Data>
}
   e5e90:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
   e5e94:	bd08      	pop	{r3, pc}

000e5e96 <_ZN9USBSerial5flushEv>:
  return 0;
}

void USBSerial::flush()
{
  HAL_USB_USART_Flush_Data(_serial);
   e5e96:	7c00      	ldrb	r0, [r0, #16]
   e5e98:	f7ff ba80 	b.w	e539c <HAL_USB_USART_Flush_Data>

000e5e9c <_ZN9USBSerialD0Ev>:
   e5e9c:	b510      	push	{r4, lr}
   e5e9e:	2114      	movs	r1, #20
   e5ea0:	4604      	mov	r4, r0
   e5ea2:	f000 f986 	bl	e61b2 <_ZdlPvj>
   e5ea6:	4620      	mov	r0, r4
   e5ea8:	bd10      	pop	{r4, pc}

000e5eaa <_ZN9USBSerial5writeEh>:
{
	return std::max(0, (int)HAL_USB_USART_Available_Data(_serial));
}

size_t USBSerial::write(uint8_t byte)
{
   e5eaa:	b538      	push	{r3, r4, r5, lr}
   e5eac:	4604      	mov	r4, r0
  if (HAL_USB_USART_Available_Data_For_Write(_serial) > 0 || _blocking) {
   e5eae:	7c00      	ldrb	r0, [r0, #16]
{
	return std::max(0, (int)HAL_USB_USART_Available_Data(_serial));
}

size_t USBSerial::write(uint8_t byte)
{
   e5eb0:	460d      	mov	r5, r1
  if (HAL_USB_USART_Available_Data_For_Write(_serial) > 0 || _blocking) {
   e5eb2:	f7ff fa5b 	bl	e536c <HAL_USB_USART_Available_Data_For_Write>
   e5eb6:	2800      	cmp	r0, #0
   e5eb8:	dc01      	bgt.n	e5ebe <_ZN9USBSerial5writeEh+0x14>
   e5eba:	7c60      	ldrb	r0, [r4, #17]
   e5ebc:	b128      	cbz	r0, e5eca <_ZN9USBSerial5writeEh+0x20>
    return std::max(0, (int)HAL_USB_USART_Send_Data(_serial, byte));
   e5ebe:	4629      	mov	r1, r5
   e5ec0:	7c20      	ldrb	r0, [r4, #16]
   e5ec2:	f7ff fa63 	bl	e538c <HAL_USB_USART_Send_Data>
   e5ec6:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
  }
  return 0;
}
   e5eca:	bd38      	pop	{r3, r4, r5, pc}

000e5ecc <_ZN9USBSerialC1E20HAL_USB_USART_SerialRK20HAL_USB_USART_Config>:

  HAL_USB_USART_Config conf = acquireSerialBuffer();
  HAL_USB_USART_Init(_serial, &conf);
}

USBSerial::USBSerial(HAL_USB_USART_Serial serial, const HAL_USB_USART_Config& conf)
   e5ecc:	b510      	push	{r4, lr}
   e5ece:	4604      	mov	r4, r0
   e5ed0:	2300      	movs	r3, #0
   e5ed2:	6063      	str	r3, [r4, #4]
   e5ed4:	f44f 737a 	mov.w	r3, #1000	; 0x3e8
   e5ed8:	60a3      	str	r3, [r4, #8]
   e5eda:	4b05      	ldr	r3, [pc, #20]	; (e5ef0 <_ZN9USBSerialC1E20HAL_USB_USART_SerialRK20HAL_USB_USART_Config+0x24>)
   e5edc:	6023      	str	r3, [r4, #0]
{
  _serial = serial;
  _blocking = true;
   e5ede:	2301      	movs	r3, #1

  HAL_USB_USART_Config conf = acquireSerialBuffer();
  HAL_USB_USART_Init(_serial, &conf);
}

USBSerial::USBSerial(HAL_USB_USART_Serial serial, const HAL_USB_USART_Config& conf)
   e5ee0:	4608      	mov	r0, r1
{
  _serial = serial;
   e5ee2:	7421      	strb	r1, [r4, #16]
  _blocking = true;
   e5ee4:	7463      	strb	r3, [r4, #17]

  HAL_USB_USART_Init(_serial, &conf);
   e5ee6:	4611      	mov	r1, r2
   e5ee8:	f7ff fa28 	bl	e533c <HAL_USB_USART_Init>
}
   e5eec:	4620      	mov	r0, r4
   e5eee:	bd10      	pop	{r4, pc}
   e5ef0:	000ed000 	.word	0x000ed000

000e5ef4 <_ZN9USBSerial5beginEl>:
// Public methods
//

void USBSerial::begin(long speed)
{
    HAL_USB_USART_Begin(_serial, speed, NULL);
   e5ef4:	2200      	movs	r2, #0
   e5ef6:	7c00      	ldrb	r0, [r0, #16]
   e5ef8:	f7ff ba28 	b.w	e534c <HAL_USB_USART_Begin>

000e5efc <_Z19acquireSerialBufferv>:

// Preinstantiate Objects //////////////////////////////////////////////////////
#ifdef SPARK_USB_SERIAL

HAL_USB_USART_Config __attribute__((weak)) acquireSerialBuffer()
{
   e5efc:	b510      	push	{r4, lr}
  HAL_USB_USART_Config conf = {0};
   e5efe:	2214      	movs	r2, #20

// Preinstantiate Objects //////////////////////////////////////////////////////
#ifdef SPARK_USB_SERIAL

HAL_USB_USART_Config __attribute__((weak)) acquireSerialBuffer()
{
   e5f00:	4604      	mov	r4, r0
  HAL_USB_USART_Config conf = {0};
   e5f02:	2100      	movs	r1, #0
   e5f04:	f002 fe38 	bl	e8b78 <memset>
  conf.rx_buffer_size = USB_RX_BUFFER_SIZE;
  conf.tx_buffer_size = USB_TX_BUFFER_SIZE;
#endif

  return conf;
}
   e5f08:	4620      	mov	r0, r4
   e5f0a:	bd10      	pop	{r4, pc}

000e5f0c <_Z16_fetch_usbserialv>:

USBSerial& _fetch_usbserial()
{
   e5f0c:	b530      	push	{r4, r5, lr}
  HAL_USB_USART_Config conf = acquireSerialBuffer();
	static USBSerial _usbserial(HAL_USB_USART_SERIAL, conf);
   e5f0e:	4d0e      	ldr	r5, [pc, #56]	; (e5f48 <_Z16_fetch_usbserialv+0x3c>)

  return conf;
}

USBSerial& _fetch_usbserial()
{
   e5f10:	b087      	sub	sp, #28
  HAL_USB_USART_Config conf = acquireSerialBuffer();
   e5f12:	a801      	add	r0, sp, #4
   e5f14:	f7ff fff2 	bl	e5efc <_Z19acquireSerialBufferv>
	static USBSerial _usbserial(HAL_USB_USART_SERIAL, conf);
   e5f18:	6829      	ldr	r1, [r5, #0]
   e5f1a:	f011 0401 	ands.w	r4, r1, #1
   e5f1e:	d110      	bne.n	e5f42 <_Z16_fetch_usbserialv+0x36>
   e5f20:	4628      	mov	r0, r5
   e5f22:	f7ee f8d5 	bl	d40d0 <__cxa_guard_acquire>
   e5f26:	b160      	cbz	r0, e5f42 <_Z16_fetch_usbserialv+0x36>
   e5f28:	aa01      	add	r2, sp, #4
   e5f2a:	4621      	mov	r1, r4
   e5f2c:	4807      	ldr	r0, [pc, #28]	; (e5f4c <_Z16_fetch_usbserialv+0x40>)
   e5f2e:	f7ff ffcd 	bl	e5ecc <_ZN9USBSerialC1E20HAL_USB_USART_SerialRK20HAL_USB_USART_Config>
   e5f32:	4628      	mov	r0, r5
   e5f34:	f7ee f8d1 	bl	d40da <__cxa_guard_release>
   e5f38:	4a05      	ldr	r2, [pc, #20]	; (e5f50 <_Z16_fetch_usbserialv+0x44>)
   e5f3a:	4906      	ldr	r1, [pc, #24]	; (e5f54 <_Z16_fetch_usbserialv+0x48>)
   e5f3c:	4803      	ldr	r0, [pc, #12]	; (e5f4c <_Z16_fetch_usbserialv+0x40>)
   e5f3e:	f000 f933 	bl	e61a8 <__aeabi_atexit>
	return _usbserial;
}
   e5f42:	4802      	ldr	r0, [pc, #8]	; (e5f4c <_Z16_fetch_usbserialv+0x40>)
   e5f44:	b007      	add	sp, #28
   e5f46:	bd30      	pop	{r4, r5, pc}
   e5f48:	2003e6fc 	.word	0x2003e6fc
   e5f4c:	2003e700 	.word	0x2003e700
   e5f50:	2003c2a0 	.word	0x2003c2a0
   e5f54:	000e5e4d 	.word	0x000e5e4d

000e5f58 <serialEventRun>:

/**
 * Provides background processing of serial data.
 */
void serialEventRun()
{
   e5f58:	b508      	push	{r3, lr}
    if (serialEvent && Serial.available()>0)
   e5f5a:	4b0f      	ldr	r3, [pc, #60]	; (e5f98 <serialEventRun+0x40>)
   e5f5c:	b133      	cbz	r3, e5f6c <serialEventRun+0x14>
   e5f5e:	f7ff ffd5 	bl	e5f0c <_Z16_fetch_usbserialv>
   e5f62:	6803      	ldr	r3, [r0, #0]
   e5f64:	691b      	ldr	r3, [r3, #16]
   e5f66:	4798      	blx	r3
   e5f68:	2800      	cmp	r0, #0
   e5f6a:	dc0d      	bgt.n	e5f88 <serialEventRun+0x30>
        serialEvent();

    if (serialEvent1 && Serial1.available()>0)
   e5f6c:	4b0b      	ldr	r3, [pc, #44]	; (e5f9c <serialEventRun+0x44>)
   e5f6e:	b133      	cbz	r3, e5f7e <serialEventRun+0x26>
   e5f70:	f7ff ff44 	bl	e5dfc <_Z22__fetch_global_Serial1v>
   e5f74:	6803      	ldr	r3, [r0, #0]
   e5f76:	691b      	ldr	r3, [r3, #16]
   e5f78:	4798      	blx	r3
   e5f7a:	2800      	cmp	r0, #0
   e5f7c:	dc07      	bgt.n	e5f8e <serialEventRun+0x36>
        serialEvent1();

#if Wiring_Serial2
    if (serialEventRun2) serialEventRun2();
   e5f7e:	4b08      	ldr	r3, [pc, #32]	; (e5fa0 <serialEventRun+0x48>)
   e5f80:	b143      	cbz	r3, e5f94 <serialEventRun+0x3c>
   e5f82:	f3af 8000 	nop.w

#if Wiring_USBSerial1
    if (usbSerialEvent1 && USBSerial1.available()>0)
        usbSerialEvent1();
#endif
}
   e5f86:	bd08      	pop	{r3, pc}
 * Provides background processing of serial data.
 */
void serialEventRun()
{
    if (serialEvent && Serial.available()>0)
        serialEvent();
   e5f88:	f3af 8000 	nop.w
   e5f8c:	e7ee      	b.n	e5f6c <serialEventRun+0x14>

    if (serialEvent1 && Serial1.available()>0)
        serialEvent1();
   e5f8e:	f3af 8000 	nop.w
   e5f92:	e7f4      	b.n	e5f7e <serialEventRun+0x26>
   e5f94:	bd08      	pop	{r3, pc}
   e5f96:	bf00      	nop
	...

000e5fa4 <_post_loop>:
#if Wiring_Serial5
void serialEvent5() __attribute__((weak));
#endif

void _post_loop()
{
   e5fa4:	b508      	push	{r3, lr}
	serialEventRun();
   e5fa6:	f7ff ffd7 	bl	e5f58 <serialEventRun>
		return !timeout_fn;
	}

	static inline system_tick_t current_time()
	{
		return HAL_Timer_Get_Milli_Seconds();
   e5faa:	f7ff f8b7 	bl	e511c <HAL_Timer_Get_Milli_Seconds>
	/**
	 * Lifesign that the application is still working normally.
	 */
	static void checkin()
	{
		last_checkin = current_time();
   e5fae:	4b01      	ldr	r3, [pc, #4]	; (e5fb4 <_post_loop+0x10>)
   e5fb0:	6018      	str	r0, [r3, #0]
   e5fb2:	bd08      	pop	{r3, pc}
   e5fb4:	2003e718 	.word	0x2003e718

000e5fb8 <_Z27ctrl_request_custom_handlerP12ctrl_request>:
bool __backup_ram_was_valid() { return false; }

#endif

// Default handler for CTRL_REQUEST_APP_CUSTOM requests
void __attribute((weak)) ctrl_request_custom_handler(ctrl_request* req) {
   e5fb8:	b507      	push	{r0, r1, r2, lr}
    system_ctrl_set_result(req, SYSTEM_ERROR_NOT_SUPPORTED, nullptr, nullptr, nullptr);
   e5fba:	2300      	movs	r3, #0
   e5fbc:	9300      	str	r3, [sp, #0]
   e5fbe:	461a      	mov	r2, r3
   e5fc0:	f06f 0177 	mvn.w	r1, #119	; 0x77
   e5fc4:	f7ff fa1c 	bl	e5400 <system_ctrl_set_result>
}
   e5fc8:	b003      	add	sp, #12
   e5fca:	f85d fb04 	ldr.w	pc, [sp], #4
	...

000e5fd0 <_ZL20ctrl_request_handlerP12ctrl_request>:
// Callback invoked to process a logging configuration request
void(*log_process_ctrl_request_callback)(ctrl_request* req) = nullptr;
#endif

// Application handler for control requests
static void ctrl_request_handler(ctrl_request* req) {
   e5fd0:	b507      	push	{r0, r1, r2, lr}
    switch (req->type) {
   e5fd2:	8843      	ldrh	r3, [r0, #2]
   e5fd4:	2b0a      	cmp	r3, #10
   e5fd6:	d008      	beq.n	e5fea <_ZL20ctrl_request_handlerP12ctrl_request+0x1a>
   e5fd8:	2b50      	cmp	r3, #80	; 0x50
   e5fda:	d109      	bne.n	e5ff0 <_ZL20ctrl_request_handlerP12ctrl_request+0x20>
#if Wiring_LogConfig
    case CTRL_REQUEST_LOG_CONFIG: {
        if (log_process_ctrl_request_callback) {
   e5fdc:	4b09      	ldr	r3, [pc, #36]	; (e6004 <_ZL20ctrl_request_handlerP12ctrl_request+0x34>)
   e5fde:	681b      	ldr	r3, [r3, #0]
   e5fe0:	b13b      	cbz	r3, e5ff2 <_ZL20ctrl_request_handlerP12ctrl_request+0x22>
    }
    default:
        system_ctrl_set_result(req, SYSTEM_ERROR_NOT_SUPPORTED, nullptr, nullptr, nullptr);
        break;
    }
}
   e5fe2:	b003      	add	sp, #12
   e5fe4:	f85d eb04 	ldr.w	lr, [sp], #4
static void ctrl_request_handler(ctrl_request* req) {
    switch (req->type) {
#if Wiring_LogConfig
    case CTRL_REQUEST_LOG_CONFIG: {
        if (log_process_ctrl_request_callback) {
            log_process_ctrl_request_callback(req);
   e5fe8:	4718      	bx	r3
        }
        break;
    }
#endif
    case CTRL_REQUEST_APP_CUSTOM: {
        ctrl_request_custom_handler(req);
   e5fea:	f7ff ffe5 	bl	e5fb8 <_Z27ctrl_request_custom_handlerP12ctrl_request>
        break;
   e5fee:	e006      	b.n	e5ffe <_ZL20ctrl_request_handlerP12ctrl_request+0x2e>
    }
    default:
        system_ctrl_set_result(req, SYSTEM_ERROR_NOT_SUPPORTED, nullptr, nullptr, nullptr);
   e5ff0:	2300      	movs	r3, #0
   e5ff2:	9300      	str	r3, [sp, #0]
   e5ff4:	461a      	mov	r2, r3
   e5ff6:	f06f 0177 	mvn.w	r1, #119	; 0x77
   e5ffa:	f7ff fa01 	bl	e5400 <system_ctrl_set_result>
        break;
    }
}
   e5ffe:	b003      	add	sp, #12
   e6000:	f85d fb04 	ldr.w	pc, [sp], #4
   e6004:	2003e714 	.word	0x2003e714

000e6008 <module_user_init_hook>:

void module_user_init_hook()
{
   e6008:	b510      	push	{r4, lr}
    }
#endif

#if HAL_PLATFORM_RNG
    // Initialize the default stdlib PRNG using hardware RNG as a seed
    const uint32_t seed = HAL_RNG_GetRandomNumber();
   e600a:	f7ff f877 	bl	e50fc <HAL_RNG_GetRandomNumber>
   e600e:	4604      	mov	r4, r0
    srand(seed);
   e6010:	f002 fdba 	bl	e8b88 <srand>

    // If the user defines random_seed_from_cloud, call it with a seed value
    // generated by a hardware RNG as well.
    if (random_seed_from_cloud) {
   e6014:	4b07      	ldr	r3, [pc, #28]	; (e6034 <module_user_init_hook+0x2c>)
   e6016:	b113      	cbz	r3, e601e <module_user_init_hook+0x16>
        random_seed_from_cloud(seed);
   e6018:	4620      	mov	r0, r4
   e601a:	f3af 8000 	nop.w
    }
#endif
    // Register the random_seed_from_cloud handler
    spark_set_random_seed_from_cloud_handler(&random_seed_from_cloud, nullptr);
   e601e:	2100      	movs	r1, #0
   e6020:	4804      	ldr	r0, [pc, #16]	; (e6034 <module_user_init_hook+0x2c>)
   e6022:	f7ff f9f7 	bl	e5414 <spark_set_random_seed_from_cloud_handler>

    // Register application handler for the control requests
    system_ctrl_set_app_request_handler(ctrl_request_handler, nullptr);
   e6026:	2100      	movs	r1, #0
   e6028:	4803      	ldr	r0, [pc, #12]	; (e6038 <module_user_init_hook+0x30>)
}
   e602a:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
#endif
    // Register the random_seed_from_cloud handler
    spark_set_random_seed_from_cloud_handler(&random_seed_from_cloud, nullptr);

    // Register application handler for the control requests
    system_ctrl_set_app_request_handler(ctrl_request_handler, nullptr);
   e602e:	f7ff b9dd 	b.w	e53ec <system_ctrl_set_app_request_handler>
   e6032:	bf00      	nop
   e6034:	00000000 	.word	0x00000000
   e6038:	000e5fd1 	.word	0x000e5fd1

000e603c <pinAvailable>:

/*
 * @brief Perform safety check on desired pin to see if it's already
 * being used.  Return 0 if used, otherwise return 1 if available.
 */
bool pinAvailable(uint16_t pin) {
   e603c:	b510      	push	{r4, lr}
   e603e:	4604      	mov	r4, r0

  // SPI safety check
#ifndef SPARK_WIRING_NO_SPI
  if(SPI.isEnabled() == true && (pin == SCK || pin == MOSI || pin == MISO))
   e6040:	480f      	ldr	r0, [pc, #60]	; (e6080 <pinAvailable+0x44>)
   e6042:	f7ff fe65 	bl	e5d10 <_ZN8SPIClass9isEnabledEv>
   e6046:	b128      	cbz	r0, e6054 <pinAvailable+0x18>
   e6048:	f1a4 030b 	sub.w	r3, r4, #11
   e604c:	2b02      	cmp	r3, #2
   e604e:	d801      	bhi.n	e6054 <pinAvailable+0x18>
  {
    return 0; // 'pin' is used
   e6050:	2000      	movs	r0, #0
   e6052:	bd10      	pop	{r4, pc}
  }
#endif
  // I2C safety check
#ifndef SPARK_WIRING_NO_I2C
  if(Wire.isEnabled() == true && (pin == SCL || pin == SDA))
   e6054:	f000 f866 	bl	e6124 <_Z19__fetch_global_Wirev>
   e6058:	f7ff fb3e 	bl	e56d8 <_ZN7TwoWire9isEnabledEv>
   e605c:	b108      	cbz	r0, e6062 <pinAvailable+0x26>
   e605e:	2c01      	cmp	r4, #1
   e6060:	d9f6      	bls.n	e6050 <pinAvailable+0x14>
    return 0; // 'pin' is used
  }
#endif
#ifndef SPARK_WIRING_NO_USART_SERIAL
  // Serial1 safety check
  if(Serial1.isEnabled() == true && (pin == RX || pin == TX))
   e6062:	f7ff fecb 	bl	e5dfc <_Z22__fetch_global_Serial1v>
   e6066:	f7ff fec5 	bl	e5df4 <_ZN11USARTSerial9isEnabledEv>
   e606a:	b118      	cbz	r0, e6074 <pinAvailable+0x38>
   e606c:	f1a4 0309 	sub.w	r3, r4, #9
   e6070:	2b01      	cmp	r3, #1
   e6072:	d9ed      	bls.n	e6050 <pinAvailable+0x14>
  {
    return 0; // 'pin' is used
  }
#endif

  if (pin >= TOTAL_PINS)
   e6074:	2c1e      	cmp	r4, #30
   e6076:	bf8c      	ite	hi
   e6078:	2000      	movhi	r0, #0
   e607a:	2001      	movls	r0, #1
    return 0;
  else
    return 1; // 'pin' is available
}
   e607c:	bd10      	pop	{r4, pc}
   e607e:	bf00      	nop
   e6080:	2003e734 	.word	0x2003e734

000e6084 <pinMode>:
 * or INPUT_PULLDOWN
 */
void pinMode(uint16_t pin, PinMode setMode)
{

  if(pin >= TOTAL_PINS || setMode == PIN_MODE_NONE )
   e6084:	281e      	cmp	r0, #30
/*
 * @brief Set the mode of the pin to OUTPUT, INPUT, INPUT_PULLUP,
 * or INPUT_PULLDOWN
 */
void pinMode(uint16_t pin, PinMode setMode)
{
   e6086:	b538      	push	{r3, r4, r5, lr}
   e6088:	4604      	mov	r4, r0
   e608a:	460d      	mov	r5, r1

  if(pin >= TOTAL_PINS || setMode == PIN_MODE_NONE )
   e608c:	d80a      	bhi.n	e60a4 <pinMode+0x20>
   e608e:	29ff      	cmp	r1, #255	; 0xff
   e6090:	d008      	beq.n	e60a4 <pinMode+0x20>
  {
    return;
  }

  // Safety check
  if( !pinAvailable(pin) ) {
   e6092:	f7ff ffd3 	bl	e603c <pinAvailable>
   e6096:	b128      	cbz	r0, e60a4 <pinMode+0x20>
    return;
  }

  HAL_Pin_Mode(pin, setMode);
   e6098:	4629      	mov	r1, r5
   e609a:	4620      	mov	r0, r4
}
   e609c:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
  // Safety check
  if( !pinAvailable(pin) ) {
    return;
  }

  HAL_Pin_Mode(pin, setMode);
   e60a0:	f7ff b854 	b.w	e514c <HAL_Pin_Mode>
   e60a4:	bd38      	pop	{r3, r4, r5, pc}

000e60a6 <digitalWrite>:

/*
 * @brief Sets a GPIO pin to HIGH or LOW.
 */
void digitalWrite(pin_t pin, uint8_t value)
{
   e60a6:	b538      	push	{r3, r4, r5, lr}
   e60a8:	4604      	mov	r4, r0
   e60aa:	460d      	mov	r5, r1
    PinMode mode = HAL_Get_Pin_Mode(pin);
   e60ac:	f7ff f856 	bl	e515c <HAL_Get_Pin_Mode>
    if (mode==PIN_MODE_NONE || is_input_mode(mode))
   e60b0:	28ff      	cmp	r0, #255	; 0xff
   e60b2:	d010      	beq.n	e60d6 <digitalWrite+0x30>
}

inline bool is_input_mode(PinMode mode) {
    return  mode == INPUT ||
            mode == INPUT_PULLUP ||
            mode == INPUT_PULLDOWN ||
   e60b4:	2806      	cmp	r0, #6
   e60b6:	d804      	bhi.n	e60c2 <digitalWrite+0x1c>
   e60b8:	234d      	movs	r3, #77	; 0x4d
   e60ba:	fa23 f000 	lsr.w	r0, r3, r0
   e60be:	07c3      	lsls	r3, r0, #31
   e60c0:	d409      	bmi.n	e60d6 <digitalWrite+0x30>
{
    PinMode mode = HAL_Get_Pin_Mode(pin);
    if (mode==PIN_MODE_NONE || is_input_mode(mode))
        return;
  // Safety check
  if( !pinAvailable(pin) ) {
   e60c2:	4620      	mov	r0, r4
   e60c4:	f7ff ffba 	bl	e603c <pinAvailable>
   e60c8:	b128      	cbz	r0, e60d6 <digitalWrite+0x30>
    return;
  }

  HAL_GPIO_Write(pin, value);
   e60ca:	4629      	mov	r1, r5
   e60cc:	4620      	mov	r0, r4
}
   e60ce:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
  // Safety check
  if( !pinAvailable(pin) ) {
    return;
  }

  HAL_GPIO_Write(pin, value);
   e60d2:	f7ff b84b 	b.w	e516c <HAL_GPIO_Write>
   e60d6:	bd38      	pop	{r3, r4, r5, pc}

000e60d8 <_Z11analogWritetm>:
/*
 * @brief Should take an integer 0-255 and create a 500Hz PWM signal with a duty cycle from 0-100%.
 * On Photon, DAC1 and DAC2 act as true analog outputs(values: 0 to 4095) using onchip DAC peripheral
 */
void analogWrite(pin_t pin, uint32_t value)
{
   e60d8:	b538      	push	{r3, r4, r5, lr}
   e60da:	4604      	mov	r4, r0
   e60dc:	460d      	mov	r5, r1
    // Safety check
    if (!pinAvailable(pin))
   e60de:	f7ff ffad 	bl	e603c <pinAvailable>
   e60e2:	b1f0      	cbz	r0, e6122 <_Z11analogWritetm+0x4a>
    {
        return;
    }

    if (HAL_Validate_Pin_Function(pin, PF_DAC) == PF_DAC)
   e60e4:	2104      	movs	r1, #4
   e60e6:	4620      	mov	r0, r4
   e60e8:	f7ff f828 	bl	e513c <HAL_Validate_Pin_Function>
   e60ec:	2804      	cmp	r0, #4
   e60ee:	d105      	bne.n	e60fc <_Z11analogWritetm+0x24>
    {
        HAL_DAC_Write(pin, value);
   e60f0:	b2a9      	uxth	r1, r5
   e60f2:	4620      	mov	r0, r4
            return;
        }

        HAL_PWM_Write_Ext(pin, value);
    }
}
   e60f4:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
        return;
    }

    if (HAL_Validate_Pin_Function(pin, PF_DAC) == PF_DAC)
    {
        HAL_DAC_Write(pin, value);
   e60f8:	f7ff b840 	b.w	e517c <HAL_DAC_Write>
    }
    else if (HAL_Validate_Pin_Function(pin, PF_TIMER) == PF_TIMER)
   e60fc:	2102      	movs	r1, #2
   e60fe:	4620      	mov	r0, r4
   e6100:	f7ff f81c 	bl	e513c <HAL_Validate_Pin_Function>
   e6104:	2802      	cmp	r0, #2
   e6106:	d10c      	bne.n	e6122 <_Z11analogWritetm+0x4a>
    {
        PinMode mode = HAL_Get_Pin_Mode(pin);
   e6108:	4620      	mov	r0, r4
   e610a:	f7ff f827 	bl	e515c <HAL_Get_Pin_Mode>

        if (mode != OUTPUT && mode != AF_OUTPUT_PUSHPULL)
   e610e:	2801      	cmp	r0, #1
   e6110:	d001      	beq.n	e6116 <_Z11analogWritetm+0x3e>
   e6112:	2804      	cmp	r0, #4
   e6114:	d105      	bne.n	e6122 <_Z11analogWritetm+0x4a>
        {
            return;
        }

        HAL_PWM_Write_Ext(pin, value);
   e6116:	4629      	mov	r1, r5
   e6118:	4620      	mov	r0, r4
    }
}
   e611a:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
        if (mode != OUTPUT && mode != AF_OUTPUT_PUSHPULL)
        {
            return;
        }

        HAL_PWM_Write_Ext(pin, value);
   e611e:	f7ff b835 	b.w	e518c <HAL_PWM_Write_Ext>
   e6122:	bd38      	pop	{r3, r4, r5, pc}

000e6124 <_Z19__fetch_global_Wirev>:
#include "i2c_hal.h"

#ifndef SPARK_WIRING_NO_I2C

TwoWire& __fetch_global_Wire()
{
   e6124:	b538      	push	{r3, r4, r5, lr}
	static TwoWire wire(HAL_I2C_INTERFACE1);
   e6126:	4d0b      	ldr	r5, [pc, #44]	; (e6154 <_Z19__fetch_global_Wirev+0x30>)
   e6128:	6829      	ldr	r1, [r5, #0]
   e612a:	f011 0401 	ands.w	r4, r1, #1
   e612e:	d10f      	bne.n	e6150 <_Z19__fetch_global_Wirev+0x2c>
   e6130:	4628      	mov	r0, r5
   e6132:	f7ed ffcd 	bl	d40d0 <__cxa_guard_acquire>
   e6136:	b158      	cbz	r0, e6150 <_Z19__fetch_global_Wirev+0x2c>
   e6138:	4621      	mov	r1, r4
   e613a:	4807      	ldr	r0, [pc, #28]	; (e6158 <_Z19__fetch_global_Wirev+0x34>)
   e613c:	f7ff faba 	bl	e56b4 <_ZN7TwoWireC1E17HAL_I2C_Interface>
   e6140:	4628      	mov	r0, r5
   e6142:	f7ed ffca 	bl	d40da <__cxa_guard_release>
   e6146:	4a05      	ldr	r2, [pc, #20]	; (e615c <_Z19__fetch_global_Wirev+0x38>)
   e6148:	4905      	ldr	r1, [pc, #20]	; (e6160 <_Z19__fetch_global_Wirev+0x3c>)
   e614a:	4803      	ldr	r0, [pc, #12]	; (e6158 <_Z19__fetch_global_Wirev+0x34>)
   e614c:	f000 f82c 	bl	e61a8 <__aeabi_atexit>
	return wire;
}
   e6150:	4801      	ldr	r0, [pc, #4]	; (e6158 <_Z19__fetch_global_Wirev+0x34>)
   e6152:	bd38      	pop	{r3, r4, r5, pc}
   e6154:	2003e71c 	.word	0x2003e71c
   e6158:	2003e720 	.word	0x2003e720
   e615c:	2003c2a0 	.word	0x2003c2a0
   e6160:	000e565d 	.word	0x000e565d

000e6164 <_GLOBAL__sub_I_SPI>:
#ifndef SPARK_WIRING_NO_SPI

SPIClass SPI(HAL_SPI_INTERFACE1);

#if Wiring_SPI1
SPIClass SPI1(HAL_SPI_INTERFACE2);
   e6164:	b570      	push	{r4, r5, r6, lr}
#include "core_hal.h"
#include "spark_macros.h"

#ifndef SPARK_WIRING_NO_SPI

SPIClass SPI(HAL_SPI_INTERFACE1);
   e6166:	4c0c      	ldr	r4, [pc, #48]	; (e6198 <_GLOBAL__sub_I_SPI+0x34>)
   e6168:	4e0c      	ldr	r6, [pc, #48]	; (e619c <_GLOBAL__sub_I_SPI+0x38>)
   e616a:	4d0d      	ldr	r5, [pc, #52]	; (e61a0 <_GLOBAL__sub_I_SPI+0x3c>)
   e616c:	2100      	movs	r1, #0
   e616e:	4620      	mov	r0, r4
   e6170:	f7ff fd4e 	bl	e5c10 <_ZN8SPIClassC1E17HAL_SPI_Interface>
   e6174:	4620      	mov	r0, r4

#if Wiring_SPI1
SPIClass SPI1(HAL_SPI_INTERFACE2);
   e6176:	4c0b      	ldr	r4, [pc, #44]	; (e61a4 <_GLOBAL__sub_I_SPI+0x40>)
#include "core_hal.h"
#include "spark_macros.h"

#ifndef SPARK_WIRING_NO_SPI

SPIClass SPI(HAL_SPI_INTERFACE1);
   e6178:	4632      	mov	r2, r6
   e617a:	4629      	mov	r1, r5
   e617c:	f000 f814 	bl	e61a8 <__aeabi_atexit>

#if Wiring_SPI1
SPIClass SPI1(HAL_SPI_INTERFACE2);
   e6180:	2101      	movs	r1, #1
   e6182:	4620      	mov	r0, r4
   e6184:	f7ff fd44 	bl	e5c10 <_ZN8SPIClassC1E17HAL_SPI_Interface>
   e6188:	4632      	mov	r2, r6
   e618a:	4629      	mov	r1, r5
   e618c:	4620      	mov	r0, r4
   e618e:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
   e6192:	f000 b809 	b.w	e61a8 <__aeabi_atexit>
   e6196:	bf00      	nop
   e6198:	2003e734 	.word	0x2003e734
   e619c:	2003c2a0 	.word	0x2003c2a0
   e61a0:	000e5c01 	.word	0x000e5c01
   e61a4:	2003e744 	.word	0x2003e744

000e61a8 <__aeabi_atexit>:
   e61a8:	460b      	mov	r3, r1
   e61aa:	4601      	mov	r1, r0
   e61ac:	4618      	mov	r0, r3
   e61ae:	f002 bca7 	b.w	e8b00 <__cxa_atexit>

000e61b2 <_ZdlPvj>:
   e61b2:	f7ed bf74 	b.w	d409e <_ZdlPv>
	...

000e61b8 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj>:
   e61b8:	4b24      	ldr	r3, [pc, #144]	; (e624c <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0x94>)
   e61ba:	681a      	ldr	r2, [r3, #0]
   e61bc:	07d0      	lsls	r0, r2, #31
   e61be:	bf5c      	itt	pl
   e61c0:	2201      	movpl	r2, #1
   e61c2:	601a      	strpl	r2, [r3, #0]
   e61c4:	4b22      	ldr	r3, [pc, #136]	; (e6250 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0x98>)
   e61c6:	681a      	ldr	r2, [r3, #0]
   e61c8:	07d1      	lsls	r1, r2, #31
   e61ca:	bf5c      	itt	pl
   e61cc:	2201      	movpl	r2, #1
   e61ce:	601a      	strpl	r2, [r3, #0]
   e61d0:	4b20      	ldr	r3, [pc, #128]	; (e6254 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0x9c>)
   e61d2:	681a      	ldr	r2, [r3, #0]
   e61d4:	07d2      	lsls	r2, r2, #31
   e61d6:	bf5c      	itt	pl
   e61d8:	2201      	movpl	r2, #1
   e61da:	601a      	strpl	r2, [r3, #0]
   e61dc:	4b1e      	ldr	r3, [pc, #120]	; (e6258 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0xa0>)
   e61de:	681a      	ldr	r2, [r3, #0]
   e61e0:	07d0      	lsls	r0, r2, #31
   e61e2:	bf5c      	itt	pl
   e61e4:	2201      	movpl	r2, #1
   e61e6:	601a      	strpl	r2, [r3, #0]
   e61e8:	4b1c      	ldr	r3, [pc, #112]	; (e625c <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0xa4>)
   e61ea:	681a      	ldr	r2, [r3, #0]
   e61ec:	07d1      	lsls	r1, r2, #31
   e61ee:	bf5c      	itt	pl
   e61f0:	2201      	movpl	r2, #1
   e61f2:	601a      	strpl	r2, [r3, #0]
   e61f4:	4b1a      	ldr	r3, [pc, #104]	; (e6260 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0xa8>)
   e61f6:	681a      	ldr	r2, [r3, #0]
   e61f8:	07d2      	lsls	r2, r2, #31
   e61fa:	bf5c      	itt	pl
   e61fc:	2201      	movpl	r2, #1
   e61fe:	601a      	strpl	r2, [r3, #0]
   e6200:	4b18      	ldr	r3, [pc, #96]	; (e6264 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0xac>)
   e6202:	681a      	ldr	r2, [r3, #0]
   e6204:	07d0      	lsls	r0, r2, #31
   e6206:	bf5c      	itt	pl
   e6208:	2201      	movpl	r2, #1
   e620a:	601a      	strpl	r2, [r3, #0]
   e620c:	4b16      	ldr	r3, [pc, #88]	; (e6268 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0xb0>)
   e620e:	681a      	ldr	r2, [r3, #0]
   e6210:	07d1      	lsls	r1, r2, #31
   e6212:	bf5c      	itt	pl
   e6214:	2201      	movpl	r2, #1
   e6216:	601a      	strpl	r2, [r3, #0]
   e6218:	4b14      	ldr	r3, [pc, #80]	; (e626c <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0xb4>)
   e621a:	681a      	ldr	r2, [r3, #0]
   e621c:	07d2      	lsls	r2, r2, #31
   e621e:	bf5c      	itt	pl
   e6220:	2201      	movpl	r2, #1
   e6222:	601a      	strpl	r2, [r3, #0]
   e6224:	4b12      	ldr	r3, [pc, #72]	; (e6270 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0xb8>)
   e6226:	681a      	ldr	r2, [r3, #0]
   e6228:	07d0      	lsls	r0, r2, #31
   e622a:	bf5c      	itt	pl
   e622c:	2201      	movpl	r2, #1
   e622e:	601a      	strpl	r2, [r3, #0]
   e6230:	4b10      	ldr	r3, [pc, #64]	; (e6274 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0xbc>)
   e6232:	681a      	ldr	r2, [r3, #0]
   e6234:	07d1      	lsls	r1, r2, #31
   e6236:	bf5c      	itt	pl
   e6238:	2201      	movpl	r2, #1
   e623a:	601a      	strpl	r2, [r3, #0]
   e623c:	4b0e      	ldr	r3, [pc, #56]	; (e6278 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKSsj+0xc0>)
   e623e:	681a      	ldr	r2, [r3, #0]
   e6240:	07d2      	lsls	r2, r2, #31
   e6242:	bf5c      	itt	pl
   e6244:	2201      	movpl	r2, #1
   e6246:	601a      	strpl	r2, [r3, #0]
   e6248:	4770      	bx	lr
   e624a:	bf00      	nop
   e624c:	2003e780 	.word	0x2003e780
   e6250:	2003e77c 	.word	0x2003e77c
   e6254:	2003e778 	.word	0x2003e778
   e6258:	2003e774 	.word	0x2003e774
   e625c:	2003e770 	.word	0x2003e770
   e6260:	2003e76c 	.word	0x2003e76c
   e6264:	2003e768 	.word	0x2003e768
   e6268:	2003e764 	.word	0x2003e764
   e626c:	2003e760 	.word	0x2003e760
   e6270:	2003e75c 	.word	0x2003e75c
   e6274:	2003e758 	.word	0x2003e758
   e6278:	2003e754 	.word	0x2003e754

000e627c <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj>:
   e627c:	4b18      	ldr	r3, [pc, #96]	; (e62e0 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x64>)
   e627e:	681a      	ldr	r2, [r3, #0]
   e6280:	07d1      	lsls	r1, r2, #31
   e6282:	bf5c      	itt	pl
   e6284:	2201      	movpl	r2, #1
   e6286:	601a      	strpl	r2, [r3, #0]
   e6288:	4b16      	ldr	r3, [pc, #88]	; (e62e4 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x68>)
   e628a:	681a      	ldr	r2, [r3, #0]
   e628c:	07d2      	lsls	r2, r2, #31
   e628e:	bf5c      	itt	pl
   e6290:	2201      	movpl	r2, #1
   e6292:	601a      	strpl	r2, [r3, #0]
   e6294:	4b14      	ldr	r3, [pc, #80]	; (e62e8 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x6c>)
   e6296:	681a      	ldr	r2, [r3, #0]
   e6298:	07d0      	lsls	r0, r2, #31
   e629a:	bf5c      	itt	pl
   e629c:	2201      	movpl	r2, #1
   e629e:	601a      	strpl	r2, [r3, #0]
   e62a0:	4b12      	ldr	r3, [pc, #72]	; (e62ec <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x70>)
   e62a2:	681a      	ldr	r2, [r3, #0]
   e62a4:	07d1      	lsls	r1, r2, #31
   e62a6:	bf5c      	itt	pl
   e62a8:	2201      	movpl	r2, #1
   e62aa:	601a      	strpl	r2, [r3, #0]
   e62ac:	4b10      	ldr	r3, [pc, #64]	; (e62f0 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x74>)
   e62ae:	681a      	ldr	r2, [r3, #0]
   e62b0:	07d2      	lsls	r2, r2, #31
   e62b2:	bf5c      	itt	pl
   e62b4:	2201      	movpl	r2, #1
   e62b6:	601a      	strpl	r2, [r3, #0]
   e62b8:	4b0e      	ldr	r3, [pc, #56]	; (e62f4 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x78>)
   e62ba:	681a      	ldr	r2, [r3, #0]
   e62bc:	07d0      	lsls	r0, r2, #31
   e62be:	bf5c      	itt	pl
   e62c0:	2201      	movpl	r2, #1
   e62c2:	601a      	strpl	r2, [r3, #0]
   e62c4:	4b0c      	ldr	r3, [pc, #48]	; (e62f8 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x7c>)
   e62c6:	681a      	ldr	r2, [r3, #0]
   e62c8:	07d1      	lsls	r1, r2, #31
   e62ca:	bf5c      	itt	pl
   e62cc:	2201      	movpl	r2, #1
   e62ce:	601a      	strpl	r2, [r3, #0]
   e62d0:	4b0a      	ldr	r3, [pc, #40]	; (e62fc <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x80>)
   e62d2:	681a      	ldr	r2, [r3, #0]
   e62d4:	07d2      	lsls	r2, r2, #31
   e62d6:	bf5c      	itt	pl
   e62d8:	2201      	movpl	r2, #1
   e62da:	601a      	strpl	r2, [r3, #0]
   e62dc:	4770      	bx	lr
   e62de:	bf00      	nop
   e62e0:	2003e7a0 	.word	0x2003e7a0
   e62e4:	2003e79c 	.word	0x2003e79c
   e62e8:	2003e798 	.word	0x2003e798
   e62ec:	2003e794 	.word	0x2003e794
   e62f0:	2003e790 	.word	0x2003e790
   e62f4:	2003e78c 	.word	0x2003e78c
   e62f8:	2003e788 	.word	0x2003e788
   e62fc:	2003e784 	.word	0x2003e784

000e6300 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj>:
   e6300:	4b18      	ldr	r3, [pc, #96]	; (e6364 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x64>)
   e6302:	681a      	ldr	r2, [r3, #0]
   e6304:	07d1      	lsls	r1, r2, #31
   e6306:	bf5c      	itt	pl
   e6308:	2201      	movpl	r2, #1
   e630a:	601a      	strpl	r2, [r3, #0]
   e630c:	4b16      	ldr	r3, [pc, #88]	; (e6368 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x68>)
   e630e:	681a      	ldr	r2, [r3, #0]
   e6310:	07d2      	lsls	r2, r2, #31
   e6312:	bf5c      	itt	pl
   e6314:	2201      	movpl	r2, #1
   e6316:	601a      	strpl	r2, [r3, #0]
   e6318:	4b14      	ldr	r3, [pc, #80]	; (e636c <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x6c>)
   e631a:	681a      	ldr	r2, [r3, #0]
   e631c:	07d0      	lsls	r0, r2, #31
   e631e:	bf5c      	itt	pl
   e6320:	2201      	movpl	r2, #1
   e6322:	601a      	strpl	r2, [r3, #0]
   e6324:	4b12      	ldr	r3, [pc, #72]	; (e6370 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x70>)
   e6326:	681a      	ldr	r2, [r3, #0]
   e6328:	07d1      	lsls	r1, r2, #31
   e632a:	bf5c      	itt	pl
   e632c:	2201      	movpl	r2, #1
   e632e:	601a      	strpl	r2, [r3, #0]
   e6330:	4b10      	ldr	r3, [pc, #64]	; (e6374 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x74>)
   e6332:	681a      	ldr	r2, [r3, #0]
   e6334:	07d2      	lsls	r2, r2, #31
   e6336:	bf5c      	itt	pl
   e6338:	2201      	movpl	r2, #1
   e633a:	601a      	strpl	r2, [r3, #0]
   e633c:	4b0e      	ldr	r3, [pc, #56]	; (e6378 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x78>)
   e633e:	681a      	ldr	r2, [r3, #0]
   e6340:	07d0      	lsls	r0, r2, #31
   e6342:	bf5c      	itt	pl
   e6344:	2201      	movpl	r2, #1
   e6346:	601a      	strpl	r2, [r3, #0]
   e6348:	4b0c      	ldr	r3, [pc, #48]	; (e637c <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x7c>)
   e634a:	681a      	ldr	r2, [r3, #0]
   e634c:	07d1      	lsls	r1, r2, #31
   e634e:	bf5c      	itt	pl
   e6350:	2201      	movpl	r2, #1
   e6352:	601a      	strpl	r2, [r3, #0]
   e6354:	4b0a      	ldr	r3, [pc, #40]	; (e6380 <_GLOBAL__sub_I__ZNSt12ctype_bynameIwEC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEj+0x80>)
   e6356:	681a      	ldr	r2, [r3, #0]
   e6358:	07d2      	lsls	r2, r2, #31
   e635a:	bf5c      	itt	pl
   e635c:	2201      	movpl	r2, #1
   e635e:	601a      	strpl	r2, [r3, #0]
   e6360:	4770      	bx	lr
   e6362:	bf00      	nop
   e6364:	2003e7c0 	.word	0x2003e7c0
   e6368:	2003e7bc 	.word	0x2003e7bc
   e636c:	2003e7b8 	.word	0x2003e7b8
   e6370:	2003e7b4 	.word	0x2003e7b4
   e6374:	2003e7b0 	.word	0x2003e7b0
   e6378:	2003e7ac 	.word	0x2003e7ac
   e637c:	2003e7a8 	.word	0x2003e7a8
   e6380:	2003e7a4 	.word	0x2003e7a4

000e6384 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj>:
   e6384:	4b24      	ldr	r3, [pc, #144]	; (e6418 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0x94>)
   e6386:	681a      	ldr	r2, [r3, #0]
   e6388:	07d0      	lsls	r0, r2, #31
   e638a:	bf5c      	itt	pl
   e638c:	2201      	movpl	r2, #1
   e638e:	601a      	strpl	r2, [r3, #0]
   e6390:	4b22      	ldr	r3, [pc, #136]	; (e641c <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0x98>)
   e6392:	681a      	ldr	r2, [r3, #0]
   e6394:	07d1      	lsls	r1, r2, #31
   e6396:	bf5c      	itt	pl
   e6398:	2201      	movpl	r2, #1
   e639a:	601a      	strpl	r2, [r3, #0]
   e639c:	4b20      	ldr	r3, [pc, #128]	; (e6420 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0x9c>)
   e639e:	681a      	ldr	r2, [r3, #0]
   e63a0:	07d2      	lsls	r2, r2, #31
   e63a2:	bf5c      	itt	pl
   e63a4:	2201      	movpl	r2, #1
   e63a6:	601a      	strpl	r2, [r3, #0]
   e63a8:	4b1e      	ldr	r3, [pc, #120]	; (e6424 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0xa0>)
   e63aa:	681a      	ldr	r2, [r3, #0]
   e63ac:	07d0      	lsls	r0, r2, #31
   e63ae:	bf5c      	itt	pl
   e63b0:	2201      	movpl	r2, #1
   e63b2:	601a      	strpl	r2, [r3, #0]
   e63b4:	4b1c      	ldr	r3, [pc, #112]	; (e6428 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0xa4>)
   e63b6:	681a      	ldr	r2, [r3, #0]
   e63b8:	07d1      	lsls	r1, r2, #31
   e63ba:	bf5c      	itt	pl
   e63bc:	2201      	movpl	r2, #1
   e63be:	601a      	strpl	r2, [r3, #0]
   e63c0:	4b1a      	ldr	r3, [pc, #104]	; (e642c <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0xa8>)
   e63c2:	681a      	ldr	r2, [r3, #0]
   e63c4:	07d2      	lsls	r2, r2, #31
   e63c6:	bf5c      	itt	pl
   e63c8:	2201      	movpl	r2, #1
   e63ca:	601a      	strpl	r2, [r3, #0]
   e63cc:	4b18      	ldr	r3, [pc, #96]	; (e6430 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0xac>)
   e63ce:	681a      	ldr	r2, [r3, #0]
   e63d0:	07d0      	lsls	r0, r2, #31
   e63d2:	bf5c      	itt	pl
   e63d4:	2201      	movpl	r2, #1
   e63d6:	601a      	strpl	r2, [r3, #0]
   e63d8:	4b16      	ldr	r3, [pc, #88]	; (e6434 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0xb0>)
   e63da:	681a      	ldr	r2, [r3, #0]
   e63dc:	07d1      	lsls	r1, r2, #31
   e63de:	bf5c      	itt	pl
   e63e0:	2201      	movpl	r2, #1
   e63e2:	601a      	strpl	r2, [r3, #0]
   e63e4:	4b14      	ldr	r3, [pc, #80]	; (e6438 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0xb4>)
   e63e6:	681a      	ldr	r2, [r3, #0]
   e63e8:	07d2      	lsls	r2, r2, #31
   e63ea:	bf5c      	itt	pl
   e63ec:	2201      	movpl	r2, #1
   e63ee:	601a      	strpl	r2, [r3, #0]
   e63f0:	4b12      	ldr	r3, [pc, #72]	; (e643c <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0xb8>)
   e63f2:	681a      	ldr	r2, [r3, #0]
   e63f4:	07d0      	lsls	r0, r2, #31
   e63f6:	bf5c      	itt	pl
   e63f8:	2201      	movpl	r2, #1
   e63fa:	601a      	strpl	r2, [r3, #0]
   e63fc:	4b10      	ldr	r3, [pc, #64]	; (e6440 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0xbc>)
   e63fe:	681a      	ldr	r2, [r3, #0]
   e6400:	07d1      	lsls	r1, r2, #31
   e6402:	bf5c      	itt	pl
   e6404:	2201      	movpl	r2, #1
   e6406:	601a      	strpl	r2, [r3, #0]
   e6408:	4b0e      	ldr	r3, [pc, #56]	; (e6444 <_GLOBAL__sub_I__ZNSt12ctype_bynameIcEC2ERKSsj+0xc0>)
   e640a:	681a      	ldr	r2, [r3, #0]
   e640c:	07d2      	lsls	r2, r2, #31
   e640e:	bf5c      	itt	pl
   e6410:	2201      	movpl	r2, #1
   e6412:	601a      	strpl	r2, [r3, #0]
   e6414:	4770      	bx	lr
   e6416:	bf00      	nop
   e6418:	2003e7f0 	.word	0x2003e7f0
   e641c:	2003e7ec 	.word	0x2003e7ec
   e6420:	2003e7e8 	.word	0x2003e7e8
   e6424:	2003e7e4 	.word	0x2003e7e4
   e6428:	2003e7e0 	.word	0x2003e7e0
   e642c:	2003e7dc 	.word	0x2003e7dc
   e6430:	2003e7d8 	.word	0x2003e7d8
   e6434:	2003e7d4 	.word	0x2003e7d4
   e6438:	2003e7d0 	.word	0x2003e7d0
   e643c:	2003e7cc 	.word	0x2003e7cc
   e6440:	2003e7c8 	.word	0x2003e7c8
   e6444:	2003e7c4 	.word	0x2003e7c4

000e6448 <floor>:
   e6448:	ec51 0b10 	vmov	r0, r1, d0
   e644c:	f3c1 530a 	ubfx	r3, r1, #20, #11
   e6450:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   e6454:	f2a3 35ff 	subw	r5, r3, #1023	; 0x3ff
   e6458:	2d13      	cmp	r5, #19
   e645a:	460c      	mov	r4, r1
   e645c:	460f      	mov	r7, r1
   e645e:	ee10 6a10 	vmov	r6, s0
   e6462:	dc1d      	bgt.n	e64a0 <floor+0x58>
   e6464:	2d00      	cmp	r5, #0
   e6466:	db43      	blt.n	e64f0 <floor+0xa8>
   e6468:	4b3d      	ldr	r3, [pc, #244]	; (e6560 <floor+0x118>)
   e646a:	fa43 f805 	asr.w	r8, r3, r5
   e646e:	ea01 0308 	and.w	r3, r1, r8
   e6472:	4303      	orrs	r3, r0
   e6474:	d019      	beq.n	e64aa <floor+0x62>
   e6476:	a338      	add	r3, pc, #224	; (adr r3, e6558 <floor+0x110>)
   e6478:	e9d3 2300 	ldrd	r2, r3, [r3]
   e647c:	f001 fe20 	bl	e80c0 <__adddf3>
   e6480:	2200      	movs	r2, #0
   e6482:	2300      	movs	r3, #0
   e6484:	f002 fa5e 	bl	e8944 <__aeabi_dcmpgt>
   e6488:	b120      	cbz	r0, e6494 <floor+0x4c>
   e648a:	2c00      	cmp	r4, #0
   e648c:	db49      	blt.n	e6522 <floor+0xda>
   e648e:	ea27 0408 	bic.w	r4, r7, r8
   e6492:	2600      	movs	r6, #0
   e6494:	4623      	mov	r3, r4
   e6496:	4632      	mov	r2, r6
   e6498:	ec43 2b10 	vmov	d0, r2, r3
   e649c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   e64a0:	2d33      	cmp	r5, #51	; 0x33
   e64a2:	dd06      	ble.n	e64b2 <floor+0x6a>
   e64a4:	f5b5 6f80 	cmp.w	r5, #1024	; 0x400
   e64a8:	d032      	beq.n	e6510 <floor+0xc8>
   e64aa:	ec41 0b10 	vmov	d0, r0, r1
   e64ae:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   e64b2:	f2a3 4313 	subw	r3, r3, #1043	; 0x413
   e64b6:	f04f 38ff 	mov.w	r8, #4294967295	; 0xffffffff
   e64ba:	fa28 f803 	lsr.w	r8, r8, r3
   e64be:	ea10 0f08 	tst.w	r0, r8
   e64c2:	d0f2      	beq.n	e64aa <floor+0x62>
   e64c4:	a324      	add	r3, pc, #144	; (adr r3, e6558 <floor+0x110>)
   e64c6:	e9d3 2300 	ldrd	r2, r3, [r3]
   e64ca:	f001 fdf9 	bl	e80c0 <__adddf3>
   e64ce:	2200      	movs	r2, #0
   e64d0:	2300      	movs	r3, #0
   e64d2:	f002 fa37 	bl	e8944 <__aeabi_dcmpgt>
   e64d6:	2800      	cmp	r0, #0
   e64d8:	d0dc      	beq.n	e6494 <floor+0x4c>
   e64da:	2c00      	cmp	r4, #0
   e64dc:	db27      	blt.n	e652e <floor+0xe6>
   e64de:	463c      	mov	r4, r7
   e64e0:	ea26 0608 	bic.w	r6, r6, r8
   e64e4:	4623      	mov	r3, r4
   e64e6:	4632      	mov	r2, r6
   e64e8:	ec43 2b10 	vmov	d0, r2, r3
   e64ec:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   e64f0:	a319      	add	r3, pc, #100	; (adr r3, e6558 <floor+0x110>)
   e64f2:	e9d3 2300 	ldrd	r2, r3, [r3]
   e64f6:	f001 fde3 	bl	e80c0 <__adddf3>
   e64fa:	2200      	movs	r2, #0
   e64fc:	2300      	movs	r3, #0
   e64fe:	f002 fa21 	bl	e8944 <__aeabi_dcmpgt>
   e6502:	2800      	cmp	r0, #0
   e6504:	d0c6      	beq.n	e6494 <floor+0x4c>
   e6506:	2c00      	cmp	r4, #0
   e6508:	db1c      	blt.n	e6544 <floor+0xfc>
   e650a:	2600      	movs	r6, #0
   e650c:	4634      	mov	r4, r6
   e650e:	e7c1      	b.n	e6494 <floor+0x4c>
   e6510:	ee10 2a10 	vmov	r2, s0
   e6514:	460b      	mov	r3, r1
   e6516:	f001 fdd3 	bl	e80c0 <__adddf3>
   e651a:	ec41 0b10 	vmov	d0, r0, r1
   e651e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
   e6522:	f44f 1380 	mov.w	r3, #1048576	; 0x100000
   e6526:	fa43 f505 	asr.w	r5, r3, r5
   e652a:	442f      	add	r7, r5
   e652c:	e7af      	b.n	e648e <floor+0x46>
   e652e:	2d14      	cmp	r5, #20
   e6530:	d010      	beq.n	e6554 <floor+0x10c>
   e6532:	2301      	movs	r3, #1
   e6534:	f1c5 0534 	rsb	r5, r5, #52	; 0x34
   e6538:	fa03 f505 	lsl.w	r5, r3, r5
   e653c:	19ae      	adds	r6, r5, r6
   e653e:	bf28      	it	cs
   e6540:	18ff      	addcs	r7, r7, r3
   e6542:	e7cc      	b.n	e64de <floor+0x96>
   e6544:	f024 4200 	bic.w	r2, r4, #2147483648	; 0x80000000
   e6548:	4b06      	ldr	r3, [pc, #24]	; (e6564 <floor+0x11c>)
   e654a:	4332      	orrs	r2, r6
   e654c:	bf18      	it	ne
   e654e:	461c      	movne	r4, r3
   e6550:	2600      	movs	r6, #0
   e6552:	e79f      	b.n	e6494 <floor+0x4c>
   e6554:	3701      	adds	r7, #1
   e6556:	e7c2      	b.n	e64de <floor+0x96>
   e6558:	8800759c 	.word	0x8800759c
   e655c:	7e37e43c 	.word	0x7e37e43c
   e6560:	000fffff 	.word	0x000fffff
   e6564:	bff00000 	.word	0xbff00000

000e6568 <frexp>:
   e6568:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
   e656a:	ec53 2b10 	vmov	r2, r3, d0
   e656e:	4e17      	ldr	r6, [pc, #92]	; (e65cc <frexp+0x64>)
   e6570:	f023 4100 	bic.w	r1, r3, #2147483648	; 0x80000000
   e6574:	2500      	movs	r5, #0
   e6576:	42b1      	cmp	r1, r6
   e6578:	4604      	mov	r4, r0
   e657a:	6005      	str	r5, [r0, #0]
   e657c:	dc23      	bgt.n	e65c6 <frexp+0x5e>
   e657e:	ea52 0601 	orrs.w	r6, r2, r1
   e6582:	d020      	beq.n	e65c6 <frexp+0x5e>
   e6584:	f5b1 1f80 	cmp.w	r1, #1048576	; 0x100000
   e6588:	4618      	mov	r0, r3
   e658a:	da0c      	bge.n	e65a6 <frexp+0x3e>
   e658c:	4619      	mov	r1, r3
   e658e:	2200      	movs	r2, #0
   e6590:	ee10 0a10 	vmov	r0, s0
   e6594:	4b0e      	ldr	r3, [pc, #56]	; (e65d0 <frexp+0x68>)
   e6596:	f001 ff45 	bl	e8424 <__aeabi_dmul>
   e659a:	f06f 0535 	mvn.w	r5, #53	; 0x35
   e659e:	4602      	mov	r2, r0
   e65a0:	4608      	mov	r0, r1
   e65a2:	f021 4100 	bic.w	r1, r1, #2147483648	; 0x80000000
   e65a6:	f020 40ff 	bic.w	r0, r0, #2139095040	; 0x7f800000
   e65aa:	f420 00e0 	bic.w	r0, r0, #7340032	; 0x700000
   e65ae:	1509      	asrs	r1, r1, #20
   e65b0:	f040 537f 	orr.w	r3, r0, #1069547520	; 0x3fc00000
   e65b4:	f2a1 31fe 	subw	r1, r1, #1022	; 0x3fe
   e65b8:	4429      	add	r1, r5
   e65ba:	f443 1300 	orr.w	r3, r3, #2097152	; 0x200000
   e65be:	6021      	str	r1, [r4, #0]
   e65c0:	ec43 2b10 	vmov	d0, r2, r3
   e65c4:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
   e65c6:	ec43 2b10 	vmov	d0, r2, r3
   e65ca:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
   e65cc:	7fefffff 	.word	0x7fefffff
   e65d0:	43500000 	.word	0x43500000

000e65d4 <round>:
   e65d4:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
   e65d6:	ec53 2b10 	vmov	r2, r3, d0
   e65da:	f3c3 540a 	ubfx	r4, r3, #20, #11
   e65de:	f2a4 30ff 	subw	r0, r4, #1023	; 0x3ff
   e65e2:	2813      	cmp	r0, #19
   e65e4:	4619      	mov	r1, r3
   e65e6:	ee10 7a10 	vmov	r7, s0
   e65ea:	dc12      	bgt.n	e6612 <round+0x3e>
   e65ec:	2800      	cmp	r0, #0
   e65ee:	db32      	blt.n	e6656 <round+0x82>
   e65f0:	4e23      	ldr	r6, [pc, #140]	; (e6680 <round+0xac>)
   e65f2:	4106      	asrs	r6, r0
   e65f4:	4233      	tst	r3, r6
   e65f6:	461d      	mov	r5, r3
   e65f8:	d02a      	beq.n	e6650 <round+0x7c>
   e65fa:	f44f 2100 	mov.w	r1, #524288	; 0x80000
   e65fe:	4101      	asrs	r1, r0
   e6600:	4429      	add	r1, r5
   e6602:	ea21 0106 	bic.w	r1, r1, r6
   e6606:	2400      	movs	r4, #0
   e6608:	460b      	mov	r3, r1
   e660a:	4622      	mov	r2, r4
   e660c:	ec43 2b10 	vmov	d0, r2, r3
   e6610:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
   e6612:	2833      	cmp	r0, #51	; 0x33
   e6614:	dd05      	ble.n	e6622 <round+0x4e>
   e6616:	f5b0 6f80 	cmp.w	r0, #1024	; 0x400
   e661a:	d022      	beq.n	e6662 <round+0x8e>
   e661c:	ec43 2b10 	vmov	d0, r2, r3
   e6620:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
   e6622:	f2a4 4413 	subw	r4, r4, #1043	; 0x413
   e6626:	f04f 35ff 	mov.w	r5, #4294967295	; 0xffffffff
   e662a:	fa25 f404 	lsr.w	r4, r5, r4
   e662e:	4222      	tst	r2, r4
   e6630:	d0f4      	beq.n	e661c <round+0x48>
   e6632:	2301      	movs	r3, #1
   e6634:	f1c0 0033 	rsb	r0, r0, #51	; 0x33
   e6638:	fa03 f000 	lsl.w	r0, r3, r0
   e663c:	19c0      	adds	r0, r0, r7
   e663e:	bf28      	it	cs
   e6640:	18c9      	addcs	r1, r1, r3
   e6642:	ea20 0404 	bic.w	r4, r0, r4
   e6646:	460b      	mov	r3, r1
   e6648:	4622      	mov	r2, r4
   e664a:	ec43 2b10 	vmov	d0, r2, r3
   e664e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
   e6650:	2a00      	cmp	r2, #0
   e6652:	d1d2      	bne.n	e65fa <round+0x26>
   e6654:	e7e2      	b.n	e661c <round+0x48>
   e6656:	3001      	adds	r0, #1
   e6658:	f003 4100 	and.w	r1, r3, #2147483648	; 0x80000000
   e665c:	d009      	beq.n	e6672 <round+0x9e>
   e665e:	2400      	movs	r4, #0
   e6660:	e7d2      	b.n	e6608 <round+0x34>
   e6662:	ee10 0a10 	vmov	r0, s0
   e6666:	4619      	mov	r1, r3
   e6668:	f001 fd2a 	bl	e80c0 <__adddf3>
   e666c:	ec41 0b10 	vmov	d0, r0, r1
   e6670:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
   e6672:	f041 517f 	orr.w	r1, r1, #1069547520	; 0x3fc00000
   e6676:	f441 1140 	orr.w	r1, r1, #3145728	; 0x300000
   e667a:	2400      	movs	r4, #0
   e667c:	e7c4      	b.n	e6608 <round+0x34>
   e667e:	bf00      	nop
   e6680:	000fffff 	.word	0x000fffff

000e6684 <ceilf>:
   e6684:	ee10 2a10 	vmov	r2, s0
   e6688:	f022 4100 	bic.w	r1, r2, #2147483648	; 0x80000000
   e668c:	0dcb      	lsrs	r3, r1, #23
   e668e:	3b7f      	subs	r3, #127	; 0x7f
   e6690:	2b16      	cmp	r3, #22
   e6692:	dc1c      	bgt.n	e66ce <ceilf+0x4a>
   e6694:	2b00      	cmp	r3, #0
   e6696:	ee10 0a10 	vmov	r0, s0
   e669a:	db21      	blt.n	e66e0 <ceilf+0x5c>
   e669c:	4919      	ldr	r1, [pc, #100]	; (e6704 <ceilf+0x80>)
   e669e:	4119      	asrs	r1, r3
   e66a0:	420a      	tst	r2, r1
   e66a2:	d01c      	beq.n	e66de <ceilf+0x5a>
   e66a4:	eddf 7a18 	vldr	s15, [pc, #96]	; e6708 <ceilf+0x84>
   e66a8:	ee70 7a27 	vadd.f32	s15, s0, s15
   e66ac:	eef5 7ac0 	vcmpe.f32	s15, #0.0
   e66b0:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e66b4:	dd13      	ble.n	e66de <ceilf+0x5a>
   e66b6:	2a00      	cmp	r2, #0
   e66b8:	dd04      	ble.n	e66c4 <ceilf+0x40>
   e66ba:	f44f 0200 	mov.w	r2, #8388608	; 0x800000
   e66be:	fa42 f303 	asr.w	r3, r2, r3
   e66c2:	4418      	add	r0, r3
   e66c4:	ea20 0301 	bic.w	r3, r0, r1
   e66c8:	ee00 3a10 	vmov	s0, r3
   e66cc:	4770      	bx	lr
   e66ce:	f1b1 4fff 	cmp.w	r1, #2139095040	; 0x7f800000
   e66d2:	d304      	bcc.n	e66de <ceilf+0x5a>
   e66d4:	ee30 0a00 	vadd.f32	s0, s0, s0
   e66d8:	4770      	bx	lr
   e66da:	ed9f 0a0c 	vldr	s0, [pc, #48]	; e670c <ceilf+0x88>
   e66de:	4770      	bx	lr
   e66e0:	eddf 7a09 	vldr	s15, [pc, #36]	; e6708 <ceilf+0x84>
   e66e4:	ee70 7a27 	vadd.f32	s15, s0, s15
   e66e8:	eef5 7ac0 	vcmpe.f32	s15, #0.0
   e66ec:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e66f0:	ddf5      	ble.n	e66de <ceilf+0x5a>
   e66f2:	2a00      	cmp	r2, #0
   e66f4:	dbf1      	blt.n	e66da <ceilf+0x56>
   e66f6:	2900      	cmp	r1, #0
   e66f8:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   e66fc:	bf18      	it	ne
   e66fe:	eeb0 0a67 	vmovne.f32	s0, s15
   e6702:	4770      	bx	lr
   e6704:	007fffff 	.word	0x007fffff
   e6708:	7149f2ca 	.word	0x7149f2ca
   e670c:	80000000 	.word	0x80000000

000e6710 <cosf>:
   e6710:	b500      	push	{lr}
   e6712:	ee10 3a10 	vmov	r3, s0
   e6716:	4a20      	ldr	r2, [pc, #128]	; (e6798 <cosf+0x88>)
   e6718:	f023 4300 	bic.w	r3, r3, #2147483648	; 0x80000000
   e671c:	4293      	cmp	r3, r2
   e671e:	b083      	sub	sp, #12
   e6720:	dd19      	ble.n	e6756 <cosf+0x46>
   e6722:	f1b3 4fff 	cmp.w	r3, #2139095040	; 0x7f800000
   e6726:	db04      	blt.n	e6732 <cosf+0x22>
   e6728:	ee30 0a40 	vsub.f32	s0, s0, s0
   e672c:	b003      	add	sp, #12
   e672e:	f85d fb04 	ldr.w	pc, [sp], #4
   e6732:	4668      	mov	r0, sp
   e6734:	f000 fe9e 	bl	e7474 <__ieee754_rem_pio2f>
   e6738:	f000 0003 	and.w	r0, r0, #3
   e673c:	2801      	cmp	r0, #1
   e673e:	d01a      	beq.n	e6776 <cosf+0x66>
   e6740:	2802      	cmp	r0, #2
   e6742:	d00f      	beq.n	e6764 <cosf+0x54>
   e6744:	b300      	cbz	r0, e6788 <cosf+0x78>
   e6746:	2001      	movs	r0, #1
   e6748:	eddd 0a01 	vldr	s1, [sp, #4]
   e674c:	ed9d 0a00 	vldr	s0, [sp]
   e6750:	f001 fbc4 	bl	e7edc <__kernel_sinf>
   e6754:	e7ea      	b.n	e672c <cosf+0x1c>
   e6756:	eddf 0a11 	vldr	s1, [pc, #68]	; e679c <cosf+0x8c>
   e675a:	f001 f829 	bl	e77b0 <__kernel_cosf>
   e675e:	b003      	add	sp, #12
   e6760:	f85d fb04 	ldr.w	pc, [sp], #4
   e6764:	eddd 0a01 	vldr	s1, [sp, #4]
   e6768:	ed9d 0a00 	vldr	s0, [sp]
   e676c:	f001 f820 	bl	e77b0 <__kernel_cosf>
   e6770:	eeb1 0a40 	vneg.f32	s0, s0
   e6774:	e7da      	b.n	e672c <cosf+0x1c>
   e6776:	eddd 0a01 	vldr	s1, [sp, #4]
   e677a:	ed9d 0a00 	vldr	s0, [sp]
   e677e:	f001 fbad 	bl	e7edc <__kernel_sinf>
   e6782:	eeb1 0a40 	vneg.f32	s0, s0
   e6786:	e7d1      	b.n	e672c <cosf+0x1c>
   e6788:	eddd 0a01 	vldr	s1, [sp, #4]
   e678c:	ed9d 0a00 	vldr	s0, [sp]
   e6790:	f001 f80e 	bl	e77b0 <__kernel_cosf>
   e6794:	e7ca      	b.n	e672c <cosf+0x1c>
   e6796:	bf00      	nop
   e6798:	3f490fd8 	.word	0x3f490fd8
   e679c:	00000000 	.word	0x00000000

000e67a0 <floorf>:
   e67a0:	ee10 2a10 	vmov	r2, s0
   e67a4:	f022 4100 	bic.w	r1, r2, #2147483648	; 0x80000000
   e67a8:	0dcb      	lsrs	r3, r1, #23
   e67aa:	3b7f      	subs	r3, #127	; 0x7f
   e67ac:	2b16      	cmp	r3, #22
   e67ae:	dc17      	bgt.n	e67e0 <floorf+0x40>
   e67b0:	2b00      	cmp	r3, #0
   e67b2:	ee10 0a10 	vmov	r0, s0
   e67b6:	db19      	blt.n	e67ec <floorf+0x4c>
   e67b8:	491a      	ldr	r1, [pc, #104]	; (e6824 <floorf+0x84>)
   e67ba:	4119      	asrs	r1, r3
   e67bc:	420a      	tst	r2, r1
   e67be:	d022      	beq.n	e6806 <floorf+0x66>
   e67c0:	eddf 7a19 	vldr	s15, [pc, #100]	; e6828 <floorf+0x88>
   e67c4:	ee70 7a27 	vadd.f32	s15, s0, s15
   e67c8:	eef5 7ac0 	vcmpe.f32	s15, #0.0
   e67cc:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e67d0:	dd19      	ble.n	e6806 <floorf+0x66>
   e67d2:	2a00      	cmp	r2, #0
   e67d4:	db18      	blt.n	e6808 <floorf+0x68>
   e67d6:	ea20 0301 	bic.w	r3, r0, r1
   e67da:	ee00 3a10 	vmov	s0, r3
   e67de:	4770      	bx	lr
   e67e0:	f1b1 4fff 	cmp.w	r1, #2139095040	; 0x7f800000
   e67e4:	d30f      	bcc.n	e6806 <floorf+0x66>
   e67e6:	ee30 0a00 	vadd.f32	s0, s0, s0
   e67ea:	4770      	bx	lr
   e67ec:	eddf 7a0e 	vldr	s15, [pc, #56]	; e6828 <floorf+0x88>
   e67f0:	ee70 7a27 	vadd.f32	s15, s0, s15
   e67f4:	eef5 7ac0 	vcmpe.f32	s15, #0.0
   e67f8:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e67fc:	dd03      	ble.n	e6806 <floorf+0x66>
   e67fe:	2a00      	cmp	r2, #0
   e6800:	db08      	blt.n	e6814 <floorf+0x74>
   e6802:	ed9f 0a0a 	vldr	s0, [pc, #40]	; e682c <floorf+0x8c>
   e6806:	4770      	bx	lr
   e6808:	f44f 0200 	mov.w	r2, #8388608	; 0x800000
   e680c:	fa42 f303 	asr.w	r3, r2, r3
   e6810:	4418      	add	r0, r3
   e6812:	e7e0      	b.n	e67d6 <floorf+0x36>
   e6814:	2900      	cmp	r1, #0
   e6816:	eeff 7a00 	vmov.f32	s15, #240	; 0xbf800000 -1.0
   e681a:	bf18      	it	ne
   e681c:	eeb0 0a67 	vmovne.f32	s0, s15
   e6820:	4770      	bx	lr
   e6822:	bf00      	nop
   e6824:	007fffff 	.word	0x007fffff
   e6828:	7149f2ca 	.word	0x7149f2ca
   e682c:	00000000 	.word	0x00000000

000e6830 <fmaxf>:
   e6830:	b508      	push	{r3, lr}
   e6832:	ed2d 8b02 	vpush	{d8}
   e6836:	eeb0 8a60 	vmov.f32	s16, s1
   e683a:	eef0 8a40 	vmov.f32	s17, s0
   e683e:	f000 f833 	bl	e68a8 <__fpclassifyf>
   e6842:	b920      	cbnz	r0, e684e <fmaxf+0x1e>
   e6844:	eeb0 0a48 	vmov.f32	s0, s16
   e6848:	ecbd 8b02 	vpop	{d8}
   e684c:	bd08      	pop	{r3, pc}
   e684e:	eeb0 0a48 	vmov.f32	s0, s16
   e6852:	f000 f829 	bl	e68a8 <__fpclassifyf>
   e6856:	b120      	cbz	r0, e6862 <fmaxf+0x32>
   e6858:	eef4 8ac8 	vcmpe.f32	s17, s16
   e685c:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e6860:	ddf0      	ble.n	e6844 <fmaxf+0x14>
   e6862:	eeb0 0a68 	vmov.f32	s0, s17
   e6866:	ecbd 8b02 	vpop	{d8}
   e686a:	bd08      	pop	{r3, pc}

000e686c <fminf>:
   e686c:	b508      	push	{r3, lr}
   e686e:	ed2d 8b02 	vpush	{d8}
   e6872:	eeb0 8a60 	vmov.f32	s16, s1
   e6876:	eef0 8a40 	vmov.f32	s17, s0
   e687a:	f000 f815 	bl	e68a8 <__fpclassifyf>
   e687e:	b920      	cbnz	r0, e688a <fminf+0x1e>
   e6880:	eeb0 0a48 	vmov.f32	s0, s16
   e6884:	ecbd 8b02 	vpop	{d8}
   e6888:	bd08      	pop	{r3, pc}
   e688a:	eeb0 0a48 	vmov.f32	s0, s16
   e688e:	f000 f80b 	bl	e68a8 <__fpclassifyf>
   e6892:	b120      	cbz	r0, e689e <fminf+0x32>
   e6894:	eef4 8ac8 	vcmpe.f32	s17, s16
   e6898:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e689c:	d5f0      	bpl.n	e6880 <fminf+0x14>
   e689e:	eeb0 0a68 	vmov.f32	s0, s17
   e68a2:	ecbd 8b02 	vpop	{d8}
   e68a6:	bd08      	pop	{r3, pc}

000e68a8 <__fpclassifyf>:
   e68a8:	ee10 3a10 	vmov	r3, s0
   e68ac:	f033 4000 	bics.w	r0, r3, #2147483648	; 0x80000000
   e68b0:	d101      	bne.n	e68b6 <__fpclassifyf+0xe>
   e68b2:	2002      	movs	r0, #2
   e68b4:	4770      	bx	lr
   e68b6:	f5a0 0300 	sub.w	r3, r0, #8388608	; 0x800000
   e68ba:	f1b3 4ffe 	cmp.w	r3, #2130706432	; 0x7f000000
   e68be:	d201      	bcs.n	e68c4 <__fpclassifyf+0x1c>
   e68c0:	2004      	movs	r0, #4
   e68c2:	4770      	bx	lr
   e68c4:	4b05      	ldr	r3, [pc, #20]	; (e68dc <__fpclassifyf+0x34>)
   e68c6:	1e42      	subs	r2, r0, #1
   e68c8:	429a      	cmp	r2, r3
   e68ca:	d801      	bhi.n	e68d0 <__fpclassifyf+0x28>
   e68cc:	2003      	movs	r0, #3
   e68ce:	4770      	bx	lr
   e68d0:	f1a0 40ff 	sub.w	r0, r0, #2139095040	; 0x7f800000
   e68d4:	fab0 f080 	clz	r0, r0
   e68d8:	0940      	lsrs	r0, r0, #5
   e68da:	4770      	bx	lr
   e68dc:	007ffffe 	.word	0x007ffffe

000e68e0 <roundf>:
   e68e0:	b082      	sub	sp, #8
   e68e2:	ed8d 0a01 	vstr	s0, [sp, #4]
   e68e6:	9901      	ldr	r1, [sp, #4]
   e68e8:	f3c1 53c7 	ubfx	r3, r1, #23, #8
   e68ec:	3b7f      	subs	r3, #127	; 0x7f
   e68ee:	2b16      	cmp	r3, #22
   e68f0:	dc10      	bgt.n	e6914 <roundf+0x34>
   e68f2:	2b00      	cmp	r3, #0
   e68f4:	db1a      	blt.n	e692c <roundf+0x4c>
   e68f6:	4a11      	ldr	r2, [pc, #68]	; (e693c <roundf+0x5c>)
   e68f8:	fa42 f003 	asr.w	r0, r2, r3
   e68fc:	4201      	tst	r1, r0
   e68fe:	d00b      	beq.n	e6918 <roundf+0x38>
   e6900:	f44f 0280 	mov.w	r2, #4194304	; 0x400000
   e6904:	411a      	asrs	r2, r3
   e6906:	440a      	add	r2, r1
   e6908:	ea22 0200 	bic.w	r2, r2, r0
   e690c:	ee00 2a10 	vmov	s0, r2
   e6910:	b002      	add	sp, #8
   e6912:	4770      	bx	lr
   e6914:	2b80      	cmp	r3, #128	; 0x80
   e6916:	d003      	beq.n	e6920 <roundf+0x40>
   e6918:	ed9d 0a01 	vldr	s0, [sp, #4]
   e691c:	b002      	add	sp, #8
   e691e:	4770      	bx	lr
   e6920:	eddd 7a01 	vldr	s15, [sp, #4]
   e6924:	ee37 0aa7 	vadd.f32	s0, s15, s15
   e6928:	b002      	add	sp, #8
   e692a:	4770      	bx	lr
   e692c:	3301      	adds	r3, #1
   e692e:	f001 4200 	and.w	r2, r1, #2147483648	; 0x80000000
   e6932:	d1eb      	bne.n	e690c <roundf+0x2c>
   e6934:	f042 527e 	orr.w	r2, r2, #1065353216	; 0x3f800000
   e6938:	e7e8      	b.n	e690c <roundf+0x2c>
   e693a:	bf00      	nop
   e693c:	007fffff 	.word	0x007fffff

000e6940 <sinf>:
   e6940:	b500      	push	{lr}
   e6942:	ee10 3a10 	vmov	r3, s0
   e6946:	4a21      	ldr	r2, [pc, #132]	; (e69cc <sinf+0x8c>)
   e6948:	f023 4300 	bic.w	r3, r3, #2147483648	; 0x80000000
   e694c:	4293      	cmp	r3, r2
   e694e:	b083      	sub	sp, #12
   e6950:	dd1a      	ble.n	e6988 <sinf+0x48>
   e6952:	f1b3 4fff 	cmp.w	r3, #2139095040	; 0x7f800000
   e6956:	db04      	blt.n	e6962 <sinf+0x22>
   e6958:	ee30 0a40 	vsub.f32	s0, s0, s0
   e695c:	b003      	add	sp, #12
   e695e:	f85d fb04 	ldr.w	pc, [sp], #4
   e6962:	4668      	mov	r0, sp
   e6964:	f000 fd86 	bl	e7474 <__ieee754_rem_pio2f>
   e6968:	f000 0003 	and.w	r0, r0, #3
   e696c:	2801      	cmp	r0, #1
   e696e:	d01d      	beq.n	e69ac <sinf+0x6c>
   e6970:	2802      	cmp	r0, #2
   e6972:	d011      	beq.n	e6998 <sinf+0x58>
   e6974:	b308      	cbz	r0, e69ba <sinf+0x7a>
   e6976:	eddd 0a01 	vldr	s1, [sp, #4]
   e697a:	ed9d 0a00 	vldr	s0, [sp]
   e697e:	f000 ff17 	bl	e77b0 <__kernel_cosf>
   e6982:	eeb1 0a40 	vneg.f32	s0, s0
   e6986:	e7e9      	b.n	e695c <sinf+0x1c>
   e6988:	2000      	movs	r0, #0
   e698a:	eddf 0a11 	vldr	s1, [pc, #68]	; e69d0 <sinf+0x90>
   e698e:	f001 faa5 	bl	e7edc <__kernel_sinf>
   e6992:	b003      	add	sp, #12
   e6994:	f85d fb04 	ldr.w	pc, [sp], #4
   e6998:	2001      	movs	r0, #1
   e699a:	eddd 0a01 	vldr	s1, [sp, #4]
   e699e:	ed9d 0a00 	vldr	s0, [sp]
   e69a2:	f001 fa9b 	bl	e7edc <__kernel_sinf>
   e69a6:	eeb1 0a40 	vneg.f32	s0, s0
   e69aa:	e7d7      	b.n	e695c <sinf+0x1c>
   e69ac:	eddd 0a01 	vldr	s1, [sp, #4]
   e69b0:	ed9d 0a00 	vldr	s0, [sp]
   e69b4:	f000 fefc 	bl	e77b0 <__kernel_cosf>
   e69b8:	e7d0      	b.n	e695c <sinf+0x1c>
   e69ba:	2001      	movs	r0, #1
   e69bc:	eddd 0a01 	vldr	s1, [sp, #4]
   e69c0:	ed9d 0a00 	vldr	s0, [sp]
   e69c4:	f001 fa8a 	bl	e7edc <__kernel_sinf>
   e69c8:	e7c8      	b.n	e695c <sinf+0x1c>
   e69ca:	bf00      	nop
   e69cc:	3f490fd8 	.word	0x3f490fd8
	...

000e69d8 <exp>:
   e69d8:	b5f0      	push	{r4, r5, r6, r7, lr}
   e69da:	ed2d 8b04 	vpush	{d8-d9}
   e69de:	eeb0 9a40 	vmov.f32	s18, s0
   e69e2:	eef0 9a60 	vmov.f32	s19, s1
   e69e6:	4c3a      	ldr	r4, [pc, #232]	; (e6ad0 <exp+0xf8>)
   e69e8:	b08b      	sub	sp, #44	; 0x2c
   e69ea:	f000 f9cd 	bl	e6d88 <__ieee754_exp>
   e69ee:	f994 3000 	ldrsb.w	r3, [r4]
   e69f2:	eeb0 8a40 	vmov.f32	s16, s0
   e69f6:	eef0 8a60 	vmov.f32	s17, s1
   e69fa:	3301      	adds	r3, #1
   e69fc:	d038      	beq.n	e6a70 <exp+0x98>
   e69fe:	eeb0 0a49 	vmov.f32	s0, s18
   e6a02:	eef0 0a69 	vmov.f32	s1, s19
   e6a06:	f001 fab1 	bl	e7f6c <finite>
   e6a0a:	b388      	cbz	r0, e6a70 <exp+0x98>
   e6a0c:	a32c      	add	r3, pc, #176	; (adr r3, e6ac0 <exp+0xe8>)
   e6a0e:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6a12:	ec51 0b19 	vmov	r0, r1, d9
   e6a16:	f001 ff95 	bl	e8944 <__aeabi_dcmpgt>
   e6a1a:	4605      	mov	r5, r0
   e6a1c:	bb80      	cbnz	r0, e6a80 <exp+0xa8>
   e6a1e:	a32a      	add	r3, pc, #168	; (adr r3, e6ac8 <exp+0xf0>)
   e6a20:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6a24:	ec51 0b19 	vmov	r0, r1, d9
   e6a28:	f001 ff6e 	bl	e8908 <__aeabi_dcmplt>
   e6a2c:	b300      	cbz	r0, e6a70 <exp+0x98>
   e6a2e:	f994 3000 	ldrsb.w	r3, [r4]
   e6a32:	4a28      	ldr	r2, [pc, #160]	; (e6ad4 <exp+0xfc>)
   e6a34:	9508      	str	r5, [sp, #32]
   e6a36:	2600      	movs	r6, #0
   e6a38:	2700      	movs	r7, #0
   e6a3a:	2104      	movs	r1, #4
   e6a3c:	2b02      	cmp	r3, #2
   e6a3e:	ed8d 9b04 	vstr	d9, [sp, #16]
   e6a42:	ed8d 9b02 	vstr	d9, [sp, #8]
   e6a46:	e9cd 6706 	strd	r6, r7, [sp, #24]
   e6a4a:	e88d 0006 	stmia.w	sp, {r1, r2}
   e6a4e:	d030      	beq.n	e6ab2 <exp+0xda>
   e6a50:	4668      	mov	r0, sp
   e6a52:	f001 fa93 	bl	e7f7c <matherr>
   e6a56:	b360      	cbz	r0, e6ab2 <exp+0xda>
   e6a58:	9b08      	ldr	r3, [sp, #32]
   e6a5a:	b11b      	cbz	r3, e6a64 <exp+0x8c>
   e6a5c:	f7fe fd52 	bl	e5504 <__errno>
   e6a60:	9b08      	ldr	r3, [sp, #32]
   e6a62:	6003      	str	r3, [r0, #0]
   e6a64:	ed9d 0b06 	vldr	d0, [sp, #24]
   e6a68:	b00b      	add	sp, #44	; 0x2c
   e6a6a:	ecbd 8b04 	vpop	{d8-d9}
   e6a6e:	bdf0      	pop	{r4, r5, r6, r7, pc}
   e6a70:	eeb0 0a48 	vmov.f32	s0, s16
   e6a74:	eef0 0a68 	vmov.f32	s1, s17
   e6a78:	b00b      	add	sp, #44	; 0x2c
   e6a7a:	ecbd 8b04 	vpop	{d8-d9}
   e6a7e:	bdf0      	pop	{r4, r5, r6, r7, pc}
   e6a80:	4a14      	ldr	r2, [pc, #80]	; (e6ad4 <exp+0xfc>)
   e6a82:	f994 3000 	ldrsb.w	r3, [r4]
   e6a86:	9201      	str	r2, [sp, #4]
   e6a88:	2103      	movs	r1, #3
   e6a8a:	2200      	movs	r2, #0
   e6a8c:	ed8d 9b04 	vstr	d9, [sp, #16]
   e6a90:	ed8d 9b02 	vstr	d9, [sp, #8]
   e6a94:	9100      	str	r1, [sp, #0]
   e6a96:	9208      	str	r2, [sp, #32]
   e6a98:	b92b      	cbnz	r3, e6aa6 <exp+0xce>
   e6a9a:	4b0f      	ldr	r3, [pc, #60]	; (e6ad8 <exp+0x100>)
   e6a9c:	f04f 4260 	mov.w	r2, #3758096384	; 0xe0000000
   e6aa0:	e9cd 2306 	strd	r2, r3, [sp, #24]
   e6aa4:	e7d4      	b.n	e6a50 <exp+0x78>
   e6aa6:	490d      	ldr	r1, [pc, #52]	; (e6adc <exp+0x104>)
   e6aa8:	2000      	movs	r0, #0
   e6aaa:	2b02      	cmp	r3, #2
   e6aac:	e9cd 0106 	strd	r0, r1, [sp, #24]
   e6ab0:	d1ce      	bne.n	e6a50 <exp+0x78>
   e6ab2:	f7fe fd27 	bl	e5504 <__errno>
   e6ab6:	2322      	movs	r3, #34	; 0x22
   e6ab8:	6003      	str	r3, [r0, #0]
   e6aba:	e7cd      	b.n	e6a58 <exp+0x80>
   e6abc:	f3af 8000 	nop.w
   e6ac0:	fefa39ef 	.word	0xfefa39ef
   e6ac4:	40862e42 	.word	0x40862e42
   e6ac8:	d52d3051 	.word	0xd52d3051
   e6acc:	c0874910 	.word	0xc0874910
   e6ad0:	2003c234 	.word	0x2003c234
   e6ad4:	000ed028 	.word	0x000ed028
   e6ad8:	47efffff 	.word	0x47efffff
   e6adc:	7ff00000 	.word	0x7ff00000

000e6ae0 <expf>:
   e6ae0:	b5d0      	push	{r4, r6, r7, lr}
   e6ae2:	ed2d 8b02 	vpush	{d8}
   e6ae6:	4c39      	ldr	r4, [pc, #228]	; (e6bcc <expf+0xec>)
   e6ae8:	b08a      	sub	sp, #40	; 0x28
   e6aea:	eef0 8a40 	vmov.f32	s17, s0
   e6aee:	f000 fadd 	bl	e70ac <__ieee754_expf>
   e6af2:	f994 3000 	ldrsb.w	r3, [r4]
   e6af6:	3301      	adds	r3, #1
   e6af8:	eeb0 8a40 	vmov.f32	s16, s0
   e6afc:	d03e      	beq.n	e6b7c <expf+0x9c>
   e6afe:	eeb0 0a68 	vmov.f32	s0, s17
   e6b02:	f001 fa4d 	bl	e7fa0 <finitef>
   e6b06:	2800      	cmp	r0, #0
   e6b08:	d038      	beq.n	e6b7c <expf+0x9c>
   e6b0a:	eddf 7a31 	vldr	s15, [pc, #196]	; e6bd0 <expf+0xf0>
   e6b0e:	eef4 8ae7 	vcmpe.f32	s17, s15
   e6b12:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e6b16:	dc37      	bgt.n	e6b88 <expf+0xa8>
   e6b18:	eddf 7a2e 	vldr	s15, [pc, #184]	; e6bd4 <expf+0xf4>
   e6b1c:	eef4 8ae7 	vcmpe.f32	s17, s15
   e6b20:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e6b24:	d52a      	bpl.n	e6b7c <expf+0x9c>
   e6b26:	2304      	movs	r3, #4
   e6b28:	4a2b      	ldr	r2, [pc, #172]	; (e6bd8 <expf+0xf8>)
   e6b2a:	9300      	str	r3, [sp, #0]
   e6b2c:	ee18 0a90 	vmov	r0, s17
   e6b30:	2300      	movs	r3, #0
   e6b32:	9308      	str	r3, [sp, #32]
   e6b34:	9201      	str	r2, [sp, #4]
   e6b36:	f001 fc21 	bl	e837c <__aeabi_f2d>
   e6b3a:	f994 3000 	ldrsb.w	r3, [r4]
   e6b3e:	2600      	movs	r6, #0
   e6b40:	2700      	movs	r7, #0
   e6b42:	2b02      	cmp	r3, #2
   e6b44:	e9cd 0104 	strd	r0, r1, [sp, #16]
   e6b48:	e9cd 0102 	strd	r0, r1, [sp, #8]
   e6b4c:	e9cd 6706 	strd	r6, r7, [sp, #24]
   e6b50:	d037      	beq.n	e6bc2 <expf+0xe2>
   e6b52:	4668      	mov	r0, sp
   e6b54:	f001 fa12 	bl	e7f7c <matherr>
   e6b58:	2800      	cmp	r0, #0
   e6b5a:	d032      	beq.n	e6bc2 <expf+0xe2>
   e6b5c:	9b08      	ldr	r3, [sp, #32]
   e6b5e:	b11b      	cbz	r3, e6b68 <expf+0x88>
   e6b60:	f7fe fcd0 	bl	e5504 <__errno>
   e6b64:	9b08      	ldr	r3, [sp, #32]
   e6b66:	6003      	str	r3, [r0, #0]
   e6b68:	e9dd 0106 	ldrd	r0, r1, [sp, #24]
   e6b6c:	f001 ff3c 	bl	e89e8 <__aeabi_d2f>
   e6b70:	ee00 0a10 	vmov	s0, r0
   e6b74:	b00a      	add	sp, #40	; 0x28
   e6b76:	ecbd 8b02 	vpop	{d8}
   e6b7a:	bdd0      	pop	{r4, r6, r7, pc}
   e6b7c:	eeb0 0a48 	vmov.f32	s0, s16
   e6b80:	b00a      	add	sp, #40	; 0x28
   e6b82:	ecbd 8b02 	vpop	{d8}
   e6b86:	bdd0      	pop	{r4, r6, r7, pc}
   e6b88:	2303      	movs	r3, #3
   e6b8a:	4a13      	ldr	r2, [pc, #76]	; (e6bd8 <expf+0xf8>)
   e6b8c:	9300      	str	r3, [sp, #0]
   e6b8e:	ee18 0a90 	vmov	r0, s17
   e6b92:	2300      	movs	r3, #0
   e6b94:	9308      	str	r3, [sp, #32]
   e6b96:	9201      	str	r2, [sp, #4]
   e6b98:	f001 fbf0 	bl	e837c <__aeabi_f2d>
   e6b9c:	f994 3000 	ldrsb.w	r3, [r4]
   e6ba0:	e9cd 0104 	strd	r0, r1, [sp, #16]
   e6ba4:	e9cd 0102 	strd	r0, r1, [sp, #8]
   e6ba8:	b92b      	cbnz	r3, e6bb6 <expf+0xd6>
   e6baa:	4b0c      	ldr	r3, [pc, #48]	; (e6bdc <expf+0xfc>)
   e6bac:	f04f 4260 	mov.w	r2, #3758096384	; 0xe0000000
   e6bb0:	e9cd 2306 	strd	r2, r3, [sp, #24]
   e6bb4:	e7cd      	b.n	e6b52 <expf+0x72>
   e6bb6:	490a      	ldr	r1, [pc, #40]	; (e6be0 <expf+0x100>)
   e6bb8:	2000      	movs	r0, #0
   e6bba:	2b02      	cmp	r3, #2
   e6bbc:	e9cd 0106 	strd	r0, r1, [sp, #24]
   e6bc0:	d1c7      	bne.n	e6b52 <expf+0x72>
   e6bc2:	f7fe fc9f 	bl	e5504 <__errno>
   e6bc6:	2322      	movs	r3, #34	; 0x22
   e6bc8:	6003      	str	r3, [r0, #0]
   e6bca:	e7c7      	b.n	e6b5c <expf+0x7c>
   e6bcc:	2003c234 	.word	0x2003c234
   e6bd0:	42b17180 	.word	0x42b17180
   e6bd4:	c2cff1b5 	.word	0xc2cff1b5
   e6bd8:	000ed02c 	.word	0x000ed02c
   e6bdc:	47efffff 	.word	0x47efffff
   e6be0:	7ff00000 	.word	0x7ff00000

000e6be4 <logf>:
   e6be4:	b510      	push	{r4, lr}
   e6be6:	ed2d 8b02 	vpush	{d8}
   e6bea:	b08a      	sub	sp, #40	; 0x28
   e6bec:	eeb0 8a40 	vmov.f32	s16, s0
   e6bf0:	f000 fb34 	bl	e725c <__ieee754_logf>
   e6bf4:	4b34      	ldr	r3, [pc, #208]	; (e6cc8 <logf+0xe4>)
   e6bf6:	f993 4000 	ldrsb.w	r4, [r3]
   e6bfa:	1c63      	adds	r3, r4, #1
   e6bfc:	d009      	beq.n	e6c12 <logf+0x2e>
   e6bfe:	eeb4 8a48 	vcmp.f32	s16, s16
   e6c02:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e6c06:	d604      	bvs.n	e6c12 <logf+0x2e>
   e6c08:	eeb5 8ac0 	vcmpe.f32	s16, #0.0
   e6c0c:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e6c10:	dd03      	ble.n	e6c1a <logf+0x36>
   e6c12:	b00a      	add	sp, #40	; 0x28
   e6c14:	ecbd 8b02 	vpop	{d8}
   e6c18:	bd10      	pop	{r4, pc}
   e6c1a:	4b2c      	ldr	r3, [pc, #176]	; (e6ccc <logf+0xe8>)
   e6c1c:	9301      	str	r3, [sp, #4]
   e6c1e:	ee18 0a10 	vmov	r0, s16
   e6c22:	2300      	movs	r3, #0
   e6c24:	9308      	str	r3, [sp, #32]
   e6c26:	f001 fba9 	bl	e837c <__aeabi_f2d>
   e6c2a:	e9cd 0104 	strd	r0, r1, [sp, #16]
   e6c2e:	e9cd 0102 	strd	r0, r1, [sp, #8]
   e6c32:	b9dc      	cbnz	r4, e6c6c <logf+0x88>
   e6c34:	4b26      	ldr	r3, [pc, #152]	; (e6cd0 <logf+0xec>)
   e6c36:	eeb5 8a40 	vcmp.f32	s16, #0.0
   e6c3a:	f04f 4260 	mov.w	r2, #3758096384	; 0xe0000000
   e6c3e:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e6c42:	e9cd 2306 	strd	r2, r3, [sp, #24]
   e6c46:	d136      	bne.n	e6cb6 <logf+0xd2>
   e6c48:	2302      	movs	r3, #2
   e6c4a:	9300      	str	r3, [sp, #0]
   e6c4c:	4668      	mov	r0, sp
   e6c4e:	f001 f995 	bl	e7f7c <matherr>
   e6c52:	b1c0      	cbz	r0, e6c86 <logf+0xa2>
   e6c54:	9b08      	ldr	r3, [sp, #32]
   e6c56:	b9db      	cbnz	r3, e6c90 <logf+0xac>
   e6c58:	e9dd 0106 	ldrd	r0, r1, [sp, #24]
   e6c5c:	f001 fec4 	bl	e89e8 <__aeabi_d2f>
   e6c60:	ee00 0a10 	vmov	s0, r0
   e6c64:	b00a      	add	sp, #40	; 0x28
   e6c66:	ecbd 8b02 	vpop	{d8}
   e6c6a:	bd10      	pop	{r4, pc}
   e6c6c:	4b19      	ldr	r3, [pc, #100]	; (e6cd4 <logf+0xf0>)
   e6c6e:	eeb5 8a40 	vcmp.f32	s16, #0.0
   e6c72:	2200      	movs	r2, #0
   e6c74:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e6c78:	e9cd 2306 	strd	r2, r3, [sp, #24]
   e6c7c:	d10d      	bne.n	e6c9a <logf+0xb6>
   e6c7e:	2302      	movs	r3, #2
   e6c80:	429c      	cmp	r4, r3
   e6c82:	9300      	str	r3, [sp, #0]
   e6c84:	d1e2      	bne.n	e6c4c <logf+0x68>
   e6c86:	f7fe fc3d 	bl	e5504 <__errno>
   e6c8a:	2322      	movs	r3, #34	; 0x22
   e6c8c:	6003      	str	r3, [r0, #0]
   e6c8e:	e7e1      	b.n	e6c54 <logf+0x70>
   e6c90:	f7fe fc38 	bl	e5504 <__errno>
   e6c94:	9b08      	ldr	r3, [sp, #32]
   e6c96:	6003      	str	r3, [r0, #0]
   e6c98:	e7de      	b.n	e6c58 <logf+0x74>
   e6c9a:	2301      	movs	r3, #1
   e6c9c:	2c02      	cmp	r4, #2
   e6c9e:	9300      	str	r3, [sp, #0]
   e6ca0:	d10b      	bne.n	e6cba <logf+0xd6>
   e6ca2:	f7fe fc2f 	bl	e5504 <__errno>
   e6ca6:	2321      	movs	r3, #33	; 0x21
   e6ca8:	6003      	str	r3, [r0, #0]
   e6caa:	480b      	ldr	r0, [pc, #44]	; (e6cd8 <logf+0xf4>)
   e6cac:	f001 f968 	bl	e7f80 <nan>
   e6cb0:	ed8d 0b06 	vstr	d0, [sp, #24]
   e6cb4:	e7ce      	b.n	e6c54 <logf+0x70>
   e6cb6:	2301      	movs	r3, #1
   e6cb8:	9300      	str	r3, [sp, #0]
   e6cba:	4668      	mov	r0, sp
   e6cbc:	f001 f95e 	bl	e7f7c <matherr>
   e6cc0:	2800      	cmp	r0, #0
   e6cc2:	d1f2      	bne.n	e6caa <logf+0xc6>
   e6cc4:	e7ed      	b.n	e6ca2 <logf+0xbe>
   e6cc6:	bf00      	nop
   e6cc8:	2003c234 	.word	0x2003c234
   e6ccc:	000ed034 	.word	0x000ed034
   e6cd0:	c7efffff 	.word	0xc7efffff
   e6cd4:	fff00000 	.word	0xfff00000
   e6cd8:	000ed038 	.word	0x000ed038

000e6cdc <sqrtf>:
   e6cdc:	b510      	push	{r4, lr}
   e6cde:	ed2d 8b02 	vpush	{d8}
   e6ce2:	b08a      	sub	sp, #40	; 0x28
   e6ce4:	eeb0 8a40 	vmov.f32	s16, s0
   e6ce8:	f000 fd10 	bl	e770c <__ieee754_sqrtf>
   e6cec:	4b24      	ldr	r3, [pc, #144]	; (e6d80 <sqrtf+0xa4>)
   e6cee:	f993 4000 	ldrsb.w	r4, [r3]
   e6cf2:	1c63      	adds	r3, r4, #1
   e6cf4:	d009      	beq.n	e6d0a <sqrtf+0x2e>
   e6cf6:	eeb4 8a48 	vcmp.f32	s16, s16
   e6cfa:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e6cfe:	d604      	bvs.n	e6d0a <sqrtf+0x2e>
   e6d00:	eeb5 8ac0 	vcmpe.f32	s16, #0.0
   e6d04:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e6d08:	d403      	bmi.n	e6d12 <sqrtf+0x36>
   e6d0a:	b00a      	add	sp, #40	; 0x28
   e6d0c:	ecbd 8b02 	vpop	{d8}
   e6d10:	bd10      	pop	{r4, pc}
   e6d12:	2301      	movs	r3, #1
   e6d14:	4a1b      	ldr	r2, [pc, #108]	; (e6d84 <sqrtf+0xa8>)
   e6d16:	9300      	str	r3, [sp, #0]
   e6d18:	ee18 0a10 	vmov	r0, s16
   e6d1c:	2300      	movs	r3, #0
   e6d1e:	9201      	str	r2, [sp, #4]
   e6d20:	9308      	str	r3, [sp, #32]
   e6d22:	f001 fb2b 	bl	e837c <__aeabi_f2d>
   e6d26:	2200      	movs	r2, #0
   e6d28:	e9cd 0104 	strd	r0, r1, [sp, #16]
   e6d2c:	e9cd 0102 	strd	r0, r1, [sp, #8]
   e6d30:	2300      	movs	r3, #0
   e6d32:	b1bc      	cbz	r4, e6d64 <sqrtf+0x88>
   e6d34:	4610      	mov	r0, r2
   e6d36:	4619      	mov	r1, r3
   e6d38:	f001 fc9e 	bl	e8678 <__aeabi_ddiv>
   e6d3c:	2c02      	cmp	r4, #2
   e6d3e:	e9cd 0106 	strd	r0, r1, [sp, #24]
   e6d42:	d111      	bne.n	e6d68 <sqrtf+0x8c>
   e6d44:	f7fe fbde 	bl	e5504 <__errno>
   e6d48:	2321      	movs	r3, #33	; 0x21
   e6d4a:	6003      	str	r3, [r0, #0]
   e6d4c:	9b08      	ldr	r3, [sp, #32]
   e6d4e:	b98b      	cbnz	r3, e6d74 <sqrtf+0x98>
   e6d50:	e9dd 0106 	ldrd	r0, r1, [sp, #24]
   e6d54:	f001 fe48 	bl	e89e8 <__aeabi_d2f>
   e6d58:	ee00 0a10 	vmov	s0, r0
   e6d5c:	b00a      	add	sp, #40	; 0x28
   e6d5e:	ecbd 8b02 	vpop	{d8}
   e6d62:	bd10      	pop	{r4, pc}
   e6d64:	e9cd 2306 	strd	r2, r3, [sp, #24]
   e6d68:	4668      	mov	r0, sp
   e6d6a:	f001 f907 	bl	e7f7c <matherr>
   e6d6e:	2800      	cmp	r0, #0
   e6d70:	d1ec      	bne.n	e6d4c <sqrtf+0x70>
   e6d72:	e7e7      	b.n	e6d44 <sqrtf+0x68>
   e6d74:	f7fe fbc6 	bl	e5504 <__errno>
   e6d78:	9b08      	ldr	r3, [sp, #32]
   e6d7a:	6003      	str	r3, [r0, #0]
   e6d7c:	e7e8      	b.n	e6d50 <sqrtf+0x74>
   e6d7e:	bf00      	nop
   e6d80:	2003c234 	.word	0x2003c234
   e6d84:	000ed03c 	.word	0x000ed03c

000e6d88 <__ieee754_exp>:
   e6d88:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e6d8c:	ec55 4b10 	vmov	r4, r5, d0
   e6d90:	49bd      	ldr	r1, [pc, #756]	; (e7088 <__ieee754_exp+0x300>)
   e6d92:	f025 4200 	bic.w	r2, r5, #2147483648	; 0x80000000
   e6d96:	428a      	cmp	r2, r1
   e6d98:	b083      	sub	sp, #12
   e6d9a:	ea4f 77d5 	mov.w	r7, r5, lsr #31
   e6d9e:	d90d      	bls.n	e6dbc <__ieee754_exp+0x34>
   e6da0:	49ba      	ldr	r1, [pc, #744]	; (e708c <__ieee754_exp+0x304>)
   e6da2:	428a      	cmp	r2, r1
   e6da4:	d92a      	bls.n	e6dfc <__ieee754_exp+0x74>
   e6da6:	f3c5 0313 	ubfx	r3, r5, #0, #20
   e6daa:	4323      	orrs	r3, r4
   e6dac:	f040 80fa 	bne.w	e6fa4 <__ieee754_exp+0x21c>
   e6db0:	b10f      	cbz	r7, e6db6 <__ieee754_exp+0x2e>
   e6db2:	ed9f 0b9d 	vldr	d0, [pc, #628]	; e7028 <__ieee754_exp+0x2a0>
   e6db6:	b003      	add	sp, #12
   e6db8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e6dbc:	4bb4      	ldr	r3, [pc, #720]	; (e7090 <__ieee754_exp+0x308>)
   e6dbe:	429a      	cmp	r2, r3
   e6dc0:	f200 80d5 	bhi.w	e6f6e <__ieee754_exp+0x1e6>
   e6dc4:	4bb3      	ldr	r3, [pc, #716]	; (e7094 <__ieee754_exp+0x30c>)
   e6dc6:	429a      	cmp	r2, r3
   e6dc8:	f200 80ea 	bhi.w	e6fa0 <__ieee754_exp+0x218>
   e6dcc:	a398      	add	r3, pc, #608	; (adr r3, e7030 <__ieee754_exp+0x2a8>)
   e6dce:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6dd2:	ee10 0a10 	vmov	r0, s0
   e6dd6:	4629      	mov	r1, r5
   e6dd8:	f001 f972 	bl	e80c0 <__adddf3>
   e6ddc:	2200      	movs	r2, #0
   e6dde:	4bae      	ldr	r3, [pc, #696]	; (e7098 <__ieee754_exp+0x310>)
   e6de0:	f001 fdb0 	bl	e8944 <__aeabi_dcmpgt>
   e6de4:	2800      	cmp	r0, #0
   e6de6:	f000 811c 	beq.w	e7022 <__ieee754_exp+0x29a>
   e6dea:	4620      	mov	r0, r4
   e6dec:	4629      	mov	r1, r5
   e6dee:	2200      	movs	r2, #0
   e6df0:	4ba9      	ldr	r3, [pc, #676]	; (e7098 <__ieee754_exp+0x310>)
   e6df2:	f001 f965 	bl	e80c0 <__adddf3>
   e6df6:	ec41 0b10 	vmov	d0, r0, r1
   e6dfa:	e7dc      	b.n	e6db6 <__ieee754_exp+0x2e>
   e6dfc:	a38e      	add	r3, pc, #568	; (adr r3, e7038 <__ieee754_exp+0x2b0>)
   e6dfe:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6e02:	ee10 0a10 	vmov	r0, s0
   e6e06:	4629      	mov	r1, r5
   e6e08:	f001 fd9c 	bl	e8944 <__aeabi_dcmpgt>
   e6e0c:	2800      	cmp	r0, #0
   e6e0e:	f040 80d3 	bne.w	e6fb8 <__ieee754_exp+0x230>
   e6e12:	a38b      	add	r3, pc, #556	; (adr r3, e7040 <__ieee754_exp+0x2b8>)
   e6e14:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6e18:	4620      	mov	r0, r4
   e6e1a:	4629      	mov	r1, r5
   e6e1c:	f001 fd74 	bl	e8908 <__aeabi_dcmplt>
   e6e20:	2800      	cmp	r0, #0
   e6e22:	d1c6      	bne.n	e6db2 <__ieee754_exp+0x2a>
   e6e24:	4e9d      	ldr	r6, [pc, #628]	; (e709c <__ieee754_exp+0x314>)
   e6e26:	a388      	add	r3, pc, #544	; (adr r3, e7048 <__ieee754_exp+0x2c0>)
   e6e28:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6e2c:	eb06 06c7 	add.w	r6, r6, r7, lsl #3
   e6e30:	4620      	mov	r0, r4
   e6e32:	4629      	mov	r1, r5
   e6e34:	f001 faf6 	bl	e8424 <__aeabi_dmul>
   e6e38:	e9d6 2300 	ldrd	r2, r3, [r6]
   e6e3c:	f001 f940 	bl	e80c0 <__adddf3>
   e6e40:	f001 fd8a 	bl	e8958 <__aeabi_d2iz>
   e6e44:	4606      	mov	r6, r0
   e6e46:	f001 fa87 	bl	e8358 <__aeabi_i2d>
   e6e4a:	a381      	add	r3, pc, #516	; (adr r3, e7050 <__ieee754_exp+0x2c8>)
   e6e4c:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6e50:	4680      	mov	r8, r0
   e6e52:	4689      	mov	r9, r1
   e6e54:	f001 fae6 	bl	e8424 <__aeabi_dmul>
   e6e58:	4602      	mov	r2, r0
   e6e5a:	460b      	mov	r3, r1
   e6e5c:	4620      	mov	r0, r4
   e6e5e:	4629      	mov	r1, r5
   e6e60:	f001 f92c 	bl	e80bc <__aeabi_dsub>
   e6e64:	a37c      	add	r3, pc, #496	; (adr r3, e7058 <__ieee754_exp+0x2d0>)
   e6e66:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6e6a:	e9cd 0100 	strd	r0, r1, [sp]
   e6e6e:	4640      	mov	r0, r8
   e6e70:	4649      	mov	r1, r9
   e6e72:	f001 fad7 	bl	e8424 <__aeabi_dmul>
   e6e76:	4682      	mov	sl, r0
   e6e78:	468b      	mov	fp, r1
   e6e7a:	4652      	mov	r2, sl
   e6e7c:	465b      	mov	r3, fp
   e6e7e:	e9dd 0100 	ldrd	r0, r1, [sp]
   e6e82:	f001 f91b 	bl	e80bc <__aeabi_dsub>
   e6e86:	4604      	mov	r4, r0
   e6e88:	460d      	mov	r5, r1
   e6e8a:	4622      	mov	r2, r4
   e6e8c:	462b      	mov	r3, r5
   e6e8e:	4620      	mov	r0, r4
   e6e90:	4629      	mov	r1, r5
   e6e92:	f001 fac7 	bl	e8424 <__aeabi_dmul>
   e6e96:	a372      	add	r3, pc, #456	; (adr r3, e7060 <__ieee754_exp+0x2d8>)
   e6e98:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6e9c:	4680      	mov	r8, r0
   e6e9e:	4689      	mov	r9, r1
   e6ea0:	f001 fac0 	bl	e8424 <__aeabi_dmul>
   e6ea4:	a370      	add	r3, pc, #448	; (adr r3, e7068 <__ieee754_exp+0x2e0>)
   e6ea6:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6eaa:	f001 f907 	bl	e80bc <__aeabi_dsub>
   e6eae:	4642      	mov	r2, r8
   e6eb0:	464b      	mov	r3, r9
   e6eb2:	f001 fab7 	bl	e8424 <__aeabi_dmul>
   e6eb6:	a36e      	add	r3, pc, #440	; (adr r3, e7070 <__ieee754_exp+0x2e8>)
   e6eb8:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6ebc:	f001 f900 	bl	e80c0 <__adddf3>
   e6ec0:	4642      	mov	r2, r8
   e6ec2:	464b      	mov	r3, r9
   e6ec4:	f001 faae 	bl	e8424 <__aeabi_dmul>
   e6ec8:	a36b      	add	r3, pc, #428	; (adr r3, e7078 <__ieee754_exp+0x2f0>)
   e6eca:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6ece:	f001 f8f5 	bl	e80bc <__aeabi_dsub>
   e6ed2:	4642      	mov	r2, r8
   e6ed4:	464b      	mov	r3, r9
   e6ed6:	f001 faa5 	bl	e8424 <__aeabi_dmul>
   e6eda:	a369      	add	r3, pc, #420	; (adr r3, e7080 <__ieee754_exp+0x2f8>)
   e6edc:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6ee0:	f001 f8ee 	bl	e80c0 <__adddf3>
   e6ee4:	4642      	mov	r2, r8
   e6ee6:	464b      	mov	r3, r9
   e6ee8:	f001 fa9c 	bl	e8424 <__aeabi_dmul>
   e6eec:	4602      	mov	r2, r0
   e6eee:	460b      	mov	r3, r1
   e6ef0:	4620      	mov	r0, r4
   e6ef2:	4629      	mov	r1, r5
   e6ef4:	f001 f8e2 	bl	e80bc <__aeabi_dsub>
   e6ef8:	4680      	mov	r8, r0
   e6efa:	4689      	mov	r9, r1
   e6efc:	2e00      	cmp	r6, #0
   e6efe:	d065      	beq.n	e6fcc <__ieee754_exp+0x244>
   e6f00:	4620      	mov	r0, r4
   e6f02:	4629      	mov	r1, r5
   e6f04:	4642      	mov	r2, r8
   e6f06:	464b      	mov	r3, r9
   e6f08:	f001 fa8c 	bl	e8424 <__aeabi_dmul>
   e6f0c:	4642      	mov	r2, r8
   e6f0e:	4604      	mov	r4, r0
   e6f10:	460d      	mov	r5, r1
   e6f12:	464b      	mov	r3, r9
   e6f14:	2000      	movs	r0, #0
   e6f16:	f04f 4180 	mov.w	r1, #1073741824	; 0x40000000
   e6f1a:	f001 f8cf 	bl	e80bc <__aeabi_dsub>
   e6f1e:	4602      	mov	r2, r0
   e6f20:	460b      	mov	r3, r1
   e6f22:	4620      	mov	r0, r4
   e6f24:	4629      	mov	r1, r5
   e6f26:	f001 fba7 	bl	e8678 <__aeabi_ddiv>
   e6f2a:	4602      	mov	r2, r0
   e6f2c:	460b      	mov	r3, r1
   e6f2e:	4650      	mov	r0, sl
   e6f30:	4659      	mov	r1, fp
   e6f32:	f001 f8c3 	bl	e80bc <__aeabi_dsub>
   e6f36:	e9dd 2300 	ldrd	r2, r3, [sp]
   e6f3a:	f001 f8bf 	bl	e80bc <__aeabi_dsub>
   e6f3e:	460b      	mov	r3, r1
   e6f40:	4602      	mov	r2, r0
   e6f42:	4955      	ldr	r1, [pc, #340]	; (e7098 <__ieee754_exp+0x310>)
   e6f44:	2000      	movs	r0, #0
   e6f46:	f001 f8b9 	bl	e80bc <__aeabi_dsub>
   e6f4a:	f46f 737f 	mvn.w	r3, #1020	; 0x3fc
   e6f4e:	429e      	cmp	r6, r3
   e6f50:	da60      	bge.n	e7014 <__ieee754_exp+0x28c>
   e6f52:	f506 767a 	add.w	r6, r6, #1000	; 0x3e8
   e6f56:	eb01 5106 	add.w	r1, r1, r6, lsl #20
   e6f5a:	2200      	movs	r2, #0
   e6f5c:	f04f 73b8 	mov.w	r3, #24117248	; 0x1700000
   e6f60:	f001 fa60 	bl	e8424 <__aeabi_dmul>
   e6f64:	ec41 0b10 	vmov	d0, r0, r1
   e6f68:	b003      	add	sp, #12
   e6f6a:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e6f6e:	4b4c      	ldr	r3, [pc, #304]	; (e70a0 <__ieee754_exp+0x318>)
   e6f70:	429a      	cmp	r2, r3
   e6f72:	f63f af57 	bhi.w	e6e24 <__ieee754_exp+0x9c>
   e6f76:	4b4b      	ldr	r3, [pc, #300]	; (e70a4 <__ieee754_exp+0x31c>)
   e6f78:	ea4f 08c7 	mov.w	r8, r7, lsl #3
   e6f7c:	4443      	add	r3, r8
   e6f7e:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6f82:	ee10 0a10 	vmov	r0, s0
   e6f86:	4629      	mov	r1, r5
   e6f88:	f001 f898 	bl	e80bc <__aeabi_dsub>
   e6f8c:	4b46      	ldr	r3, [pc, #280]	; (e70a8 <__ieee754_exp+0x320>)
   e6f8e:	f1c7 0601 	rsb	r6, r7, #1
   e6f92:	4498      	add	r8, r3
   e6f94:	e9cd 0100 	strd	r0, r1, [sp]
   e6f98:	e9d8 ab00 	ldrd	sl, fp, [r8]
   e6f9c:	1bf6      	subs	r6, r6, r7
   e6f9e:	e76c      	b.n	e6e7a <__ieee754_exp+0xf2>
   e6fa0:	2600      	movs	r6, #0
   e6fa2:	e772      	b.n	e6e8a <__ieee754_exp+0x102>
   e6fa4:	ee10 2a10 	vmov	r2, s0
   e6fa8:	462b      	mov	r3, r5
   e6faa:	4620      	mov	r0, r4
   e6fac:	4629      	mov	r1, r5
   e6fae:	f001 f887 	bl	e80c0 <__adddf3>
   e6fb2:	ec41 0b10 	vmov	d0, r0, r1
   e6fb6:	e6fe      	b.n	e6db6 <__ieee754_exp+0x2e>
   e6fb8:	a31d      	add	r3, pc, #116	; (adr r3, e7030 <__ieee754_exp+0x2a8>)
   e6fba:	e9d3 2300 	ldrd	r2, r3, [r3]
   e6fbe:	4610      	mov	r0, r2
   e6fc0:	4619      	mov	r1, r3
   e6fc2:	f001 fa2f 	bl	e8424 <__aeabi_dmul>
   e6fc6:	ec41 0b10 	vmov	d0, r0, r1
   e6fca:	e6f4      	b.n	e6db6 <__ieee754_exp+0x2e>
   e6fcc:	4602      	mov	r2, r0
   e6fce:	460b      	mov	r3, r1
   e6fd0:	4620      	mov	r0, r4
   e6fd2:	4629      	mov	r1, r5
   e6fd4:	f001 fa26 	bl	e8424 <__aeabi_dmul>
   e6fd8:	2200      	movs	r2, #0
   e6fda:	4606      	mov	r6, r0
   e6fdc:	460f      	mov	r7, r1
   e6fde:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
   e6fe2:	4640      	mov	r0, r8
   e6fe4:	4649      	mov	r1, r9
   e6fe6:	f001 f869 	bl	e80bc <__aeabi_dsub>
   e6fea:	4602      	mov	r2, r0
   e6fec:	460b      	mov	r3, r1
   e6fee:	4630      	mov	r0, r6
   e6ff0:	4639      	mov	r1, r7
   e6ff2:	f001 fb41 	bl	e8678 <__aeabi_ddiv>
   e6ff6:	4622      	mov	r2, r4
   e6ff8:	462b      	mov	r3, r5
   e6ffa:	f001 f85f 	bl	e80bc <__aeabi_dsub>
   e6ffe:	4602      	mov	r2, r0
   e7000:	460b      	mov	r3, r1
   e7002:	2000      	movs	r0, #0
   e7004:	4924      	ldr	r1, [pc, #144]	; (e7098 <__ieee754_exp+0x310>)
   e7006:	f001 f859 	bl	e80bc <__aeabi_dsub>
   e700a:	ec41 0b10 	vmov	d0, r0, r1
   e700e:	b003      	add	sp, #12
   e7010:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e7014:	eb01 5106 	add.w	r1, r1, r6, lsl #20
   e7018:	ec41 0b10 	vmov	d0, r0, r1
   e701c:	b003      	add	sp, #12
   e701e:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e7022:	4606      	mov	r6, r0
   e7024:	e731      	b.n	e6e8a <__ieee754_exp+0x102>
   e7026:	bf00      	nop
	...
   e7030:	8800759c 	.word	0x8800759c
   e7034:	7e37e43c 	.word	0x7e37e43c
   e7038:	fefa39ef 	.word	0xfefa39ef
   e703c:	40862e42 	.word	0x40862e42
   e7040:	d52d3051 	.word	0xd52d3051
   e7044:	c0874910 	.word	0xc0874910
   e7048:	652b82fe 	.word	0x652b82fe
   e704c:	3ff71547 	.word	0x3ff71547
   e7050:	fee00000 	.word	0xfee00000
   e7054:	3fe62e42 	.word	0x3fe62e42
   e7058:	35793c76 	.word	0x35793c76
   e705c:	3dea39ef 	.word	0x3dea39ef
   e7060:	72bea4d0 	.word	0x72bea4d0
   e7064:	3e663769 	.word	0x3e663769
   e7068:	c5d26bf1 	.word	0xc5d26bf1
   e706c:	3ebbbd41 	.word	0x3ebbbd41
   e7070:	af25de2c 	.word	0xaf25de2c
   e7074:	3f11566a 	.word	0x3f11566a
   e7078:	16bebd93 	.word	0x16bebd93
   e707c:	3f66c16c 	.word	0x3f66c16c
   e7080:	5555553e 	.word	0x5555553e
   e7084:	3fc55555 	.word	0x3fc55555
   e7088:	40862e41 	.word	0x40862e41
   e708c:	7fefffff 	.word	0x7fefffff
   e7090:	3fd62e42 	.word	0x3fd62e42
   e7094:	3e2fffff 	.word	0x3e2fffff
   e7098:	3ff00000 	.word	0x3ff00000
   e709c:	000ed048 	.word	0x000ed048
   e70a0:	3ff0a2b1 	.word	0x3ff0a2b1
   e70a4:	000ed068 	.word	0x000ed068
   e70a8:	000ed058 	.word	0x000ed058

000e70ac <__ieee754_expf>:
   e70ac:	ee10 3a10 	vmov	r3, s0
   e70b0:	f023 4200 	bic.w	r2, r3, #2147483648	; 0x80000000
   e70b4:	f1b2 4fff 	cmp.w	r2, #2139095040	; 0x7f800000
   e70b8:	d856      	bhi.n	e7168 <__ieee754_expf+0xbc>
   e70ba:	ea4f 71d3 	mov.w	r1, r3, lsr #31
   e70be:	d056      	beq.n	e716e <__ieee754_expf+0xc2>
   e70c0:	4854      	ldr	r0, [pc, #336]	; (e7214 <__ieee754_expf+0x168>)
   e70c2:	4283      	cmp	r3, r0
   e70c4:	dc73      	bgt.n	e71ae <__ieee754_expf+0x102>
   e70c6:	2b00      	cmp	r3, #0
   e70c8:	db69      	blt.n	e719e <__ieee754_expf+0xf2>
   e70ca:	4b53      	ldr	r3, [pc, #332]	; (e7218 <__ieee754_expf+0x16c>)
   e70cc:	429a      	cmp	r2, r3
   e70ce:	d955      	bls.n	e717c <__ieee754_expf+0xd0>
   e70d0:	4b52      	ldr	r3, [pc, #328]	; (e721c <__ieee754_expf+0x170>)
   e70d2:	429a      	cmp	r2, r3
   e70d4:	d87d      	bhi.n	e71d2 <__ieee754_expf+0x126>
   e70d6:	4852      	ldr	r0, [pc, #328]	; (e7220 <__ieee754_expf+0x174>)
   e70d8:	4a52      	ldr	r2, [pc, #328]	; (e7224 <__ieee754_expf+0x178>)
   e70da:	008b      	lsls	r3, r1, #2
   e70dc:	4418      	add	r0, r3
   e70de:	ed90 7a00 	vldr	s14, [r0]
   e70e2:	441a      	add	r2, r3
   e70e4:	ee70 4a47 	vsub.f32	s9, s0, s14
   e70e8:	f1c1 0301 	rsb	r3, r1, #1
   e70ec:	ed92 7a00 	vldr	s14, [r2]
   e70f0:	1a5b      	subs	r3, r3, r1
   e70f2:	ee34 0ac7 	vsub.f32	s0, s9, s14
   e70f6:	ee60 7a00 	vmul.f32	s15, s0, s0
   e70fa:	ed9f 4a4b 	vldr	s8, [pc, #300]	; e7228 <__ieee754_expf+0x17c>
   e70fe:	ed9f 5a4b 	vldr	s10, [pc, #300]	; e722c <__ieee754_expf+0x180>
   e7102:	eddf 5a4b 	vldr	s11, [pc, #300]	; e7230 <__ieee754_expf+0x184>
   e7106:	ed9f 6a4b 	vldr	s12, [pc, #300]	; e7234 <__ieee754_expf+0x188>
   e710a:	eddf 6a4b 	vldr	s13, [pc, #300]	; e7238 <__ieee754_expf+0x18c>
   e710e:	eea7 5a84 	vfma.f32	s10, s15, s8
   e7112:	eee7 5a85 	vfma.f32	s11, s15, s10
   e7116:	eea7 6aa5 	vfma.f32	s12, s15, s11
   e711a:	eee7 6a86 	vfma.f32	s13, s15, s12
   e711e:	eeb0 6a40 	vmov.f32	s12, s0
   e7122:	eea7 6ae6 	vfms.f32	s12, s15, s13
   e7126:	eef0 6a00 	vmov.f32	s13, #0	; 0x40000000  2.0
   e712a:	2b00      	cmp	r3, #0
   e712c:	d044      	beq.n	e71b8 <__ieee754_expf+0x10c>
   e712e:	ee20 0a06 	vmul.f32	s0, s0, s12
   e7132:	ee76 7ac6 	vsub.f32	s15, s13, s12
   e7136:	f113 0f7d 	cmn.w	r3, #125	; 0x7d
   e713a:	ee80 6a27 	vdiv.f32	s12, s0, s15
   e713e:	eef7 6a00 	vmov.f32	s13, #112	; 0x3f800000  1.0
   e7142:	ee37 7a46 	vsub.f32	s14, s14, s12
   e7146:	ee37 7a64 	vsub.f32	s14, s14, s9
   e714a:	ee36 0ac7 	vsub.f32	s0, s13, s14
   e714e:	da5a      	bge.n	e7206 <__ieee754_expf+0x15a>
   e7150:	ee10 2a10 	vmov	r2, s0
   e7154:	3364      	adds	r3, #100	; 0x64
   e7156:	eb02 53c3 	add.w	r3, r2, r3, lsl #23
   e715a:	eddf 7a38 	vldr	s15, [pc, #224]	; e723c <__ieee754_expf+0x190>
   e715e:	ee00 3a10 	vmov	s0, r3
   e7162:	ee20 0a27 	vmul.f32	s0, s0, s15
   e7166:	4770      	bx	lr
   e7168:	ee30 0a00 	vadd.f32	s0, s0, s0
   e716c:	4770      	bx	lr
   e716e:	eddf 7a34 	vldr	s15, [pc, #208]	; e7240 <__ieee754_expf+0x194>
   e7172:	2900      	cmp	r1, #0
   e7174:	bf18      	it	ne
   e7176:	eeb0 0a67 	vmovne.f32	s0, s15
   e717a:	4770      	bx	lr
   e717c:	f1b2 5f46 	cmp.w	r2, #830472192	; 0x31800000
   e7180:	d213      	bcs.n	e71aa <__ieee754_expf+0xfe>
   e7182:	eddf 7a30 	vldr	s15, [pc, #192]	; e7244 <__ieee754_expf+0x198>
   e7186:	ee70 7a27 	vadd.f32	s15, s0, s15
   e718a:	eef7 6a00 	vmov.f32	s13, #112	; 0x3f800000  1.0
   e718e:	eef4 7ae6 	vcmpe.f32	s15, s13
   e7192:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e7196:	dd08      	ble.n	e71aa <__ieee754_expf+0xfe>
   e7198:	ee30 0a26 	vadd.f32	s0, s0, s13
   e719c:	4770      	bx	lr
   e719e:	4b2a      	ldr	r3, [pc, #168]	; (e7248 <__ieee754_expf+0x19c>)
   e71a0:	429a      	cmp	r2, r3
   e71a2:	d992      	bls.n	e70ca <__ieee754_expf+0x1e>
   e71a4:	ed9f 0a26 	vldr	s0, [pc, #152]	; e7240 <__ieee754_expf+0x194>
   e71a8:	4770      	bx	lr
   e71aa:	2300      	movs	r3, #0
   e71ac:	e7a3      	b.n	e70f6 <__ieee754_expf+0x4a>
   e71ae:	ed9f 0a25 	vldr	s0, [pc, #148]	; e7244 <__ieee754_expf+0x198>
   e71b2:	ee20 0a00 	vmul.f32	s0, s0, s0
   e71b6:	4770      	bx	lr
   e71b8:	ee60 7a06 	vmul.f32	s15, s0, s12
   e71bc:	ee76 6a66 	vsub.f32	s13, s12, s13
   e71c0:	eeb7 6a00 	vmov.f32	s12, #112	; 0x3f800000  1.0
   e71c4:	ee87 7aa6 	vdiv.f32	s14, s15, s13
   e71c8:	ee37 0a40 	vsub.f32	s0, s14, s0
   e71cc:	ee36 0a40 	vsub.f32	s0, s12, s0
   e71d0:	4770      	bx	lr
   e71d2:	4b1e      	ldr	r3, [pc, #120]	; (e724c <__ieee754_expf+0x1a0>)
   e71d4:	ed9f 6a1e 	vldr	s12, [pc, #120]	; e7250 <__ieee754_expf+0x1a4>
   e71d8:	eddf 6a1e 	vldr	s13, [pc, #120]	; e7254 <__ieee754_expf+0x1a8>
   e71dc:	ed9f 7a1e 	vldr	s14, [pc, #120]	; e7258 <__ieee754_expf+0x1ac>
   e71e0:	eb03 0381 	add.w	r3, r3, r1, lsl #2
   e71e4:	edd3 7a00 	vldr	s15, [r3]
   e71e8:	eee0 7a06 	vfma.f32	s15, s0, s12
   e71ec:	eef0 4a40 	vmov.f32	s9, s0
   e71f0:	eefd 7ae7 	vcvt.s32.f32	s15, s15
   e71f4:	ee17 3a90 	vmov	r3, s15
   e71f8:	eef8 7ae7 	vcvt.f32.s32	s15, s15
   e71fc:	eee7 4ae6 	vfms.f32	s9, s15, s13
   e7200:	ee27 7a87 	vmul.f32	s14, s15, s14
   e7204:	e775      	b.n	e70f2 <__ieee754_expf+0x46>
   e7206:	ee10 2a10 	vmov	r2, s0
   e720a:	eb02 53c3 	add.w	r3, r2, r3, lsl #23
   e720e:	ee00 3a10 	vmov	s0, r3
   e7212:	4770      	bx	lr
   e7214:	42b17217 	.word	0x42b17217
   e7218:	3eb17218 	.word	0x3eb17218
   e721c:	3f851591 	.word	0x3f851591
   e7220:	000ed088 	.word	0x000ed088
   e7224:	000ed080 	.word	0x000ed080
   e7228:	3331bb4c 	.word	0x3331bb4c
   e722c:	b5ddea0e 	.word	0xb5ddea0e
   e7230:	388ab355 	.word	0x388ab355
   e7234:	bb360b61 	.word	0xbb360b61
   e7238:	3e2aaaab 	.word	0x3e2aaaab
   e723c:	0d800000 	.word	0x0d800000
   e7240:	00000000 	.word	0x00000000
   e7244:	7149f2ca 	.word	0x7149f2ca
   e7248:	42cff1b5 	.word	0x42cff1b5
   e724c:	000ed078 	.word	0x000ed078
   e7250:	3fb8aa3b 	.word	0x3fb8aa3b
   e7254:	3f317180 	.word	0x3f317180
   e7258:	3717f7d1 	.word	0x3717f7d1

000e725c <__ieee754_logf>:
   e725c:	b430      	push	{r4, r5}
   e725e:	b082      	sub	sp, #8
   e7260:	ed8d 0a01 	vstr	s0, [sp, #4]
   e7264:	9b01      	ldr	r3, [sp, #4]
   e7266:	f023 4200 	bic.w	r2, r3, #2147483648	; 0x80000000
   e726a:	b372      	cbz	r2, e72ca <__ieee754_logf+0x6e>
   e726c:	2b00      	cmp	r3, #0
   e726e:	db40      	blt.n	e72f2 <__ieee754_logf+0x96>
   e7270:	f1b3 4fff 	cmp.w	r3, #2139095040	; 0x7f800000
   e7274:	da48      	bge.n	e7308 <__ieee754_logf+0xac>
   e7276:	f5b3 0f00 	cmp.w	r3, #8388608	; 0x800000
   e727a:	db2f      	blt.n	e72dc <__ieee754_logf+0x80>
   e727c:	2200      	movs	r2, #0
   e727e:	496e      	ldr	r1, [pc, #440]	; (e7438 <__ieee754_logf+0x1dc>)
   e7280:	f3c3 0516 	ubfx	r5, r3, #0, #23
   e7284:	4429      	add	r1, r5
   e7286:	f401 0100 	and.w	r1, r1, #8388608	; 0x800000
   e728a:	15db      	asrs	r3, r3, #23
   e728c:	3b7f      	subs	r3, #127	; 0x7f
   e728e:	f081 547e 	eor.w	r4, r1, #1065353216	; 0x3f800000
   e7292:	4413      	add	r3, r2
   e7294:	f105 000f 	add.w	r0, r5, #15
   e7298:	ea44 0205 	orr.w	r2, r4, r5
   e729c:	ee00 2a10 	vmov	s0, r2
   e72a0:	f3c0 0216 	ubfx	r2, r0, #0, #23
   e72a4:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   e72a8:	2a0f      	cmp	r2, #15
   e72aa:	eb03 53d1 	add.w	r3, r3, r1, lsr #23
   e72ae:	ee70 7a67 	vsub.f32	s15, s0, s15
   e72b2:	dc30      	bgt.n	e7316 <__ieee754_logf+0xba>
   e72b4:	eef5 7a40 	vcmp.f32	s15, #0.0
   e72b8:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e72bc:	d16c      	bne.n	e7398 <__ieee754_logf+0x13c>
   e72be:	2b00      	cmp	r3, #0
   e72c0:	f040 8096 	bne.w	e73f0 <__ieee754_logf+0x194>
   e72c4:	ed9f 0a5d 	vldr	s0, [pc, #372]	; e743c <__ieee754_logf+0x1e0>
   e72c8:	e005      	b.n	e72d6 <__ieee754_logf+0x7a>
   e72ca:	ed9f 7a5d 	vldr	s14, [pc, #372]	; e7440 <__ieee754_logf+0x1e4>
   e72ce:	eddf 7a5b 	vldr	s15, [pc, #364]	; e743c <__ieee754_logf+0x1e0>
   e72d2:	ee87 0a27 	vdiv.f32	s0, s14, s15
   e72d6:	b002      	add	sp, #8
   e72d8:	bc30      	pop	{r4, r5}
   e72da:	4770      	bx	lr
   e72dc:	eddf 7a59 	vldr	s15, [pc, #356]	; e7444 <__ieee754_logf+0x1e8>
   e72e0:	ed9d 7a01 	vldr	s14, [sp, #4]
   e72e4:	ee67 7a27 	vmul.f32	s15, s14, s15
   e72e8:	f06f 0218 	mvn.w	r2, #24
   e72ec:	ee17 3a90 	vmov	r3, s15
   e72f0:	e7c5      	b.n	e727e <__ieee754_logf+0x22>
   e72f2:	eddd 7a01 	vldr	s15, [sp, #4]
   e72f6:	ee37 7ae7 	vsub.f32	s14, s15, s15
   e72fa:	eddf 7a50 	vldr	s15, [pc, #320]	; e743c <__ieee754_logf+0x1e0>
   e72fe:	ee87 0a27 	vdiv.f32	s0, s14, s15
   e7302:	b002      	add	sp, #8
   e7304:	bc30      	pop	{r4, r5}
   e7306:	4770      	bx	lr
   e7308:	eddd 7a01 	vldr	s15, [sp, #4]
   e730c:	ee37 0aa7 	vadd.f32	s0, s15, s15
   e7310:	b002      	add	sp, #8
   e7312:	bc30      	pop	{r4, r5}
   e7314:	4770      	bx	lr
   e7316:	eef0 6a00 	vmov.f32	s13, #0	; 0x40000000  2.0
   e731a:	ee77 6aa6 	vadd.f32	s13, s15, s13
   e731e:	ed9f 2a4a 	vldr	s4, [pc, #296]	; e7448 <__ieee754_logf+0x1ec>
   e7322:	ed9f 4a4a 	vldr	s8, [pc, #296]	; e744c <__ieee754_logf+0x1f0>
   e7326:	ed9f 5a4a 	vldr	s10, [pc, #296]	; e7450 <__ieee754_logf+0x1f4>
   e732a:	eddf 2a4a 	vldr	s5, [pc, #296]	; e7454 <__ieee754_logf+0x1f8>
   e732e:	eddf 4a4a 	vldr	s9, [pc, #296]	; e7458 <__ieee754_logf+0x1fc>
   e7332:	ed9f 7a4a 	vldr	s14, [pc, #296]	; e745c <__ieee754_logf+0x200>
   e7336:	ed9f 6a4a 	vldr	s12, [pc, #296]	; e7460 <__ieee754_logf+0x204>
   e733a:	4a4a      	ldr	r2, [pc, #296]	; (e7464 <__ieee754_logf+0x208>)
   e733c:	eec7 3aa6 	vdiv.f32	s7, s15, s13
   e7340:	f5c5 1157 	rsb	r1, r5, #3522560	; 0x35c000
   e7344:	442a      	add	r2, r5
   e7346:	f501 7122 	add.w	r1, r1, #648	; 0x288
   e734a:	430a      	orrs	r2, r1
   e734c:	2a00      	cmp	r2, #0
   e734e:	ee06 3a90 	vmov	s13, r3
   e7352:	ee63 5aa3 	vmul.f32	s11, s7, s7
   e7356:	eeb8 3ae6 	vcvt.f32.s32	s6, s13
   e735a:	ee65 6aa5 	vmul.f32	s13, s11, s11
   e735e:	eea6 4a82 	vfma.f32	s8, s13, s4
   e7362:	eee6 4aa2 	vfma.f32	s9, s13, s5
   e7366:	eea6 5a84 	vfma.f32	s10, s13, s8
   e736a:	eea6 6aa4 	vfma.f32	s12, s13, s9
   e736e:	eea6 7a85 	vfma.f32	s14, s13, s10
   e7372:	ee27 7a25 	vmul.f32	s14, s14, s11
   e7376:	eea6 7a86 	vfma.f32	s14, s13, s12
   e737a:	dd46      	ble.n	e740a <__ieee754_logf+0x1ae>
   e737c:	eeb6 0a00 	vmov.f32	s0, #96	; 0x3f000000  0.5
   e7380:	ee27 0a80 	vmul.f32	s0, s15, s0
   e7384:	ee20 0a27 	vmul.f32	s0, s0, s15
   e7388:	bb0b      	cbnz	r3, e73ce <__ieee754_logf+0x172>
   e738a:	ee37 7a00 	vadd.f32	s14, s14, s0
   e738e:	eea3 0ac7 	vfms.f32	s0, s7, s14
   e7392:	ee37 0ac0 	vsub.f32	s0, s15, s0
   e7396:	e79e      	b.n	e72d6 <__ieee754_logf+0x7a>
   e7398:	ed9f 7a33 	vldr	s14, [pc, #204]	; e7468 <__ieee754_logf+0x20c>
   e739c:	eeb6 0a00 	vmov.f32	s0, #96	; 0x3f000000  0.5
   e73a0:	eea7 0ac7 	vfms.f32	s0, s15, s14
   e73a4:	ee27 7aa7 	vmul.f32	s14, s15, s15
   e73a8:	ee20 0a07 	vmul.f32	s0, s0, s14
   e73ac:	2b00      	cmp	r3, #0
   e73ae:	d0f0      	beq.n	e7392 <__ieee754_logf+0x136>
   e73b0:	ee07 3a10 	vmov	s14, r3
   e73b4:	ed9f 6a2d 	vldr	s12, [pc, #180]	; e746c <__ieee754_logf+0x210>
   e73b8:	eddf 6a2d 	vldr	s13, [pc, #180]	; e7470 <__ieee754_logf+0x214>
   e73bc:	eeb8 7ac7 	vcvt.f32.s32	s14, s14
   e73c0:	eea7 0a46 	vfms.f32	s0, s14, s12
   e73c4:	ee30 0a67 	vsub.f32	s0, s0, s15
   e73c8:	ee97 0a26 	vfnms.f32	s0, s14, s13
   e73cc:	e783      	b.n	e72d6 <__ieee754_logf+0x7a>
   e73ce:	eddf 6a27 	vldr	s13, [pc, #156]	; e746c <__ieee754_logf+0x210>
   e73d2:	ed9f 6a27 	vldr	s12, [pc, #156]	; e7470 <__ieee754_logf+0x214>
   e73d6:	ee37 7a00 	vadd.f32	s14, s14, s0
   e73da:	ee63 6a26 	vmul.f32	s13, s6, s13
   e73de:	eee3 6a87 	vfma.f32	s13, s7, s14
   e73e2:	ee30 0a66 	vsub.f32	s0, s0, s13
   e73e6:	ee30 0a67 	vsub.f32	s0, s0, s15
   e73ea:	ee93 0a06 	vfnms.f32	s0, s6, s12
   e73ee:	e772      	b.n	e72d6 <__ieee754_logf+0x7a>
   e73f0:	ee07 3a90 	vmov	s15, r3
   e73f4:	ed9f 0a1d 	vldr	s0, [pc, #116]	; e746c <__ieee754_logf+0x210>
   e73f8:	ed9f 7a1d 	vldr	s14, [pc, #116]	; e7470 <__ieee754_logf+0x214>
   e73fc:	eef8 7ae7 	vcvt.f32.s32	s15, s15
   e7400:	ee27 0a80 	vmul.f32	s0, s15, s0
   e7404:	eea7 0a87 	vfma.f32	s0, s15, s14
   e7408:	e765      	b.n	e72d6 <__ieee754_logf+0x7a>
   e740a:	b173      	cbz	r3, e742a <__ieee754_logf+0x1ce>
   e740c:	ed9f 0a17 	vldr	s0, [pc, #92]	; e746c <__ieee754_logf+0x210>
   e7410:	eddf 6a17 	vldr	s13, [pc, #92]	; e7470 <__ieee754_logf+0x214>
   e7414:	ee37 7ac7 	vsub.f32	s14, s15, s14
   e7418:	ee20 0a43 	vnmul.f32	s0, s0, s6
   e741c:	eea3 0a87 	vfma.f32	s0, s7, s14
   e7420:	ee30 0a67 	vsub.f32	s0, s0, s15
   e7424:	ee93 0a26 	vfnms.f32	s0, s6, s13
   e7428:	e755      	b.n	e72d6 <__ieee754_logf+0x7a>
   e742a:	ee37 7ac7 	vsub.f32	s14, s15, s14
   e742e:	eee3 7ac7 	vfms.f32	s15, s7, s14
   e7432:	eeb0 0a67 	vmov.f32	s0, s15
   e7436:	e74e      	b.n	e72d6 <__ieee754_logf+0x7a>
   e7438:	004afb20 	.word	0x004afb20
   e743c:	00000000 	.word	0x00000000
   e7440:	cc000000 	.word	0xcc000000
   e7444:	4c000000 	.word	0x4c000000
   e7448:	3e178897 	.word	0x3e178897
   e744c:	3e3a3325 	.word	0x3e3a3325
   e7450:	3e924925 	.word	0x3e924925
   e7454:	3e1cd04f 	.word	0x3e1cd04f
   e7458:	3e638e29 	.word	0x3e638e29
   e745c:	3f2aaaab 	.word	0x3f2aaaab
   e7460:	3ecccccd 	.word	0x3ecccccd
   e7464:	ffcf5c30 	.word	0xffcf5c30
   e7468:	3eaaaaab 	.word	0x3eaaaaab
   e746c:	3717f7d1 	.word	0x3717f7d1
   e7470:	3f317180 	.word	0x3f317180

000e7474 <__ieee754_rem_pio2f>:
   e7474:	b570      	push	{r4, r5, r6, lr}
   e7476:	ee10 3a10 	vmov	r3, s0
   e747a:	4a96      	ldr	r2, [pc, #600]	; (e76d4 <__ieee754_rem_pio2f+0x260>)
   e747c:	f023 4400 	bic.w	r4, r3, #2147483648	; 0x80000000
   e7480:	4294      	cmp	r4, r2
   e7482:	b086      	sub	sp, #24
   e7484:	dd5f      	ble.n	e7546 <__ieee754_rem_pio2f+0xd2>
   e7486:	4a94      	ldr	r2, [pc, #592]	; (e76d8 <__ieee754_rem_pio2f+0x264>)
   e7488:	4294      	cmp	r4, r2
   e748a:	ee10 6a10 	vmov	r6, s0
   e748e:	dc1b      	bgt.n	e74c8 <__ieee754_rem_pio2f+0x54>
   e7490:	2b00      	cmp	r3, #0
   e7492:	eddf 7a92 	vldr	s15, [pc, #584]	; e76dc <__ieee754_rem_pio2f+0x268>
   e7496:	4a92      	ldr	r2, [pc, #584]	; (e76e0 <__ieee754_rem_pio2f+0x26c>)
   e7498:	f024 040f 	bic.w	r4, r4, #15
   e749c:	f340 80d5 	ble.w	e764a <__ieee754_rem_pio2f+0x1d6>
   e74a0:	4294      	cmp	r4, r2
   e74a2:	ee70 7a67 	vsub.f32	s15, s0, s15
   e74a6:	d05e      	beq.n	e7566 <__ieee754_rem_pio2f+0xf2>
   e74a8:	ed9f 7a8e 	vldr	s14, [pc, #568]	; e76e4 <__ieee754_rem_pio2f+0x270>
   e74ac:	ee77 6ac7 	vsub.f32	s13, s15, s14
   e74b0:	2301      	movs	r3, #1
   e74b2:	ee77 7ae6 	vsub.f32	s15, s15, s13
   e74b6:	edc0 6a00 	vstr	s13, [r0]
   e74ba:	ee77 7ac7 	vsub.f32	s15, s15, s14
   e74be:	edc0 7a01 	vstr	s15, [r0, #4]
   e74c2:	4618      	mov	r0, r3
   e74c4:	b006      	add	sp, #24
   e74c6:	bd70      	pop	{r4, r5, r6, pc}
   e74c8:	4a87      	ldr	r2, [pc, #540]	; (e76e8 <__ieee754_rem_pio2f+0x274>)
   e74ca:	4294      	cmp	r4, r2
   e74cc:	4605      	mov	r5, r0
   e74ce:	dd5c      	ble.n	e758a <__ieee754_rem_pio2f+0x116>
   e74d0:	f1b4 4fff 	cmp.w	r4, #2139095040	; 0x7f800000
   e74d4:	da3f      	bge.n	e7556 <__ieee754_rem_pio2f+0xe2>
   e74d6:	15e2      	asrs	r2, r4, #23
   e74d8:	3a86      	subs	r2, #134	; 0x86
   e74da:	eba4 53c2 	sub.w	r3, r4, r2, lsl #23
   e74de:	ee07 3a10 	vmov	s14, r3
   e74e2:	eefd 6ac7 	vcvt.s32.f32	s13, s14
   e74e6:	eddf 7a81 	vldr	s15, [pc, #516]	; e76ec <__ieee754_rem_pio2f+0x278>
   e74ea:	eef8 6ae6 	vcvt.f32.s32	s13, s13
   e74ee:	ee37 7a66 	vsub.f32	s14, s14, s13
   e74f2:	edcd 6a03 	vstr	s13, [sp, #12]
   e74f6:	ee27 7a27 	vmul.f32	s14, s14, s15
   e74fa:	eefd 6ac7 	vcvt.s32.f32	s13, s14
   e74fe:	eef8 6ae6 	vcvt.f32.s32	s13, s13
   e7502:	ee37 7a66 	vsub.f32	s14, s14, s13
   e7506:	edcd 6a04 	vstr	s13, [sp, #16]
   e750a:	ee67 7a27 	vmul.f32	s15, s14, s15
   e750e:	eef5 7a40 	vcmp.f32	s15, #0.0
   e7512:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e7516:	edcd 7a05 	vstr	s15, [sp, #20]
   e751a:	f040 80b7 	bne.w	e768c <__ieee754_rem_pio2f+0x218>
   e751e:	eef5 6a40 	vcmp.f32	s13, #0.0
   e7522:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e7526:	bf0c      	ite	eq
   e7528:	2301      	moveq	r3, #1
   e752a:	2302      	movne	r3, #2
   e752c:	4970      	ldr	r1, [pc, #448]	; (e76f0 <__ieee754_rem_pio2f+0x27c>)
   e752e:	9101      	str	r1, [sp, #4]
   e7530:	2102      	movs	r1, #2
   e7532:	9100      	str	r1, [sp, #0]
   e7534:	a803      	add	r0, sp, #12
   e7536:	4629      	mov	r1, r5
   e7538:	f000 f9bc 	bl	e78b4 <__kernel_rem_pio2f>
   e753c:	2e00      	cmp	r6, #0
   e753e:	f2c0 8097 	blt.w	e7670 <__ieee754_rem_pio2f+0x1fc>
   e7542:	4603      	mov	r3, r0
   e7544:	e004      	b.n	e7550 <__ieee754_rem_pio2f+0xdc>
   e7546:	2200      	movs	r2, #0
   e7548:	ed80 0a00 	vstr	s0, [r0]
   e754c:	6042      	str	r2, [r0, #4]
   e754e:	2300      	movs	r3, #0
   e7550:	4618      	mov	r0, r3
   e7552:	b006      	add	sp, #24
   e7554:	bd70      	pop	{r4, r5, r6, pc}
   e7556:	ee70 7a40 	vsub.f32	s15, s0, s0
   e755a:	2300      	movs	r3, #0
   e755c:	edc0 7a01 	vstr	s15, [r0, #4]
   e7560:	edc0 7a00 	vstr	s15, [r0]
   e7564:	e7f4      	b.n	e7550 <__ieee754_rem_pio2f+0xdc>
   e7566:	eddf 6a63 	vldr	s13, [pc, #396]	; e76f4 <__ieee754_rem_pio2f+0x280>
   e756a:	ed9f 7a63 	vldr	s14, [pc, #396]	; e76f8 <__ieee754_rem_pio2f+0x284>
   e756e:	ee77 7ae6 	vsub.f32	s15, s15, s13
   e7572:	2301      	movs	r3, #1
   e7574:	ee77 6ac7 	vsub.f32	s13, s15, s14
   e7578:	ee77 7ae6 	vsub.f32	s15, s15, s13
   e757c:	edc0 6a00 	vstr	s13, [r0]
   e7580:	ee77 7ac7 	vsub.f32	s15, s15, s14
   e7584:	edc0 7a01 	vstr	s15, [r0, #4]
   e7588:	e7e2      	b.n	e7550 <__ieee754_rem_pio2f+0xdc>
   e758a:	f000 fd01 	bl	e7f90 <fabsf>
   e758e:	eddf 6a5b 	vldr	s13, [pc, #364]	; e76fc <__ieee754_rem_pio2f+0x288>
   e7592:	eddf 5a52 	vldr	s11, [pc, #328]	; e76dc <__ieee754_rem_pio2f+0x268>
   e7596:	ed9f 7a53 	vldr	s14, [pc, #332]	; e76e4 <__ieee754_rem_pio2f+0x270>
   e759a:	eef6 7a00 	vmov.f32	s15, #96	; 0x3f000000  0.5
   e759e:	eee0 7a26 	vfma.f32	s15, s0, s13
   e75a2:	eefd 7ae7 	vcvt.s32.f32	s15, s15
   e75a6:	ee17 3a90 	vmov	r3, s15
   e75aa:	eef8 6ae7 	vcvt.f32.s32	s13, s15
   e75ae:	2b1f      	cmp	r3, #31
   e75b0:	eeb1 6a66 	vneg.f32	s12, s13
   e75b4:	eea6 0a25 	vfma.f32	s0, s12, s11
   e75b8:	ee66 7a87 	vmul.f32	s15, s13, s14
   e75bc:	dc1d      	bgt.n	e75fa <__ieee754_rem_pio2f+0x186>
   e75be:	4950      	ldr	r1, [pc, #320]	; (e7700 <__ieee754_rem_pio2f+0x28c>)
   e75c0:	1e58      	subs	r0, r3, #1
   e75c2:	f024 02ff 	bic.w	r2, r4, #255	; 0xff
   e75c6:	f851 1020 	ldr.w	r1, [r1, r0, lsl #2]
   e75ca:	428a      	cmp	r2, r1
   e75cc:	d015      	beq.n	e75fa <__ieee754_rem_pio2f+0x186>
   e75ce:	ee30 7a67 	vsub.f32	s14, s0, s15
   e75d2:	ed85 7a00 	vstr	s14, [r5]
   e75d6:	ee30 0a47 	vsub.f32	s0, s0, s14
   e75da:	2e00      	cmp	r6, #0
   e75dc:	ee30 0a67 	vsub.f32	s0, s0, s15
   e75e0:	ed85 0a01 	vstr	s0, [r5, #4]
   e75e4:	dab4      	bge.n	e7550 <__ieee754_rem_pio2f+0xdc>
   e75e6:	eeb1 7a47 	vneg.f32	s14, s14
   e75ea:	eeb1 0a40 	vneg.f32	s0, s0
   e75ee:	ed85 7a00 	vstr	s14, [r5]
   e75f2:	ed85 0a01 	vstr	s0, [r5, #4]
   e75f6:	425b      	negs	r3, r3
   e75f8:	e7aa      	b.n	e7550 <__ieee754_rem_pio2f+0xdc>
   e75fa:	ee30 7a67 	vsub.f32	s14, s0, s15
   e75fe:	15e4      	asrs	r4, r4, #23
   e7600:	ee17 2a10 	vmov	r2, s14
   e7604:	f3c2 52c7 	ubfx	r2, r2, #23, #8
   e7608:	1aa2      	subs	r2, r4, r2
   e760a:	2a08      	cmp	r2, #8
   e760c:	dde1      	ble.n	e75d2 <__ieee754_rem_pio2f+0x15e>
   e760e:	eddf 7a39 	vldr	s15, [pc, #228]	; e76f4 <__ieee754_rem_pio2f+0x280>
   e7612:	ed9f 7a39 	vldr	s14, [pc, #228]	; e76f8 <__ieee754_rem_pio2f+0x284>
   e7616:	eef0 5a40 	vmov.f32	s11, s0
   e761a:	eee6 5a27 	vfma.f32	s11, s12, s15
   e761e:	ee30 0a65 	vsub.f32	s0, s0, s11
   e7622:	eea6 0a27 	vfma.f32	s0, s12, s15
   e7626:	eef0 7a40 	vmov.f32	s15, s0
   e762a:	eed6 7a87 	vfnms.f32	s15, s13, s14
   e762e:	ee35 7ae7 	vsub.f32	s14, s11, s15
   e7632:	ee17 2a10 	vmov	r2, s14
   e7636:	f3c2 52c7 	ubfx	r2, r2, #23, #8
   e763a:	1aa4      	subs	r4, r4, r2
   e763c:	2c19      	cmp	r4, #25
   e763e:	dc3a      	bgt.n	e76b6 <__ieee754_rem_pio2f+0x242>
   e7640:	ed85 7a00 	vstr	s14, [r5]
   e7644:	eeb0 0a65 	vmov.f32	s0, s11
   e7648:	e7c5      	b.n	e75d6 <__ieee754_rem_pio2f+0x162>
   e764a:	4294      	cmp	r4, r2
   e764c:	ee70 7a27 	vadd.f32	s15, s0, s15
   e7650:	d01e      	beq.n	e7690 <__ieee754_rem_pio2f+0x21c>
   e7652:	ed9f 7a24 	vldr	s14, [pc, #144]	; e76e4 <__ieee754_rem_pio2f+0x270>
   e7656:	ee77 6a87 	vadd.f32	s13, s15, s14
   e765a:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
   e765e:	ee77 7ae6 	vsub.f32	s15, s15, s13
   e7662:	edc0 6a00 	vstr	s13, [r0]
   e7666:	ee77 7a87 	vadd.f32	s15, s15, s14
   e766a:	edc0 7a01 	vstr	s15, [r0, #4]
   e766e:	e76f      	b.n	e7550 <__ieee754_rem_pio2f+0xdc>
   e7670:	ed95 7a00 	vldr	s14, [r5]
   e7674:	edd5 7a01 	vldr	s15, [r5, #4]
   e7678:	eeb1 7a47 	vneg.f32	s14, s14
   e767c:	eef1 7a67 	vneg.f32	s15, s15
   e7680:	4243      	negs	r3, r0
   e7682:	ed85 7a00 	vstr	s14, [r5]
   e7686:	edc5 7a01 	vstr	s15, [r5, #4]
   e768a:	e761      	b.n	e7550 <__ieee754_rem_pio2f+0xdc>
   e768c:	2303      	movs	r3, #3
   e768e:	e74d      	b.n	e752c <__ieee754_rem_pio2f+0xb8>
   e7690:	eddf 6a18 	vldr	s13, [pc, #96]	; e76f4 <__ieee754_rem_pio2f+0x280>
   e7694:	ed9f 7a18 	vldr	s14, [pc, #96]	; e76f8 <__ieee754_rem_pio2f+0x284>
   e7698:	ee77 7aa6 	vadd.f32	s15, s15, s13
   e769c:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
   e76a0:	ee77 6a87 	vadd.f32	s13, s15, s14
   e76a4:	ee77 7ae6 	vsub.f32	s15, s15, s13
   e76a8:	edc0 6a00 	vstr	s13, [r0]
   e76ac:	ee77 7a87 	vadd.f32	s15, s15, s14
   e76b0:	edc0 7a01 	vstr	s15, [r0, #4]
   e76b4:	e74c      	b.n	e7550 <__ieee754_rem_pio2f+0xdc>
   e76b6:	ed9f 7a13 	vldr	s14, [pc, #76]	; e7704 <__ieee754_rem_pio2f+0x290>
   e76ba:	ed9f 5a13 	vldr	s10, [pc, #76]	; e7708 <__ieee754_rem_pio2f+0x294>
   e76be:	eeb0 0a65 	vmov.f32	s0, s11
   e76c2:	eea6 0a07 	vfma.f32	s0, s12, s14
   e76c6:	ee75 7ac0 	vsub.f32	s15, s11, s0
   e76ca:	eee6 7a07 	vfma.f32	s15, s12, s14
   e76ce:	eed6 7a85 	vfnms.f32	s15, s13, s10
   e76d2:	e77c      	b.n	e75ce <__ieee754_rem_pio2f+0x15a>
   e76d4:	3f490fd8 	.word	0x3f490fd8
   e76d8:	4016cbe3 	.word	0x4016cbe3
   e76dc:	3fc90f80 	.word	0x3fc90f80
   e76e0:	3fc90fd0 	.word	0x3fc90fd0
   e76e4:	37354443 	.word	0x37354443
   e76e8:	43490f80 	.word	0x43490f80
   e76ec:	43800000 	.word	0x43800000
   e76f0:	000ed110 	.word	0x000ed110
   e76f4:	37354400 	.word	0x37354400
   e76f8:	2e85a308 	.word	0x2e85a308
   e76fc:	3f22f984 	.word	0x3f22f984
   e7700:	000ed090 	.word	0x000ed090
   e7704:	2e85a300 	.word	0x2e85a300
   e7708:	248d3132 	.word	0x248d3132

000e770c <__ieee754_sqrtf>:
   e770c:	ee10 3a10 	vmov	r3, s0
   e7710:	f023 4200 	bic.w	r2, r3, #2147483648	; 0x80000000
   e7714:	f1b2 4fff 	cmp.w	r2, #2139095040	; 0x7f800000
   e7718:	b470      	push	{r4, r5, r6}
   e771a:	d230      	bcs.n	e777e <__ieee754_sqrtf+0x72>
   e771c:	b36a      	cbz	r2, e777a <__ieee754_sqrtf+0x6e>
   e771e:	2b00      	cmp	r3, #0
   e7720:	db3d      	blt.n	e779e <__ieee754_sqrtf+0x92>
   e7722:	f5b2 0f00 	cmp.w	r2, #8388608	; 0x800000
   e7726:	ea4f 50e3 	mov.w	r0, r3, asr #23
   e772a:	d32c      	bcc.n	e7786 <__ieee754_sqrtf+0x7a>
   e772c:	f1a0 027f 	sub.w	r2, r0, #127	; 0x7f
   e7730:	f3c3 0316 	ubfx	r3, r3, #0, #23
   e7734:	07d1      	lsls	r1, r2, #31
   e7736:	f443 0300 	orr.w	r3, r3, #8388608	; 0x800000
   e773a:	bf48      	it	mi
   e773c:	005b      	lslmi	r3, r3, #1
   e773e:	2400      	movs	r4, #0
   e7740:	1056      	asrs	r6, r2, #1
   e7742:	005b      	lsls	r3, r3, #1
   e7744:	4625      	mov	r5, r4
   e7746:	2119      	movs	r1, #25
   e7748:	f04f 7280 	mov.w	r2, #16777216	; 0x1000000
   e774c:	18a8      	adds	r0, r5, r2
   e774e:	4298      	cmp	r0, r3
   e7750:	dc02      	bgt.n	e7758 <__ieee754_sqrtf+0x4c>
   e7752:	1a1b      	subs	r3, r3, r0
   e7754:	1885      	adds	r5, r0, r2
   e7756:	4414      	add	r4, r2
   e7758:	3901      	subs	r1, #1
   e775a:	ea4f 0343 	mov.w	r3, r3, lsl #1
   e775e:	ea4f 0252 	mov.w	r2, r2, lsr #1
   e7762:	d1f3      	bne.n	e774c <__ieee754_sqrtf+0x40>
   e7764:	b113      	cbz	r3, e776c <__ieee754_sqrtf+0x60>
   e7766:	f004 0301 	and.w	r3, r4, #1
   e776a:	441c      	add	r4, r3
   e776c:	1064      	asrs	r4, r4, #1
   e776e:	f104 547c 	add.w	r4, r4, #1056964608	; 0x3f000000
   e7772:	eb04 53c6 	add.w	r3, r4, r6, lsl #23
   e7776:	ee00 3a10 	vmov	s0, r3
   e777a:	bc70      	pop	{r4, r5, r6}
   e777c:	4770      	bx	lr
   e777e:	eea0 0a00 	vfma.f32	s0, s0, s0
   e7782:	bc70      	pop	{r4, r5, r6}
   e7784:	4770      	bx	lr
   e7786:	f413 0200 	ands.w	r2, r3, #8388608	; 0x800000
   e778a:	d001      	beq.n	e7790 <__ieee754_sqrtf+0x84>
   e778c:	e00c      	b.n	e77a8 <__ieee754_sqrtf+0x9c>
   e778e:	460a      	mov	r2, r1
   e7790:	005b      	lsls	r3, r3, #1
   e7792:	021c      	lsls	r4, r3, #8
   e7794:	f102 0101 	add.w	r1, r2, #1
   e7798:	d5f9      	bpl.n	e778e <__ieee754_sqrtf+0x82>
   e779a:	1a80      	subs	r0, r0, r2
   e779c:	e7c6      	b.n	e772c <__ieee754_sqrtf+0x20>
   e779e:	ee70 7a40 	vsub.f32	s15, s0, s0
   e77a2:	ee87 0aa7 	vdiv.f32	s0, s15, s15
   e77a6:	e7e8      	b.n	e777a <__ieee754_sqrtf+0x6e>
   e77a8:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
   e77ac:	e7f5      	b.n	e779a <__ieee754_sqrtf+0x8e>
   e77ae:	bf00      	nop

000e77b0 <__kernel_cosf>:
   e77b0:	ee10 3a10 	vmov	r3, s0
   e77b4:	f023 4300 	bic.w	r3, r3, #2147483648	; 0x80000000
   e77b8:	f1b3 5f48 	cmp.w	r3, #838860800	; 0x32000000
   e77bc:	da2c      	bge.n	e7818 <__kernel_cosf+0x68>
   e77be:	eefd 7ac0 	vcvt.s32.f32	s15, s0
   e77c2:	ee17 3a90 	vmov	r3, s15
   e77c6:	2b00      	cmp	r3, #0
   e77c8:	d060      	beq.n	e788c <__kernel_cosf+0xdc>
   e77ca:	ee20 7a00 	vmul.f32	s14, s0, s0
   e77ce:	eddf 4a31 	vldr	s9, [pc, #196]	; e7894 <__kernel_cosf+0xe4>
   e77d2:	ed9f 5a31 	vldr	s10, [pc, #196]	; e7898 <__kernel_cosf+0xe8>
   e77d6:	eddf 5a31 	vldr	s11, [pc, #196]	; e789c <__kernel_cosf+0xec>
   e77da:	ed9f 6a31 	vldr	s12, [pc, #196]	; e78a0 <__kernel_cosf+0xf0>
   e77de:	eddf 7a31 	vldr	s15, [pc, #196]	; e78a4 <__kernel_cosf+0xf4>
   e77e2:	eddf 6a31 	vldr	s13, [pc, #196]	; e78a8 <__kernel_cosf+0xf8>
   e77e6:	eea7 5a24 	vfma.f32	s10, s14, s9
   e77ea:	eee7 5a05 	vfma.f32	s11, s14, s10
   e77ee:	eea7 6a25 	vfma.f32	s12, s14, s11
   e77f2:	eee7 7a06 	vfma.f32	s15, s14, s12
   e77f6:	eee7 6a27 	vfma.f32	s13, s14, s15
   e77fa:	ee66 6a87 	vmul.f32	s13, s13, s14
   e77fe:	ee60 0ac0 	vnmul.f32	s1, s1, s0
   e7802:	eeb6 6a00 	vmov.f32	s12, #96	; 0x3f000000  0.5
   e7806:	eee7 0a26 	vfma.f32	s1, s14, s13
   e780a:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   e780e:	eed7 0a06 	vfnms.f32	s1, s14, s12
   e7812:	ee37 0ae0 	vsub.f32	s0, s15, s1
   e7816:	4770      	bx	lr
   e7818:	ee20 7a00 	vmul.f32	s14, s0, s0
   e781c:	eddf 4a1d 	vldr	s9, [pc, #116]	; e7894 <__kernel_cosf+0xe4>
   e7820:	ed9f 5a1d 	vldr	s10, [pc, #116]	; e7898 <__kernel_cosf+0xe8>
   e7824:	eddf 5a1d 	vldr	s11, [pc, #116]	; e789c <__kernel_cosf+0xec>
   e7828:	ed9f 6a1d 	vldr	s12, [pc, #116]	; e78a0 <__kernel_cosf+0xf0>
   e782c:	eddf 7a1d 	vldr	s15, [pc, #116]	; e78a4 <__kernel_cosf+0xf4>
   e7830:	eddf 6a1d 	vldr	s13, [pc, #116]	; e78a8 <__kernel_cosf+0xf8>
   e7834:	4a1d      	ldr	r2, [pc, #116]	; (e78ac <__kernel_cosf+0xfc>)
   e7836:	eea7 5a24 	vfma.f32	s10, s14, s9
   e783a:	4293      	cmp	r3, r2
   e783c:	eee7 5a05 	vfma.f32	s11, s14, s10
   e7840:	eea7 6a25 	vfma.f32	s12, s14, s11
   e7844:	eee7 7a06 	vfma.f32	s15, s14, s12
   e7848:	eee7 6a27 	vfma.f32	s13, s14, s15
   e784c:	ee66 6a87 	vmul.f32	s13, s13, s14
   e7850:	ddd5      	ble.n	e77fe <__kernel_cosf+0x4e>
   e7852:	4a17      	ldr	r2, [pc, #92]	; (e78b0 <__kernel_cosf+0x100>)
   e7854:	4293      	cmp	r3, r2
   e7856:	dc14      	bgt.n	e7882 <__kernel_cosf+0xd2>
   e7858:	f103 437f 	add.w	r3, r3, #4278190080	; 0xff000000
   e785c:	ee07 3a90 	vmov	s15, r3
   e7860:	eeb7 6a00 	vmov.f32	s12, #112	; 0x3f800000  1.0
   e7864:	ee36 6a67 	vsub.f32	s12, s12, s15
   e7868:	ee60 0ac0 	vnmul.f32	s1, s1, s0
   e786c:	eef6 5a00 	vmov.f32	s11, #96	; 0x3f000000  0.5
   e7870:	eee7 0a26 	vfma.f32	s1, s14, s13
   e7874:	eed7 7a25 	vfnms.f32	s15, s14, s11
   e7878:	ee77 7ae0 	vsub.f32	s15, s15, s1
   e787c:	ee36 0a67 	vsub.f32	s0, s12, s15
   e7880:	4770      	bx	lr
   e7882:	eeb6 6a07 	vmov.f32	s12, #103	; 0x3f380000  0.7187500
   e7886:	eef5 7a02 	vmov.f32	s15, #82	; 0x3e900000  0.2812500
   e788a:	e7ed      	b.n	e7868 <__kernel_cosf+0xb8>
   e788c:	eeb7 0a00 	vmov.f32	s0, #112	; 0x3f800000  1.0
   e7890:	4770      	bx	lr
   e7892:	bf00      	nop
   e7894:	ad47d74e 	.word	0xad47d74e
   e7898:	310f74f6 	.word	0x310f74f6
   e789c:	b493f27c 	.word	0xb493f27c
   e78a0:	37d00d01 	.word	0x37d00d01
   e78a4:	bab60b61 	.word	0xbab60b61
   e78a8:	3d2aaaab 	.word	0x3d2aaaab
   e78ac:	3e999999 	.word	0x3e999999
   e78b0:	3f480000 	.word	0x3f480000

000e78b4 <__kernel_rem_pio2f>:
   e78b4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
   e78b8:	ed2d 8b04 	vpush	{d8-d9}
   e78bc:	b0d7      	sub	sp, #348	; 0x15c
   e78be:	1e5f      	subs	r7, r3, #1
   e78c0:	4cda      	ldr	r4, [pc, #872]	; (e7c2c <__kernel_rem_pio2f+0x378>)
   e78c2:	9d64      	ldr	r5, [sp, #400]	; 0x190
   e78c4:	9301      	str	r3, [sp, #4]
   e78c6:	1ed3      	subs	r3, r2, #3
   e78c8:	bf48      	it	mi
   e78ca:	1d13      	addmi	r3, r2, #4
   e78cc:	f854 6025 	ldr.w	r6, [r4, r5, lsl #2]
   e78d0:	10db      	asrs	r3, r3, #3
   e78d2:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
   e78d6:	f103 0a01 	add.w	sl, r3, #1
   e78da:	468b      	mov	fp, r1
   e78dc:	19f1      	adds	r1, r6, r7
   e78de:	9302      	str	r3, [sp, #8]
   e78e0:	4681      	mov	r9, r0
   e78e2:	eba2 0aca 	sub.w	sl, r2, sl, lsl #3
   e78e6:	eba3 0307 	sub.w	r3, r3, r7
   e78ea:	d414      	bmi.n	e7916 <__kernel_rem_pio2f+0x62>
   e78ec:	4419      	add	r1, r3
   e78ee:	9865      	ldr	r0, [sp, #404]	; 0x194
   e78f0:	3101      	adds	r1, #1
   e78f2:	aa1a      	add	r2, sp, #104	; 0x68
   e78f4:	2b00      	cmp	r3, #0
   e78f6:	bfaa      	itet	ge
   e78f8:	f850 4023 	ldrge.w	r4, [r0, r3, lsl #2]
   e78fc:	eddf 7ad0 	vldrlt	s15, [pc, #832]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7900:	ee07 4a90 	vmovge	s15, r4
   e7904:	f103 0301 	add.w	r3, r3, #1
   e7908:	bfa8      	it	ge
   e790a:	eef8 7ae7 	vcvtge.f32.s32	s15, s15
   e790e:	428b      	cmp	r3, r1
   e7910:	ece2 7a01 	vstmia	r2!, {s15}
   e7914:	d1ee      	bne.n	e78f4 <__kernel_rem_pio2f+0x40>
   e7916:	2e00      	cmp	r6, #0
   e7918:	f2c0 82d6 	blt.w	e7ec8 <__kernel_rem_pio2f+0x614>
   e791c:	9b01      	ldr	r3, [sp, #4]
   e791e:	ad42      	add	r5, sp, #264	; 0x108
   e7920:	009c      	lsls	r4, r3, #2
   e7922:	f106 0e01 	add.w	lr, r6, #1
   e7926:	ab1a      	add	r3, sp, #104	; 0x68
   e7928:	eb05 0e8e 	add.w	lr, r5, lr, lsl #2
   e792c:	1918      	adds	r0, r3, r4
   e792e:	eb09 0104 	add.w	r1, r9, r4
   e7932:	2f00      	cmp	r7, #0
   e7934:	f2c0 81c0 	blt.w	e7cb8 <__kernel_rem_pio2f+0x404>
   e7938:	eddf 7ac1 	vldr	s15, [pc, #772]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e793c:	464b      	mov	r3, r9
   e793e:	4602      	mov	r2, r0
   e7940:	ecf3 6a01 	vldmia	r3!, {s13}
   e7944:	ed32 7a01 	vldmdb	r2!, {s14}
   e7948:	428b      	cmp	r3, r1
   e794a:	eee6 7a87 	vfma.f32	s15, s13, s14
   e794e:	d1f7      	bne.n	e7940 <__kernel_rem_pio2f+0x8c>
   e7950:	ece5 7a01 	vstmia	r5!, {s15}
   e7954:	4575      	cmp	r5, lr
   e7956:	f100 0004 	add.w	r0, r0, #4
   e795a:	d1ea      	bne.n	e7932 <__kernel_rem_pio2f+0x7e>
   e795c:	f106 4380 	add.w	r3, r6, #1073741824	; 0x40000000
   e7960:	3b02      	subs	r3, #2
   e7962:	009b      	lsls	r3, r3, #2
   e7964:	aa06      	add	r2, sp, #24
   e7966:	f103 0804 	add.w	r8, r3, #4
   e796a:	eddf 8ab1 	vldr	s17, [pc, #708]	; e7c30 <__kernel_rem_pio2f+0x37c>
   e796e:	ed9f 8ab1 	vldr	s16, [pc, #708]	; e7c34 <__kernel_rem_pio2f+0x380>
   e7972:	f8cd b010 	str.w	fp, [sp, #16]
   e7976:	4413      	add	r3, r2
   e7978:	444c      	add	r4, r9
   e797a:	4490      	add	r8, r2
   e797c:	9303      	str	r3, [sp, #12]
   e797e:	4635      	mov	r5, r6
   e7980:	ab56      	add	r3, sp, #344	; 0x158
   e7982:	eb03 0385 	add.w	r3, r3, r5, lsl #2
   e7986:	2d00      	cmp	r5, #0
   e7988:	ed13 0a14 	vldr	s0, [r3, #-80]	; 0xffffffb0
   e798c:	dd19      	ble.n	e79c2 <__kernel_rem_pio2f+0x10e>
   e798e:	a942      	add	r1, sp, #264	; 0x108
   e7990:	eb01 0385 	add.w	r3, r1, r5, lsl #2
   e7994:	aa05      	add	r2, sp, #20
   e7996:	ee60 7a28 	vmul.f32	s15, s0, s17
   e799a:	eeb0 7a40 	vmov.f32	s14, s0
   e799e:	eefd 7ae7 	vcvt.s32.f32	s15, s15
   e79a2:	ed73 6a01 	vldmdb	r3!, {s13}
   e79a6:	eef8 7ae7 	vcvt.f32.s32	s15, s15
   e79aa:	428b      	cmp	r3, r1
   e79ac:	eea7 7ac8 	vfms.f32	s14, s15, s16
   e79b0:	ee37 0aa6 	vadd.f32	s0, s15, s13
   e79b4:	eebd 7ac7 	vcvt.s32.f32	s14, s14
   e79b8:	ee17 0a10 	vmov	r0, s14
   e79bc:	f842 0f04 	str.w	r0, [r2, #4]!
   e79c0:	d1e9      	bne.n	e7996 <__kernel_rem_pio2f+0xe2>
   e79c2:	4650      	mov	r0, sl
   e79c4:	f000 faf6 	bl	e7fb4 <scalbnf>
   e79c8:	eeb0 9a40 	vmov.f32	s18, s0
   e79cc:	eeb4 0a00 	vmov.f32	s0, #64	; 0x3e000000  0.125
   e79d0:	ee29 0a00 	vmul.f32	s0, s18, s0
   e79d4:	f7fe fee4 	bl	e67a0 <floorf>
   e79d8:	eef2 7a00 	vmov.f32	s15, #32	; 0x41000000  8.0
   e79dc:	eea0 9a67 	vfms.f32	s18, s0, s15
   e79e0:	f1ba 0f00 	cmp.w	sl, #0
   e79e4:	eefd 7ac9 	vcvt.s32.f32	s15, s18
   e79e8:	ee17 ba90 	vmov	fp, s15
   e79ec:	eef8 7ae7 	vcvt.f32.s32	s15, s15
   e79f0:	ee39 9a67 	vsub.f32	s18, s18, s15
   e79f4:	f340 8145 	ble.w	e7c82 <__kernel_rem_pio2f+0x3ce>
   e79f8:	f105 3eff 	add.w	lr, r5, #4294967295	; 0xffffffff
   e79fc:	ab06      	add	r3, sp, #24
   e79fe:	f1ca 0208 	rsb	r2, sl, #8
   e7a02:	f853 302e 	ldr.w	r3, [r3, lr, lsl #2]
   e7a06:	fa43 f002 	asr.w	r0, r3, r2
   e7a0a:	fa00 f202 	lsl.w	r2, r0, r2
   e7a0e:	a906      	add	r1, sp, #24
   e7a10:	1a9b      	subs	r3, r3, r2
   e7a12:	f1ca 0207 	rsb	r2, sl, #7
   e7a16:	f841 302e 	str.w	r3, [r1, lr, lsl #2]
   e7a1a:	4483      	add	fp, r0
   e7a1c:	fa43 f102 	asr.w	r1, r3, r2
   e7a20:	2900      	cmp	r1, #0
   e7a22:	dd37      	ble.n	e7a94 <__kernel_rem_pio2f+0x1e0>
   e7a24:	2d00      	cmp	r5, #0
   e7a26:	f10b 0b01 	add.w	fp, fp, #1
   e7a2a:	f340 8228 	ble.w	e7e7e <__kernel_rem_pio2f+0x5ca>
   e7a2e:	2200      	movs	r2, #0
   e7a30:	4610      	mov	r0, r2
   e7a32:	f10d 0e14 	add.w	lr, sp, #20
   e7a36:	468c      	mov	ip, r1
   e7a38:	e008      	b.n	e7a4c <__kernel_rem_pio2f+0x198>
   e7a3a:	f5c3 7180 	rsb	r1, r3, #256	; 0x100
   e7a3e:	b113      	cbz	r3, e7a46 <__kernel_rem_pio2f+0x192>
   e7a40:	f8ce 1000 	str.w	r1, [lr]
   e7a44:	2001      	movs	r0, #1
   e7a46:	3201      	adds	r2, #1
   e7a48:	4295      	cmp	r5, r2
   e7a4a:	dd0c      	ble.n	e7a66 <__kernel_rem_pio2f+0x1b2>
   e7a4c:	f85e 3f04 	ldr.w	r3, [lr, #4]!
   e7a50:	2800      	cmp	r0, #0
   e7a52:	d0f2      	beq.n	e7a3a <__kernel_rem_pio2f+0x186>
   e7a54:	3201      	adds	r2, #1
   e7a56:	f1c3 03ff 	rsb	r3, r3, #255	; 0xff
   e7a5a:	4295      	cmp	r5, r2
   e7a5c:	f8ce 3000 	str.w	r3, [lr]
   e7a60:	f04f 0001 	mov.w	r0, #1
   e7a64:	dcf2      	bgt.n	e7a4c <__kernel_rem_pio2f+0x198>
   e7a66:	4661      	mov	r1, ip
   e7a68:	f1ba 0f00 	cmp.w	sl, #0
   e7a6c:	dd10      	ble.n	e7a90 <__kernel_rem_pio2f+0x1dc>
   e7a6e:	f1ba 0f01 	cmp.w	sl, #1
   e7a72:	f000 810d 	beq.w	e7c90 <__kernel_rem_pio2f+0x3dc>
   e7a76:	f1ba 0f02 	cmp.w	sl, #2
   e7a7a:	d109      	bne.n	e7a90 <__kernel_rem_pio2f+0x1dc>
   e7a7c:	1e6a      	subs	r2, r5, #1
   e7a7e:	ab06      	add	r3, sp, #24
   e7a80:	f10d 0e18 	add.w	lr, sp, #24
   e7a84:	f853 3022 	ldr.w	r3, [r3, r2, lsl #2]
   e7a88:	f003 033f 	and.w	r3, r3, #63	; 0x3f
   e7a8c:	f84e 3022 	str.w	r3, [lr, r2, lsl #2]
   e7a90:	2902      	cmp	r1, #2
   e7a92:	d05c      	beq.n	e7b4e <__kernel_rem_pio2f+0x29a>
   e7a94:	eeb5 9a40 	vcmp.f32	s18, #0.0
   e7a98:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e7a9c:	d169      	bne.n	e7b72 <__kernel_rem_pio2f+0x2be>
   e7a9e:	f105 3eff 	add.w	lr, r5, #4294967295	; 0xffffffff
   e7aa2:	4576      	cmp	r6, lr
   e7aa4:	dc0f      	bgt.n	e7ac6 <__kernel_rem_pio2f+0x212>
   e7aa6:	f105 4280 	add.w	r2, r5, #1073741824	; 0x40000000
   e7aaa:	3a01      	subs	r2, #1
   e7aac:	ab06      	add	r3, sp, #24
   e7aae:	eb03 0282 	add.w	r2, r3, r2, lsl #2
   e7ab2:	2000      	movs	r0, #0
   e7ab4:	f852 3904 	ldr.w	r3, [r2], #-4
   e7ab8:	4542      	cmp	r2, r8
   e7aba:	ea40 0003 	orr.w	r0, r0, r3
   e7abe:	d1f9      	bne.n	e7ab4 <__kernel_rem_pio2f+0x200>
   e7ac0:	2800      	cmp	r0, #0
   e7ac2:	f040 8110 	bne.w	e7ce6 <__kernel_rem_pio2f+0x432>
   e7ac6:	1e73      	subs	r3, r6, #1
   e7ac8:	aa06      	add	r2, sp, #24
   e7aca:	f852 3023 	ldr.w	r3, [r2, r3, lsl #2]
   e7ace:	2b00      	cmp	r3, #0
   e7ad0:	f040 81d2 	bne.w	e7e78 <__kernel_rem_pio2f+0x5c4>
   e7ad4:	9b03      	ldr	r3, [sp, #12]
   e7ad6:	f04f 0e01 	mov.w	lr, #1
   e7ada:	f853 2904 	ldr.w	r2, [r3], #-4
   e7ade:	f10e 0e01 	add.w	lr, lr, #1
   e7ae2:	2a00      	cmp	r2, #0
   e7ae4:	d0f9      	beq.n	e7ada <__kernel_rem_pio2f+0x226>
   e7ae6:	44ae      	add	lr, r5
   e7ae8:	1c6b      	adds	r3, r5, #1
   e7aea:	4573      	cmp	r3, lr
   e7aec:	dc2d      	bgt.n	e7b4a <__kernel_rem_pio2f+0x296>
   e7aee:	9a02      	ldr	r2, [sp, #8]
   e7af0:	1898      	adds	r0, r3, r2
   e7af2:	9a01      	ldr	r2, [sp, #4]
   e7af4:	f100 4080 	add.w	r0, r0, #1073741824	; 0x40000000
   e7af8:	1951      	adds	r1, r2, r5
   e7afa:	eb0e 0c02 	add.w	ip, lr, r2
   e7afe:	9a65      	ldr	r2, [sp, #404]	; 0x194
   e7b00:	3801      	subs	r0, #1
   e7b02:	eb02 0080 	add.w	r0, r2, r0, lsl #2
   e7b06:	aa1a      	add	r2, sp, #104	; 0x68
   e7b08:	eb02 0181 	add.w	r1, r2, r1, lsl #2
   e7b0c:	eb02 0c8c 	add.w	ip, r2, ip, lsl #2
   e7b10:	aa42      	add	r2, sp, #264	; 0x108
   e7b12:	eb02 0583 	add.w	r5, r2, r3, lsl #2
   e7b16:	f850 3f04 	ldr.w	r3, [r0, #4]!
   e7b1a:	ee07 3a90 	vmov	s15, r3
   e7b1e:	eef8 7ae7 	vcvt.f32.s32	s15, s15
   e7b22:	2f00      	cmp	r7, #0
   e7b24:	ece1 7a01 	vstmia	r1!, {s15}
   e7b28:	eddf 7a45 	vldr	s15, [pc, #276]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7b2c:	db09      	blt.n	e7b42 <__kernel_rem_pio2f+0x28e>
   e7b2e:	464b      	mov	r3, r9
   e7b30:	460a      	mov	r2, r1
   e7b32:	ecf3 6a01 	vldmia	r3!, {s13}
   e7b36:	ed32 7a01 	vldmdb	r2!, {s14}
   e7b3a:	42a3      	cmp	r3, r4
   e7b3c:	eee6 7a87 	vfma.f32	s15, s13, s14
   e7b40:	d1f7      	bne.n	e7b32 <__kernel_rem_pio2f+0x27e>
   e7b42:	4561      	cmp	r1, ip
   e7b44:	ece5 7a01 	vstmia	r5!, {s15}
   e7b48:	d1e5      	bne.n	e7b16 <__kernel_rem_pio2f+0x262>
   e7b4a:	4675      	mov	r5, lr
   e7b4c:	e718      	b.n	e7980 <__kernel_rem_pio2f+0xcc>
   e7b4e:	eeb7 0a00 	vmov.f32	s0, #112	; 0x3f800000  1.0
   e7b52:	ee30 9a49 	vsub.f32	s18, s0, s18
   e7b56:	2800      	cmp	r0, #0
   e7b58:	d09c      	beq.n	e7a94 <__kernel_rem_pio2f+0x1e0>
   e7b5a:	4650      	mov	r0, sl
   e7b5c:	9105      	str	r1, [sp, #20]
   e7b5e:	f000 fa29 	bl	e7fb4 <scalbnf>
   e7b62:	ee39 9a40 	vsub.f32	s18, s18, s0
   e7b66:	9905      	ldr	r1, [sp, #20]
   e7b68:	eeb5 9a40 	vcmp.f32	s18, #0.0
   e7b6c:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e7b70:	d095      	beq.n	e7a9e <__kernel_rem_pio2f+0x1ea>
   e7b72:	eeb0 0a49 	vmov.f32	s0, s18
   e7b76:	f1ca 0000 	rsb	r0, sl, #0
   e7b7a:	ee09 ba90 	vmov	s19, fp
   e7b7e:	4688      	mov	r8, r1
   e7b80:	f8dd b010 	ldr.w	fp, [sp, #16]
   e7b84:	f000 fa16 	bl	e7fb4 <scalbnf>
   e7b88:	ed9f 7a2a 	vldr	s14, [pc, #168]	; e7c34 <__kernel_rem_pio2f+0x380>
   e7b8c:	eeb4 0ac7 	vcmpe.f32	s0, s14
   e7b90:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e7b94:	f2c0 817e 	blt.w	e7e94 <__kernel_rem_pio2f+0x5e0>
   e7b98:	eddf 7a25 	vldr	s15, [pc, #148]	; e7c30 <__kernel_rem_pio2f+0x37c>
   e7b9c:	ee60 7a27 	vmul.f32	s15, s0, s15
   e7ba0:	a906      	add	r1, sp, #24
   e7ba2:	eefd 7ae7 	vcvt.s32.f32	s15, s15
   e7ba6:	1c6b      	adds	r3, r5, #1
   e7ba8:	eef8 7ae7 	vcvt.f32.s32	s15, s15
   e7bac:	f10a 0a08 	add.w	sl, sl, #8
   e7bb0:	eea7 0ac7 	vfms.f32	s0, s15, s14
   e7bb4:	eefd 7ae7 	vcvt.s32.f32	s15, s15
   e7bb8:	eebd 0ac0 	vcvt.s32.f32	s0, s0
   e7bbc:	ee10 2a10 	vmov	r2, s0
   e7bc0:	f841 2025 	str.w	r2, [r1, r5, lsl #2]
   e7bc4:	ee17 2a90 	vmov	r2, s15
   e7bc8:	f841 2023 	str.w	r2, [r1, r3, lsl #2]
   e7bcc:	4650      	mov	r0, sl
   e7bce:	eeb7 0a00 	vmov.f32	s0, #112	; 0x3f800000  1.0
   e7bd2:	9301      	str	r3, [sp, #4]
   e7bd4:	f000 f9ee 	bl	e7fb4 <scalbnf>
   e7bd8:	9b01      	ldr	r3, [sp, #4]
   e7bda:	2b00      	cmp	r3, #0
   e7bdc:	f2c0 8166 	blt.w	e7eac <__kernel_rem_pio2f+0x5f8>
   e7be0:	009f      	lsls	r7, r3, #2
   e7be2:	ac42      	add	r4, sp, #264	; 0x108
   e7be4:	aa06      	add	r2, sp, #24
   e7be6:	1d38      	adds	r0, r7, #4
   e7be8:	eb04 0e07 	add.w	lr, r4, r7
   e7bec:	ed9f 7a10 	vldr	s14, [pc, #64]	; e7c30 <__kernel_rem_pio2f+0x37c>
   e7bf0:	4410      	add	r0, r2
   e7bf2:	f10e 0204 	add.w	r2, lr, #4
   e7bf6:	ed70 7a01 	vldmdb	r0!, {s15}
   e7bfa:	eef8 7ae7 	vcvt.f32.s32	s15, s15
   e7bfe:	ee67 7a80 	vmul.f32	s15, s15, s0
   e7c02:	ee20 0a07 	vmul.f32	s0, s0, s14
   e7c06:	ed62 7a01 	vstmdb	r2!, {s15}
   e7c0a:	42a2      	cmp	r2, r4
   e7c0c:	d1f3      	bne.n	e7bf6 <__kernel_rem_pio2f+0x342>
   e7c0e:	f50d 7c82 	add.w	ip, sp, #260	; 0x104
   e7c12:	2500      	movs	r5, #0
   e7c14:	2e00      	cmp	r6, #0
   e7c16:	f2c0 8121 	blt.w	e7e5c <__kernel_rem_pio2f+0x5a8>
   e7c1a:	4807      	ldr	r0, [pc, #28]	; (e7c38 <__kernel_rem_pio2f+0x384>)
   e7c1c:	ed9f 7a07 	vldr	s14, [pc, #28]	; e7c3c <__kernel_rem_pio2f+0x388>
   e7c20:	eddf 7a07 	vldr	s15, [pc, #28]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7c24:	4671      	mov	r1, lr
   e7c26:	2200      	movs	r2, #0
   e7c28:	e011      	b.n	e7c4e <__kernel_rem_pio2f+0x39a>
   e7c2a:	bf00      	nop
   e7c2c:	000ed428 	.word	0x000ed428
   e7c30:	3b800000 	.word	0x3b800000
   e7c34:	43800000 	.word	0x43800000
   e7c38:	000ed434 	.word	0x000ed434
   e7c3c:	3fc90000 	.word	0x3fc90000
   e7c40:	00000000 	.word	0x00000000
   e7c44:	4295      	cmp	r5, r2
   e7c46:	db09      	blt.n	e7c5c <__kernel_rem_pio2f+0x3a8>
   e7c48:	3004      	adds	r0, #4
   e7c4a:	ed90 7a00 	vldr	s14, [r0]
   e7c4e:	ecf1 6a01 	vldmia	r1!, {s13}
   e7c52:	3201      	adds	r2, #1
   e7c54:	4296      	cmp	r6, r2
   e7c56:	eee6 7a87 	vfma.f32	s15, s13, s14
   e7c5a:	daf3      	bge.n	e7c44 <__kernel_rem_pio2f+0x390>
   e7c5c:	f1ae 0e04 	sub.w	lr, lr, #4
   e7c60:	aa56      	add	r2, sp, #344	; 0x158
   e7c62:	eb02 0285 	add.w	r2, r2, r5, lsl #2
   e7c66:	45f4      	cmp	ip, lr
   e7c68:	ed42 7a28 	vstr	s15, [r2, #-160]	; 0xffffff60
   e7c6c:	f105 0501 	add.w	r5, r5, #1
   e7c70:	d1d0      	bne.n	e7c14 <__kernel_rem_pio2f+0x360>
   e7c72:	9a64      	ldr	r2, [sp, #400]	; 0x190
   e7c74:	2a03      	cmp	r2, #3
   e7c76:	f200 80ae 	bhi.w	e7dd6 <__kernel_rem_pio2f+0x522>
   e7c7a:	e8df f002 	tbb	[pc, r2]
   e7c7e:	b5dc      	.short	0xb5dc
   e7c80:	50b5      	.short	0x50b5
   e7c82:	d110      	bne.n	e7ca6 <__kernel_rem_pio2f+0x3f2>
   e7c84:	1e6b      	subs	r3, r5, #1
   e7c86:	aa06      	add	r2, sp, #24
   e7c88:	f852 1023 	ldr.w	r1, [r2, r3, lsl #2]
   e7c8c:	1209      	asrs	r1, r1, #8
   e7c8e:	e6c7      	b.n	e7a20 <__kernel_rem_pio2f+0x16c>
   e7c90:	1e6a      	subs	r2, r5, #1
   e7c92:	ab06      	add	r3, sp, #24
   e7c94:	f10d 0e18 	add.w	lr, sp, #24
   e7c98:	f853 3022 	ldr.w	r3, [r3, r2, lsl #2]
   e7c9c:	f003 037f 	and.w	r3, r3, #127	; 0x7f
   e7ca0:	f84e 3022 	str.w	r3, [lr, r2, lsl #2]
   e7ca4:	e6f4      	b.n	e7a90 <__kernel_rem_pio2f+0x1dc>
   e7ca6:	eef6 7a00 	vmov.f32	s15, #96	; 0x3f000000  0.5
   e7caa:	eeb4 9ae7 	vcmpe.f32	s18, s15
   e7cae:	eef1 fa10 	vmrs	APSR_nzcv, fpscr
   e7cb2:	da0b      	bge.n	e7ccc <__kernel_rem_pio2f+0x418>
   e7cb4:	2100      	movs	r1, #0
   e7cb6:	e6ed      	b.n	e7a94 <__kernel_rem_pio2f+0x1e0>
   e7cb8:	ed5f 7a1f 	vldr	s15, [pc, #-124]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7cbc:	ece5 7a01 	vstmia	r5!, {s15}
   e7cc0:	4575      	cmp	r5, lr
   e7cc2:	f100 0004 	add.w	r0, r0, #4
   e7cc6:	f47f ae34 	bne.w	e7932 <__kernel_rem_pio2f+0x7e>
   e7cca:	e647      	b.n	e795c <__kernel_rem_pio2f+0xa8>
   e7ccc:	2d00      	cmp	r5, #0
   e7cce:	f10b 0b01 	add.w	fp, fp, #1
   e7cd2:	bfc8      	it	gt
   e7cd4:	2102      	movgt	r1, #2
   e7cd6:	f73f aeaa 	bgt.w	e7a2e <__kernel_rem_pio2f+0x17a>
   e7cda:	eef7 7a00 	vmov.f32	s15, #112	; 0x3f800000  1.0
   e7cde:	ee37 9ac9 	vsub.f32	s18, s15, s18
   e7ce2:	2102      	movs	r1, #2
   e7ce4:	e6d6      	b.n	e7a94 <__kernel_rem_pio2f+0x1e0>
   e7ce6:	aa06      	add	r2, sp, #24
   e7ce8:	ee09 ba90 	vmov	s19, fp
   e7cec:	f852 202e 	ldr.w	r2, [r2, lr, lsl #2]
   e7cf0:	f8dd b010 	ldr.w	fp, [sp, #16]
   e7cf4:	4673      	mov	r3, lr
   e7cf6:	4688      	mov	r8, r1
   e7cf8:	f1aa 0a08 	sub.w	sl, sl, #8
   e7cfc:	2a00      	cmp	r2, #0
   e7cfe:	f47f af65 	bne.w	e7bcc <__kernel_rem_pio2f+0x318>
   e7d02:	f10e 4280 	add.w	r2, lr, #1073741824	; 0x40000000
   e7d06:	3a01      	subs	r2, #1
   e7d08:	a906      	add	r1, sp, #24
   e7d0a:	eb01 0282 	add.w	r2, r1, r2, lsl #2
   e7d0e:	f852 1904 	ldr.w	r1, [r2], #-4
   e7d12:	3b01      	subs	r3, #1
   e7d14:	f1aa 0a08 	sub.w	sl, sl, #8
   e7d18:	2900      	cmp	r1, #0
   e7d1a:	d0f8      	beq.n	e7d0e <__kernel_rem_pio2f+0x45a>
   e7d1c:	e756      	b.n	e7bcc <__kernel_rem_pio2f+0x318>
   e7d1e:	2b00      	cmp	r3, #0
   e7d20:	f340 80c1 	ble.w	e7ea6 <__kernel_rem_pio2f+0x5f2>
   e7d24:	f103 4280 	add.w	r2, r3, #1073741824	; 0x40000000
   e7d28:	3a01      	subs	r2, #1
   e7d2a:	0090      	lsls	r0, r2, #2
   e7d2c:	a956      	add	r1, sp, #344	; 0x158
   e7d2e:	19cd      	adds	r5, r1, r7
   e7d30:	1d04      	adds	r4, r0, #4
   e7d32:	a92e      	add	r1, sp, #184	; 0xb8
   e7d34:	3008      	adds	r0, #8
   e7d36:	ed15 7a28 	vldr	s14, [r5, #-160]	; 0xffffff60
   e7d3a:	440c      	add	r4, r1
   e7d3c:	4408      	add	r0, r1
   e7d3e:	ad2f      	add	r5, sp, #188	; 0xbc
   e7d40:	ed74 7a01 	vldmdb	r4!, {s15}
   e7d44:	ee77 6a87 	vadd.f32	s13, s15, s14
   e7d48:	ee77 7ae6 	vsub.f32	s15, s15, s13
   e7d4c:	ee77 7a87 	vadd.f32	s15, s15, s14
   e7d50:	eeb0 7a66 	vmov.f32	s14, s13
   e7d54:	ed60 7a01 	vstmdb	r0!, {s15}
   e7d58:	42a8      	cmp	r0, r5
   e7d5a:	edc4 6a00 	vstr	s13, [r4]
   e7d5e:	d1ef      	bne.n	e7d40 <__kernel_rem_pio2f+0x48c>
   e7d60:	2b01      	cmp	r3, #1
   e7d62:	f340 80a0 	ble.w	e7ea6 <__kernel_rem_pio2f+0x5f2>
   e7d66:	0092      	lsls	r2, r2, #2
   e7d68:	ab56      	add	r3, sp, #344	; 0x158
   e7d6a:	441f      	add	r7, r3
   e7d6c:	f102 0008 	add.w	r0, r2, #8
   e7d70:	ab2e      	add	r3, sp, #184	; 0xb8
   e7d72:	4418      	add	r0, r3
   e7d74:	3204      	adds	r2, #4
   e7d76:	ed17 7a28 	vldr	s14, [r7, #-160]	; 0xffffff60
   e7d7a:	4413      	add	r3, r2
   e7d7c:	ac30      	add	r4, sp, #192	; 0xc0
   e7d7e:	4602      	mov	r2, r0
   e7d80:	ed73 7a01 	vldmdb	r3!, {s15}
   e7d84:	ee77 6a27 	vadd.f32	s13, s14, s15
   e7d88:	ee77 7ae6 	vsub.f32	s15, s15, s13
   e7d8c:	ee77 7a87 	vadd.f32	s15, s15, s14
   e7d90:	eeb0 7a66 	vmov.f32	s14, s13
   e7d94:	ed62 7a01 	vstmdb	r2!, {s15}
   e7d98:	4294      	cmp	r4, r2
   e7d9a:	edc3 6a00 	vstr	s13, [r3]
   e7d9e:	d1ef      	bne.n	e7d80 <__kernel_rem_pio2f+0x4cc>
   e7da0:	ed5f 7a59 	vldr	s15, [pc, #-356]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7da4:	ed30 7a01 	vldmdb	r0!, {s14}
   e7da8:	4284      	cmp	r4, r0
   e7daa:	ee77 7a87 	vadd.f32	s15, s15, s14
   e7dae:	d1f9      	bne.n	e7da4 <__kernel_rem_pio2f+0x4f0>
   e7db0:	4643      	mov	r3, r8
   e7db2:	2b00      	cmp	r3, #0
   e7db4:	d065      	beq.n	e7e82 <__kernel_rem_pio2f+0x5ce>
   e7db6:	eddd 6a2e 	vldr	s13, [sp, #184]	; 0xb8
   e7dba:	ed9d 7a2f 	vldr	s14, [sp, #188]	; 0xbc
   e7dbe:	eef1 7a67 	vneg.f32	s15, s15
   e7dc2:	eef1 6a66 	vneg.f32	s13, s13
   e7dc6:	eeb1 7a47 	vneg.f32	s14, s14
   e7dca:	edcb 7a02 	vstr	s15, [fp, #8]
   e7dce:	edcb 6a00 	vstr	s13, [fp]
   e7dd2:	ed8b 7a01 	vstr	s14, [fp, #4]
   e7dd6:	ee19 3a90 	vmov	r3, s19
   e7dda:	f003 0007 	and.w	r0, r3, #7
   e7dde:	b057      	add	sp, #348	; 0x15c
   e7de0:	ecbd 8b04 	vpop	{d8-d9}
   e7de4:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
   e7de8:	1d3a      	adds	r2, r7, #4
   e7dea:	a82e      	add	r0, sp, #184	; 0xb8
   e7dec:	ed5f 7a6c 	vldr	s15, [pc, #-432]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7df0:	4402      	add	r2, r0
   e7df2:	ed32 7a01 	vldmdb	r2!, {s14}
   e7df6:	4282      	cmp	r2, r0
   e7df8:	ee77 7a87 	vadd.f32	s15, s15, s14
   e7dfc:	d1f9      	bne.n	e7df2 <__kernel_rem_pio2f+0x53e>
   e7dfe:	4642      	mov	r2, r8
   e7e00:	b37a      	cbz	r2, e7e62 <__kernel_rem_pio2f+0x5ae>
   e7e02:	eddd 6a2e 	vldr	s13, [sp, #184]	; 0xb8
   e7e06:	eeb1 7a67 	vneg.f32	s14, s15
   e7e0a:	2b00      	cmp	r3, #0
   e7e0c:	ee76 7ae7 	vsub.f32	s15, s13, s15
   e7e10:	ed8b 7a00 	vstr	s14, [fp]
   e7e14:	dd0a      	ble.n	e7e2c <__kernel_rem_pio2f+0x578>
   e7e16:	a82f      	add	r0, sp, #188	; 0xbc
   e7e18:	2201      	movs	r2, #1
   e7e1a:	ecb0 7a01 	vldmia	r0!, {s14}
   e7e1e:	3201      	adds	r2, #1
   e7e20:	4293      	cmp	r3, r2
   e7e22:	ee77 7a87 	vadd.f32	s15, s15, s14
   e7e26:	daf8      	bge.n	e7e1a <__kernel_rem_pio2f+0x566>
   e7e28:	4643      	mov	r3, r8
   e7e2a:	b10b      	cbz	r3, e7e30 <__kernel_rem_pio2f+0x57c>
   e7e2c:	eef1 7a67 	vneg.f32	s15, s15
   e7e30:	edcb 7a01 	vstr	s15, [fp, #4]
   e7e34:	e7cf      	b.n	e7dd6 <__kernel_rem_pio2f+0x522>
   e7e36:	aa56      	add	r2, sp, #344	; 0x158
   e7e38:	443a      	add	r2, r7
   e7e3a:	ed5f 7a7f 	vldr	s15, [pc, #-508]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7e3e:	3a9c      	subs	r2, #156	; 0x9c
   e7e40:	ed32 7a01 	vldmdb	r2!, {s14}
   e7e44:	3b01      	subs	r3, #1
   e7e46:	1c59      	adds	r1, r3, #1
   e7e48:	ee77 7a87 	vadd.f32	s15, s15, s14
   e7e4c:	d1f8      	bne.n	e7e40 <__kernel_rem_pio2f+0x58c>
   e7e4e:	4643      	mov	r3, r8
   e7e50:	b10b      	cbz	r3, e7e56 <__kernel_rem_pio2f+0x5a2>
   e7e52:	eef1 7a67 	vneg.f32	s15, s15
   e7e56:	edcb 7a00 	vstr	s15, [fp]
   e7e5a:	e7bc      	b.n	e7dd6 <__kernel_rem_pio2f+0x522>
   e7e5c:	ed5f 7a88 	vldr	s15, [pc, #-544]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7e60:	e6fc      	b.n	e7c5c <__kernel_rem_pio2f+0x3a8>
   e7e62:	ed9d 7a2e 	vldr	s14, [sp, #184]	; 0xb8
   e7e66:	edcb 7a00 	vstr	s15, [fp]
   e7e6a:	2b00      	cmp	r3, #0
   e7e6c:	ee77 7a67 	vsub.f32	s15, s14, s15
   e7e70:	dcd1      	bgt.n	e7e16 <__kernel_rem_pio2f+0x562>
   e7e72:	edcb 7a01 	vstr	s15, [fp, #4]
   e7e76:	e7ae      	b.n	e7dd6 <__kernel_rem_pio2f+0x522>
   e7e78:	f04f 0e01 	mov.w	lr, #1
   e7e7c:	e633      	b.n	e7ae6 <__kernel_rem_pio2f+0x232>
   e7e7e:	2000      	movs	r0, #0
   e7e80:	e5f2      	b.n	e7a68 <__kernel_rem_pio2f+0x1b4>
   e7e82:	9a2e      	ldr	r2, [sp, #184]	; 0xb8
   e7e84:	9b2f      	ldr	r3, [sp, #188]	; 0xbc
   e7e86:	edcb 7a02 	vstr	s15, [fp, #8]
   e7e8a:	f8cb 2000 	str.w	r2, [fp]
   e7e8e:	f8cb 3004 	str.w	r3, [fp, #4]
   e7e92:	e7a0      	b.n	e7dd6 <__kernel_rem_pio2f+0x522>
   e7e94:	eebd 0ac0 	vcvt.s32.f32	s0, s0
   e7e98:	a906      	add	r1, sp, #24
   e7e9a:	ee10 2a10 	vmov	r2, s0
   e7e9e:	462b      	mov	r3, r5
   e7ea0:	f841 2025 	str.w	r2, [r1, r5, lsl #2]
   e7ea4:	e692      	b.n	e7bcc <__kernel_rem_pio2f+0x318>
   e7ea6:	ed5f 7a9a 	vldr	s15, [pc, #-616]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7eaa:	e781      	b.n	e7db0 <__kernel_rem_pio2f+0x4fc>
   e7eac:	9a64      	ldr	r2, [sp, #400]	; 0x190
   e7eae:	2a03      	cmp	r2, #3
   e7eb0:	d891      	bhi.n	e7dd6 <__kernel_rem_pio2f+0x522>
   e7eb2:	a101      	add	r1, pc, #4	; (adr r1, e7eb8 <__kernel_rem_pio2f+0x604>)
   e7eb4:	f851 f022 	ldr.w	pc, [r1, r2, lsl #2]
   e7eb8:	000e7ed5 	.word	0x000e7ed5
   e7ebc:	000e7ecf 	.word	0x000e7ecf
   e7ec0:	000e7ecf 	.word	0x000e7ecf
   e7ec4:	000e7ea7 	.word	0x000e7ea7
   e7ec8:	9b01      	ldr	r3, [sp, #4]
   e7eca:	009c      	lsls	r4, r3, #2
   e7ecc:	e546      	b.n	e795c <__kernel_rem_pio2f+0xa8>
   e7ece:	ed5f 7aa4 	vldr	s15, [pc, #-656]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7ed2:	e794      	b.n	e7dfe <__kernel_rem_pio2f+0x54a>
   e7ed4:	ed5f 7aa6 	vldr	s15, [pc, #-664]	; e7c40 <__kernel_rem_pio2f+0x38c>
   e7ed8:	e7b9      	b.n	e7e4e <__kernel_rem_pio2f+0x59a>
   e7eda:	bf00      	nop

000e7edc <__kernel_sinf>:
   e7edc:	ee10 3a10 	vmov	r3, s0
   e7ee0:	f023 4300 	bic.w	r3, r3, #2147483648	; 0x80000000
   e7ee4:	f1b3 5f48 	cmp.w	r3, #838860800	; 0x32000000
   e7ee8:	da04      	bge.n	e7ef4 <__kernel_sinf+0x18>
   e7eea:	eefd 7ac0 	vcvt.s32.f32	s15, s0
   e7eee:	ee17 3a90 	vmov	r3, s15
   e7ef2:	b323      	cbz	r3, e7f3e <__kernel_sinf+0x62>
   e7ef4:	ee60 7a00 	vmul.f32	s15, s0, s0
   e7ef8:	ed9f 5a15 	vldr	s10, [pc, #84]	; e7f50 <__kernel_sinf+0x74>
   e7efc:	eddf 5a15 	vldr	s11, [pc, #84]	; e7f54 <__kernel_sinf+0x78>
   e7f00:	ed9f 6a15 	vldr	s12, [pc, #84]	; e7f58 <__kernel_sinf+0x7c>
   e7f04:	eddf 6a15 	vldr	s13, [pc, #84]	; e7f5c <__kernel_sinf+0x80>
   e7f08:	ed9f 7a15 	vldr	s14, [pc, #84]	; e7f60 <__kernel_sinf+0x84>
   e7f0c:	eee7 5a85 	vfma.f32	s11, s15, s10
   e7f10:	ee20 5a27 	vmul.f32	s10, s0, s15
   e7f14:	eea7 6aa5 	vfma.f32	s12, s15, s11
   e7f18:	eee7 6a86 	vfma.f32	s13, s15, s12
   e7f1c:	eea7 7aa6 	vfma.f32	s14, s15, s13
   e7f20:	b170      	cbz	r0, e7f40 <__kernel_sinf+0x64>
   e7f22:	ee27 7a45 	vnmul.f32	s14, s14, s10
   e7f26:	eef6 6a00 	vmov.f32	s13, #96	; 0x3f000000  0.5
   e7f2a:	eea0 7aa6 	vfma.f32	s14, s1, s13
   e7f2e:	eddf 6a0d 	vldr	s13, [pc, #52]	; e7f64 <__kernel_sinf+0x88>
   e7f32:	eed7 0a87 	vfnms.f32	s1, s15, s14
   e7f36:	eee5 0a26 	vfma.f32	s1, s10, s13
   e7f3a:	ee30 0a60 	vsub.f32	s0, s0, s1
   e7f3e:	4770      	bx	lr
   e7f40:	eddf 6a09 	vldr	s13, [pc, #36]	; e7f68 <__kernel_sinf+0x8c>
   e7f44:	eee7 6a87 	vfma.f32	s13, s15, s14
   e7f48:	eea5 0a26 	vfma.f32	s0, s10, s13
   e7f4c:	4770      	bx	lr
   e7f4e:	bf00      	nop
   e7f50:	2f2ec9d3 	.word	0x2f2ec9d3
   e7f54:	b2d72f34 	.word	0xb2d72f34
   e7f58:	3638ef1b 	.word	0x3638ef1b
   e7f5c:	b9500d01 	.word	0xb9500d01
   e7f60:	3c088889 	.word	0x3c088889
   e7f64:	3e2aaaab 	.word	0x3e2aaaab
   e7f68:	be2aaaab 	.word	0xbe2aaaab

000e7f6c <finite>:
   e7f6c:	ee10 3a90 	vmov	r3, s1
   e7f70:	f043 4000 	orr.w	r0, r3, #2147483648	; 0x80000000
   e7f74:	f500 1080 	add.w	r0, r0, #1048576	; 0x100000
   e7f78:	0fc0      	lsrs	r0, r0, #31
   e7f7a:	4770      	bx	lr

000e7f7c <matherr>:
   e7f7c:	2000      	movs	r0, #0
   e7f7e:	4770      	bx	lr

000e7f80 <nan>:
   e7f80:	ed9f 0b01 	vldr	d0, [pc, #4]	; e7f88 <nan+0x8>
   e7f84:	4770      	bx	lr
   e7f86:	bf00      	nop
   e7f88:	00000000 	.word	0x00000000
   e7f8c:	7ff80000 	.word	0x7ff80000

000e7f90 <fabsf>:
   e7f90:	ee10 3a10 	vmov	r3, s0
   e7f94:	f023 4300 	bic.w	r3, r3, #2147483648	; 0x80000000
   e7f98:	ee00 3a10 	vmov	s0, r3
   e7f9c:	4770      	bx	lr
   e7f9e:	bf00      	nop

000e7fa0 <finitef>:
   e7fa0:	ee10 3a10 	vmov	r3, s0
   e7fa4:	f023 4000 	bic.w	r0, r3, #2147483648	; 0x80000000
   e7fa8:	f1b0 4fff 	cmp.w	r0, #2139095040	; 0x7f800000
   e7fac:	bfac      	ite	ge
   e7fae:	2000      	movge	r0, #0
   e7fb0:	2001      	movlt	r0, #1
   e7fb2:	4770      	bx	lr

000e7fb4 <scalbnf>:
   e7fb4:	b508      	push	{r3, lr}
   e7fb6:	ee10 3a10 	vmov	r3, s0
   e7fba:	f033 4200 	bics.w	r2, r3, #2147483648	; 0x80000000
   e7fbe:	ed2d 8b02 	vpush	{d8}
   e7fc2:	d011      	beq.n	e7fe8 <scalbnf+0x34>
   e7fc4:	f1b2 4fff 	cmp.w	r2, #2139095040	; 0x7f800000
   e7fc8:	d211      	bcs.n	e7fee <scalbnf+0x3a>
   e7fca:	f5b2 0f00 	cmp.w	r2, #8388608	; 0x800000
   e7fce:	d313      	bcc.n	e7ff8 <scalbnf+0x44>
   e7fd0:	0dd2      	lsrs	r2, r2, #23
   e7fd2:	4402      	add	r2, r0
   e7fd4:	2afe      	cmp	r2, #254	; 0xfe
   e7fd6:	dc2e      	bgt.n	e8036 <scalbnf+0x82>
   e7fd8:	2a00      	cmp	r2, #0
   e7fda:	dd1a      	ble.n	e8012 <scalbnf+0x5e>
   e7fdc:	f023 43ff 	bic.w	r3, r3, #2139095040	; 0x7f800000
   e7fe0:	ea43 53c2 	orr.w	r3, r3, r2, lsl #23
   e7fe4:	ee00 3a10 	vmov	s0, r3
   e7fe8:	ecbd 8b02 	vpop	{d8}
   e7fec:	bd08      	pop	{r3, pc}
   e7fee:	ecbd 8b02 	vpop	{d8}
   e7ff2:	ee30 0a00 	vadd.f32	s0, s0, s0
   e7ff6:	bd08      	pop	{r3, pc}
   e7ff8:	4b1d      	ldr	r3, [pc, #116]	; (e8070 <scalbnf+0xbc>)
   e7ffa:	eddf 7a1e 	vldr	s15, [pc, #120]	; e8074 <scalbnf+0xc0>
   e7ffe:	4298      	cmp	r0, r3
   e8000:	ee20 0a27 	vmul.f32	s0, s0, s15
   e8004:	db22      	blt.n	e804c <scalbnf+0x98>
   e8006:	ee10 3a10 	vmov	r3, s0
   e800a:	f3c3 52c7 	ubfx	r2, r3, #23, #8
   e800e:	3a19      	subs	r2, #25
   e8010:	e7df      	b.n	e7fd2 <scalbnf+0x1e>
   e8012:	f112 0f16 	cmn.w	r2, #22
   e8016:	da1e      	bge.n	e8056 <scalbnf+0xa2>
   e8018:	f24c 3350 	movw	r3, #50000	; 0xc350
   e801c:	4298      	cmp	r0, r3
   e801e:	dc0a      	bgt.n	e8036 <scalbnf+0x82>
   e8020:	ed9f 8a15 	vldr	s16, [pc, #84]	; e8078 <scalbnf+0xc4>
   e8024:	eef0 0a40 	vmov.f32	s1, s0
   e8028:	eeb0 0a48 	vmov.f32	s0, s16
   e802c:	f000 f82a 	bl	e8084 <copysignf>
   e8030:	ee20 0a08 	vmul.f32	s0, s0, s16
   e8034:	e7d8      	b.n	e7fe8 <scalbnf+0x34>
   e8036:	ed9f 8a11 	vldr	s16, [pc, #68]	; e807c <scalbnf+0xc8>
   e803a:	eef0 0a40 	vmov.f32	s1, s0
   e803e:	eeb0 0a48 	vmov.f32	s0, s16
   e8042:	f000 f81f 	bl	e8084 <copysignf>
   e8046:	ee20 0a08 	vmul.f32	s0, s0, s16
   e804a:	e7cd      	b.n	e7fe8 <scalbnf+0x34>
   e804c:	eddf 0a0a 	vldr	s1, [pc, #40]	; e8078 <scalbnf+0xc4>
   e8050:	ee20 0a20 	vmul.f32	s0, s0, s1
   e8054:	e7c8      	b.n	e7fe8 <scalbnf+0x34>
   e8056:	3219      	adds	r2, #25
   e8058:	f023 43ff 	bic.w	r3, r3, #2139095040	; 0x7f800000
   e805c:	ea43 53c2 	orr.w	r3, r3, r2, lsl #23
   e8060:	eddf 7a07 	vldr	s15, [pc, #28]	; e8080 <scalbnf+0xcc>
   e8064:	ee00 3a10 	vmov	s0, r3
   e8068:	ee20 0a27 	vmul.f32	s0, s0, s15
   e806c:	e7bc      	b.n	e7fe8 <scalbnf+0x34>
   e806e:	bf00      	nop
   e8070:	ffff3cb0 	.word	0xffff3cb0
   e8074:	4c000000 	.word	0x4c000000
   e8078:	0da24260 	.word	0x0da24260
   e807c:	7149f2ca 	.word	0x7149f2ca
   e8080:	33000000 	.word	0x33000000

000e8084 <copysignf>:
   e8084:	ee10 3a10 	vmov	r3, s0
   e8088:	f023 4200 	bic.w	r2, r3, #2147483648	; 0x80000000
   e808c:	ee10 3a90 	vmov	r3, s1
   e8090:	f003 4300 	and.w	r3, r3, #2147483648	; 0x80000000
   e8094:	4313      	orrs	r3, r2
   e8096:	ee00 3a10 	vmov	s0, r3
   e809a:	4770      	bx	lr

000e809c <__aeabi_llsl>:
   e809c:	4091      	lsls	r1, r2
   e809e:	1c03      	adds	r3, r0, #0
   e80a0:	4090      	lsls	r0, r2
   e80a2:	469c      	mov	ip, r3
   e80a4:	3a20      	subs	r2, #32
   e80a6:	4093      	lsls	r3, r2
   e80a8:	4319      	orrs	r1, r3
   e80aa:	4252      	negs	r2, r2
   e80ac:	4663      	mov	r3, ip
   e80ae:	40d3      	lsrs	r3, r2
   e80b0:	4319      	orrs	r1, r3
   e80b2:	4770      	bx	lr

000e80b4 <__aeabi_drsub>:
   e80b4:	f081 4100 	eor.w	r1, r1, #2147483648	; 0x80000000
   e80b8:	e002      	b.n	e80c0 <__adddf3>
   e80ba:	bf00      	nop

000e80bc <__aeabi_dsub>:
   e80bc:	f083 4300 	eor.w	r3, r3, #2147483648	; 0x80000000

000e80c0 <__adddf3>:
   e80c0:	b530      	push	{r4, r5, lr}
   e80c2:	ea4f 0441 	mov.w	r4, r1, lsl #1
   e80c6:	ea4f 0543 	mov.w	r5, r3, lsl #1
   e80ca:	ea94 0f05 	teq	r4, r5
   e80ce:	bf08      	it	eq
   e80d0:	ea90 0f02 	teqeq	r0, r2
   e80d4:	bf1f      	itttt	ne
   e80d6:	ea54 0c00 	orrsne.w	ip, r4, r0
   e80da:	ea55 0c02 	orrsne.w	ip, r5, r2
   e80de:	ea7f 5c64 	mvnsne.w	ip, r4, asr #21
   e80e2:	ea7f 5c65 	mvnsne.w	ip, r5, asr #21
   e80e6:	f000 80e2 	beq.w	e82ae <__adddf3+0x1ee>
   e80ea:	ea4f 5454 	mov.w	r4, r4, lsr #21
   e80ee:	ebd4 5555 	rsbs	r5, r4, r5, lsr #21
   e80f2:	bfb8      	it	lt
   e80f4:	426d      	neglt	r5, r5
   e80f6:	dd0c      	ble.n	e8112 <__adddf3+0x52>
   e80f8:	442c      	add	r4, r5
   e80fa:	ea80 0202 	eor.w	r2, r0, r2
   e80fe:	ea81 0303 	eor.w	r3, r1, r3
   e8102:	ea82 0000 	eor.w	r0, r2, r0
   e8106:	ea83 0101 	eor.w	r1, r3, r1
   e810a:	ea80 0202 	eor.w	r2, r0, r2
   e810e:	ea81 0303 	eor.w	r3, r1, r3
   e8112:	2d36      	cmp	r5, #54	; 0x36
   e8114:	bf88      	it	hi
   e8116:	bd30      	pophi	{r4, r5, pc}
   e8118:	f011 4f00 	tst.w	r1, #2147483648	; 0x80000000
   e811c:	ea4f 3101 	mov.w	r1, r1, lsl #12
   e8120:	f44f 1c80 	mov.w	ip, #1048576	; 0x100000
   e8124:	ea4c 3111 	orr.w	r1, ip, r1, lsr #12
   e8128:	d002      	beq.n	e8130 <__adddf3+0x70>
   e812a:	4240      	negs	r0, r0
   e812c:	eb61 0141 	sbc.w	r1, r1, r1, lsl #1
   e8130:	f013 4f00 	tst.w	r3, #2147483648	; 0x80000000
   e8134:	ea4f 3303 	mov.w	r3, r3, lsl #12
   e8138:	ea4c 3313 	orr.w	r3, ip, r3, lsr #12
   e813c:	d002      	beq.n	e8144 <__adddf3+0x84>
   e813e:	4252      	negs	r2, r2
   e8140:	eb63 0343 	sbc.w	r3, r3, r3, lsl #1
   e8144:	ea94 0f05 	teq	r4, r5
   e8148:	f000 80a7 	beq.w	e829a <__adddf3+0x1da>
   e814c:	f1a4 0401 	sub.w	r4, r4, #1
   e8150:	f1d5 0e20 	rsbs	lr, r5, #32
   e8154:	db0d      	blt.n	e8172 <__adddf3+0xb2>
   e8156:	fa02 fc0e 	lsl.w	ip, r2, lr
   e815a:	fa22 f205 	lsr.w	r2, r2, r5
   e815e:	1880      	adds	r0, r0, r2
   e8160:	f141 0100 	adc.w	r1, r1, #0
   e8164:	fa03 f20e 	lsl.w	r2, r3, lr
   e8168:	1880      	adds	r0, r0, r2
   e816a:	fa43 f305 	asr.w	r3, r3, r5
   e816e:	4159      	adcs	r1, r3
   e8170:	e00e      	b.n	e8190 <__adddf3+0xd0>
   e8172:	f1a5 0520 	sub.w	r5, r5, #32
   e8176:	f10e 0e20 	add.w	lr, lr, #32
   e817a:	2a01      	cmp	r2, #1
   e817c:	fa03 fc0e 	lsl.w	ip, r3, lr
   e8180:	bf28      	it	cs
   e8182:	f04c 0c02 	orrcs.w	ip, ip, #2
   e8186:	fa43 f305 	asr.w	r3, r3, r5
   e818a:	18c0      	adds	r0, r0, r3
   e818c:	eb51 71e3 	adcs.w	r1, r1, r3, asr #31
   e8190:	f001 4500 	and.w	r5, r1, #2147483648	; 0x80000000
   e8194:	d507      	bpl.n	e81a6 <__adddf3+0xe6>
   e8196:	f04f 0e00 	mov.w	lr, #0
   e819a:	f1dc 0c00 	rsbs	ip, ip, #0
   e819e:	eb7e 0000 	sbcs.w	r0, lr, r0
   e81a2:	eb6e 0101 	sbc.w	r1, lr, r1
   e81a6:	f5b1 1f80 	cmp.w	r1, #1048576	; 0x100000
   e81aa:	d31b      	bcc.n	e81e4 <__adddf3+0x124>
   e81ac:	f5b1 1f00 	cmp.w	r1, #2097152	; 0x200000
   e81b0:	d30c      	bcc.n	e81cc <__adddf3+0x10c>
   e81b2:	0849      	lsrs	r1, r1, #1
   e81b4:	ea5f 0030 	movs.w	r0, r0, rrx
   e81b8:	ea4f 0c3c 	mov.w	ip, ip, rrx
   e81bc:	f104 0401 	add.w	r4, r4, #1
   e81c0:	ea4f 5244 	mov.w	r2, r4, lsl #21
   e81c4:	f512 0f80 	cmn.w	r2, #4194304	; 0x400000
   e81c8:	f080 809a 	bcs.w	e8300 <__adddf3+0x240>
   e81cc:	f1bc 4f00 	cmp.w	ip, #2147483648	; 0x80000000
   e81d0:	bf08      	it	eq
   e81d2:	ea5f 0c50 	movseq.w	ip, r0, lsr #1
   e81d6:	f150 0000 	adcs.w	r0, r0, #0
   e81da:	eb41 5104 	adc.w	r1, r1, r4, lsl #20
   e81de:	ea41 0105 	orr.w	r1, r1, r5
   e81e2:	bd30      	pop	{r4, r5, pc}
   e81e4:	ea5f 0c4c 	movs.w	ip, ip, lsl #1
   e81e8:	4140      	adcs	r0, r0
   e81ea:	eb41 0101 	adc.w	r1, r1, r1
   e81ee:	f411 1f80 	tst.w	r1, #1048576	; 0x100000
   e81f2:	f1a4 0401 	sub.w	r4, r4, #1
   e81f6:	d1e9      	bne.n	e81cc <__adddf3+0x10c>
   e81f8:	f091 0f00 	teq	r1, #0
   e81fc:	bf04      	itt	eq
   e81fe:	4601      	moveq	r1, r0
   e8200:	2000      	moveq	r0, #0
   e8202:	fab1 f381 	clz	r3, r1
   e8206:	bf08      	it	eq
   e8208:	3320      	addeq	r3, #32
   e820a:	f1a3 030b 	sub.w	r3, r3, #11
   e820e:	f1b3 0220 	subs.w	r2, r3, #32
   e8212:	da0c      	bge.n	e822e <__adddf3+0x16e>
   e8214:	320c      	adds	r2, #12
   e8216:	dd08      	ble.n	e822a <__adddf3+0x16a>
   e8218:	f102 0c14 	add.w	ip, r2, #20
   e821c:	f1c2 020c 	rsb	r2, r2, #12
   e8220:	fa01 f00c 	lsl.w	r0, r1, ip
   e8224:	fa21 f102 	lsr.w	r1, r1, r2
   e8228:	e00c      	b.n	e8244 <__adddf3+0x184>
   e822a:	f102 0214 	add.w	r2, r2, #20
   e822e:	bfd8      	it	le
   e8230:	f1c2 0c20 	rsble	ip, r2, #32
   e8234:	fa01 f102 	lsl.w	r1, r1, r2
   e8238:	fa20 fc0c 	lsr.w	ip, r0, ip
   e823c:	bfdc      	itt	le
   e823e:	ea41 010c 	orrle.w	r1, r1, ip
   e8242:	4090      	lslle	r0, r2
   e8244:	1ae4      	subs	r4, r4, r3
   e8246:	bfa2      	ittt	ge
   e8248:	eb01 5104 	addge.w	r1, r1, r4, lsl #20
   e824c:	4329      	orrge	r1, r5
   e824e:	bd30      	popge	{r4, r5, pc}
   e8250:	ea6f 0404 	mvn.w	r4, r4
   e8254:	3c1f      	subs	r4, #31
   e8256:	da1c      	bge.n	e8292 <__adddf3+0x1d2>
   e8258:	340c      	adds	r4, #12
   e825a:	dc0e      	bgt.n	e827a <__adddf3+0x1ba>
   e825c:	f104 0414 	add.w	r4, r4, #20
   e8260:	f1c4 0220 	rsb	r2, r4, #32
   e8264:	fa20 f004 	lsr.w	r0, r0, r4
   e8268:	fa01 f302 	lsl.w	r3, r1, r2
   e826c:	ea40 0003 	orr.w	r0, r0, r3
   e8270:	fa21 f304 	lsr.w	r3, r1, r4
   e8274:	ea45 0103 	orr.w	r1, r5, r3
   e8278:	bd30      	pop	{r4, r5, pc}
   e827a:	f1c4 040c 	rsb	r4, r4, #12
   e827e:	f1c4 0220 	rsb	r2, r4, #32
   e8282:	fa20 f002 	lsr.w	r0, r0, r2
   e8286:	fa01 f304 	lsl.w	r3, r1, r4
   e828a:	ea40 0003 	orr.w	r0, r0, r3
   e828e:	4629      	mov	r1, r5
   e8290:	bd30      	pop	{r4, r5, pc}
   e8292:	fa21 f004 	lsr.w	r0, r1, r4
   e8296:	4629      	mov	r1, r5
   e8298:	bd30      	pop	{r4, r5, pc}
   e829a:	f094 0f00 	teq	r4, #0
   e829e:	f483 1380 	eor.w	r3, r3, #1048576	; 0x100000
   e82a2:	bf06      	itte	eq
   e82a4:	f481 1180 	eoreq.w	r1, r1, #1048576	; 0x100000
   e82a8:	3401      	addeq	r4, #1
   e82aa:	3d01      	subne	r5, #1
   e82ac:	e74e      	b.n	e814c <__adddf3+0x8c>
   e82ae:	ea7f 5c64 	mvns.w	ip, r4, asr #21
   e82b2:	bf18      	it	ne
   e82b4:	ea7f 5c65 	mvnsne.w	ip, r5, asr #21
   e82b8:	d029      	beq.n	e830e <__adddf3+0x24e>
   e82ba:	ea94 0f05 	teq	r4, r5
   e82be:	bf08      	it	eq
   e82c0:	ea90 0f02 	teqeq	r0, r2
   e82c4:	d005      	beq.n	e82d2 <__adddf3+0x212>
   e82c6:	ea54 0c00 	orrs.w	ip, r4, r0
   e82ca:	bf04      	itt	eq
   e82cc:	4619      	moveq	r1, r3
   e82ce:	4610      	moveq	r0, r2
   e82d0:	bd30      	pop	{r4, r5, pc}
   e82d2:	ea91 0f03 	teq	r1, r3
   e82d6:	bf1e      	ittt	ne
   e82d8:	2100      	movne	r1, #0
   e82da:	2000      	movne	r0, #0
   e82dc:	bd30      	popne	{r4, r5, pc}
   e82de:	ea5f 5c54 	movs.w	ip, r4, lsr #21
   e82e2:	d105      	bne.n	e82f0 <__adddf3+0x230>
   e82e4:	0040      	lsls	r0, r0, #1
   e82e6:	4149      	adcs	r1, r1
   e82e8:	bf28      	it	cs
   e82ea:	f041 4100 	orrcs.w	r1, r1, #2147483648	; 0x80000000
   e82ee:	bd30      	pop	{r4, r5, pc}
   e82f0:	f514 0480 	adds.w	r4, r4, #4194304	; 0x400000
   e82f4:	bf3c      	itt	cc
   e82f6:	f501 1180 	addcc.w	r1, r1, #1048576	; 0x100000
   e82fa:	bd30      	popcc	{r4, r5, pc}
   e82fc:	f001 4500 	and.w	r5, r1, #2147483648	; 0x80000000
   e8300:	f045 41fe 	orr.w	r1, r5, #2130706432	; 0x7f000000
   e8304:	f441 0170 	orr.w	r1, r1, #15728640	; 0xf00000
   e8308:	f04f 0000 	mov.w	r0, #0
   e830c:	bd30      	pop	{r4, r5, pc}
   e830e:	ea7f 5c64 	mvns.w	ip, r4, asr #21
   e8312:	bf1a      	itte	ne
   e8314:	4619      	movne	r1, r3
   e8316:	4610      	movne	r0, r2
   e8318:	ea7f 5c65 	mvnseq.w	ip, r5, asr #21
   e831c:	bf1c      	itt	ne
   e831e:	460b      	movne	r3, r1
   e8320:	4602      	movne	r2, r0
   e8322:	ea50 3401 	orrs.w	r4, r0, r1, lsl #12
   e8326:	bf06      	itte	eq
   e8328:	ea52 3503 	orrseq.w	r5, r2, r3, lsl #12
   e832c:	ea91 0f03 	teqeq	r1, r3
   e8330:	f441 2100 	orrne.w	r1, r1, #524288	; 0x80000
   e8334:	bd30      	pop	{r4, r5, pc}
   e8336:	bf00      	nop

000e8338 <__aeabi_ui2d>:
   e8338:	f090 0f00 	teq	r0, #0
   e833c:	bf04      	itt	eq
   e833e:	2100      	moveq	r1, #0
   e8340:	4770      	bxeq	lr
   e8342:	b530      	push	{r4, r5, lr}
   e8344:	f44f 6480 	mov.w	r4, #1024	; 0x400
   e8348:	f104 0432 	add.w	r4, r4, #50	; 0x32
   e834c:	f04f 0500 	mov.w	r5, #0
   e8350:	f04f 0100 	mov.w	r1, #0
   e8354:	e750      	b.n	e81f8 <__adddf3+0x138>
   e8356:	bf00      	nop

000e8358 <__aeabi_i2d>:
   e8358:	f090 0f00 	teq	r0, #0
   e835c:	bf04      	itt	eq
   e835e:	2100      	moveq	r1, #0
   e8360:	4770      	bxeq	lr
   e8362:	b530      	push	{r4, r5, lr}
   e8364:	f44f 6480 	mov.w	r4, #1024	; 0x400
   e8368:	f104 0432 	add.w	r4, r4, #50	; 0x32
   e836c:	f010 4500 	ands.w	r5, r0, #2147483648	; 0x80000000
   e8370:	bf48      	it	mi
   e8372:	4240      	negmi	r0, r0
   e8374:	f04f 0100 	mov.w	r1, #0
   e8378:	e73e      	b.n	e81f8 <__adddf3+0x138>
   e837a:	bf00      	nop

000e837c <__aeabi_f2d>:
   e837c:	0042      	lsls	r2, r0, #1
   e837e:	ea4f 01e2 	mov.w	r1, r2, asr #3
   e8382:	ea4f 0131 	mov.w	r1, r1, rrx
   e8386:	ea4f 7002 	mov.w	r0, r2, lsl #28
   e838a:	bf1f      	itttt	ne
   e838c:	f012 437f 	andsne.w	r3, r2, #4278190080	; 0xff000000
   e8390:	f093 4f7f 	teqne	r3, #4278190080	; 0xff000000
   e8394:	f081 5160 	eorne.w	r1, r1, #939524096	; 0x38000000
   e8398:	4770      	bxne	lr
   e839a:	f092 0f00 	teq	r2, #0
   e839e:	bf14      	ite	ne
   e83a0:	f093 4f7f 	teqne	r3, #4278190080	; 0xff000000
   e83a4:	4770      	bxeq	lr
   e83a6:	b530      	push	{r4, r5, lr}
   e83a8:	f44f 7460 	mov.w	r4, #896	; 0x380
   e83ac:	f001 4500 	and.w	r5, r1, #2147483648	; 0x80000000
   e83b0:	f021 4100 	bic.w	r1, r1, #2147483648	; 0x80000000
   e83b4:	e720      	b.n	e81f8 <__adddf3+0x138>
   e83b6:	bf00      	nop

000e83b8 <__aeabi_ul2d>:
   e83b8:	ea50 0201 	orrs.w	r2, r0, r1
   e83bc:	bf08      	it	eq
   e83be:	4770      	bxeq	lr
   e83c0:	b530      	push	{r4, r5, lr}
   e83c2:	f04f 0500 	mov.w	r5, #0
   e83c6:	e00a      	b.n	e83de <__aeabi_l2d+0x16>

000e83c8 <__aeabi_l2d>:
   e83c8:	ea50 0201 	orrs.w	r2, r0, r1
   e83cc:	bf08      	it	eq
   e83ce:	4770      	bxeq	lr
   e83d0:	b530      	push	{r4, r5, lr}
   e83d2:	f011 4500 	ands.w	r5, r1, #2147483648	; 0x80000000
   e83d6:	d502      	bpl.n	e83de <__aeabi_l2d+0x16>
   e83d8:	4240      	negs	r0, r0
   e83da:	eb61 0141 	sbc.w	r1, r1, r1, lsl #1
   e83de:	f44f 6480 	mov.w	r4, #1024	; 0x400
   e83e2:	f104 0432 	add.w	r4, r4, #50	; 0x32
   e83e6:	ea5f 5c91 	movs.w	ip, r1, lsr #22
   e83ea:	f43f aedc 	beq.w	e81a6 <__adddf3+0xe6>
   e83ee:	f04f 0203 	mov.w	r2, #3
   e83f2:	ea5f 0cdc 	movs.w	ip, ip, lsr #3
   e83f6:	bf18      	it	ne
   e83f8:	3203      	addne	r2, #3
   e83fa:	ea5f 0cdc 	movs.w	ip, ip, lsr #3
   e83fe:	bf18      	it	ne
   e8400:	3203      	addne	r2, #3
   e8402:	eb02 02dc 	add.w	r2, r2, ip, lsr #3
   e8406:	f1c2 0320 	rsb	r3, r2, #32
   e840a:	fa00 fc03 	lsl.w	ip, r0, r3
   e840e:	fa20 f002 	lsr.w	r0, r0, r2
   e8412:	fa01 fe03 	lsl.w	lr, r1, r3
   e8416:	ea40 000e 	orr.w	r0, r0, lr
   e841a:	fa21 f102 	lsr.w	r1, r1, r2
   e841e:	4414      	add	r4, r2
   e8420:	e6c1      	b.n	e81a6 <__adddf3+0xe6>
   e8422:	bf00      	nop

000e8424 <__aeabi_dmul>:
   e8424:	b570      	push	{r4, r5, r6, lr}
   e8426:	f04f 0cff 	mov.w	ip, #255	; 0xff
   e842a:	f44c 6ce0 	orr.w	ip, ip, #1792	; 0x700
   e842e:	ea1c 5411 	ands.w	r4, ip, r1, lsr #20
   e8432:	bf1d      	ittte	ne
   e8434:	ea1c 5513 	andsne.w	r5, ip, r3, lsr #20
   e8438:	ea94 0f0c 	teqne	r4, ip
   e843c:	ea95 0f0c 	teqne	r5, ip
   e8440:	f000 f8de 	bleq	e8600 <__aeabi_dmul+0x1dc>
   e8444:	442c      	add	r4, r5
   e8446:	ea81 0603 	eor.w	r6, r1, r3
   e844a:	ea21 514c 	bic.w	r1, r1, ip, lsl #21
   e844e:	ea23 534c 	bic.w	r3, r3, ip, lsl #21
   e8452:	ea50 3501 	orrs.w	r5, r0, r1, lsl #12
   e8456:	bf18      	it	ne
   e8458:	ea52 3503 	orrsne.w	r5, r2, r3, lsl #12
   e845c:	f441 1180 	orr.w	r1, r1, #1048576	; 0x100000
   e8460:	f443 1380 	orr.w	r3, r3, #1048576	; 0x100000
   e8464:	d038      	beq.n	e84d8 <__aeabi_dmul+0xb4>
   e8466:	fba0 ce02 	umull	ip, lr, r0, r2
   e846a:	f04f 0500 	mov.w	r5, #0
   e846e:	fbe1 e502 	umlal	lr, r5, r1, r2
   e8472:	f006 4200 	and.w	r2, r6, #2147483648	; 0x80000000
   e8476:	fbe0 e503 	umlal	lr, r5, r0, r3
   e847a:	f04f 0600 	mov.w	r6, #0
   e847e:	fbe1 5603 	umlal	r5, r6, r1, r3
   e8482:	f09c 0f00 	teq	ip, #0
   e8486:	bf18      	it	ne
   e8488:	f04e 0e01 	orrne.w	lr, lr, #1
   e848c:	f1a4 04ff 	sub.w	r4, r4, #255	; 0xff
   e8490:	f5b6 7f00 	cmp.w	r6, #512	; 0x200
   e8494:	f564 7440 	sbc.w	r4, r4, #768	; 0x300
   e8498:	d204      	bcs.n	e84a4 <__aeabi_dmul+0x80>
   e849a:	ea5f 0e4e 	movs.w	lr, lr, lsl #1
   e849e:	416d      	adcs	r5, r5
   e84a0:	eb46 0606 	adc.w	r6, r6, r6
   e84a4:	ea42 21c6 	orr.w	r1, r2, r6, lsl #11
   e84a8:	ea41 5155 	orr.w	r1, r1, r5, lsr #21
   e84ac:	ea4f 20c5 	mov.w	r0, r5, lsl #11
   e84b0:	ea40 505e 	orr.w	r0, r0, lr, lsr #21
   e84b4:	ea4f 2ece 	mov.w	lr, lr, lsl #11
   e84b8:	f1b4 0cfd 	subs.w	ip, r4, #253	; 0xfd
   e84bc:	bf88      	it	hi
   e84be:	f5bc 6fe0 	cmphi.w	ip, #1792	; 0x700
   e84c2:	d81e      	bhi.n	e8502 <__aeabi_dmul+0xde>
   e84c4:	f1be 4f00 	cmp.w	lr, #2147483648	; 0x80000000
   e84c8:	bf08      	it	eq
   e84ca:	ea5f 0e50 	movseq.w	lr, r0, lsr #1
   e84ce:	f150 0000 	adcs.w	r0, r0, #0
   e84d2:	eb41 5104 	adc.w	r1, r1, r4, lsl #20
   e84d6:	bd70      	pop	{r4, r5, r6, pc}
   e84d8:	f006 4600 	and.w	r6, r6, #2147483648	; 0x80000000
   e84dc:	ea46 0101 	orr.w	r1, r6, r1
   e84e0:	ea40 0002 	orr.w	r0, r0, r2
   e84e4:	ea81 0103 	eor.w	r1, r1, r3
   e84e8:	ebb4 045c 	subs.w	r4, r4, ip, lsr #1
   e84ec:	bfc2      	ittt	gt
   e84ee:	ebd4 050c 	rsbsgt	r5, r4, ip
   e84f2:	ea41 5104 	orrgt.w	r1, r1, r4, lsl #20
   e84f6:	bd70      	popgt	{r4, r5, r6, pc}
   e84f8:	f441 1180 	orr.w	r1, r1, #1048576	; 0x100000
   e84fc:	f04f 0e00 	mov.w	lr, #0
   e8500:	3c01      	subs	r4, #1
   e8502:	f300 80ab 	bgt.w	e865c <__aeabi_dmul+0x238>
   e8506:	f114 0f36 	cmn.w	r4, #54	; 0x36
   e850a:	bfde      	ittt	le
   e850c:	2000      	movle	r0, #0
   e850e:	f001 4100 	andle.w	r1, r1, #2147483648	; 0x80000000
   e8512:	bd70      	pople	{r4, r5, r6, pc}
   e8514:	f1c4 0400 	rsb	r4, r4, #0
   e8518:	3c20      	subs	r4, #32
   e851a:	da35      	bge.n	e8588 <__aeabi_dmul+0x164>
   e851c:	340c      	adds	r4, #12
   e851e:	dc1b      	bgt.n	e8558 <__aeabi_dmul+0x134>
   e8520:	f104 0414 	add.w	r4, r4, #20
   e8524:	f1c4 0520 	rsb	r5, r4, #32
   e8528:	fa00 f305 	lsl.w	r3, r0, r5
   e852c:	fa20 f004 	lsr.w	r0, r0, r4
   e8530:	fa01 f205 	lsl.w	r2, r1, r5
   e8534:	ea40 0002 	orr.w	r0, r0, r2
   e8538:	f001 4200 	and.w	r2, r1, #2147483648	; 0x80000000
   e853c:	f021 4100 	bic.w	r1, r1, #2147483648	; 0x80000000
   e8540:	eb10 70d3 	adds.w	r0, r0, r3, lsr #31
   e8544:	fa21 f604 	lsr.w	r6, r1, r4
   e8548:	eb42 0106 	adc.w	r1, r2, r6
   e854c:	ea5e 0e43 	orrs.w	lr, lr, r3, lsl #1
   e8550:	bf08      	it	eq
   e8552:	ea20 70d3 	biceq.w	r0, r0, r3, lsr #31
   e8556:	bd70      	pop	{r4, r5, r6, pc}
   e8558:	f1c4 040c 	rsb	r4, r4, #12
   e855c:	f1c4 0520 	rsb	r5, r4, #32
   e8560:	fa00 f304 	lsl.w	r3, r0, r4
   e8564:	fa20 f005 	lsr.w	r0, r0, r5
   e8568:	fa01 f204 	lsl.w	r2, r1, r4
   e856c:	ea40 0002 	orr.w	r0, r0, r2
   e8570:	f001 4100 	and.w	r1, r1, #2147483648	; 0x80000000
   e8574:	eb10 70d3 	adds.w	r0, r0, r3, lsr #31
   e8578:	f141 0100 	adc.w	r1, r1, #0
   e857c:	ea5e 0e43 	orrs.w	lr, lr, r3, lsl #1
   e8580:	bf08      	it	eq
   e8582:	ea20 70d3 	biceq.w	r0, r0, r3, lsr #31
   e8586:	bd70      	pop	{r4, r5, r6, pc}
   e8588:	f1c4 0520 	rsb	r5, r4, #32
   e858c:	fa00 f205 	lsl.w	r2, r0, r5
   e8590:	ea4e 0e02 	orr.w	lr, lr, r2
   e8594:	fa20 f304 	lsr.w	r3, r0, r4
   e8598:	fa01 f205 	lsl.w	r2, r1, r5
   e859c:	ea43 0302 	orr.w	r3, r3, r2
   e85a0:	fa21 f004 	lsr.w	r0, r1, r4
   e85a4:	f001 4100 	and.w	r1, r1, #2147483648	; 0x80000000
   e85a8:	fa21 f204 	lsr.w	r2, r1, r4
   e85ac:	ea20 0002 	bic.w	r0, r0, r2
   e85b0:	eb00 70d3 	add.w	r0, r0, r3, lsr #31
   e85b4:	ea5e 0e43 	orrs.w	lr, lr, r3, lsl #1
   e85b8:	bf08      	it	eq
   e85ba:	ea20 70d3 	biceq.w	r0, r0, r3, lsr #31
   e85be:	bd70      	pop	{r4, r5, r6, pc}
   e85c0:	f094 0f00 	teq	r4, #0
   e85c4:	d10f      	bne.n	e85e6 <__aeabi_dmul+0x1c2>
   e85c6:	f001 4600 	and.w	r6, r1, #2147483648	; 0x80000000
   e85ca:	0040      	lsls	r0, r0, #1
   e85cc:	eb41 0101 	adc.w	r1, r1, r1
   e85d0:	f411 1f80 	tst.w	r1, #1048576	; 0x100000
   e85d4:	bf08      	it	eq
   e85d6:	3c01      	subeq	r4, #1
   e85d8:	d0f7      	beq.n	e85ca <__aeabi_dmul+0x1a6>
   e85da:	ea41 0106 	orr.w	r1, r1, r6
   e85de:	f095 0f00 	teq	r5, #0
   e85e2:	bf18      	it	ne
   e85e4:	4770      	bxne	lr
   e85e6:	f003 4600 	and.w	r6, r3, #2147483648	; 0x80000000
   e85ea:	0052      	lsls	r2, r2, #1
   e85ec:	eb43 0303 	adc.w	r3, r3, r3
   e85f0:	f413 1f80 	tst.w	r3, #1048576	; 0x100000
   e85f4:	bf08      	it	eq
   e85f6:	3d01      	subeq	r5, #1
   e85f8:	d0f7      	beq.n	e85ea <__aeabi_dmul+0x1c6>
   e85fa:	ea43 0306 	orr.w	r3, r3, r6
   e85fe:	4770      	bx	lr
   e8600:	ea94 0f0c 	teq	r4, ip
   e8604:	ea0c 5513 	and.w	r5, ip, r3, lsr #20
   e8608:	bf18      	it	ne
   e860a:	ea95 0f0c 	teqne	r5, ip
   e860e:	d00c      	beq.n	e862a <__aeabi_dmul+0x206>
   e8610:	ea50 0641 	orrs.w	r6, r0, r1, lsl #1
   e8614:	bf18      	it	ne
   e8616:	ea52 0643 	orrsne.w	r6, r2, r3, lsl #1
   e861a:	d1d1      	bne.n	e85c0 <__aeabi_dmul+0x19c>
   e861c:	ea81 0103 	eor.w	r1, r1, r3
   e8620:	f001 4100 	and.w	r1, r1, #2147483648	; 0x80000000
   e8624:	f04f 0000 	mov.w	r0, #0
   e8628:	bd70      	pop	{r4, r5, r6, pc}
   e862a:	ea50 0641 	orrs.w	r6, r0, r1, lsl #1
   e862e:	bf06      	itte	eq
   e8630:	4610      	moveq	r0, r2
   e8632:	4619      	moveq	r1, r3
   e8634:	ea52 0643 	orrsne.w	r6, r2, r3, lsl #1
   e8638:	d019      	beq.n	e866e <__aeabi_dmul+0x24a>
   e863a:	ea94 0f0c 	teq	r4, ip
   e863e:	d102      	bne.n	e8646 <__aeabi_dmul+0x222>
   e8640:	ea50 3601 	orrs.w	r6, r0, r1, lsl #12
   e8644:	d113      	bne.n	e866e <__aeabi_dmul+0x24a>
   e8646:	ea95 0f0c 	teq	r5, ip
   e864a:	d105      	bne.n	e8658 <__aeabi_dmul+0x234>
   e864c:	ea52 3603 	orrs.w	r6, r2, r3, lsl #12
   e8650:	bf1c      	itt	ne
   e8652:	4610      	movne	r0, r2
   e8654:	4619      	movne	r1, r3
   e8656:	d10a      	bne.n	e866e <__aeabi_dmul+0x24a>
   e8658:	ea81 0103 	eor.w	r1, r1, r3
   e865c:	f001 4100 	and.w	r1, r1, #2147483648	; 0x80000000
   e8660:	f041 41fe 	orr.w	r1, r1, #2130706432	; 0x7f000000
   e8664:	f441 0170 	orr.w	r1, r1, #15728640	; 0xf00000
   e8668:	f04f 0000 	mov.w	r0, #0
   e866c:	bd70      	pop	{r4, r5, r6, pc}
   e866e:	f041 41fe 	orr.w	r1, r1, #2130706432	; 0x7f000000
   e8672:	f441 0178 	orr.w	r1, r1, #16252928	; 0xf80000
   e8676:	bd70      	pop	{r4, r5, r6, pc}

000e8678 <__aeabi_ddiv>:
   e8678:	b570      	push	{r4, r5, r6, lr}
   e867a:	f04f 0cff 	mov.w	ip, #255	; 0xff
   e867e:	f44c 6ce0 	orr.w	ip, ip, #1792	; 0x700
   e8682:	ea1c 5411 	ands.w	r4, ip, r1, lsr #20
   e8686:	bf1d      	ittte	ne
   e8688:	ea1c 5513 	andsne.w	r5, ip, r3, lsr #20
   e868c:	ea94 0f0c 	teqne	r4, ip
   e8690:	ea95 0f0c 	teqne	r5, ip
   e8694:	f000 f8a7 	bleq	e87e6 <__aeabi_ddiv+0x16e>
   e8698:	eba4 0405 	sub.w	r4, r4, r5
   e869c:	ea81 0e03 	eor.w	lr, r1, r3
   e86a0:	ea52 3503 	orrs.w	r5, r2, r3, lsl #12
   e86a4:	ea4f 3101 	mov.w	r1, r1, lsl #12
   e86a8:	f000 8088 	beq.w	e87bc <__aeabi_ddiv+0x144>
   e86ac:	ea4f 3303 	mov.w	r3, r3, lsl #12
   e86b0:	f04f 5580 	mov.w	r5, #268435456	; 0x10000000
   e86b4:	ea45 1313 	orr.w	r3, r5, r3, lsr #4
   e86b8:	ea43 6312 	orr.w	r3, r3, r2, lsr #24
   e86bc:	ea4f 2202 	mov.w	r2, r2, lsl #8
   e86c0:	ea45 1511 	orr.w	r5, r5, r1, lsr #4
   e86c4:	ea45 6510 	orr.w	r5, r5, r0, lsr #24
   e86c8:	ea4f 2600 	mov.w	r6, r0, lsl #8
   e86cc:	f00e 4100 	and.w	r1, lr, #2147483648	; 0x80000000
   e86d0:	429d      	cmp	r5, r3
   e86d2:	bf08      	it	eq
   e86d4:	4296      	cmpeq	r6, r2
   e86d6:	f144 04fd 	adc.w	r4, r4, #253	; 0xfd
   e86da:	f504 7440 	add.w	r4, r4, #768	; 0x300
   e86de:	d202      	bcs.n	e86e6 <__aeabi_ddiv+0x6e>
   e86e0:	085b      	lsrs	r3, r3, #1
   e86e2:	ea4f 0232 	mov.w	r2, r2, rrx
   e86e6:	1ab6      	subs	r6, r6, r2
   e86e8:	eb65 0503 	sbc.w	r5, r5, r3
   e86ec:	085b      	lsrs	r3, r3, #1
   e86ee:	ea4f 0232 	mov.w	r2, r2, rrx
   e86f2:	f44f 1080 	mov.w	r0, #1048576	; 0x100000
   e86f6:	f44f 2c00 	mov.w	ip, #524288	; 0x80000
   e86fa:	ebb6 0e02 	subs.w	lr, r6, r2
   e86fe:	eb75 0e03 	sbcs.w	lr, r5, r3
   e8702:	bf22      	ittt	cs
   e8704:	1ab6      	subcs	r6, r6, r2
   e8706:	4675      	movcs	r5, lr
   e8708:	ea40 000c 	orrcs.w	r0, r0, ip
   e870c:	085b      	lsrs	r3, r3, #1
   e870e:	ea4f 0232 	mov.w	r2, r2, rrx
   e8712:	ebb6 0e02 	subs.w	lr, r6, r2
   e8716:	eb75 0e03 	sbcs.w	lr, r5, r3
   e871a:	bf22      	ittt	cs
   e871c:	1ab6      	subcs	r6, r6, r2
   e871e:	4675      	movcs	r5, lr
   e8720:	ea40 005c 	orrcs.w	r0, r0, ip, lsr #1
   e8724:	085b      	lsrs	r3, r3, #1
   e8726:	ea4f 0232 	mov.w	r2, r2, rrx
   e872a:	ebb6 0e02 	subs.w	lr, r6, r2
   e872e:	eb75 0e03 	sbcs.w	lr, r5, r3
   e8732:	bf22      	ittt	cs
   e8734:	1ab6      	subcs	r6, r6, r2
   e8736:	4675      	movcs	r5, lr
   e8738:	ea40 009c 	orrcs.w	r0, r0, ip, lsr #2
   e873c:	085b      	lsrs	r3, r3, #1
   e873e:	ea4f 0232 	mov.w	r2, r2, rrx
   e8742:	ebb6 0e02 	subs.w	lr, r6, r2
   e8746:	eb75 0e03 	sbcs.w	lr, r5, r3
   e874a:	bf22      	ittt	cs
   e874c:	1ab6      	subcs	r6, r6, r2
   e874e:	4675      	movcs	r5, lr
   e8750:	ea40 00dc 	orrcs.w	r0, r0, ip, lsr #3
   e8754:	ea55 0e06 	orrs.w	lr, r5, r6
   e8758:	d018      	beq.n	e878c <__aeabi_ddiv+0x114>
   e875a:	ea4f 1505 	mov.w	r5, r5, lsl #4
   e875e:	ea45 7516 	orr.w	r5, r5, r6, lsr #28
   e8762:	ea4f 1606 	mov.w	r6, r6, lsl #4
   e8766:	ea4f 03c3 	mov.w	r3, r3, lsl #3
   e876a:	ea43 7352 	orr.w	r3, r3, r2, lsr #29
   e876e:	ea4f 02c2 	mov.w	r2, r2, lsl #3
   e8772:	ea5f 1c1c 	movs.w	ip, ip, lsr #4
   e8776:	d1c0      	bne.n	e86fa <__aeabi_ddiv+0x82>
   e8778:	f411 1f80 	tst.w	r1, #1048576	; 0x100000
   e877c:	d10b      	bne.n	e8796 <__aeabi_ddiv+0x11e>
   e877e:	ea41 0100 	orr.w	r1, r1, r0
   e8782:	f04f 0000 	mov.w	r0, #0
   e8786:	f04f 4c00 	mov.w	ip, #2147483648	; 0x80000000
   e878a:	e7b6      	b.n	e86fa <__aeabi_ddiv+0x82>
   e878c:	f411 1f80 	tst.w	r1, #1048576	; 0x100000
   e8790:	bf04      	itt	eq
   e8792:	4301      	orreq	r1, r0
   e8794:	2000      	moveq	r0, #0
   e8796:	f1b4 0cfd 	subs.w	ip, r4, #253	; 0xfd
   e879a:	bf88      	it	hi
   e879c:	f5bc 6fe0 	cmphi.w	ip, #1792	; 0x700
   e87a0:	f63f aeaf 	bhi.w	e8502 <__aeabi_dmul+0xde>
   e87a4:	ebb5 0c03 	subs.w	ip, r5, r3
   e87a8:	bf04      	itt	eq
   e87aa:	ebb6 0c02 	subseq.w	ip, r6, r2
   e87ae:	ea5f 0c50 	movseq.w	ip, r0, lsr #1
   e87b2:	f150 0000 	adcs.w	r0, r0, #0
   e87b6:	eb41 5104 	adc.w	r1, r1, r4, lsl #20
   e87ba:	bd70      	pop	{r4, r5, r6, pc}
   e87bc:	f00e 4e00 	and.w	lr, lr, #2147483648	; 0x80000000
   e87c0:	ea4e 3111 	orr.w	r1, lr, r1, lsr #12
   e87c4:	eb14 045c 	adds.w	r4, r4, ip, lsr #1
   e87c8:	bfc2      	ittt	gt
   e87ca:	ebd4 050c 	rsbsgt	r5, r4, ip
   e87ce:	ea41 5104 	orrgt.w	r1, r1, r4, lsl #20
   e87d2:	bd70      	popgt	{r4, r5, r6, pc}
   e87d4:	f441 1180 	orr.w	r1, r1, #1048576	; 0x100000
   e87d8:	f04f 0e00 	mov.w	lr, #0
   e87dc:	3c01      	subs	r4, #1
   e87de:	e690      	b.n	e8502 <__aeabi_dmul+0xde>
   e87e0:	ea45 0e06 	orr.w	lr, r5, r6
   e87e4:	e68d      	b.n	e8502 <__aeabi_dmul+0xde>
   e87e6:	ea0c 5513 	and.w	r5, ip, r3, lsr #20
   e87ea:	ea94 0f0c 	teq	r4, ip
   e87ee:	bf08      	it	eq
   e87f0:	ea95 0f0c 	teqeq	r5, ip
   e87f4:	f43f af3b 	beq.w	e866e <__aeabi_dmul+0x24a>
   e87f8:	ea94 0f0c 	teq	r4, ip
   e87fc:	d10a      	bne.n	e8814 <__aeabi_ddiv+0x19c>
   e87fe:	ea50 3401 	orrs.w	r4, r0, r1, lsl #12
   e8802:	f47f af34 	bne.w	e866e <__aeabi_dmul+0x24a>
   e8806:	ea95 0f0c 	teq	r5, ip
   e880a:	f47f af25 	bne.w	e8658 <__aeabi_dmul+0x234>
   e880e:	4610      	mov	r0, r2
   e8810:	4619      	mov	r1, r3
   e8812:	e72c      	b.n	e866e <__aeabi_dmul+0x24a>
   e8814:	ea95 0f0c 	teq	r5, ip
   e8818:	d106      	bne.n	e8828 <__aeabi_ddiv+0x1b0>
   e881a:	ea52 3503 	orrs.w	r5, r2, r3, lsl #12
   e881e:	f43f aefd 	beq.w	e861c <__aeabi_dmul+0x1f8>
   e8822:	4610      	mov	r0, r2
   e8824:	4619      	mov	r1, r3
   e8826:	e722      	b.n	e866e <__aeabi_dmul+0x24a>
   e8828:	ea50 0641 	orrs.w	r6, r0, r1, lsl #1
   e882c:	bf18      	it	ne
   e882e:	ea52 0643 	orrsne.w	r6, r2, r3, lsl #1
   e8832:	f47f aec5 	bne.w	e85c0 <__aeabi_dmul+0x19c>
   e8836:	ea50 0441 	orrs.w	r4, r0, r1, lsl #1
   e883a:	f47f af0d 	bne.w	e8658 <__aeabi_dmul+0x234>
   e883e:	ea52 0543 	orrs.w	r5, r2, r3, lsl #1
   e8842:	f47f aeeb 	bne.w	e861c <__aeabi_dmul+0x1f8>
   e8846:	e712      	b.n	e866e <__aeabi_dmul+0x24a>

000e8848 <__gedf2>:
   e8848:	f04f 3cff 	mov.w	ip, #4294967295	; 0xffffffff
   e884c:	e006      	b.n	e885c <__cmpdf2+0x4>
   e884e:	bf00      	nop

000e8850 <__ledf2>:
   e8850:	f04f 0c01 	mov.w	ip, #1
   e8854:	e002      	b.n	e885c <__cmpdf2+0x4>
   e8856:	bf00      	nop

000e8858 <__cmpdf2>:
   e8858:	f04f 0c01 	mov.w	ip, #1
   e885c:	f84d cd04 	str.w	ip, [sp, #-4]!
   e8860:	ea4f 0c41 	mov.w	ip, r1, lsl #1
   e8864:	ea7f 5c6c 	mvns.w	ip, ip, asr #21
   e8868:	ea4f 0c43 	mov.w	ip, r3, lsl #1
   e886c:	bf18      	it	ne
   e886e:	ea7f 5c6c 	mvnsne.w	ip, ip, asr #21
   e8872:	d01b      	beq.n	e88ac <__cmpdf2+0x54>
   e8874:	b001      	add	sp, #4
   e8876:	ea50 0c41 	orrs.w	ip, r0, r1, lsl #1
   e887a:	bf0c      	ite	eq
   e887c:	ea52 0c43 	orrseq.w	ip, r2, r3, lsl #1
   e8880:	ea91 0f03 	teqne	r1, r3
   e8884:	bf02      	ittt	eq
   e8886:	ea90 0f02 	teqeq	r0, r2
   e888a:	2000      	moveq	r0, #0
   e888c:	4770      	bxeq	lr
   e888e:	f110 0f00 	cmn.w	r0, #0
   e8892:	ea91 0f03 	teq	r1, r3
   e8896:	bf58      	it	pl
   e8898:	4299      	cmppl	r1, r3
   e889a:	bf08      	it	eq
   e889c:	4290      	cmpeq	r0, r2
   e889e:	bf2c      	ite	cs
   e88a0:	17d8      	asrcs	r0, r3, #31
   e88a2:	ea6f 70e3 	mvncc.w	r0, r3, asr #31
   e88a6:	f040 0001 	orr.w	r0, r0, #1
   e88aa:	4770      	bx	lr
   e88ac:	ea4f 0c41 	mov.w	ip, r1, lsl #1
   e88b0:	ea7f 5c6c 	mvns.w	ip, ip, asr #21
   e88b4:	d102      	bne.n	e88bc <__cmpdf2+0x64>
   e88b6:	ea50 3c01 	orrs.w	ip, r0, r1, lsl #12
   e88ba:	d107      	bne.n	e88cc <__cmpdf2+0x74>
   e88bc:	ea4f 0c43 	mov.w	ip, r3, lsl #1
   e88c0:	ea7f 5c6c 	mvns.w	ip, ip, asr #21
   e88c4:	d1d6      	bne.n	e8874 <__cmpdf2+0x1c>
   e88c6:	ea52 3c03 	orrs.w	ip, r2, r3, lsl #12
   e88ca:	d0d3      	beq.n	e8874 <__cmpdf2+0x1c>
   e88cc:	f85d 0b04 	ldr.w	r0, [sp], #4
   e88d0:	4770      	bx	lr
   e88d2:	bf00      	nop

000e88d4 <__aeabi_cdrcmple>:
   e88d4:	4684      	mov	ip, r0
   e88d6:	4610      	mov	r0, r2
   e88d8:	4662      	mov	r2, ip
   e88da:	468c      	mov	ip, r1
   e88dc:	4619      	mov	r1, r3
   e88de:	4663      	mov	r3, ip
   e88e0:	e000      	b.n	e88e4 <__aeabi_cdcmpeq>
   e88e2:	bf00      	nop

000e88e4 <__aeabi_cdcmpeq>:
   e88e4:	b501      	push	{r0, lr}
   e88e6:	f7ff ffb7 	bl	e8858 <__cmpdf2>
   e88ea:	2800      	cmp	r0, #0
   e88ec:	bf48      	it	mi
   e88ee:	f110 0f00 	cmnmi.w	r0, #0
   e88f2:	bd01      	pop	{r0, pc}

000e88f4 <__aeabi_dcmpeq>:
   e88f4:	f84d ed08 	str.w	lr, [sp, #-8]!
   e88f8:	f7ff fff4 	bl	e88e4 <__aeabi_cdcmpeq>
   e88fc:	bf0c      	ite	eq
   e88fe:	2001      	moveq	r0, #1
   e8900:	2000      	movne	r0, #0
   e8902:	f85d fb08 	ldr.w	pc, [sp], #8
   e8906:	bf00      	nop

000e8908 <__aeabi_dcmplt>:
   e8908:	f84d ed08 	str.w	lr, [sp, #-8]!
   e890c:	f7ff ffea 	bl	e88e4 <__aeabi_cdcmpeq>
   e8910:	bf34      	ite	cc
   e8912:	2001      	movcc	r0, #1
   e8914:	2000      	movcs	r0, #0
   e8916:	f85d fb08 	ldr.w	pc, [sp], #8
   e891a:	bf00      	nop

000e891c <__aeabi_dcmple>:
   e891c:	f84d ed08 	str.w	lr, [sp, #-8]!
   e8920:	f7ff ffe0 	bl	e88e4 <__aeabi_cdcmpeq>
   e8924:	bf94      	ite	ls
   e8926:	2001      	movls	r0, #1
   e8928:	2000      	movhi	r0, #0
   e892a:	f85d fb08 	ldr.w	pc, [sp], #8
   e892e:	bf00      	nop

000e8930 <__aeabi_dcmpge>:
   e8930:	f84d ed08 	str.w	lr, [sp, #-8]!
   e8934:	f7ff ffce 	bl	e88d4 <__aeabi_cdrcmple>
   e8938:	bf94      	ite	ls
   e893a:	2001      	movls	r0, #1
   e893c:	2000      	movhi	r0, #0
   e893e:	f85d fb08 	ldr.w	pc, [sp], #8
   e8942:	bf00      	nop

000e8944 <__aeabi_dcmpgt>:
   e8944:	f84d ed08 	str.w	lr, [sp, #-8]!
   e8948:	f7ff ffc4 	bl	e88d4 <__aeabi_cdrcmple>
   e894c:	bf34      	ite	cc
   e894e:	2001      	movcc	r0, #1
   e8950:	2000      	movcs	r0, #0
   e8952:	f85d fb08 	ldr.w	pc, [sp], #8
   e8956:	bf00      	nop

000e8958 <__aeabi_d2iz>:
   e8958:	ea4f 0241 	mov.w	r2, r1, lsl #1
   e895c:	f512 1200 	adds.w	r2, r2, #2097152	; 0x200000
   e8960:	d215      	bcs.n	e898e <__aeabi_d2iz+0x36>
   e8962:	d511      	bpl.n	e8988 <__aeabi_d2iz+0x30>
   e8964:	f46f 7378 	mvn.w	r3, #992	; 0x3e0
   e8968:	ebb3 5262 	subs.w	r2, r3, r2, asr #21
   e896c:	d912      	bls.n	e8994 <__aeabi_d2iz+0x3c>
   e896e:	ea4f 23c1 	mov.w	r3, r1, lsl #11
   e8972:	f043 4300 	orr.w	r3, r3, #2147483648	; 0x80000000
   e8976:	ea43 5350 	orr.w	r3, r3, r0, lsr #21
   e897a:	f011 4f00 	tst.w	r1, #2147483648	; 0x80000000
   e897e:	fa23 f002 	lsr.w	r0, r3, r2
   e8982:	bf18      	it	ne
   e8984:	4240      	negne	r0, r0
   e8986:	4770      	bx	lr
   e8988:	f04f 0000 	mov.w	r0, #0
   e898c:	4770      	bx	lr
   e898e:	ea50 3001 	orrs.w	r0, r0, r1, lsl #12
   e8992:	d105      	bne.n	e89a0 <__aeabi_d2iz+0x48>
   e8994:	f011 4000 	ands.w	r0, r1, #2147483648	; 0x80000000
   e8998:	bf08      	it	eq
   e899a:	f06f 4000 	mvneq.w	r0, #2147483648	; 0x80000000
   e899e:	4770      	bx	lr
   e89a0:	f04f 0000 	mov.w	r0, #0
   e89a4:	4770      	bx	lr
   e89a6:	bf00      	nop

000e89a8 <__aeabi_d2uiz>:
   e89a8:	004a      	lsls	r2, r1, #1
   e89aa:	d211      	bcs.n	e89d0 <__aeabi_d2uiz+0x28>
   e89ac:	f512 1200 	adds.w	r2, r2, #2097152	; 0x200000
   e89b0:	d211      	bcs.n	e89d6 <__aeabi_d2uiz+0x2e>
   e89b2:	d50d      	bpl.n	e89d0 <__aeabi_d2uiz+0x28>
   e89b4:	f46f 7378 	mvn.w	r3, #992	; 0x3e0
   e89b8:	ebb3 5262 	subs.w	r2, r3, r2, asr #21
   e89bc:	d40e      	bmi.n	e89dc <__aeabi_d2uiz+0x34>
   e89be:	ea4f 23c1 	mov.w	r3, r1, lsl #11
   e89c2:	f043 4300 	orr.w	r3, r3, #2147483648	; 0x80000000
   e89c6:	ea43 5350 	orr.w	r3, r3, r0, lsr #21
   e89ca:	fa23 f002 	lsr.w	r0, r3, r2
   e89ce:	4770      	bx	lr
   e89d0:	f04f 0000 	mov.w	r0, #0
   e89d4:	4770      	bx	lr
   e89d6:	ea50 3001 	orrs.w	r0, r0, r1, lsl #12
   e89da:	d102      	bne.n	e89e2 <__aeabi_d2uiz+0x3a>
   e89dc:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
   e89e0:	4770      	bx	lr
   e89e2:	f04f 0000 	mov.w	r0, #0
   e89e6:	4770      	bx	lr

000e89e8 <__aeabi_d2f>:
   e89e8:	ea4f 0241 	mov.w	r2, r1, lsl #1
   e89ec:	f1b2 43e0 	subs.w	r3, r2, #1879048192	; 0x70000000
   e89f0:	bf24      	itt	cs
   e89f2:	f5b3 1c00 	subscs.w	ip, r3, #2097152	; 0x200000
   e89f6:	f1dc 5cfe 	rsbscs	ip, ip, #532676608	; 0x1fc00000
   e89fa:	d90d      	bls.n	e8a18 <__aeabi_d2f+0x30>
   e89fc:	f001 4c00 	and.w	ip, r1, #2147483648	; 0x80000000
   e8a00:	ea4f 02c0 	mov.w	r2, r0, lsl #3
   e8a04:	ea4c 7050 	orr.w	r0, ip, r0, lsr #29
   e8a08:	f1b2 4f00 	cmp.w	r2, #2147483648	; 0x80000000
   e8a0c:	eb40 0083 	adc.w	r0, r0, r3, lsl #2
   e8a10:	bf08      	it	eq
   e8a12:	f020 0001 	biceq.w	r0, r0, #1
   e8a16:	4770      	bx	lr
   e8a18:	f011 4f80 	tst.w	r1, #1073741824	; 0x40000000
   e8a1c:	d121      	bne.n	e8a62 <__aeabi_d2f+0x7a>
   e8a1e:	f113 7238 	adds.w	r2, r3, #48234496	; 0x2e00000
   e8a22:	bfbc      	itt	lt
   e8a24:	f001 4000 	andlt.w	r0, r1, #2147483648	; 0x80000000
   e8a28:	4770      	bxlt	lr
   e8a2a:	f441 1180 	orr.w	r1, r1, #1048576	; 0x100000
   e8a2e:	ea4f 5252 	mov.w	r2, r2, lsr #21
   e8a32:	f1c2 0218 	rsb	r2, r2, #24
   e8a36:	f1c2 0c20 	rsb	ip, r2, #32
   e8a3a:	fa10 f30c 	lsls.w	r3, r0, ip
   e8a3e:	fa20 f002 	lsr.w	r0, r0, r2
   e8a42:	bf18      	it	ne
   e8a44:	f040 0001 	orrne.w	r0, r0, #1
   e8a48:	ea4f 23c1 	mov.w	r3, r1, lsl #11
   e8a4c:	ea4f 23d3 	mov.w	r3, r3, lsr #11
   e8a50:	fa03 fc0c 	lsl.w	ip, r3, ip
   e8a54:	ea40 000c 	orr.w	r0, r0, ip
   e8a58:	fa23 f302 	lsr.w	r3, r3, r2
   e8a5c:	ea4f 0343 	mov.w	r3, r3, lsl #1
   e8a60:	e7cc      	b.n	e89fc <__aeabi_d2f+0x14>
   e8a62:	ea7f 5362 	mvns.w	r3, r2, asr #21
   e8a66:	d107      	bne.n	e8a78 <__aeabi_d2f+0x90>
   e8a68:	ea50 3301 	orrs.w	r3, r0, r1, lsl #12
   e8a6c:	bf1e      	ittt	ne
   e8a6e:	f04f 40fe 	movne.w	r0, #2130706432	; 0x7f000000
   e8a72:	f440 0040 	orrne.w	r0, r0, #12582912	; 0xc00000
   e8a76:	4770      	bxne	lr
   e8a78:	f001 4000 	and.w	r0, r1, #2147483648	; 0x80000000
   e8a7c:	f040 40fe 	orr.w	r0, r0, #2130706432	; 0x7f000000
   e8a80:	f440 0000 	orr.w	r0, r0, #8388608	; 0x800000
   e8a84:	4770      	bx	lr
   e8a86:	bf00      	nop

000e8a88 <__aeabi_d2lz>:
   e8a88:	b538      	push	{r3, r4, r5, lr}
   e8a8a:	2200      	movs	r2, #0
   e8a8c:	2300      	movs	r3, #0
   e8a8e:	4604      	mov	r4, r0
   e8a90:	460d      	mov	r5, r1
   e8a92:	f7ff ff39 	bl	e8908 <__aeabi_dcmplt>
   e8a96:	b928      	cbnz	r0, e8aa4 <__aeabi_d2lz+0x1c>
   e8a98:	4620      	mov	r0, r4
   e8a9a:	4629      	mov	r1, r5
   e8a9c:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
   e8aa0:	f000 b80a 	b.w	e8ab8 <__aeabi_d2ulz>
   e8aa4:	4620      	mov	r0, r4
   e8aa6:	f105 4100 	add.w	r1, r5, #2147483648	; 0x80000000
   e8aaa:	f000 f805 	bl	e8ab8 <__aeabi_d2ulz>
   e8aae:	4240      	negs	r0, r0
   e8ab0:	eb61 0141 	sbc.w	r1, r1, r1, lsl #1
   e8ab4:	bd38      	pop	{r3, r4, r5, pc}
   e8ab6:	bf00      	nop

000e8ab8 <__aeabi_d2ulz>:
   e8ab8:	b5d0      	push	{r4, r6, r7, lr}
   e8aba:	2200      	movs	r2, #0
   e8abc:	4b0e      	ldr	r3, [pc, #56]	; (e8af8 <__aeabi_d2ulz+0x40>)
   e8abe:	4606      	mov	r6, r0
   e8ac0:	460f      	mov	r7, r1
   e8ac2:	f7ff fcaf 	bl	e8424 <__aeabi_dmul>
   e8ac6:	f7ff ff6f 	bl	e89a8 <__aeabi_d2uiz>
   e8aca:	4604      	mov	r4, r0
   e8acc:	f7ff fc34 	bl	e8338 <__aeabi_ui2d>
   e8ad0:	2200      	movs	r2, #0
   e8ad2:	4b0a      	ldr	r3, [pc, #40]	; (e8afc <__aeabi_d2ulz+0x44>)
   e8ad4:	f7ff fca6 	bl	e8424 <__aeabi_dmul>
   e8ad8:	4602      	mov	r2, r0
   e8ada:	460b      	mov	r3, r1
   e8adc:	4630      	mov	r0, r6
   e8ade:	4639      	mov	r1, r7
   e8ae0:	f7ff faec 	bl	e80bc <__aeabi_dsub>
   e8ae4:	f7ff ff60 	bl	e89a8 <__aeabi_d2uiz>
   e8ae8:	4623      	mov	r3, r4
   e8aea:	2200      	movs	r2, #0
   e8aec:	ea42 0200 	orr.w	r2, r2, r0
   e8af0:	4610      	mov	r0, r2
   e8af2:	4619      	mov	r1, r3
   e8af4:	bdd0      	pop	{r4, r6, r7, pc}
   e8af6:	bf00      	nop
   e8af8:	3df00000 	.word	0x3df00000
   e8afc:	41f00000 	.word	0x41f00000

000e8b00 <__cxa_atexit>:
   e8b00:	b510      	push	{r4, lr}
   e8b02:	4c05      	ldr	r4, [pc, #20]	; (e8b18 <__cxa_atexit+0x18>)
   e8b04:	4613      	mov	r3, r2
   e8b06:	b12c      	cbz	r4, e8b14 <__cxa_atexit+0x14>
   e8b08:	460a      	mov	r2, r1
   e8b0a:	4601      	mov	r1, r0
   e8b0c:	2002      	movs	r0, #2
   e8b0e:	f3af 8000 	nop.w
   e8b12:	bd10      	pop	{r4, pc}
   e8b14:	4620      	mov	r0, r4
   e8b16:	bd10      	pop	{r4, pc}
   e8b18:	00000000 	.word	0x00000000

000e8b1c <exit>:
   e8b1c:	b508      	push	{r3, lr}
   e8b1e:	4b07      	ldr	r3, [pc, #28]	; (e8b3c <exit+0x20>)
   e8b20:	4604      	mov	r4, r0
   e8b22:	b113      	cbz	r3, e8b2a <exit+0xe>
   e8b24:	2100      	movs	r1, #0
   e8b26:	f3af 8000 	nop.w
   e8b2a:	4b05      	ldr	r3, [pc, #20]	; (e8b40 <exit+0x24>)
   e8b2c:	6818      	ldr	r0, [r3, #0]
   e8b2e:	6a83      	ldr	r3, [r0, #40]	; 0x28
   e8b30:	b103      	cbz	r3, e8b34 <exit+0x18>
   e8b32:	4798      	blx	r3
   e8b34:	4620      	mov	r0, r4
   e8b36:	f7eb fab7 	bl	d40a8 <_exit>
   e8b3a:	bf00      	nop
   e8b3c:	00000000 	.word	0x00000000
   e8b40:	000ed4c0 	.word	0x000ed4c0

000e8b44 <memcmp>:
   e8b44:	b510      	push	{r4, lr}
   e8b46:	3901      	subs	r1, #1
   e8b48:	4402      	add	r2, r0
   e8b4a:	4290      	cmp	r0, r2
   e8b4c:	d007      	beq.n	e8b5e <memcmp+0x1a>
   e8b4e:	f810 3b01 	ldrb.w	r3, [r0], #1
   e8b52:	f811 4f01 	ldrb.w	r4, [r1, #1]!
   e8b56:	42a3      	cmp	r3, r4
   e8b58:	d0f7      	beq.n	e8b4a <memcmp+0x6>
   e8b5a:	1b18      	subs	r0, r3, r4
   e8b5c:	bd10      	pop	{r4, pc}
   e8b5e:	2000      	movs	r0, #0
   e8b60:	bd10      	pop	{r4, pc}

000e8b62 <memcpy>:
   e8b62:	b510      	push	{r4, lr}
   e8b64:	1e43      	subs	r3, r0, #1
   e8b66:	440a      	add	r2, r1
   e8b68:	4291      	cmp	r1, r2
   e8b6a:	d004      	beq.n	e8b76 <memcpy+0x14>
   e8b6c:	f811 4b01 	ldrb.w	r4, [r1], #1
   e8b70:	f803 4f01 	strb.w	r4, [r3, #1]!
   e8b74:	e7f8      	b.n	e8b68 <memcpy+0x6>
   e8b76:	bd10      	pop	{r4, pc}

000e8b78 <memset>:
   e8b78:	4402      	add	r2, r0
   e8b7a:	4603      	mov	r3, r0
   e8b7c:	4293      	cmp	r3, r2
   e8b7e:	d002      	beq.n	e8b86 <memset+0xe>
   e8b80:	f803 1b01 	strb.w	r1, [r3], #1
   e8b84:	e7fa      	b.n	e8b7c <memset+0x4>
   e8b86:	4770      	bx	lr

000e8b88 <srand>:
   e8b88:	b538      	push	{r3, r4, r5, lr}
   e8b8a:	4b12      	ldr	r3, [pc, #72]	; (e8bd4 <srand+0x4c>)
   e8b8c:	681c      	ldr	r4, [r3, #0]
   e8b8e:	6ba3      	ldr	r3, [r4, #56]	; 0x38
   e8b90:	4605      	mov	r5, r0
   e8b92:	b9d3      	cbnz	r3, e8bca <srand+0x42>
   e8b94:	2018      	movs	r0, #24
   e8b96:	f7fc fc95 	bl	e54c4 <malloc>
   e8b9a:	f243 330e 	movw	r3, #13070	; 0x330e
   e8b9e:	63a0      	str	r0, [r4, #56]	; 0x38
   e8ba0:	8003      	strh	r3, [r0, #0]
   e8ba2:	f64a 33cd 	movw	r3, #43981	; 0xabcd
   e8ba6:	8043      	strh	r3, [r0, #2]
   e8ba8:	f241 2334 	movw	r3, #4660	; 0x1234
   e8bac:	8083      	strh	r3, [r0, #4]
   e8bae:	f24e 636d 	movw	r3, #58989	; 0xe66d
   e8bb2:	80c3      	strh	r3, [r0, #6]
   e8bb4:	f64d 63ec 	movw	r3, #57068	; 0xdeec
   e8bb8:	8103      	strh	r3, [r0, #8]
   e8bba:	2305      	movs	r3, #5
   e8bbc:	8143      	strh	r3, [r0, #10]
   e8bbe:	230b      	movs	r3, #11
   e8bc0:	8183      	strh	r3, [r0, #12]
   e8bc2:	2201      	movs	r2, #1
   e8bc4:	2300      	movs	r3, #0
   e8bc6:	e9c0 2304 	strd	r2, r3, [r0, #16]
   e8bca:	6ba3      	ldr	r3, [r4, #56]	; 0x38
   e8bcc:	2200      	movs	r2, #0
   e8bce:	611d      	str	r5, [r3, #16]
   e8bd0:	615a      	str	r2, [r3, #20]
   e8bd2:	bd38      	pop	{r3, r4, r5, pc}
   e8bd4:	2003c298 	.word	0x2003c298

000e8bd8 <strcmp>:
   e8bd8:	f810 2b01 	ldrb.w	r2, [r0], #1
   e8bdc:	f811 3b01 	ldrb.w	r3, [r1], #1
   e8be0:	2a01      	cmp	r2, #1
   e8be2:	bf28      	it	cs
   e8be4:	429a      	cmpcs	r2, r3
   e8be6:	d0f7      	beq.n	e8bd8 <strcmp>
   e8be8:	1ad0      	subs	r0, r2, r3
   e8bea:	4770      	bx	lr

000e8bec <strlen>:
   e8bec:	4603      	mov	r3, r0
   e8bee:	f813 2b01 	ldrb.w	r2, [r3], #1
   e8bf2:	2a00      	cmp	r2, #0
   e8bf4:	d1fb      	bne.n	e8bee <strlen+0x2>
   e8bf6:	1a18      	subs	r0, r3, r0
   e8bf8:	3801      	subs	r0, #1
   e8bfa:	4770      	bx	lr

000e8bfc <dynalib_user>:
   e8bfc:	4021 000d 405d 000d 4089 000d 408d 000d     !@..]@...@...@..
   e8c0c:	0000 0000 7325 203a 656c 676e 6874 253d     ....%s: length=%
   e8c1c:	2064 005b 6e55 6e6b 776f 206e 7974 6570     d [.Unknown type
   e8c2c:	4e00 544f 5059 0045 4c46 414f 3354 0032     .NOTYPE.FLOAT32.
   e8c3c:	4e49 3354 0032 4955 544e 0038 4e49 3654     INT32.UINT8.INT6
   e8c4c:	0034 5453 4952 474e 4200 4f4f 004c 4e49     4.STRING.BOOL.IN
   e8c5c:	3154 0036 4f43 504d 454c 3658 0034 4c46     T16.COMPLEX64.FL
   e8c6c:	414f 3154 0036 0000                         OAT16...

000e8c74 <CSWTCH.19>:
   e8c74:	8c2d 000e 8c34 000e 8c3c 000e 8c42 000e     -...4...<...B...
   e8c84:	8c48 000e 8c4e 000e 8c55 000e 8c5a 000e     H...N...U...Z...
   e8c94:	8c60 000e 8c43 000e 8c6a 000e               `...C...j...

000e8ca0 <kInferencesPerCycle>:
   e8ca0:	03e8 0000                                   ....

000e8ca4 <g_sine_model_data>:
   e8ca4:	0018 0000 4654 334c 0000 000e 0018 0004     ....TFL3........
   e8cb4:	0008 000c 0010 0014 000e 0000 0003 0000     ................
   e8cc4:	0a10 0000 05b8 0000 05a0 0000 0004 0000     ................
   e8cd4:	000b 0000 0590 0000 057c 0000 0524 0000     ........|...$...
   e8ce4:	04d4 0000 00c4 0000 0074 0000 0024 0000     ........t...$...
   e8cf4:	001c 0000 0014 0000 000c 0000 0004 0000     ................
   e8d04:	f654 ffff f658 ffff f65c ffff f660 ffff     T...X...\...`...
   e8d14:	fac2 ffff 0004 0000 0040 0000 197c 3ea7     ........@...|..>
   e8d24:	8199 3eb9 8b56 3e9f d888 bf12 1074 3e56     ...>V..>....t.V>
   e8d34:	c6fe bedf 10f2 be5a e2f0 be0a 5a10 be98     ......Z......Z..
   e8d44:	36b9 3dce 7f8f 3e87 b12c bdfd a6e6 be8a     .6.=...>,.......
   e8d54:	3ea5 3eda 3450 bded 9190 be69 fb0e ffff     .>.>P4....i.....
   e8d64:	0004 0000 0040 0000 4167 bf48 cd24 bea0     ....@...gAH.$...
   e8d74:	92b7 bf0c 0000 0000 fe98 3f3c 0000 0000     ..........<?....
	...
   e8d90:	174a be9a cb41 beb6 0000 0000 0000 0000     J...A...........
   e8da0:	d613 3e1e 0000 0000 0000 0000 fb5a ffff     ...>........Z...
   e8db0:	0004 0000 0400 0000 984b bddd 6b40 becb     ........K...@k..
   e8dc0:	0c36 3cd4 44bd 3eb5 7095 3ee3 ace7 3e86     6..<.D.>.p.>...>
   e8dd0:	c400 3d4e a67e 3e1d 87bd 3ebb b8b4 bf09     ..N=~..>...>....
   e8de0:	1fa1 bef8 908d 3edd fade be6f 75b2 3de4     .......>..o..u.=
   e8df0:	fe6e 3e36 1820 bec2 c739 befb a4fe be30     n.6> ...9.....0.
   e8e00:	91f7 bede abde 3e24 bbfb 3ece 23eb be80     ......$>...>.#..
   e8e10:	587b be73 2e9a 3e03 4210 bca9 1210 bd64     {Xs....>.B....d.
   e8e20:	8de3 3d0c 489e be97 5134 bed4 3b02 3e0d     ...=.H..4Q...;.>
   e8e30:	6762 be89 df74 3da2 25f3 beb3 34ef 3d7b     bg..t..=.%...4{=
   e8e40:	7061 3de3 76ba bec0 e97d 3ea7 abc3 bed0     ap.=.v..}..>....
   e8e50:	7ccf bedb 2770 be9a f598 bd3c 4bff 3e4b     .|..p'....<..KK>
   e8e60:	a07e bdf8 6ed4 3d86 4a00 3a07 244c be61     ~....n.=.J.:L$a.
   e8e70:	6854 bdf7 3f02 be77 7923 3eb3 831c bdad     Th...?w.#y.>....
   e8e80:	92c8 3e8d f3a8 bd15 4de6 3d6c e7ac be98     ...>.....Ml=....
   e8e90:	ec81 3ebd 55e2 3e73 77c1 3ec7 1b6e 3d5e     ...>.Us>.w.>n.^=
   e8ea0:	7827 3f02 21d4 3d90 dc52 3e1f dabf 3e88     'x.?.!.=R..>...>
   e8eb0:	7980 bde3 6f40 be10 4320 bd2e 76f0 bdc5     .y..@o.. C...v..
   e8ec0:	a0cc be04 69f0 bed7 feb1 be64 4120 be84     .....i....d. A..
   e8ed0:	c3b2 be26 f4d8 be09 4464 3dd1 e1d5 bec8     ..&.....dD.=....
   e8ee0:	bc35 be3f 94c0 3d82 2bdc bdb1 db02 bebf     5.?....=.+......
   e8ef0:	7fa5 3e8a b421 3ea2 86cd bf56 3b9c bc76     ...>!..>..V..;v.
   e8f00:	6d85 bf60 0086 be3c 23c1 3e7e cd96 3e3f     .m`...<..#~>..?>
   e8f10:	9186 3e2d ef55 3e87 977e be03 cd2a 3e01     ..->U..>~...*..>
   e8f20:	c932 be8e 7772 be3b a1e0 bebc b78d 3ea7     2...rw;........>
   e8f30:	051c be95 1ff7 3ebb 3ec9 3ed6 4280 bde9     .......>.>.>.B..
   e8f40:	0c27 bed2 325c be34 cb14 bdca 3add be67     '...\24......:g.
   e8f50:	bb1c be8d ac91 be5c 4052 be6f 71d7 3e94     ......\.R@o..q.>
   e8f60:	7118 be09 299b bed9 667d bed2 d698 beb2     .q...)..}f......
   e8f70:	c900 3a84 dabc bdc2 c21d bf1b ddd4 3e92     ...:...........>
   e8f80:	8707 be6c c240 be3b e2bd 3e9c b50a bea0     ..l.@.;....>....
   e8f90:	d5e2 be9c bb3e 3e7c b417 3ecf 8ed5 bec8     ....>.|>...>....
   e8fa0:	f97c 3e5c fc80 3d0d d5c5 3e8b 17f5 3ea2     |.\>...=...>...>
   e8fb0:	60c7 be89 95ec 3d87 c27a bf5d 9477 3e98     .`.....=z.].w..>
   e8fc0:	3977 bc07 2942 3e00 d0af 3ea9 2331 bec4     w9..B).>...>1#..
   e8fd0:	3695 be5b dcc7 be83 6b1e 3e47 245b 3e99     .6[......kG>[$.>
   e8fe0:	2799 3e54 20c8 bddd 865a 3e2f f080 be69     .'T>. ..Z./>..i.
   e8ff0:	fc44 bd84 a082 be2a e687 3e2a 34d8 3dae     D.....*...*>.4.=
   e9000:	bd50 3eb5 8cc4 be88 bce3 3ea5 daa9 3e9e     P..>.......>...>
   e9010:	b83e be23 9080 3d15 3f97 3ec3 5cca 3e9d     >.#....=.?.>.\.>
   e9020:	e821 3ee1 49c0 bc01 0b00 bd88 f73f 3cca     !..>.I......?..<
   e9030:	5afb 3eb1 d260 3c0d 23ce bf78 4f8f beb9     .Z.>`..<.#x..O..
   e9040:	6a69 bf34 5e4b 3ea9 8c64 3ed9 7752 3e36     ij4.K^.>d..>Rw6>
   e9050:	afeb 3ebe be40 3c36 6508 bd3b e055 bd66     ...>@.6<.e;.U.f.
   e9060:	e8d2 be9b e386 be09 3d93 3edd 660f 3f18     .........=.>.f.?
   e9070:	0518 bd33 15de bed7 cfaa be49 a5a2 3e64     ..3.......I...d>
   e9080:	9ce6 be42 4254 3dcc bda0 be9d 69c2 3e48     ..B.TB.=.....iH>
   e9090:	8b5b bea2 13c0 3d87 fd36 3e69 8605 be40     [......=6.i>..@.
   e90a0:	7a1e bece 1346 bea7 5268 be86 9e04 bd86     .z..F...hR......
   e90b0:	548c 3dc1 3be0 3cad 6742 bd85 97ea 3e42     .T.=.;.<Bg....B>
   e90c0:	136e bf3b 5b56 3e16 abaa 3edf 41c8 3d36     n.;.V[.>...>.A6=
   e90d0:	2d24 be47 a577 3eae c2c0 3c5b acac 3e4e     $-G.w..>..[<..N>
   e90e0:	ec99 be13 abf2 3e73 a1aa be48 d3e8 be01     ......s>..H.....
   e90f0:	b760 bdc7 7264 3dd3 d383 3e99 760c be34     `...dr.=...>.v4.
   e9100:	da42 3e0d 47fb 3e9a dc8b be92 7f56 3e6b     B..>.G.>....V.k>
   e9110:	d404 bd88 9e11 3e80 893c 3dff 3eb3 3e88     .......><..=.>.>
   e9120:	f0f7 3e88 fb28 bec9 3e53 3ecf 75ac bedc     ...>(...S>.>.u..
   e9130:	cadd 3ed7 5801 3ea7 b829 bf13 8176 bc12     ...>.X.>)...v...
   e9140:	8b28 bf16 ec0e 3e0e 0a40 bddb ec98 bdbf     (......>@.......
   e9150:	5532 be0c f9fb 3ec9 4a83 be6d 5976 bee2     2U.....>.Jm.vY..
   e9160:	7d54 bb9f e89d 3e95 d35c 3dd0 8a19 3eb0     T}.....>\..=...>
   e9170:	6fde be2e 16d0 3d83 7d9c bf11 cc2b 3c25     .o.....=.}..+.%<
   e9180:	a52a be27 1422 bec7 7a5e 3eac 414e be94     *.'."...^z.>NA..
   e9190:	685a 3e7b fd86 3e4e 56a2 be6a feca be81     Zh{>..N>.Vj.....
   e91a0:	c343 bdb1 b8c5 3ea7 2355 3ecd 2eaf 3e76     C......>U#.>..v>
   e91b0:	a869 be90 ba0d 3eb9 ff66 ffff 0004 0000     i......>f.......
   e91c0:	0040 0000 d653 3de2 b666 3ecc e703 3ef6     @...S..=f..>...>
   e91d0:	28e0 bf10 0000 0000 3d3e 3eb0 0000 0000     .(......>=.>....
   e91e0:	f062 3e77 9da6 3ea4 4b3a bef3 9e71 3ea7     b.w>...>:K..q..>
   e91f0:	0000 0000 3934 3ea2 0000 0000 9ccc 3e4a     ....49.>......J>
   e9200:	40ab 3ea3 ffb2 ffff 0004 0000 0040 0000     .@.>........@...
   e9210:	71b3 3f67 7a9a bf95 48e1 bee8 728a 3e96     .qg?.z...H...r.>
   e9220:	d200 bbd3 c51a 3fd7 7eac bec8 a790 be95     .......?.~......
   e9230:	d73b bedc a841 3f16 5b50 3fcb b952 beed     ;...A..?P[.?R...
   e9240:	a72e bec6 0faf bf14 dab3 3f59 ec02 bed7     ..........Y?....
   e9250:	0000 0006 0008 0004 0006 0000 0004 0000     ................
   e9260:	0004 0000 1166 bf1f fbb8 ffff 000f 0000     ....f...........
   e9270:	4f54 4f43 4320 6e6f 6576 7472 6465 002e     TOCO Converted..
   e9280:	0001 0000 0010 0000 000c 0014 0004 0008     ................
   e9290:	000c 0010 000c 0000 00f0 0000 00e4 0000     ................
   e92a0:	00d8 0000 0004 0000 0003 0000 0090 0000     ................
   e92b0:	0048 0000 0004 0000 ffce ffff 0000 0800     H...............
   e92c0:	0018 0000 000c 0000 0004 0000 fc1c ffff     ................
   e92d0:	0001 0000 0000 0000 0003 0000 0007 0000     ................
   e92e0:	0008 0000 0009 0000 0000 000e 0014 0000     ................
   e92f0:	0008 000c 0007 0010 000e 0000 0000 0800     ................
   e9300:	001c 0000 0010 0000 0004 0000 ffba ffff     ................
   e9310:	0000 0100 0001 0000 0007 0000 0003 0000     ................
   e9320:	0004 0000 0005 0000 0006 0000 0000 000e     ................
   e9330:	0016 0000 0008 000c 0007 0010 000e 0000     ................
   e9340:	0000 0800 0024 0000 0018 0000 000c 0000     ....$...........
   e9350:	0000 0006 0008 0007 0006 0000 0000 0100     ................
   e9360:	0001 0000 0004 0000 0003 0000 0001 0000     ................
   e9370:	0002 0000 0003 0000 0001 0000 0000 0000     ................
   e9380:	0001 0000 0001 0000 000a 0000 0310 0000     ................
   e9390:	02a4 0000 0240 0000 01f4 0000 01ac 0000     ....@...........
   e93a0:	0148 0000 00fc 0000 00b4 0000 0050 0000     H...........P...
   e93b0:	0004 0000 fd26 ffff 003c 0000 0001 0000     ....&...<.......
   e93c0:	000c 0000 0004 0000 fd18 ffff 0020 0000     ............ ...
   e93d0:	6573 7571 6e65 6974 6c61 315f 642f 6e65     sequential_1/den
   e93e0:	6573 345f 4d2f 7461 754d 5f6c 6962 7361     se_4/MatMul_bias
   e93f0:	0000 0000 0001 0000 0001 0000 fd6e ffff     ............n...
   e9400:	0050 0000 0002 0000 000c 0000 0004 0000     P...............
   e9410:	fd60 ffff 0034 0000 6573 7571 6e65 6974     `...4...sequenti
   e9420:	6c61 315f 642f 6e65 6573 345f 4d2f 7461     al_1/dense_4/Mat
   e9430:	754d 2f6c 6552 6461 6156 6972 6261 656c     Mul/ReadVariable
   e9440:	704f 742f 6172 736e 6f70 6573 0000 0000     Op/transpose....
   e9450:	0002 0000 0001 0000 0010 0000 fdce ffff     ................
   e9460:	0034 0000 0008 0000 000c 0000 0004 0000     4...............
   e9470:	fdc0 ffff 0019 0000 6573 7571 6e65 6974     ........sequenti
   e9480:	6c61 315f 642f 6e65 6573 335f 522f 6c65     al_1/dense_3/Rel
   e9490:	0075 0000 0002 0000 0001 0000 0010 0000     u...............
   e94a0:	fe12 ffff 003c 0000 0003 0000 000c 0000     ....<...........
   e94b0:	0004 0000 fe04 ffff 0020 0000 6573 7571     ........ ...sequ
   e94c0:	6e65 6974 6c61 315f 642f 6e65 6573 335f     ential_1/dense_3
   e94d0:	4d2f 7461 754d 5f6c 6962 7361 0000 0000     /MatMul_bias....
   e94e0:	0001 0000 0010 0000 fe5a ffff 0050 0000     ........Z...P...
   e94f0:	0004 0000 000c 0000 0004 0000 fe4c ffff     ............L...
   e9500:	0034 0000 6573 7571 6e65 6974 6c61 315f     4...sequential_1
   e9510:	642f 6e65 6573 335f 4d2f 7461 754d 2f6c     /dense_3/MatMul/
   e9520:	6552 6461 6156 6972 6261 656c 704f 742f     ReadVariableOp/t
   e9530:	6172 736e 6f70 6573 0000 0000 0002 0000     ranspose........
   e9540:	0010 0000 0010 0000 feba ffff 0034 0000     ............4...
   e9550:	000a 0000 000c 0000 0004 0000 feac ffff     ................
   e9560:	0019 0000 6573 7571 6e65 6974 6c61 315f     ....sequential_1
   e9570:	642f 6e65 6573 325f 522f 6c65 0075 0000     /dense_2/Relu...
   e9580:	0002 0000 0001 0000 0010 0000 fefe ffff     ................
   e9590:	003c 0000 0005 0000 000c 0000 0004 0000     <...............
   e95a0:	fef0 ffff 0020 0000 6573 7571 6e65 6974     .... ...sequenti
   e95b0:	6c61 315f 642f 6e65 6573 325f 4d2f 7461     al_1/dense_2/Mat
   e95c0:	754d 5f6c 6962 7361 0000 0000 0001 0000     Mul_bias........
   e95d0:	0010 0000 ff46 ffff 0050 0000 0006 0000     ....F...P.......
   e95e0:	000c 0000 0004 0000 ff38 ffff 0034 0000     ........8...4...
   e95f0:	6573 7571 6e65 6974 6c61 315f 642f 6e65     sequential_1/den
   e9600:	6573 325f 4d2f 7461 754d 2f6c 6552 6461     se_2/MatMul/Read
   e9610:	6156 6972 6261 656c 704f 742f 6172 736e     VariableOp/trans
   e9620:	6f70 6573 0000 0000 0002 0000 0010 0000     pose............
   e9630:	0001 0000 ffa6 ffff 0048 0000 0009 0000     ........H.......
   e9640:	002c 0000 000c 0000 0008 000c 0004 0008     ,...............
   e9650:	0008 0000 0010 0000 0004 0000 0001 0000     ................
   e9660:	0000 437f 0001 0000 0000 0000 000d 0000     ...C............
   e9670:	6564 736e 5f65 5f32 6e69 7570 0074 0000     dense_2_input...
   e9680:	0002 0000 0001 0000 0001 0000 0000 000e     ................
   e9690:	0014 0004 0000 0008 000c 0010 000e 0000     ................
   e96a0:	0028 0000 0007 0000 0010 0000 0008 0000     (...............
   e96b0:	0004 0004 0004 0000 0008 0000 6449 6e65     ............Iden
   e96c0:	6974 7974 0000 0000 0002 0000 0001 0000     tity............
   e96d0:	0001 0000 0001 0000 0010 0000 0000 000a     ................
   e96e0:	000c 0007 0000 0008 000a 0000 0000 0900     ................
   e96f0:	0003 0000 6e49 6f76 656b 6620 6961 656c     ....Invoke faile
   e9700:	2064 6e6f 7820 765f 6c61 203a 6625 000a     d on x_val: %f..
   e9710:	4654 694c 6574 6620 726f 5020 7261 6974     TFLite for Parti
   e9720:	6c63 0065 6f4d 6564 206c 7270 766f 6469     cle.Model provid
   e9730:	6465 6920 2073 6373 6568 616d 7620 7265     ed is schema ver
   e9740:	6973 6e6f 2520 2064 6f6e 2074 7165 6175     sion %d not equa
   e9750:	206c 6f74 7320 7075 6f70 7472 6465 7620     l to supported v
   e9760:	7265 6973 6e6f 2520 2e64 4100 6c6c 636f     ersion %d..Alloc
   e9770:	7461 5465 6e65 6f73 7372 2928 6620 6961     ateTensors() fai
   e9780:	656c 0064 6c46 7461 7542 6666 7265 2073     led.FlatBuffers 
   e9790:	2e31 3131 302e 0000                         1.11.0..

000e9798 <_ZTV12Adafruit_GFX>:
	...
   e97a8:	4d1d 000d 5a81 000e 40bd 000d 4697 000d     .M...Z...@...F..
   e97b8:	464d 000d 467f 000d 465b 000d 466d 000d     MF...F..[F..mF..
   e97c8:	458d 000d 4697 000d 4877 000d 4875 000d     .E...F..wH..uH..
   e97d8:	4699 000d 46d7 000d 4711 000d 4757 000d     .F...F...G..WG..
   e97e8:	4773 000d 47f5 000d                         sG...G..

000e97f0 <_ZL4font>:
   e97f0:	0000 0000 3e00 4f5b 3e5b 6b3e 6b4f 1c3e     .....>[O[>>kOk>.
   e9800:	7c3e 1c3e 3c18 3c7e 1c18 7d57 1c57 5e1c     >|>..<~<..W}W..^
   e9810:	5e7f 001c 3c18 0018 e7ff e7c3 00ff 2418     .^...<.........$
   e9820:	0018 e7ff e7db 30ff 3a48 0e06 2926 2979     .......0H:..&)y)
   e9830:	4026 057f 0705 7f40 2505 5a3f e73c 5a3c     &@....@..%?Z<.<Z
   e9840:	3e7f 1c1c 0808 1c1c 7f3e 2214 227f 5f14     .>......>.."."._
   e9850:	005f 5f5f 0906 017f 007f 8966 6a95 6060     _.__......f..j``
   e9860:	6060 9460 ffa2 94a2 0408 047e 1008 7e20     ```.......~... ~
   e9870:	1020 0808 1c2a 0808 2a1c 0808 101e 1010      ...*....*......
   e9880:	0c10 0c1e 0c1e 3830 383e 0630 3e0e 060e     ......08>80..>..
   e9890:	0000 0000 0000 5f00 0000 0700 0700 1400     ......._........
   e98a0:	147f 147f 2a24 2a7f 2312 0813 6264 4936     ....$*.*.#..db6I
   e98b0:	2056 0050 0708 0003 1c00 4122 0000 2241     V P......."A..A"
   e98c0:	001c 1c2a 1c7f 082a 3e08 0808 8000 3070     ..*...*..>....p0
   e98d0:	0800 0808 0808 0000 6060 2000 0810 0204     ........``. ....
   e98e0:	513e 4549 003e 7f42 0040 4972 4949 2146     >QIE>.B.@.rIIIF!
   e98f0:	4941 334d 1418 7f12 2710 4545 3945 4a3c     AIM3.....'EEE9<J
   e9900:	4949 4131 1121 0709 4936 4949 4636 4949     II1A!...6III6FII
   e9910:	1e29 0000 0014 0000 3440 0000 0800 2214     ).......@4....."
   e9920:	1441 1414 1414 4100 1422 0208 5901 0609     A......A"....Y..
   e9930:	413e 595d 7c4e 1112 7c12 497f 4949 3e36     >A]YN|...|.III6>
   e9940:	4141 2241 417f 4141 7f3e 4949 4149 097f     AAA".AAA>.IIIA..
   e9950:	0909 3e01 4141 7351 087f 0808 007f 7f41     ...>AAQs......A.
   e9960:	0041 4020 3f41 7f01 1408 4122 407f 4040     A. @A?...."A.@@@
   e9970:	7f40 1c02 7f02 047f 1008 3e7f 4141 3e41     @..........>AAA>
   e9980:	097f 0909 3e06 5141 5e21 097f 2919 2646     .....>AQ!^...)F&
   e9990:	4949 3249 0103 017f 3f03 4040 3f40 201f     III2.....?@@@?. 
   e99a0:	2040 3f1f 3840 3f40 1463 1408 0363 7804     @ .?@8@?c...c..x
   e99b0:	0304 5961 4d49 0043 417f 4141 0402 1008     ..aYIMC..AAA....
   e99c0:	0020 4141 7f41 0204 0201 4004 4040 4040      .AAA......@@@@@
   e99d0:	0300 0807 2000 5454 4078 287f 4444 3838     ..... TTx@.(DD88
   e99e0:	4444 2844 4438 2844 387f 5454 1854 0800     DDD(8DD(.8TTT...
   e99f0:	097e 1802 a4a4 789c 087f 0404 0078 7d44     ~......x....x.D}
   e9a00:	0040 4020 3d40 7f00 2810 0044 4100 407f     @. @@=...(D..A.@
   e9a10:	7c00 7804 7804 087c 0404 3878 4444 3844     .|.x.x|...x8DDD8
   e9a20:	18fc 2424 1818 2424 fc18 087c 0404 4808     ..$$..$$..|....H
   e9a30:	5454 2454 0404 443f 3c24 4040 7c20 201c     TTT$..?D$<@@ |. 
   e9a40:	2040 3c1c 3040 3c40 2844 2810 4c44 9090     @ .<@0@<D(.(DL..
   e9a50:	7c90 6444 4c54 0044 3608 0041 0000 0077     .|DdTLD..6A...w.
   e9a60:	0000 3641 0008 0102 0402 3c02 2326 3c26     ..A6.......<&#&<
   e9a70:	a11e 61a1 3a12 4040 7a20 5438 5554 2159     ...a.:@@ z8TTUY!
   e9a80:	5555 4179 5422 7854 2142 5455 4078 5420     UUyA"TTxB!UTx@ T
   e9a90:	7955 0c40 521e 1272 5539 5555 3959 5454     Uy@..Rr.9UUUY9TT
   e9aa0:	5954 5539 5454 0058 4500 417c 0200 7d45     TY9UTTX..E|A..E}
   e9ab0:	0042 4501 407c 127d 1211 f07d 2528 f028     B..E|@}...}.(%(.
   e9ac0:	547c 4555 2000 5454 547c 0a7c 7f09 3249     |TUE. TT|T|...I2
   e9ad0:	4949 3249 443a 4444 323a 484a 3048 413a     III2:DDD:2JHH0:A
   e9ae0:	2141 3a7a 4042 7820 9d00 a0a0 3d7d 4242     A!z:B@ x....}=BB
   e9af0:	3d42 403d 4040 3c3d ff24 2424 7e48 4349     B==@@@=<$.$$H~IC
   e9b00:	2b66 fc2f 2b2f 09ff f629 c020 7e88 0309     f+/./+..). ..~..
   e9b10:	5420 7954 0041 4400 417d 4830 4a48 3832      TTyA..D}A0HHJ28
   e9b20:	4040 7a22 7a00 0a0a 7d72 190d 7d31 2926     @@"z.z..r}..1}&)
   e9b30:	2f29 2628 2929 2629 4830 404d 3820 0808     )/(&)))&0HM@ 8..
   e9b40:	0808 0808 0808 2f38 c810 baac 102f 3428     ......8/..../.(4
   e9b50:	00fa 7b00 0000 1408 142a 2222 2a14 0814     ...{....*."".*..
   e9b60:	0055 0055 aa55 aa55 aa55 55ff 55ff 00ff     U.U.U.U.U..U.U..
   e9b70:	0000 00ff 1010 ff10 1400 1414 00ff 1010     ................
   e9b80:	00ff 10ff f010 f010 1414 fc14 1400 f714     ................
   e9b90:	ff00 0000 00ff 14ff f414 fc04 1414 1017     ................
   e9ba0:	101f 1f10 1f10 1414 1f14 1000 1010 00f0     ................
   e9bb0:	0000 1f00 1010 1010 101f 1010 f010 0010     ................
   e9bc0:	0000 10ff 1010 1010 1010 1010 10ff 0000     ................
   e9bd0:	ff00 0014 ff00 ff00 0000 101f 0017 fc00     ................
   e9be0:	f404 1414 1017 1417 f414 f404 0000 00ff     ................
   e9bf0:	14f7 1414 1414 1414 00f7 14f7 1414 1417     ................
   e9c00:	1010 101f 141f 1414 14f4 1010 10f0 00f0     ................
   e9c10:	1f00 1f10 0000 1f00 0014 0000 14fc 0000     ................
   e9c20:	10f0 10f0 ff10 ff10 1414 ff14 1014 1010     ................
   e9c30:	001f 0000 f000 ff10 ffff ffff f0f0 f0f0     ................
   e9c40:	fff0 ffff 0000 0000 ff00 0fff 0f0f 0f0f     ................
   e9c50:	4438 3844 fc44 4a4a 344a 027e 0602 0206     8DD8D.JJJ4~.....
   e9c60:	027e 027e 5563 4149 3863 4444 043c 7e40     ~.~.cUIAc8DD<.@~
   e9c70:	1e20 0620 7e02 0202 a599 a5e7 1c99 492a      . ..~........*I
   e9c80:	1c2a 724c 7201 304c 4d4a 304d 4830 4878     *.Lr.rL0JMM00HxH
   e9c90:	bc30 5a62 3d46 493e 4949 7e00 0101 7e01     0.bZF=>III.~...~
   e9ca0:	2a2a 2a2a 442a 5f44 4444 5140 444a 4040     *****DD_DD@QJD@@
   e9cb0:	4a44 4051 0000 01ff e003 ff80 0000 0808     DJQ@............
   e9cc0:	6b6b 3608 3612 3624 0f06 0f09 0006 1800     kk.6.6$6........
   e9cd0:	0018 0000 1010 3000 ff40 0101 1f00 0101     .......0@.......
   e9ce0:	001e 1d19 1217 3c00 3c3c 003c 0000 0000     .......<<<<.....

000e9cf0 <_ZTV15Adafruit_SPITFT>:
	...
   e9d00:	4d1d 000d 5a81 000e 4e55 000d 4f33 000d     .M...Z..UN..3O..
   e9d10:	50a3 000d 5193 000d 4e29 000d 4e3f 000d     .P...Q..)N..?N..
   e9d20:	458d 000d 4f23 000d 4877 000d 5129 000d     .E..#O..wH..)Q..
   e9d30:	4e81 000d 4eb5 000d 4ee9 000d 4757 000d     .N...N...N..WG..
   e9d40:	4773 000d 47f5 000d 40bd 000d 40bd 000d     sG...G...@...@..

000e9d50 <_ZTV15Adafruit_HX8357>:
	...
   e9d58:	5231 000d 5233 000d 4d1d 000d 5a81 000e     1R..3R...M...Z..
   e9d68:	4e55 000d 4f33 000d 50a3 000d 5193 000d     UN..3O...P...Q..
   e9d78:	4e29 000d 4e3f 000d 458d 000d 4f23 000d     )N..?N...E..#O..
   e9d88:	52f9 000d 5241 000d 4e81 000d 4eb5 000d     .R..AR...N...N..
   e9d98:	4ee9 000d 4757 000d 4773 000d 47f5 000d     .N..WG..sG...G..
   e9da8:	5269 000d 535d 000d                         iR..]S..

000e9db0 <_ZL5initb>:
   e9db0:	03d0 4144 d106 4002 d210 0502 c012 1405     ..DA...@........
   e9dc0:	003b 1102 01c5 e90c 0101 03ea 0003 eb00     ;...............
   e9dd0:	4004 2654 c8db 000c 0015 0022 7708 6626     .@T&......"..w&f
   e9de0:	0422 3600 c001 013a 2b55 0004 0100 2adf     "..6..:.U+.....*
   e9df0:	0004 0100 b43f 0001 9811 8229 0100               ....?.....)..

000e9dfd <_ZL5initd>:
   e9dfd:	8201 03b9 83ff ff57 b3bc 8004 0600 b606     ......W.........
   e9e0d:	2501 01b0 cc68 0501 06b1 1500 1c1c aa83     .%..h...........
   e9e1d:	06c0 5050 3c01 081e 07b4 4002 2a00 0d2a     ..PP.<.....@.**.
   e9e2d:	e078 0222 110a 231d 4135 4b4b 3a42 1b27     x."....#5AKKB:'.
   e9e3d:	0908 0203 110a 231d 4135 4b4b 3a42 1b27     .......#5AKKB:'.
   e9e4d:	0908 0003 3a01 5501 0136 35c0 0001 0244     .....:.U6..5..D.
   e9e5d:	0200 9e11 8a29 0000                              ....)..

000e9e64 <_ZTVN8particle13__SPISettingsE>:
	...
   e9e6c:	5471 000d 6564 6166 6c75 2074 4d00 4253     qT..default .MSB
   e9e7c:	4c00 4253 3c00 5053 5349 7465 6974 676e     .LSB.<SPISetting
   e9e8c:	2073 6564 6166 6c75 3e74 3c00 5053 5349     s default>.<SPIS
   e9e9c:	7465 6974 676e 2073 7325 6c25 2075 7325     ettings %s%lu %s
   e9eac:	4d20 444f 2545 3e64 6600                          MODE%d>.

000e9eb5 <_ZZNK11flatbuffers6VectorIlE3GetEmE19__PRETTY_FUNCTION__>:
   e9eb5:	6c66 7461 7562 6666 7265 3a73 563a 6365     flatbuffers::Vec
   e9ec5:	6f74 3c72 3e54 3a3a 6572 7574 6e72 745f     tor<T>::return_t
   e9ed5:	7079 2065 6c66 7461 7562 6666 7265 3a73     ype flatbuffers:
   e9ee5:	563a 6365 6f74 3c72 3e54 3a3a 6547 2874     :Vector<T>::Get(
   e9ef5:	6c66 7461 7562 6666 7265 3a73 753a 666f     flatbuffers::uof
   e9f05:	7366 7465 745f 2029 6f63 736e 2074 775b     fset_t) const [w
   e9f15:	7469 2068 2054 203d 6f6c 676e 6920 746e     ith T = long int
   e9f25:	203b 6c66 7461 7562 6666 7265 3a73 563a     ; flatbuffers::V
   e9f35:	6365 6f74 3c72 3e54 3a3a 6572 7574 6e72     ector<T>::return
   e9f45:	745f 7079 2065 203d 6f6c 676e 6920 746e     _type = long int
   e9f55:	203b 6c66 7461 7562 6666 7265 3a73 753a     ; flatbuffers::u
   e9f65:	666f 7366 7465 745f 3d20 6c20 6e6f 2067     offset_t = long 
   e9f75:	6e75 6973 6e67 6465 6920 746e 005d 6e49     unsigned int].In
   e9f85:	7570 2074 7261 6172 2079 6f6e 2074 7270     put array not pr
   e9f95:	766f 6469 6465 6620 726f 6f20 6570 6172     ovided for opera
   e9fa5:	6974 6e6f 2720 7325 2e27 000a 6f46 6e75     tion '%s'...Foun
   e9fb5:	2064 6f74 206f 616d 796e 6420 6d69 6e65     d too many dimen
   e9fc5:	6973 6e6f 2073 6e69 7420 6568 6920 706e     sions in the inp
   e9fd5:	7475 6120 7272 7961 6f20 2066 706f 7265     ut array of oper
   e9fe5:	7461 6f69 206e 2527 2773 0a2e 6900 3c20     ation '%s'...i <
   e9ff5:	7320 7a69 2865 0029 552f 6573 7372 622f      size()./Users/b
   ea005:	6173 7274 6d6f 442f 7665 6c65 706f 656d     satrom/Developme
   ea015:	746e 702f 7261 6974 6c63 2f65 696c 7262     nt/particle/libr
   ea025:	7261 6569 2f73 6150 7472 6369 656c 545f     aries/Particle_T
   ea035:	6e65 6f73 4672 6f6c 4c77 7469 5f65 7845     ensorFlowLite_Ex
   ea045:	6d61 6c70 7365 732f 6e69 5f65 6977 6874     amples/sine_with
   ea055:	735f 7263 6565 2f6e 696c 2f62 6554 736e     _screen/lib/Tens
   ea065:	726f 6c46 776f 694c 6574 732f 6372 742f     orFlowLite/src/t
   ea075:	6968 6472 705f 7261 7974 662f 616c 6274     hird_party/flatb
   ea085:	6675 6566 7372 692f 636e 756c 6564 662f     uffers/include/f
   ea095:	616c 6274 6675 6566 7372 662f 616c 6274     latbuffers/flatb
   ea0a5:	6675 6566 7372 682e 5500 736e 7075 6f70     uffers.h.Unsuppo
   ea0b5:	7472 6465 6420 7461 2061 7974 6570 2520     rted data type %
   ea0c5:	2064 6e69 7420 6e65 6f73 0a72 5500 686e     d in tensor..Unh
   ea0d5:	6e61 6c64 6465 6620 6c75 796c 632d 6e6f     andled fully-con
   ea0e5:	656e 7463 6465 7720 6965 6867 7374 6620     nected weights f
   ea0f5:	726f 616d 2e74 5500 686e 6e61 6c64 6465     ormat..Unhandled
   ea105:	4c20 5453 204d 656b 6e72 6c65 7420 7079      LSTM kernel typ
   ea115:	3a65 2520 0064 6f4e 7620 6c61 6469 4c20     e: %d.No valid L
   ea125:	5453 204d 7562 6c69 6974 206e 706f 6974     STM builtin opti
   ea135:	6e6f 2073 7865 7369 0074 6572 6873 7061     ons exist.reshap
   ea145:	0065 7173 6575 7a65 0065 4544 454c 4147     e.squeeze.DELEGA
   ea155:	4554 6f20 2070 6873 756f 646c 276e 2074     TE op shouldn't 
   ea165:	7865 7369 2074 6e69 6d20 646f 6c65 002e     exist in model..

000ea175 <CSWTCH.73>:
   ea175:	0201 0403 0005 2800                              .......

000ea17c <_ZZN6tflite24EnumNamesBuiltinOperatorEvE5names>:
   ea17c:	a428 000e a42c 000e a43c 000e a454 000e     (...,...<...T...
   ea18c:	a44a 000e a45c 000e a46b 000e a476 000e     J...\...k...v...
   ea19c:	a487 000e a48d 000e a49d 000e a4ae 000e     ................
   ea1ac:	a4bf 000e a4ca 000e a4e7 000e a4f0 000e     ................
   ea1bc:	a679 000e a4ff 000e a50b 000e a684 000e     y...............
   ea1cc:	a50f 000e a51c 000e a522 000e a52a 000e     ........"...*...
   ea1dc:	a637 000e a651 000e a53a 000e a549 000e     7...Q...:...I...
   ea1ec:	a54e 000e a553 000e a565 000e a56f 000e     N...S...e...o...
   ea1fc:	a574 000e a57b 000e a808 000e a593 000e     t...{...........
   ea20c:	a5af 000e a5b6 000e a5c8 000e a5da 000e     ................
   ea21c:	a5e4 000e a5e9 000e a795 000e a5ed 000e     ................
   ea22c:	a5f5 000e a612 000e a620 000e a63b 000e     ........ ...;...
   ea23c:	a63f 000e a647 000e a64d 000e a659 000e     ?...G...M...Y...
   ea24c:	a662 000e a67e 000e a683 000e a689 000e     b...~...........
   ea25c:	a691 000e a699 000e a6a1 000e a6a6 000e     ................
   ea26c:	a6aa 000e a6b0 000e a6b8 000e a6c6 000e     ................
   ea27c:	a6d1 000e a61a 000e a6d8 000e a6dc 000e     ................
   ea28c:	a6eb 000e a6fb 000e a700 000e a6c0 000e     ................
   ea29c:	a70c 000e a716 000e a71a 000e a71f 000e     ................
   ea2ac:	a71e 000e a524 000e a724 000e a728 000e     ....$...$...(...
   ea2bc:	a730 000e a73b 000e a747 000e a77f 000e     0...;...G.......
   ea2cc:	a752 000e a75d 000e a765 000e a771 000e     R...]...e...q...
   ea2dc:	a77d 000e a784 000e a78f 000e a799 000e     }...............
   ea2ec:	a7a4 000e a7ab 000e a7b6 000e a7bb 000e     ................
   ea2fc:	a7c5 000e a7cb 000e a7e3 000e a7ee 000e     ................
   ea30c:	a801 000e a80c 000e a810 000e a818 000e     ................
   ea31c:	a81f 000e a824 000e a82f 000e a835 000e     ....$.../...5...
   ea32c:	a83f 000e a843 000e a849 000e a685 000e     ?...C...I.......
   ea33c:	a84e 000e a85f 000e a46d 000e a86b 000e     N..._...m...k...
   ea34c:	a87b 000e a881 000e a88c 000e a88f 000e     {...............
   ea35c:	a895 000e a8ac 000e 0000 0000 704f 6220     ............Op b
   ea36c:	6975 746c 6e69 635f 646f 2065 756f 2074     uiltin_code out 
   ea37c:	666f 7220 6e61 6567 203a 6425 202e 7241     of range: %d. Ar
   ea38c:	2065 6f79 2075 7375 6e69 2067 6c6f 2064     e you using old 
   ea39c:	4654 694c 6574 6220 6e69 7261 2079 6977     TFLite binary wi
   ea3ac:	6874 6e20 7765 7265 6d20 646f 6c65 003f     th newer model?.
   ea3bc:	6944 6e64 7427 6620 6e69 2064 706f 6620     Didn't find op f
   ea3cc:	726f 6220 6975 746c 6e69 6f20 6370 646f     or builtin opcod
   ea3dc:	2065 2527 2773 7620 7265 6973 6e6f 2720     e '%s' version '
   ea3ec:	6425 0a27 4f00 6570 6172 6f74 2072 6977     %d'..Operator wi
   ea3fc:	6874 4320 5355 4f54 204d 7562 6c69 6974     th CUSTOM builti
   ea40c:	5f6e 6f63 6564 6820 7361 6e20 206f 7563     n_code has no cu
   ea41c:	7473 6d6f 635f 646f 2e65 000a 4441 0044     stom_code...ADD.
   ea42c:	5641 5245 4741 5f45 4f50 4c4f 325f 0044     AVERAGE_POOL_2D.
   ea43c:	4f43 434e 5441 4e45 5441 4f49 004e 4544     CONCATENATION.DE
   ea44c:	5450 5748 5349 5f45 4f43 564e 325f 0044     PTHWISE_CONV_2D.
   ea45c:	4544 5450 5f48 4f54 535f 4150 4543 4400     DEPTH_TO_SPACE.D
   ea46c:	5145 4155 544e 5a49 0045 4d45 4542 4444     EQUANTIZE.EMBEDD
   ea47c:	4e49 5f47 4f4c 4b4f 5055 4600 4f4c 524f     ING_LOOKUP.FLOOR
   ea48c:	4600 4c55 594c 435f 4e4f 454e 5443 4445     .FULLY_CONNECTED
   ea49c:	4800 5341 5448 4241 454c 4c5f 4f4f 554b     .HASHTABLE_LOOKU
   ea4ac:	0050 324c 4e5f 524f 414d 494c 415a 4954     P.L2_NORMALIZATI
   ea4bc:	4e4f 4c00 5f32 4f50 4c4f 325f 0044 4f4c     ON.L2_POOL_2D.LO
   ea4cc:	4143 5f4c 4552 5053 4e4f 4553 4e5f 524f     CAL_RESPONSE_NOR
   ea4dc:	414d 494c 415a 4954 4e4f 4c00 474f 5349     MALIZATION.LOGIS
   ea4ec:	4954 0043 534c 5f48 5250 4a4f 4345 4954     TIC.LSH_PROJECTI
   ea4fc:	4e4f 4d00 5841 505f 4f4f 5f4c 4432 4d00     ON.MAX_POOL_2D.M
   ea50c:	4c55 5200 4c45 5f55 314e 545f 5f4f 0031     UL.RELU_N1_TO_1.
   ea51c:	4552 554c 0036 4552 4853 5041 0045 4552     RELU6.RESHAPE.RE
   ea52c:	4953 455a 425f 4c49 4e49 4145 0052 5053     SIZE_BILINEAR.SP
   ea53c:	4341 5f45 4f54 445f 5045 4854 5300 4456     ACE_TO_DEPTH.SVD
   ea54c:	0046 4154 484e 4300 4e4f 4143 5f54 4d45     F.TANH.CONCAT_EM
   ea55c:	4542 4444 4e49 5347 5300 494b 5f50 5247     BEDDINGS.SKIP_GR
   ea56c:	4d41 4300 4c41 004c 5543 5453 4d4f 4500     AM.CALL.CUSTOM.E
   ea57c:	424d 4445 4944 474e 4c5f 4f4f 554b 5f50     MBEDDING_LOOKUP_
   ea58c:	5053 5241 4553 5500 494e 4944 4552 5443     SPARSE.UNIDIRECT
   ea59c:	4f49 414e 5f4c 4553 5551 4e45 4543 525f     IONAL_SEQUENCE_R
   ea5ac:	4e4e 4700 5441 4548 0052 4142 4354 5f48     NN.GATHER.BATCH_
   ea5bc:	4f54 535f 4150 4543 4e5f 0044 5053 4341     TO_SPACE_ND.SPAC
   ea5cc:	5f45 4f54 425f 5441 4843 4e5f 0044 5254     E_TO_BATCH_ND.TR
   ea5dc:	4e41 5053 534f 0045 454d 4e41 5300 4255     ANSPOSE.MEAN.SUB
   ea5ec:	5300 5551 4545 455a 5500 494e 4944 4552     .SQUEEZE.UNIDIRE
   ea5fc:	5443 4f49 414e 5f4c 4553 5551 4e45 4543     CTIONAL_SEQUENCE
   ea60c:	4c5f 5453 004d 5453 4952 4544 5f44 4c53     _LSTM.STRIDED_SL
   ea61c:	4349 0045 4942 4944 4552 5443 4f49 414e     ICE.BIDIRECTIONA
   ea62c:	5f4c 4553 5551 4e45 4543 525f 4e4e 4500     L_SEQUENCE_RNN.E
   ea63c:	5058 5400 504f 5f4b 3256 5300 4c50 5449     XP.TOPK_V2.SPLIT
   ea64c:	4c00 474f 535f 464f 4d54 5841 4400 4c45     .LOG_SOFTMAX.DEL
   ea65c:	4745 5441 0045 4942 4944 4552 5443 4f49     EGATE.BIDIRECTIO
   ea66c:	414e 5f4c 4553 5551 4e45 4543 4c5f 5453     NAL_SEQUENCE_LST
   ea67c:	004d 4143 5453 5000 4552 554c 4d00 5841     M.CAST.PRELU.MAX
   ea68c:	4d49 4d55 4100 4752 4d5f 5841 4d00 4e49     IMUM.ARG_MAX.MIN
   ea69c:	4d49 4d55 4c00 5345 0053 454e 0047 4150     IMUM.LESS.NEG.PA
   ea6ac:	5644 0032 5247 4145 4554 0052 5247 4145     DV2.GREATER.GREA
   ea6bc:	4554 5f52 5145 4155 004c 454c 5353 455f     TER_EQUAL.LESS_E
   ea6cc:	5551 4c41 5300 4c45 4345 0054 4953 004e     QUAL.SELECT.SIN.
   ea6dc:	5254 4e41 5053 534f 5f45 4f43 564e 5300     TRANSPOSE_CONV.S
   ea6ec:	4150 5352 5f45 4f54 445f 4e45 4553 5400     PARSE_TO_DENSE.T
   ea6fc:	4c49 0045 5845 4150 444e 445f 4d49 0053     ILE.EXPAND_DIMS.
   ea70c:	4f4e 5f54 5145 4155 004c 4f4c 0047 5553     NOT_EQUAL.LOG.SU
   ea71c:	004d 5352 5251 0054 4f50 0057 5241 5f47     M.RSQRT.POW.ARG_
   ea72c:	494d 004e 4146 454b 515f 4155 544e 5200     MIN.FAKE_QUANT.R
   ea73c:	4445 4355 5f45 5250 444f 5200 4445 4355     EDUCE_PROD.REDUC
   ea74c:	5f45 414d 0058 4f4c 4947 4143 5f4c 524f     E_MAX.LOGICAL_OR
   ea75c:	4f00 454e 485f 544f 4c00 474f 4349 4c41     .ONE_HOT.LOGICAL
   ea76c:	415f 444e 4c00 474f 4349 4c41 4e5f 544f     _AND.LOGICAL_NOT
   ea77c:	5500 504e 4341 004b 4552 5544 4543 4d5f     .UNPACK.REDUCE_M
   ea78c:	4e49 4600 4f4c 524f 445f 5649 5200 4445     IN.FLOOR_DIV.RED
   ea79c:	4355 5f45 4e41 0059 5153 4155 4552 5a00     UCE_ANY.SQUARE.Z
   ea7ac:	5245 534f 4c5f 4b49 0045 4946 4c4c 4600     EROS_LIKE.FILL.F
   ea7bc:	4f4c 524f 4d5f 444f 5200 4e41 4547 5200     LOOR_MOD.RANGE.R
   ea7cc:	5345 5a49 5f45 454e 5241 5345 5f54 454e     ESIZE_NEAREST_NE
   ea7dc:	4749 4248 524f 4c00 4145 594b 525f 4c45     IGHBOR.LEAKY_REL
   ea7ec:	0055 5153 4155 4552 5f44 4944 4646 5245     U.SQUARED_DIFFER
   ea7fc:	4e45 4543 4d00 5249 4f52 5f52 4150 0044     ENCE.MIRROR_PAD.
   ea80c:	4241 0053 5053 494c 5f54 0056 4e55 5149     ABS.SPLIT_V.UNIQ
   ea81c:	4555 4300 4945 004c 4552 4556 5352 5f45     UE.CEIL.REVERSE_
   ea82c:	3256 4100 4444 4e5f 4700 5441 4548 5f52     V2.ADD_N.GATHER_
   ea83c:	444e 4300 534f 5700 4548 4552 5200 4e41     ND.COS.WHERE.RAN
   ea84c:	004b 4552 4556 5352 5f45 4553 5551 4e45     K.REVERSE_SEQUEN
   ea85c:	4543 4d00 5441 4952 5f58 4944 4741 4d00     CE.MATRIX_DIAG.M
   ea86c:	5441 4952 5f58 4553 5f54 4944 4741 5200     ATRIX_SET_DIAG.R
   ea87c:	554f 444e 4800 5241 5f44 5753 5349 0048     OUND.HARD_SWISH.
   ea88c:	4649 5700 4948 454c 4e00 4e4f 4d5f 5841     IF.WHILE.NON_MAX
   ea89c:	535f 5055 5250 5345 4953 4e4f 565f 0034     _SUPPRESSION_V4.
   ea8ac:	4f4e 5f4e 414d 5f58 5553 5050 4552 5353     NON_MAX_SUPPRESS
   ea8bc:	4f49 5f4e 3556 0300 0804 0d0b 110e 1312     ION_V5..........
   ea8cc:	1514 1716 6e49 0066 614e 004e 322a 005e     ....Inf.NaN.*2^.
   ea8dc:	7954 6570 2520 2073 2528 2964 6e20 746f     Type %s (%d) not
   ea8ec:	6920 2073 6f6e 2074 7573 7070 726f 6574      is not supporte
   ea8fc:	0064                                        d.

000ea8fe <_ZZNK11flatbuffers6VectorIlE3GetEmE19__PRETTY_FUNCTION__>:
   ea8fe:	6c66 7461 7562 6666 7265 3a73 563a 6365     flatbuffers::Vec
   ea90e:	6f74 3c72 3e54 3a3a 6572 7574 6e72 745f     tor<T>::return_t
   ea91e:	7079 2065 6c66 7461 7562 6666 7265 3a73     ype flatbuffers:
   ea92e:	563a 6365 6f74 3c72 3e54 3a3a 6547 2874     :Vector<T>::Get(
   ea93e:	6c66 7461 7562 6666 7265 3a73 753a 666f     flatbuffers::uof
   ea94e:	7366 7465 745f 2029 6f63 736e 2074 775b     fset_t) const [w
   ea95e:	7469 2068 2054 203d 6f6c 676e 6920 746e     ith T = long int
   ea96e:	203b 6c66 7461 7562 6666 7265 3a73 563a     ; flatbuffers::V
   ea97e:	6365 6f74 3c72 3e54 3a3a 6572 7574 6e72     ector<T>::return
   ea98e:	745f 7079 2065 203d 6f6c 676e 6920 746e     _type = long int
   ea99e:	203b 6c66 7461 7562 6666 7265 3a73 753a     ; flatbuffers::u
   ea9ae:	666f 7366 7465 745f 3d20 6c20 6e6f 2067     offset_t = long 
   ea9be:	6e75 6973 6e67 6465 6920 746e 005d          unsigned int].

000ea9cc <_ZZNK11flatbuffers6VectorINS_6OffsetIN6tflite8OperatorEEEE3GetEmE19__PRETTY_FUNCTION__>:
   ea9cc:	6c66 7461 7562 6666 7265 3a73 563a 6365     flatbuffers::Vec
   ea9dc:	6f74 3c72 3e54 3a3a 6572 7574 6e72 745f     tor<T>::return_t
   ea9ec:	7079 2065 6c66 7461 7562 6666 7265 3a73     ype flatbuffers:
   ea9fc:	563a 6365 6f74 3c72 3e54 3a3a 6547 2874     :Vector<T>::Get(
   eaa0c:	6c66 7461 7562 6666 7265 3a73 753a 666f     flatbuffers::uof
   eaa1c:	7366 7465 745f 2029 6f63 736e 2074 775b     fset_t) const [w
   eaa2c:	7469 2068 2054 203d 6c66 7461 7562 6666     ith T = flatbuff
   eaa3c:	7265 3a73 4f3a 6666 6573 3c74 6674 696c     ers::Offset<tfli
   eaa4c:	6574 3a3a 704f 7265 7461 726f 3b3e 6620     te::Operator>; f
   eaa5c:	616c 6274 6675 6566 7372 3a3a 6556 7463     latbuffers::Vect
   eaa6c:	726f 543c 3a3e 723a 7465 7275 5f6e 7974     or<T>::return_ty
   eaa7c:	6570 3d20 6320 6e6f 7473 7420 6c66 7469     pe = const tflit
   eaa8c:	3a65 4f3a 6570 6172 6f74 2a72 203b 6c66     e::Operator*; fl
   eaa9c:	7461 7562 6666 7265 3a73 753a 666f 7366     atbuffers::uoffs
   eaaac:	7465 745f 3d20 6c20 6e6f 2067 6e75 6973     et_t = long unsi
   eaabc:	6e67 6465 6920 746e 005d                    gned int].

000eaac6 <_ZZNK11flatbuffers6VectorINS_6OffsetIN6tflite6TensorEEEE3GetEmE19__PRETTY_FUNCTION__>:
   eaac6:	6c66 7461 7562 6666 7265 3a73 563a 6365     flatbuffers::Vec
   eaad6:	6f74 3c72 3e54 3a3a 6572 7574 6e72 745f     tor<T>::return_t
   eaae6:	7079 2065 6c66 7461 7562 6666 7265 3a73     ype flatbuffers:
   eaaf6:	563a 6365 6f74 3c72 3e54 3a3a 6547 2874     :Vector<T>::Get(
   eab06:	6c66 7461 7562 6666 7265 3a73 753a 666f     flatbuffers::uof
   eab16:	7366 7465 745f 2029 6f63 736e 2074 775b     fset_t) const [w
   eab26:	7469 2068 2054 203d 6c66 7461 7562 6666     ith T = flatbuff
   eab36:	7265 3a73 4f3a 6666 6573 3c74 6674 696c     ers::Offset<tfli
   eab46:	6574 3a3a 6554 736e 726f 3b3e 6620 616c     te::Tensor>; fla
   eab56:	6274 6675 6566 7372 3a3a 6556 7463 726f     tbuffers::Vector
   eab66:	543c 3a3e 723a 7465 7275 5f6e 7974 6570     <T>::return_type
   eab76:	3d20 6320 6e6f 7473 7420 6c66 7469 3a65      = const tflite:
   eab86:	543a 6e65 6f73 2a72 203b 6c66 7461 7562     :Tensor*; flatbu
   eab96:	6666 7265 3a73 753a 666f 7366 7465 745f     ffers::uoffset_t
   eaba6:	3d20 6c20 6e6f 2067 6e75 6973 6e67 6465      = long unsigned
   eabb6:	6920 746e 005d 6e4f 796c 3120 7320 6275      int].Only 1 sub
   eabc6:	7267 7061 2068 7369 6320 7275 6572 746e     graph is current
   eabd6:	796c 7320 7075 6f70 7472 6465 0a2e 3c00     ly supported...<
   eabe6:	6f4e 6e20 6d61 3e65 4900 766e 6c61 6469     No name>.Invalid
   eabf6:	7020 6572 612d 6c6c 636f 7461 6465 6920      pre-allocated i
   eac06:	706e 7475 2520 2064 7270 766f 6469 6465     nput %d provided
   eac16:	002e 7241 6e65 2061 6973 657a 6920 2073     ..Arena size is 
   eac26:	6f74 206f 6d73 6c61 206c 6f66 2072 6361     too small for ac
   eac36:	6974 6176 6974 6e6f 6220 6675 6566 7372     tivation buffers
   eac46:	202e 654e 6465 6465 2520 2064 7562 2074     . Needed %d but 
   eac56:	6e6f 796c 2520 2064 6177 2073 7661 6961     only %d was avai
   eac66:	616c 6c62 2e65 5600 7261 6169 6c62 2065     lable..Variable 
   eac76:	7369 6e20 746f 6120 6c6c 636f 7461 6465     is not allocated
   eac86:	4c00 676f 6369 6520 7272 726f 6920 206e     .Logic error in 
   eac96:	656d 6f6d 7972 7020 616c 6e6e 7265 202c     memory planner, 
   eaca6:	6574 736e 726f 2520 2064 6168 2073 6e61     tensor %d has an
   eacb6:	6920 766e 6c61 6469 6c20 6669 7465 6d69      invalid lifetim
   eacc6:	0065                                        e.

000eacc8 <_ZZNK11flatbuffers6VectorIfE3GetEmE19__PRETTY_FUNCTION__>:
   eacc8:	6c66 7461 7562 6666 7265 3a73 563a 6365     flatbuffers::Vec
   eacd8:	6f74 3c72 3e54 3a3a 6572 7574 6e72 745f     tor<T>::return_t
   eace8:	7079 2065 6c66 7461 7562 6666 7265 3a73     ype flatbuffers:
   eacf8:	563a 6365 6f74 3c72 3e54 3a3a 6547 2874     :Vector<T>::Get(
   ead08:	6c66 7461 7562 6666 7265 3a73 753a 666f     flatbuffers::uof
   ead18:	7366 7465 745f 2029 6f63 736e 2074 775b     fset_t) const [w
   ead28:	7469 2068 2054 203d 6c66 616f 3b74 6620     ith T = float; f
   ead38:	616c 6274 6675 6566 7372 3a3a 6556 7463     latbuffers::Vect
   ead48:	726f 543c 3a3e 723a 7465 7275 5f6e 7974     or<T>::return_ty
   ead58:	6570 3d20 6620 6f6c 7461 203b 6c66 7461     pe = float; flat
   ead68:	7562 6666 7265 3a73 753a 666f 7366 7465     buffers::uoffset
   ead78:	745f 3d20 6c20 6e6f 2067 6e75 6973 6e67     _t = long unsign
   ead88:	6465 6920 746e 005d                         ed int].

000ead90 <_ZZNK11flatbuffers6VectorINS_6OffsetIN6tflite6BufferEEEE3GetEmE19__PRETTY_FUNCTION__>:
   ead90:	6c66 7461 7562 6666 7265 3a73 563a 6365     flatbuffers::Vec
   eada0:	6f74 3c72 3e54 3a3a 6572 7574 6e72 745f     tor<T>::return_t
   eadb0:	7079 2065 6c66 7461 7562 6666 7265 3a73     ype flatbuffers:
   eadc0:	563a 6365 6f74 3c72 3e54 3a3a 6547 2874     :Vector<T>::Get(
   eadd0:	6c66 7461 7562 6666 7265 3a73 753a 666f     flatbuffers::uof
   eade0:	7366 7465 745f 2029 6f63 736e 2074 775b     fset_t) const [w
   eadf0:	7469 2068 2054 203d 6c66 7461 7562 6666     ith T = flatbuff
   eae00:	7265 3a73 4f3a 6666 6573 3c74 6674 696c     ers::Offset<tfli
   eae10:	6574 3a3a 7542 6666 7265 3b3e 6620 616c     te::Buffer>; fla
   eae20:	6274 6675 6566 7372 3a3a 6556 7463 726f     tbuffers::Vector
   eae30:	543c 3a3e 723a 7465 7275 5f6e 7974 6570     <T>::return_type
   eae40:	3d20 6320 6e6f 7473 7420 6c66 7469 3a65      = const tflite:
   eae50:	423a 6675 6566 2a72 203b 6c66 7461 7562     :Buffer*; flatbu
   eae60:	6666 7265 3a73 753a 666f 7366 7465 745f     ffers::uoffset_t
   eae70:	3d20 6c20 6e6f 2067 6e75 6973 6e67 6465      = long unsigned
   eae80:	6920 746e 005d                               int].

000eae86 <_ZZNK11flatbuffers6VectorIxE3GetEmE19__PRETTY_FUNCTION__>:
   eae86:	6c66 7461 7562 6666 7265 3a73 563a 6365     flatbuffers::Vec
   eae96:	6f74 3c72 3e54 3a3a 6572 7574 6e72 745f     tor<T>::return_t
   eaea6:	7079 2065 6c66 7461 7562 6666 7265 3a73     ype flatbuffers:
   eaeb6:	563a 6365 6f74 3c72 3e54 3a3a 6547 2874     :Vector<T>::Get(
   eaec6:	6c66 7461 7562 6666 7265 3a73 753a 666f     flatbuffers::uof
   eaed6:	7366 7465 745f 2029 6f63 736e 2074 775b     fset_t) const [w
   eaee6:	7469 2068 2054 203d 6f6c 676e 6c20 6e6f     ith T = long lon
   eaef6:	2067 6e69 3b74 6620 616c 6274 6675 6566     g int; flatbuffe
   eaf06:	7372 3a3a 6556 7463 726f 543c 3a3e 723a     rs::Vector<T>::r
   eaf16:	7465 7275 5f6e 7974 6570 3d20 6c20 6e6f     eturn_type = lon
   eaf26:	2067 6f6c 676e 6920 746e 203b 6c66 7461     g long int; flat
   eaf36:	7562 6666 7265 3a73 753a 666f 7366 7465     buffers::uoffset
   eaf46:	745f 3d20 6c20 6e6f 2067 6e75 6973 6e67     _t = long unsign
   eaf56:	6465 6920 746e 005d 0000                    ed int]...

000eaf60 <_ZTVN6tflite18MicroErrorReporterE>:
	...
   eaf68:	41b1 000d 41c5 000d 6ea9 000d 0a0d 5400     .A...A...n.....T
   eaf78:	6e65 6f73 2072 6e69 6564 2078 6425 6f20     ensor index %d o
   eaf88:	7475 6f20 2066 6172 676e 2065 6c28 6e65     ut of range (len
   eaf98:	7467 2068 7369 2520 2964 4f00 7475 7570     gth is %d).Outpu
   eafa8:	2074 6e69 6564 2078 6425 6f20 7475 6f20     t index %d out o
   eafb8:	2066 6172 676e 2065 6c28 6e65 7467 2068     f range (length 
   eafc8:	7369 2520 2964 4900 706e 7475 6920 646e     is %d).Input ind
   eafd8:	7865 2520 2064 756f 2074 666f 7220 6e61     ex %d out of ran
   eafe8:	6567 2820 656c 676e 6874 6920 2073 6425     ge (length is %d
   eaff8:	0029 6e49 6f76 656b 2928 6320 6c61 656c     ).Invoke() calle
   eb008:	2064 6661 6574 2072 6e69 7469 6169 696c     d after initiali
   eb018:	617a 6974 6e6f 6620 6961 656c 0a64 4d00     zation failed..M
   eb028:	7369 6973 676e 7220 6765 7369 7274 7461     issing registrat
   eb038:	6f69 206e 6f66 2072 706f 6f63 6564 695f     ion for opcode_i
   eb048:	646e 7865 2520 0a64 5300 696b 7070 6e69     ndex %d..Skippin
   eb058:	2067 706f 6620 726f 6f20 6370 646f 5f65     g op for opcode_
   eb068:	6e69 6564 2078 6425 000a 6e55 7573 7070     index %d..Unsupp
   eb078:	726f 6574 2064 6562 6168 6976 726f 203a     orted behavior: 
   eb088:	6f66 6e75 2064 7562 6c69 6974 206e 706f     found builtin op
   eb098:	7265 7461 726f 2520 2073 6977 6874 6320     erator %s with c
   eb0a8:	7375 6f74 206d 706f 6974 6e6f 2e73 000a     ustom options...
   eb0b8:	6f4e 6564 2520 2073 6e28 6d75 6562 2072     Node %s (number 
   eb0c8:	6425 2029 6166 6c69 6465 7420 206f 7270     %d) failed to pr
   eb0d8:	7065 7261 2065 6977 6874 7320 6174 7574     epare with statu
   eb0e8:	2073 6425 4e00 646f 2065 7325 2820 756e     s %d.Node %s (nu
   eb0f8:	626d 7265 2520 2964 6620 6961 656c 2064     mber %d) failed 
   eb108:	6f74 6920 766e 6b6f 2065 6977 6874 7320     to invoke with s
   eb118:	6174 7574 2073 6425 0000 0000               tatus %d....

000eb124 <_ZTVN6tflite12_GLOBAL__N_118StackDataAllocatorE>:
	...
   eb12c:	6f61 000d 6f6b 000d 6f6d 000d 6f8f 000d     ao..ko..mo...o..
   eb13c:	7865 6f70 656e 746e 3e20 203d 0030 552f     exponent >= 0./U
   eb14c:	6573 7372 622f 6173 7274 6d6f 442f 7665     sers/bsatrom/Dev
   eb15c:	6c65 706f 656d 746e 702f 7261 6974 6c63     elopment/particl
   eb16c:	2f65 696c 7262 7261 6569 2f73 6150 7472     e/libraries/Part
   eb17c:	6369 656c 545f 6e65 6f73 4672 6f6c 4c77     icle_TensorFlowL
   eb18c:	7469 5f65 7845 6d61 6c70 7365 732f 6e69     ite_Examples/sin
   eb19c:	5f65 6977 6874 735f 7263 6565 2f6e 696c     e_with_screen/li
   eb1ac:	2f62 6554 736e 726f 6c46 776f 694c 6574     b/TensorFlowLite
   eb1bc:	732f 6372 742f 6968 6472 705f 7261 7974     /src/third_party
   eb1cc:	672f 6d65 6c6d 776f 2f70 6966 6578 7064     /gemmlowp/fixedp
   eb1dc:	696f 746e 662f 7869 6465 6f70 6e69 2e74     oint/fixedpoint.
   eb1ec:	0068 7865 6f70 656e 746e 3c20 203d 3133     h.exponent <= 31
   eb1fc:	4900 706e 7475 2073 6e61 2064 756f 7074     .Inputs and outp
   eb20c:	7475 2073 6f6e 2074 6c61 206c 6c66 616f     uts not all floa
   eb21c:	7c74 6975 746e 7c38 6e69 3874 7420 7079     t|uint8|int8 typ
   eb22c:	7365 002e                                   es..

000eb230 <_ZZN8gemmlowp19RoundingDivideByPOTIlEET_S1_iE19__PRETTY_FUNCTION__>:
   eb230:	6e49 6574 6567 5472 7079 2065 6567 6d6d     IntegerType gemm
   eb240:	6f6c 7077 3a3a 6f52 6e75 6964 676e 6944     lowp::RoundingDi
   eb250:	6976 6564 7942 4f50 2854 6e49 6574 6567     videByPOT(Intege
   eb260:	5472 7079 2c65 6920 746e 2029 775b 7469     rType, int) [wit
   eb270:	2068 6e49 6574 6567 5472 7079 2065 203d     h IntegerType = 
   eb280:	6f6c 676e 6920 746e 005d 0000               long int]...

000eb28c <_ZTVN6tflite3ops5micro14AllOpsResolverE>:
	...
   eb294:	72dd 000d 730b 000d 41b3 000d 41b5 000d     .r...s...A...A..
   eb2a4:	6e4f 796c 6620 6f6c 7461 3233 202c 6975     Only float32, ui
   eb2b4:	746e 2038 6e61 2064 6e69 3874 6120 6572     nt8 and int8 are
   eb2c4:	7320 7075 6f70 7472 6465 6320 7275 6572      supported curre
   eb2d4:	746e 796c 202c 6f67 2074 7325 002e 6e4f     ntly, got %s..On
   eb2e4:	796c 6920 746e 3233 6120 6572 7320 7075     ly int32 are sup
   eb2f4:	6f70 7472 6465 6320 7275 6572 746e 796c     ported currently
   eb304:	202c 6f67 2074 7325 002e 552f 6573 7372     , got %s../Users
   eb314:	622f 6173 7274 6d6f 442f 7665 6c65 706f     /bsatrom/Develop
   eb324:	656d 746e 702f 7261 6974 6c63 2f65 696c     ment/particle/li
   eb334:	7262 7261 6569 2f73 6150 7472 6369 656c     braries/Particle
   eb344:	545f 6e65 6f73 4672 6f6c 4c77 7469 5f65     _TensorFlowLite_
   eb354:	7845 6d61 6c70 7365 732f 6e69 5f65 6977     Examples/sine_wi
   eb364:	6874 735f 7263 6565 2f6e 696c 2f62 6554     th_screen/lib/Te
   eb374:	736e 726f 6c46 776f 694c 6574 732f 6372     nsorFlowLite/src
   eb384:	742f 6e65 6f73 6672 6f6c 2f77 696c 6574     /tensorflow/lite
   eb394:	652f 7078 7265 6d69 6e65 6174 2f6c 696d     /experimental/mi
   eb3a4:	7263 2f6f 656b 6e72 6c65 2f73 6563 6c69     cro/kernels/ceil
   eb3b4:	632e 7070 2500 3a73 6425 2520 2073 3d21     .cpp.%s:%d %s !=
   eb3c4:	2520 2073 2528 2064 3d21 2520 2964 4e00      %s (%d != %d).N
   eb3d4:	6d75 6e49 7570 7374 6e28 646f 2965 4e00     umInputs(node).N
   eb3e4:	6d75 754f 7074 7475 2873 6f6e 6564 0029     umOutputs(node).
   eb3f4:	6e69 7570 2d74 743e 7079 0065 756f 7074     input->type.outp
   eb404:	7475 3e2d 7974 6570 6900 706e 7475 3e2d     ut->type.input->
   eb414:	7962 6574 0073 756f 7074 7475 3e2d 7962     bytes.output->by
   eb424:	6574 0073 6e69 7570 2d74 643e 6d69 2d73     tes.input->dims-
   eb434:	733e 7a69 0065 756f 7074 7475 3e2d 6964     >size.output->di
   eb444:	736d 3e2d 6973 657a 6900 706e 7475 3e2d     ms->size.input->
   eb454:	6964 736d 3e2d 6164 6174 695b 005d 756f     dims->data[i].ou
   eb464:	7074 7475 3e2d 6964 736d 3e2d 6164 6174     tput->dims->data
   eb474:	695b 005d 6f44 7365 6e20 746f 7320 7075     [i].Does not sup
   eb484:	6f70 7472 7420 7079 2065 6425 202c 6572     port type %d, re
   eb494:	7571 7269 7365 6220 6f6f 7c6c 6c66 616f     quires bool|floa
   eb4a4:	7c74 6e69 7c74 6975 746e 0038 6f44 7365     t|int|uint8.Does
   eb4b4:	6e20 746f 7320 7075 6f70 7472 7420 7079      not support typ
   eb4c4:	2065 6425 202c 6572 7571 7269 7365 6620     e %d, requires f
   eb4d4:	6f6c 7461 697c 746e 757c 6e69 3874 2f00     loat|int|uint8./
   eb4e4:	7355 7265 2f73 7362 7461 6f72 2f6d 6544     Users/bsatrom/De
   eb4f4:	6576 6f6c 6d70 6e65 2f74 6170 7472 6369     velopment/partic
   eb504:	656c 6c2f 6269 6172 6972 7365 502f 7261     le/libraries/Par
   eb514:	6974 6c63 5f65 6554 736e 726f 6c46 776f     ticle_TensorFlow
   eb524:	694c 6574 455f 6178 706d 656c 2f73 6973     Lite_Examples/si
   eb534:	656e 775f 7469 5f68 6373 6572 6e65 6c2f     ne_with_screen/l
   eb544:	6269 542f 6e65 6f73 4672 6f6c 4c77 7469     ib/TensorFlowLit
   eb554:	2f65 7273 2f63 6574 736e 726f 6c66 776f     e/src/tensorflow
   eb564:	6c2f 7469 2f65 7865 6570 6972 656d 746e     /lite/experiment
   eb574:	6c61 6d2f 6369 6f72 6b2f 7265 656e 736c     al/micro/kernels
   eb584:	632f 6e6f 2e76 7063 0070 7325 253a 2064     /conv.cpp.%s:%d 
   eb594:	7325 7720 7361 6e20 746f 7420 7572 2e65     %s was not true.
   eb5a4:	6800 7361 625f 6169 2073 7c7c 6e20 646f     .has_bias || nod
   eb5b4:	2d65 693e 706e 7475 2d73 733e 7a69 2065     e->inputs->size 
   eb5c4:	3d3d 3220 6e00 646f 2d65 6f3e 7475 7570     == 2.node->outpu
   eb5d4:	7374 3e2d 6973 657a 6b00 6654 694c 6574     ts->size.kTfLite
   eb5e4:	6641 6966 656e 7551 6e61 6974 617a 6974     AffineQuantizati
   eb5f4:	6e6f 6600 6c69 6574 2d72 713e 6175 746e     on.filter->quant
   eb604:	7a69 7461 6f69 2e6e 7974 6570 6100 6666     ization.type.aff
   eb614:	6e69 5f65 7571 6e61 6974 617a 6974 6e6f     ine_quantization
   eb624:	6100 6666 6e69 5f65 7571 6e61 6974 617a     .affine_quantiza
   eb634:	6974 6e6f 3e2d 6373 6c61 0065 7954 6570     tion->scale.Type
   eb644:	2520 2073 2528 2964 6e20 746f 7320 7075      %s (%d) not sup
   eb654:	6f70 7472 6465 002e                         ported..

000eb65c <_ZZN8gemmlowp19RoundingDivideByPOTIlEET_S1_iE19__PRETTY_FUNCTION__>:
   eb65c:	6e49 6574 6567 5472 7079 2065 6567 6d6d     IntegerType gemm
   eb66c:	6f6c 7077 3a3a 6f52 6e75 6964 676e 6944     lowp::RoundingDi
   eb67c:	6976 6564 7942 4f50 2854 6e49 6574 6567     videByPOT(Intege
   eb68c:	5472 7079 2c65 6920 746e 2029 775b 7469     rType, int) [wit
   eb69c:	2068 6e49 6574 6567 5472 7079 2065 203d     h IntegerType = 
   eb6ac:	6f6c 676e 6920 746e 005d 552f 6573 7372     long int]./Users
   eb6bc:	622f 6173 7274 6d6f 442f 7665 6c65 706f     /bsatrom/Develop
   eb6cc:	656d 746e 702f 7261 6974 6c63 2f65 696c     ment/particle/li
   eb6dc:	7262 7261 6569 2f73 6150 7472 6369 656c     braries/Particle
   eb6ec:	545f 6e65 6f73 4672 6f6c 4c77 7469 5f65     _TensorFlowLite_
   eb6fc:	7845 6d61 6c70 7365 732f 6e69 5f65 6977     Examples/sine_wi
   eb70c:	6874 735f 7263 6565 2f6e 696c 2f62 6554     th_screen/lib/Te
   eb71c:	736e 726f 6c46 776f 694c 6574 732f 6372     nsorFlowLite/src
   eb72c:	742f 6e65 6f73 6672 6f6c 2f77 696c 6574     /tensorflow/lite
   eb73c:	652f 7078 7265 6d69 6e65 6174 2f6c 696d     /experimental/mi
   eb74c:	7263 2f6f 656b 6e72 6c65 2f73 6564 7571     cro/kernels/dequ
   eb75c:	6e61 6974 657a 632e 7070 6900 706e 7475     antize.cpp.input
   eb76c:	3e2d 7974 6570 3d20 203d 546b 4c66 7469     ->type == kTfLit
   eb77c:	5565 6e49 3874 7c20 207c 6e69 7570 2d74     eUInt8 || input-
   eb78c:	743e 7079 2065 3d3d 6b20 6654 694c 6574     >type == kTfLite
   eb79c:	6e49 3874 6f00 7475 7570 2d74 743e 7079     Int8.output->typ
   eb7ac:	2065 3d3d 6b20 6654 694c 6574 6c46 616f     e == kTfLiteFloa
   eb7bc:	3374 0032 552f 6573 7372 622f 6173 7274     t32./Users/bsatr
   eb7cc:	6d6f 442f 7665 6c65 706f 656d 746e 702f     om/Development/p
   eb7dc:	7261 6974 6c63 2f65 696c 7262 7261 6569     article/librarie
   eb7ec:	2f73 6150 7472 6369 656c 545f 6e65 6f73     s/Particle_Tenso
   eb7fc:	4672 6f6c 4c77 7469 5f65 7845 6d61 6c70     rFlowLite_Exampl
   eb80c:	7365 732f 6e69 5f65 6977 6874 735f 7263     es/sine_with_scr
   eb81c:	6565 2f6e 696c 2f62 6554 736e 726f 6c46     een/lib/TensorFl
   eb82c:	776f 694c 6574 732f 6372 742f 6e65 6f73     owLite/src/tenso
   eb83c:	6672 6f6c 2f77 696c 6574 652f 7078 7265     rflow/lite/exper
   eb84c:	6d69 6e65 6174 2f6c 696d 7263 2f6f 656b     imental/micro/ke
   eb85c:	6e72 6c65 2f73 6c65 6d65 6e65 7774 7369     rnels/elementwis
   eb86c:	2e65 7063 0070 6e49 7570 2074 6164 6174     e.cpp.Input data
   eb87c:	7420 7079 2065 7325 2820 6425 2029 7369      type %s (%d) is
   eb88c:	6e20 746f 7320 7075 6f70 7472 6465 002e      not supported..
   eb89c:	7865 6570 7463 6465 745f 7079 0065 552f     expected_type./U
   eb8ac:	6573 7372 622f 6173 7274 6d6f 442f 7665     sers/bsatrom/Dev
   eb8bc:	6c65 706f 656d 746e 702f 7261 6974 6c63     elopment/particl
   eb8cc:	2f65 696c 7262 7261 6569 2f73 6150 7472     e/libraries/Part
   eb8dc:	6369 656c 545f 6e65 6f73 4672 6f6c 4c77     icle_TensorFlowL
   eb8ec:	7469 5f65 7845 6d61 6c70 7365 732f 6e69     ite_Examples/sin
   eb8fc:	5f65 6977 6874 735f 7263 6565 2f6e 696c     e_with_screen/li
   eb90c:	2f62 6554 736e 726f 6c46 776f 694c 6574     b/TensorFlowLite
   eb91c:	732f 6372 742f 6e65 6f73 6672 6f6c 2f77     /src/tensorflow/
   eb92c:	696c 6574 652f 7078 7265 6d69 6e65 6174     lite/experimenta
   eb93c:	2f6c 696d 7263 2f6f 656b 6e72 6c65 2f73     l/micro/kernels/
   eb94c:	6c66 6f6f 2e72 7063 0070 7551 6e61 6974     floor.cpp.Quanti
   eb95c:	657a 2064 7546 6c6c 4379 6e6f 656e 7463     zed FullyConnect
   eb96c:	6465 6520 7078 6365 7374 6f20 7475 7570     ed expects outpu
   eb97c:	2074 6164 6174 7420 7079 2065 6975 746e     t data type uint
   eb98c:	2038 726f 6920 746e 3631 5400 7079 2065     8 or int16.Type 
   eb99c:	6425 6e20 746f 6320 7275 6572 746e 796c     %d not currently
   eb9ac:	7320 7075 6f70 7472 6465 002e 6e4f 796c      supported..Only
   eb9bc:	6620 6f6c 7461 3233 6920 2073 7573 7070      float32 is supp
   eb9cc:	726f 6574 2064 7563 7272 6e65 6c74 2c79     orted currently,
   eb9dc:	6720 746f 2520 0073 7954 6570 2520 2073      got %s.Type %s 
   eb9ec:	2528 2964 6920 2073 6f6e 2074 7573 7070     (%d) is not supp
   eb9fc:	726f 6574 2064 7962 4d20 7861 6d69 6d75     orted by Maximum
   eba0c:	4d2f 6e69 6d69 6d75 002e 654e 2067 6e6f     /Minimum..Neg on
   eba1c:	796c 6320 7275 6572 746e 796c 7320 7075     ly currently sup
   eba2c:	6f70 7472 2073 6c66 616f 3374 2c32 6720     ports float32, g
   eba3c:	746f 2520 2e64 5400 7079 2065 2527 2773     ot %d..Type '%s'
   eba4c:	6920 2073 6f6e 2074 7573 7070 726f 6574      is not supporte
   eba5c:	2064 7962 7020 6361 2e6b 5400 7079 2065     d by pack..Type 
   eba6c:	7325 6e20 746f 6320 7275 6572 746e 796c     %s not currently
   eba7c:	7320 7075 6f70 7472 6465 002e 6e49 7570      supported..Inpu
   eba8c:	2074 7974 6570 2520 2073 7369 6e20 746f     t type %s is not
   eba9c:	6320 7275 6572 746e 796c 7320 7075 6f70      currently suppo
   ebaac:	7472 6465 4f00 6c6e 2079 6c66 616f 3374     rted.Only float3
   ebabc:	2032 6e61 2064 6975 746e 2038 7261 2065     2 and uint8 are 
   ebacc:	7573 7070 726f 6574 2064 7563 7272 6e65     supported curren
   ebadc:	6c74 2c79 6720 746f 2520 2e64 4900               tly, got %d..

000ebae9 <_ZZN8gemmlowp19RoundingDivideByPOTIlEET_S1_iE19__PRETTY_FUNCTION__>:
   ebae9:	6e49 6574 6567 5472 7079 2065 6567 6d6d     IntegerType gemm
   ebaf9:	6f6c 7077 3a3a 6f52 6e75 6964 676e 6944     lowp::RoundingDi
   ebb09:	6976 6564 7942 4f50 2854 6e49 6574 6567     videByPOT(Intege
   ebb19:	5472 7079 2c65 6920 746e 2029 775b 7469     rType, int) [wit
   ebb29:	2068 6e49 6574 6567 5472 7079 2065 203d     h IntegerType = 
   ebb39:	6f6c 676e 6920 746e 005d 552f 6573 7372     long int]./Users
   ebb49:	622f 6173 7274 6d6f 442f 7665 6c65 706f     /bsatrom/Develop
   ebb59:	656d 746e 702f 7261 6974 6c63 2f65 696c     ment/particle/li
   ebb69:	7262 7261 6569 2f73 6150 7472 6369 656c     braries/Particle
   ebb79:	545f 6e65 6f73 4672 6f6c 4c77 7469 5f65     _TensorFlowLite_
   ebb89:	7845 6d61 6c70 7365 732f 6e69 5f65 6977     Examples/sine_wi
   ebb99:	6874 735f 7263 6565 2f6e 696c 2f62 6554     th_screen/lib/Te
   ebba9:	736e 726f 6c46 776f 694c 6574 732f 6372     nsorFlowLite/src
   ebbb9:	742f 6e65 6f73 6672 6f6c 2f77 696c 6574     /tensorflow/lite
   ebbc9:	652f 7078 7265 6d69 6e65 6174 2f6c 696d     /experimental/mi
   ebbd9:	7263 2f6f 656b 6e72 6c65 2f73 7571 6e61     cro/kernels/quan
   ebbe9:	6974 657a 632e 7070 6f00 7475 7570 2d74     tize.cpp.output-
   ebbf9:	713e 6175 746e 7a69 7461 6f69 2e6e 7974     >quantization.ty
   ebc09:	6570 6100 6666 6e69 5f65 7571 6e61 6974     pe.affine_quanti
   ebc19:	617a 6974 6e6f 3e2d 6373 6c61 2d65 733e     zation->scale->s
   ebc29:	7a69 2065 3d3d 3120 6900 706e 7475 3e2d     ize == 1.input->
   ebc39:	7974 6570 3d20 203d 546b 4c66 7469 4665     type == kTfLiteF
   ebc49:	6f6c 7461 3233 6f00 7475 7570 2d74 743e     loat32.output->t
   ebc59:	7079 2065 3d3d 6b20 6654 694c 6574 4955     ype == kTfLiteUI
   ebc69:	746e 2038 7c7c 6f20 7475 7570 2d74 743e     nt8 || output->t
   ebc79:	7079 2065 3d3d 6b20 6654 694c 6574 6e49     ype == kTfLiteIn
   ebc89:	3874 4f00 7475 7570 2074 7974 6570 2520     t8.Output type %
   ebc99:	2073 2528 2964 6e20 746f 7320 7075 6f70     s (%d) not suppo
   ebca9:	7472 6465 2f00 7355 7265 2f73 7362 7461     rted./Users/bsat
   ebcb9:	6f72 2f6d 6544 6576 6f6c 6d70 6e65 2f74     rom/Development/
   ebcc9:	6170 7472 6369 656c 6c2f 6269 6172 6972     particle/librari
   ebcd9:	7365 502f 7261 6974 6c63 5f65 6554 736e     es/Particle_Tens
   ebce9:	726f 6c46 776f 694c 6574 455f 6178 706d     orFlowLite_Examp
   ebcf9:	656c 2f73 6973 656e 775f 7469 5f68 6373     les/sine_with_sc
   ebd09:	6572 6e65 6c2f 6269 542f 6e65 6f73 4672     reen/lib/TensorF
   ebd19:	6f6c 4c77 7469 2f65 7273 2f63 6574 736e     lowLite/src/tens
   ebd29:	726f 6c66 776f 6c2f 7469 2f65 7865 6570     orflow/lite/expe
   ebd39:	6972 656d 746e 6c61 6d2f 6369 6f72 6b2f     rimental/micro/k
   ebd49:	7265 656e 736c 722f 7365 6168 6570 632e     ernels/reshape.c
   ebd59:	7070 4e00 6d75 6e49 7570 7374 6e28 646f     pp.NumInputs(nod
   ebd69:	2965 3d20 203d 2031 7c7c 4e20 6d75 6e49     e) == 1 || NumIn
   ebd79:	7570 7374 6e28 646f 2965 3d20 203d 0032     puts(node) == 2.
   ebd89:	312d 7300 7274 7465 6863 645f 6d69 6e00     -1.stretch_dim.n
   ebd99:	6d75 6f5f 7475 7570 5f74 6c65 6d65 6e65     um_output_elemen
   ebda9:	7374 6e00 6d75 695f 706e 7475 655f 656c     ts.num_input_ele
   ebdb9:	656d 746e 0073 552f 6573 7372 622f 6173     ments./Users/bsa
   ebdc9:	7274 6d6f 442f 7665 6c65 706f 656d 746e     trom/Development
   ebdd9:	702f 7261 6974 6c63 2f65 696c 7262 7261     /particle/librar
   ebde9:	6569 2f73 6150 7472 6369 656c 545f 6e65     ies/Particle_Ten
   ebdf9:	6f73 4672 6f6c 4c77 7469 5f65 7845 6d61     sorFlowLite_Exam
   ebe09:	6c70 7365 732f 6e69 5f65 6977 6874 735f     ples/sine_with_s
   ebe19:	7263 6565 2f6e 696c 2f62 6554 736e 726f     creen/lib/Tensor
   ebe29:	6c46 776f 694c 6574 732f 6372 742f 6e65     FlowLite/src/ten
   ebe39:	6f73 6672 6f6c 2f77 696c 6574 652f 7078     sorflow/lite/exp
   ebe49:	7265 6d69 6e65 6174 2f6c 696d 7263 2f6f     erimental/micro/
   ebe59:	656b 6e72 6c65 2f73 6f72 6e75 2e64 7063     kernels/round.cp
   ebe69:	0070 552f 6573 7372 622f 6173 7274 6d6f     p./Users/bsatrom
   ebe79:	442f 7665 6c65 706f 656d 746e 702f 7261     /Development/par
   ebe89:	6974 6c63 2f65 696c 7262 7261 6569 2f73     ticle/libraries/
   ebe99:	6150 7472 6369 656c 545f 6e65 6f73 4672     Particle_TensorF
   ebea9:	6f6c 4c77 7469 5f65 7845 6d61 6c70 7365     lowLite_Examples
   ebeb9:	732f 6e69 5f65 6977 6874 735f 7263 6565     /sine_with_scree
   ebec9:	2f6e 696c 2f62 6554 736e 726f 6c46 776f     n/lib/TensorFlow
   ebed9:	694c 6574 732f 6372 742f 6e65 6f73 6672     Lite/src/tensorf
   ebee9:	6f6c 2f77 696c 6574 652f 7078 7265 6d69     low/lite/experim
   ebef9:	6e65 6174 2f6c 696d 7263 2f6f 656b 6e72     ental/micro/kern
   ebf09:	6c65 2f73 6f73 7466 616d 2e78 7063 0070     els/softmax.cpp.
   ebf19:	756f 7074 7475 3e2d 6170 6172 736d 7a2e     output->params.z
   ebf29:	7265 5f6f 6f70 6e69 0074 756f 7074 7475     ero_point.output
   ebf39:	3e2d 6170 6172 736d 732e 6163 656c 3d20     ->params.scale =
   ebf49:	203d 2e31 2066 202f 3532 0036 6e4f 796c     = 1.f / 256.Only
   ebf59:	3120 2c44 3220 2044 6e61 2064 4434 7420      1D, 2D and 4D t
   ebf69:	6e65 6f73 7372 7320 7075 6f70 7472 6465     ensors supported
   ebf79:	6320 7275 6572 746e 796c 202c 6f67 2074      currently, got 
   ebf89:	6425 2e44 4f00 6c6e 2079 4432 6120 646e     %dD..Only 2D and
   ebf99:	3420 2044 6574 736e 726f 2073 7573 7070      4D tensors supp
   ebfa9:	726f 6574 2064 7563 7272 6e65 6c74 2c79     orted currently,
   ebfb9:	6720 746f 2520 4464 002e 6e4f 796c 6620      got %dD..Only f
   ebfc9:	6f6c 7461 3233 6120 646e 7520 6e69 3874     loat32 and uint8
   ebfd9:	745f 7320 7075 6f70 7472 6465 6320 7275     _t supported cur
   ebfe9:	6572 746e 796c 202c 6f67 2074 6425 002e     rently, got %d..

000ebff9 <_ZZN8gemmlowp19RoundingDivideByPOTIlEET_S1_iE19__PRETTY_FUNCTION__>:
   ebff9:	6e49 6574 6567 5472 7079 2065 6567 6d6d     IntegerType gemm
   ec009:	6f6c 7077 3a3a 6f52 6e75 6964 676e 6944     lowp::RoundingDi
   ec019:	6976 6564 7942 4f50 2854 6e49 6574 6567     videByPOT(Intege
   ec029:	5472 7079 2c65 6920 746e 2029 775b 7469     rType, int) [wit
   ec039:	2068 6e49 6574 6567 5472 7079 2065 203d     h IntegerType = 
   ec049:	6f6c 676e 6920 746e 005d 552f 6573 7372     long int]./Users
   ec059:	622f 6173 7274 6d6f 442f 7665 6c65 706f     /bsatrom/Develop
   ec069:	656d 746e 702f 7261 6974 6c63 2f65 696c     ment/particle/li
   ec079:	7262 7261 6569 2f73 6150 7472 6369 656c     braries/Particle
   ec089:	545f 6e65 6f73 4672 6f6c 4c77 7469 5f65     _TensorFlowLite_
   ec099:	7845 6d61 6c70 7365 732f 6e69 5f65 6977     Examples/sine_wi
   ec0a9:	6874 735f 7263 6565 2f6e 696c 2f62 6554     th_screen/lib/Te
   ec0b9:	736e 726f 6c46 776f 694c 6574 732f 6372     nsorFlowLite/src
   ec0c9:	742f 6e65 6f73 6672 6f6c 2f77 696c 6574     /tensorflow/lite
   ec0d9:	652f 7078 7265 6d69 6e65 6174 2f6c 696d     /experimental/mi
   ec0e9:	7263 2f6f 656b 6e72 6c65 2f73 7073 696c     cro/kernels/spli
   ec0f9:	2e74 7063 2070 6f4e 206e 6f63 736e 6174     t.cpp Non consta
   ec109:	746e 6120 6978 2073 6574 736e 726f 6e20     nt axis tensor n
   ec119:	746f 7320 7075 6f70 7472 6465 2f00 7355     ot supported./Us
   ec129:	7265 2f73 7362 7461 6f72 2f6d 6544 6576     ers/bsatrom/Deve
   ec139:	6f6c 6d70 6e65 2f74 6170 7472 6369 656c     lopment/particle
   ec149:	6c2f 6269 6172 6972 7365 502f 7261 6974     /libraries/Parti
   ec159:	6c63 5f65 6554 736e 726f 6c46 776f 694c     cle_TensorFlowLi
   ec169:	6574 455f 6178 706d 656c 2f73 6973 656e     te_Examples/sine
   ec179:	775f 7469 5f68 6373 6572 6e65 6c2f 6269     _with_screen/lib
   ec189:	542f 6e65 6f73 4672 6f6c 4c77 7469 2f65     /TensorFlowLite/
   ec199:	7273 2f63 6574 736e 726f 6c66 776f 6c2f     src/tensorflow/l
   ec1a9:	7469 2f65 7865 6570 6972 656d 746e 6c61     ite/experimental
   ec1b9:	6d2f 6369 6f72 6b2f 7265 656e 736c 732f     /micro/kernels/s
   ec1c9:	6c70 7469 632e 7070 6100 6978 5f73 6176     plit.cpp.axis_va
   ec1d9:	756c 2065 3d3e 3020 6100 6978 5f73 6176     lue >= 0.axis_va
   ec1e9:	756c 2065 203c 754e 446d 6d69 6e65 6973     lue < NumDimensi
   ec1f9:	6e6f 2873 6e69 7570 2974 5400 7079 2065     ons(input).Type 
   ec209:	7325 6320 7275 6572 746e 796c 6e20 746f     %s currently not
   ec219:	7320 7075 6f70 7472 6465 002e 552f 6573      supported../Use
   ec229:	7372 622f 6173 7274 6d6f 442f 7665 6c65     rs/bsatrom/Devel
   ec239:	706f 656d 746e 702f 7261 6974 6c63 2f65     opment/particle/
   ec249:	696c 7262 7261 6569 2f73 6150 7472 6369     libraries/Partic
   ec259:	656c 545f 6e65 6f73 4672 6f6c 4c77 7469     le_TensorFlowLit
   ec269:	5f65 7845 6d61 6c70 7365 732f 6e69 5f65     e_Examples/sine_
   ec279:	6977 6874 735f 7263 6565 2f6e 696c 2f62     with_screen/lib/
   ec289:	6554 736e 726f 6c46 776f 694c 6574 732f     TensorFlowLite/s
   ec299:	6372 742f 6e65 6f73 6672 6f6c 2f77 696c     rc/tensorflow/li
   ec2a9:	6574 652f 7078 7265 6d69 6e65 6174 2f6c     te/experimental/
   ec2b9:	696d 7263 2f6f 656b 6e72 6c65 2f73 7473     micro/kernels/st
   ec2c9:	6972 6564 5f64 6c73 6369 2e65 7063 2070     rided_slice.cpp 
   ec2d9:	7473 6972 6564 7620 6c61 6575 6820 7361     stride value has
   ec2e9:	7420 206f 6562 6e20 6e6f 7a2d 7265 006f      to be non-zero.
   ec2f9:	552f 6573 7372 622f 6173 7274 6d6f 442f     /Users/bsatrom/D
   ec309:	7665 6c65 706f 656d 746e 702f 7261 6974     evelopment/parti
   ec319:	6c63 2f65 696c 7262 7261 6569 2f73 6150     cle/libraries/Pa
   ec329:	7472 6369 656c 545f 6e65 6f73 4672 6f6c     rticle_TensorFlo
   ec339:	4c77 7469 5f65 7845 6d61 6c70 7365 732f     wLite_Examples/s
   ec349:	6e69 5f65 6977 6874 735f 7263 6565 2f6e     ine_with_screen/
   ec359:	696c 2f62 6554 736e 726f 6c46 776f 694c     lib/TensorFlowLi
   ec369:	6574 732f 6372 742f 6e65 6f73 6672 6f6c     te/src/tensorflo
   ec379:	2f77 696c 6574 652f 7078 7265 6d69 6e65     w/lite/experimen
   ec389:	6174 2f6c 696d 7263 2f6f 656b 6e72 6c65     tal/micro/kernel
   ec399:	2f73 7473 6972 6564 5f64 6c73 6369 2e65     s/strided_slice.
   ec3a9:	7063 0070 6964 5f6d 6873 7061 0065 756f     cpp.dim_shape.ou
   ec3b9:	7074 7475 735f 6168 6570 3e2d 6164 6174     tput_shape->data
   ec3c9:	735b 6168 6570 735f 7a69 5d65 7300 6168     [shape_size].sha
   ec3d9:	6570 735f 7a69 0065 756f 7074 7475 735f     pe_size.output_s
   ec3e9:	6168 6570 3e2d 6973 657a 2f00 7355 7265     hape->size./User
   ec3f9:	2f73 7362 7461 6f72 2f6d 6544 6576 6f6c     s/bsatrom/Develo
   ec409:	6d70 6e65 2f74 6170 7472 6369 656c 6c2f     pment/particle/l
   ec419:	6269 6172 6972 7365 502f 7261 6974 6c63     ibraries/Particl
   ec429:	5f65 6554 736e 726f 6c46 776f 694c 6574     e_TensorFlowLite
   ec439:	455f 6178 706d 656c 2f73 6973 656e 775f     _Examples/sine_w
   ec449:	7469 5f68 6373 6572 6e65 6c2f 6269 542f     ith_screen/lib/T
   ec459:	6e65 6f73 4672 6f6c 4c77 7469 2f65 7273     ensorFlowLite/sr
   ec469:	2f63 6574 736e 726f 6c66 776f 6c2f 7469     c/tensorflow/lit
   ec479:	2f65 7865 6570 6972 656d 746e 6c61 6d2f     e/experimental/m
   ec489:	6369 6f72 6b2f 7265 656e 736c 732f 7274     icro/kernels/str
   ec499:	6469 6465 735f 696c 6563 632e 7070 6920     ided_slice.cpp i
   ec4a9:	706e 7475 6420 6d69 7320 6f68 6c75 2064     nput dim should 
   ec4b9:	6f6e 2074 7865 6563 6465 3420 5400 7079     not exceed 4.Typ
   ec4c9:	2065 6425 6920 2073 7563 7272 6e65 6c74     e %d is currentl
   ec4d9:	2079 6f6e 2074 7573 7070 726f 6574 2064     y not supported 
   ec4e9:	7962 5320 7274 6469 6465 6c53 6369 2e65     by StridedSlice.
   ec4f9:	2f00 7355 7265 2f73 7362 7461 6f72 2f6d     ./Users/bsatrom/
   ec509:	6544 6576 6f6c 6d70 6e65 2f74 6170 7472     Development/part
   ec519:	6369 656c 6c2f 6269 6172 6972 7365 502f     icle/libraries/P
   ec529:	7261 6974 6c63 5f65 6554 736e 726f 6c46     article_TensorFl
   ec539:	776f 694c 6574 455f 6178 706d 656c 2f73     owLite_Examples/
   ec549:	6973 656e 775f 7469 5f68 6373 6572 6e65     sine_with_screen
   ec559:	6c2f 6269 542f 6e65 6f73 4672 6f6c 4c77     /lib/TensorFlowL
   ec569:	7469 2f65 7273 2f63 6574 736e 726f 6c66     ite/src/tensorfl
   ec579:	776f 6c2f 7469 2f65 7865 6570 6972 656d     ow/lite/experime
   ec589:	746e 6c61 6d2f 6369 6f72 6b2f 7265 656e     ntal/micro/kerne
   ec599:	736c 732f 6476 2e66 7063 0070 6f6e 6564     ls/svdf.cpp.node
   ec5a9:	3e2d 6e69 7570 7374 3e2d 6973 657a 6e00     ->inputs->size.n
   ec5b9:	6d75 665f 6c69 6574 7372 2520 7220 6e61     um_filters % ran
   ec5c9:	006b 754e 446d 6d69 6e65 6973 6e6f 2873     k.NumDimensions(
   ec5d9:	6577 6769 7468 5f73 6566 7461 7275 2965     weights_feature)
   ec5e9:	6900 706e 7475 735f 7a69 0065 6577 6769     .input_size.weig
   ec5f9:	7468 5f73 6566 7461 7275 2d65 643e 6d69     hts_feature->dim
   ec609:	2d73 643e 7461 5b61 5d31 4e00 6d75 6944     s->data[1].NumDi
   ec619:	656d 736e 6f69 736e 7728 6965 6867 7374     mensions(weights
   ec629:	745f 6d69 2965 6e00 6d75 755f 696e 7374     _time).num_units
   ec639:	6200 6169 2d73 643e 6d69 2d73 643e 7461     .bias->dims->dat
   ec649:	5b61 5d30 6200 6169 2d73 743e 7079 0065     a[0].bias->type.
   ec659:	6361 6974 6176 6974 6e6f 735f 6174 6574     activation_state
   ec669:	3e2d 7974 6570 4e00 6d75 6944 656d 736e     ->type.NumDimens
   ec679:	6f69 736e 6128 7463 7669 7461 6f69 5f6e     ions(activation_
   ec689:	7473 7461 2965 6200 7461 6863 735f 7a69     state).batch_siz
   ec699:	0065 6361 6974 6176 6974 6e6f 735f 6174     e.activation_sta
   ec6a9:	6574 3e2d 6964 736d 3e2d 6164 6174 305b     te->dims->data[0
   ec6b9:	005d 656d 6f6d 7972 735f 7a69 2065 202a     ].memory_size * 
   ec6c9:	756e 5f6d 6966 746c 7265 0073 6361 6974     num_filters.acti
   ec6d9:	6176 6974 6e6f 735f 6174 6574 3e2d 6964     vation_state->di
   ec6e9:	736d 3e2d 6164 6174 315b 005d 6373 6172     ms->data[1].scra
   ec6f9:	6374 5f68 6574 736e 726f 3e2d 7974 6570     tch_tensor->type
   ec709:	4e00 6d75 6944 656d 736e 6f69 736e 7328     .NumDimensions(s
   ec719:	7263 7461 6863 745f 6e65 6f73 2972 7300     cratch_tensor).s
   ec729:	7263 7461 6863 745f 6e65 6f73 2d72 643e     cratch_tensor->d
   ec739:	6d69 2d73 643e 7461 5b61 5d30 7300 7263     ims->data[0].scr
   ec749:	7461 6863 745f 6e65 6f73 2d72 643e 6d69     atch_tensor->dim
   ec759:	2d73 643e 7461 5b61 5d31 7700 6965 6867     s->data[1].weigh
   ec769:	7374 745f 6d69 2d65 743e 7079 2065 3d3d     ts_time->type ==
   ec779:	6b20 6654 694c 6574 4955 746e 2038 7c7c      kTfLiteUInt8 ||
   ec789:	7720 6965 6867 7374 745f 6d69 2d65 743e      weights_time->t
   ec799:	7079 2065 3d3d 6b20 6654 694c 6574 6e49     ype == kTfLiteIn
   ec7a9:	3874 6e00 646f 2d65 743e 6d65 6f70 6172     t8.node->tempora
   ec7b9:	6972 7365 3e2d 6973 657a 7300 7263 7461     ries->size.scrat
   ec7c9:	6863 695f 706e 7475 715f 6175 746e 7a69     ch_input_quantiz
   ec7d9:	6465 3e2d 7974 6570 3d20 203d 546b 4c66     ed->type == kTfL
   ec7e9:	7469 5565 6e49 3874 7c20 207c 6373 6172     iteUInt8 || scra
   ec7f9:	6374 5f68 6e69 7570 5f74 7571 6e61 6974     tch_input_quanti
   ec809:	657a 2d64 743e 7079 2065 3d3d 6b20 6654     zed->type == kTf
   ec819:	694c 6574 6e49 3874 7300 7263 7461 6863     LiteInt8.scratch
   ec829:	695f 706e 7475 715f 6175 746e 7a69 6465     _input_quantized
   ec839:	3e2d 6964 736d 3e2d 6164 6174 305b 005d     ->dims->data[0].
   ec849:	6373 6172 6374 5f68 6373 6c61 6e69 5f67     scratch_scaling_
   ec859:	6166 7463 726f 2d73 743e 7079 0065 754e     factors->type.Nu
   ec869:	446d 6d69 6e65 6973 6e6f 2873 6373 6172     mDimensions(scra
   ec879:	6374 5f68 6373 6c61 6e69 5f67 6166 7463     tch_scaling_fact
   ec889:	726f 2973 7300 7263 7461 6863 735f 6163     ors).scratch_sca
   ec899:	696c 676e 665f 6361 6f74 7372 3e2d 6964     ling_factors->di
   ec8a9:	736d 3e2d 6164 6174 305b 005d 6373 6172     ms->data[0].scra
   ec8b9:	6374 5f68 6c66 616f 5f74 6577 6769 7468     tch_float_weight
   ec8c9:	5f73 6974 656d 3e2d 7974 6570 4e00 6d75     s_time->type.Num
   ec8d9:	6944 656d 736e 6f69 736e 7328 7263 7461     Dimensions(scrat
   ec8e9:	6863 665f 6f6c 7461 775f 6965 6867 7374     ch_float_weights
   ec8f9:	745f 6d69 2965 7300 7263 7461 6863 665f     _time).scratch_f
   ec909:	6f6c 7461 775f 6965 6867 7374 745f 6d69     loat_weights_tim
   ec919:	2d65 643e 6d69 2d73 643e 7461 5b61 5d30     e->dims->data[0]
   ec929:	6d00 6d65 726f 5f79 6973 657a 7300 7263     .memory_size.scr
   ec939:	7461 6863 665f 6f6c 7461 775f 6965 6867     atch_float_weigh
   ec949:	7374 745f 6d69 2d65 643e 6d69 2d73 643e     ts_time->dims->d
   ec959:	7461 5b61 5d31 7700 6965 6867 7374 665f     ata[1].weights_f
   ec969:	6165 7574 6572 3e2d 7974 6570 4e00 6d75     eature->type.Num
   ec979:	6944 656d 736e 6f69 736e 6f28 7475 7570     Dimensions(outpu
   ec989:	2974 6f00 7475 7570 2d74 643e 6d69 2d73     t).output->dims-
   ec999:	643e 7461 5b61 5d30 6f00 7475 7570 2d74     >data[0].output-
   ec9a9:	643e 6d69 2d73 643e 7461 5b61 5d31 5400     >dims->data[1].T
   ec9b9:	7079 2065 2527 2773 6920 2073 6f6e 2074     ype '%s' is not 
   ec9c9:	7573 7070 726f 6574 2064 7962 7520 706e     supported by unp
   ec9d9:	6361 2e6b 2f00 7355 7265 2f73 7362 7461     ack../Users/bsat
   ec9e9:	6f72 2f6d 6544 6576 6f6c 6d70 6e65 2f74     rom/Development/
   ec9f9:	6170 7472 6369 656c 6c2f 6269 6172 6972     particle/librari
   eca09:	7365 502f 7261 6974 6c63 5f65 6554 736e     es/Particle_Tens
   eca19:	726f 6c46 776f 694c 6574 455f 6178 706d     orFlowLite_Examp
   eca29:	656c 2f73 6973 656e 775f 7469 5f68 6373     les/sine_with_sc
   eca39:	6572 6e65 6c2f 6269 542f 6e65 6f73 4672     reen/lib/TensorF
   eca49:	6f6c 4c77 7469 2f65 7273 2f63 6574 736e     lowLite/src/tens
   eca59:	726f 6c66 776f 6c2f 7469 2f65 7865 6570     orflow/lite/expe
   eca69:	6972 656d 746e 6c61 6d2f 6369 6f72 6b2f     rimental/micro/k
   eca79:	7265 656e 736c 702f 726f 6174 6c62 5f65     ernels/portable_
   eca89:	706f 6974 696d 657a 2f64 6564 7470 7768     optimized/depthw
   eca99:	7369 5f65 6f63 766e 632e 7070 4d00 6c75     ise_conv.cpp.Mul
   ecaa9:	6974 6c70 2065 6564 7470 7768 7369 2065     tiple depthwise 
   ecab9:	6f63 766e 6f20 7370 6d20 7461 6863 6f20     conv ops match o
   ecac9:	7470 6d69 7a69 7461 6f69 206e 6170 6172     ptimization para
   ecad9:	656d 6574 7372 202c 7562 2074 6e6f 796c     meters, but only
   ecae9:	7420 6568 6620 7269 7473 7720 6c69 206c      the first will 
   ecaf9:	7375 2065 6874 2065 6166 7473 7020 7461     use the fast pat
   ecb09:	2c68 6220 6365 7561 6573 7420 6568 6572     h, because there
   ecb19:	7327 6f20 6c6e 2079 6e6f 2065 4152 204d     's only one RAM 
   ecb29:	6163 6863 2065 7661 6961 616c 6c62 0065     cache available.
   ecb39:	6953 657a 7420 6f6f 6c20 7261 6567 6620     Size too large f
   ecb49:	726f 7220 7365 6168 6570 2064 6577 6769     or reshaped weig
   ecb59:	7468 6220 6675 6566 2072 2528 2064 656e     ht buffer (%d ne
   ecb69:	6465 6465 202c 6425 6120 6176 6c69 6261     eded, %d availab
   ecb79:	656c 0029 6f54 206f 616d 796e 6220 6675     le).Too many buf
   ecb89:	6566 7372 2820 616d 2078 7369 2520 2964     fers (max is %d)
   ecb99:	6200 6675 6566 2072 6e69 6564 2078 6425     .buffer index %d
   ecba9:	6920 2073 756f 7374 6469 2065 6172 676e      is outside rang
   ecbb9:	2065 2030 6f74 2520 0064 764f 7265 616c     e 0 to %d.Overla
   ecbc9:	3a70 2520 2064 2528 3d64 253e 2c64 2520     p: %d (%d=>%d, %
   ecbd9:	2d64 253e 2964 7620 2073 6425 2820 6425     d->%d) vs %d (%d
   ecbe9:	3e3d 6425 202c 6425 3e2d 6425 0029 0000          =>%d, %d->%d)..

000ecbf8 <_ZTVN6tflite19GreedyMemoryPlannerE>:
	...
   ecc00:	479d 000e 47a3 000e 47b1 000e 49fb 000e     .G...G...G...I..
   ecc10:	479f 000e 4a31 000e 552f 6573 7372 622f     .G..1J../Users/b
   ecc20:	6173 7274 6d6f 442f 7665 6c65 706f 656d     satrom/Developme
   ecc30:	746e 702f 7261 6974 6c63 2f65 696c 7262     nt/particle/libr
   ecc40:	7261 6569 2f73 6150 7472 6369 656c 545f     aries/Particle_T
   ecc50:	6e65 6f73 4672 6f6c 4c77 7469 5f65 7845     ensorFlowLite_Ex
   ecc60:	6d61 6c70 7365 732f 6e69 5f65 6977 6874     amples/sine_with
   ecc70:	735f 7263 6565 2f6e 696c 2f62 6554 736e     _screen/lib/Tens
   ecc80:	726f 6c46 776f 694c 6574 732f 6372 742f     orFlowLite/src/t
   ecc90:	6e65 6f73 6672 6f6c 2f77 696c 6574 6b2f     ensorflow/lite/k
   ecca0:	7265 656e 736c 6b2f 7265 656e 5f6c 7475     ernels/kernel_ut
   eccb0:	6c69 632e 7070 6900 706e 7475 705f 6f72     il.cpp.input_pro
   eccc0:	7564 7463 735f 6163 656c 3e20 203d 0030     duct_scale >= 0.
   eccd0:	7473 3a64 613a 7362 6928 706e 7475 705f     std::abs(input_p
   ecce0:	6f72 7564 7463 735f 6163 656c 2d20 6220     roduct_scale - b
   eccf0:	6169 5f73 6373 6c61 2965 3c20 203d 6531     ias_scale) <= 1e
   ecd00:	362d 2a20 7320 6474 3a3a 696d 286e 6e69     -6 * std::min(in
   ecd10:	7570 5f74 7270 646f 6375 5f74 6373 6c61     put_product_scal
   ecd20:	2c65 6220 6169 5f73 6373 6c61 2965 6600     e, bias_scale).f
   ecd30:	6c61 6573 6900 706e 7475 3e2d 7571 6e61     alse.input->quan
   ecd40:	6974 617a 6974 6e6f 742e 7079 0065 6966     tization.type.fi
   ecd50:	746c 7265 3e2d 7974 6570 6600 6c69 6574     lter->type.filte
   ecd60:	2d72 643e 6d69 2d73 643e 7461 5b61 6661     r->dims->data[af
   ecd70:	6966 656e 715f 6175 746e 7a69 7461 6f69     fine_quantizatio
   ecd80:	2d6e 713e 6175 746e 7a69 6465 645f 6d69     n->quantized_dim
   ecd90:	6e65 6973 6e6f 005d 6661 6966 656e 715f     ension].affine_q
   ecda0:	6175 746e 7a69 7461 6f69 2d6e 733e 6163     uantization->sca
   ecdb0:	656c 3e2d 6973 657a 6400 2031 3d3d 6420     le->size.d1 == d
   ecdc0:	2032 7c7c 6420 2031 3d3d 3120 7c20 207c     2 || d1 == 1 || 
   ecdd0:	3264 3d20 203d 0031                         d2 == 1.

000ecdd8 <_ZTVN5spark13EthernetClassE>:
	...
   ecde0:	563d 000e 5633 000e 5629 000e 561f 000e     =V..3V..)V...V..
   ecdf0:	5613 000e 5607 000e 55fb 000e 55f3 000e     .V...V...U...U..
   ece00:	55e9 000e 55df 000e 59a1 000e               .U...U...Y..

000ece0c <_ZTV7TwoWire>:
	...
   ece14:	565d 000e 56a7 000e 567f 000e 565f 000e     ]V...V...V.._V..
   ece24:	5687 000e 568f 000e 5697 000e 569f 000e     .V...V...V...V..

000ece34 <_ZTV9IPAddress>:
	...
   ece3c:	56f1 000e 56e1 000e 56e3 000e 6162 6475     .V...V...V..baud
   ece4c:	5300 7265 6169 006c 6553 6972 6c61 0031     .Serial.Serial1.
   ece5c:	6170 6172 006d 6d63 0064 6469 6800 646e     param.cmd.id.hnd
   ece6c:	7300 7274 006d 6966 746c 6c00 6c76 6100     .strm.filt.lvl.a
   ece7c:	6464 6148 646e 656c 0072 6572 6f6d 6576     ddHandler.remove
   ece8c:	6148 646e 656c 0072 6e65 6d75 6148 646e     Handler.enumHand
   ece9c:	656c 7372 4a00 4f53 534e 7274 6165 4c6d     lers.JSONStreamL
   eceac:	676f 6148 646e 656c 0072 7061 0070 3025     ogHandler.app.%0
   ecebc:	3031 2075 5d00 0020 202c 2800 3a29 0020     10u .] ., .(): .
   ececc:	6f63 6564 3d20 0020 6925 6400 7465 6961     code = .%i.detai
   ecedc:	736c 3d20 0020 6e6c 6600 006e 6f63 6564     ls = .ln.fn.code
   eceec:	6400 7465 6961 006c 6f6e 656e 7400 6172     .detail.none.tra
   ecefc:	6563 6900 666e 006f 6177 6e72 6500 7272     ce.info.warn.err
   ecf0c:	726f 7000 6e61 6369 6100 6c6c 0000 0000     or.panic.all....

000ecf1c <_ZTVN5spark9MeshClassE>:
	...
   ecf24:	5833 000e 5829 000e 581f 000e 5815 000e     3X..)X...X...X..
   ecf34:	5809 000e 57fd 000e 57f1 000e 57e9 000e     .X...W...W...W..
   ecf44:	57df 000e 57d5 000e 59a1 000e               .W...W...Y..

000ecf50 <_ZTVN5spark12NetworkClassE>:
	...
   ecf58:	5939 000e 5943 000e 594d 000e 5957 000e     9Y..CY..MY..WY..
   ecf68:	5961 000e 596d 000e 5979 000e 5985 000e     aY..mY..yY...Y..
   ecf78:	598d 000e 5997 000e 59a1 000e               .Y...Y...Y..

000ecf84 <_ZTV8SPIClass>:
	...
   ecf8c:	5c01 000e 5c03 000e                         .\...\..

000ecf94 <_ZL14clock_divisors>:
   ecf94:	0800 1810 2820 3830 005a 2b25 3330 3a64     .... (08Z.%+03d:
   ecfa4:	3025 7532 2500 2d59 6d25 252d 5464 4825     %02u.%Y-%m-%dT%H
   ecfb4:	253a 3a4d 5325 7a25 6100 6373 6974 656d     :%M:%S%z.asctime
   ecfc4:	0000 0000                                   ....

000ecfc8 <_ZTV11USARTSerial>:
	...
   ecfd0:	5d45 000e 5d95 000e 5da3 000e 5a81 000e     E]...]...]...Z..
   ecfe0:	5d59 000e 5d7b 000e 5d67 000e 5d8f 000e     Y]..{]..g]...]..
   ecff0:	5d47 000e 5d4b 000e                         G]..K]..

000ecff8 <_ZTV9USBSerial>:
	...
   ed000:	5e4d 000e 5e9d 000e 5eab 000e 5a81 000e     M^...^...^...Z..
   ed010:	5e89 000e 5e4f 000e 5e65 000e 5e97 000e     .^..O^..e^...^..
   ed020:	5e7b 000e 5e49 000e 7865 0070 7865 6670     {^..I^..exp.expf
   ed030:	0000 0000 6f6c 6667 0000 0000 7173 7472     ....logf....sqrt
   ed040:	0066 0000 0000 0000                         f.......

000ed048 <halF>:
   ed048:	0000 0000 0000 3fe0 0000 0000 0000 bfe0     .......?........

000ed058 <ln2LO>:
   ed058:	3c76 3579 39ef 3dea 3c76 3579 39ef bdea     v<y5.9.=v<y5.9..

000ed068 <ln2HI>:
   ed068:	0000 fee0 2e42 3fe6 0000 fee0 2e42 bfe6     ....B..?....B...

000ed078 <halF>:
   ed078:	0000 3f00 0000 bf00                         ...?....

000ed080 <ln2LO>:
   ed080:	f7d1 3717 f7d1 b717                         ...7....

000ed088 <ln2HI>:
   ed088:	7180 3f31 7180 bf31                         .q1?.q1.

000ed090 <npio2_hw>:
   ed090:	0f00 3fc9 0f00 4049 cb00 4096 0f00 40c9     ...?..I@...@...@
   ed0a0:	5300 40fb cb00 4116 ed00 412f 0f00 4149     .S.@...A../A..IA
   ed0b0:	3100 4162 5300 417b 3a00 418a cb00 4196     .1bA.S{A.:.A...A
   ed0c0:	5c00 41a3 ed00 41af 7e00 41bc 0f00 41c9     .\.A...A.~.A...A
   ed0d0:	a000 41d5 3100 41e2 c200 41ee 5300 41fb     ...A.1.A...A.S.A
   ed0e0:	f200 4203 3a00 420a 8300 4210 cb00 4216     ...B.:.B...B...B
   ed0f0:	1400 421d 5c00 4223 a500 4229 ed00 422f     ...B.\#B..)B../B
   ed100:	3600 4236 7e00 423c c700 4242 0f00 4249     .66B.~<B..BB..IB

000ed110 <two_over_pi>:
   ed110:	00a2 0000 00f9 0000 0083 0000 006e 0000     ............n...
   ed120:	004e 0000 0044 0000 0015 0000 0029 0000     N...D.......)...
   ed130:	00fc 0000 0027 0000 0057 0000 00d1 0000     ....'...W.......
   ed140:	00f5 0000 0034 0000 00dd 0000 00c0 0000     ....4...........
   ed150:	00db 0000 0062 0000 0095 0000 0099 0000     ....b...........
   ed160:	003c 0000 0043 0000 0090 0000 0041 0000     <...C.......A...
   ed170:	00fe 0000 0051 0000 0063 0000 00ab 0000     ....Q...c.......
   ed180:	00de 0000 00bb 0000 00c5 0000 0061 0000     ............a...
   ed190:	00b7 0000 0024 0000 006e 0000 003a 0000     ....$...n...:...
   ed1a0:	0042 0000 004d 0000 00d2 0000 00e0 0000     B...M...........
   ed1b0:	0006 0000 0049 0000 002e 0000 00ea 0000     ....I...........
   ed1c0:	0009 0000 00d1 0000 0092 0000 001c 0000     ................
   ed1d0:	00fe 0000 001d 0000 00eb 0000 001c 0000     ................
   ed1e0:	00b1 0000 0029 0000 00a7 0000 003e 0000     ....).......>...
   ed1f0:	00e8 0000 0082 0000 0035 0000 00f5 0000     ........5.......
   ed200:	002e 0000 00bb 0000 0044 0000 0084 0000     ........D.......
   ed210:	00e9 0000 009c 0000 0070 0000 0026 0000     ........p...&...
   ed220:	00b4 0000 005f 0000 007e 0000 0041 0000     ...._...~...A...
   ed230:	0039 0000 0091 0000 00d6 0000 0039 0000     9...........9...
   ed240:	0083 0000 0053 0000 0039 0000 00f4 0000     ....S...9.......
   ed250:	009c 0000 0084 0000 005f 0000 008b 0000     ........_.......
   ed260:	00bd 0000 00f9 0000 0028 0000 003b 0000     ........(...;...
   ed270:	001f 0000 00f8 0000 0097 0000 00ff 0000     ................
   ed280:	00de 0000 0005 0000 0098 0000 000f 0000     ................
   ed290:	00ef 0000 002f 0000 0011 0000 008b 0000     ..../...........
   ed2a0:	005a 0000 000a 0000 006d 0000 001f 0000     Z.......m.......
   ed2b0:	006d 0000 0036 0000 007e 0000 00cf 0000     m...6...~.......
   ed2c0:	0027 0000 00cb 0000 0009 0000 00b7 0000     '...............
   ed2d0:	004f 0000 0046 0000 003f 0000 0066 0000     O...F...?...f...
   ed2e0:	009e 0000 005f 0000 00ea 0000 002d 0000     ...._.......-...
   ed2f0:	0075 0000 0027 0000 00ba 0000 00c7 0000     u...'...........
   ed300:	00eb 0000 00e5 0000 00f1 0000 007b 0000     ............{...
   ed310:	003d 0000 0007 0000 0039 0000 00f7 0000     =.......9.......
   ed320:	008a 0000 0052 0000 0092 0000 00ea 0000     ....R...........
   ed330:	006b 0000 00fb 0000 005f 0000 00b1 0000     k......._.......
   ed340:	001f 0000 008d 0000 005d 0000 0008 0000     ........].......
   ed350:	0056 0000 0003 0000 0030 0000 0046 0000     V.......0...F...
   ed360:	00fc 0000 007b 0000 006b 0000 00ab 0000     ....{...k.......
   ed370:	00f0 0000 00cf 0000 00bc 0000 0020 0000     ............ ...
   ed380:	009a 0000 00f4 0000 0036 0000 001d 0000     ........6.......
   ed390:	00a9 0000 00e3 0000 0091 0000 0061 0000     ............a...
   ed3a0:	005e 0000 00e6 0000 001b 0000 0008 0000     ^...............
   ed3b0:	0065 0000 0099 0000 0085 0000 005f 0000     e..........._...
   ed3c0:	0014 0000 00a0 0000 0068 0000 0040 0000     ........h...@...
   ed3d0:	008d 0000 00ff 0000 00d8 0000 0080 0000     ................
   ed3e0:	004d 0000 0073 0000 0027 0000 0031 0000     M...s...'...1...
   ed3f0:	0006 0000 0006 0000 0015 0000 0056 0000     ............V...
   ed400:	00ca 0000 0073 0000 00a8 0000 00c9 0000     ....s...........
   ed410:	0060 0000 00e2 0000 007b 0000 00c0 0000     `.......{.......
   ed420:	008c 0000 006b 0000                         ....k...

000ed428 <init_jk>:
   ed428:	0004 0000 0007 0000 0009 0000               ............

000ed434 <PIo2>:
   ed434:	0000 3fc9 0000 39f0 0000 37da 0000 33a2     ...?...9...7...3
   ed444:	0000 2e84 0000 2b50 0000 27c2 0000 22d0     ......P+...'..."
   ed454:	0000 1fc4 0000 1bc6 0000 1744               ..........D.

000ed460 <__sf_fake_stdin>:
	...

000ed480 <__sf_fake_stdout>:
	...

000ed4a0 <__sf_fake_stderr>:
	...

000ed4c0 <_global_impure_ptr>:
   ed4c0:	c238 2003                                   8.. 

000ed4c4 <link_const_variable_data_end>:
   ed4c4:	000d41ad 	.word	0x000d41ad
   ed4c8:	000d43b1 	.word	0x000d43b1
   ed4cc:	000d4e25 	.word	0x000d4e25
   ed4d0:	000d522d 	.word	0x000d522d
   ed4d4:	000d546d 	.word	0x000d546d
   ed4d8:	000d54c9 	.word	0x000d54c9
   ed4dc:	000d755d 	.word	0x000d755d
   ed4e0:	000e55bd 	.word	0x000e55bd
   ed4e4:	000e5649 	.word	0x000e5649
   ed4e8:	000e57c5 	.word	0x000e57c5
   ed4ec:	000e58e9 	.word	0x000e58e9
   ed4f0:	000e5a6d 	.word	0x000e5a6d
   ed4f4:	000e5be5 	.word	0x000e5be5
   ed4f8:	000e5d19 	.word	0x000e5d19
   ed4fc:	000e5d31 	.word	0x000e5d31
   ed500:	000e6165 	.word	0x000e6165
   ed504:	000e61b9 	.word	0x000e61b9
   ed508:	000e627d 	.word	0x000e627d
   ed50c:	000e6301 	.word	0x000e6301
   ed510:	000e6385 	.word	0x000e6385

000ed514 <link_constructors_end>:
	...
